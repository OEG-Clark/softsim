{"home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Random-Model.random_model.RandomModel.__init__": [[6, 9], ["ccobra.CCobraModel.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["import", "ccobra", "\n", "\n", "class", "RandomModel", "(", "ccobra", ".", "CCobraModel", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Random-Model.random_model.RandomModel.predict": [[10, 12], ["numpy.random.randint", "len"], "methods", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.TransitiveClosure.__init__": [[135, 137], ["ccobra.CCobraModel.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'TransitiveClosure'", ")", ":", "\n", "        ", "super", "(", "TransitiveClosure", ",", "self", ")", ".", "__init__", "(", "name", ",", "[", "'spatial-relational'", "]", ",", "[", "'verify'", ",", "\"accept\"", ",", "'single-choice'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.TransitiveClosure.predict": [[138, 154], ["transitive_closure.is_valid_conclusion", "transitive_closure.is_possible_model", "transitive_closure.is_valid_conclusion", "len", "result_options.append", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.is_valid_conclusion", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.is_possible_model", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.is_valid_conclusion"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "item", ".", "response_type", "==", "'verify'", ":", "\n", "            ", "return", "is_valid_conclusion", "(", "item", ".", "task", ",", "item", ".", "choices", "[", "0", "]", ")", "\n", "\n", "", "if", "item", ".", "response_type", "==", "'accept'", ":", "\n", "            ", "return", "is_possible_model", "(", "item", ".", "task", ",", "item", ".", "choices", "[", "0", "]", ")", "\n", "\n", "", "result_options", "=", "[", "]", "\n", "for", "choice", "in", "item", ".", "choices", ":", "\n", "            ", "if", "is_valid_conclusion", "(", "item", ".", "task", ",", "choice", ")", ":", "\n", "                ", "result_options", ".", "append", "(", "choice", ")", "\n", "\n", "", "", "if", "len", "(", "result_options", ")", "==", "0", ":", "\n", "            ", "result_options", "=", "item", ".", "choices", "\n", "\n", "", "return", "result_options", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "result_options", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.get_transitive_closure": [[31, 108], ["set", "set.update", "list", "x.lower", "rule.lower().split.split", "set.add", "len", "set", "set.update", "print", "rule.lower().split.lower().split", "len", "len", "rule2.lower().split.lower().split", "set", "rule.lower().split.lower", "COMBINATIONS.items", "rule2.lower().split.lower", "COMBINATIONS.items", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "set.add", "rule1_set.intersection", "set.add", "set.add"], "function", ["None"], ["def", "get_transitive_closure", "(", "premises", ",", "max_depth", "=", "10", ")", ":", "\n", "    ", "premises", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "premises", "]", "\n", "new_found", "=", "True", "\n", "it", "=", "0", "\n", "\n", "closure", "=", "set", "(", ")", "\n", "closure", ".", "update", "(", "premises", ")", "\n", "\n", "for", "rule", "in", "list", "(", "closure", ")", ":", "\n", "        ", "rule", "=", "rule", ".", "split", "(", "';'", ")", "\n", "closure", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "rule", "[", "0", "]", "]", ",", "rule", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "\n", "", "while", "new_found", ":", "\n", "        ", "if", "it", ">=", "max_depth", ":", "\n", "            ", "print", "(", "\"Break due to max-depth\"", ")", "\n", "break", "\n", "", "new_found", "=", "False", "\n", "c_size", "=", "len", "(", "closure", ")", "\n", "\n", "newly", "=", "set", "(", ")", "\n", "for", "rule", "in", "closure", ":", "\n", "            ", "rule", "=", "rule", ".", "lower", "(", ")", ".", "split", "(", "\";\"", ")", "\n", "\n", "for", "rule2", "in", "closure", ":", "\n", "                ", "if", "rule", "==", "rule2", ":", "\n", "                    ", "continue", "\n", "\n", "", "rule2", "=", "rule2", ".", "lower", "(", ")", ".", "split", "(", "\";\"", ")", "\n", "\n", "# Merge combined directions only in transitive case", "\n", "rule_set", "=", "set", "(", "[", "rule", "[", "0", "]", ",", "rule2", "[", "0", "]", "]", ")", "\n", "if", "rule", "[", "1", "]", "==", "rule2", "[", "1", "]", "and", "rule", "[", "2", "]", "==", "rule2", "[", "2", "]", ":", "\n", "                    ", "for", "key", ",", "value", "in", "COMBINATIONS", ".", "items", "(", ")", ":", "\n", "                        ", "if", "value", "==", "rule_set", ":", "\n", "                            ", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "key", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "key", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "", "", "", "elif", "rule", "[", "2", "]", "==", "rule2", "[", "1", "]", ":", "\n", "                    ", "for", "key", ",", "value", "in", "COMBINATIONS", ".", "items", "(", ")", ":", "\n", "                        ", "if", "value", "==", "rule_set", ":", "\n", "                            ", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "key", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "key", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "\n", "# Perform transitive closure", "\n", "", "", "", "if", "rule", "[", "2", "]", "==", "rule2", "[", "1", "]", ":", "\n", "                    ", "if", "rule", "[", "0", "]", "==", "rule2", "[", "0", "]", ":", "\n", "                        ", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "rule", "[", "0", "]", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "rule", "[", "0", "]", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "", "elif", "rule2", "[", "0", "]", "in", "COMBINATIONS", "and", "rule", "[", "0", "]", "in", "COMBINATIONS", "[", "rule2", "[", "0", "]", "]", ":", "\n", "# e.g., rule2 == north-east, rule == north", "\n", "# => north-east and north", "\n", "                        ", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "rule", "[", "0", "]", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "rule2", "[", "0", "]", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "rule", "[", "0", "]", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "rule2", "[", "0", "]", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "", "elif", "rule", "[", "0", "]", "in", "COMBINATIONS", "and", "rule2", "[", "0", "]", "in", "COMBINATIONS", "[", "rule", "[", "0", "]", "]", ":", "\n", "# e.g., rule == north-east, rule2 == north", "\n", "# => north-east and north", "\n", "                        ", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "rule", "[", "0", "]", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "rule2", "[", "0", "]", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "rule", "[", "0", "]", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "rule2", "[", "0", "]", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "", "elif", "rule", "[", "0", "]", "in", "COMBINATIONS", "and", "rule2", "[", "0", "]", "in", "COMBINATIONS", ":", "\n", "# e.g., north-east and north-west", "\n", "                        ", "rule1_set", "=", "COMBINATIONS", "[", "rule", "[", "0", "]", "]", "\n", "rule2_set", "=", "COMBINATIONS", "[", "rule2", "[", "0", "]", "]", "\n", "new_ops", "=", "rule1_set", ".", "intersection", "(", "rule2_set", ")", "\n", "for", "new_op", "in", "new_ops", ":", "\n", "                            ", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "new_op", ",", "rule", "[", "1", "]", ",", "rule2", "[", "2", "]", "]", ")", ")", "\n", "newly", ".", "add", "(", "\";\"", ".", "join", "(", "[", "OPPOSITES", "[", "new_op", "]", ",", "rule2", "[", "2", "]", ",", "rule", "[", "1", "]", "]", ")", ")", "\n", "\n", "", "", "", "", "", "closure", ".", "update", "(", "newly", ")", "\n", "\n", "if", "len", "(", "closure", ")", ">", "c_size", ":", "\n", "            ", "new_found", "=", "True", "\n", "c_size", "=", "len", "(", "closure", ")", "\n", "", "it", "+=", "1", "\n", "", "return", "closure", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.is_valid_conclusion": [[109, 118], ["transitive_closure.get_transitive_closure"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.get_transitive_closure"], ["", "def", "is_valid_conclusion", "(", "premises", ",", "conclusion", ")", ":", "\n", "    ", "premises_str", "=", "[", "\";\"", ".", "join", "(", "x", ")", ".", "lower", "(", ")", "for", "x", "in", "premises", "]", "\n", "closure", "=", "get_transitive_closure", "(", "premises_str", ")", "\n", "conclusion_strs", "=", "[", "\";\"", ".", "join", "(", "x", ")", ".", "lower", "(", ")", "for", "x", "in", "conclusion", "]", "\n", "\n", "for", "concl", "in", "conclusion_strs", ":", "\n", "        ", "if", "concl", "not", "in", "closure", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.is_possible_model": [[119, 133], ["transitive_closure.get_transitive_closure", "conclusion_strs.append", "partial_conclusion[].lower"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Transitive-Closure.transitive_closure.get_transitive_closure"], ["", "def", "is_possible_model", "(", "premises", ",", "conclusion", ")", ":", "\n", "    ", "premises_str", "=", "[", "\";\"", ".", "join", "(", "x", ")", ".", "lower", "(", ")", "for", "x", "in", "premises", "]", "\n", "closure", "=", "get_transitive_closure", "(", "premises_str", ")", "\n", "\n", "# invert the conclusions", "\n", "conclusion_strs", "=", "[", "]", "\n", "for", "partial_conclusion", "in", "conclusion", ":", "\n", "        ", "reverted", "=", "OPPOSITES", "[", "partial_conclusion", "[", "0", "]", ".", "lower", "(", ")", "]", "\n", "conclusion_strs", ".", "append", "(", "\"{};{};{}\"", ".", "format", "(", "reverted", ",", "partial_conclusion", "[", "1", "]", ",", "partial_conclusion", "[", "2", "]", ")", ".", "lower", "(", ")", ")", "\n", "\n", "", "for", "concl", "in", "conclusion_strs", ":", "\n", "        ", "if", "concl", "in", "closure", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Uniform-Model.uniform_model.UniformModel.__init__": [[6, 8], ["ccobra.CCobraModel.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'UniformModel'", ")", ":", "\n", "        ", "super", "(", "UniformModel", ",", "self", ")", ".", "__init__", "(", "name", ",", "[", "\"syllogistic\"", "]", ",", "[", "\"single-choice\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Uniform-Model.uniform_model.UniformModel.predict": [[9, 11], ["numpy.random.randint", "len"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "item", ".", "choices", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "item", ".", "choices", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.__init__": [[6, 12], ["ccobra.CCobraModel.__init__", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'MFAModel'", ",", "k", "=", "1", ")", ":", "\n", "        ", "super", "(", "MFAModel", ",", "self", ")", ".", "__init__", "(", "name", ",", "[", "\"syllogistic\"", "]", ",", "[", "\"single-choice\"", "]", ")", "\n", "\n", "# Initialize member variables", "\n", "self", ".", "mfa_population", "=", "dict", "(", ")", "\n", "self", ".", "mfa_personal", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.pre_train": [[13, 30], ["ccobra.syllogistic.Syllogism", "ccobra.syllogistic.Syllogism.encode_response", "dict", "mfa_model.MFAModel.mfa_population[].get"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get"], ["", "def", "pre_train", "(", "self", ",", "dataset", ")", ":", "\n", "# Iterate over subjects in the dataset", "\n", "        ", "for", "subj_data", "in", "dataset", ":", "\n", "# Iterate over the task for an individual subject", "\n", "            ", "for", "task_data", "in", "subj_data", ":", "\n", "# Create the syllogism object and extract the task and response encodings", "\n", "                ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "task_data", "[", "'item'", "]", ")", "\n", "encoded_task", "=", "syllogism", ".", "encoded_task", "\n", "encoded_response", "=", "syllogism", ".", "encode_response", "(", "task_data", "[", "'response'", "]", ")", "\n", "\n", "# Prepare the response counter for this task if not present already", "\n", "if", "encoded_task", "not", "in", "self", ".", "mfa_population", ":", "\n", "                    ", "self", ".", "mfa_population", "[", "encoded_task", "]", "=", "dict", "(", ")", "\n", "\n", "# Increment the response count for the present task", "\n", "", "self", ".", "mfa_population", "[", "encoded_task", "]", "[", "encoded_response", "]", "=", "self", ".", "mfa_population", "[", "encoded_task", "]", ".", "get", "(", "encoded_response", ",", "0", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.pre_train_person": [[32, 47], ["ccobra.syllogistic.Syllogism", "ccobra.syllogistic.Syllogism.encode_response", "dict", "mfa_model.MFAModel.mfa_personal[].get"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get"], ["", "", "", "def", "pre_train_person", "(", "self", ",", "dataset", ")", ":", "\n", "# Iterate over the given tasks for the individual subject to be predicted for", "\n", "        ", "for", "task_data", "in", "dataset", ":", "\n", "# Create the syllogism object and extract the task and response encodings", "\n", "            ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "task_data", "[", "'item'", "]", ")", "\n", "encoded_task", "=", "syllogism", ".", "encoded_task", "\n", "encoded_response", "=", "syllogism", ".", "encode_response", "(", "task_data", "[", "'response'", "]", ")", "\n", "\n", "# Prepare the response counter for this task if not present already", "\n", "if", "encoded_task", "not", "in", "self", ".", "mfa_personal", ":", "\n", "                ", "self", ".", "mfa_personal", "[", "encoded_task", "]", "=", "dict", "(", ")", "\n", "\n", "# Increment the response count for the present task", "\n", "", "self", ".", "mfa_personal", "[", "encoded_task", "]", "[", "encoded_response", "]", "=", "self", ".", "mfa_personal", "[", "encoded_task", "]", ".", "get", "(", "encoded_response", ",", "0", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.get_mfa_prediction": [[48, 82], ["ccobra.syllogistic.Syllogism", "ccobra.syllogistic.Syllogism.encode_response", "mfa_dictionary[].items", "potential_responses.append", "max_responses.append", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "", "def", "get_mfa_prediction", "(", "self", ",", "item", ",", "mfa_dictionary", ")", ":", "\n", "# Extract the encoded task", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "encoded_task", "=", "syllogism", ".", "encoded_task", "\n", "encoded_choices", "=", "[", "syllogism", ".", "encode_response", "(", "x", ")", "for", "x", "in", "item", ".", "choices", "]", "\n", "\n", "if", "encoded_task", "in", "mfa_dictionary", ":", "\n", "# Extract the potential MFA responses which are allowed in terms", "\n", "# of the possible response choices", "\n", "            ", "potential_responses", "=", "[", "]", "\n", "for", "response", ",", "count", "in", "mfa_dictionary", "[", "encoded_task", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "response", "in", "encoded_choices", ":", "\n", "                    ", "potential_responses", ".", "append", "(", "(", "response", ",", "count", ")", ")", "\n", "\n", "# If potential responses are available, determine the one with", "\n", "# maximum frequency", "\n", "", "", "if", "potential_responses", ":", "\n", "                ", "max_count", "=", "-", "1", "\n", "max_responses", "=", "[", "]", "\n", "for", "response", ",", "count", "in", "potential_responses", ":", "\n", "                    ", "if", "count", ">", "max_count", ":", "\n", "                        ", "max_count", "=", "count", "\n", "max_responses", "=", "[", "]", "\n", "\n", "", "if", "count", ">=", "max_count", ":", "\n", "                        ", "max_responses", ".", "append", "(", "response", ")", "\n", "\n", "# In case of ties, draw the MFA response at random from the options", "\n", "# with maximum frequency", "\n", "", "", "encoded_prediction", "=", "max_responses", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "max_responses", ")", "-", "1", ")", "]", "\n", "return", "encoded_prediction", "\n", "\n", "# If no MFA response is available, return None", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.predict": [[83, 99], ["ccobra.syllogistic.Syllogism", "mfa_model.MFAModel.get_mfa_prediction", "mfa_model.MFAModel.get_mfa_prediction", "ccobra.syllogistic.Syllogism.decode_response", "ccobra.syllogistic.Syllogism.decode_response", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.get_mfa_prediction", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.get_mfa_prediction", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "# Create the syllogism object", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "\n", "# Return the personal MFA if available", "\n", "personal_prediction", "=", "self", ".", "get_mfa_prediction", "(", "item", ",", "self", ".", "mfa_personal", ")", "\n", "if", "personal_prediction", "is", "not", "None", ":", "\n", "            ", "return", "syllogism", ".", "decode_response", "(", "personal_prediction", ")", "\n", "\n", "# Return the population MFA if available", "\n", "", "population_prediction", "=", "self", ".", "get_mfa_prediction", "(", "item", ",", "self", ".", "mfa_population", ")", "\n", "if", "population_prediction", "is", "not", "None", ":", "\n", "            ", "return", "syllogism", ".", "decode_response", "(", "population_prediction", ")", "\n", "\n", "# Return a random response if no MFA data is available", "\n", "", "return", "item", ".", "choices", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "item", ".", "choices", ")", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MFA-Model.mfa_model.MFAModel.adapt": [[100, 113], ["ccobra.syllogistic.Syllogism", "ccobra.syllogistic.Syllogism.encode_response", "dict", "mfa_model.MFAModel.mfa_personal[].get"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get"], ["", "def", "adapt", "(", "self", ",", "item", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "# Extract the encoded task and response", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "encoded_task", "=", "syllogism", ".", "encoded_task", "\n", "encoded_response", "=", "syllogism", ".", "encode_response", "(", "target", ")", "\n", "\n", "# Prepare the response counter for this task if not present already", "\n", "if", "encoded_task", "not", "in", "self", ".", "mfa_personal", ":", "\n", "            ", "self", ".", "mfa_personal", "[", "encoded_task", "]", "=", "dict", "(", ")", "\n", "\n", "# Increment the response count for the present task", "\n", "", "self", ".", "mfa_personal", "[", "encoded_task", "]", "[", "encoded_response", "]", "=", "self", ".", "mfa_personal", "[", "encoded_task", "]", ".", "get", "(", "encoded_response", ",", "0", ")", "+", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.NVC-Model.nvc_model.NVCModel.__init__": [[4, 6], ["ccobra.CCobraModel.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'NVCModel'", ")", ":", "\n", "        ", "super", "(", "NVCModel", ",", "self", ")", ".", "__init__", "(", "name", ",", "[", "\"syllogistic\"", "]", ",", "[", "\"single-choice\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.NVC-Model.nvc_model.NVCModel.predict": [[7, 9], ["None"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "[", "[", "'NVC'", "]", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Matching.matching.Matching.__init__": [[7, 16], ["ccobra.CCobraModel.__init__", "pandas.read_csv", "dict", "zip", "pred_df[].tolist", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Matching'", ")", ":", "\n", "        ", "super", "(", "Matching", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "pred_df", "=", "pd", ".", "read_csv", "(", "'Matching.csv'", ")", "\n", "self", ".", "predictions", "=", "dict", "(", "\n", "zip", "(", "\n", "pred_df", "[", "'Syllogism'", "]", ".", "tolist", "(", ")", ",", "\n", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "pred_df", "[", "'Prediction'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Matching.matching.Matching.predict": [[17, 22], ["ccobra.syllogistic.encode_task", "ccobra.syllogistic.decode_response", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "enc_task", "=", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "item", ".", "task", ")", "\n", "enc_resp", "=", "self", ".", "predictions", "[", "enc_task", "]", "\n", "dec_resp", "=", "[", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "enc_resp", "]", "\n", "return", "dec_resp", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dec_resp", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Conversion.conversion.Conversion.__init__": [[7, 16], ["ccobra.CCobraModel.__init__", "pandas.read_csv", "dict", "zip", "pred_df[].tolist", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Conversion'", ")", ":", "\n", "        ", "super", "(", "Conversion", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "pred_df", "=", "pd", ".", "read_csv", "(", "'Conversion.csv'", ")", "\n", "self", ".", "predictions", "=", "dict", "(", "\n", "zip", "(", "\n", "pred_df", "[", "'Syllogism'", "]", ".", "tolist", "(", ")", ",", "\n", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "pred_df", "[", "'Prediction'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Conversion.conversion.Conversion.predict": [[17, 22], ["ccobra.syllogistic.encode_task", "ccobra.syllogistic.decode_response", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "enc_task", "=", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "item", ".", "task", ")", "\n", "enc_resp", "=", "self", ".", "predictions", "[", "enc_task", "]", "\n", "dec_resp", "=", "[", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "enc_resp", "]", "\n", "return", "dec_resp", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dec_resp", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.PSYCOP.psycop.PSYCOP.__init__": [[7, 16], ["ccobra.CCobraModel.__init__", "pandas.read_csv", "dict", "zip", "pred_df[].tolist", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'PSYCOP'", ")", ":", "\n", "        ", "super", "(", "PSYCOP", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "pred_df", "=", "pd", ".", "read_csv", "(", "'PSYCOP.csv'", ")", "\n", "self", ".", "predictions", "=", "dict", "(", "\n", "zip", "(", "\n", "pred_df", "[", "'Syllogism'", "]", ".", "tolist", "(", ")", ",", "\n", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "pred_df", "[", "'Prediction'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.PSYCOP.psycop.PSYCOP.predict": [[17, 22], ["ccobra.syllogistic.encode_task", "ccobra.syllogistic.decode_response", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "enc_task", "=", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "item", ".", "task", ")", "\n", "enc_resp", "=", "self", ".", "predictions", "[", "enc_task", "]", "\n", "dec_resp", "=", "[", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "enc_resp", "]", "\n", "return", "dec_resp", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dec_resp", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.VerbalModels.verbalmodels.VerbalModels.__init__": [[7, 16], ["ccobra.CCobraModel.__init__", "pandas.read_csv", "dict", "zip", "pred_df[].tolist", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'VerbalModels'", ")", ":", "\n", "        ", "super", "(", "VerbalModels", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "pred_df", "=", "pd", ".", "read_csv", "(", "'VerbalModels.csv'", ")", "\n", "self", ".", "predictions", "=", "dict", "(", "\n", "zip", "(", "\n", "pred_df", "[", "'Syllogism'", "]", ".", "tolist", "(", ")", ",", "\n", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "pred_df", "[", "'Prediction'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.VerbalModels.verbalmodels.VerbalModels.predict": [[17, 22], ["ccobra.syllogistic.encode_task", "ccobra.syllogistic.decode_response", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "enc_task", "=", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "item", ".", "task", ")", "\n", "enc_resp", "=", "self", ".", "predictions", "[", "enc_task", "]", "\n", "dec_resp", "=", "[", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "enc_resp", "]", "\n", "return", "dec_resp", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dec_resp", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.PHM.phm.PHM.__init__": [[7, 16], ["ccobra.CCobraModel.__init__", "pandas.read_csv", "dict", "zip", "pred_df[].tolist", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'PHM'", ")", ":", "\n", "        ", "super", "(", "PHM", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "pred_df", "=", "pd", ".", "read_csv", "(", "'PHM.csv'", ")", "\n", "self", ".", "predictions", "=", "dict", "(", "\n", "zip", "(", "\n", "pred_df", "[", "'Syllogism'", "]", ".", "tolist", "(", ")", ",", "\n", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "pred_df", "[", "'Prediction'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.PHM.phm.PHM.predict": [[17, 22], ["ccobra.syllogistic.encode_task", "ccobra.syllogistic.decode_response", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "enc_task", "=", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "item", ".", "task", ")", "\n", "enc_resp", "=", "self", ".", "predictions", "[", "enc_task", "]", "\n", "dec_resp", "=", "[", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "enc_resp", "]", "\n", "return", "dec_resp", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dec_resp", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MentalModels.mmt.MMT.__init__": [[7, 16], ["ccobra.CCobraModel.__init__", "pandas.read_csv", "dict", "zip", "pred_df[].tolist", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'MMT'", ")", ":", "\n", "        ", "super", "(", "MMT", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "pred_df", "=", "pd", ".", "read_csv", "(", "'MMT.csv'", ")", "\n", "self", ".", "predictions", "=", "dict", "(", "\n", "zip", "(", "\n", "pred_df", "[", "'Syllogism'", "]", ".", "tolist", "(", ")", ",", "\n", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "pred_df", "[", "'Prediction'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.MentalModels.mmt.MMT.predict": [[17, 22], ["ccobra.syllogistic.encode_task", "ccobra.syllogistic.decode_response", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "enc_task", "=", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "item", ".", "task", ")", "\n", "enc_resp", "=", "self", ".", "predictions", "[", "enc_task", "]", "\n", "dec_resp", "=", "[", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "enc_resp", "]", "\n", "return", "dec_resp", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dec_resp", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Atmosphere.atmosphere.Atmosphere.__init__": [[7, 16], ["ccobra.CCobraModel.__init__", "pandas.read_csv", "dict", "zip", "pred_df[].tolist", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Atmosphere'", ")", ":", "\n", "        ", "super", "(", "Atmosphere", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "pred_df", "=", "pd", ".", "read_csv", "(", "'Atmosphere.csv'", ")", "\n", "self", ".", "predictions", "=", "dict", "(", "\n", "zip", "(", "\n", "pred_df", "[", "'Syllogism'", "]", ".", "tolist", "(", ")", ",", "\n", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "pred_df", "[", "'Prediction'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.Atmosphere.atmosphere.Atmosphere.predict": [[17, 22], ["ccobra.syllogistic.encode_task", "ccobra.syllogistic.decode_response", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "enc_task", "=", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "item", ".", "task", ")", "\n", "enc_resp", "=", "self", ".", "predictions", "[", "enc_task", "]", "\n", "dec_resp", "=", "[", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "enc_resp", "]", "\n", "return", "dec_resp", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "dec_resp", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.onehot.onehot_syllogism": [[5, 9], ["numpy.zeros", "ccobra.syllogistic.SYLLOGISMS.index"], "function", ["None"], ["def", "onehot_syllogism", "(", "syl", ")", ":", "\n", "    ", "result", "=", "np", ".", "zeros", "(", "(", "64", ",", ")", ",", "dtype", "=", "'float'", ")", "\n", "result", "[", "ccobra", ".", "syllogistic", ".", "SYLLOGISMS", ".", "index", "(", "syl", ")", "]", "=", "1", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.onehot.onehot_syllogism_content": [[10, 27], ["numpy.zeros", "quants.index", "quants.index", "int"], "function", ["None"], ["", "def", "onehot_syllogism_content", "(", "syl", ")", ":", "\n", "    ", "\"\"\"\n    >>> onehot_syllogism('AA1')\n    array([1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n    >>> onehot_syllogism('OI3')\n    array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n    >>> onehot_syllogism('IE4')\n    array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n\n    \"\"\"", "\n", "\n", "task", "=", "np", ".", "zeros", "(", "(", "12", ",", ")", ",", "dtype", "=", "'float'", ")", "\n", "quants", "=", "quants", "=", "[", "'A'", ",", "'I'", ",", "'E'", ",", "'O'", "]", "\n", "task", "[", "quants", ".", "index", "(", "syl", "[", "0", "]", ")", "]", "=", "1", "\n", "task", "[", "4", "+", "quants", ".", "index", "(", "syl", "[", "1", "]", ")", "]", "=", "1", "\n", "task", "[", "8", "+", "int", "(", "syl", "[", "2", "]", ")", "-", "1", "]", "=", "1", "\n", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.onehot.onehot_response": [[28, 42], ["numpy.zeros", "ccobra.syllogistic.RESPONSES.index"], "function", ["None"], ["", "def", "onehot_response", "(", "response", ")", ":", "\n", "    ", "\"\"\"\n    >>> onehot_response('Aac')\n    array([1., 0., 0., 0., 0., 0., 0., 0., 0.])\n    >>> onehot_response('NVC')\n    array([0., 0., 0., 0., 0., 0., 0., 0., 1.])\n    >>> onehot_response('Oca')\n    array([0., 0., 0., 0., 0., 0., 0., 1., 0.])\n\n    \"\"\"", "\n", "\n", "resp", "=", "np", ".", "zeros", "(", "(", "9", ",", ")", ",", "dtype", "=", "'float'", ")", "\n", "resp", "[", "ccobra", ".", "syllogistic", ".", "RESPONSES", ".", "index", "(", "response", ")", "]", "=", "1", "\n", "return", "resp", "\n", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.sylmlp.SylMLP.__init__": [[14, 20], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SylMLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "12", ",", "256", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "256", ",", "256", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "256", ",", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.sylmlp.SylMLP.forward": [[21, 26], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "sylmlp.SylMLP.fc3", "sylmlp.SylMLP.fc1", "sylmlp.SylMLP.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.sylmlp.MLPModel.__init__": [[28, 40], ["ccobra.CCobraModel.__init__", "sylmlp.SylMLP", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "sylmlp.MLPModel.net.parameters"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'MLP-Adapt'", ")", ":", "\n", "        ", "super", "(", "MLPModel", ",", "self", ")", ".", "__init__", "(", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "# Initialize the neural network", "\n", "self", ".", "net", "=", "SylMLP", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "\n", "# General training properties", "\n", "self", ".", "n_epochs", "=", "50", "\n", "self", ".", "n_epochs_adapt", "=", "3", "\n", "self", ".", "batch_size", "=", "8", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.sylmlp.MLPModel.pre_train": [[41, 63], ["torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "sylmlp.MLPModel.train_network", "ccobra.syllogistic.Syllogism", "onehot.onehot_syllogism_content", "ccobra.syllogistic.Syllogism.encode_response", "onehot.onehot_response", "train_x.append", "train_y.append", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNNModel.train_network", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_syllogism_content", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_response"], ["", "def", "pre_train", "(", "self", ",", "dataset", ",", "**", "kwargs", ")", ":", "\n", "        ", "train_x", "=", "[", "]", "\n", "train_y", "=", "[", "]", "\n", "\n", "for", "subj_data", "in", "dataset", ":", "\n", "            ", "for", "task_data", "in", "subj_data", ":", "\n", "                ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "task_data", "[", "'item'", "]", ")", "\n", "\n", "# Encode the task input", "\n", "task", "=", "onehot", ".", "onehot_syllogism_content", "(", "syllogism", ".", "encoded_task", ")", "\n", "\n", "# Encode the response output", "\n", "encoded_response", "=", "syllogism", ".", "encode_response", "(", "task_data", "[", "'response'", "]", ")", "\n", "resp", "=", "onehot", ".", "onehot_response", "(", "encoded_response", ")", "\n", "\n", "train_x", ".", "append", "(", "task", ")", "\n", "train_y", ".", "append", "(", "resp", ")", "\n", "\n", "", "", "self", ".", "train_x", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "train_x", ")", ")", ".", "float", "(", ")", "\n", "self", ".", "train_y", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "train_y", ")", ")", ".", "float", "(", ")", "\n", "\n", "self", ".", "train_network", "(", "self", ".", "train_x", ",", "self", ".", "train_y", ",", "self", ".", "batch_size", ",", "self", ".", "n_epochs", ",", "verbose", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.sylmlp.MLPModel.train_network": [[64, 96], ["range", "time.time", "numpy.random.permutation", "range", "numpy.arange", "sylmlp.MLPModel.optimizer.zero_grad", "sylmlp.MLPModel.net", "sylmlp.MLPModel.criterion", "sylmlp.MLPModel.backward", "sylmlp.MLPModel.optimizer.step", "losses.append", "print", "len", "len", "sylmlp.MLPModel.item", "numpy.mean", "time.time"], "methods", ["None"], ["", "def", "train_network", "(", "self", ",", "train_x", ",", "train_y", ",", "batch_size", ",", "n_epochs", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Shuffle the training data", "\n", "perm_idxs", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "train_x", ")", ")", ")", "\n", "train_x", "=", "train_x", "[", "perm_idxs", "]", "\n", "train_y", "=", "train_y", "[", "perm_idxs", "]", "\n", "\n", "# Batched training loop", "\n", "losses", "=", "[", "]", "\n", "for", "batch_idx", "in", "range", "(", "len", "(", "train_x", ")", "//", "batch_size", ")", ":", "\n", "                ", "start", "=", "batch_idx", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "epoch_x", "=", "train_x", "[", "start", ":", "end", "]", "\n", "epoch_y", "=", "train_y", "[", "start", ":", "end", "]", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Optimize", "\n", "outputs", "=", "self", ".", "net", "(", "epoch_x", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "outputs", ",", "epoch_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Print statistics", "\n", "", "if", "verbose", ":", "\n", "                ", "print", "(", "'Epoch {} ({:.2f}s): {}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "np", ".", "mean", "(", "losses", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.sylmlp.MLPModel.predict": [[97, 110], ["ccobra.syllogistic.Syllogism", "onehot.onehot_syllogism_content", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "sylmlp.MLPModel.net", "sylmlp.MLPModel.argmax().item", "ccobra.syllogistic.Syllogism.decode_response", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "sylmlp.MLPModel.argmax"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_syllogism_content", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "", "", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "# Encode the task", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "\n", "# Query the model", "\n", "inp", "=", "onehot", ".", "onehot_syllogism_content", "(", "syllogism", ".", "encoded_task", ")", "\n", "inp_tensor", "=", "torch", ".", "from_numpy", "(", "inp", ")", ".", "float", "(", ")", "\n", "output", "=", "self", ".", "net", "(", "inp_tensor", ")", "\n", "\n", "# Return maximum response", "\n", "response", "=", "output", ".", "argmax", "(", ")", ".", "item", "(", ")", "\n", "enc_response", "=", "ccobra", ".", "syllogistic", ".", "RESPONSES", "[", "response", "]", "\n", "return", "syllogism", ".", "decode_response", "(", "enc_response", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.mlp.sylmlp.MLPModel.adapt": [[111, 122], ["ccobra.syllogistic.Syllogism", "onehot.onehot_syllogism_content", "onehot.onehot_response", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "sylmlp.MLPModel.train_network", "ccobra.syllogistic.Syllogism.encode_response", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "onehot.onehot_syllogism_content.reshape", "onehot.onehot_response.reshape"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_syllogism_content", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNNModel.train_network", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "adapt", "(", "self", ",", "item", ",", "truth", ",", "**", "kwargs", ")", ":", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "\n", "# Onehot encoding", "\n", "onehot_syl", "=", "onehot", ".", "onehot_syllogism_content", "(", "syllogism", ".", "encoded_task", ")", "\n", "onehot_resp", "=", "onehot", ".", "onehot_response", "(", "syllogism", ".", "encode_response", "(", "truth", ")", ")", "\n", "\n", "adapt_x", "=", "torch", ".", "from_numpy", "(", "onehot_syl", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "adapt_y", "=", "torch", ".", "from_numpy", "(", "onehot_resp", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "\n", "self", ".", "train_network", "(", "adapt_x", ",", "adapt_y", ",", "1", ",", "self", ".", "n_epochs_adapt", ",", "verbose", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNN.__init__": [[13, 22], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", "=", "12", ",", "hidden_size", "=", "64", ",", "output_size", "=", "9", ")", ":", "\n", "        ", "super", "(", "RNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "\n", "dropout", "=", "0.2", ")", "\n", "self", ".", "h2o", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNN.forward": [[23, 27], ["sylrnn.RNN.lstm", "sylrnn.RNN.h2o"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "output", ",", "hidden", "=", "self", ".", "lstm", "(", "input", ",", "hidden", ")", "\n", "output", "=", "self", ".", "h2o", "(", "output", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNNModel.__init__": [[29, 42], ["ccobra.CCobraModel.__init__", "sylrnn.RNN", "torch.Adam", "torch.Adam", "torch.Adam", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "sylrnn.RNNModel.net.parameters"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'RNN'", ")", ":", "\n", "        ", "super", "(", "RNNModel", ",", "self", ")", ".", "__init__", "(", "\n", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "self", ".", "net", "=", "RNN", "(", ")", "\n", "self", ".", "hidden", "=", "None", "\n", "\n", "# Training parameters", "\n", "self", ".", "n_epochs", "=", "13", "\n", "\n", "# Training algorithms", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "parameters", "(", ")", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNNModel.pre_train": [[43, 70], ["torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "sylrnn.RNNModel.train_network", "train_x.append", "train_y.append", "ccobra.syllogistic.Syllogism", "onehot.onehot_syllogism_content", "onehot.onehot_response", "subj_train_x.append", "subj_train_y.append", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "ccobra.syllogistic.Syllogism.encode_response", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNNModel.train_network", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_syllogism_content", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "pre_train", "(", "self", ",", "dataset", ")", ":", "\n", "# Prepare the data for training by converting it into a 64 x n_subj x 12", "\n", "        ", "train_x", "=", "[", "]", "\n", "train_y", "=", "[", "]", "\n", "\n", "for", "subj_data", "in", "dataset", ":", "\n", "            ", "subj_train_x", "=", "[", "]", "\n", "subj_train_y", "=", "[", "]", "\n", "\n", "for", "task_data", "in", "subj_data", ":", "\n", "                ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "task_data", "[", "'item'", "]", ")", "\n", "\n", "# Onehot encodings", "\n", "onehot_task", "=", "onehot", ".", "onehot_syllogism_content", "(", "syllogism", ".", "encoded_task", ")", "\n", "onehot_response", "=", "onehot", ".", "onehot_response", "(", "\n", "syllogism", ".", "encode_response", "(", "task_data", "[", "'response'", "]", ")", ")", "\n", "\n", "subj_train_x", ".", "append", "(", "onehot_task", ")", "\n", "subj_train_y", ".", "append", "(", "onehot_response", ")", "\n", "\n", "", "train_x", ".", "append", "(", "subj_train_x", ")", "\n", "train_y", ".", "append", "(", "subj_train_y", ")", "\n", "\n", "", "self", ".", "train_x", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "train_x", ")", ")", ".", "float", "(", ")", "\n", "self", ".", "train_y", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "train_y", ")", ")", ".", "float", "(", ")", "\n", "\n", "self", ".", "train_network", "(", "self", ".", "train_x", ",", "self", ".", "train_y", ",", "self", ".", "n_epochs", ",", "verbose", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNNModel.train_network": [[71, 119], ["print", "range", "time.time", "numpy.random.permutation", "range", "print", "range", "print", "print", "sylrnn.RNNModel.net.eval", "numpy.arange", "len", "cur_x.view", "sylrnn.RNNModel.net", "sylrnn.RNNModel.criterion", "sylrnn.RNNModel.optimizer.zero_grad", "sylrnn.RNNModel.backward", "sylrnn.RNNModel.optimizer.step", "losses.append", "len", "sylrnn.RNNModel.net", "pred.view().argmax", "sylrnn.RNNModel.train_y[].argmax", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "accs.append", "len", "outputs.view", "cur_y.argmax", "sylrnn.RNNModel.item", "numpy.mean", "numpy.std", "sylrnn.RNNModel.train_x[].view", "numpy.mean", "numpy.std", "time.time", "pred.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "train_network", "(", "self", ",", "train_x", ",", "train_y", ",", "n_epochs", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "print", "(", "'Starting training...'", ")", "\n", "for", "epoch", "in", "range", "(", "self", ".", "n_epochs", ")", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Shuffle the training data", "\n", "perm_idxs", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "train_x", ")", ")", ")", "\n", "train_x", "=", "train_x", "[", "perm_idxs", "]", "\n", "train_y", "=", "train_y", "[", "perm_idxs", "]", "\n", "\n", "# Loop over the training instances", "\n", "losses", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "train_x", ")", ")", ":", "\n", "                ", "cur_x", "=", "train_x", "[", "idx", "]", "\n", "cur_y", "=", "train_y", "[", "idx", "]", "\n", "\n", "input", "=", "cur_x", ".", "view", "(", "64", ",", "1", ",", "-", "1", ")", "\n", "outputs", ",", "_", "=", "self", ".", "net", "(", "input", ",", "None", ")", "\n", "\n", "# Backpropagation and parameter optimization", "\n", "loss", "=", "self", ".", "criterion", "(", "outputs", ".", "view", "(", "64", ",", "-", "1", ")", ",", "cur_y", ".", "argmax", "(", "1", ")", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Print statistics", "\n", "", "print", "(", "'Epoch {}/{} ({:.2f}s): {:.4f} ({:.4f})'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "n_epochs", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "np", ".", "mean", "(", "losses", ")", ",", "np", ".", "std", "(", "losses", ")", ")", ")", "\n", "\n", "# Test the predictive accuracy", "\n", "accs", "=", "[", "]", "\n", "for", "subj_idx", "in", "range", "(", "len", "(", "self", ".", "train_x", ")", ")", ":", "\n", "                ", "pred", ",", "_", "=", "self", ".", "net", "(", "self", ".", "train_x", "[", "subj_idx", "]", ".", "view", "(", "64", ",", "1", ",", "-", "1", ")", ",", "None", ")", "\n", "pred_max", "=", "pred", ".", "view", "(", "64", ",", "-", "1", ")", ".", "argmax", "(", "1", ")", "\n", "truth", "=", "self", ".", "train_y", "[", "subj_idx", "]", ".", "argmax", "(", "1", ")", "\n", "\n", "acc", "=", "torch", ".", "mean", "(", "(", "pred_max", "==", "truth", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", "\n", "accs", ".", "append", "(", "acc", ")", "\n", "\n", "", "print", "(", "'   acc mean: {:.2f}'", ".", "format", "(", "np", ".", "mean", "(", "accs", ")", ")", ")", "\n", "print", "(", "'   acc std : {:.2f}'", ".", "format", "(", "np", ".", "std", "(", "accs", ")", ")", ")", "\n", "\n", "# input = torch.from_numpy(onehot.onehot_syllogism_content('AA1')).float().view(1, -1)", "\n", "# print('   AA1:', self.net(input, self.net.initHidden()))", "\n", "\n", "self", ".", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.sylrnn.RNNModel.predict": [[120, 131], ["ccobra.syllogistic.Syllogism", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "sylrnn.RNNModel.net", "output.argmax().item", "ccobra.syllogistic.Syllogism.decode_response", "torch.from_numpy().float.view", "torch.from_numpy().float.view", "torch.from_numpy().float.view", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "output.argmax", "onehot.onehot_syllogism_content"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_syllogism_content"], ["", "", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "\n", "# Obtain the prediction", "\n", "input", "=", "torch", ".", "from_numpy", "(", "onehot", ".", "onehot_syllogism_content", "(", "syllogism", ".", "encoded_task", ")", ")", ".", "float", "(", ")", "\n", "output", ",", "self", ".", "hidden", "=", "self", ".", "net", "(", "input", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", ",", "self", ".", "hidden", ")", "\n", "\n", "# Return maximum response", "\n", "response", "=", "output", ".", "argmax", "(", ")", ".", "item", "(", ")", "\n", "enc_response", "=", "ccobra", ".", "syllogistic", ".", "RESPONSES", "[", "response", "]", "\n", "return", "syllogism", ".", "decode_response", "(", "enc_response", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_syllogism": [[5, 9], ["numpy.zeros", "ccobra.syllogistic.SYLLOGISMS.index"], "function", ["None"], ["def", "onehot_syllogism", "(", "syl", ")", ":", "\n", "    ", "result", "=", "np", ".", "zeros", "(", "(", "64", ",", ")", ",", "dtype", "=", "'float'", ")", "\n", "result", "[", "ccobra", ".", "syllogistic", ".", "SYLLOGISMS", ".", "index", "(", "syl", ")", "]", "=", "1", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_syllogism_content": [[10, 27], ["numpy.zeros", "quants.index", "quants.index", "int"], "function", ["None"], ["", "def", "onehot_syllogism_content", "(", "syl", ")", ":", "\n", "    ", "\"\"\"\n    >>> onehot_syllogism('AA1')\n    array([1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n    >>> onehot_syllogism('OI3')\n    array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.])\n    >>> onehot_syllogism('IE4')\n    array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n\n    \"\"\"", "\n", "\n", "task", "=", "np", ".", "zeros", "(", "(", "12", ",", ")", ",", "dtype", "=", "'float'", ")", "\n", "quants", "=", "quants", "=", "[", "'A'", ",", "'I'", ",", "'E'", ",", "'O'", "]", "\n", "task", "[", "quants", ".", "index", "(", "syl", "[", "0", "]", ")", "]", "=", "1", "\n", "task", "[", "4", "+", "quants", ".", "index", "(", "syl", "[", "1", "]", ")", "]", "=", "1", "\n", "task", "[", "8", "+", "int", "(", "syl", "[", "2", "]", ")", "-", "1", "]", "=", "1", "\n", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.rnn.onehot.onehot_response": [[28, 42], ["numpy.zeros", "ccobra.syllogistic.RESPONSES.index"], "function", ["None"], ["", "def", "onehot_response", "(", "response", ")", ":", "\n", "    ", "\"\"\"\n    >>> onehot_response('Aac')\n    array([1., 0., 0., 0., 0., 0., 0., 0., 0.])\n    >>> onehot_response('NVC')\n    array([0., 0., 0., 0., 0., 0., 0., 0., 1.])\n    >>> onehot_response('Oca')\n    array([0., 0., 0., 0., 0., 0., 0., 1., 0.])\n\n    \"\"\"", "\n", "\n", "resp", "=", "np", ".", "zeros", "(", "(", "9", ",", ")", ",", "dtype", "=", "'float'", ")", "\n", "resp", "[", "ccobra", ".", "syllogistic", ".", "RESPONSES", ".", "index", "(", "response", ")", "]", "=", "1", "\n", "return", "resp", "\n", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.autoencoder.autoenc_model.SylMLPModel.__init__": [[13, 24], ["ccobra.CCobraModel.__init__", "autoencoder.DenoisingAutoencoder", "print", "print", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "autoenc_model.SylMLPModel.net.parameters", "list", "autoenc_model.SylMLPModel.net.parameters"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Autoencoder'", ")", ":", "\n", "        ", "super", "(", "SylMLPModel", ",", "self", ")", ".", "__init__", "(", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n", "self", ".", "net", "=", "autoencoder", ".", "DenoisingAutoencoder", "(", ")", "\n", "print", "(", "'n_parameters:'", ",", "len", "(", "list", "(", "self", ".", "net", ".", "parameters", "(", ")", ")", ")", ")", "\n", "print", "(", "self", ".", "net", ")", "\n", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "parameters", "(", ")", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "self", ".", "history", "=", "torch", ".", "zeros", "(", "(", "576", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.autoencoder.autoenc_model.SylMLPModel.pre_train": [[25, 84], ["torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "print", "print", "range", "numpy.zeros", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "numpy.random.permutation", "range", "print", "ccobra.syllogistic.Syllogism", "ccobra.syllogistic.Syllogism.encode_response", "ccobra.syllogistic.SYLLOGISMS.index", "ccobra.syllogistic.RESPONSES.index", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.arange", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "autoenc_model.SylMLPModel.optimizer.zero_grad", "autoenc_model.SylMLPModel.net", "autoenc_model.SylMLPModel.criterion", "autoenc_model.SylMLPModel.backward", "autoenc_model.SylMLPModel.optimizer.step", "epoch_losses.append", "numpy.array", "numpy.array", "len", "len", "autoenc_model.SylMLPModel.item", "numpy.mean", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "pre_train", "(", "self", ",", "dataset", ")", ":", "\n", "# Extract the training data and result targets from the training dataset", "\n", "        ", "train_x", "=", "[", "]", "\n", "train_y", "=", "[", "]", "\n", "for", "train_subject", "in", "dataset", ":", "\n", "            ", "user_vector", "=", "np", ".", "zeros", "(", "(", "576", ",", ")", ",", "dtype", "=", "'int'", ")", "\n", "\n", "for", "train_task", "in", "train_subject", ":", "\n", "                ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "train_task", "[", "'item'", "]", ")", "\n", "\n", "enc_task", "=", "syllogism", ".", "encoded_task", "\n", "enc_truth", "=", "syllogism", ".", "encode_response", "(", "train_task", "[", "'response'", "]", ")", "\n", "\n", "task_idx", "=", "ccobra", ".", "syllogistic", ".", "SYLLOGISMS", ".", "index", "(", "enc_task", ")", "\n", "truth_idx", "=", "ccobra", ".", "syllogistic", ".", "RESPONSES", ".", "index", "(", "enc_truth", ")", "\n", "\n", "user_vector", "[", "task_idx", "*", "9", "+", "truth_idx", "]", "=", "1", "\n", "\n", "", "train_x", ".", "append", "(", "user_vector", ")", "\n", "train_y", ".", "append", "(", "user_vector", ")", "\n", "\n", "", "train_x", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "train_x", ")", ")", ".", "float", "(", ")", "\n", "train_y", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "train_y", ")", ")", ".", "float", "(", ")", "\n", "\n", "print", "(", "'train_x:'", ",", "train_x", ".", "shape", ")", "\n", "print", "(", "'train_y:'", ",", "train_y", ".", "shape", ")", "\n", "\n", "batch_size", "=", "32", "\n", "epochs", "=", "30", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "# Randomize the inputs", "\n", "            ", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "train_x", ")", ")", ")", "\n", "train_x", "=", "train_x", "[", "permutation", "]", "\n", "train_y", "=", "train_y", "[", "permutation", "]", "\n", "\n", "epoch_losses", "=", "[", "]", "\n", "for", "mb_idx", "in", "range", "(", "len", "(", "train_x", ")", "//", "batch_size", ")", ":", "\n", "                ", "start", "=", "mb_idx", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "mb_x", "=", "train_x", "[", "start", ":", "end", "]", "\n", "mb_y", "=", "mb_x", "\n", "\n", "# Noise the input", "\n", "input_data", "=", "mb_x", "\n", "noise", "=", "torch", ".", "bernoulli", "(", "torch", ".", "zeros_like", "(", "input_data", ")", "+", "0.8", ")", "\n", "input_data", "=", "input_data", "*", "noise", "\n", "\n", "# Perform the training on the minibatch", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "outputs", "=", "self", ".", "net", "(", "input_data", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "outputs", ",", "mb_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "epoch_losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "print", "(", "'Epoch {}/{}: {}...'", ".", "format", "(", "epoch", "+", "1", ",", "epochs", ",", "np", ".", "mean", "(", "epoch_losses", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.autoencoder.autoenc_model.SylMLPModel.predict": [[85, 93], ["ccobra.syllogistic.Syllogism", "ccobra.syllogistic.SYLLOGISMS.index", "[].argmax().item", "ccobra.syllogistic.Syllogism.decode_response", "[].argmax", "autoenc_model.SylMLPModel.net"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "enc_task", "=", "syllogism", ".", "encoded_task", "\n", "task_idx", "=", "ccobra", ".", "syllogistic", ".", "SYLLOGISMS", ".", "index", "(", "enc_task", ")", "\n", "\n", "# Query the network for the user completion", "\n", "pred_idx", "=", "self", ".", "net", "(", "self", ".", "history", ")", "[", "task_idx", "*", "9", ":", "task_idx", "*", "9", "+", "9", "]", ".", "argmax", "(", ")", ".", "item", "(", ")", "\n", "return", "syllogism", ".", "decode_response", "(", "ccobra", ".", "syllogistic", ".", "RESPONSES", "[", "pred_idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.autoencoder.autoenc_model.SylMLPModel.adapt": [[94, 99], ["ccobra.syllogistic.Syllogism", "ccobra.syllogistic.SYLLOGISMS.index", "ccobra.syllogistic.RESPONSES.index", "ccobra.syllogistic.Syllogism.encode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "adapt", "(", "self", ",", "item", ",", "truth", ",", "**", "kwargs", ")", ":", "\n", "        ", "syllogism", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "syl_idx", "=", "ccobra", ".", "syllogistic", ".", "SYLLOGISMS", ".", "index", "(", "syllogism", ".", "encoded_task", ")", "\n", "truth_idx", "=", "ccobra", ".", "syllogistic", ".", "RESPONSES", ".", "index", "(", "syllogism", ".", "encode_response", "(", "truth", ")", ")", "\n", "self", ".", "history", "[", "syl_idx", "*", "9", "+", "truth_idx", "]", "=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.autoencoder.autoencoder.DenoisingAutoencoder.__init__": [[5, 10], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DenoisingAutoencoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "576", ",", "2000", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "2000", ",", "576", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.autoencoder.autoencoder.DenoisingAutoencoder.forward": [[11, 15], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "autoencoder.DenoisingAutoencoder.fc1", "autoencoder.DenoisingAutoencoder.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "torch", ".", "sigmoid", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "torch", ".", "sigmoid", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.TransSet.transset.TransitivitySet.__init__": [[121, 133], ["ccobra.CCobraModel.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'TransSet'", ")", ":", "\n", "        ", "\"\"\" Initializes the TransitivitySet model.\n\n        Parameters\n        ----------\n        name : str\n            Unique name of the model. Will be used throughout the ORCA\n            framework as a means for identifying the model.\n\n        \"\"\"", "\n", "\n", "super", "(", "TransitivitySet", ",", "self", ")", ".", "__init__", "(", "name", ",", "[", "'syllogistic'", "]", ",", "[", "'single-choice'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.TransSet.transset.TransitivitySet.predict": [[135, 150], ["ccobra.syllogistic.Syllogism", "transset.generate_prediction", "ccobra.syllogistic.Syllogism.decode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.TransSet.transset.generate_prediction", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Predicts weighted responses to a given syllogism.\n\n        \"\"\"", "\n", "\n", "# Obtain the syllogistic task encoding", "\n", "syl", "=", "ccobra", ".", "syllogistic", ".", "Syllogism", "(", "item", ")", "\n", "syllogism", "=", "syl", ".", "encoded_task", "\n", "figure", "=", "syllogism", "[", "2", "]", "\n", "first", "=", "syllogism", "[", "0", "]", "\n", "second", "=", "syllogism", "[", "1", "]", "\n", "\n", "# Generate and return the current prediction", "\n", "pred", "=", "generate_prediction", "(", "figure", ",", "first", ",", "second", ")", "\n", "return", "syl", ".", "decode_response", "(", "pred", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.TransSet.transset.atmosphere_predictions": [[8, 45], ["None"], "function", ["None"], ["def", "atmosphere_predictions", "(", "premises", ")", ":", "\n", "    ", "\"\"\" Produces atmosphere predictions to a given tuple of premises.\n\n    Parameters\n    ----------\n    premises : list(str)\n        List of premises (e.g., 'AA').\n\n    Returns\n    -------\n    list(str)\n        List of atmosphere predictions (e.g., ['Aac', 'Aca'])\n\n    \"\"\"", "\n", "\n", "responses", "=", "[", "]", "\n", "if", "premises", "==", "'AA'", ":", "\n", "        ", "responses", "=", "[", "'Aac'", ",", "'Aca'", "]", "\n", "", "elif", "premises", "==", "'AI'", ":", "\n", "        ", "responses", "=", "[", "'Iac'", ",", "'Ica'", "]", "\n", "", "elif", "premises", "==", "'AE'", ":", "\n", "        ", "responses", "=", "[", "'Eac'", ",", "'Eca'", "]", "\n", "", "elif", "premises", "==", "'AO'", ":", "\n", "        ", "responses", "=", "[", "'Oac'", ",", "'Oca'", "]", "\n", "", "elif", "premises", "==", "'EE'", ":", "\n", "        ", "responses", "=", "[", "'Eac'", ",", "'Eca'", "]", "\n", "", "elif", "premises", "==", "'EI'", ":", "\n", "        ", "responses", "=", "[", "'Oac'", ",", "'Oca'", "]", "\n", "", "elif", "premises", "==", "'EO'", ":", "\n", "        ", "responses", "=", "[", "'Oac'", ",", "'Oca'", "]", "\n", "", "elif", "premises", "==", "'II'", ":", "\n", "        ", "responses", "=", "[", "'Iac'", ",", "'Ica'", "]", "\n", "", "elif", "premises", "==", "'IO'", ":", "\n", "        ", "responses", "=", "[", "'Oac'", ",", "'Oca'", "]", "\n", "", "elif", "premises", "==", "'OO'", ":", "\n", "        ", "responses", "=", "[", "'Oac'", ",", "'Oca'", "]", "\n", "", "return", "responses", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.TransSet.transset.generate_prediction": [[46, 115], ["transset.atmosphere_predictions", "sorted"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.TransSet.transset.atmosphere_predictions"], ["", "def", "generate_prediction", "(", "figure", ",", "first", ",", "second", ")", ":", "\n", "    ", "\"\"\" Generates predictions according the the TransSet theory.\n\n    \"\"\"", "\n", "\n", "neg_quantifiers", "=", "[", "'E'", ",", "'O'", "]", "\n", "\n", "# DETERMINE THE DIRECTION", "\n", "\n", "# Figure 3 and 4: There is no clear path to process a set of As to the", "\n", "# endpoint of Cs. Therefore, different heuristics are used to find a", "\n", "# direction. The quantifiers are ranked according to the ability to choose", "\n", "# a set with high confidence (therefore all > none > (some/somenot))", "\n", "ordering", "=", "{", "'A'", ":", "3", ",", "'E'", ":", "2", ",", "'I'", ":", "1", ",", "'O'", ":", "1", "}", "\n", "\n", "# For figure 3 (where all paths point to B), the side with the 'more", "\n", "# informative' set is assumed to be the endpoint (e.g., \"some A\" and \"all C\", it is", "\n", "# reasonable to assume that the answer has to be a mapping from A to C, so", "\n", "# ac is the direction). For ties: NVC, as it is unclear which set is a subset of the other.", "\n", "if", "figure", "==", "'3'", ":", "\n", "        ", "if", "ordering", "[", "second", "]", ">", "ordering", "[", "first", "]", ":", "\n", "            ", "figure", "=", "'1'", "\n", "", "elif", "ordering", "[", "second", "]", "<", "ordering", "[", "first", "]", ":", "\n", "            ", "figure", "=", "'2'", "\n", "", "else", ":", "\n", "            ", "return", "\"NVC\"", "\n", "\n", "# Figure 4 (all paths start from B) it is the other way round: the 'more", "\n", "# informative' set determines the starting point. As the premise starts with B, the", "\n", "# more informative set is a natural choice to be filtered by B, before the second premise", "\n", "# is applied.", "\n", "", "", "if", "figure", "==", "'4'", ":", "\n", "        ", "if", "ordering", "[", "first", "]", ">", "ordering", "[", "second", "]", ":", "\n", "            ", "figure", "=", "'1'", "\n", "", "elif", "ordering", "[", "first", "]", "<", "ordering", "[", "second", "]", ":", "\n", "            ", "figure", "=", "'2'", "\n", "", "else", ":", "\n", "            ", "return", "\"NVC\"", "\n", "", "", "dir", "=", "'ac'", "\n", "\n", "# The direction in fig 1 ist ac, in fig 2 it is ca. Therefore the premise", "\n", "# order can also be changed.", "\n", "if", "figure", "==", "'1'", ":", "\n", "        ", "dir", "=", "'ac'", "\n", "", "elif", "figure", "==", "'2'", ":", "\n", "        ", "dir", "=", "'ca'", "\n", "tmp", "=", "first", "\n", "first", "=", "second", "\n", "second", "=", "tmp", "\n", "\n", "# DETERMINE THE QUANTIFIER", "\n", "\n", "# It is assumed that the confidence in a path depends on the non-negative", "\n", "# quantifiers. The first premise is more important, as it is used in the", "\n", "# second premise to find the answer. therefore, a negative quantifier", "\n", "# in the first premise should increase the likelyhood of NVC more than a", "\n", "# negative quantifier in the second premise. Especially syllogisms with two", "\n", "# negative quantifiers will most likely be considered NVC", "\n", "", "if", "(", "first", "in", "neg_quantifiers", ")", "and", "not", "(", "second", "==", "'A'", ")", ":", "\n", "        ", "return", "\"NVC\"", "\n", "\n", "# After this pre-filtering, the atmosphere is used for the rest, as the set-based", "\n", "# approach is compatible with it's results.", "\n", "", "premises", "=", "''", ".", "join", "(", "sorted", "(", "[", "first", ",", "second", "]", ")", ")", "\n", "atmosphere_prediction", "=", "atmosphere_predictions", "(", "premises", ")", "\n", "\n", "# The figure determines the direction", "\n", "direction_idx", "=", "0", "if", "(", "dir", "==", "'ac'", ")", "else", "1", "\n", "return", "atmosphere_prediction", "[", "direction_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.encoder.CCobraResponseEncoder.encode_response": [[11, 30], ["NotImplementedError"], "methods", ["None"], ["def", "encode_response", "(", "self", ",", "response", ",", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a response\n\n        Parameters\n        ----------\n        response : list(str)\n            Response in tuple representation.\n\n        task : list(list(str))\n            Task in tuple representation.\n\n        Returns\n        -------\n        str\n            Response representation.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.encoder.CCobraTaskEncoder.encode_task": [[37, 53], ["NotImplementedError"], "methods", ["None"], ["def", "encode_task", "(", "self", ",", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a task.\n\n        Parameters\n        ----------\n        task : list(list(str))\n            Task in tuple representation.\n\n        Returns\n        -------\n        str\n            Task representation.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.item.Item.__init__": [[12, 65], ["range", "convert_to_basic_types", "x.split", "x.split", "len", "task.split", "choices.split", "x.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.convert_to_basic_types"], ["def", "__init__", "(", "self", ",", "identifier", ",", "domain", ",", "task", ",", "resp_type", ",", "choices", ",", "sequence_number", ")", ":", "\n", "        ", "\"\"\" Constructs the task item container with information about the\n        domain, task premises, response type, and response choices.\n\n        Parameters\n        ----------\n        identifier : object\n            Unique identifier for the participant.\n\n        domain : str\n            Task domain (e.g., 'syllogistic').\n\n        task : str\n            Task text in tuple string encoding (e.g.,\n            'All;pilots;gardeners/Some;gardeners;cooks').\n\n        resp_type : str\n            Response type (e.g., 'single-choice').\n\n        choices : list(str)\n            Response options in string representation.\n\n        sequence_number : int\n            Position of the item in the experimental sequence.\n\n        \"\"\"", "\n", "\n", "#: Unique identifier of the participant", "\n", "self", ".", "identifier", "=", "identifier", "\n", "\n", "#: Response type of the task", "\n", "self", ".", "response_type", "=", "resp_type", "\n", "\n", "#: Task string representation", "\n", "self", ".", "task_str", "=", "task", "\n", "\n", "#: Task in list representation", "\n", "self", ".", "task", "=", "[", "x", ".", "split", "(", "\";\"", ")", "for", "x", "in", "task", ".", "split", "(", "\"/\"", ")", "if", "x", "]", "\n", "\n", "#: Choices string representation", "\n", "self", ".", "choices_str", "=", "choices", "\n", "\n", "#: Choices in list representation", "\n", "self", ".", "choices", "=", "[", "x", ".", "split", "(", "'/'", ")", "for", "x", "in", "choices", ".", "split", "(", "'|'", ")", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "choices", ")", ")", ":", "\n", "            ", "self", ".", "choices", "[", "idx", "]", "=", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "self", ".", "choices", "[", "idx", "]", "]", "\n", "", "self", ".", "choices", "=", "convert_to_basic_types", "(", "self", ".", "choices", ")", "\n", "\n", "#: Domain of the task", "\n", "self", ".", "domain", "=", "domain", "\n", "\n", "#: Position of the task in the experimental sequence", "\n", "self", ".", "sequence_number", "=", "sequence_number", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.item.Item.__eq__": [[66, 98], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\" Equality comparator.\n\n        Parameters\n        ----------\n        other : object\n            Object to compare with.\n\n        Returns\n        -------\n        bool\n            True, if object is equal, false otherwise.\n\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "other", ",", "Item", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "if", "self", ".", "identifier", "!=", "other", ".", "identifier", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "response_type", "!=", "other", ".", "response_type", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "task_str", "!=", "other", ".", "task_str", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "choices_str", "!=", "other", ".", "choices_str", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "domain", "!=", "other", ".", "domain", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "sequence_number", "!=", "other", ".", "sequence_number", ":", "\n", "            ", "return", "False", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.item.Item.__ne__": [[99, 115], ["item.Item.__eq__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.item.Item.__eq__"], ["", "def", "__ne__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\" Not-Equal comparator. Defines unequality as the converse of equality.\n\n        Parameters\n        ----------\n        other : object\n            Object to compare to.\n\n        Returns\n        -------\n        bool\n            True, if object is unequal.\n\n        \"\"\"", "\n", "\n", "return", "not", "self", ".", "__eq__", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.item.Item.__str__": [[116, 134], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\" String representation of the item.\n\n        Returns\n        -------\n        str\n            String representation of the item.\n\n        \"\"\"", "\n", "\n", "rep", "=", "'CCOBRA Item:\\n'", "\n", "rep", "+=", "'\\tIdentifier: {}\\n'", ".", "format", "(", "self", ".", "identifier", ")", "\n", "rep", "+=", "'\\tTask: {}\\n'", ".", "format", "(", "self", ".", "task", ")", "\n", "rep", "+=", "'\\tSequence Number: {}\\n'", ".", "format", "(", "self", ".", "sequence_number", ")", "\n", "rep", "+=", "'\\tDomain: {}\\n'", ".", "format", "(", "self", ".", "domain", ")", "\n", "rep", "+=", "'\\tResponse Type: {}\\n'", ".", "format", "(", "self", ".", "response_type", ")", "\n", "rep", "+=", "'\\tChoices: {}'", ".", "format", "(", "self", ".", "choices", ")", "\n", "return", "rep", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.comparator.CCobraComparator.compare": [[10, 35], ["NotImplementedError"], "methods", ["None"], ["def", "compare", "(", "self", ",", "prediction", ",", "target", ",", "response_type", ",", "choices", ")", ":", "\n", "        ", "\"\"\" Base comparison method.\n\n        Parameters\n        ----------\n        prediction : object\n            Prediction object for comparison.\n\n        target : object\n            Target object for comparison.\n            \n        response_type : string\n            The response type of the prediction and target.\n            \n        choices : list(object)\n            The choice options that were available for this comparison.\n\n        Returns\n        -------\n        float\n            Comparison result.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.comparator.CCobraComparator.get_name": [[36, 47], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the name of the comparator.\n\n        Returns\n        -------\n        string\n            Comparator name.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.__init__": [[19, 50], ["data.CCobraData.verify_data", "data.CCobraData.prepare_data", "len", "data.CCobraData._data[].unique().tolist", "data.CCobraData._data[].unique().tolist", "data.CCobraData._data[].unique", "data.CCobraData._data[].unique", "data.CCobraData._data[].unique"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.verify_data", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.prepare_data"], ["def", "__init__", "(", "self", ",", "data", ",", "target_columns", ")", ":", "\n", "        ", "\"\"\" Initializes the CCOBRA data container by passing a data frame\n        and validating its contents.\n\n        Parameters\n        ----------\n        data : pd.DataFrame\n            DataFrame to store in the CCOBRA data container.\n\n        required_fields : list(str), optional\n            List of required columns in the data. Defaults to ['id', 'sequence',\n            'task', 'choices', 'response', 'response_type', 'domain']\n\n        \"\"\"", "\n", "\n", "self", ".", "target_columns", "=", "target_columns", "\n", "self", ".", "required_fields", "=", "[", "\n", "'id'", ",", "'sequence'", ",", "'task'", ",", "'choices'", ",", "'response_type'", ",", "'domain'", "\n", "]", "+", "target_columns", "\n", "\n", "# Verify and store the data", "\n", "self", ".", "verify_data", "(", "data", ")", "\n", "self", ".", "_data", "=", "data", "\n", "\n", "# Normalize the data container", "\n", "self", ".", "prepare_data", "(", ")", "\n", "\n", "# Extract meta information", "\n", "self", ".", "n_subjects", "=", "len", "(", "self", ".", "_data", "[", "'_unique_id'", "]", ".", "unique", "(", ")", ")", "\n", "self", ".", "domains", "=", "self", ".", "_data", "[", "'domain'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "response_types", "=", "self", ".", "_data", "[", "'response_type'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.verify_data": [[51, 70], ["set", "set", "ValueError"], "methods", ["None"], ["", "def", "verify_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Verifies if all required fields are in the data.\n\n        Parameters\n        ----------\n        data : pd.DataFrame\n            DataFrame to verify.\n\n        Raises\n        ------\n        ValueError\n            Thrown if data does not contain required columns.\n\n        \"\"\"", "\n", "\n", "missing", "=", "set", "(", "self", ".", "required_fields", ")", "-", "set", "(", "data", ".", "columns", ")", "\n", "if", "missing", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Data does not contain columns: {}\"", ".", "format", "(", "missing", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.prepare_data": [[71, 80], ["None"], "methods", ["None"], ["", "", "def", "prepare_data", "(", "self", ")", ":", "\n", "        ", "\"\"\" Prepares the dataset by adding internally_used columns\n\n        \"\"\"", "\n", "\n", "assert", "'_unique_id'", "not", "in", "self", ".", "_data", "\n", "\n", "# Add unique numerical subject identifier", "\n", "self", ".", "_data", "[", "'_unique_id'", "]", "=", "self", ".", "_data", "[", "'id'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.prefix_identifiers": [[81, 92], ["data.CCobraData._data[].apply", "str"], "methods", ["None"], ["", "def", "prefix_identifiers", "(", "self", ",", "prefix", "=", "'_train_'", ")", ":", "\n", "        ", "\"\"\" Prefixes the subject identifier keys.\n\n        Parameters\n        ----------\n        prefix : str\n            Prefix to apply to key numerical identifiers.\n\n        \"\"\"", "\n", "\n", "self", ".", "_data", "[", "'_unique_id'", "]", "=", "self", ".", "_data", "[", "'_unique_id'", "]", ".", "apply", "(", "lambda", "x", ":", "prefix", "+", "str", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get": [[93, 104], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the contained data.\n\n        Returns\n        -------\n        pd.DataFrame\n            Dataframe containing the data.\n\n        \"\"\"", "\n", "\n", "return", "self", ".", "_data", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.head": [[105, 111], ["data.CCobraData._data.head"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.head"], ["", "def", "head", "(", "self", ")", ":", "\n", "        ", "\"\"\" Displays the first 10 lines of the dataframe.\n\n        \"\"\"", "\n", "\n", "return", "self", ".", "_data", ".", "head", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.to_eval_dict": [[112, 183], ["df.groupby", "subj_df.sort_values.sort_values.sort_values", "subj_df.sort_values.sort_values.iterrows", "item.Item.Item", "isinstance", "convert_to_basic_types", "task_series.iteritems", "copy.deepcopy", "subj_data.append", "task_series[].split", "isinstance", "responses.append", "task_series[].split", "responses.append", "x.split", "response.split", "x.split", "response.split"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.convert_to_basic_types"], ["", "def", "to_eval_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" Converts the dataset to an evaluation dictionary mapping from individuals to data.\n\n        Returns\n        -------\n        dict(object, list)\n            Dictionary mapping from subject identifiers to lists of experimental data.\n\n        \"\"\"", "\n", "\n", "# Prepare the dictionary of subjects containing lists of tasks they responded to", "\n", "df", "=", "self", ".", "_data", "\n", "\n", "dataset", "=", "{", "}", "\n", "for", "subj", ",", "subj_df", "in", "df", ".", "groupby", "(", "'_unique_id'", ")", ":", "\n", "            ", "assert", "subj", "not", "in", "dataset", "\n", "\n", "subj_df", "=", "subj_df", ".", "sort_values", "(", "'sequence'", ")", "\n", "\n", "subj_data", "=", "[", "]", "\n", "for", "_", ",", "task_series", "in", "subj_df", ".", "iterrows", "(", ")", ":", "\n", "                ", "task_dict", "=", "{", "}", "\n", "\n", "# Extract the task information", "\n", "item", "=", "Item", "(", "\n", "task_series", "[", "'id'", "]", ",", "task_series", "[", "'domain'", "]", ",", "\n", "task_series", "[", "'task'", "]", ",", "task_series", "[", "'response_type'", "]", ",", "\n", "task_series", "[", "'choices'", "]", ",", "task_series", "[", "'sequence'", "]", "\n", ")", "\n", "task_dict", "[", "'item'", "]", "=", "item", "\n", "\n", "# Parse the main response", "\n", "responses", "=", "None", "\n", "if", "isinstance", "(", "task_series", "[", "'response'", "]", ",", "str", ")", ":", "\n", "                    ", "responses", "=", "[", "]", "\n", "for", "response", "in", "task_series", "[", "'response'", "]", ".", "split", "(", "'|'", ")", ":", "\n", "                        ", "responses", ".", "append", "(", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "response", ".", "split", "(", "'/'", ")", "]", ")", "\n", "", "if", "task_series", "[", "'response_type'", "]", "!=", "'multiple-choice'", ":", "\n", "                        ", "responses", "=", "responses", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                    ", "responses", "=", "task_series", "[", "'response'", "]", "\n", "", "task_dict", "[", "'response'", "]", "=", "convert_to_basic_types", "(", "responses", ")", "\n", "\n", "# Parse the auxiliary targets", "\n", "for", "target_col", "in", "self", ".", "target_columns", ":", "\n", "                    ", "if", "target_col", "==", "'response'", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "isinstance", "(", "task_series", "[", "target_col", "]", ",", "str", ")", ":", "\n", "                        ", "responses", "=", "[", "]", "\n", "for", "response", "in", "task_series", "[", "target_col", "]", ".", "split", "(", "'|'", ")", ":", "\n", "                            ", "responses", ".", "append", "(", "[", "x", ".", "split", "(", "';'", ")", "for", "x", "in", "response", ".", "split", "(", "'/'", ")", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "responses", "=", "task_series", "[", "target_col", "]", "\n", "", "task_dict", "[", "target_col", "]", "=", "responses", "\n", "\n", "# Add auxiliary elements from the data", "\n", "", "aux", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "task_series", ".", "iteritems", "(", ")", ":", "\n", "                    ", "if", "key", "not", "in", "self", ".", "required_fields", "+", "[", "'_unique_id'", "]", ":", "\n", "                        ", "aux", "[", "key", "]", "=", "value", "\n", "", "", "task_dict", "[", "'aux'", "]", "=", "aux", "\n", "\n", "task_dict", "[", "'full'", "]", "=", "copy", ".", "deepcopy", "(", "task_dict", "[", "'aux'", "]", ")", "\n", "for", "target_col", "in", "self", ".", "target_columns", ":", "\n", "                    ", "task_dict", "[", "'full'", "]", "[", "target_col", "]", "=", "task_dict", "[", "target_col", "]", "\n", "\n", "", "subj_data", ".", "append", "(", "task_dict", ")", "\n", "", "dataset", "[", "subj", "]", "=", "subj_data", "\n", "\n", "", "return", "dataset", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.convert_to_basic_types": [[9, 49], ["isinstance", "isinstance", "isinstance", "isinstance", "str", "int", "helper.convert_to_basic_types", "float"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.convert_to_basic_types"], ["def", "convert_to_basic_types", "(", "elem", ")", ":", "\n", "    ", "\"\"\" Converts an element to primitive types. If the element\n    is a list, the inner elements will be converted instead.\n    The preference order is bool > int > float > string.\n\n    Parameters\n    ----------\n    elem : Object\n        Element to convert.\n\n    Returns\n    -------\n    Object\n        Primitive object representing the given element.\n\n    \"\"\"", "\n", "if", "isinstance", "(", "elem", ",", "int", ")", ":", "\n", "        ", "return", "elem", "\n", "", "if", "isinstance", "(", "elem", ",", "float", ")", ":", "\n", "        ", "return", "elem", "\n", "", "if", "isinstance", "(", "elem", ",", "bool", ")", ":", "\n", "        ", "return", "elem", "\n", "", "if", "isinstance", "(", "elem", ",", "list", ")", ":", "\n", "        ", "return", "[", "convert_to_basic_types", "(", "x", ")", "for", "x", "in", "elem", "]", "\n", "\n", "", "elem", "=", "str", "(", "elem", ")", "\n", "if", "elem", "==", "\"True\"", ":", "\n", "        ", "return", "True", "\n", "", "if", "elem", "==", "\"False\"", ":", "\n", "        ", "return", "False", "\n", "\n", "", "try", ":", "\n", "        ", "result", "=", "int", "(", "elem", ")", "\n", "return", "result", "\n", "", "except", "ValueError", ":", "\n", "        ", "try", ":", "\n", "            ", "result", "=", "float", "(", "elem", ")", "\n", "return", "result", "\n", "", "except", "ValueError", ":", "\n", "            ", "return", "elem", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string": [[50, 99], ["copy.deepcopy", "helper.tuple_to_string.join_deepest"], "function", ["None"], ["", "", "", "def", "tuple_to_string", "(", "tuptup", ")", ":", "\n", "    ", "\"\"\" Converts a tuple to its string representation. Uses different separators (';', '/', '|') for\n    different depths of the representation.\n\n    Parameters\n    ----------\n    tuptup : list\n        Tuple to convert to its string representation.\n\n    Returns\n    -------\n    str\n        String representation of the input tuple.\n\n    \"\"\"", "\n", "\n", "def", "join_deepest", "(", "tup", ",", "sep", "=", "';'", ")", ":", "\n", "        ", "\"\"\" Recursive function to create the string representation for the deepest level of the\n        tuptup list.\n\n        Parameters\n        ----------\n        tup : object\n            Element to join if list or list of lists.\n\n        sep : str, optional\n            Separation character to join the list elements by.\n\n        Returns\n        -------\n        object\n            List containing joined string in max depth. Str if input depth = 1.\n\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "tup", ",", "list", ")", ":", "\n", "            ", "return", "str", "(", "tup", ")", "\n", "", "if", "not", "isinstance", "(", "tup", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "return", "sep", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tup", "]", ")", "\n", "\n", "", "for", "idx", ",", "val", "in", "enumerate", "(", "tup", ")", ":", "\n", "            ", "tup", "[", "idx", "]", "=", "join_deepest", "(", "val", ",", "sep", ")", "\n", "", "return", "tup", "\n", "\n", "", "tup", "=", "copy", ".", "deepcopy", "(", "tuptup", ")", "\n", "tup", "=", "join_deepest", "(", "tup", ",", "';'", ")", "\n", "tup", "=", "join_deepest", "(", "tup", ",", "'/'", ")", "\n", "tup", "=", "join_deepest", "(", "tup", ",", "'|'", ")", "\n", "return", "tup", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.unnest": [[101, 123], ["isinstance", "len"], "function", ["None"], ["", "def", "unnest", "(", "tup", ")", ":", "\n", "    ", "\"\"\" Unnests a nested tuple. If an element is insight nested lists, the function\n    returns the element, otherwise the list is returned.\n\n    Parameters\n    ----------\n    tup : list\n        Nested tuples.\n\n    Returns\n    -------\n    object\n        Element or list without unneccessary nesting.\n\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "if", "not", "isinstance", "(", "tup", ",", "list", ")", ":", "\n", "            ", "return", "tup", "\n", "", "if", "len", "(", "tup", ")", "!=", "1", ":", "\n", "            ", "return", "tup", "\n", "\n", "", "tup", "=", "tup", "[", "0", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.__init__": [[17, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "supported_domains", ",", "supported_response_types", ")", ":", "\n", "        ", "\"\"\" Base constructor of CCOBRA models.\n\n        Parameters\n        ----------\n        name : str\n            Unique name of the model. Will be used throughout the CCOBRA\n            framework as a means for identifying the model.\n\n        supported_domains : list(str)\n            List containing the domains that are supported by the model (e.g.\n            'syllogistic').\n\n        supported_response_types : list(str)\n            List containing the response types that are supported by the model\n            (e.g., 'single-choice')\n\n        \"\"\"", "\n", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "supported_domains", "=", "supported_domains", "\n", "self", ".", "supported_response_types", "=", "supported_response_types", "\n", "\n", "self", ".", "evaluation_type", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.setup_environment": [[42, 54], ["None"], "methods", ["None"], ["", "def", "setup_environment", "(", "self", ",", "evaluation_type", ")", ":", "\n", "        ", "\"\"\" Setup environment of the model using information about the prediction setting and the\n        information provided during training.\n\n        Parameters\n        ----------\n        evaluation_type : str\n            Type of the CCOBRA evaluation (adaption, coverage).\n\n        \"\"\"", "\n", "\n", "self", ".", "evaluation_type", "=", "evaluation_type", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.start_participant": [[55, 61], ["None"], "methods", ["None"], ["", "def", "start_participant", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Callback to indicate participant start.\n\n        \"\"\"", "\n", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.end_participant": [[62, 76], ["None"], "methods", ["None"], ["", "def", "end_participant", "(", "self", ",", "identifier", ",", "model_log", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Hook for when participant simulation ends.\n\n        Parameters\n        ----------\n        identifier : str or int\n            Participant identifier.\n\n        model_log : dict(str, object)\n            Dictionary to allow the model to log information for the final output (e.g., parameter\n            configurations for this participant).\n        \"\"\"", "\n", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.pre_train": [[77, 94], ["None"], "methods", ["None"], ["", "def", "pre_train", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\" Pre-trains the model based on given group data. This data is not necessarily other\n        participants from the same experiment, but can also refer to an unrelated external dataset.\n        The information supplied here represents the information known about the general population\n        in the domain of interest.\n\n        Parameters\n        ----------\n        dataset : list(list(dict(str, object)))\n            Training data for the model. List of participants which each\n            contain lists of tasks represented as dictionaries with the\n            corresponding task information (e.g., the item container and\n            given response).\n\n        \"\"\"", "\n", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.pre_train_person": [[95, 119], ["len", "model.CCobraModel.adapt", "dict", "task_data.items"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.adapt"], ["", "def", "pre_train_person", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\" Excerpt of the prediction data containing responses of the individual. Is supposed to\n        combat the cold-start problem by supplying models with information about the exact\n        individual to be predicted for. Allows to fit models to a specific individual. For\n        example, in coverage settings, the responses given by the individual are supplied here.\n\n        If not overriden by the model implemenation, uses adapt to perform the training.\n\n        Parameters\n        ----------\n        dataset : list(dict(str, object))\n            Training data for the model. List of tasks containing the items\n            and corresponding responses.\n\n        \"\"\"", "\n", "\n", "if", "len", "(", "dataset", ")", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "for", "task_data", "in", "dataset", ":", "\n", "            ", "self", ".", "adapt", "(", "\n", "task_data", "[", "'item'", "]", ",", "\n", "task_data", "[", "'response'", "]", ",", "\n", "**", "dict", "(", "[", "x", "for", "x", "in", "task_data", ".", "items", "(", ")", "if", "x", "[", "0", "]", "not", "in", "[", "'item'", ",", "'response'", "]", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.pre_person_background": [[121, 137], ["None"], "methods", ["None"], ["", "", "def", "pre_person_background", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\" Background information about the person to be predicted for. In contrast to the\n        data supplied by pre_adapt, the data given here is not extracted from the test data.\n        For example, could be responses given by the individual in question to an external\n        independent experiment (e.g., participated in a spatial-relation experiment and later\n        in a syllogistic experiment which serve as the test data).\n\n        Parameters\n        ----------\n        dataset : list(dict(str, object))\n            Training data for the model. List of tasks containing the items\n            and corresponding responses.\n\n        \"\"\"", "\n", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.predict": [[138, 155], ["NotImplementedError"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "item", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Generates a single response prediction for a given task.\n\n        Parameters\n        ----------\n        item : ccobra.Item\n            Task information container. Holds the task text, response type,\n            response choices, etc.\n\n        Returns\n        -------\n        str\n            Response prediction.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.adapt": [[156, 171], ["None"], "methods", ["None"], ["", "def", "adapt", "(", "self", ",", "item", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Trains the model based on a given task-target combination.\n\n        Parameters\n        ----------\n        item : ccobra.Item\n            Task information container. Holds the task text, response type,\n            response choices, etc.\n\n        target : str\n            True response given by the human reasoner.\n\n        \"\"\"", "\n", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.GeneralizedSyllogism.__init__": [[97, 147], ["item.Item", "syllogism_gen.encode_task", "int"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task"], ["def", "__init__", "(", "self", ",", "item", ")", ":", "\n", "        ", "\"\"\" Constructs the generalized Syllogism based on a given task item.\n\n        Parameters\n        ----------\n        item : ccobra.Item\n            CCOBRA task item container to base this Syllogism helper on.\n\n        \"\"\"", "\n", "\n", "#: Instance of the item the Syllogism is constructed on. The instance", "\n", "#: is copied in order to prevent reference mismatches from happening.", "\n", "self", ".", "item", "=", "Item", "(", "\n", "item", ".", "identifier", ",", "\n", "item", ".", "domain", ",", "\n", "item", ".", "task_str", ",", "\n", "item", ".", "response_type", ",", "\n", "item", ".", "choices_str", ",", "\n", "item", ".", "sequence_number", ")", "\n", "\n", "#: Reference to the task the Syllogism is constructed on.", "\n", "self", ".", "task", "=", "self", ".", "item", ".", "task", "\n", "\n", "#: String representation of the task", "\n", "self", ".", "encoded_task", "=", "encode_task", "(", "self", ".", "task", ")", "\n", "\n", "#: List representation of the first premise", "\n", "self", ".", "p1", "=", "self", ".", "task", "[", "0", "]", "\n", "\n", "#: List representation of the second premise", "\n", "self", ".", "p2", "=", "self", ".", "task", "[", "1", "]", "\n", "\n", "#: Quantifier of the first premise", "\n", "self", ".", "quantifier_p1", "=", "self", ".", "task", "[", "0", "]", "[", "0", "]", "\n", "\n", "#: Quantifier of the second premise", "\n", "self", ".", "quantifier_p2", "=", "self", ".", "task", "[", "1", "]", "[", "0", "]", "\n", "\n", "#: Figure of the syllogism", "\n", "self", ".", "figure", "=", "int", "(", "self", ".", "encoded_task", "[", "-", "1", "]", ")", "\n", "\n", "# Figure out the figure and identify the terms", "\n", "if", "self", ".", "figure", "==", "1", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "1", "]", "[", "2", "]", "\n", "", "elif", "self", ".", "figure", "==", "2", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "1", "]", "[", "1", "]", "\n", "", "elif", "self", ".", "figure", "==", "3", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "1", "]", "[", "1", "]", "\n", "", "elif", "self", ".", "figure", "==", "4", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "1", "]", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.GeneralizedSyllogism.encode_response": [[148, 166], ["syllogism_gen.GeneralizedSyllogism.encode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "", "def", "encode_response", "(", "self", ",", "response", ")", ":", "\n", "        ", "\"\"\" Encodes a given syllogistic response based on the information\n        contained in the premises.\n\n        Parameters\n        ----------\n        response : list(str)\n            Syllogistic response in list representation (e.g.,\n            ['All', 'clerks', 'managers']).\n\n        Returns\n        -------\n        str\n            String encoding of the response (e.g., 'Aac').\n\n        \"\"\"", "\n", "\n", "return", "encode_response", "(", "response", ",", "self", ".", "item", ".", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.GeneralizedSyllogism.decode_response": [[167, 185], ["syllogism_gen.GeneralizedSyllogism.decode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "decode_response", "(", "self", ",", "encoded_response", ")", ":", "\n", "        ", "\"\"\" Decodes a syllogistic response in string representation based on\n        the information stored in the syllogism's premises.\n\n        Parameters\n        ----------\n        encoded_response : str\n            Encoded syllogistic response (e.g., 'Aac').\n\n        Returns\n        -------\n        list(str)\n            List representation of the encoded response (e.g.,\n            ['All', 'clerks', 'managers']).\n\n        \"\"\"", "\n", "\n", "return", "decode_response", "(", "encoded_response", ",", "self", ".", "item", ".", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.GeneralizedSyllogism.is_classical": [[186, 198], ["None"], "methods", ["None"], ["", "def", "is_classical", "(", "self", ")", ":", "\n", "        ", "\"\"\" Checks if the represented syllogism is in the classical set of 64 problems.\n\n        \"\"\"", "\n", "\n", "if", "self", ".", "quantifier_p1", "not", "in", "[", "'A'", ",", "'I'", ",", "'E'", ",", "'O'", "]", ":", "\n", "            ", "return", "False", "\n", "\n", "", "if", "self", ".", "quantifier_p2", "not", "in", "[", "'A'", ",", "'I'", ",", "'E'", ",", "'O'", "]", ":", "\n", "            ", "return", "False", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.GeneralizedSyllogism.__str__": [[199, 223], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Constructs a string representation for the Syllogism object.\n\n        Returns\n        -------\n        str\n            String representation containing the premise, quantifier, figure,\n            and term information.\n\n        \"\"\"", "\n", "\n", "rep", "=", "'Generalized Syllogism:\\n'", "\n", "rep", "+=", "'\\ttask: {}\\n'", ".", "format", "(", "self", ".", "task", ")", "\n", "rep", "+=", "'\\tencoded_task: {}\\n'", ".", "format", "(", "self", ".", "encoded_task", ")", "\n", "rep", "+=", "'\\tp1: {}\\n'", ".", "format", "(", "self", ".", "p1", ")", "\n", "rep", "+=", "'\\tp2: {}\\n'", ".", "format", "(", "self", ".", "p2", ")", "\n", "rep", "+=", "'\\tquantifier_p1: {}\\n'", ".", "format", "(", "self", ".", "quantifier_p1", ")", "\n", "rep", "+=", "'\\tquantifier_p2: {}\\n'", ".", "format", "(", "self", ".", "quantifier_p2", ")", "\n", "rep", "+=", "'\\tfigure: {}\\n'", ".", "format", "(", "self", ".", "figure", ")", "\n", "rep", "+=", "'\\tTerms:\\n'", "\n", "rep", "+=", "'\\t\\tA: {}\\n'", ".", "format", "(", "self", ".", "A", ")", "\n", "rep", "+=", "'\\t\\tB: {}\\n'", ".", "format", "(", "self", ".", "B", ")", "\n", "rep", "+=", "'\\t\\tC: {}\\n'", ".", "format", "(", "self", ".", "C", ")", "\n", "return", "rep", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.encode_task": [[10, 26], ["task_encoder_sylgen.GeneralizedSyllogisticTaskEncoder.encode_task"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task"], ["def", "encode_task", "(", "task", ")", ":", "\n", "    ", "\"\"\" Encodes a generalized syllogistic task.\n\n    Parameters\n    ----------\n    task : list(list(str))\n        List representation of the syllogism (e.g., [['All', 'A', 'B'], ['Most', 'B', 'C']]).\n\n    Returns\n    -------\n    str\n        Syllogistic task encoding (e.g., 'AI1').\n\n    \"\"\"", "\n", "\n", "return", "GeneralizedSyllogisticTaskEncoder", ".", "encode_task", "(", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.encode_response": [[27, 46], ["resp_encoder_sylgen.GeneralizedSyllogisticResponseEncoder.encode_response"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "encode_response", "(", "response", ",", "task", ")", ":", "\n", "    ", "\"\"\" Encodes a response to its generalized syllogistic encoding.\n\n    Parameters\n    ----------\n    response : list(str)\n        Syllogistc response in list representation (e.g., ['Most', 'A', 'C'])\n\n    task : list(list(str))\n        Syllogistic task in list representation (e.g., [['All', 'A', 'B'], ['Most', 'B', 'C']]).\n\n    Returns\n    -------\n    str\n        Syllogistic response encoding (e.g., 'Tac').\n\n    \"\"\"", "\n", "\n", "return", "GeneralizedSyllogisticResponseEncoder", ".", "encode_response", "(", "response", ",", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.syllogism_gen.decode_response": [[47, 91], ["task_encoder_sylgen.QUANTIFIERS_SYLLOGISTIC_GENERALIZED_ENCODING.items", "set", "set", "set", "set", "ValueError", "list", "list", "list", "list"], "function", ["None"], ["", "def", "decode_response", "(", "enc_response", ",", "task", ")", ":", "\n", "    ", "\"\"\" Decodes an encoded generalized syllogistic response by transforming it to the\n    corresponding tuple representation and inserting the appropriate terms.\n\n    Parameters\n    ----------\n    enc_response : str\n        Encoded syllogistic response (e.g., 'Aac').\n\n    task : list(str)\n        Syllogistic task in the tuple list representation (e.g.,\n        [['Some', 'models', 'managers'], ['All', 'models', 'clerks']]).\n\n    Returns\n    -------\n    list\n        List representation of the response to decode.\n\n    \"\"\"", "\n", "\n", "if", "enc_response", "==", "'NVC'", ":", "\n", "        ", "return", "[", "[", "'NVC'", "]", "]", "\n", "", "if", "enc_response", "==", "[", "'NVC'", "]", ":", "\n", "        ", "return", "[", "enc_response", "]", "\n", "", "if", "enc_response", "==", "[", "[", "'NVC'", "]", "]", ":", "\n", "        ", "return", "enc_response", "\n", "\n", "", "obj_a", "=", "set", "(", "task", "[", "0", "]", "[", "1", ":", "]", ")", "-", "set", "(", "task", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "obj_c", "=", "set", "(", "task", "[", "1", "]", "[", "1", ":", "]", ")", "-", "set", "(", "task", "[", "0", "]", "[", "1", ":", "]", ")", "\n", "\n", "# Determine quantifier", "\n", "quant", "=", "None", "\n", "for", "resp", ",", "enc", "in", "QUANTIFIERS_SYLLOGISTIC_GENERALIZED_ENCODING", ".", "items", "(", ")", ":", "\n", "        ", "if", "enc", "==", "enc_response", "[", "0", "]", ":", "\n", "            ", "quant", "=", "resp", "\n", "break", "\n", "\n", "", "", "if", "quant", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid Quantifier in response encoding: {}'", ".", "format", "(", "enc_response", ")", ")", "\n", "\n", "# Handle response direction", "\n", "", "if", "enc_response", "[", "1", ":", "]", "==", "'ac'", ":", "\n", "        ", "return", "[", "[", "quant", ",", "list", "(", "obj_a", ")", "[", "0", "]", ",", "list", "(", "obj_c", ")", "[", "0", "]", "]", "]", "\n", "", "return", "[", "[", "quant", ",", "list", "(", "obj_c", ")", "[", "0", "]", ",", "list", "(", "obj_a", ")", "[", "0", "]", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.resp_encoder_sylgen.GeneralizedSyllogisticResponseEncoder.encode_response": [[28, 63], ["object_sets[].intersection", "isinstance", "set", "list"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "encode_response", "(", "response", ",", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a response to its syllogistic encoding.\n\n        Parameters\n        ----------\n        response : list(str)\n            Syllogistc response in list representation (e.g., ['All', 'A', 'C'])\n\n        task : list(list(str))\n            Syllogistic task in list representation (e.g., [['All', 'A', 'B'], ['Some', 'B', 'C']]).\n\n        Returns\n        -------\n        str\n            Syllogistic response encoding (e.g., 'Aac').\n\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "response", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "response", "=", "[", "response", "]", "\n", "\n", "", "if", "response", "[", "0", "]", "==", "'NVC'", ":", "\n", "            ", "return", "'NVC'", "\n", "\n", "", "if", "response", "[", "0", "]", "[", "0", "]", "==", "'NVC'", ":", "\n", "            ", "return", "'NVC'", "\n", "\n", "", "object_sets", "=", "[", "set", "(", "x", "[", "1", ":", "]", ")", "for", "x", "in", "task", "]", "\n", "midterm", "=", "object_sets", "[", "0", "]", ".", "intersection", "(", "object_sets", "[", "1", "]", ")", "\n", "obj_a", "=", "object_sets", "[", "0", "]", "-", "midterm", "\n", "\n", "quant", "=", "QUANTIFIERS_SYLLOGISTIC_GENERALIZED_ENCODING", "[", "response", "[", "0", "]", "[", "0", "]", "]", "\n", "\n", "return", "quant", "+", "(", "'ac'", "if", "response", "[", "0", "]", "[", "1", "]", "==", "list", "(", "obj_a", ")", "[", "0", "]", "else", "'ca'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic_generalized.task_encoder_sylgen.GeneralizedSyllogisticTaskEncoder.encode_task": [[28, 67], ["str", "ValueError"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "encode_task", "(", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a task to its generalized syllogistic encoding.\n\n        Parameters\n        ----------\n        task : list(list(str))\n            List representation of the syllogism (e.g., [['All', 'A', 'B'], ['Some', 'B', 'C']]).\n\n        Returns\n        -------\n        str\n            Syllogistic task encoding (e.g., 'AI1').\n\n        Raises\n        ------\n        ValueError\n            If figure of syllogism cannot be determined.\n\n        \"\"\"", "\n", "\n", "prem_1", ",", "prem_2", "=", "task", "\n", "\n", "quant1", "=", "QUANTIFIERS_SYLLOGISTIC_GENERALIZED_ENCODING", "[", "prem_1", "[", "0", "]", "]", "\n", "quant2", "=", "QUANTIFIERS_SYLLOGISTIC_GENERALIZED_ENCODING", "[", "prem_2", "[", "0", "]", "]", "\n", "figure", "=", "1", "\n", "\n", "if", "prem_1", "[", "1", "]", "==", "prem_2", "[", "1", "]", ":", "\n", "            ", "figure", "=", "4", "\n", "", "elif", "prem_1", "[", "2", "]", "==", "prem_2", "[", "1", "]", ":", "\n", "            ", "figure", "=", "1", "\n", "", "elif", "prem_1", "[", "2", "]", "==", "prem_2", "[", "2", "]", ":", "\n", "            ", "figure", "=", "3", "\n", "", "elif", "prem_1", "[", "1", "]", "==", "prem_2", "[", "2", "]", ":", "\n", "            ", "figure", "=", "2", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Could not determine figure of:'", ",", "task", ")", "\n", "\n", "", "return", "quant1", "+", "quant2", "+", "str", "(", "figure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.propositional.resp_encoder_prop.PropositionalResponseEncoder.encode_clause": [[20, 56], ["reversed", "term.lower", "len", "stack.append", "stack.append", "stack.append", "stack.pop", "stack.append", "stack.pop", "stack.pop", "stack.append", "stack.pop", "stack.pop", "stack.append", "stack.pop", "stack.pop", "stack.pop", "stack.pop"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "encode_clause", "(", "clause", ")", ":", "\n", "        ", "\"\"\" Encodes a single clause by parsing the Polish normal form.\n\n        Parameters\n        ----------\n        clause : list(str)\n            Propositional clause in list representation (e.g., ['If', 'not', 'A', 'B']).\n\n        Returns\n        -------\n        str\n            String representation of the input clause (e.g., \"~A -> B\").\n\n        \"\"\"", "\n", "\n", "# Parse the clause in reverse", "\n", "stack", "=", "[", "]", "\n", "for", "term", "in", "reversed", "(", "clause", ")", ":", "\n", "            ", "norm_term", "=", "term", ".", "lower", "(", ")", "\n", "if", "norm_term", "in", "OPERATORS", ":", "\n", "                ", "if", "norm_term", "==", "'not'", ":", "\n", "                    ", "stack", ".", "append", "(", "'~{}'", ".", "format", "(", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'and'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} & {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'or'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} | {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'iff'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} <=> {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'if'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} -> {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "stack", ".", "append", "(", "term", ")", "\n", "\n", "", "", "assert", "len", "(", "stack", ")", "==", "1", ",", "'Error: {} -> {}'", ".", "format", "(", "clause", ",", "stack", ")", "\n", "return", "stack", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.propositional.resp_encoder_prop.PropositionalResponseEncoder.encode_response": [[57, 77], ["resp_encoder_prop.PropositionalResponseEncoder.encode_clause"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.propositional.task_encoder_prop.PropositionalTaskEncoder.encode_clause"], ["", "@", "staticmethod", "\n", "def", "encode_response", "(", "response", ",", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a response to its propositional encoding.\n\n        Parameters\n        ----------\n        response : list(str)\n            Propositional response in list representation (e.g., [\"not\", \"A\"]).\n\n        task : list(list(str))\n            Propositional task as a list of clauses (e.g., [[\"If\", \"A\", \"B\"], [\"A\"]]).\n\n        Returns\n        -------\n        str\n            String representation of the propositional response.\n\n        \"\"\"", "\n", "\n", "return", "PropositionalResponseEncoder", ".", "encode_clause", "(", "response", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.propositional.task_encoder_prop.PropositionalTaskEncoder.encode_clause": [[20, 56], ["reversed", "term.lower", "len", "stack.append", "stack.append", "stack.append", "stack.pop", "stack.append", "stack.pop", "stack.pop", "stack.append", "stack.pop", "stack.pop", "stack.append", "stack.pop", "stack.pop", "stack.pop", "stack.pop"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "encode_clause", "(", "clause", ")", ":", "\n", "        ", "\"\"\" Encodes a single clause by parsing the Polish normal form.\n\n        Parameters\n        ----------\n        clause : list(str)\n            Propositional clause in list representation (e.g., ['If', 'not', 'A', 'B']).\n\n        Returns\n        -------\n        str\n            String representation of the input clause (e.g., \"~A -> B\").\n\n        \"\"\"", "\n", "\n", "# Parse the clause in reverse", "\n", "stack", "=", "[", "]", "\n", "for", "term", "in", "reversed", "(", "clause", ")", ":", "\n", "            ", "norm_term", "=", "term", ".", "lower", "(", ")", "\n", "if", "norm_term", "in", "OPERATORS", ":", "\n", "                ", "if", "norm_term", "==", "'not'", ":", "\n", "                    ", "stack", ".", "append", "(", "'~{}'", ".", "format", "(", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'and'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} & {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'or'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} | {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'iff'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} <=> {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "elif", "norm_term", "==", "'if'", ":", "\n", "                    ", "stack", ".", "append", "(", "'({} -> {})'", ".", "format", "(", "stack", ".", "pop", "(", ")", ",", "stack", ".", "pop", "(", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "stack", ".", "append", "(", "term", ")", "\n", "\n", "", "", "assert", "len", "(", "stack", ")", "==", "1", ",", "'Error: {} -> {}'", ".", "format", "(", "clause", ",", "stack", ")", "\n", "return", "stack", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.propositional.task_encoder_prop.PropositionalTaskEncoder.encode_task": [[57, 74], ["task_encoder_prop.PropositionalTaskEncoder.encode_clause"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.propositional.task_encoder_prop.PropositionalTaskEncoder.encode_clause"], ["", "@", "staticmethod", "\n", "def", "encode_task", "(", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a task to its propositional encoding.\n\n        Parameters\n        ----------\n        task : list(list(str))\n            Propositional task as a list of clauses (e.g., [[\"If\", \"A\", \"B\"], [\"A\"]]).\n\n        Returns\n        -------\n        str\n            String representation of the propositional task.\n\n        \"\"\"", "\n", "\n", "return", "' ; '", ".", "join", "(", "[", "PropositionalTaskEncoder", ".", "encode_clause", "(", "x", ")", "for", "x", "in", "task", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.resp_encoder_syl.SyllogisticResponseEncoder.encode_response": [[13, 49], ["object_sets[].intersection", "[].replace().replace().replace().replace", "isinstance", "set", "[].replace().replace().replace", "[].replace().replace", "list", "[].replace"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "encode_response", "(", "response", ",", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a response to its syllogistic encoding.\n\n        Parameters\n        ----------\n        response : list(str)\n            Syllogistc response in list representation (e.g., ['All', 'A', 'C'])\n\n        task : list(list(str))\n            Syllogistic task in list representation (e.g., [['All', 'A', 'B'], ['Some', 'B', 'C']]).\n\n        Returns\n        -------\n        str\n            Syllogistic response encoding (e.g., 'Aac').\n\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "response", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "response", "=", "[", "response", "]", "\n", "\n", "", "if", "response", "[", "0", "]", "==", "'NVC'", ":", "\n", "            ", "return", "'NVC'", "\n", "\n", "", "if", "response", "[", "0", "]", "[", "0", "]", "==", "'NVC'", ":", "\n", "            ", "return", "'NVC'", "\n", "\n", "", "object_sets", "=", "[", "set", "(", "x", "[", "1", ":", "]", ")", "for", "x", "in", "task", "]", "\n", "midterm", "=", "object_sets", "[", "0", "]", ".", "intersection", "(", "object_sets", "[", "1", "]", ")", "\n", "obj_a", "=", "object_sets", "[", "0", "]", "-", "midterm", "\n", "\n", "quant", "=", "response", "[", "0", "]", "[", "0", "]", ".", "replace", "(", "'All'", ",", "'A'", ")", ".", "replace", "(", "\n", "'Some not'", ",", "'O'", ")", ".", "replace", "(", "'Some'", ",", "'I'", ")", ".", "replace", "(", "'No'", ",", "'E'", ")", "\n", "\n", "return", "quant", "+", "(", "'ac'", "if", "response", "[", "0", "]", "[", "1", "]", "==", "list", "(", "obj_a", ")", "[", "0", "]", "else", "'ca'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.Syllogism.__init__": [[231, 281], ["item.Item", "syllogism.encode_task", "int"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task"], ["def", "__init__", "(", "self", ",", "item", ")", ":", "\n", "        ", "\"\"\" Constructs the Syllogism based on a given task item.\n\n        Parameters\n        ----------\n        item : ccobra.Item\n            CCOBRA task item container to base this Syllogism helper on.\n\n        \"\"\"", "\n", "\n", "#: Instance of the item the Syllogism is constructed on. The instance", "\n", "#: is copied in order to prevent reference mismatches from happening.", "\n", "self", ".", "item", "=", "Item", "(", "\n", "item", ".", "identifier", ",", "\n", "item", ".", "domain", ",", "\n", "item", ".", "task_str", ",", "\n", "item", ".", "response_type", ",", "\n", "item", ".", "choices_str", ",", "\n", "item", ".", "sequence_number", ")", "\n", "\n", "#: Reference to the task the Syllogism is constructed on.", "\n", "self", ".", "task", "=", "self", ".", "item", ".", "task", "\n", "\n", "#: String representation of the task", "\n", "self", ".", "encoded_task", "=", "encode_task", "(", "self", ".", "task", ")", "\n", "\n", "#: List representation of the first premise", "\n", "self", ".", "p1", "=", "self", ".", "task", "[", "0", "]", "\n", "\n", "#: List representation of the second premise", "\n", "self", ".", "p2", "=", "self", ".", "task", "[", "1", "]", "\n", "\n", "#: Quantifier of the first premise", "\n", "self", ".", "quantifier_p1", "=", "self", ".", "task", "[", "0", "]", "[", "0", "]", "\n", "\n", "#: Quantifier of the second premise", "\n", "self", ".", "quantifier_p2", "=", "self", ".", "task", "[", "1", "]", "[", "0", "]", "\n", "\n", "#: Figure of the syllogism", "\n", "self", ".", "figure", "=", "int", "(", "self", ".", "encoded_task", "[", "-", "1", "]", ")", "\n", "\n", "# Figure out the figure and identify the terms", "\n", "if", "self", ".", "figure", "==", "1", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "1", "]", "[", "2", "]", "\n", "", "elif", "self", ".", "figure", "==", "2", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "1", "]", "[", "1", "]", "\n", "", "elif", "self", ".", "figure", "==", "3", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "1", "]", "[", "1", "]", "\n", "", "elif", "self", ".", "figure", "==", "4", ":", "\n", "            ", "self", ".", "A", ",", "self", ".", "B", ",", "self", ".", "C", "=", "self", ".", "task", "[", "0", "]", "[", "2", "]", ",", "self", ".", "task", "[", "0", "]", "[", "1", "]", ",", "self", ".", "task", "[", "1", "]", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.Syllogism.encode_response": [[282, 300], ["syllogism.Syllogism.encode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "", "def", "encode_response", "(", "self", ",", "response", ")", ":", "\n", "        ", "\"\"\" Encodes a given syllogistic response based on the information\n        contained in the premises.\n\n        Parameters\n        ----------\n        response : list(str)\n            Syllogistic response in list representation (e.g.,\n            ['All', 'clerks', 'managers']).\n\n        Returns\n        -------\n        str\n            String encoding of the response (e.g., 'Aac').\n\n        \"\"\"", "\n", "\n", "return", "encode_response", "(", "response", ",", "self", ".", "item", ".", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.Syllogism.decode_response": [[301, 319], ["syllogism.Syllogism.decode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "decode_response", "(", "self", ",", "encoded_response", ")", ":", "\n", "        ", "\"\"\" Decodes a syllogistic response in string representation based on\n        the information stored in the syllogism's premises.\n\n        Parameters\n        ----------\n        encoded_response : str\n            Encoded syllogistic response (e.g., 'Aac').\n\n        Returns\n        -------\n        list(str)\n            List representation of the encoded response (e.g.,\n            ['All', 'clerks', 'managers']).\n\n        \"\"\"", "\n", "\n", "return", "decode_response", "(", "encoded_response", ",", "self", ".", "item", ".", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.Syllogism.is_valid_syllogism": [[320, 331], ["None"], "methods", ["None"], ["", "def", "is_valid_syllogism", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns true if syllogism is valid, i.e., has a logically valid conclusion.\n\n        Returns\n        -------\n        bool\n            True, if syllogism is valid, i.e., has a logically valid conclusion. False otherwise.\n\n        \"\"\"", "\n", "\n", "return", "self", ".", "encoded_task", "in", "VALID_SYLLOGISMS", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.Syllogism.logically_valid_conclusions": [[332, 344], ["None"], "methods", ["None"], ["", "def", "logically_valid_conclusions", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the list of logically valid (according to first-order logics) conclusions for\n        the syllogism.\n\n        Returns\n        -------\n        list(str)\n            List of logically valid conclusions.\n\n        \"\"\"", "\n", "\n", "return", "SYLLOGISTIC_FOL_RESPONSES", "[", "self", ".", "encoded_task", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.Syllogism.__str__": [[345, 369], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Constructs a string representation for the Syllogism object.\n\n        Returns\n        -------\n        str\n            String representation containing the premise, quantifier, figure,\n            and term information.\n\n        \"\"\"", "\n", "\n", "rep", "=", "'Syllogism:\\n'", "\n", "rep", "+=", "'\\ttask: {}\\n'", ".", "format", "(", "self", ".", "task", ")", "\n", "rep", "+=", "'\\tencoded_task: {}\\n'", ".", "format", "(", "self", ".", "encoded_task", ")", "\n", "rep", "+=", "'\\tp1: {}\\n'", ".", "format", "(", "self", ".", "p1", ")", "\n", "rep", "+=", "'\\tp2: {}\\n'", ".", "format", "(", "self", ".", "p2", ")", "\n", "rep", "+=", "'\\tquantifier_p1: {}\\n'", ".", "format", "(", "self", ".", "quantifier_p1", ")", "\n", "rep", "+=", "'\\tquantifier_p2: {}\\n'", ".", "format", "(", "self", ".", "quantifier_p2", ")", "\n", "rep", "+=", "'\\tfigure: {}\\n'", ".", "format", "(", "self", ".", "figure", ")", "\n", "rep", "+=", "'\\tTerms:\\n'", "\n", "rep", "+=", "'\\t\\tA: {}\\n'", ".", "format", "(", "self", ".", "A", ")", "\n", "rep", "+=", "'\\t\\tB: {}\\n'", ".", "format", "(", "self", ".", "B", ")", "\n", "rep", "+=", "'\\t\\tC: {}\\n'", ".", "format", "(", "self", ".", "C", ")", "\n", "return", "rep", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.encode_task": [[107, 123], ["task_encoder_syl.SyllogisticTaskEncoder.encode_task"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task"], ["def", "encode_task", "(", "task", ")", ":", "\n", "    ", "\"\"\" Encodes a syllogistic task.\n\n    Parameters\n    ----------\n    task : list(list(str))\n        List representation of the syllogism (e.g., [['All', 'A', 'B'], ['Some', 'B', 'C']]).\n\n    Returns\n    -------\n    str\n        Syllogistic task encoding (e.g., 'AI1').\n\n    \"\"\"", "\n", "\n", "return", "SyllogisticTaskEncoder", ".", "encode_task", "(", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.encode_response": [[124, 143], ["resp_encoder_syl.SyllogisticResponseEncoder.encode_response"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "encode_response", "(", "response", ",", "task", ")", ":", "\n", "    ", "\"\"\" Encodes a response to its syllogistic encoding.\n\n    Parameters\n    ----------\n    response : list(str)\n        Syllogistc response in list representation (e.g., ['All', 'A', 'C'])\n\n    task : list(list(str))\n        Syllogistic task in list representation (e.g., [['All', 'A', 'B'], ['Some', 'B', 'C']]).\n\n    Returns\n    -------\n    str\n        Syllogistic response encoding (e.g., 'Aac').\n\n    \"\"\"", "\n", "\n", "return", "SyllogisticResponseEncoder", ".", "encode_response", "(", "response", ",", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response": [[145, 181], ["enc_response[].replace().replace().replace().replace", "set", "set", "set", "set", "enc_response[].replace().replace().replace", "list", "list", "enc_response[].replace().replace", "list", "list", "enc_response[].replace"], "function", ["None"], ["", "def", "decode_response", "(", "enc_response", ",", "task", ")", ":", "\n", "    ", "\"\"\" Decodes an encoded syllogistic response by transforming it to the\n    corresponding tuple representation and inserting the appropriate terms.\n\n    Parameters\n    ----------\n    enc_response : str\n        Encoded syllogistic response (e.g., 'Aac').\n\n    task : list(str)\n        Syllogistic task in the tuple list representation (e.g.,\n        [['Some', 'models', 'managers'], ['All', 'models', 'clerks']]).\n\n    Returns\n    -------\n    list\n        List representation of the response to decode.\n\n    \"\"\"", "\n", "\n", "if", "enc_response", "==", "'NVC'", ":", "\n", "        ", "return", "[", "[", "'NVC'", "]", "]", "\n", "", "if", "enc_response", "==", "[", "'NVC'", "]", ":", "\n", "        ", "return", "[", "enc_response", "]", "\n", "", "if", "enc_response", "==", "[", "[", "'NVC'", "]", "]", ":", "\n", "        ", "return", "enc_response", "\n", "\n", "", "obj_a", "=", "set", "(", "task", "[", "0", "]", "[", "1", ":", "]", ")", "-", "set", "(", "task", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "obj_c", "=", "set", "(", "task", "[", "1", "]", "[", "1", ":", "]", ")", "-", "set", "(", "task", "[", "0", "]", "[", "1", ":", "]", ")", "\n", "\n", "quant", "=", "enc_response", "[", "0", "]", ".", "replace", "(", "'A'", ",", "'All'", ")", ".", "replace", "(", "\n", "'I'", ",", "'Some'", ")", ".", "replace", "(", "'O'", ",", "'Some not'", ")", ".", "replace", "(", "'E'", ",", "'No'", ")", "\n", "if", "enc_response", "[", "1", ":", "]", "==", "'ac'", ":", "\n", "        ", "return", "[", "[", "quant", ",", "list", "(", "obj_a", ")", "[", "0", "]", ",", "list", "(", "obj_c", ")", "[", "0", "]", "]", "]", "\n", "\n", "", "return", "[", "[", "quant", ",", "list", "(", "obj_c", ")", "[", "0", "]", ",", "list", "(", "obj_a", ")", "[", "0", "]", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.dataset_to_matrix": [[182, 223], ["numpy.zeros", "enumerate", "isinstance", "ValueError", "numpy.zeros", "np.zeros.reshape", "len", "syllogism.Syllogism", "syllogism.Syllogism.encode_response", "SYLLOGISMS.index", "RESPONSES.index", "np.zeros.sum"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "dataset_to_matrix", "(", "dataset", ")", ":", "\n", "    ", "\"\"\" Convert a training dataset (e.g., pre_train) into a corresponding matrix representation of\n    shape (576 x n_subj).\n\n    Parameters\n    ----------\n    dataset : list(list(...))\n        Training dataset (e.g., pre_train) represented as a list of subjects represented as lists\n        of tasks and corresponding responses.\n\n    Returns\n    -------\n    mat : np.ndarray\n        Dataset matrix of shape (576 x n_subj). The first dimension reflects the different response\n        option to syllogistic problems (64 tasks x 9 responses = 576 options). The resulting\n        matrix is normalized so that each block of 9 options (i.e., tasks) is normalized to sum\n        up to 1. Each column therefore sums up to 64.\n\n    \"\"\"", "\n", "\n", "# Check for valid arguments", "\n", "if", "not", "isinstance", "(", "dataset", ",", "list", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid dataset. Must be of type list'", ")", "\n", "\n", "", "mat", "=", "np", ".", "zeros", "(", "(", "576", ",", "len", "(", "dataset", ")", ")", ")", "\n", "for", "subj_idx", ",", "subj_data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "        ", "subj_mat", "=", "np", ".", "zeros", "(", "(", "64", ",", "9", ")", ")", "\n", "\n", "for", "task_data", "in", "subj_data", ":", "\n", "            ", "syllog", "=", "Syllogism", "(", "task_data", "[", "'item'", "]", ")", "\n", "enc_resp", "=", "syllog", ".", "encode_response", "(", "task_data", "[", "'response'", "]", ")", "\n", "\n", "syl_idx", "=", "SYLLOGISMS", ".", "index", "(", "syllog", ".", "encoded_task", ")", "\n", "rsp_idx", "=", "RESPONSES", ".", "index", "(", "enc_resp", ")", "\n", "subj_mat", "[", "syl_idx", ",", "rsp_idx", "]", "+=", "1", "\n", "\n", "# Normalize subject response data and add to overall result matrix", "\n", "", "subj_mat", "=", "subj_mat", "/", "subj_mat", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "mat", "[", ":", ",", "subj_idx", "]", "=", "subj_mat", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "", "return", "mat", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task": [[12, 53], ["prem_1[].replace().replace().replace().replace", "prem_2[].replace().replace().replace().replace", "str", "prem_1[].replace().replace().replace", "prem_2[].replace().replace().replace", "prem_1[].replace().replace", "prem_2[].replace().replace", "ValueError", "prem_1[].replace", "prem_2[].replace"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "encode_task", "(", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a task to its syllogistic encoding.\n\n        Parameters\n        ----------\n        task : list(list(str))\n            List representation of the syllogism (e.g., [['All', 'A', 'B'], ['Some', 'B', 'C']]).\n\n        Returns\n        -------\n        str\n            Syllogistic task encoding (e.g., 'AI1').\n\n        Raises\n        ------\n        ValueError\n            If figure of syllogism cannot be determined.\n\n        \"\"\"", "\n", "\n", "prem_1", ",", "prem_2", "=", "task", "\n", "\n", "quant1", "=", "prem_1", "[", "0", "]", ".", "replace", "(", "'All'", ",", "'A'", ")", ".", "replace", "(", "\n", "'Some not'", ",", "'O'", ")", ".", "replace", "(", "'Some'", ",", "'I'", ")", ".", "replace", "(", "'No'", ",", "'E'", ")", "\n", "quant2", "=", "prem_2", "[", "0", "]", ".", "replace", "(", "'All'", ",", "'A'", ")", ".", "replace", "(", "\n", "'Some not'", ",", "'O'", ")", ".", "replace", "(", "'Some'", ",", "'I'", ")", ".", "replace", "(", "'No'", ",", "'E'", ")", "\n", "figure", "=", "1", "\n", "\n", "if", "prem_1", "[", "1", "]", "==", "prem_2", "[", "1", "]", ":", "\n", "            ", "figure", "=", "4", "\n", "", "elif", "prem_1", "[", "2", "]", "==", "prem_2", "[", "1", "]", ":", "\n", "            ", "figure", "=", "1", "\n", "", "elif", "prem_1", "[", "2", "]", "==", "prem_2", "[", "2", "]", ":", "\n", "            ", "figure", "=", "3", "\n", "", "elif", "prem_1", "[", "1", "]", "==", "prem_2", "[", "2", "]", ":", "\n", "            ", "figure", "=", "2", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Could not determine figure of:'", ",", "task", ")", "\n", "\n", "", "return", "quant1", "+", "quant2", "+", "str", "(", "figure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_response": [[54, 90], ["object_sets[].intersection", "[].replace().replace().replace().replace", "isinstance", "set", "[].replace().replace().replace", "[].replace().replace", "list", "[].replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "encode_response", "(", "response", ",", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a response to its syllogistic encoding.\n\n        Parameters\n        ----------\n        response : list(str)\n            Syllogistc response in list representation (e.g., ['All', 'A', 'C'])\n\n        task : list(list(str))\n            Syllogistic task in list representation (e.g., [['All', 'A', 'B'], ['Some', 'B', 'C']]).\n\n        Returns\n        -------\n        str\n            Syllogistic response encoding (e.g., 'Aac').\n\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "response", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "response", "=", "[", "response", "]", "\n", "\n", "", "if", "response", "[", "0", "]", "==", "'NVC'", ":", "\n", "            ", "return", "'NVC'", "\n", "\n", "", "if", "response", "[", "0", "]", "[", "0", "]", "==", "'NVC'", ":", "\n", "            ", "return", "'NVC'", "\n", "\n", "", "object_sets", "=", "[", "set", "(", "x", "[", "1", ":", "]", ")", "for", "x", "in", "task", "]", "\n", "midterm", "=", "object_sets", "[", "0", "]", ".", "intersection", "(", "object_sets", "[", "1", "]", ")", "\n", "obj_a", "=", "object_sets", "[", "0", "]", "-", "midterm", "\n", "\n", "quant", "=", "response", "[", "0", "]", "[", "0", "]", ".", "replace", "(", "'All'", ",", "'A'", ")", ".", "replace", "(", "\n", "'Some not'", ",", "'O'", ")", ".", "replace", "(", "'Some'", ",", "'I'", ")", ".", "replace", "(", "'No'", ",", "'E'", ")", "\n", "\n", "return", "quant", "+", "(", "'ac'", "if", "response", "[", "0", "]", "[", "1", "]", "==", "list", "(", "obj_a", ")", "[", "0", "]", "else", "'ca'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.test_encoding.EncodingTestCase.test_encode_response_quantifiers": [[10, 39], ["test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["def", "test_encode_response_quantifiers", "(", "self", ")", ":", "\n", "        ", "\"\"\" Tests the encodings of all syllogistic quantifiers on a single\n        demonstrative task.\n\n        \"\"\"", "\n", "\n", "task", "=", "[", "\n", "[", "'All'", ",", "'models'", ",", "'managers'", "]", ",", "\n", "[", "'All'", ",", "'managers'", ",", "'clerks'", "]", "\n", "]", "\n", "\n", "self", ".", "assertEqual", "(", "'Aac'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'All'", ",", "'models'", ",", "'clerks'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'Aca'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'All'", ",", "'clerks'", ",", "'models'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'Iac'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'Some'", ",", "'models'", ",", "'clerks'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'Ica'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'Some'", ",", "'clerks'", ",", "'models'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'Eac'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'No'", ",", "'models'", ",", "'clerks'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'Eca'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'No'", ",", "'clerks'", ",", "'models'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'Oac'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'Some not'", ",", "'models'", ",", "'clerks'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'Oca'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'Some not'", ",", "'clerks'", ",", "'models'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'NVC'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "'NVC'", "]", ",", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.test_encoding.EncodingTestCase.test_encode_response_brackets": [[40, 55], ["test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response", "ccobra.syllogistic.encode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "test_encode_response_brackets", "(", "self", ")", ":", "\n", "        ", "task", "=", "[", "\n", "[", "'All'", ",", "'models'", ",", "'managers'", "]", ",", "\n", "[", "'All'", ",", "'managers'", ",", "'clerks'", "]", "\n", "]", "\n", "\n", "# Regular quantified response", "\n", "self", ".", "assertEqual", "(", "'Aac'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "[", "'All'", ",", "'models'", ",", "'clerks'", "]", "]", ",", "task", ")", ")", "\n", "\n", "# NVC response", "\n", "self", ".", "assertEqual", "(", "'NVC'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "'NVC'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "'NVC'", ",", "ccobra", ".", "syllogistic", ".", "encode_response", "(", "\n", "[", "[", "'NVC'", "]", "]", ",", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.test_encoding.EncodingTestCase.test_encode_task_figure": [[56, 65], ["test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "ccobra.syllogistic.encode_task", "ccobra.syllogistic.encode_task", "ccobra.syllogistic.encode_task", "ccobra.syllogistic.encode_task"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task"], ["", "def", "test_encode_task_figure", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "'AA1'", ",", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "\n", "[", "[", "'All'", ",", "'A'", ",", "'B'", "]", ",", "[", "'All'", ",", "'B'", ",", "'C'", "]", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "'AA2'", ",", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "\n", "[", "[", "'All'", ",", "'B'", ",", "'A'", "]", ",", "[", "'All'", ",", "'C'", ",", "'B'", "]", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "'AA3'", ",", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "\n", "[", "[", "'All'", ",", "'A'", ",", "'B'", "]", ",", "[", "'All'", ",", "'C'", ",", "'B'", "]", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "'AA4'", ",", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "\n", "[", "[", "'All'", ",", "'B'", ",", "'A'", "]", ",", "[", "'All'", ",", "'B'", ",", "'C'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.test_encoding.EncodingTestCase.test_encode_task_quantifiers": [[66, 71], ["test_encoding.EncodingTestCase.assertEqual", "test_encoding.EncodingTestCase.assertEqual", "ccobra.syllogistic.encode_task", "ccobra.syllogistic.encode_task"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task"], ["", "def", "test_encode_task_quantifiers", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "'AO1'", ",", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "\n", "[", "[", "'All'", ",", "'A'", ",", "'B'", "]", ",", "[", "'Some not'", ",", "'B'", ",", "'C'", "]", "]", ")", ")", "\n", "self", ".", "assertEqual", "(", "'EI1'", ",", "ccobra", ".", "syllogistic", ".", "encode_task", "(", "\n", "[", "[", "'No'", ",", "'A'", ",", "'B'", "]", ",", "[", "'Some'", ",", "'B'", ",", "'C'", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.test_decoding.DecodingTestCase.test_decode_response_quantifiers": [[10, 32], ["test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["def", "test_decode_response_quantifiers", "(", "self", ")", ":", "\n", "        ", "task", "=", "[", "[", "'All'", ",", "'models'", ",", "'managers'", "]", ",", "[", "'All'", ",", "'managers'", ",", "'clerks'", "]", "]", "\n", "\n", "self", ".", "assertEqual", "(", "[", "[", "'All'", ",", "'models'", ",", "'clerks'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Aac'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'All'", ",", "'clerks'", ",", "'models'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Acc'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'Some'", ",", "'models'", ",", "'clerks'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Iac'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'Some'", ",", "'clerks'", ",", "'models'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Icc'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'No'", ",", "'models'", ",", "'clerks'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Eac'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'No'", ",", "'clerks'", ",", "'models'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Ecc'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'Some not'", ",", "'models'", ",", "'clerks'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Oac'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'Some not'", ",", "'clerks'", ",", "'models'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'Occ'", ",", "task", ")", ")", "\n", "\n", "self", ".", "assertEqual", "(", "[", "[", "'NVC'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'NVC'", ",", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.test_decoding.DecodingTestCase.test_decode_response_brackets": [[33, 42], ["test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "test_decoding.DecodingTestCase.assertEqual", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response", "ccobra.syllogistic.decode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.syllogism.decode_response"], ["", "def", "test_decode_response_brackets", "(", "self", ")", ":", "\n", "        ", "task", "=", "[", "[", "'All'", ",", "'models'", ",", "'managers'", "]", ",", "[", "'All'", ",", "'managers'", ",", "'clerks'", "]", "]", "\n", "\n", "self", ".", "assertEqual", "(", "[", "[", "'NVC'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "'NVC'", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'NVC'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "[", "'NVC'", "]", ",", "task", ")", ")", "\n", "self", ".", "assertEqual", "(", "[", "[", "'NVC'", "]", "]", ",", "\n", "ccobra", ".", "syllogistic", ".", "decode_response", "(", "[", "[", "'NVC'", "]", "]", ",", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response": [[13, 32], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "encode_response", "(", "response", ",", "task", ")", ":", "\n", "        ", "\"\"\" Encodes a response to its syllogistic encoding.\n\n        Parameters\n        ----------\n        response : list(str)\n            Any response that should be returned\n\n        task : list(list(str))\n            Unused\n\n        Returns\n        -------\n        str\n            The response\n\n        \"\"\"", "\n", "return", "response", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.runner.parse_arguments": [[29, 71], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "vars", "argparse.ArgumentParser.parse_args", "print", "argparse.ArgumentParser.print_help", "sys.exit", "args[].lower", "logging.basicConfig", "args[].lower", "logging.basicConfig", "args[].lower", "logging.basicConfig"], "function", ["None"], ["def", "parse_arguments", "(", ")", ":", "\n", "    ", "\"\"\" Parses the command line arguments for the benchmark runner.\n\n    Returns\n    -------\n    dict\n        Dictionary mapping from cmd arguments to values.\n\n    \"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'CCOBRA version {}.'", ".", "format", "(", "__version__", ")", ")", "\n", "parser", ".", "add_argument", "(", "'benchmark'", ",", "type", "=", "str", ",", "help", "=", "'Benchmark file.'", ")", "\n", "parser", ".", "add_argument", "(", "'-m'", ",", "'--model'", ",", "type", "=", "str", ",", "help", "=", "'Model file.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-o'", ",", "'--output'", ",", "type", "=", "str", ",", "default", "=", "'browser'", ",", "help", "=", "'Output style (browser/server).'", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--cache'", ",", "type", "=", "str", ",", "help", "=", "'Load specified cache file.'", ")", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "'--save'", ",", "type", "=", "str", ",", "help", "=", "'Store results as csv table.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-cn'", ",", "'--classname'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'Load a specific class from a folder containing multiple classes.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ll'", ",", "'--logginglevel'", ",", "type", "=", "str", ",", "default", "=", "'NONE'", ",", "\n", "help", "=", "'Set logging level [NONE, DEBUG, INFO, WARNING].'", "\n", ")", "\n", "\n", "args", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "\n", "# Check for validity of command line arguments", "\n", "if", "not", "args", "[", "'model'", "]", "and", "not", "args", "[", "'benchmark'", "]", ":", "\n", "        ", "print", "(", "'ERROR: Must specify either model or benchmark.'", ")", "\n", "parser", ".", "print_help", "(", ")", "\n", "sys", ".", "exit", "(", "99", ")", "\n", "\n", "# Setup logging", "\n", "", "if", "args", "[", "'logginglevel'", "]", ".", "lower", "(", ")", "==", "'debug'", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "DEBUG", ")", "\n", "", "elif", "args", "[", "'logginglevel'", "]", ".", "lower", "(", ")", "==", "'info'", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "", "elif", "args", "[", "'logginglevel'", "]", ".", "lower", "(", ")", "==", "'warning'", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "WARNING", ")", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.runner.silence_stdout": [[72, 93], ["open"], "function", ["None"], ["", "@", "contextmanager", "\n", "def", "silence_stdout", "(", "silent", ",", "target", "=", "os", ".", "devnull", ")", ":", "\n", "    ", "\"\"\" Contextmanager to silence stdout printing.\n\n    Parameters\n    ----------\n    silent : bool\n        Flag to indicate whether contextmanager should actually silence stdout.\n\n    target : filepath, optional\n        Target to redirect silenced stdout output to. Default is os.devnull.\n        Can be modified to point to a log file instead.\n\n    \"\"\"", "\n", "\n", "new_target", "=", "open", "(", "target", ",", "'w'", ")", "if", "silent", "else", "sys", ".", "stdout", "\n", "old_target", ",", "sys", ".", "stdout", "=", "sys", ".", "stdout", ",", "new_target", "\n", "try", ":", "\n", "        ", "yield", "new_target", "\n", "", "finally", ":", "\n", "        ", "sys", ".", "stdout", "=", "old_target", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.runner.main": [[94, 199], ["benchmark.Benchmark", "evaluator.Evaluator", "enumerate", "visualization.html_creator.HTMLCreator", "os.path.basename", "pandas.read_csv", "runner.silence_stdout", "evaluator.Evaluator.evaluate", "res_df.to_csv", "visualization.viz_plot.AccuracyVisualizer", "visualization.viz_plot.BoxplotVisualizer", "visualization.viz_plot.SubjectTableVisualizer", "os.path.basename", "list", "list", "html_creator.HTMLCreator.to_html", "sys.stdout.buffer.write", "html_creator.HTMLCreator.to_html", "datetime.datetime.now().strftime", "os.path.join", "webbrowser.open", "metrics.append", "metrics.append", "res_df[].unique", "res_df[].unique", "htmlcrtr.to_html.encode", "os.path.splitext", "codecs.open", "html_out.write", "os.path.basename", "os.path.basename", "os.path.basename", "os.path.basename", "datetime.datetime.now", "os.path.realpath", "bmark.Benchmark.data_pre_train_path.split", "bmark.Benchmark.data_pre_train_person_path.split", "bmark.Benchmark.data_pre_person_background_path.split", "visualization.viz_plot.AccuracyVisualizer", "visualization.viz_plot.BoxplotVisualizer", "visualization.viz_plot.SubjectTableVisualizer", "visualization.viz_plot.MFATableVisualizer", "visualization.viz_plot.ModelLogVisualizer"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.runner.silence_stdout", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluator.Evaluator.evaluate", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.to_html", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.to_html"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "\"\"\" Main benchmark routine. Parses the arguments, loads models and data,\n    runs the evaluation loop and produces the output.\n\n    Parameters\n    ----------\n    args : dict\n        Command line argument dictionary.\n\n    \"\"\"", "\n", "\n", "# Load cache information", "\n", "cache_df", "=", "None", "\n", "if", "args", "[", "'cache'", "]", ":", "\n", "        ", "cache_df", "=", "pd", ".", "read_csv", "(", "args", "[", "'cache'", "]", ")", "\n", "\n", "# Load the benchmark settings", "\n", "", "benchmark", "=", "bmark", ".", "Benchmark", "(", "\n", "args", "[", "'benchmark'", "]", ",", "\n", "argmodel", "=", "(", "args", "[", "'model'", "]", ",", "args", "[", "'classname'", "]", ")", ",", "\n", "cached", "=", "(", "cache_df", "is", "not", "None", ")", "\n", ")", "\n", "\n", "# Run the model evaluation", "\n", "is_silent", "=", "(", "args", "[", "'output'", "]", "in", "[", "'html'", ",", "'server'", "]", ")", "\n", "eva", "=", "evaluator", ".", "Evaluator", "(", "benchmark", ",", "is_silent", "=", "is_silent", ",", "cache_df", "=", "cache_df", ")", "\n", "with", "silence_stdout", "(", "is_silent", ")", ":", "\n", "        ", "res_df", ",", "model_log", "=", "eva", ".", "evaluate", "(", ")", "\n", "\n", "", "if", "'save'", "in", "args", ":", "\n", "        ", "res_df", ".", "to_csv", "(", "args", "[", "'save'", "]", ",", "index", "=", "False", ")", "\n", "\n", "# Create metrics dictionary", "\n", "#(TODO: check if there is a good way of dynamically specify the visualization)", "\n", "", "default_list", "=", "[", "\n", "viz_plot", ".", "AccuracyVisualizer", "(", ")", ",", "\n", "viz_plot", ".", "BoxplotVisualizer", "(", ")", ",", "\n", "viz_plot", ".", "SubjectTableVisualizer", "(", ")", "\n", "]", "\n", "metrics", "=", "[", "]", "\n", "for", "idx", ",", "eva", "in", "enumerate", "(", "benchmark", ".", "evaluation_handlers", ")", ":", "\n", "        ", "if", "idx", "==", "0", ":", "\n", "            ", "metrics", ".", "append", "(", "(", "\n", "eva", ",", "[", "\n", "viz_plot", ".", "AccuracyVisualizer", "(", ")", ",", "\n", "viz_plot", ".", "BoxplotVisualizer", "(", ")", ",", "\n", "viz_plot", ".", "SubjectTableVisualizer", "(", ")", ",", "\n", "viz_plot", ".", "MFATableVisualizer", "(", ")", ",", "\n", "viz_plot", ".", "ModelLogVisualizer", "(", ")", "\n", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "metrics", ".", "append", "(", "(", "\n", "eva", ",", "default_list", "\n", ")", ")", "\n", "\n", "# Run the metric visualizer", "\n", "", "", "htmlcrtr", "=", "html_creator", ".", "HTMLCreator", "(", "metrics", ")", "\n", "\n", "# Prepare the benchmark output information and visualize the evaluation results", "\n", "path_pre_train", "=", "''", "\n", "path_pre_train_person", "=", "''", "\n", "path_pre_person_background", "=", "''", "\n", "path_test", "=", "os", ".", "path", ".", "basename", "(", "benchmark", ".", "data_test_path", ")", "\n", "\n", "if", "benchmark", ".", "data_pre_train_path", ":", "\n", "        ", "path_pre_train", "=", "';'", ".", "join", "(", "[", "\n", "os", ".", "path", ".", "basename", "(", "x", ")", "for", "x", "in", "benchmark", ".", "data_pre_train_path", ".", "split", "(", "';'", ")", "]", ")", "\n", "", "if", "benchmark", ".", "data_pre_train_person_path", ":", "\n", "        ", "path_pre_train_person", "=", "';'", ".", "join", "(", "[", "\n", "os", ".", "path", ".", "basename", "(", "x", ")", "for", "x", "in", "benchmark", ".", "data_pre_train_person_path", ".", "split", "(", "';'", ")", "]", ")", "\n", "", "if", "benchmark", ".", "data_pre_person_background_path", ":", "\n", "        ", "path_pre_person_background", "=", "';'", ".", "join", "(", "[", "\n", "os", ".", "path", ".", "basename", "(", "x", ")", "for", "x", "in", "benchmark", ".", "data_pre_person_background_path", ".", "split", "(", "';'", ")", "]", ")", "\n", "\n", "", "benchmark_info", "=", "{", "\n", "'name'", ":", "os", ".", "path", ".", "basename", "(", "args", "[", "'benchmark'", "]", ")", ",", "\n", "'data.test'", ":", "path_test", ",", "\n", "'data.pre_train'", ":", "path_pre_train", ",", "\n", "'data.pre_train_person'", ":", "path_pre_train_person", ",", "\n", "'data.pre_person_background'", ":", "path_pre_person_background", ",", "\n", "'type'", ":", "benchmark", ".", "type", ",", "\n", "'domains'", ":", "list", "(", "res_df", "[", "'domain'", "]", ".", "unique", "(", ")", ")", ",", "\n", "'response_types'", ":", "list", "(", "res_df", "[", "'response_type'", "]", ".", "unique", "(", ")", ")", ",", "\n", "}", "\n", "\n", "benchmark_info", "[", "'corresponding_data'", "]", "=", "benchmark", ".", "corresponding_data", "\n", "\n", "# Generate the HTML output", "\n", "if", "args", "[", "'output'", "]", "==", "'server'", ":", "\n", "        ", "html", "=", "htmlcrtr", ".", "to_html", "(", "res_df", ",", "benchmark_info", ",", "model_log", ",", "embedded", "=", "True", ")", "\n", "sys", ".", "stdout", ".", "buffer", ".", "write", "(", "html", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "else", ":", "\n", "        ", "html", "=", "htmlcrtr", ".", "to_html", "(", "res_df", ",", "benchmark_info", ",", "model_log", ",", "embedded", "=", "False", ")", "\n", "\n", "# Save HTML output to file", "\n", "benchmark_filename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "args", "[", "'benchmark'", "]", ")", ")", "[", "0", "]", "\n", "timestamp", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d_%H-%M-%S'", ")", "\n", "html_filename", "=", "'_'", ".", "join", "(", "[", "benchmark_filename", ",", "timestamp", ",", "'.html'", "]", ")", "\n", "html_filepath", "=", "os", ".", "path", ".", "join", "(", "benchmark", ".", "base_path", ",", "html_filename", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "html_filepath", ",", "'w'", ",", "'utf-8'", ")", "as", "html_out", ":", "\n", "            ", "html_out", ".", "write", "(", "html", ")", "\n", "\n", "# Open HTML output in default browser", "\n", "", "webbrowser", ".", "open", "(", "'file://'", "+", "os", ".", "path", ".", "realpath", "(", "html_filepath", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.runner.entry_point": [[200, 225], ["runner.parse_arguments", "print", "exit", "runner.main", "len", "sys.exit", "str", "print", "print"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.runner.parse_arguments", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.runner.main"], ["", "", "def", "entry_point", "(", ")", ":", "\n", "    ", "\"\"\" Entry point for the CCOBRA executables.\n\n    \"\"\"", "\n", "\n", "# Manually catch version command line argument", "\n", "if", "len", "(", "sys", ".", "argv", ")", ">", "1", "and", "sys", ".", "argv", "[", "1", "]", "==", "'--version'", ":", "\n", "        ", "print", "(", "'CCOBRA version {}'", ".", "format", "(", "__version__", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "# Parse command line arguments", "\n", "", "args", "=", "parse_arguments", "(", ")", "\n", "\n", "try", ":", "\n", "        ", "main", "(", "args", ")", "\n", "", "except", "Exception", "as", "exc", ":", "\n", "        ", "if", "args", "[", "'output'", "]", "!=", "'html'", ":", "\n", "            ", "raise", "\n", "", "msg", "=", "'Error: '", "+", "str", "(", "exc", ")", "\n", "if", "args", "[", "'output'", "]", "==", "'html'", ":", "\n", "            ", "print", "(", "'<p>{}</p><script>document.getElementById(\\\"result\\\").style.backgroundColor '", "'= \\\"Tomato\\\";</script>'", ".", "format", "(", "msg", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "exc", ")", "\n", "", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.contextmanager.dir_context": [[10, 34], ["os.path.abspath", "os.path.isfile", "os.getcwd", "os.chdir", "sys.path.append", "os.path.dirname", "os.chdir", "sys.path.remove"], "function", ["None"], ["@", "contextmanager", "\n", "def", "dir_context", "(", "path", ")", ":", "\n", "    ", "\"\"\" Context manager for the working directory. Stores the current working directory before\n    switching it. Finally, resets to the old wd.\n\n    Parameters\n    ----------\n    path : str\n        String to set the working directory to.\n\n    \"\"\"", "\n", "\n", "context", "=", "os", ".", "path", ".", "abspath", "(", "path", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "context", ")", ":", "\n", "        ", "context", "=", "os", ".", "path", ".", "dirname", "(", "context", ")", "\n", "\n", "", "old_dir", "=", "os", ".", "getcwd", "(", ")", "\n", "os", ".", "chdir", "(", "context", ")", "\n", "sys", ".", "path", ".", "append", "(", "context", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "os", ".", "chdir", "(", "old_dir", ")", "\n", "sys", ".", "path", ".", "remove", "(", "context", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.get_class": [[23, 133], ["os.path.abspath", "os.path.isfile", "set", "candidates.items", "python_files.append", "importlib.machinery.SourceFileLoader", "importlib.machinery.SourceFileLoader.load_module", "inspect.getmembers", "ValueError", "len", "candidates.values", "inspect.getmembers", "len", "ValueError", "os.path.join", "os.path.splitext", "set.add", "candidates.values", "len", "ValueError", "os.listdir", "os.path.basename", "issubclass", "list", "list", "os.path.isfile", "candidates.values", "str", "str", "remaining_classes.remove", "os.path.join", "ValueError"], "methods", ["None"], ["def", "get_class", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "\"\"\" Determines the model class attribute.\n\n        Parameters\n        ----------\n        model_path : str\n            Path to the file to scan for CCobraModel classes.\n\n        Returns\n        -------\n        str\n            CCobraModel class attribute.\n\n        Raises\n        ------\n        ValueError\n            Thrown if the class to load could not be determined.\n\n        \"\"\"", "\n", "\n", "python_files", "=", "[", "]", "\n", "abs_path", "=", "os", ".", "path", ".", "abspath", "(", "model_path", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "abs_path", ")", ":", "\n", "            ", "python_files", ".", "append", "(", "abs_path", ")", "\n", "", "else", ":", "\n", "            ", "python_files", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "abs_path", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "\n", "abs_path", ")", "if", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "abs_path", ",", "f", ")", ")", "and", "f", "[", "-", "2", ":", "]", "==", "\"py\"", "]", "\n", "\n", "", "candidates", "=", "{", "}", "\n", "candidate_class_names", "=", "set", "(", ")", "\n", "\n", "for", "python_file", "in", "python_files", ":", "\n", "            ", "module_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "python_file", ")", ")", "[", "0", "]", "\n", "\n", "sfl", "=", "importlib", ".", "machinery", ".", "SourceFileLoader", "(", "module_name", ",", "python_file", ")", "\n", "module", "=", "sfl", ".", "load_module", "(", ")", "\n", "member_class_modules", "=", "inspect", ".", "getmembers", "(", "module", ",", "inspect", ".", "isclass", ")", "\n", "\n", "candidate_module", "=", "None", "\n", "candidate_class", "=", "None", "\n", "for", "member_class_module", "in", "member_class_modules", ":", "\n", "                ", "member_class", "=", "member_class_module", "[", "1", "]", "\n", "\n", "if", "member_class", "is", "self", ".", "superclass", ":", "\n", "                    ", "continue", "\n", "", "elif", "issubclass", "(", "member_class", ",", "self", ".", "superclass", ")", ":", "\n", "                    ", "if", "self", ".", "load_specific_class", "is", "None", "and", "candidate_module", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "'Multiple model classes found in file '", "'(e.g., {} and {}). '", "'Please only specify one per file.'", ".", "format", "(", "\n", "member_class", ".", "__name__", ",", "candidate_class", ".", "__name__", ")", ")", "\n", "\n", "", "if", "self", ".", "load_specific_class", "is", "None", "or", "self", ".", "load_specific_class", "==", "member_class", ".", "__name__", ":", "\n", "                        ", "candidate_module", "=", "module", "\n", "candidate_class", "=", "member_class", "\n", "\n", "", "", "", "if", "candidate_module", ":", "\n", "                ", "full_name", "=", "'{}.{}'", ".", "format", "(", "\n", "candidate_module", ".", "__name__", ",", "candidate_class", ".", "__name__", ")", "\n", "candidates", "[", "full_name", "]", "=", "(", "candidate_module", ",", "candidate_class", ")", "\n", "candidate_class_names", ".", "add", "(", "full_name", ")", "\n", "\n", "", "", "if", "not", "candidates", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"No suitable classes found in model_path '{}'.\"", ".", "format", "(", "\n", "model_path", ")", ")", "\n", "", "if", "len", "(", "candidates", ")", "==", "1", ":", "\n", "            ", "return", "list", "(", "candidates", ".", "values", "(", ")", ")", "[", "0", "]", "[", "1", "]", "\n", "\n", "", "if", "self", ".", "load_specific_class", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "load_specific_class", "in", "candidates", ":", "\n", "# print(\"Selecting {} because the user demands it\".format(self.load_specific_class))", "\n", "                ", "return", "candidates", "[", "self", ".", "load_specific_class", "]", "[", "1", "]", "\n", "\n", "", "for", "candidate", "in", "candidates", ".", "values", "(", ")", ":", "\n", "                ", "candidate_class", "=", "candidate", "[", "1", "]", "\n", "if", "candidate_class", ".", "__name__", "==", "self", ".", "load_specific_class", ":", "\n", "# print(\"Selecting {} because the user did not \" \\", "\n", "#     \"provide a full path\".format(self.load_specific_class))", "\n", "                    ", "return", "candidate_class", "\n", "\n", "", "", "", "remaining_classes", "=", "{", "x", "[", "1", "]", "for", "x", "in", "candidates", ".", "values", "(", ")", "}", "\n", "for", "full_name", ",", "content", "in", "candidates", ".", "items", "(", ")", ":", "\n", "            ", "candidate_module", "=", "content", "[", "0", "]", "\n", "candidate_class", "=", "content", "[", "1", "]", "\n", "imported_modules", "=", "inspect", ".", "getmembers", "(", "\n", "candidate_module", ",", "inspect", ".", "ismodule", ")", "\n", "\n", "for", "imported_module", "in", "imported_modules", ":", "\n", "                ", "imported_module", "=", "imported_module", "[", "1", "]", "\n", "\n", "for", "other", "in", "candidates", ":", "\n", "                    ", "other_module", "=", "candidates", "[", "other", "]", "[", "0", "]", "\n", "other_class", "=", "candidates", "[", "other", "]", "[", "1", "]", "\n", "\n", "if", "str", "(", "other_module", ")", "==", "str", "(", "imported_module", ")", ":", "\n", "                        ", "remaining_classes", ".", "remove", "(", "other_class", ")", "\n", "\n", "", "", "", "", "if", "len", "(", "remaining_classes", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Could not determine main class. Candidates were: '{}'.\"", ".", "format", "(", "\n", "remaining_classes", ")", ")", "\n", "", "elif", "len", "(", "remaining_classes", ")", "==", "1", ":", "\n", "            ", "return", "list", "(", "remaining_classes", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Could not determine main class.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.__init__": [[134, 169], ["set", "modelimporter.ModelImporter.get_class", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.get_class"], ["", "", "def", "__init__", "(", "self", ",", "model_path", ",", "superclass", "=", "object", ",", "load_specific_class", "=", "None", ")", ":", "\n", "        ", "\"\"\" Imports a model based on a given python source script. Dynamically\n        identifies the contained model class and prepares for instantiation.\n\n        Parameters\n        ----------\n        model_path : str\n            Path to the python script to import. May be absolute or relative.\n\n        superclass : object, optional\n            Superclass determining which classes to consider for\n            initialization.\n\n        load_specific_class : str, optional\n            Name of the class to load. Required if model file contains multiple CCobraModels.\n\n        Raises\n        ------\n        ValueError\n            When multiple applicable model classes are found (determined via\n            the superclass parameter). Only one single model is allowed per\n            file.\n\n        ValueError\n            When no model with the given superclass is found.\n\n        \"\"\"", "\n", "\n", "self", ".", "load_specific_class", "=", "load_specific_class", "\n", "self", ".", "superclass", "=", "superclass", "\n", "\n", "self", ".", "old_modules", "=", "set", "(", "sys", ".", "modules", ")", "\n", "self", ".", "class_attribute", "=", "self", ".", "get_class", "(", "model_path", ")", "\n", "\n", "self", ".", "old_path", "=", "copy", ".", "deepcopy", "(", "sys", ".", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.unimport": [[170, 186], ["set", "module_name.startswith"], "methods", ["None"], ["", "def", "unimport", "(", "self", ")", ":", "\n", "        ", "\"\"\" Cuts off all dependencies loaded together with the module from\n        the module graph.\n\n        Attention: Might cause problems with garbage collection.\n\n        \"\"\"", "\n", "\n", "# Make sure that modules with same names do not produce conflicts", "\n", "loaded_modules", "=", "set", "(", "sys", ".", "modules", ")", "-", "self", ".", "old_modules", "\n", "for", "module_name", "in", "loaded_modules", ":", "\n", "            ", "if", "module_name", ".", "startswith", "(", "'torch'", ")", ":", "\n", "                ", "continue", "\n", "", "del", "sys", ".", "modules", "[", "module_name", "]", "\n", "\n", "", "sys", ".", "path", "=", "self", ".", "old_path", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.instantiate": [[187, 202], ["modelimporter.ModelImporter.class_attribute"], "methods", ["None"], ["", "def", "instantiate", "(", "self", ",", "model_kwargs", "=", "None", ")", ":", "\n", "        ", "\"\"\" Creates an instance of the imported model by calling the empy\n        default constructor.\n\n        Returns\n        -------\n        CCobraModel\n            CCobraModel instance.\n\n        \"\"\"", "\n", "\n", "if", "not", "model_kwargs", ":", "\n", "            ", "model_kwargs", "=", "{", "}", "\n", "\n", "", "return", "self", ".", "class_attribute", "(", "**", "model_kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.__init__": [[16, 49], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_column", ",", "comparator", ",", "predict_fn_name", ",", "adapt_fn_name", ",", "task_encoders", ",", "resp_encoders", ")", ":", "\n", "        ", "\"\"\" Initializes the Evaluation handler for a given data column and evaluation settings.\n\n        Parameters\n        ----------\n        data_column : str\n            Name of the data column to predict.\n\n        comparator : ccobra.CCobraComparator\n            Comparator to be used when comparing the prediction to the true value.\n\n        predict_fn_name : str\n            Name of the predict function within the models-\n\n        adapt_fn_name : str\n            Name of the adapt function within the models-\n\n        task_encoders : dict(str, ccobra.CCobraTaskEncoder)\n            Dictionary specifying the task encoders to be used for the domains in the dataset.\n\n        resp_encoders : dict(str, ccobra.CCobraResponseEncoder)\n            Dictionary specifying the response encoders to be used for the domains in the dataset.\n\n        \"\"\"", "\n", "self", ".", "data_column", "=", "data_column", "\n", "self", ".", "comparator", "=", "comparator", "\n", "self", ".", "predict_fn_name", "=", "predict_fn_name", "\n", "self", ".", "adapt_fn_name", "=", "adapt_fn_name", "\n", "self", ".", "task_encoders", "=", "task_encoders", "\n", "self", ".", "resp_encoders", "=", "resp_encoders", "\n", "\n", "# Prepare result dataframe", "\n", "self", ".", "result", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.predict": [[50, 137], ["copy.deepcopy", "copy.deepcopy", "getattr", "getattr.", "evaluation_handler.EvaluationHandler.comparator.compare", "evaluation_handler.EvaluationHandler.result.append", "NotImplementedError", "tuple_to_string", "tuple_to_string", "evaluation_handler.EvaluationHandler.task_encoders[].encode_task", "len", "ValueError", "evaluation_handler.EvaluationHandler.resp_encoders[].encode_response", "isinstance", "ValueError", "evaluation_handler.EvaluationHandler.resp_encoders[].encode_response", "evaluation_handler.EvaluationHandler.resp_encoders[].encode_response", "sorted", "sorted", "evaluation_handler.EvaluationHandler.resp_encoders[].encode_response", "evaluation_handler.EvaluationHandler.resp_encoders[].encode_response"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.equality.EqualityComparator.compare", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.syllogistic.task_encoder_syl.SyllogisticTaskEncoder.encode_task", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.encoders.response_encoder_identity.IdentityResponseEncoder.encode_response"], ["", "def", "predict", "(", "self", ",", "model", ",", "modelname", ",", "item", ",", "target", ",", "aux", ")", ":", "\n", "        ", "\"\"\" Queries a given model for the prediction to a given task and manages the results.\n\n        Parameters\n        ----------\n        model : ccobra.CCobraModel\n            Model to query.\n\n        modelname : str\n            Name of the model in the results.\n\n        item : ccobra.Item\n            The item that the model should base the prediction on.\n\n        target : tuple\n            True response for the given item.\n\n        aux : dict(str, object)\n            Dictionary containing auxiliary information that should be passed to the model.\n\n        \"\"\"", "\n", "item", "=", "copy", ".", "deepcopy", "(", "item", ")", "\n", "aux", "=", "copy", ".", "deepcopy", "(", "aux", ")", "\n", "\n", "# Obtain the model prediction", "\n", "pred_fn", "=", "getattr", "(", "model", ",", "self", ".", "predict_fn_name", ",", "None", ")", "\n", "if", "pred_fn", "is", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"{} has to be implemented in {}\"", ".", "format", "(", "self", ".", "predict_fn_name", ",", "modelname", ")", ")", "\n", "\n", "", "prediction", "=", "pred_fn", "(", "item", ",", "**", "aux", ")", "\n", "\n", "score", "=", "self", ".", "comparator", ".", "compare", "(", "prediction", ",", "target", ",", "item", ".", "response_type", ",", "item", ".", "choices", ")", "\n", "\n", "# Collect the evaluation result data", "\n", "res_dict", "=", "{", "\n", "'model'", ":", "modelname", ",", "\n", "'id'", ":", "item", ".", "identifier", ",", "\n", "'domain'", ":", "item", ".", "domain", ",", "\n", "'response_type'", ":", "item", ".", "response_type", ",", "\n", "'sequence'", ":", "item", ".", "sequence_number", ",", "\n", "'task'", ":", "item", ".", "task_str", ",", "\n", "'choices'", ":", "item", ".", "choices_str", ",", "\n", "'truth'", ":", "tuple_to_string", "(", "target", ")", ",", "\n", "'prediction'", ":", "tuple_to_string", "(", "prediction", ")", ",", "\n", "'score'", ":", "score", "\n", "}", "\n", "\n", "if", "self", ".", "task_encoders", ":", "\n", "            ", "domain", "=", "res_dict", "[", "'domain'", "]", "\n", "res_dict", "[", "'task_enc'", "]", "=", "self", ".", "task_encoders", "[", "domain", "]", ".", "encode_task", "(", "item", ".", "task", ")", "if", "domain", "in", "self", ".", "task_encoders", "else", "np", ".", "nan", "\n", "\n", "", "if", "self", ".", "resp_encoders", ":", "\n", "            ", "domain", "=", "res_dict", "[", "'domain'", "]", "\n", "if", "item", ".", "response_type", "==", "\"verify\"", "or", "item", ".", "response_type", "==", "\"accept\"", ":", "\n", "                ", "if", "len", "(", "item", ".", "choices", ")", "!=", "1", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Only a single choice is allowed for response types 'verify' and 'accept'\"", ")", "\n", "\n", "", "truth_enc", "=", "np", ".", "nan", "\n", "prediction_enc", "=", "np", ".", "nan", "\n", "if", "domain", "in", "self", ".", "resp_encoders", ":", "\n", "                    ", "verification_target", "=", "item", ".", "choices", "[", "0", "]", "\n", "verification_enc", "=", "self", ".", "resp_encoders", "[", "domain", "]", ".", "encode_response", "(", "verification_target", ",", "item", ".", "task", ")", "\n", "\n", "prediction_enc", "=", "\"{};{}\"", ".", "format", "(", "verification_enc", ",", "prediction", ")", "\n", "truth_enc", "=", "\"{};{}\"", ".", "format", "(", "verification_enc", ",", "target", ")", "\n", "\n", "", "res_dict", "[", "'truth_enc_{}'", ".", "format", "(", "self", ".", "data_column", ")", "]", "=", "truth_enc", "\n", "res_dict", "[", "'prediction_enc_{}'", ".", "format", "(", "self", ".", "data_column", ")", "]", "=", "prediction_enc", "\n", "", "elif", "item", ".", "response_type", "==", "\"multiple-choice\"", ":", "\n", "                ", "if", "not", "isinstance", "(", "prediction", ",", "list", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\"A list of responses is required for multiple-choice predictions, but '{}' predicted '{}'\"", ".", "format", "(", "modelname", ",", "prediction", ")", ")", "\n", "\n", "", "pred_encs", "=", "np", ".", "nan", "\n", "truth_encs", "=", "np", ".", "nan", "\n", "if", "domain", "in", "self", ".", "resp_encoders", ":", "\n", "                    ", "pred_encs", "=", "\"|\"", ".", "join", "(", "sorted", "(", "[", "self", ".", "resp_encoders", "[", "domain", "]", ".", "encode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "prediction", "]", ")", ")", "\n", "truth_encs", "=", "\"|\"", ".", "join", "(", "sorted", "(", "[", "self", ".", "resp_encoders", "[", "domain", "]", ".", "encode_response", "(", "x", ",", "item", ".", "task", ")", "for", "x", "in", "target", "]", ")", ")", "\n", "", "res_dict", "[", "'prediction_enc_{}'", ".", "format", "(", "self", ".", "data_column", ")", "]", "=", "pred_encs", "\n", "res_dict", "[", "'truth_enc_{}'", ".", "format", "(", "self", ".", "data_column", ")", "]", "=", "truth_encs", "\n", "\n", "", "else", ":", "\n", "                ", "truth_enc", "=", "self", ".", "resp_encoders", "[", "domain", "]", ".", "encode_response", "(", "target", ",", "item", ".", "task", ")", "if", "domain", "in", "self", ".", "resp_encoders", "else", "np", ".", "nan", "\n", "prediction_enc", "=", "self", ".", "resp_encoders", "[", "domain", "]", ".", "encode_response", "(", "prediction", ",", "item", ".", "task", ")", "if", "domain", "in", "self", ".", "resp_encoders", "else", "np", ".", "nan", "\n", "res_dict", "[", "'truth_enc_{}'", ".", "format", "(", "self", ".", "data_column", ")", "]", "=", "truth_enc", "\n", "res_dict", "[", "'prediction_enc_{}'", ".", "format", "(", "self", ".", "data_column", ")", "]", "=", "prediction_enc", "\n", "\n", "", "", "self", ".", "result", ".", "append", "(", "res_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.adapt": [[138, 166], ["copy.deepcopy", "copy.deepcopy", "getattr", "getattr.", "copy.deepcopy.items"], "methods", ["None"], ["", "def", "adapt", "(", "self", ",", "model", ",", "item", ",", "full", ")", ":", "\n", "        ", "\"\"\" Allows the given model to adapt to the true response to a given task.\n\n        Parameters\n        ----------\n        model : ccobra.CCobraModel\n            Model to query.\n\n        item : ccobra.Item\n            The item that the model should base the prediction on.\n\n        full : dict(str, object)\n            Dictionary containing the true response and the auxiliary information.\n\n        \"\"\"", "\n", "if", "self", ".", "adapt_fn_name", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "item", "=", "copy", ".", "deepcopy", "(", "item", ")", "\n", "full", "=", "copy", ".", "deepcopy", "(", "full", ")", "\n", "\n", "target", "=", "full", "[", "self", ".", "data_column", "]", "\n", "aux", "=", "{", "x", ":", "y", "for", "x", ",", "y", "in", "full", ".", "items", "(", ")", "if", "x", "!=", "self", ".", "data_column", "}", "\n", "adapt_fn", "=", "getattr", "(", "model", ",", "self", ".", "adapt_fn_name", ",", "None", ")", "\n", "if", "adapt_fn", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "adapt_fn", "(", "item", ",", "target", ",", "**", "aux", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.get_result_df": [[167, 177], ["pandas.DataFrame"], "methods", ["None"], ["", "def", "get_result_df", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the results for the respective evaluation setting.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame containing the results for the evaluation setting.\n\n        \"\"\"", "\n", "return", "pd", ".", "DataFrame", "(", "self", ".", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.__repr__": [[178, 188], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "'EvaluationHandler(data_column={}, comparator={}, predict_fn_name={}, adapt_fn_name={}, task_encoders={}, resp_encoders={})'", ".", "format", "(", "\n", "self", ".", "data_column", ",", "\n", "self", ".", "comparator", ",", "\n", "self", ".", "predict_fn_name", ",", "\n", "self", ".", "adapt_fn_name", ",", "\n", "self", ".", "task_encoders", ",", "\n", "self", ".", "resp_encoders", "\n", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.ModelInfo.__init__": [[204, 241], ["isinstance", "benchmark.fix_model_path", "benchmark.fix_model_path", "model_info.get", "model_info.get", "model_info.get"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_model_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_model_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get"], ["def", "__init__", "(", "self", ",", "model_info", ",", "base_path", ",", "load_specific_class", "=", "None", ")", ":", "\n", "        ", "\"\"\" Model initialization.\n\n        Parameters\n        ----------\n        model_info : object\n            Benchmark information about the model. Can either be string or dictionary.\n\n        base_path : str\n            Base path for handling relative path specifications.\n\n        load_specific_class : str, optional\n            Specific class name to load. Is used whenever multiple alternative CCOBRA model classes\n            are specified within the model file.\n\n        \"\"\"", "\n", "\n", "#: Model filepath", "\n", "self", ".", "path", "=", "None", "\n", "\n", "#: String for overriding model name with", "\n", "self", ".", "override_name", "=", "None", "\n", "\n", "#: Class name for dynamic loading. Is used whenever multiple alternative CCOBRA model", "\n", "#: classes are specified within the model file.", "\n", "self", ".", "load_specific_class", "=", "load_specific_class", "\n", "\n", "#: Keyword arguments for the dynamic model instantiation", "\n", "self", ".", "args", "=", "{", "}", "\n", "\n", "if", "isinstance", "(", "model_info", ",", "str", ")", ":", "\n", "            ", "self", ".", "path", "=", "fix_model_path", "(", "model_info", ",", "base_path", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "path", "=", "fix_model_path", "(", "model_info", "[", "'filename'", "]", ",", "base_path", ")", "\n", "self", ".", "override_name", "=", "model_info", ".", "get", "(", "'override_name'", ",", "self", ".", "override_name", ")", "\n", "self", ".", "args", "=", "model_info", ".", "get", "(", "'args'", ",", "self", ".", "args", ")", "\n", "self", ".", "load_specific_class", "=", "model_info", ".", "get", "(", "'classname'", ",", "self", ".", "load_specific_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.ModelInfo.__repr__": [[242, 253], ["str"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Generates a string representation for the model info container.\n\n        Returns\n        -------\n        str\n            ModelInfo string representation.\n\n        \"\"\"", "\n", "\n", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.ModelInfo.__str__": [[254, 266], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Generates a string representation for the model info container.\n\n        Returns\n        -------\n        str\n            ModelInfo string representation.\n\n        \"\"\"", "\n", "\n", "return", "'path={}, override_name={}, load_specific_class={}, args={}'", ".", "format", "(", "\n", "self", ".", "path", ",", "self", ".", "override_name", ",", "self", ".", "load_specific_class", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.__init__": [[272, 324], ["logger.debug", "logger.debug", "os.path.dirname", "logger.debug", "benchmark.Benchmark.parse_type", "benchmark.Benchmark.parse_auxiliary_evaluations", "benchmark.Benchmark.parse_models", "benchmark.Benchmark.parse_data", "open", "json.load", "logger.debug", "os.path.abspath", "benchmark.Benchmark.json_content[].append", "logger.debug", "os.path.abspath", "ValueError"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_type", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_auxiliary_evaluations", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_models", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data"], ["def", "__init__", "(", "self", ",", "json_path", ",", "argmodel", "=", "None", ",", "cached", "=", "False", ")", ":", "\n", "        ", "\"\"\" Initializes the benchmark instance by reading the JSON benchmark specification file\n        content.\n\n        Parameters\n        ----------\n        json_path : str\n            Path to the JSON benchmark specification file.\n\n        argmodel : (str, str), optional\n            Tuple containing the path to a specific model to load and the classname information.\n\n        cached : bool, optional\n            Flag to indicate whether the benchmark is cached or not. If true, the benchmark models\n            are ignored.\n\n        \"\"\"", "\n", "\n", "logger", ".", "debug", "(", "'Opening benchmark: \"%s\"'", ",", "json_path", ")", "\n", "\n", "# Load raw benchmark file content", "\n", "self", ".", "json_content", "=", "None", "\n", "with", "open", "(", "json_path", ")", "as", "json_file", ":", "\n", "            ", "self", ".", "json_content", "=", "json", ".", "load", "(", "json_file", ")", "\n", "", "logger", ".", "debug", "(", "'JSON content:\\n%s'", ",", "self", ".", "json_content", ")", "\n", "\n", "# Remove models in case of a cached run", "\n", "if", "cached", ":", "\n", "            ", "self", ".", "json_content", "[", "'models'", "]", "=", "[", "]", "\n", "logger", ".", "debug", "(", "'Cached run. Removed models from benchmark'", ")", "\n", "\n", "# Inject model added via arguments", "\n", "", "if", "argmodel", "!=", "(", "None", ",", "None", ")", ":", "\n", "            ", "argmodel_path", "=", "os", ".", "path", ".", "abspath", "(", "argmodel", "[", "0", "]", ")", "\n", "self", ".", "json_content", "[", "'models'", "]", ".", "append", "(", "\n", "{", "\"filename\"", ":", "argmodel_path", ",", "\"classname\"", ":", "argmodel", "[", "1", "]", "}", ")", "\n", "logger", ".", "debug", "(", "'Injected model supplied via arguments'", ")", "\n", "\n", "# Determine JSON path to fix relative path information", "\n", "", "self", ".", "base_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "json_path", ")", ")", "\n", "logger", ".", "debug", "(", "'base_path: %s'", ",", "self", ".", "base_path", ")", "\n", "\n", "# Parse the JSON content", "\n", "self", ".", "parse_type", "(", ")", "\n", "self", ".", "parse_auxiliary_evaluations", "(", ")", "\n", "self", ".", "parse_models", "(", ")", "\n", "self", ".", "parse_data", "(", ")", "\n", "\n", "# Verify conditions for coverage", "\n", "if", "self", ".", "type", "==", "'coverage'", ":", "\n", "            ", "if", "self", ".", "data_pre_train_person", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'data.pre_train_person is not allowed in coverage evaluation.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_type": [[325, 335], ["benchmark.Benchmark.json_content.get", "logger.debug", "ValueError"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get"], ["", "", "", "def", "parse_type", "(", "self", ")", ":", "\n", "        ", "\"\"\" Parses the benchmark type (prediction, adaption, coverage).\n\n        \"\"\"", "\n", "\n", "# Set type and validate", "\n", "self", ".", "type", "=", "self", ".", "json_content", ".", "get", "(", "'type'", ",", "'adaption'", ")", "\n", "if", "self", ".", "type", "not", "in", "[", "'prediction'", ",", "'adaption'", ",", "'coverage'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported evaluation type: {}'", ".", "format", "(", "self", ".", "type", ")", ")", "\n", "", "logger", ".", "debug", "(", "'Evaluation type: %s'", ",", "self", ".", "type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_comparator": [[336, 373], ["logger.debug", "logger.debug", "benchmark.fix_rel_path", "logger.debug", "benchmark.prepare_comparator", "comparators.EqualityComparator", "os.path.isfile", "ValueError", "comparators.NVCComparator", "comparators.AbsDiffComparator", "comparators.SquaredDiffComparator"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_rel_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.prepare_comparator"], ["", "def", "parse_comparator", "(", "self", ",", "comparator_str", ")", ":", "\n", "        ", "\"\"\" Parses the comparator information.\n\n        Parameters\n        ----------\n        comparator_str : str\n            Either is one of the library-defined comparator labels (equality, nvc, absdiff) or\n            a path to a comparator implementation to load dynamically.\n\n        Returns\n        -------\n        ccobra.CCobraComparator\n            Comparator object.\n\n        \"\"\"", "\n", "\n", "# Create the comparator instance", "\n", "logger", ".", "debug", "(", "'Comparator string: %s'", ",", "comparator_str", ")", "\n", "if", "comparator_str", "==", "'equality'", ":", "\n", "            ", "return", "comparators", ".", "EqualityComparator", "(", ")", "\n", "", "elif", "comparator_str", "==", "'nvc'", ":", "\n", "            ", "return", "comparators", ".", "NVCComparator", "(", ")", "\n", "", "elif", "comparator_str", "==", "'absdiff'", ":", "\n", "            ", "return", "comparators", ".", "AbsDiffComparator", "(", ")", "\n", "", "elif", "comparator_str", "==", "'squareddiff'", ":", "\n", "            ", "return", "comparators", ".", "SquaredDiffComparator", "(", ")", "\n", "\n", "", "logger", ".", "debug", "(", "'Nonlabel comparator string: %s'", ",", "comparator_str", ")", "\n", "\n", "# Normalize path string", "\n", "comparator_str", "=", "fix_rel_path", "(", "comparator_str", ",", "self", ".", "base_path", ")", "\n", "logger", ".", "debug", "(", "'Absolute comparator path: %s'", ",", "comparator_str", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "comparator_str", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Comparator string is not a file: {}'", ".", "format", "(", "comparator_str", ")", ")", "\n", "\n", "", "return", "prepare_comparator", "(", "comparator_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_auxiliary_evaluations": [[374, 429], ["benchmark.Benchmark.json_content.get", "benchmark.Benchmark.json_content.get", "benchmark.Benchmark.json_content.get", "benchmark.Benchmark.insert", "benchmark.Benchmark.json_content.get", "evaluation_handler.EvaluationHandler", "evaluation_handlers.append", "evaluation_targets.append", "logger.debug", "benchmark.prepare_task_encoders", "benchmark.prepare_resp_encoders", "benchmark.Benchmark.parse_comparator", "eva.get", "eva.get"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.prepare_task_encoders", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.prepare_resp_encoders", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_comparator", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get"], ["", "def", "parse_auxiliary_evaluations", "(", "self", ")", ":", "\n", "        ", "\"\"\" Parses auxiliary evaluation configurations from the benchmark content.\n\n        \"\"\"", "\n", "\n", "evaluations", "=", "self", ".", "json_content", ".", "get", "(", "'aux_evaluations'", ",", "[", "]", ")", "\n", "\n", "task_encoders", "=", "self", ".", "json_content", ".", "get", "(", "'task_encoders'", ",", "{", "}", ")", "\n", "if", "'syllogistic'", "not", "in", "task_encoders", ":", "\n", "            ", "task_encoders", "[", "'syllogistic'", "]", "=", "'%ccobra%/syllogistic/task_encoder_syl.py'", "\n", "", "if", "'propositional'", "not", "in", "task_encoders", ":", "\n", "            ", "task_encoders", "[", "'propositional'", "]", "=", "'%ccobra%/propositional/task_encoder_prop.py'", "\n", "\n", "", "resp_encoders", "=", "self", ".", "json_content", ".", "get", "(", "'response_encoders'", ",", "{", "}", ")", "\n", "if", "'syllogistic'", "not", "in", "resp_encoders", ":", "\n", "            ", "resp_encoders", "[", "'syllogistic'", "]", "=", "'%ccobra%/syllogistic/resp_encoder_syl.py'", "\n", "", "if", "'propositional'", "not", "in", "resp_encoders", ":", "\n", "            ", "resp_encoders", "[", "'propositional'", "]", "=", "'%ccobra%/propositional/resp_encoder_prop.py'", "\n", "\n", "", "response_eval", "=", "{", "\n", "'data_column'", ":", "'response'", ",", "\n", "'comparator'", ":", "self", ".", "json_content", ".", "get", "(", "'comparator'", ",", "'equality'", ")", ",", "\n", "'prediction_fn_name'", ":", "'predict'", ",", "\n", "'adapt_fn_name'", ":", "'adapt'", ",", "\n", "'task_encoders'", ":", "task_encoders", ",", "\n", "'response_encoders'", ":", "resp_encoders", "\n", "}", "\n", "evaluations", ".", "insert", "(", "0", ",", "response_eval", ")", "\n", "\n", "evaluation_handlers", "=", "[", "]", "\n", "evaluation_targets", "=", "[", "]", "\n", "for", "eva", "in", "evaluations", ":", "\n", "            ", "task_encoders", "=", "None", "\n", "if", "'task_encoders'", "in", "eva", ":", "\n", "                ", "task_encoders", "=", "prepare_task_encoders", "(", "eva", "[", "'task_encoders'", "]", ",", "self", ".", "base_path", ")", "\n", "\n", "", "resp_encoders", "=", "None", "\n", "if", "'response_encoders'", "in", "eva", ":", "\n", "                ", "resp_encoders", "=", "prepare_resp_encoders", "(", "eva", "[", "'response_encoders'", "]", ",", "self", ".", "base_path", ")", "\n", "\n", "", "eh", "=", "evaluation_handler", ".", "EvaluationHandler", "(", "\n", "data_column", "=", "eva", "[", "'data_column'", "]", ",", "\n", "comparator", "=", "self", ".", "parse_comparator", "(", "eva", ".", "get", "(", "'comparator'", ",", "'equality'", ")", ")", ",", "\n", "predict_fn_name", "=", "eva", "[", "'prediction_fn_name'", "]", ",", "\n", "adapt_fn_name", "=", "eva", ".", "get", "(", "'adapt_fn_name'", ",", "None", ")", ",", "\n", "task_encoders", "=", "task_encoders", ",", "\n", "resp_encoders", "=", "resp_encoders", "\n", ")", "\n", "evaluation_handlers", ".", "append", "(", "eh", ")", "\n", "evaluation_targets", ".", "append", "(", "eva", "[", "'data_column'", "]", ")", "\n", "\n", "logger", ".", "debug", "(", "'Added evaluation handler: %s'", ",", "eh", ")", "\n", "\n", "", "self", ".", "evaluation_handlers", "=", "evaluation_handlers", "\n", "self", ".", "evaluation_targets", "=", "evaluation_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data_path": [[430, 468], ["isinstance", "logger.debug", "benchmark.fix_rel_path", "pandas.read_csv", "logger.debug", "pandas.concat", "benchmark.Benchmark.parse_data_path"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_rel_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data_path"], ["", "def", "parse_data_path", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\" Reads in a dataset CSV file and returns it as a pandas.DataFrame object. If a list\n        of paths is supplied, the datasets are combined.\n\n        Parameters\n        ----------\n        path : str\n            Path to the data file.\n\n        Returns\n        -------\n        (str, pandas.DataFrame)\n            A tuple consisting of the filepath and the corresponding data frame. If a list of data\n            paths was provided, the resulting string represents a ;-joined representation of the\n            paths and the dataframe is the combination of the individual dataframes.\n\n        \"\"\"", "\n", "\n", "if", "not", "path", ":", "\n", "            ", "return", "None", ",", "None", "\n", "\n", "", "if", "isinstance", "(", "path", ",", "list", ")", ":", "\n", "            ", "logger", ".", "debug", "(", "'List data path encountered: %s'", ",", "path", ")", "\n", "parts", "=", "[", "self", ".", "parse_data_path", "(", "x", ")", "for", "x", "in", "path", "]", "\n", "paths", "=", "';'", ".", "join", "(", "[", "x", "[", "0", "]", "for", "x", "in", "parts", "]", ")", "\n", "\n", "# Combine the datasets", "\n", "comb_df", "=", "pd", ".", "concat", "(", "[", "df", "for", "_", ",", "df", "in", "parts", "]", ")", "\n", "return", "paths", ",", "comb_df", "\n", "\n", "", "logger", ".", "debug", "(", "'Regular data path encountered: %s'", ",", "path", ")", "\n", "\n", "# Resolve relative paths", "\n", "full_path", "=", "fix_rel_path", "(", "path", ",", "self", ".", "base_path", ")", "\n", "\n", "# Load the data and create CCOBRA container", "\n", "df", "=", "pd", ".", "read_csv", "(", "full_path", ")", "\n", "return", "full_path", ",", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data": [[469, 538], ["benchmark.Benchmark.parse_data_path", "logger.debug", "benchmark.Benchmark.parse_data_path", "logger.debug", "benchmark.Benchmark.parse_data_path", "logger.debug", "benchmark.Benchmark.parse_data_path", "logger.debug", "data_test_df[].unique", "benchmark.Benchmark.json_content.get", "logger.debug", "data.CCobraData", "ValueError", "benchmark.Benchmark.json_content.get", "benchmark.Benchmark.json_content.get", "benchmark.Benchmark.json_content.get", "data.CCobraData", "data.CCobraData", "data.CCobraData", "logger.debug", "benchmark.Benchmark.data_pre_train.prefix_identifiers", "logger.debug", "data_pre_train_df.merge", "data_pre_train_df.merge.loc[].drop", "data_pre_train_person_df[].isin", "data_pre_person_background_df[].isin", "pandas.concat", "data.CCobraData", "pandas.concat", "data.CCobraData", "data_train_only_df[].isin", "pandas.concat.drop", "pandas.concat.drop", "data_train_only_df[].isin"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_data_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.prefix_identifiers"], ["", "def", "parse_data", "(", "self", ")", ":", "\n", "        ", "\"\"\" Parses the benchmark data information. Reads in an preprocesses the datasets.\n\n        \"\"\"", "\n", "\n", "# Verify information", "\n", "if", "'data.test'", "not", "in", "self", ".", "json_content", ":", "\n", "            ", "raise", "ValueError", "(", "'Test dataset (data.test) must be supplied.'", ")", "\n", "\n", "# Parse training data fields", "\n", "", "self", ".", "data_pre_train_path", ",", "data_pre_train_df", "=", "self", ".", "parse_data_path", "(", "self", ".", "json_content", ".", "get", "(", "'data.pre_train'", ",", "''", ")", ")", "\n", "logger", ".", "debug", "(", "'data_pre_train_path: %s'", ",", "self", ".", "data_pre_train_path", ")", "\n", "self", ".", "data_pre_train_person_path", ",", "data_pre_train_person_df", "=", "self", ".", "parse_data_path", "(", "self", ".", "json_content", ".", "get", "(", "'data.pre_train_person'", ",", "''", ")", ")", "\n", "logger", ".", "debug", "(", "'data_pre_train_person_path: %s'", ",", "self", ".", "data_pre_train_person_path", ")", "\n", "self", ".", "data_pre_person_background_path", ",", "data_pre_person_background_df", "=", "self", ".", "parse_data_path", "(", "self", ".", "json_content", ".", "get", "(", "'data.pre_person_background'", ",", "''", ")", ")", "\n", "logger", ".", "debug", "(", "'data_pre_person_background_path: %s'", ",", "self", ".", "data_pre_person_background_path", ")", "\n", "\n", "# Parse test data field", "\n", "self", ".", "data_test_path", ",", "data_test_df", "=", "self", ".", "parse_data_path", "(", "self", ".", "json_content", "[", "'data.test'", "]", ")", "\n", "logger", ".", "debug", "(", "'data_test_path: %s'", ",", "self", ".", "data_test_path", ")", "\n", "\n", "# Filter person data so that only test ids are present", "\n", "test_ids", "=", "data_test_df", "[", "'id'", "]", ".", "unique", "(", ")", "\n", "if", "data_pre_train_person_df", "is", "not", "None", ":", "\n", "            ", "data_pre_train_person_df", "=", "data_pre_train_person_df", ".", "loc", "[", "\n", "data_pre_train_person_df", "[", "'id'", "]", ".", "isin", "(", "test_ids", ")", "]", "\n", "", "if", "data_pre_person_background_df", "is", "not", "None", ":", "\n", "            ", "data_pre_person_background_df", "=", "data_pre_person_background_df", ".", "loc", "[", "\n", "data_pre_person_background_df", "[", "'id'", "]", ".", "isin", "(", "test_ids", ")", "]", "\n", "\n", "# Set corresponding data", "\n", "", "self", ".", "corresponding_data", "=", "self", ".", "json_content", ".", "get", "(", "'corresponding_data'", ",", "False", ")", "\n", "logger", ".", "debug", "(", "'corresponding_data: %s'", ",", "self", ".", "corresponding_data", ")", "\n", "\n", "# Construct CCOBRA datasets", "\n", "self", ".", "data_test", "=", "CCobraData", "(", "data_test_df", ",", "target_columns", "=", "self", ".", "evaluation_targets", ")", "\n", "self", ".", "data_pre_train", "=", "CCobraData", "(", "data_pre_train_df", ",", "target_columns", "=", "self", ".", "evaluation_targets", ")", "if", "data_pre_train_df", "is", "not", "None", "else", "None", "\n", "self", ".", "data_pre_train_person", "=", "CCobraData", "(", "data_pre_train_person_df", ",", "target_columns", "=", "self", ".", "evaluation_targets", ")", "if", "data_pre_train_person_df", "is", "not", "None", "else", "None", "\n", "self", ".", "data_pre_person_background", "=", "CCobraData", "(", "data_pre_person_background_df", ",", "target_columns", "=", "self", ".", "evaluation_targets", ")", "if", "data_pre_person_background_df", "is", "not", "None", "else", "None", "\n", "\n", "# In case of non-corresponding datasets, make sure that identifiers do not overlap by", "\n", "# offsetting the training data (ensures that test identifiers remain identifiable)", "\n", "if", "self", ".", "data_pre_train", "is", "not", "None", "and", "not", "self", ".", "corresponding_data", ":", "\n", "            ", "logger", ".", "debug", "(", "'adjusting identifier offsets...'", ")", "\n", "self", ".", "data_pre_train", ".", "prefix_identifiers", "(", ")", "\n", "", "elif", "self", ".", "data_pre_train", "is", "not", "None", "and", "self", ".", "corresponding_data", ":", "\n", "            ", "logger", ".", "debug", "(", "'extracting additional person data from comparing data_pre_train with data_test...'", ")", "\n", "\n", "# Identify the columns which are present only in the training data", "\n", "merge", "=", "data_pre_train_df", ".", "merge", "(", "data_test_df", ",", "how", "=", "'left'", ",", "indicator", "=", "True", ")", "\n", "data_train_only_df", "=", "merge", ".", "loc", "[", "merge", "[", "'_merge'", "]", "==", "'left_only'", "]", ".", "drop", "(", "columns", "=", "[", "'_merge'", "]", ")", "\n", "\n", "# Append domain related data to pre_train_person", "\n", "domain_related_df", "=", "data_train_only_df", ".", "loc", "[", "data_train_only_df", "[", "'domain'", "]", ".", "isin", "(", "self", ".", "data_test", ".", "domains", ")", "]", "\n", "\n", "if", "data_pre_train_person_df", "is", "not", "None", ":", "\n", "                ", "domain_related_df", "=", "pd", ".", "concat", "(", "domain_related_df", ",", "data_pre_train_person_df", ")", "\n", "\n", "", "if", "not", "domain_related_df", ".", "empty", ":", "\n", "                ", "self", ".", "data_pre_train_person", "=", "CCobraData", "(", "domain_related_df", ".", "drop", "(", "columns", "=", "'_unique_id'", ")", ",", "target_columns", "=", "self", ".", "evaluation_targets", ")", "\n", "\n", "# Append domain unrelated data to pre_person_background", "\n", "", "domain_unrelated_df", "=", "data_train_only_df", ".", "loc", "[", "~", "data_train_only_df", "[", "'domain'", "]", ".", "isin", "(", "self", ".", "data_test", ".", "domains", ")", "]", "\n", "\n", "if", "data_pre_person_background_df", "is", "not", "None", ":", "\n", "                ", "domain_unrelated_df", "=", "pd", ".", "concat", "(", "domain_unrelated_df", ",", "data_pre_person_background_df", ")", "\n", "\n", "", "if", "not", "domain_unrelated_df", ".", "empty", ":", "\n", "                ", "self", ".", "data_pre_person_background", "=", "CCobraData", "(", "domain_unrelated_df", ".", "drop", "(", "columns", "=", "'_unique_id'", ")", ",", "target_columns", "=", "self", ".", "evaluation_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.parse_models": [[539, 547], ["logger.debug", "benchmark.ModelInfo", "str"], "methods", ["None"], ["", "", "", "def", "parse_models", "(", "self", ")", ":", "\n", "        ", "\"\"\" Parses the benchmark model information.\n\n        \"\"\"", "\n", "\n", "# Prepare the models for loading", "\n", "self", ".", "models", "=", "[", "ModelInfo", "(", "x", ",", "self", ".", "base_path", ")", "for", "x", "in", "self", ".", "json_content", "[", "'models'", "]", "]", "\n", "logger", ".", "debug", "(", "'models:\\n%s'", ",", "'\\n'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "self", ".", "models", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.Benchmark.__str__": [[548, 570], ["s.append", "s.append", "s.append", "s.append", "s.append", "s.append", "s.append", "s.append", "s.append", "enumerate", "s.append", "s.append", "s.append", "s.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Generates a string representation of the benchmark information.\n\n        \"\"\"", "\n", "\n", "s", "=", "[", "]", "\n", "s", ".", "append", "(", "'Benchmark:'", ")", "\n", "s", ".", "append", "(", "'   type: {}'", ".", "format", "(", "self", ".", "type", ")", ")", "\n", "s", ".", "append", "(", "'   data paths:'", ")", "\n", "s", ".", "append", "(", "'      pre_train: {}'", ".", "format", "(", "self", ".", "data_pre_train_path", ")", ")", "\n", "s", ".", "append", "(", "'      pre_train_person: {}'", ".", "format", "(", "self", ".", "data_pre_train_person_path", ")", ")", "\n", "s", ".", "append", "(", "'      pre_person_background: {}'", ".", "format", "(", "self", ".", "data_pre_person_background_path", ")", ")", "\n", "s", ".", "append", "(", "'      test : {}'", ".", "format", "(", "self", ".", "data_test_path", ")", ")", "\n", "s", ".", "append", "(", "'   corresponding_data: {}'", ".", "format", "(", "self", ".", "corresponding_data", ")", ")", "\n", "s", ".", "append", "(", "'   models:'", ")", "\n", "for", "idx", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "s", ".", "append", "(", "'      ({}) {}'", ".", "format", "(", "idx", "+", "1", ",", "model", ")", ")", "\n", "", "s", ".", "append", "(", "'   evaluation handlers:'", ")", "\n", "for", "eh", "in", "self", ".", "evaluation_handlers", ":", "\n", "            ", "s", ".", "append", "(", "'      {}'", ".", "format", "(", "str", "(", "eh", ")", ")", ")", "\n", "", "s", ".", "append", "(", "'   evaluation targets: {}'", ".", "format", "(", "self", ".", "evaluation_targets", ")", ")", "\n", "return", "'\\n'", ".", "join", "(", "s", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_rel_path": [[24, 51], ["path.replace.replace", "os.path.normpath", "os.path.split", "os.path.isabs", "os.path.split"], "function", ["None"], ["def", "fix_rel_path", "(", "path", ",", "base_path", ")", ":", "\n", "    ", "\"\"\" Fixes relative paths by prepending the benchmark filepath.\n\n    Parameters\n    ----------\n    path : str\n        Path to fix.\n\n    base_path : str\n        Basepath used to fix relative paths with. Is prepended to the relative path.\n\n    Returns\n    -------\n    str\n        Fixed absolute path.\n\n    \"\"\"", "\n", "\n", "# Replace internal ccobra path", "\n", "if", "'%ccobra%'", "in", "path", ":", "\n", "        ", "package_path", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "split", "(", "__file__", ")", "[", "0", "]", ")", "[", "0", "]", "\n", "path", "=", "path", ".", "replace", "(", "'%ccobra%'", ",", "package_path", ")", "\n", "\n", "", "if", "path", "and", "not", "os", ".", "path", ".", "isabs", "(", "path", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "normpath", "(", "base_path", "+", "os", ".", "sep", "+", "path", ")", "\n", "\n", "", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_model_path": [[52, 100], ["os.listdir", "ValueError", "benchmark.fix_rel_path", "os.path.isfile", "os.path.join", "len", "os.path.isfile", "python_files.append", "os.path.join", "os.path.isdir", "sub_directories.append", "os.listdir", "os.path.isfile", "os.path.join"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_rel_path"], ["", "def", "fix_model_path", "(", "path", ",", "base_path", "=", "None", ")", ":", "\n", "    ", "\"\"\" Fixes the model path by checking if the path directly refers to a python file. Otherwise\n    searches for a subdirectory containing possible modules.\n\n    Parameters\n    ----------\n    path : str\n        Model path to fix.\n\n    base_path : str, optional\n        Base path to fix the model path with if it is relative.\n\n    Returns\n    -------\n    str\n        Path pointing to the file assumed to contain the model.\n\n    \"\"\"", "\n", "\n", "abs_path", "=", "path", "\n", "if", "base_path", ":", "\n", "        ", "abs_path", "=", "fix_rel_path", "(", "path", ",", "base_path", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "abs_path", ")", "and", "abs_path", "[", "-", "2", ":", "]", "==", "\"py\"", ":", "\n", "        ", "return", "abs_path", "\n", "\n", "", "python_files", "=", "[", "]", "\n", "sub_directories", "=", "[", "]", "\n", "for", "f_name", "in", "os", ".", "listdir", "(", "abs_path", ")", ":", "\n", "        ", "f_path", "=", "os", ".", "path", ".", "join", "(", "abs_path", ",", "f_name", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "f_path", ")", "and", "f_name", "[", "-", "2", ":", "]", "==", "\"py\"", ":", "\n", "            ", "python_files", ".", "append", "(", "f_path", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "f_path", ")", "and", "f_name", "[", "0", "]", "!=", "\".\"", "and", "f_name", "[", ":", "2", "]", "!=", "\"__\"", ":", "\n", "            ", "sub_directories", ".", "append", "(", "f_path", ")", "\n", "\n", "", "", "if", "python_files", ":", "\n", "        ", "return", "abs_path", "\n", "\n", "", "if", "len", "(", "sub_directories", ")", "==", "1", ":", "\n", "        ", "python_files", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "sub_directories", "[", "0", "]", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "\n", "sub_directories", "[", "0", "]", ")", "if", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "sub_directories", "[", "0", "]", ",", "f", ")", ")", "and", "f", "[", "-", "2", ":", "]", "==", "\"py\"", "]", "\n", "if", "python_files", ":", "\n", "            ", "return", "sub_directories", "[", "0", "]", "\n", "\n", "", "", "raise", "ValueError", "(", "\"Could not identify model to load for '{}'\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.prepare_task_encoders": [[101, 135], ["encoder_paths.items", "benchmark.fix_rel_path", "contextmanager.dir_context", "modelimporter.ModelImporter", "modelimporter.ModelImporter.instantiate", "ValueError"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_rel_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.contextmanager.dir_context", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.instantiate"], ["", "def", "prepare_task_encoders", "(", "encoder_paths", ",", "base_path", ")", ":", "\n", "    ", "\"\"\" Processes the task encoder information from the benchmark specification. Handles\n    relative paths or path placeholders (e.g., '%ccobra%' mapping to the module directory of\n    the local CCOBRA installation).\n\n    Parameters\n    ----------\n    encoder_paths : dict(str, str)\n        Dictionary mapping from domains to task encoders with absolute paths.\n\n    Returns\n    -------\n    dict(str, str)\n        Dictionary mapping from domains to paths containing task encoders.\n\n    \"\"\"", "\n", "\n", "encs", "=", "{", "}", "\n", "for", "domain", ",", "encoder_path", "in", "encoder_paths", ".", "items", "(", ")", ":", "\n", "# Normalize encoder path", "\n", "        ", "encoder_path", "=", "fix_rel_path", "(", "encoder_path", ",", "base_path", ")", "\n", "\n", "# To instantiate the encoder we need to change to its context (i.e., set the PATH variable", "\n", "# accordingly).", "\n", "enc", "=", "None", "\n", "with", "contextmanager", ".", "dir_context", "(", "encoder_path", ")", ":", "\n", "            ", "imp", "=", "modelimporter", ".", "ModelImporter", "(", "encoder_path", ",", "superclass", "=", "CCobraTaskEncoder", ")", "\n", "enc", "=", "imp", ".", "instantiate", "(", ")", "\n", "\n", "", "if", "not", "enc", ":", "\n", "            ", "raise", "ValueError", "(", "'Failed to instantiate encoder class.'", ")", "\n", "", "encs", "[", "domain", "]", "=", "enc", "\n", "\n", "", "return", "encs", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.prepare_resp_encoders": [[136, 170], ["encoder_paths.items", "benchmark.fix_rel_path", "contextmanager.dir_context", "modelimporter.ModelImporter", "modelimporter.ModelImporter.instantiate", "ValueError"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.fix_rel_path", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.contextmanager.dir_context", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.instantiate"], ["", "def", "prepare_resp_encoders", "(", "encoder_paths", ",", "base_path", ")", ":", "\n", "    ", "\"\"\" Processes the response encoder information from the benchmark specification. Handles\n    relative paths or path placeholders (e.g., '%ccobra%' mapping to the module directory of\n    the local CCOBRA installation).\n\n    Parameters\n    ----------\n    encoder_paths : dict(str, str)\n        Dictionary mapping from domains to response encoders with absolute paths.\n\n    Returns\n    -------\n    dict(str, str)\n        Dictionary mapping from domains to paths containing response encoders.\n\n    \"\"\"", "\n", "\n", "encs", "=", "{", "}", "\n", "for", "domain", ",", "encoder_path", "in", "encoder_paths", ".", "items", "(", ")", ":", "\n", "# Normalize encoder path", "\n", "        ", "encoder_path", "=", "fix_rel_path", "(", "encoder_path", ",", "base_path", ")", "\n", "\n", "# To instantiate the encoder we need to change to its context (i.e., set the PATH variable", "\n", "# accordingly).", "\n", "enc", "=", "None", "\n", "with", "contextmanager", ".", "dir_context", "(", "encoder_path", ")", ":", "\n", "            ", "imp", "=", "modelimporter", ".", "ModelImporter", "(", "encoder_path", ",", "superclass", "=", "CCobraResponseEncoder", ")", "\n", "enc", "=", "imp", ".", "instantiate", "(", ")", "\n", "\n", "", "if", "not", "enc", ":", "\n", "            ", "raise", "ValueError", "(", "'Failed to instantiate encoder class.'", ")", "\n", "", "encs", "[", "domain", "]", "=", "enc", "\n", "\n", "", "return", "encs", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.benchmark.prepare_comparator": [[171, 197], ["contextmanager.dir_context", "modelimporter.ModelImporter", "modelimporter.ModelImporter.instantiate", "ValueError"], "function", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.contextmanager.dir_context", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.instantiate"], ["", "def", "prepare_comparator", "(", "comparator_path", ")", ":", "\n", "    ", "\"\"\" Processes the comparator path from the benchmark specification. Imports the object\n    dynamically.\n\n    Parameters\n    ----------\n    comparator_path : str\n        Path to the python script file containing the comparator definition.\n\n    Returns\n    -------\n    ccobra.CCobraComparator\n        Comparator object.\n\n    \"\"\"", "\n", "\n", "comp", "=", "None", "\n", "\n", "with", "contextmanager", ".", "dir_context", "(", "comparator_path", ")", ":", "\n", "        ", "imp", "=", "modelimporter", ".", "ModelImporter", "(", "comparator_path", ",", "superclass", "=", "CCobraComparator", ")", "\n", "comp", "=", "imp", ".", "instantiate", "(", ")", "\n", "\n", "", "if", "not", "comp", ":", "\n", "        ", "raise", "ValueError", "(", "'Failed to instantiate comparator class.'", ")", "\n", "\n", "", "return", "comp", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluator.Evaluator.__init__": [[26, 83], ["logger.info", "benchmark.data_test.to_eval_dict", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "benchmark.data_pre_train.to_eval_dict", "logger.debug", "benchmark.data_pre_train_person.to_eval_dict", "logger.debug", "benchmark.data_pre_person_background.to_eval_dict"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.to_eval_dict", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.to_eval_dict", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.to_eval_dict", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.to_eval_dict"], ["def", "__init__", "(", "self", ",", "benchmark", ",", "is_silent", "=", "False", ",", "cache_df", "=", "None", ")", ":", "\n", "        ", "\"\"\" Initializes the evaluator object by preparing the data representations and precomputing\n        the required training and adaption steps.\n\n        Parameters\n        ----------\n        benchmarks : ccobra.Benchmark\n            Benchmark container.\n\n        is_silent : bool, optional\n            Flag indicating that output is supposed to be suppressed.\n\n        cache_df : pandas.DataFrame, option\n            Cache result dataframe.\n\n        \"\"\"", "\n", "\n", "logger", ".", "info", "(", "'Setting up evaluator...'", ")", "\n", "\n", "# Store the information", "\n", "self", ".", "benchmark", "=", "benchmark", "\n", "self", ".", "is_silent", "=", "is_silent", "\n", "self", ".", "cache_df", "=", "cache_df", "\n", "\n", "# Extract the dataset information", "\n", "self", ".", "dict_test", "=", "benchmark", ".", "data_test", ".", "to_eval_dict", "(", ")", "\n", "\n", "self", ".", "dict_pre_train", "=", "None", "\n", "self", ".", "dict_pre_train_person", "=", "None", "\n", "self", ".", "dict_pre_person_background", "=", "None", "\n", "\n", "if", "benchmark", ".", "data_pre_train", "is", "not", "None", ":", "\n", "            ", "logger", ".", "debug", "(", "'Supplied training data to evaluation.'", ")", "\n", "self", ".", "dict_pre_train", "=", "benchmark", ".", "data_pre_train", ".", "to_eval_dict", "(", ")", "\n", "", "if", "benchmark", ".", "data_pre_train_person", "is", "not", "None", ":", "\n", "            ", "logger", ".", "debug", "(", "'Supplied person training data to evaluation.'", ")", "\n", "self", ".", "dict_pre_train_person", "=", "benchmark", ".", "data_pre_train_person", ".", "to_eval_dict", "(", ")", "\n", "", "if", "benchmark", ".", "data_pre_person_background", "is", "not", "None", ":", "\n", "            ", "logger", ".", "debug", "(", "'Supplied person background data to evaluation.'", ")", "\n", "self", ".", "dict_pre_person_background", "=", "benchmark", ".", "data_pre_person_background", ".", "to_eval_dict", "(", ")", "\n", "\n", "", "if", "benchmark", ".", "type", "==", "'coverage'", ":", "\n", "            ", "self", ".", "dict_pre_train_person", "=", "self", ".", "dict_test", "\n", "\n", "# Extract the functionality to apply", "\n", "", "self", ".", "do_adapt", "=", "(", "benchmark", ".", "type", "==", "'adaption'", ")", "\n", "self", ".", "do_pre_train_global", "=", "(", "self", ".", "dict_pre_train", "is", "not", "None", ")", "and", "not", "benchmark", ".", "corresponding_data", "\n", "self", ".", "do_pre_train_leaveoneout", "=", "(", "self", ".", "dict_pre_train", "is", "not", "None", ")", "and", "benchmark", ".", "corresponding_data", "\n", "self", ".", "do_pre_train_person", "=", "(", "self", ".", "dict_pre_train_person", "is", "not", "None", ")", "\n", "self", ".", "do_pre_person_background", "=", "(", "self", ".", "dict_pre_person_background", "is", "not", "None", ")", "\n", "\n", "logger", ".", "debug", "(", "'Evaluation ready:'", ")", "\n", "logger", ".", "debug", "(", "'   do_adapt: %s'", ",", "self", ".", "do_adapt", ")", "\n", "logger", ".", "debug", "(", "'   do_pre_train_global: %s'", ",", "self", ".", "do_pre_train_global", ")", "\n", "logger", ".", "debug", "(", "'   do_pre_train_leaveoneout: %s'", ",", "self", ".", "do_pre_train_leaveoneout", ")", "\n", "logger", ".", "debug", "(", "'   do_pre_train_person: %s'", ",", "self", ".", "do_pre_train_person", ")", "\n", "logger", ".", "debug", "(", "'   do_pre_person_background: %s'", ",", "self", ".", "do_pre_person_background", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluator.Evaluator.evaluate": [[84, 260], ["logger.info", "enumerate", "res_df.merge.merge.rename", "logger.debug", "set", "set", "logger.debug", "logger.info", "logger.debug", "logger.debug", "logger.debug", "sorted", "sorted", "pandas.concat", "evaluator.Evaluator.cache_df[].unique", "len", "print", "contextmanager.dir_context", "modelimporter.ModelImporter", "modelimporter.ModelImporter.instantiate", "modelimporter.ModelImporter.instantiate.setup_environment", "evaluator.Evaluator.check_model_applicability", "model_name_cache.add", "evaluator.Evaluator.dict_test.items", "modelimporter.ModelImporter.unimport", "logger.debug", "enc.get_result_df", "logger.debug", "res_df.merge.merge.merge", "list", "list", "logger.warning", "logger.debug", "modelimporter.ModelImporter.instantiate.pre_train", "time.time", "copy.deepcopy", "copy.deepcopy.start_participant", "time.time", "enumerate", "copy.deepcopy.end_participant", "logger.debug", "logger.debug", "len", "enc.get_result_df", "list", "logger.debug", "copy.deepcopy.pre_train", "logger.debug", "evaluator.Evaluator.dict_pre_person_background.get", "copy.deepcopy.pre_person_background", "logger.debug", "evaluator.Evaluator.dict_pre_train_person.get", "copy.deepcopy.pre_train_person", "time.time", "logger.debug", "logger.debug", "len", "evaluator.Evaluator.dict_pre_train.values", "len", "eh.predict", "evaluator.Evaluator.dict_pre_train.items", "eh.adapt", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.contextmanager.dir_context", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.instantiate", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.setup_environment", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluator.Evaluator.check_model_applicability", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.modelimporter.ModelImporter.unimport", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.get_result_df", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.pre_train", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.start_participant", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.end_participant", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.get_result_df", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.pre_train", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.pre_person_background", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.data.CCobraData.get", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.model.CCobraModel.pre_train_person", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.predict", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluation_handler.EvaluationHandler.adapt"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\" Core evaluation routine.\n\n        Returns\n        -------\n        pd.DataFrame\n            Pandas dataframe containing the evaluation results.\n\n        \"\"\"", "\n", "\n", "logger", ".", "info", "(", "'Starting evaluation routine...'", ")", "\n", "\n", "model_logging_results", "=", "{", "}", "\n", "model_name_cache", "=", "set", "(", ")", "if", "self", ".", "cache_df", "is", "None", "else", "set", "(", "self", ".", "cache_df", "[", "'model'", "]", ".", "unique", "(", ")", ")", "\n", "\n", "# Activate model context", "\n", "for", "model_idx", ",", "modelinfo", "in", "enumerate", "(", "self", ".", "benchmark", ".", "models", ")", ":", "\n", "# Print the progress", "\n", "            ", "log_str", "=", "\"Evaluating '{}' ({}/{})...\"", ".", "format", "(", "\n", "modelinfo", ".", "path", ",", "model_idx", "+", "1", ",", "len", "(", "self", ".", "benchmark", ".", "models", ")", ")", "\n", "logger", ".", "debug", "(", "''", ".", "join", "(", "[", "'='", "]", "*", "80", ")", ")", "\n", "logger", ".", "info", "(", "log_str", ")", "\n", "logger", ".", "debug", "(", "''", ".", "join", "(", "[", "'='", "]", "*", "80", ")", ")", "\n", "\n", "if", "not", "self", ".", "is_silent", ":", "\n", "                ", "print", "(", "log_str", ")", "\n", "\n", "# Initialize the dictionary for the models logging output", "\n", "", "model_logging_dict", "=", "{", "}", "\n", "\n", "# Setup model context", "\n", "with", "contextmanager", ".", "dir_context", "(", "modelinfo", ".", "path", ")", ":", "\n", "# Dynamically import the CCOBRA model", "\n", "                ", "importer", "=", "modelimporter", ".", "ModelImporter", "(", "\n", "modelinfo", ".", "path", ",", "CCobraModel", ",", "\n", "load_specific_class", "=", "modelinfo", ".", "load_specific_class", "\n", ")", "\n", "\n", "# Instantiate and prepare the model for predictions", "\n", "pre_model", "=", "importer", ".", "instantiate", "(", "modelinfo", ".", "args", ")", "\n", "pre_model", ".", "setup_environment", "(", "self", ".", "benchmark", ".", "type", ")", "\n", "\n", "# Check if model is applicable to domains/response types", "\n", "self", ".", "check_model_applicability", "(", "pre_model", ")", "\n", "\n", "# Only use the model's name if no override is specified", "\n", "model_name", "=", "modelinfo", ".", "override_name", "\n", "if", "not", "model_name", ":", "\n", "                    ", "model_name", "=", "pre_model", ".", "name", "\n", "\n", "# Ensure that names are unique and show a warning if duplicates are detected", "\n", "", "original_model_name", "=", "model_name", "\n", "changed", "=", "False", "\n", "while", "model_name", "in", "model_name_cache", ":", "\n", "                    ", "model_name", "=", "model_name", "+", "'\\''", "\n", "changed", "=", "True", "\n", "", "model_name_cache", ".", "add", "(", "model_name", ")", "\n", "\n", "if", "changed", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "'Duplicate model name detected (\"%s\"). Changed to \"%s\".'", ",", "\n", "original_model_name", ",", "model_name", "\n", ")", "\n", "\n", "# Only perform general pre-training if training data is", "\n", "# supplied and corresponding data is false. Otherwise, the", "\n", "# model has to be re-trained for each subject.", "\n", "", "if", "self", ".", "do_pre_train_global", ":", "\n", "                    ", "logger", ".", "debug", "(", "'General pre-training for %s...'", ",", "model_name", ")", "\n", "pre_model", ".", "pre_train", "(", "list", "(", "self", ".", "dict_pre_train", ".", "values", "(", ")", ")", ")", "\n", "\n", "# Iterate subject", "\n", "", "for", "subj_key_identifier", ",", "subj_data", "in", "self", ".", "dict_test", ".", "items", "(", ")", ":", "\n", "                    ", "start_subject", "=", "time", ".", "time", "(", ")", "\n", "\n", "subj_id", "=", "subj_data", "[", "0", "]", "[", "'item'", "]", ".", "identifier", "\n", "model", "=", "copy", ".", "deepcopy", "(", "pre_model", ")", "\n", "\n", "# Set the model to new participant", "\n", "model", ".", "start_participant", "(", "id", "=", "subj_id", ")", "\n", "\n", "# Perform pre-training for individual subjects only if", "\n", "# corresponding data is set to true", "\n", "if", "self", ".", "do_pre_train_leaveoneout", ":", "\n", "                        ", "logger", ".", "debug", "(", "'Individual pre-training for %s...'", ",", "model_name", ")", "\n", "cur_train_data", "=", "[", "\n", "value", "for", "key", ",", "value", "in", "self", ".", "dict_pre_train", ".", "items", "(", ")", "if", "key", "!=", "subj_id", "]", "\n", "model", ".", "pre_train", "(", "cur_train_data", ")", "\n", "\n", "# Perform background fitting", "\n", "", "if", "self", ".", "do_pre_person_background", ":", "\n", "                        ", "logger", ".", "debug", "(", "'Person background training for %s...'", ",", "model_name", ")", "\n", "cur_train_data", "=", "self", ".", "dict_pre_person_background", ".", "get", "(", "subj_key_identifier", ",", "[", "]", ")", "\n", "model", ".", "pre_person_background", "(", "cur_train_data", ")", "\n", "\n", "# Perform person training", "\n", "", "if", "self", ".", "do_pre_train_person", ":", "\n", "                        ", "logger", ".", "debug", "(", "'Person training for %s...'", ",", "model_name", ")", "\n", "subj_person_train_data", "=", "self", ".", "dict_pre_train_person", ".", "get", "(", "subj_key_identifier", ",", "[", "]", ")", "\n", "model", ".", "pre_train_person", "(", "subj_person_train_data", ")", "\n", "\n", "# Iterate over individual tasks", "\n", "", "start_eval", "=", "time", ".", "time", "(", ")", "\n", "for", "task_idx", ",", "task", "in", "enumerate", "(", "subj_data", ")", ":", "\n", "                        ", "start_task", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "debug", "(", "'Querying for task %s/%s...'", ",", "task_idx", "+", "1", ",", "len", "(", "subj_data", ")", ")", "\n", "\n", "# Integrity checks", "\n", "assert", "task", "[", "'item'", "]", ".", "identifier", "==", "subj_id", "\n", "\n", "# Query models for predictions", "\n", "for", "eh", "in", "self", ".", "benchmark", ".", "evaluation_handlers", ":", "\n", "                            ", "target", "=", "task", "[", "eh", ".", "data_column", "]", "\n", "eh", ".", "predict", "(", "model", ",", "model_name", ",", "task", "[", "'item'", "]", ",", "target", ",", "task", "[", "'aux'", "]", ")", "\n", "\n", "# Perform model adaption", "\n", "", "if", "self", ".", "do_adapt", ":", "\n", "                            ", "for", "eh", "in", "self", ".", "benchmark", ".", "evaluation_handlers", ":", "\n", "                                ", "target", "=", "task", "[", "eh", ".", "data_column", "]", "\n", "eh", ".", "adapt", "(", "model", ",", "task", "[", "'item'", "]", ",", "task", "[", "'full'", "]", ")", "\n", "\n", "", "", "logger", ".", "debug", "(", "\n", "'Task {} took {:4f}s'", ".", "format", "(", "task_idx", "+", "1", ",", "time", ".", "time", "(", ")", "-", "start_task", ")", ")", "\n", "\n", "# Finalize subject evaluation and allow the model to store parameters", "\n", "", "model_log", "=", "{", "}", "\n", "model", ".", "end_participant", "(", "subj_id", ",", "model_log", ")", "\n", "if", "len", "(", "model_log", ")", ">", "0", ":", "\n", "                        ", "model_logging_dict", "[", "subj_id", "]", "=", "model_log", "\n", "\n", "", "logger", ".", "debug", "(", "'Subject evaluation took {:.4}s'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "start_eval", ")", ")", "\n", "logger", ".", "debug", "(", "'Subject {} done. took {:.4}s'", ".", "format", "(", "\n", "subj_id", ",", "time", ".", "time", "(", ")", "-", "start_subject", ")", ")", "\n", "\n", "# Save the models logging information if available", "\n", "", "if", "len", "(", "model_logging_dict", ")", ">", "0", ":", "\n", "                    ", "model_logging_results", "[", "model_name", "]", "=", "model_logging_dict", "\n", "\n", "# Unload the imported model and its dependencies. Might cause garbage collection", "\n", "# issues", "\n", "", "importer", ".", "unimport", "(", ")", "\n", "\n", "", "", "res_df", "=", "None", "\n", "on_list", "=", "[", "\n", "'model'", ",", "\n", "'id'", ",", "\n", "'domain'", ",", "\n", "'response_type'", ",", "\n", "'sequence'", ",", "\n", "'task'", ",", "\n", "'choices'", "\n", "]", "\n", "\n", "for", "enc", "in", "self", ".", "benchmark", ".", "evaluation_handlers", ":", "\n", "            ", "if", "res_df", "is", "None", ":", "\n", "                ", "logger", ".", "debug", "(", "'Preparing new result dataframe based on evaluation handler'", ")", "\n", "res_df", "=", "enc", ".", "get_result_df", "(", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "debug", "(", "'Adding evaluation handler result to result dataframe'", ")", "\n", "res_df", "=", "res_df", ".", "merge", "(", "enc", ".", "get_result_df", "(", ")", ",", "on", "=", "on_list", ",", "suffixes", "=", "(", "''", ",", "'_'", "+", "enc", ".", "data_column", ")", ")", "\n", "\n", "# Rename score column", "\n", "", "", "res_df", "=", "res_df", ".", "rename", "(", "columns", "=", "{", "'score'", ":", "'score_response'", "}", ")", "\n", "\n", "# Integrate cache", "\n", "if", "self", ".", "cache_df", "is", "None", ":", "\n", "            ", "logger", ".", "debug", "(", "'Empty cache. Returning only result dataframe.'", ")", "\n", "return", "res_df", ",", "model_logging_results", "\n", "\n", "", "if", "res_df", ".", "empty", ":", "\n", "            ", "logger", ".", "debug", "(", "'Empty result dataframe. Returning cache only.'", ")", "\n", "return", "self", ".", "cache_df", ",", "{", "}", "\n", "\n", "", "logger", ".", "debug", "(", "'Merging cache and result dataframe...'", ")", "\n", "assert", "sorted", "(", "list", "(", "res_df", ")", ")", "==", "sorted", "(", "list", "(", "self", ".", "cache_df", ")", ")", ",", "'Incompatible cache'", "\n", "return", "pd", ".", "concat", "(", "[", "res_df", ",", "self", ".", "cache_df", "]", ")", ",", "model_logging_results", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.benchmark.evaluator.Evaluator.check_model_applicability": [[261, 291], ["set", "set", "ValueError", "set", "set", "ValueError"], "methods", ["None"], ["", "def", "check_model_applicability", "(", "self", ",", "pre_model", ")", ":", "\n", "        ", "\"\"\" Verifies the applicability of a model by checking its supported domains and response\n        types and comparing them with the evaluation dataset.\n\n        Parameters\n        ----------\n        pre_model : CCobraModel\n            Model to check applicability for.\n\n        Raises\n        ------\n        ValueError\n            Exception thrown when model is not applicable to some domains or response types\n            in the test data.\n\n        \"\"\"", "\n", "\n", "missing_domains", "=", "set", "(", "self", ".", "benchmark", ".", "data_test", ".", "domains", ")", "-", "set", "(", "pre_model", ".", "supported_domains", ")", "\n", "if", "missing_domains", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Model {} is not applicable to domains {} found in '", "'the test dataset.'", ".", "format", "(", "\n", "pre_model", ".", "name", ",", "missing_domains", ")", ")", "\n", "\n", "", "missing_response_types", "=", "set", "(", "self", ".", "benchmark", ".", "data_test", ".", "response_types", ")", "-", "set", "(", "pre_model", ".", "supported_response_types", ")", "\n", "if", "missing_response_types", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Model {} is not applicable to response_types {} '", "'found in the test dataset.'", ".", "format", "(", "\n", "pre_model", ".", "name", ",", "missing_response_types", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.absdiff.AbsDiffComparator.compare": [[15, 53], ["ccobra.unnest", "ccobra.unnest", "isinstance", "isinstance", "numpy.abs", "ValueError", "float", "float", "ValueError", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.unnest", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.unnest"], ["def", "compare", "(", "self", ",", "prediction", ",", "target", ",", "response_type", ",", "choices", ")", ":", "\n", "        ", "\"\"\" Compares two response numbers based on their absolute difference.\n\n        Parameters\n        ----------\n        prediction : tuple\n            Tuple containing number A.\n\n        target : tuple\n            Tuple containing number B.\n                \n        response_type : string\n            The response type of the prediction and target.\n            \n        choices : list(object)\n            The choice options that were available for this comparison.\n\n        Returns\n        -------\n        float\n            Absolute difference between the differences.\n\n        \"\"\"", "\n", "\n", "if", "response_type", "==", "\"multiple-choice\"", ":", "\n", "            ", "raise", "ValueError", "(", "'The Absolute Difference Comparator is incompatible with the multiple-choice response type.'", ")", "\n", "\n", "", "inner_a", "=", "unnest", "(", "prediction", ")", "\n", "inner_b", "=", "unnest", "(", "target", ")", "\n", "\n", "if", "isinstance", "(", "inner_a", ",", "str", ")", ":", "\n", "            ", "inner_a", "=", "float", "(", "inner_a", ")", "\n", "", "if", "isinstance", "(", "inner_b", ",", "str", ")", ":", "\n", "            ", "inner_b", "=", "float", "(", "inner_b", ")", "\n", "", "if", "not", "isinstance", "(", "inner_a", ",", "(", "int", ",", "float", ")", ")", "or", "not", "isinstance", "(", "inner_b", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incompatible value types for comparison.'", ")", "\n", "\n", "", "return", "np", ".", "abs", "(", "inner_a", "-", "inner_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.absdiff.AbsDiffComparator.get_name": [[54, 65], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the name of the comparator.\n\n        Returns\n        -------\n        string\n            Comparator name.\n\n        \"\"\"", "\n", "\n", "return", "\"Absolute Difference\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.nvc.NVCComparator.compare": [[13, 44], ["int", "ValueError", "ccobra.tuple_to_string", "ccobra.tuple_to_string"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string"], ["def", "compare", "(", "self", ",", "prediction", ",", "target", ",", "response_type", ",", "choices", ")", ":", "\n", "        ", "\"\"\" Compares two response objects based on their NVCness. Only returns true if both\n        responses are in agreement with either responding NVC or not NVC.\n\n        Parameters\n        ----------\n        prediction : tuple\n            Response tuple A for comparison.\n\n        target : tuple\n            Response tuple B for comparison.\n            \n        response_type : string\n            The response type of the prediction and target.\n            \n        choices : list(object)\n            The choice options that were available for this comparison.\n\n        Returns\n        -------\n        bool\n            True only if both objects agree on whether the response is NVC or not.\n\n        \"\"\"", "\n", "\n", "if", "response_type", "==", "\"multiple-choice\"", ":", "\n", "            ", "raise", "ValueError", "(", "'NVC Accuracy Comparator is incompatible with the multiple-choice response type.'", ")", "\n", "\n", "", "is_nvc_a", "=", "tuple_to_string", "(", "prediction", ")", "==", "'NVC'", "\n", "is_nvc_b", "=", "tuple_to_string", "(", "target", ")", "==", "'NVC'", "\n", "return", "int", "(", "is_nvc_a", "==", "is_nvc_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.nvc.NVCComparator.get_name": [[45, 56], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the name of the comparator.\n\n        Returns\n        -------\n        string\n            Comparator name.\n\n        \"\"\"", "\n", "\n", "return", "'NVC Accuracy'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.squareddiff.SquaredDiffComparator.compare": [[15, 53], ["ccobra.unnest", "ccobra.unnest", "isinstance", "isinstance", "ValueError", "float", "float", "ValueError", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.unnest", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.unnest"], ["def", "compare", "(", "self", ",", "prediction", ",", "target", ",", "response_type", ",", "choices", ")", ":", "\n", "        ", "\"\"\" Compares two response numbers based on their squared difference.\n\n        Parameters\n        ----------\n        prediction : tuple\n            Tuple containing number A.\n\n        target : tuple\n            Tuple containing number B.\n            \n        response_type : string\n            The response type of the prediction and target.\n            \n        choices : list(object)\n            The choice options that were available for this comparison.\n\n        Returns\n        -------\n        float\n            Squared difference between the differences.\n\n        \"\"\"", "\n", "\n", "if", "response_type", "==", "\"multiple-choice\"", ":", "\n", "            ", "raise", "ValueError", "(", "'The Squared Difference Comparator is incompatible with the multiple-choice response type.'", ")", "\n", "\n", "", "inner_a", "=", "unnest", "(", "prediction", ")", "\n", "inner_b", "=", "unnest", "(", "target", ")", "\n", "\n", "if", "isinstance", "(", "inner_a", ",", "str", ")", ":", "\n", "            ", "inner_a", "=", "float", "(", "inner_a", ")", "\n", "", "if", "isinstance", "(", "inner_b", ",", "str", ")", ":", "\n", "            ", "inner_b", "=", "float", "(", "inner_b", ")", "\n", "", "if", "not", "isinstance", "(", "inner_a", ",", "(", "int", ",", "float", ")", ")", "or", "not", "isinstance", "(", "inner_b", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incompatible value types for comparison.'", ")", "\n", "\n", "", "return", "(", "inner_a", "-", "inner_b", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.squareddiff.SquaredDiffComparator.get_name": [[54, 65], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the name of the comparator.\n\n        Returns\n        -------\n        string\n            Comparator name.\n\n        \"\"\"", "\n", "\n", "return", "\"Squared Difference\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.equality.EqualityComparator.compare": [[15, 56], ["int", "ccobra.tuple_to_string", "ccobra.tuple_to_string", "ccobra.tuple_to_string", "numpy.array", "numpy.array", "numpy.sum", "len", "ccobra.tuple_to_string", "ccobra.tuple_to_string"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.ccobra.helper.tuple_to_string"], ["def", "compare", "(", "self", ",", "prediction", ",", "target", ",", "response_type", ",", "choices", ")", ":", "\n", "        ", "\"\"\" Compares two response objects based on equality.\n        When using the multiple-choice response type, the predictions and\n        targets are interpreted as mask-vectors for the choices.\n        In this case, the score corresponds to the overlap of the vectors.\n\n        Parameters\n        ----------\n        prediction : tuple\n            Response tuple A for comparison.\n\n        target : tuple\n            Response tuple B for comparison.\n            \n        response_type : string\n            The response type of the prediction and target.\n            \n        choices : list(object)\n            The choice options that were available for this comparison.\n\n        Returns\n        -------\n        bool\n            True if both objects are equal, false otherwise.\n\n        \"\"\"", "\n", "\n", "if", "response_type", "==", "\"multiple-choice\"", ":", "\n", "\n", "            ", "string_choices", "=", "[", "tuple_to_string", "(", "x", ")", "for", "x", "in", "choices", "]", "\n", "string_preds", "=", "[", "tuple_to_string", "(", "x", ")", "for", "x", "in", "prediction", "]", "\n", "string_target", "=", "[", "tuple_to_string", "(", "x", ")", "for", "x", "in", "target", "]", "\n", "\n", "choices_pred", "=", "[", "x", "in", "string_preds", "for", "x", "in", "string_choices", "]", "\n", "choices_target", "=", "[", "x", "in", "string_target", "for", "x", "in", "string_choices", "]", "\n", "\n", "overlap", "=", "np", ".", "array", "(", "choices_pred", ")", "==", "np", ".", "array", "(", "choices_target", ")", "\n", "score", "=", "np", ".", "sum", "(", "overlap", ")", "/", "len", "(", "choices", ")", "\n", "return", "score", "\n", "\n", "", "return", "int", "(", "tuple_to_string", "(", "prediction", ")", "==", "tuple_to_string", "(", "target", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.equality.EqualityComparator.get_name": [[57, 68], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the name of the comparator.\n\n        Returns\n        -------\n        string\n            Comparator name.\n\n        \"\"\"", "\n", "\n", "return", "'Accuracy'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.PlotVisualizer.__init__": [[45, 68], ["super().__init__", "open", "file_handle.read", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["def", "__init__", "(", "self", ",", "template_file", ",", "template_CSS", "=", "None", ")", ":", "\n", "        ", "\"\"\" Initializes the Plot visualizer based on a template HTML filepath.\n\n        Parameters\n        ----------\n        template_file : str\n            Path to the template file underlying this visualizer.\n\n        template_CSS : str\n            Path to the template CSS file.\n\n        \"\"\"", "\n", "\n", "super", "(", "PlotVisualizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Member variables", "\n", "self", ".", "template_CSS", "=", "template_CSS", "\n", "\n", "# Load the HTML template", "\n", "self", ".", "template", "=", "''", "\n", "template_path", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "+", "os", ".", "sep", "+", "template_file", "\n", "with", "open", "(", "template_path", ")", "as", "file_handle", ":", "\n", "            ", "self", ".", "template", "=", "file_handle", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.PlotVisualizer.get_content_dict": [[69, 93], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "get_content_dict", "(", "self", ",", "result_df", ",", "eval_handler", ",", "model_log", ")", ":", "\n", "        ", "\"\"\" Obtain the dictionary mapping from HTML template placeholders\n        to content.\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            CCOBRA result dataframe.\n\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        Returns\n        -------\n        dict(str, str)\n            Returns the content dictionary mapping from template placeholders to html snippets.\n            None is returned, if the prerequisites for the visualization are not met.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.PlotVisualizer.to_html": [[94, 131], ["viz_plot.PlotVisualizer.get_content_dict", "eval_handler.comparator.get_name", "viz_plot.PlotVisualizer.items", "template.replace.replace.replace"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ModelLogVisualizer.get_content_dict", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.equality.EqualityComparator.get_name"], ["", "def", "to_html", "(", "self", ",", "result_df", ",", "eval_handler", ",", "model_log", "=", "None", ")", ":", "\n", "        ", "\"\"\" Fill template with content\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            CCOBRA result dataframe.\n\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        Returns\n        -------\n        str\n            Html content string for this visualizer. None is returned, if the prerequisites\n            for the visualization are not met.\n\n        \"\"\"", "\n", "\n", "# Obtain the template content", "\n", "content_dict", "=", "self", ".", "get_content_dict", "(", "result_df", ",", "eval_handler", ",", "model_log", ")", "\n", "\n", "# If the content dict is empty, the complete section can be skipped", "\n", "if", "content_dict", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "content_dict", "[", "'PLOT_TYPE'", "]", "=", "eval_handler", ".", "data_column", "\n", "content_dict", "[", "'COMPARATOR'", "]", "=", "eval_handler", ".", "comparator", ".", "get_name", "(", ")", "\n", "\n", "# Fill the template and return the resulting HTML", "\n", "template", "=", "self", ".", "template", "\n", "for", "key", ",", "value", "in", "content_dict", ".", "items", "(", ")", ":", "\n", "            ", "template", "=", "template", ".", "replace", "(", "'{{{{{}}}}}'", ".", "format", "(", "key", ")", ",", "value", ")", "\n", "", "return", "template", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.PlotVisualizer.shorttitle": [[132, 148], ["NotImplementedError"], "methods", ["None"], ["", "def", "shorttitle", "(", "self", ",", "eval_handler", ")", ":", "\n", "        ", "\"\"\" Shorttitle for the visualizer.\n\n        Parameters\n        ----------\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        Returns\n        -------\n        str\n            Shorttitle for the visualizer.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", "'Shorttitle not defined.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.AccuracyVisualizer.__init__": [[155, 161], ["viz_plot.PlotVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Constructs the visualizer by providing the super class with the html template.\n\n        \"\"\"", "\n", "\n", "super", "(", "AccuracyVisualizer", ",", "self", ")", ".", "__init__", "(", "'template_accuracy.html'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.AccuracyVisualizer.get_content_dict": [[162, 209], ["[].agg().sort_values", "len", "[].tolist", "[].agg().sort_values.index.tolist", "[].agg().sort_values.index.tolist", "acc_df[].tolist", "[].agg().sort_values.index.tolist", "json.dumps", "json.dumps", "[].agg", "numpy.all", "[].agg().sort_values", "viz_plot.ccobracolor", "range", "result_df.groupby", "[].agg", "result_df.groupby"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ccobracolor"], ["", "def", "get_content_dict", "(", "self", ",", "result_df", ",", "eval_handler", ",", "model_log", ")", ":", "\n", "        ", "\"\"\" Constructs the template-html mapping dictionary.\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            CCOBRA result dataframe.\n\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        Returns\n        -------\n        dict(str, str)\n            Returns the content dictionary mapping from template placeholders to html snippets.\n\n        \"\"\"", "\n", "\n", "data_column", "=", "\"score_{}\"", ".", "format", "(", "eval_handler", ".", "data_column", ")", "\n", "\n", "acc_df", "=", "result_df", ".", "groupby", "(", "\n", "'model'", ",", "as_index", "=", "False", ")", "[", "data_column", "]", ".", "agg", "(", "[", "'mean'", ",", "'std'", "]", ")", ".", "sort_values", "(", "'mean'", ")", "\n", "\n", "n_models", "=", "len", "(", "acc_df", ".", "index", ".", "tolist", "(", ")", ")", "\n", "alpha", "=", "'80'", "\n", "data", "=", "{", "\n", "'x'", ":", "acc_df", ".", "index", ".", "tolist", "(", ")", ",", "\n", "'y'", ":", "acc_df", "[", "'mean'", "]", ".", "tolist", "(", ")", ",", "\n", "'marker'", ":", "{", "\n", "'color'", ":", "[", "ccobracolor", "(", "x", ",", "n_models", ")", "+", "alpha", "for", "x", "in", "range", "(", "n_models", ")", "]", "\n", "}", ",", "\n", "'type'", ":", "'bar'", ",", "\n", "'name'", ":", "acc_df", ".", "index", ".", "tolist", "(", ")", "\n", "}", "\n", "\n", "# Compute the explicit ordering", "\n", "ordering", "=", "result_df", ".", "groupby", "(", "\n", "'model'", ",", "as_index", "=", "False", ")", "[", "data_column", "]", ".", "agg", "(", "'mean'", ")", ".", "sort_values", "(", "\n", "data_column", ",", "ascending", "=", "True", ")", "[", "'model'", "]", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'PLOT_DATA'", ":", "json", ".", "dumps", "(", "data", ")", ",", "\n", "'ORDERING'", ":", "json", ".", "dumps", "(", "ordering", ")", ",", "\n", "'RANGEMODE'", ":", "'nonnegative'", "if", "np", ".", "all", "(", "acc_df", "[", "'mean'", "]", ">=", "0", ")", "else", "'normal'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.AccuracyVisualizer.shorttitle": [[211, 222], ["eval_handler.comparator.get_name"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.comparators.equality.EqualityComparator.get_name"], ["", "def", "shorttitle", "(", "self", ",", "eval_handler", ")", ":", "\n", "        ", "\"\"\" Shorttitle for the visualizer.\n\n        Returns\n        -------\n        str\n            Shorttitle for the visualizer.\n\n        \"\"\"", "\n", "return", "\"Bar Plot: {} ({})\"", ".", "format", "(", "\n", "eval_handler", ".", "comparator", ".", "get_name", "(", ")", ",", "eval_handler", ".", "data_column", ")", "\n", "", "", "class", "BoxplotVisualizer", "(", "PlotVisualizer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.BoxplotVisualizer.__init__": [[229, 235], ["viz_plot.PlotVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Constructs the visualizer by providing the super class with the html template.\n\n        \"\"\"", "\n", "\n", "super", "(", "BoxplotVisualizer", ",", "self", ")", ".", "__init__", "(", "'template_box.html'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.BoxplotVisualizer.get_content_dict": [[236, 293], ["[].agg", "len", "[].agg.groupby", "sorted", "enumerate", "[].tolist", "subj_df[].unique", "sorted.append", "viz_plot.ccobracolor", "json.dumps", "json.dumps", "numpy.all", "result_df.groupby", "model_df[].tolist", "numpy.mean", "[].agg().sort_values", "[].agg", "result_df.groupby"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ccobracolor"], ["", "def", "get_content_dict", "(", "self", ",", "result_df", ",", "eval_handler", ",", "model_log", ")", ":", "\n", "        ", "\"\"\" Constructs the template-html mapping dictionary.\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            CCOBRA result dataframe.\n\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        Returns\n        -------\n        dict(str, str)\n            Returns the content dictionary mapping from template placeholders to html snippets.\n\n        \"\"\"", "\n", "data_column", "=", "\"score_{}\"", ".", "format", "(", "eval_handler", ".", "data_column", ")", "\n", "\n", "subj_df", "=", "result_df", ".", "groupby", "(", "\n", "[", "'model'", ",", "'id'", "]", ",", "as_index", "=", "False", ")", "[", "data_column", "]", ".", "agg", "(", "'mean'", ")", "\n", "data", "=", "[", "]", "\n", "n_models", "=", "len", "(", "subj_df", "[", "'model'", "]", ".", "unique", "(", ")", ")", "\n", "\n", "for", "model", ",", "model_df", "in", "subj_df", ".", "groupby", "(", "'model'", ")", ":", "\n", "            ", "data", ".", "append", "(", "{", "\n", "'y'", ":", "model_df", "[", "data_column", "]", ".", "tolist", "(", ")", ",", "\n", "'type'", ":", "'box'", ",", "\n", "'name'", ":", "model", ",", "\n", "'boxpoints'", ":", "'all'", ",", "\n", "'marker'", ":", "{", "\n", "'size'", ":", "4", "\n", "}", ",", "\n", "'text'", ":", "[", "\"Subj.ID: {}\"", ".", "format", "(", "x", ")", "for", "x", "in", "model_df", "[", "'id'", "]", "]", ",", "\n", "'hoverinfo'", ":", "'text+y'", ",", "\n", "#'hoverlabel': {", "\n", "#    'bgcolor': 'tomato',", "\n", "#    'font': {'color': 'black'}", "\n", "#}", "\n", "}", ")", "\n", "\n", "", "data", "=", "sorted", "(", "data", ",", "key", "=", "lambda", "x", ":", "np", ".", "mean", "(", "x", "[", "'y'", "]", ")", ")", "\n", "for", "idx", ",", "datum", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "datum", "[", "'marker'", "]", "[", "'color'", "]", "=", "ccobracolor", "(", "idx", ",", "n_models", ")", "\n", "\n", "# Compute the explicit ordering", "\n", "", "ordering", "=", "result_df", ".", "groupby", "(", "\n", "'model'", ",", "as_index", "=", "False", ")", "[", "data_column", "]", ".", "agg", "(", "'mean'", ")", ".", "sort_values", "(", "\n", "data_column", ",", "ascending", "=", "True", ")", "[", "'model'", "]", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'PLOT_DATA'", ":", "json", ".", "dumps", "(", "data", ")", ",", "\n", "'ORDERING'", ":", "json", ".", "dumps", "(", "ordering", ")", ",", "\n", "'RANGEMODE'", ":", "'nonnegative'", "if", "np", ".", "all", "(", "model_df", "[", "data_column", "]", ">=", "0", ")", "else", "'normal'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.BoxplotVisualizer.shorttitle": [[295, 306], ["None"], "methods", ["None"], ["", "def", "shorttitle", "(", "self", ",", "eval_handler", ")", ":", "\n", "        ", "\"\"\" Shorttitle for the visualizer.\n\n        Returns\n        -------\n        str\n            Shorttitle for the visualizer.\n\n        \"\"\"", "\n", "\n", "return", "'Subject-Based Boxplots ({})'", ".", "format", "(", "eval_handler", ".", "data_column", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.MFATableVisualizer.__init__": [[312, 314], ["viz_plot.PlotVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "MFATableVisualizer", ",", "self", ")", ".", "__init__", "(", "'template_mfa.html'", ",", "'template_mfa.css'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.MFATableVisualizer.get_content_dict": [[315, 365], ["numpy.any", "result_df.groupby", "task_df.groupby", "collections.Counter", "max", "json.dumps", "collections.Counter", "max", "sorted", "sorted", "collections.Counter.items", "collections.Counter.items", "collections.Counter.items", "collections.Counter.items"], "methods", ["None"], ["", "def", "get_content_dict", "(", "self", ",", "result_df", ",", "eval_handler", ",", "model_log", ")", ":", "\n", "        ", "\"\"\" Constructs the template-html mapping dictionary.\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            CCOBRA result dataframe.\n\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        Returns\n        -------\n        dict(str, str)\n            Returns the content dictionary mapping from template placeholders to html snippets.\n            If no task encoding or encoder was provided, None is returned.\n\n        \"\"\"", "\n", "\n", "if", "np", ".", "any", "(", "[", "x", "not", "in", "result_df", "for", "x", "in", "[", "'task_enc'", ",", "'prediction_enc_response'", ",", "'truth_enc_response'", "]", "]", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "# Construct the MFA dictionary", "\n", "", "mfa_dict", "=", "{", "}", "\n", "for", "task", ",", "task_df", "in", "result_df", ".", "groupby", "(", "'task_enc'", ")", ":", "\n", "            ", "mfa_dict", "[", "task", "]", "=", "{", "}", "\n", "for", "model", ",", "model_df", "in", "task_df", ".", "groupby", "(", "'model'", ")", ":", "\n", "                ", "pred_counts", "=", "collections", ".", "Counter", "(", "model_df", "[", "'prediction_enc_response'", "]", ")", "\n", "pred_max_count", "=", "max", "(", "[", "x", "[", "1", "]", "for", "x", "in", "pred_counts", ".", "items", "(", ")", "]", ")", "\n", "mfa", "=", "'<br>'", ".", "join", "(", "\n", "sorted", "(", "[", "x", "[", "0", "]", "for", "x", "in", "pred_counts", ".", "items", "(", ")", "if", "x", "[", "1", "]", "==", "pred_max_count", "]", ")", ")", "\n", "mfa_dict", "[", "task", "]", "[", "model", "]", "=", "mfa", "\n", "\n", "# Add data MFA", "\n", "", "truth_counts", "=", "collections", ".", "Counter", "(", "task_df", "[", "'truth_enc_response'", "]", ")", "\n", "truth_max_count", "=", "max", "(", "[", "x", "[", "1", "]", "for", "x", "in", "truth_counts", ".", "items", "(", ")", "]", ")", "\n", "mfa", "=", "'<br>'", ".", "join", "(", "\n", "sorted", "(", "[", "x", "[", "0", "]", "for", "x", "in", "truth_counts", ".", "items", "(", ")", "if", "x", "[", "1", "]", "==", "truth_max_count", "]", ")", ")", "\n", "mfa_dict", "[", "task", "]", "[", "'DATA'", "]", "=", "mfa", "\n", "\n", "", "if", "not", "mfa_dict", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "{", "\n", "'MFA_DATA'", ":", "json", ".", "dumps", "(", "mfa_dict", ")", ",", "\n", "'TEXT'", ":", "'The following table summarizes the most-frequent '", "+", "'predictions from the models to each syllogism.'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.MFATableVisualizer.shorttitle": [[367, 378], ["None"], "methods", ["None"], ["", "def", "shorttitle", "(", "self", ",", "eval_handler", ")", ":", "\n", "        ", "\"\"\" Shorttitle for the visualizer.\n\n        Returns\n        -------\n        str\n            Shorttitle for the visualizer.\n\n        \"\"\"", "\n", "\n", "return", "'Most-Frequent Answer Comparison'", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.SubjectTableVisualizer.__init__": [[384, 386], ["viz_plot.PlotVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SubjectTableVisualizer", ",", "self", ")", ".", "__init__", "(", "'template_subject_table.html'", ",", "'template_subject_table.css'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.SubjectTableVisualizer.get_content_dict": [[387, 426], ["numpy.any", "numpy.all", "numpy.all", "isinstance", "numpy.isnan", "isinstance", "numpy.isnan"], "methods", ["None"], ["", "def", "get_content_dict", "(", "self", ",", "result_df", ",", "eval_handler", ",", "model_log", ")", ":", "\n", "        ", "\"\"\" Constructs the template-html mapping dictionary.\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            CCOBRA result dataframe.\n\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        Returns\n        -------\n        dict(str, str)\n            Returns the content dictionary mapping from template placeholders to html snippets.\n            If no task encoding or encoder was provided, None is returned.\n\n        \"\"\"", "\n", "\n", "pred_enc_name", "=", "\"prediction_enc_{}\"", ".", "format", "(", "eval_handler", ".", "data_column", ")", "\n", "truth_enc_name", "=", "\"truth_enc_{}\"", ".", "format", "(", "eval_handler", ".", "data_column", ")", "\n", "\n", "if", "np", ".", "any", "(", "[", "x", "not", "in", "result_df", "for", "x", "in", "[", "'task_enc'", ",", "pred_enc_name", ",", "truth_enc_name", "]", "]", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "np", ".", "all", "(", "[", "isinstance", "(", "x", ",", "float", ")", "and", "np", ".", "isnan", "(", "x", ")", "for", "x", "in", "result_df", "[", "pred_enc_name", "]", "]", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "np", ".", "all", "(", "[", "isinstance", "(", "x", ",", "float", ")", "and", "np", ".", "isnan", "(", "x", ")", "for", "x", "in", "result_df", "[", "truth_enc_name", "]", "]", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "{", "\n", "'PRED_ENC_NAME'", ":", "pred_enc_name", ",", "\n", "'TRUTH_ENC_NAME'", ":", "truth_enc_name", ",", "\n", "'TEXT'", ":", "'The following section shows the results for specific subjects. Please select the subject'", "+", "' identifier using the selection box below.'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.SubjectTableVisualizer.shorttitle": [[428, 439], ["None"], "methods", ["None"], ["", "def", "shorttitle", "(", "self", ",", "eval_handler", ")", ":", "\n", "        ", "\"\"\" Shorttitle for the visualizer.\n\n        Returns\n        -------\n        str\n            Shorttitle for the visualizer.\n\n        \"\"\"", "\n", "\n", "return", "\"Subject Tables: {}\"", ".", "format", "(", "eval_handler", ".", "data_column", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ModelLogVisualizer.__init__": [[445, 447], ["viz_plot.PlotVisualizer.__init__"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ModelLogVisualizer", ",", "self", ")", ".", "__init__", "(", "'template_model_log.html'", ",", "'template_model_log.css'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ModelLogVisualizer.get_content_dict": [[448, 476], ["json.dumps", "len"], "methods", ["None"], ["", "def", "get_content_dict", "(", "self", ",", "result_df", ",", "eval_handler", ",", "model_log", ")", ":", "\n", "        ", "\"\"\" Constructs the template-html mapping dictionary.\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            CCOBRA result dataframe.\n\n        eval_handler : EvaluationHandler\n            EvaluationHandler objects of the current evaluation\n\n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        Returns\n        -------\n        dict(str, str)\n            Returns the content dictionary mapping from template placeholders to html snippets.\n            None is returned if no logged informations are available.\n\n        \"\"\"", "\n", "\n", "if", "model_log", "is", "None", "or", "len", "(", "model_log", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "{", "\n", "'MODEL_LOGS'", ":", "json", ".", "dumps", "(", "model_log", ")", ",", "\n", "'TEXT'", ":", "'Logged information from the models.'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ModelLogVisualizer.shorttitle": [[478, 489], ["None"], "methods", ["None"], ["", "def", "shorttitle", "(", "self", ",", "eval_handler", ")", ":", "\n", "        ", "\"\"\" Shorttitle for the visualizer.\n\n        Returns\n        -------\n        str\n            Shorttitle for the visualizer.\n\n        \"\"\"", "\n", "\n", "return", "'Model Logs'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ccobracolor": [[11, 38], ["numpy.sin", "numpy.sin", "numpy.cos", "hex().replace", "hex", "int"], "function", ["None"], ["def", "ccobracolor", "(", "idx", ",", "n_models", ",", "lightness", "=", "0.5", ")", ":", "\n", "    ", "\"\"\" Generates the CCOBRA plot color palette.\n\n    Parameters\n    ----------\n    idx : int\n        Position in the CCOBRA color spectrum.\n\n    n_models : int\n        Number of models, i.e., number of colors to construct the color spectrum for.\n\n    lightness : float, optional\n        Lightness scaling factor of the color.\n\n    Returns\n    -------\n    str\n        Hexadecimal representation of the color (e.g, '#a65959')\n\n    \"\"\"", "\n", "\n", "val", "=", "(", "idx", "+", "1", ")", "/", "(", "n_models", "+", "1", ")", "\n", "col_r", "=", "(", "np", ".", "sin", "(", "val", "*", "2", "*", "np", ".", "pi", "*", "1.247", "+", "np", ".", "pi", ")", "*", "127", "+", "128", ")", "*", "lightness", "\n", "col_g", "=", "(", "np", ".", "sin", "(", "val", "*", "2", "*", "np", ".", "pi", "*", "0.373", ")", "*", "127", "+", "128", ")", "*", "lightness", "\n", "col_b", "=", "(", "np", ".", "cos", "(", "val", "*", "2", "*", "np", ".", "pi", "*", "0.91113", ")", "*", "127", "+", "128", ")", "*", "lightness", "\n", "return", "'#'", "+", "''", ".", "join", "(", "\n", "[", "(", "'0'", "+", "hex", "(", "int", "(", "y", ")", ")", ".", "replace", "(", "'0x'", ",", "''", ")", ")", "[", "-", "2", ":", "]", "for", "y", "in", "[", "col_r", ",", "col_g", ",", "col_b", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.__init__": [[16, 49], ["ext_content_paths.items", "codecs.open", "os.path.dirname", "file_handle.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "evaluations", ")", ":", "\n", "        ", "\"\"\" Initializes the html creator with a list of evaluations\n\n        Parameters\n        ----------\n        evaluations : list(tuple(EvaluationHandler, list(PlotVisualizer)))\n            List of tuples containing an EvaluationHandler object and the corresponding list of\n            visualization objects, i.e., components for creating html snippets\n            representing views (e.g., plots) on the data.\n            \n        \"\"\"", "\n", "\n", "self", ".", "evaluations", "=", "evaluations", "\n", "\n", "# Load the template", "\n", "self", ".", "external_contents", "=", "{", "\n", "'template'", ":", "''", ",", "\n", "'plotly'", ":", "''", ",", "\n", "'html2canvas'", ":", "''", ",", "\n", "'cssness'", ":", "''", "\n", "}", "\n", "\n", "ext_content_paths", "=", "{", "\n", "'template'", ":", "'template_page.html'", ",", "\n", "'plotly'", ":", "'plotly-latest.min.js'", ",", "\n", "'html2canvas'", ":", "'html2canvas.min.js'", ",", "\n", "'cssness'", ":", "'template_page.css'", "\n", "}", "\n", "\n", "for", "key", ",", "path", "in", "ext_content_paths", ".", "items", "(", ")", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "+", "os", ".", "sep", "+", "path", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "file_handle", ":", "\n", "                ", "self", ".", "external_contents", "[", "key", "]", "=", "file_handle", ".", "read", "(", ")", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.to_html": [[50, 140], ["json.dumps", "datetime.datetime.now().strftime", "content_dict.items", "result_df.to_csv().split", "scripts.append", "json.dumps", "template.replace.replace.replace", "datetime.datetime.now", "metric.to_html", "content.append", "result_df.to_csv", "css_dependencies.append", "metric.shorttitle().lower().replace", "metric.shorttitle", "codecs.open", "os.path.dirname", "file_handle.read", "metric.shorttitle().lower", "metric.shorttitle"], "methods", ["home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.html_creator.HTMLCreator.to_html", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ModelLogVisualizer.shorttitle", "home.repos.pwc.inspect_result.CognitiveComputationLab_ccobra.visualization.viz_plot.ModelLogVisualizer.shorttitle"], ["", "", "", "def", "to_html", "(", "self", ",", "result_df", ",", "benchmark", ",", "model_log", ",", "embedded", "=", "False", ")", ":", "\n", "        ", "\"\"\" Generates the html output string.\n\n        Parameters\n        ----------\n        result_df : pd.DataFrame\n            DataFrame containing the CCOBRA evaluation results.\n\n        benchmark : dict(str, object)\n            Benchmark properties.\n            \n        model_log : dict(str, dict(str, object))\n            Dictionary containing logging information that models supplied via end_participant.\n\n        embedded : bool\n            Flag indicating embedded usage. Removes CSS and window handling scripts from the\n            resulting website.\n\n        Returns\n        -------\n        str\n            String containing html code representing the CCOBRA evaluation results.\n\n        \"\"\"", "\n", "\n", "result_data", "=", "json", ".", "dumps", "(", "result_df", ".", "to_csv", "(", "index", "=", "False", ")", ".", "split", "(", "'\\n'", ")", ")", "\n", "benchmark", "[", "'date'", "]", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d %H:%M\"", ")", "\n", "\n", "# Construct the content for the website", "\n", "content", "=", "[", "]", "\n", "css_dependencies", "=", "[", "]", "\n", "\n", "for", "evaluation_tuple", "in", "self", ".", "evaluations", ":", "\n", "            ", "eval_handler", ",", "metrics", "=", "evaluation_tuple", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "# Add dependencies", "\n", "                ", "if", "metric", ".", "template_CSS", ":", "\n", "                    ", "css_dependencies", ".", "append", "(", "metric", ".", "template_CSS", ")", "\n", "\n", "# Add HTML content div", "\n", "", "metric_html", "=", "metric", ".", "to_html", "(", "result_df", ",", "eval_handler", ",", "model_log", ")", "\n", "\n", "# Skip metrics if they have no information", "\n", "if", "metric_html", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "metric_tab_data", "=", "(", "metric", ".", "shorttitle", "(", "eval_handler", ")", ".", "lower", "(", ")", ".", "replace", "(", "' '", ",", "'-'", ")", ",", "metric", ".", "shorttitle", "(", "eval_handler", ")", ")", "\n", "\n", "metric_content", "=", "'<div id=\"{}-expand-bar\" class=\"expand-bar\">{}</div>'", ".", "format", "(", "\n", "metric_tab_data", "[", "0", "]", ",", "metric_tab_data", "[", "1", "]", ")", "\n", "metric_content", "+=", "'<div id=\"{}\" class=\"expand-bar-content\">{}</div>'", ".", "format", "(", "\n", "metric_tab_data", "[", "0", "]", ",", "metric_html", ")", "\n", "\n", "content", ".", "append", "(", "metric_content", ")", "\n", "\n", "# Generate auxiliary scripts", "\n", "", "", "scripts", "=", "[", "]", "\n", "if", "not", "embedded", ":", "\n", "            ", "scripts", ".", "append", "(", "'\\n'", ".", "join", "(", "[", "\n", "\"           window.addEventListener('resize', function() {\"", ",", "\n", "\"           var arr = document.getElementsByClassName('trigger_resize_script')\"", ",", "\n", "\"           for (var n = 0; n < arr.length; n++)\"", ",", "\n", "\"               eval(arr[n].innerHTML);\"", ",", "\n", "\"           });\"", "\n", "]", ")", ")", "\n", "\n", "# Construct CSS from visualizer dependencies", "\n", "", "css_content", "=", "''", "\n", "if", "not", "embedded", ":", "\n", "            ", "css_content", "=", "self", ".", "external_contents", "[", "'cssness'", "]", "\n", "for", "fname", "in", "css_dependencies", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "+", "os", ".", "sep", "+", "fname", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "file_handle", ":", "\n", "                    ", "css_content", "+=", "file_handle", ".", "read", "(", ")", "+", "'\\n'", "\n", "\n", "", "", "", "content_dict", "=", "{", "\n", "'CSSNESS'", ":", "css_content", ",", "\n", "'PLOTLY_LIB'", ":", "self", ".", "external_contents", "[", "'plotly'", "]", ",", "\n", "'HTML2CANVAS_LIB'", ":", "self", ".", "external_contents", "[", "'html2canvas'", "]", ",", "\n", "'RESULT_DATA'", ":", "result_data", ",", "\n", "'BENCHMARK'", ":", "json", ".", "dumps", "(", "benchmark", ")", ",", "\n", "'CONTENT'", ":", "'\\n\\n'", ".", "join", "(", "content", ")", ",", "\n", "'SCRIPTS'", ":", "'\\n\\n'", ".", "join", "(", "scripts", ")", "\n", "}", "\n", "\n", "template", "=", "self", ".", "external_contents", "[", "'template'", "]", "\n", "for", "key", ",", "value", "in", "content_dict", ".", "items", "(", ")", ":", "\n", "            ", "template", "=", "template", ".", "replace", "(", "'{{{{{}}}}}'", ".", "format", "(", "key", ")", ",", "value", ")", "\n", "", "return", "template", "\n", "", "", ""]]}