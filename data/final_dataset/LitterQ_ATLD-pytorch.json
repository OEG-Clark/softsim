{"home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_svhn.Attack_None.__init__": [[23, 30], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_svhn.Attack_None.forward": [[31, 38], ["attack_methods_new_svhn.Attack_None.basic_net", "attack_methods_new_svhn.Attack_None.basic_net.train", "attack_methods_new_svhn.Attack_None.basic_net.eval"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_svhn.Attack_PGD.__init__": [[42, 61], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_svhn.Attack_PGD.forward": [[62, 122], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new_svhn.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_svhn.Attack_PGD.basic_net.train", "attack_methods_new_svhn.Attack_PGD.basic_net.eval", "attack_methods_new_svhn.Attack_PGD.basic_net", "torch.softmax.detach", "attack_methods_new_svhn.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ".", "detach", "(", ")", ")", "[", "0", "]", "\n", "\n", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_svhn.Attack_FeaScatter.__init__": [[125, 143], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_svhn.Attack_FeaScatter.forward": [[144, 299], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "pickle.loads.", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "logits_pred_nat.size", "utils.one_hot_tensor_svhn", "utils.label_smoothing", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_svhn.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new_svhn.Attack_FeaScatter.basic_net.train", "attack_methods_new_svhn.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "utils.one_hot_tensor_svhn.size", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new_svhn.Attack_FeaScatter.discriminator.zero_grad", "attack_methods_new_svhn.Attack_FeaScatter.discriminator", "attack_methods_new_svhn.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "utils.softCrossEntropy.", "utils.softCrossEntropy.", "pickle.loads.zero_grad", "attack_methods_new_svhn.Attack_FeaScatter.D_optimizer.zero_grad", "attack_methods_new_svhn.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_svhn.Attack_FeaScatter.basic_net", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "range", "torch.MSELoss.", "print", "numpy.sum", "numpy.sum", "print", "attack_methods_new_svhn.Attack_FeaScatter.basic_net.zero_grad", "utils.softCrossEntropy.", "attack_methods_new_svhn.Attack_FeaScatter.discriminator.zero_grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "print", "pickle.dumps", "pickle.loads", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "utils.label_smoothing.detach", "utils.label_smoothing.detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_svhn.Attack_FeaScatter.discriminator", "attack_methods_new_svhn.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "utils.softCrossEntropy.", "utils.softCrossEntropy.", "print", "attack_methods_new_svhn.Attack_FeaScatter.D_optimizer.zero_grad", "discriminator_loss.backward", "attack_methods_new_svhn.Attack_FeaScatter.D_optimizer.step", "utils.label_smoothing.detach", "gd_adv[].max", "gd_gan[].max", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "utils.label_smoothing.detach", "utils.label_smoothing.detach", "discriminator_loss.item", "logits_fea_nat2.detach().cpu().numpy", "logits_fea_adv2.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "logits_fea_nat2.detach().cpu", "logits_fea_adv2.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "logits_fea_nat2.detach", "logits_fea_adv2.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "alpha", "=", "torch", ".", "rand", "(", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", ")", "\n", "\n", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "logits_pred_nat_D", "=", "torch", ".", "reshape", "(", "logits_pred_nat", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor_svhn", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pred", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "logits_fea_nat", ",", "D_cla_nat", "=", "self", ".", "discriminator", "(", "logits_pred_nat_D", ")", "\n", "#print(logits_fea_nat.shape)", "\n", "logits_fea_adv", ",", "D_cla_adv", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "D_cla_real", "=", "loss_ce", "(", "D_cla_nat", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "D_cla_fake", "=", "loss_ce", "(", "D_cla_adv", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred_2", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "logits_pred_2_D", "=", "torch", ".", "reshape", "(", "logits_pred_2", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "\n", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", ",", "D_cla_adv2", "=", "self", ".", "discriminator", "(", "logits_pred_2_D", ".", "detach", "(", ")", ")", "\n", "logits_fea_nat2", ",", "D_cla_nat2", "=", "self", ".", "discriminator", "(", "logits_pred_nat_D", ".", "detach", "(", ")", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "D_cla_real2", "=", "loss_ce", "(", "D_cla_nat2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "D_cla_fake2", "=", "loss_ce", "(", "D_cla_adv2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "+", "D_cla_real2", "+", "D_cla_fake2", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "", "gan_loss", "=", "mse", "(", "logits_pred_2_D", ",", "logits_pred_nat_D", ")", "\n", "print", "(", "'\\n--------gan_loss:---------*\\n'", ",", "gan_loss", ")", "\n", "\n", "#mse_loss = mse(test_fea_nat, test_fea_adv_2)", "\n", "#print('\\n***********MSE:',mse_loss.item(),'***********\\n')", "\n", "#print(logits_fea_nat)", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred_2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "\n", "gd_gan", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "gan_loss", ",", "inputs", "=", "x", ",", "retain_graph", "=", "True", ")", "\n", "gd_adv", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "adv_loss", ",", "inputs", "=", "x", ",", "retain_graph", "=", "True", ")", "\n", "#print('adv gradient: ', gd_adv[0].mean(), gd_adv[0].max(), gd_adv[0].min())", "\n", "#print('gan gradient: ', gd[0].mean(), gd[0].max(), gd[0].min())", "\n", "scale", "=", "gd_adv", "[", "0", "]", ".", "max", "(", ")", "/", "gd_gan", "[", "0", "]", ".", "max", "(", ")", "\n", "print", "(", "scale", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", ",", "scale", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.fs_eval_svhn.test": [[169, 210], ["net.eval", "tqdm.tqdm", "enumerate", "print", "time.time", "inputs.detach", "targets.long.long", "net", "criterion", "criterion.item", "outputs.max", "targets.long.size", "predicted.eq().sum().item", "tqdm.tqdm.set_description", "inputs.to", "targets.long.to", "time.time", "str", "print", "predicted.eq().sum", "predicted.eq().sum().item", "targets.long.size", "predicted.eq", "predicted.eq().sum", "predicted.eq"], "function", ["None"], ["def", "test", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "iterator", "=", "tqdm", "(", "testloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "pert_inputs", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "targets", "=", "targets", "[", ":", ",", "0", "]", "-", "1", "\n", "targets", "=", "targets", ".", "long", "(", ")", "\n", "\n", "\n", "outputs", ",", "_", "=", "net", "(", "pert_inputs", ",", "targets", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "total", "+=", "batch_size", "\n", "correct_num", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "correct", "+=", "correct_num", "\n", "iterator", ".", "set_description", "(", "\n", "str", "(", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "targets", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"step %d, duration %.2f, test  acc %.2f, avg-acc %.2f, loss %.2f\"", "\n", "%", "(", "batch_idx", ",", "duration", ",", "100.", "*", "correct_num", "/", "batch_size", ",", "\n", "100.", "*", "correct", "/", "total", ",", "test_loss", "/", "total", ")", ")", "\n", "\n", "", "", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "print", "(", "'Val acc:'", ",", "acc", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.fs_eval_imt_svhn.test": [[169, 210], ["net.eval", "tqdm.tqdm", "enumerate", "print", "time.time", "inputs.detach", "targets.long.long", "net", "criterion", "criterion.item", "outputs.max", "targets.long.size", "predicted.eq().sum().item", "tqdm.tqdm.set_description", "inputs.to", "targets.long.to", "time.time", "str", "print", "predicted.eq().sum", "predicted.eq().sum().item", "targets.long.size", "predicted.eq", "predicted.eq().sum", "predicted.eq"], "function", ["None"], ["def", "test", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "iterator", "=", "tqdm", "(", "testloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "pert_inputs", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "targets", "=", "targets", "[", ":", ",", "0", "]", "-", "1", "\n", "targets", "=", "targets", ".", "long", "(", ")", "\n", "\n", "\n", "outputs", ",", "_", "=", "net", "(", "pert_inputs", ",", "targets", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "total", "+=", "batch_size", "\n", "correct_num", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "correct", "+=", "correct_num", "\n", "iterator", ".", "set_description", "(", "\n", "str", "(", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "targets", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"step %d, duration %.2f, test  acc %.2f, avg-acc %.2f, loss %.2f\"", "\n", "%", "(", "batch_idx", ",", "duration", ",", "100.", "*", "correct_num", "/", "batch_size", ",", "\n", "100.", "*", "correct", "/", "total", ",", "test_loss", "/", "total", ")", ")", "\n", "\n", "", "", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "print", "(", "'Val acc:'", ",", "acc", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.ot.sinkhorn_loss_joint_IPOT": [[17, 27], ["ot.get_cost_matrix", "ot.sinkhorn", "C.size", "torch.sum", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.get_cost_matrix", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.sinkhorn"], ["def", "sinkhorn_loss_joint_IPOT", "(", "alpha", ",", "beta", ",", "x_feature", ",", "y_feature", ",", "x_label", ",", "\n", "y_label", ",", "epsilon", ",", "m", ",", "n", ")", ":", "\n", "\n", "    ", "C_fea", "=", "get_cost_matrix", "(", "x_feature", ",", "y_feature", ")", "\n", "C", "=", "C_fea", "\n", "T", "=", "sinkhorn", "(", "C", ",", "0.01", ",", "100", ")", "\n", "# T = IPOT(C, 1)", "\n", "batch_size", "=", "C", ".", "size", "(", "0", ")", "\n", "cost_ot", "=", "torch", ".", "sum", "(", "T", "*", "C", ")", "\n", "return", "cost_ot", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.ot.sinkhorn": [[29, 79], ["C.size", "C.size", "torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.exp", "torch.exp", "torch.exp", "pi.to().float.to().float", "torch.log", "torch.log", "torch.log", "ot.sinkhorn.M"], "function", ["None"], ["", "def", "sinkhorn", "(", "C", ",", "epsilon", ",", "niter", "=", "50", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "m", "=", "C", ".", "size", "(", "0", ")", "\n", "n", "=", "C", ".", "size", "(", "1", ")", "\n", "mu", "=", "Variable", "(", "1.", "/", "m", "*", "torch", ".", "FloatTensor", "(", "m", ")", ".", "fill_", "(", "1", ")", ".", "to", "(", "'cuda'", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "nu", "=", "Variable", "(", "1.", "/", "n", "*", "torch", ".", "FloatTensor", "(", "n", ")", ".", "fill_", "(", "1", ")", ".", "to", "(", "'cuda'", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "\n", "# Parameters of the Sinkhorn algorithm.", "\n", "rho", "=", "1", "# (.5) **2          # unbalanced transport", "\n", "tau", "=", "-", ".8", "# nesterov-like acceleration", "\n", "lam", "=", "rho", "/", "(", "rho", "+", "epsilon", ")", "# Update exponent", "\n", "thresh", "=", "10", "**", "(", "-", "1", ")", "# stopping criterion", "\n", "\n", "# Elementary operations .....................................................................", "\n", "def", "ave", "(", "u", ",", "u1", ")", ":", "\n", "        ", "\"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"", "\n", "return", "tau", "*", "u", "+", "(", "1", "-", "tau", ")", "*", "u1", "\n", "\n", "", "def", "M", "(", "u", ",", "v", ")", ":", "\n", "        ", "\"Modified cost for logarithmic updates\"", "\n", "\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"", "\n", "return", "(", "-", "C", "+", "u", ".", "unsqueeze", "(", "1", ")", "+", "v", ".", "unsqueeze", "(", "0", ")", ")", "/", "epsilon", "\n", "\n", "", "def", "lse", "(", "A", ")", ":", "\n", "        ", "\"log-sum-exp\"", "\n", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "A", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "+", "\n", "1e-6", ")", "# add 10^-6 to prevent NaN", "\n", "\n", "# Actual Sinkhorn loop ......................................................................", "\n", "", "u", ",", "v", ",", "err", "=", "0.", "*", "mu", ",", "0.", "*", "nu", ",", "0.", "\n", "actual_nits", "=", "0", "# to check if algorithm terminates because of threshold or max iterations reached", "\n", "\n", "for", "i", "in", "range", "(", "niter", ")", ":", "\n", "        ", "u1", "=", "u", "# useful to check the update", "\n", "u", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "mu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ")", ".", "squeeze", "(", ")", ")", "+", "u", "\n", "v", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "nu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ".", "t", "(", ")", ")", ".", "squeeze", "(", ")", ")", "+", "v", "\n", "# accelerated unbalanced iterations", "\n", "# u = ave( u, lam * ( epsilon * ( torch.log(mu) - lse(M(u,v)).squeeze()   ) + u ) )", "\n", "# v = ave( v, lam * ( epsilon * ( torch.log(nu) - lse(M(u,v).t()).squeeze() ) + v ) )", "\n", "err", "=", "(", "u", "-", "u1", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "\n", "actual_nits", "+=", "1", "\n", "if", "(", "err", "<", "thresh", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ":", "\n", "            ", "break", "\n", "", "", "U", ",", "V", "=", "u", ",", "v", "\n", "\n", "pi", "=", "torch", ".", "exp", "(", "M", "(", "U", ",", "V", ")", ")", "# Transport plan pi = diag(a)*K*diag(b)", "\n", "pi", "=", "pi", ".", "to", "(", "'cuda'", ")", ".", "float", "(", ")", "\n", "return", "pi", "# return the transport", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.ot.IPOT": [[81, 101], ["cost_matrix.size", "cost_matrix.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.exp", "torch.exp", "torch.exp", "range", "torch.ones().to", "torch.ones().to", "torch.ones().to", "range", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.ones", "torch.ones", "torch.ones", "ot.construct_diag", "ot.construct_diag", "torch.ones", "torch.ones", "torch.ones", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "delta.t"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.construct_diag", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.construct_diag"], ["", "def", "IPOT", "(", "cost_matrix", ",", "beta", "=", "1", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "m", "=", "cost_matrix", ".", "size", "(", "0", ")", "\n", "n", "=", "cost_matrix", ".", "size", "(", "1", ")", "\n", "sigma", "=", "1.0", "/", "n", "*", "torch", ".", "ones", "(", "[", "n", ",", "1", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "T", "=", "torch", ".", "ones", "(", "[", "m", ",", "n", "]", ")", ".", "to", "(", "device", ")", "\n", "A", "=", "torch", ".", "exp", "(", "-", "cost_matrix", "/", "beta", ")", "\n", "\n", "for", "t", "in", "range", "(", "50", ")", ":", "\n", "# BUG: should be elementwise product, * in numpy", "\n", "#Q = torch.mm(A, T)", "\n", "        ", "Q", "=", "A", "*", "T", "# Hardmard product", "\n", "for", "k", "in", "range", "(", "1", ")", ":", "\n", "            ", "delta", "=", "1.0", "/", "(", "m", "*", "torch", ".", "mm", "(", "Q", ",", "sigma", ")", ")", "\n", "sigma", "=", "1.0", "/", "(", "n", "*", "torch", ".", "mm", "(", "delta", ".", "t", "(", ")", ",", "Q", ")", ")", ".", "t", "(", ")", "\n", "#sigma = 1.0 / (n * torch.mv(Q, delta))", "\n", "", "tmp", "=", "torch", ".", "mm", "(", "construct_diag", "(", "torch", ".", "squeeze", "(", "delta", ")", ")", ",", "Q", ")", "\n", "T", "=", "torch", ".", "mm", "(", "tmp", ",", "construct_diag", "(", "torch", ".", "squeeze", "(", "sigma", ")", ")", ")", "\n", "\n", "", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.ot.construct_diag": [[103, 108], ["d.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "d.view", "torch.zeros", "torch.zeros", "torch.zeros", "range", "range"], "function", ["None"], ["", "def", "construct_diag", "(", "d", ")", ":", "\n", "    ", "n", "=", "d", ".", "size", "(", "0", ")", "\n", "x", "=", "torch", ".", "zeros", "(", "[", "n", ",", "n", "]", ")", ".", "to", "(", "d", ".", "device", ")", "\n", "x", "[", "range", "(", "n", ")", ",", "range", "(", "n", ")", "]", "=", "d", ".", "view", "(", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.ot.get_cost_matrix": [[110, 113], ["ot.cost_matrix_cos"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.cost_matrix_cos"], ["", "def", "get_cost_matrix", "(", "x_feature", ",", "y_feature", ")", ":", "\n", "    ", "C_fea", "=", "cost_matrix_cos", "(", "x_feature", ",", "y_feature", ")", "# Wasserstein cost function", "\n", "return", "C_fea", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.ot.cost_matrix_cos": [[115, 127], ["x.unsqueeze", "y.unsqueeze", "torch.CosineSimilarity", "torch.clamp", "torch.clamp", "torch.clamp", "nn.CosineSimilarity."], "function", ["None"], ["", "def", "cost_matrix_cos", "(", "x", ",", "y", ",", "p", "=", "2", ")", ":", "\n", "# return the m*n sized cost matrix", "\n", "    ", "\"Returns the matrix of $|x_i-y_j|^p$.\"", "\n", "# un squeeze differently so that the tensors can broadcast", "\n", "# dim-2 (summed over) is the feature dim", "\n", "x_col", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "y_lin", "=", "y", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "2", ",", "eps", "=", "1e-6", ")", "\n", "c", "=", "torch", ".", "clamp", "(", "1", "-", "cos", "(", "x_col", ",", "y_lin", ")", ",", "min", "=", "0", ")", "\n", "\n", "return", "c", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.fs_main_svhn.print_para": [[181, 187], ["net.named_parameters", "print", "print"], "function", ["None"], ["", "def", "print_para", "(", "net", ")", ":", "\n", "    ", "for", "name", ",", "param", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "requires_grad", ":", "\n", "            ", "print", "(", "name", ")", "\n", "print", "(", "param", ".", "data", ")", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.fs_main_svhn.train_fun": [[251, 349], ["print", "net.train", "torch.BCELoss", "tqdm.tqdm", "enumerate", "outputs.max", "targets.long.size", "targets.long.long", "predicted.eq().sum().item", "time.time", "optimizer.zero_grad", "net_org", "optimizer.zero_grad", "loss_fs.mean", "print", "loss_fs.mean.backward", "net.named_parameters", "optimizer.step", "loss_fs.mean.item", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "inputs.to", "targets.long.to", "inputs.detach", "loss_fs.item", "time.time", "tqdm.tqdm.set_description", "net_org", "fs_main_svhn.train_fun.get_acc"], "function", ["None"], ["def", "train_fun", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "print", "(", "'\\nEpoch: %d'", "%", "epoch", ")", "\n", "net", ".", "train", "(", ")", "\n", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "# update learning rate", "\n", "if", "epoch", "<", "args", ".", "decay_epoch1", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "\n", "", "elif", "epoch", "<", "args", ".", "decay_epoch2", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "*", "args", ".", "decay_rate", "\n", "", "else", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "*", "args", ".", "decay_rate", "*", "args", ".", "decay_rate", "\n", "", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "", "def", "get_acc", "(", "outputs", ",", "targets", ")", ":", "\n", "        ", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "=", "targets", ".", "size", "(", "0", ")", "\n", "targets", "=", "targets", ".", "long", "(", ")", "\n", "correct", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "acc", "=", "1.0", "*", "correct", "/", "total", "\n", "return", "acc", "\n", "\n", "", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "iterator", "=", "tqdm", "(", "trainloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "adv_acc", "=", "0", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# forward", "\n", "outputs", ",", "loss_fs", ",", "gan_loss", ",", "scale", "=", "net_org", "(", "inputs", ".", "detach", "(", ")", ",", "targets", ")", "\n", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "loss_fs", ".", "mean", "(", ")", "\n", "print", "(", "'loss_fs:'", ",", "loss_fs", ".", "item", "(", ")", ")", "\n", "#print('gan_loss:', gan_loss.item())", "\n", "loss", "=", "(", "loss", "+", "gan_loss", "*", "scale", "/", "2", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "for", "name", ",", "parms", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "==", "'module.final_layer.weight'", ":", "\n", "                ", "max", "=", "torch", ".", "max", "(", "parms", ".", "grad", ")", "\n", "min", "=", "torch", ".", "min", "(", "parms", ".", "grad", ")", "\n", "diff", "=", "(", "max", "-", "min", ")", "*", "0.3", "\n", "\n", "max_threshold", "=", "max", "-", "diff", "\n", "min_threshold", "=", "min", "+", "diff", "\n", "\n", "parms", ".", "grad", "=", "parms", ".", "grad", ".", "clamp", "(", "min_threshold", ",", "max_threshold", ")", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "train_loss", "=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "if", "adv_acc", "==", "0", ":", "\n", "                ", "adv_acc", "=", "get_acc", "(", "outputs", ",", "targets", ")", "\n", "", "iterator", ".", "set_description", "(", "str", "(", "adv_acc", ")", ")", "\n", "\n", "nat_outputs", ",", "_", "=", "net_org", "(", "inputs", ",", "targets", ",", "attack", "=", "False", ")", "\n", "nat_acc", "=", "get_acc", "(", "nat_outputs", ",", "targets", ")", "\n", "\n", "print", "(", "\n", "\"epoch %d, step %d, lr %.4f, duration %.2f, training nat acc %.2f, training adv acc %.2f, training adv loss %.4f\"", "\n", "%", "(", "epoch", ",", "batch_idx", ",", "lr", ",", "duration", ",", "100", "*", "nat_acc", ",", "\n", "100", "*", "adv_acc", ",", "train_loss", ")", ")", "\n", "\n", "", "", "if", "epoch", "%", "args", ".", "save_epochs", "==", "0", "or", "epoch", ">=", "args", ".", "max_epoch", "-", "2", ":", "\n", "        ", "print", "(", "'Saving..'", ")", "\n", "f_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "(", "'checkpoint-%s'", "%", "epoch", ")", ")", "\n", "state", "=", "{", "\n", "'net'", ":", "net_org", ".", "state_dict", "(", ")", ",", "\n", "# 'optimizer': optimizer.state_dict()", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "args", ".", "model_dir", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "f_path", ")", "\n", "\n", "", "if", "epoch", ">=", "0", ":", "\n", "        ", "print", "(", "'Saving latest @ epoch %s..'", "%", "(", "epoch", ")", ")", "\n", "f_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "'latest'", ")", "\n", "state", "=", "{", "\n", "'net'", ":", "net_org", ".", "state_dict", "(", ")", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'D_optimizer'", ":", "D_optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "args", ".", "model_dir", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "f_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new.Attack_None.__init__": [[23, 30], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new.Attack_None.forward": [[31, 38], ["attack_methods_new.Attack_None.basic_net", "attack_methods_new.Attack_None.basic_net.train", "attack_methods_new.Attack_None.basic_net.eval"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new.Attack_PGD.__init__": [[42, 61], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new.Attack_PGD.forward": [[62, 123], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new.Attack_PGD.basic_net.train", "attack_methods_new.Attack_PGD.basic_net.eval", "attack_methods_new.Attack_PGD.basic_net", "torch.softmax.detach", "attack_methods_new.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "#print(targets)", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ".", "detach", "(", ")", ")", "[", "0", "]", "\n", "\n", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new.Attack_FeaScatter.__init__": [[126, 144], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new.Attack_FeaScatter.forward": [[145, 308], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.loads.", "logits_pred_nat.size", "utils.one_hot_tensor_svhn", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new.Attack_FeaScatter.basic_net.train", "attack_methods_new.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "pickle.loads.zero_grad", "attack_methods_new.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new.Attack_FeaScatter.basic_net", "range", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "numpy.sum", "numpy.sum", "print", "attack_methods_new.Attack_FeaScatter.basic_net.zero_grad", "utils.label_smoothing", "utils.softCrossEntropy.", "pickle.dumps", "pickle.loads", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "print", "discriminator_loss.backward", "attack_methods_new.Attack_FeaScatter.D_optimizer.step", "utils.one_hot_tensor_svhn.size", "utils.label_smoothing.detach", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "discriminator_loss.item", "attack_methods_new.Attack_FeaScatter.detach().cpu().numpy", "attack_methods_new.Attack_FeaScatter.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "attack_methods_new.Attack_FeaScatter.detach().cpu", "attack_methods_new.Attack_FeaScatter.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "attack_methods_new.Attack_FeaScatter.detach", "attack_methods_new.Attack_FeaScatter.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "#discriminator = Discriminator().cuda()", "\n", "\n", "#logits = aux_net(inputs)[0]", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor_svhn", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "#y_gt = one_hot_tensor(targets, num_classes, device)", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "#valid = Variable(torch.rand(x.size(0),1)*0.5 + 0.7).cuda()", "\n", "#fake = Variable(torch.rand(x.size(0),1)*0.3).cuda()", "\n", "\n", "\n", "\n", "logits_fea_nat", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(logits_fea_nat)", "\n", "logits_fea_adv", "=", "self", ".", "discriminator", "(", "test_fea_adv", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "#discriminator_loss = adversarial_criterion(logits_fea_nat, target_real) + adversarial_criterion(logits_fea_adv, target_fake)", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "#discriminator_loss = logits_fea_adv.mean() - logits_fea_nat.mean()", "\n", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "\n", "#discriminator_loss = logits_fea_adv2.mean()-logits_fea_nat2.mean()", "\n", "'''\n                #alpha = torch.rand(x.size(0), 1)\n                #alpha = alpha.expand(x.size(0), test_fea_nat.nelement() / x.size(0)).contiguous().view(x.size(0), 640, 8,8)\n                alpha = torch.rand(x.size(0), 1, 1, 1)\n                alpha = alpha.expand_as(test_fea_nat)\n                alpha = alpha.cuda()\n                #print(alpha.shape)\n                interpolates = alpha * test_fea_nat + ((1 - alpha) * test_fea_adv_2).cuda()\n                interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n                disc_interpolates = self.discriminator(interpolates)\n\n                gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                                          grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n                                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n                gradients = gradients.view(gradients.size(0), -1)\n\n                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n                discriminator_loss += gradient_penalty\n                '''", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "\n", "gan_loss1", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "valid", ")", "\n", "#gan_loss2 = adversarial_criterion(logits_fea_nat2, fake)", "\n", "gan_loss", "=", "gan_loss1", "#+ gan_loss2", "\n", "#gan_loss = -logits_fea_adv2.mean()", "\n", "\n", "#mse_loss = mse(test_fea_nat, test_fea_adv_2)", "\n", "#print('\\n***********MSE:',mse_loss.item(),'***********\\n')", "\n", "#print(logits_fea_nat)", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_imt_svhn.Attack_None.__init__": [[24, 34], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "step_size", "=", "2.0", "/", "255", "*", "2.0", "\n", "self", ".", "epsilon", "=", "8.0", "/", "255", "*", "2.0", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_imt_svhn.Attack_None.forward": [[35, 76], ["torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "attack_methods_new_imt_svhn.Attack_None.basic_net", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_imt_svhn.Attack_None.basic_net.train", "attack_methods_new_imt_svhn.Attack_None.basic_net.eval", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "attack_methods_new_imt_svhn.Attack_None.discriminator", "torch.BCELoss.", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "enumerate", "mask.expand_as.expand_as.expand_as", "attack_methods_new_imt_svhn.Attack_None.D_optimizer.zero_grad", "attack_methods_new_imt_svhn.Attack_None.discriminator.zero_grad", "adv_loss.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_svhn.Attack_None.basic_net", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "numpy.ones", "numpy.ones", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "x", "=", "inputs", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "            ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "logits_pert", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "\n", "#------------imt--------------", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "for", "idxxx", "in", "range", "(", "1", ")", ":", "\n", "            ", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pert", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "logits_fea", ",", "D_cla", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "loss_D", "=", "adversarial_criterion", "(", "logits_fea", ",", "valid", ")", "\n", "mask", "=", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ")", ")", ".", "cuda", "(", ")", "\n", "for", "index", ",", "qq", "in", "enumerate", "(", "logits_fea", ")", ":", "\n", "                ", "if", "0.3", "<", "qq", "<", "0.7", ":", "\n", "                    ", "mask", "[", "index", "]", "=", "0.5", "\n", "", "", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "#print(mask)", "\n", "\n", "adv_loss", "=", "loss_D", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "#print(x.grad)", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "4", "*", "1.0", "*", "mask", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "x", "-", "self", ".", "epsilon", "*", "mask", "*", "1.0", ")", ",", "\n", "x", "+", "self", ".", "epsilon", "*", "mask", "*", "1.0", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "outputs", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_imt_svhn.Attack_PGD.__init__": [[80, 100], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_imt_svhn.Attack_PGD.forward": [[101, 193], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new_imt_svhn.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "attack_methods_new_imt_svhn.Attack_PGD.basic_net.train", "attack_methods_new_imt_svhn.Attack_PGD.basic_net.eval", "pickle.loads.", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "attack_methods_new_imt_svhn.Attack_PGD.discriminator", "torch.BCELoss.", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "enumerate", "mask.expand_as.expand_as.expand_as", "attack_methods_new_imt_svhn.Attack_PGD.D_optimizer.zero_grad", "attack_methods_new_imt_svhn.Attack_PGD.discriminator.zero_grad", "adv_loss.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.softmax.detach", "attack_methods_new_imt_svhn.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_svhn.Attack_PGD.basic_net", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "numpy.ones", "numpy.ones", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "#logits_pert = self.basic_net(x)[0]", "\n", "", "logits_pert", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "#--------imt---------------#", "\n", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "for", "idxxx", "in", "range", "(", "1", ")", ":", "\n", "            ", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pert", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "logits_fea", ",", "D_cla", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "loss_D", "=", "adversarial_criterion", "(", "logits_fea", ",", "valid", ")", "\n", "#print(logits_fea)", "\n", "mask", "=", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ")", ")", ".", "cuda", "(", ")", "\n", "for", "index", ",", "qq", "in", "enumerate", "(", "logits_fea", ")", ":", "\n", "                ", "if", "0.3", "<", "qq", "<", "0.6", ":", "\n", "                    ", "mask", "[", "index", "]", "=", "0.5", "\n", "", "", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "#print(mask)", "\n", "\n", "adv_loss", "=", "loss_D", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "#print(x.grad)", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "4", "*", "1.0", "*", "mask", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "x", "-", "self", ".", "epsilon", "*", "mask", "*", "1.0", ")", ",", "\n", "x", "+", "self", ".", "epsilon", "*", "mask", "*", "1.0", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_imt_svhn.Attack_FeaScatter.__init__": [[196, 214], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.attack_methods_new_imt_svhn.Attack_FeaScatter.forward": [[215, 378], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.loads.", "logits_pred_nat.size", "utils.one_hot_tensor_svhn", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_imt_svhn.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new_imt_svhn.Attack_FeaScatter.basic_net.train", "attack_methods_new_imt_svhn.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new_imt_svhn.Attack_FeaScatter.discriminator", "attack_methods_new_imt_svhn.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "pickle.loads.zero_grad", "attack_methods_new_imt_svhn.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_imt_svhn.Attack_FeaScatter.basic_net", "range", "attack_methods_new_imt_svhn.Attack_FeaScatter.discriminator", "attack_methods_new_imt_svhn.Attack_FeaScatter.discriminator", "torch.BCELoss.", "numpy.sum", "numpy.sum", "print", "attack_methods_new_imt_svhn.Attack_FeaScatter.basic_net.zero_grad", "utils.label_smoothing", "utils.softCrossEntropy.", "pickle.dumps", "pickle.loads", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_svhn.Attack_FeaScatter.discriminator", "attack_methods_new_imt_svhn.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "print", "discriminator_loss.backward", "attack_methods_new_imt_svhn.Attack_FeaScatter.D_optimizer.step", "utils.one_hot_tensor_svhn.size", "utils.label_smoothing.detach", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "discriminator_loss.item", "attack_methods_new_imt_svhn.Attack_FeaScatter.detach().cpu().numpy", "attack_methods_new_imt_svhn.Attack_FeaScatter.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "attack_methods_new_imt_svhn.Attack_FeaScatter.detach().cpu", "attack_methods_new_imt_svhn.Attack_FeaScatter.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "attack_methods_new_imt_svhn.Attack_FeaScatter.detach", "attack_methods_new_imt_svhn.Attack_FeaScatter.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "#discriminator = Discriminator().cuda()", "\n", "\n", "#logits = aux_net(inputs)[0]", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor_svhn", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "#y_gt = one_hot_tensor(targets, num_classes, device)", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "#valid = Variable(torch.rand(x.size(0),1)*0.5 + 0.7).cuda()", "\n", "#fake = Variable(torch.rand(x.size(0),1)*0.3).cuda()", "\n", "\n", "\n", "\n", "logits_fea_nat", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(logits_fea_nat)", "\n", "logits_fea_adv", "=", "self", ".", "discriminator", "(", "test_fea_adv", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "#discriminator_loss = adversarial_criterion(logits_fea_nat, target_real) + adversarial_criterion(logits_fea_adv, target_fake)", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "#discriminator_loss = logits_fea_adv.mean() - logits_fea_nat.mean()", "\n", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "\n", "#discriminator_loss = logits_fea_adv2.mean()-logits_fea_nat2.mean()", "\n", "'''\n                #alpha = torch.rand(x.size(0), 1)\n                #alpha = alpha.expand(x.size(0), test_fea_nat.nelement() / x.size(0)).contiguous().view(x.size(0), 640, 8,8)\n                alpha = torch.rand(x.size(0), 1, 1, 1)\n                alpha = alpha.expand_as(test_fea_nat)\n                alpha = alpha.cuda()\n                #print(alpha.shape)\n                interpolates = alpha * test_fea_nat + ((1 - alpha) * test_fea_adv_2).cuda()\n                interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n                disc_interpolates = self.discriminator(interpolates)\n\n                gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                                          grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n                                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n                gradients = gradients.view(gradients.size(0), -1)\n\n                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n                discriminator_loss += gradient_penalty\n                '''", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "\n", "gan_loss1", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "valid", ")", "\n", "#gan_loss2 = adversarial_criterion(logits_fea_nat2, fake)", "\n", "gan_loss", "=", "gan_loss1", "#+ gan_loss2", "\n", "#gan_loss = -logits_fea_adv2.mean()", "\n", "\n", "#mse_loss = mse(test_fea_nat, test_fea_adv_2)", "\n", "#print('\\n***********MSE:',mse_loss.item(),'***********\\n')", "\n", "#print(logits_fea_nat)", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.softCrossEntropy.__init__": [[49, 53], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "super", "(", "softCrossEntropy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reduce", "=", "reduce", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.softCrossEntropy.forward": [[54, 68], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: predictions\n        :param targets: target labels in vector form\n        :return: loss\n        \"\"\"", "\n", "log_likelihood", "=", "-", "F", ".", "log_softmax", "(", "inputs", ",", "dim", "=", "1", ")", "\n", "sample_num", ",", "class_num", "=", "targets", ".", "shape", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "loss", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "log_likelihood", ",", "targets", ")", ")", "/", "sample_num", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "log_likelihood", ",", "targets", ")", ",", "1", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.CWLoss.__init__": [[71, 77], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", ",", "margin", "=", "50", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "super", "(", "CWLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "reduce", "=", "reduce", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.CWLoss.forward": [[78, 98], ["utils.one_hot_tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: predictions\n        :param targets: target labels\n        :return: loss\n        \"\"\"", "\n", "onehot_targets", "=", "one_hot_tensor", "(", "targets", ",", "self", ".", "num_classes", ",", "\n", "targets", ".", "device", ")", "\n", "\n", "self_loss", "=", "torch", ".", "sum", "(", "onehot_targets", "*", "logits", ",", "dim", "=", "1", ")", "\n", "other_loss", "=", "torch", ".", "max", "(", "\n", "(", "1", "-", "onehot_targets", ")", "*", "logits", "-", "onehot_targets", "*", "1000", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "torch", ".", "clamp", "(", "self_loss", "-", "other_loss", "+", "self", ".", "margin", ",", "0", ")", ")", "\n", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "sample_num", "=", "onehot_targets", ".", "shape", "[", "0", "]", "\n", "loss", "=", "loss", "/", "sample_num", "\n", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.one_hot_tensor": [[21, 26], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "y_batch_tensor.size", "numpy.arange", "len"], "function", ["None"], ["def", "one_hot_tensor", "(", "y_batch_tensor", ",", "num_classes", ",", "device", ")", ":", "\n", "    ", "y_tensor", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "y_batch_tensor", ".", "size", "(", "0", ")", ",", "\n", "num_classes", ")", ".", "fill_", "(", "0", ")", "\n", "y_tensor", "[", "np", ".", "arange", "(", "len", "(", "y_batch_tensor", ")", ")", ",", "y_batch_tensor", "]", "=", "1.0", "\n", "return", "y_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.one_hot_tensor_svhn": [[27, 36], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "y_batch_tensor[].long", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "y_batch_tensor[].long.size", "numpy.arange", "len"], "function", ["None"], ["", "def", "one_hot_tensor_svhn", "(", "y_batch_tensor", ",", "num_classes", ",", "device", ")", ":", "\n", "    ", "y_tensor", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "y_batch_tensor", ".", "size", "(", "0", ")", ",", "\n", "num_classes", ")", ".", "fill_", "(", "0", ")", "\n", "y_batch_tensor", "=", "y_batch_tensor", "-", "1.0", "\n", "y_batch_tensor", "=", "y_batch_tensor", "[", ":", ",", "0", "]", ".", "long", "(", ")", "\n", "#print(y_batch_tensor.type())", "\n", "y_tensor", "[", "np", ".", "arange", "(", "len", "(", "y_batch_tensor", ")", ")", ",", "y_batch_tensor", "]", "=", "1.0", "\n", "#print(y_tensor.type())", "\n", "return", "y_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.label_smoothing": [[38, 42], ["None"], "function", ["None"], ["", "def", "label_smoothing", "(", "y_batch_tensor", ",", "num_classes", ",", "delta", ")", ":", "\n", "    ", "y_batch_smooth", "=", "(", "1", "-", "delta", "-", "delta", "/", "(", "num_classes", "-", "1", ")", ")", "*", "y_batch_tensor", "+", "delta", "/", "(", "num_classes", "-", "1", ")", "\n", "return", "y_batch_smooth", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.svhn.utils.str2bool": [[44, 46], ["v.lower"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "lower", "(", ")", "in", "(", "\"yes\"", ",", "\"true\"", ",", "\"t\"", ",", "\"1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.wideresnet.BasicBlock.__init__": [[8, 35], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "stride", ",", "dropRate", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "in_planes", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "out_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "droprate", "=", "dropRate", "\n", "self", ".", "equalInOut", "=", "(", "in_planes", "==", "out_planes", ")", "\n", "self", ".", "convShortcut", "=", "(", "not", "self", ".", "equalInOut", ")", "and", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", "or", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.wideresnet.BasicBlock.forward": [[36, 46], ["wideresnet.BasicBlock.relu2", "wideresnet.BasicBlock.conv2", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "wideresnet.BasicBlock.relu1", "wideresnet.BasicBlock.relu1", "wideresnet.BasicBlock.bn2", "torch.dropout", "torch.dropout", "torch.dropout", "wideresnet.BasicBlock.bn1", "wideresnet.BasicBlock.bn1", "wideresnet.BasicBlock.conv1", "wideresnet.BasicBlock.convShortcut"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "equalInOut", ":", "\n", "            ", "x", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "out", "=", "self", ".", "relu2", "(", "self", ".", "bn2", "(", "self", ".", "conv1", "(", "out", "if", "self", ".", "equalInOut", "else", "x", ")", ")", ")", "\n", "if", "self", ".", "droprate", ">", "0", ":", "\n", "            ", "out", "=", "F", ".", "dropout", "(", "out", ",", "p", "=", "self", ".", "droprate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "return", "torch", ".", "add", "(", "x", "if", "self", ".", "equalInOut", "else", "self", ".", "convShortcut", "(", "x", ")", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.wideresnet.NetworkBlock.__init__": [[49, 59], ["torch.Module.__init__", "wideresnet.NetworkBlock._make_layer"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.NetworkBlock_2._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "nb_layers", ",", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "block", ",", "\n", "stride", ",", "\n", "dropRate", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "NetworkBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "self", ".", "_make_layer", "(", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "\n", "stride", ",", "dropRate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.wideresnet.NetworkBlock._make_layer": [[60, 68], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "int", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "\n", "dropRate", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_layers", ")", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "i", "==", "0", "and", "in_planes", "or", "out_planes", ",", "out_planes", ",", "\n", "i", "==", "0", "and", "stride", "or", "1", ",", "dropRate", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.wideresnet.NetworkBlock.forward": [[69, 71], ["wideresnet.NetworkBlock.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "layer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.wideresnet.WideResNet.__init__": [[74, 113], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "wideresnet.NetworkBlock", "wideresnet.NetworkBlock", "wideresnet.NetworkBlock", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "wideresnet.WideResNet.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ",", "num_classes", ",", "widen_factor", "=", "1", ",", "dropRate", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "WideResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nChannels", "=", "[", "\n", "16", ",", "16", "*", "widen_factor", ",", "32", "*", "widen_factor", ",", "64", "*", "widen_factor", "\n", "]", "\n", "assert", "(", "(", "depth", "-", "4", ")", "%", "6", "==", "0", ")", "\n", "n", "=", "(", "depth", "-", "4", ")", "/", "6", "\n", "block", "=", "BasicBlock", "\n", "# 1st conv before any network block", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "\n", "nChannels", "[", "0", "]", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "# 1st block", "\n", "self", ".", "block1", "=", "NetworkBlock", "(", "n", ",", "nChannels", "[", "0", "]", ",", "nChannels", "[", "1", "]", ",", "block", ",", "1", ",", "\n", "dropRate", ")", "\n", "# 2nd block", "\n", "self", ".", "block2", "=", "NetworkBlock", "(", "n", ",", "nChannels", "[", "1", "]", ",", "nChannels", "[", "2", "]", ",", "block", ",", "2", ",", "\n", "dropRate", ")", "\n", "# 3rd block", "\n", "self", ".", "block3", "=", "NetworkBlock", "(", "n", ",", "nChannels", "[", "2", "]", ",", "nChannels", "[", "3", "]", ",", "block", ",", "2", ",", "\n", "dropRate", ")", "\n", "# global average pooling and classifier", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "nChannels", "[", "3", "]", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "nChannels", "[", "3", "]", ",", "num_classes", ")", "\n", "self", ".", "nChannels", "=", "nChannels", "[", "3", "]", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.wideresnet.WideResNet.forward": [[114, 125], ["wideresnet.WideResNet.conv1", "wideresnet.WideResNet.block1", "wideresnet.WideResNet.block2", "wideresnet.WideResNet.block3", "wideresnet.WideResNet.relu", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "out.view.view.view", "wideresnet.WideResNet.bn1", "wideresnet.WideResNet.fc", "out.view.view.view", "x.size"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "block1", "(", "out", ")", "\n", "out", "=", "self", ".", "block2", "(", "out", ")", "\n", "out", "=", "self", ".", "block3", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "out", ")", ")", "\n", "fea", "=", "out", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "8", ")", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "self", ".", "nChannels", ")", "\n", "\n", "return", "self", ".", "fc", "(", "out", ")", ",", "out", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "fea", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.FeatureExtractor.__init__": [[15, 18], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "list", "cnn.features.children"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cnn", ",", "feature_layer", "=", "11", ")", ":", "\n", "        ", "super", "(", "FeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "cnn", ".", "features", ".", "children", "(", ")", ")", "[", ":", "(", "feature_layer", "+", "1", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.FeatureExtractor.forward": [[19, 21], ["dis.FeatureExtractor.features"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "features", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.residualBlock.__init__": [[24, 31], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", "=", "64", ",", "k", "=", "3", ",", "n", "=", "64", ",", "s", "=", "1", ")", ":", "\n", "        ", "super", "(", "residualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "n", ",", "k", ",", "stride", "=", "s", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "n", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "n", ",", "n", ",", "k", ",", "stride", "=", "s", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.residualBlock.forward": [[32, 35], ["dis.swish", "dis.residualBlock.bn1", "dis.residualBlock.bn2", "dis.residualBlock.conv1", "dis.residualBlock.conv2"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "swish", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "return", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "y", ")", ")", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.upsampleBlock.__init__": [[38, 42], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", "upsampleBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "shuffler", "=", "nn", ".", "PixelShuffle", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.upsampleBlock.forward": [[43, 45], ["dis.swish", "dis.upsampleBlock.shuffler", "dis.upsampleBlock.conv"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "swish", "(", "self", ".", "shuffler", "(", "self", ".", "conv", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.Generator.__init__": [[47, 64], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "dis.Generator.add_module", "dis.Generator.add_module", "dis.residualBlock", "dis.upsampleBlock", "str", "str"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_residual_blocks", ",", "upsample_factor", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_residual_blocks", "=", "n_residual_blocks", "\n", "self", ".", "upsample_factor", "=", "upsample_factor", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "9", ",", "stride", "=", "1", ",", "padding", "=", "4", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_residual_blocks", ")", ":", "\n", "            ", "self", ".", "add_module", "(", "'residual_block'", "+", "str", "(", "i", "+", "1", ")", ",", "residualBlock", "(", ")", ")", "\n", "\n", "", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "upsample_factor", "/", "2", ")", ":", "\n", "            ", "self", ".", "add_module", "(", "'upsample'", "+", "str", "(", "i", "+", "1", ")", ",", "upsampleBlock", "(", "64", ",", "256", ")", ")", "\n", "\n", "", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "64", ",", "3", ",", "9", ",", "stride", "=", "1", ",", "padding", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.Generator.forward": [[65, 78], ["dis.swish", "swish.clone", "range", "range", "dis.Generator.conv3", "dis.Generator.conv1", "dis.Generator.bn2", "dis.Generator.__getattr__", "dis.Generator.conv2", "dis.Generator.__getattr__", "str", "str"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "swish", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "\n", "y", "=", "x", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_residual_blocks", ")", ":", "\n", "            ", "y", "=", "self", ".", "__getattr__", "(", "'residual_block'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "y", ")", "\n", "\n", "", "x", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "y", ")", ")", "+", "x", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "upsample_factor", "/", "2", ")", ":", "\n", "            ", "x", "=", "self", ".", "__getattr__", "(", "'upsample'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "x", ")", "\n", "\n", "", "return", "self", ".", "conv3", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.Discriminator.__init__": [[80, 101], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "640", ",", "64", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn4", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "conv5", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn5", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "conv6", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn6", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "conv7", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn7", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "conv8", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn8", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "# Replaced original paper FC layers with FCN", "\n", "self", ".", "conv9", "=", "nn", ".", "Conv2d", "(", "512", ",", "1", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.Discriminator.forward": [[102, 115], ["dis.swish", "dis.swish", "dis.swish", "dis.swish", "dis.swish", "dis.swish", "dis.swish", "dis.swish", "dis.Discriminator.conv9", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "dis.Discriminator.conv1", "dis.Discriminator.bn2", "dis.Discriminator.bn3", "dis.Discriminator.bn4", "dis.Discriminator.bn5", "dis.Discriminator.bn6", "dis.Discriminator.bn7", "dis.Discriminator.bn8", "dis.Discriminator.conv2", "dis.Discriminator.conv3", "dis.Discriminator.conv4", "dis.Discriminator.conv5", "dis.Discriminator.conv6", "dis.Discriminator.conv7", "dis.Discriminator.conv8", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "dis.Discriminator.size", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "dis.Discriminator.size"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "swish", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "\n", "x", "=", "swish", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "swish", "(", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "x", ")", ")", ")", "\n", "x", "=", "swish", "(", "self", ".", "bn4", "(", "self", ".", "conv4", "(", "x", ")", ")", ")", "\n", "x", "=", "swish", "(", "self", ".", "bn5", "(", "self", ".", "conv5", "(", "x", ")", ")", ")", "\n", "x", "=", "swish", "(", "self", ".", "bn6", "(", "self", ".", "conv6", "(", "x", ")", ")", ")", "\n", "x", "=", "swish", "(", "self", ".", "bn7", "(", "self", ".", "conv7", "(", "x", ")", ")", ")", "\n", "x", "=", "swish", "(", "self", ".", "bn8", "(", "self", ".", "conv8", "(", "x", ")", ")", ")", "\n", "\n", "x", "=", "self", ".", "conv9", "(", "x", ")", "\n", "return", "F", ".", "sigmoid", "(", "F", ".", "avg_pool2d", "(", "x", ",", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", ".", "view", "(", "x", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "#return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.BasicBlock_2.__init__": [[124, 151], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "stride", ",", "dropRate", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "BasicBlock_2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "in_planes", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "out_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "droprate", "=", "dropRate", "\n", "self", ".", "equalInOut", "=", "(", "in_planes", "==", "out_planes", ")", "\n", "self", ".", "convShortcut", "=", "(", "not", "self", ".", "equalInOut", ")", "and", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", "or", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.BasicBlock_2.forward": [[152, 162], ["dis.BasicBlock_2.relu2", "dis.BasicBlock_2.conv2", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "dis.BasicBlock_2.relu1", "dis.BasicBlock_2.relu1", "dis.BasicBlock_2.bn2", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "dis.BasicBlock_2.bn1", "dis.BasicBlock_2.bn1", "dis.BasicBlock_2.conv1", "dis.BasicBlock_2.convShortcut"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "equalInOut", ":", "\n", "            ", "x", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "out", "=", "self", ".", "relu2", "(", "self", ".", "bn2", "(", "self", ".", "conv1", "(", "out", "if", "self", ".", "equalInOut", "else", "x", ")", ")", ")", "\n", "if", "self", ".", "droprate", ">", "0", ":", "\n", "            ", "out", "=", "F", ".", "dropout", "(", "out", ",", "p", "=", "self", ".", "droprate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "return", "torch", ".", "add", "(", "x", "if", "self", ".", "equalInOut", "else", "self", ".", "convShortcut", "(", "x", ")", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.NetworkBlock_2.__init__": [[165, 175], ["torch.Module.__init__", "dis.NetworkBlock_2._make_layer"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.NetworkBlock_2._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "nb_layers", ",", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "block", ",", "\n", "stride", ",", "\n", "dropRate", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "NetworkBlock_2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "self", ".", "_make_layer", "(", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "\n", "stride", ",", "dropRate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.NetworkBlock_2._make_layer": [[176, 184], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "int", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "\n", "dropRate", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_layers", ")", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "i", "==", "0", "and", "in_planes", "or", "out_planes", ",", "out_planes", ",", "\n", "i", "==", "0", "and", "stride", "or", "1", ",", "dropRate", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.NetworkBlock_2.forward": [[185, 187], ["dis.NetworkBlock_2.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "layer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.Discriminator_2.__init__": [[190, 230], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "dis.NetworkBlock_2", "dis.NetworkBlock_2", "dis.NetworkBlock_2", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "dis.Discriminator_2.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ",", "num_classes", ",", "widen_factor", "=", "1", ",", "dropRate", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "Discriminator_2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nChannels", "=", "[", "\n", "16", ",", "16", "*", "widen_factor", ",", "32", "*", "widen_factor", ",", "64", "*", "widen_factor", "\n", "]", "\n", "assert", "(", "(", "depth", "-", "4", ")", "%", "6", "==", "0", ")", "\n", "n", "=", "(", "depth", "-", "4", ")", "/", "6", "\n", "block", "=", "BasicBlock_2", "\n", "# 1st conv before any network block", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "10", ",", "#cifar100 100,svhn 10", "\n", "nChannels", "[", "0", "]", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "# 1st block", "\n", "self", ".", "block1", "=", "NetworkBlock_2", "(", "n", ",", "nChannels", "[", "0", "]", ",", "nChannels", "[", "1", "]", ",", "block", ",", "1", ",", "\n", "dropRate", ")", "\n", "# 2nd block", "\n", "self", ".", "block2", "=", "NetworkBlock_2", "(", "n", ",", "nChannels", "[", "1", "]", ",", "nChannels", "[", "2", "]", ",", "block", ",", "2", ",", "\n", "dropRate", ")", "\n", "# 3rd block", "\n", "self", ".", "block3", "=", "NetworkBlock_2", "(", "n", ",", "nChannels", "[", "2", "]", ",", "nChannels", "[", "3", "]", ",", "block", ",", "2", ",", "\n", "dropRate", ")", "\n", "# global average pooling and classifier", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "nChannels", "[", "3", "]", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "nChannels", "[", "3", "]", ",", "num_classes", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "nChannels", "[", "3", "]", ",", "10", ")", "\n", "self", ".", "nChannels", "=", "nChannels", "[", "3", "]", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.Discriminator_2.forward": [[231, 251], ["dis.Discriminator_2.conv1", "dis.Discriminator_2.block1", "dis.Discriminator_2.block2", "dis.Discriminator_2.block3", "dis.Discriminator_2.relu", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "out.view.view.view", "dis.Discriminator_2.fc", "dis.Discriminator_2.fc2", "dis.Discriminator_2.bn1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#print(x.shape)", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "#print(out.shape)", "\n", "out", "=", "self", ".", "block1", "(", "out", ")", "\n", "#print(out.shape)", "\n", "out", "=", "self", ".", "block2", "(", "out", ")", "\n", "#print(out.shape)", "\n", "out", "=", "self", ".", "block3", "(", "out", ")", "\n", "#print(out.shape)", "\n", "out", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "out", ")", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "1", ")", "\n", "#print(out.shape)", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "self", ".", "nChannels", ")", "\n", "\n", "out1", "=", "self", ".", "fc", "(", "out", ")", "\n", "out2", "=", "self", ".", "fc2", "(", "out", ")", "\n", "#print(out.shape)", "\n", "\n", "return", "F", ".", "sigmoid", "(", "out1", ")", ",", "out2", "\n", "#return out", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.models_new.dis.swish": [[11, 13], ["torch.sigmoid"], "function", ["None"], ["def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "F", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_imt_cifar10.Attack_None.__init__": [[23, 33], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "step_size", "=", "2.0", "/", "255", "*", "2.0", "\n", "self", ".", "epsilon", "=", "8.0", "/", "255", "*", "2.0", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_imt_cifar10.Attack_None.forward": [[34, 73], ["torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "attack_methods_new_imt_cifar10.Attack_None.basic_net", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_imt_cifar10.Attack_None.basic_net.train", "attack_methods_new_imt_cifar10.Attack_None.basic_net.eval", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "attack_methods_new_imt_cifar10.Attack_None.discriminator", "torch.BCELoss.", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "enumerate", "mask.expand_as.expand_as.expand_as", "attack_methods_new_imt_cifar10.Attack_None.D_optimizer.zero_grad", "attack_methods_new_imt_cifar10.Attack_None.discriminator.zero_grad", "adv_loss.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_cifar10.Attack_None.basic_net", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "numpy.ones", "numpy.ones", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "x", "=", "inputs", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "            ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "logits_pert", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "\n", "#------------IMT--------------", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "for", "idxxx", "in", "range", "(", "1", ")", ":", "\n", "            ", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pert", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "logits_fea", ",", "D_cla", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "loss_D", "=", "adversarial_criterion", "(", "logits_fea", ",", "valid", ")", "\n", "mask", "=", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ")", ")", ".", "cuda", "(", ")", "\n", "for", "index", ",", "qq", "in", "enumerate", "(", "logits_fea", ")", ":", "\n", "                ", "if", "0.3", "<", "qq", "<", "0.7", ":", "\n", "                    ", "mask", "[", "index", "]", "=", "0.5", "\n", "", "", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "#print(mask)", "\n", "\n", "adv_loss", "=", "loss_D", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "4", "*", "1.0", "*", "mask", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "x", "-", "self", ".", "epsilon", "*", "1.0", ")", ",", "\n", "x", "+", "self", ".", "epsilon", "*", "1.0", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "outputs", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_imt_cifar10.Attack_PGD.__init__": [[77, 97], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_imt_cifar10.Attack_PGD.forward": [[98, 191], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new_imt_cifar10.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "attack_methods_new_imt_cifar10.Attack_PGD.basic_net.train", "attack_methods_new_imt_cifar10.Attack_PGD.basic_net.eval", "attack_methods_new_imt_cifar10.Attack_PGD.basic_net", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "attack_methods_new_imt_cifar10.Attack_PGD.discriminator", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.BCELoss.", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "enumerate", "mask.expand_as.expand_as.expand_as", "attack_methods_new_imt_cifar10.Attack_PGD.D_optimizer.zero_grad", "attack_methods_new_imt_cifar10.Attack_PGD.discriminator.zero_grad", "adv_loss.backward", "attack_methods_new_imt_cifar10.Attack_PGD.basic_net.zero_grad", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.softmax.detach", "attack_methods_new_imt_cifar10.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_cifar10.Attack_PGD.basic_net", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "numpy.ones", "numpy.ones", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "# Generating PGD attack", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "#--------IMT---------------#", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "for", "idxxx", "in", "range", "(", "1", ")", ":", "\n", "            ", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pert", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "logits_fea", ",", "D_cla", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "loss_D", "=", "adversarial_criterion", "(", "logits_fea", ",", "valid", ")", "\n", "mask", "=", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ")", ")", ".", "cuda", "(", ")", "\n", "for", "index", ",", "qq", "in", "enumerate", "(", "logits_fea", ")", ":", "\n", "                ", "if", "0.3", "<", "qq", "<", "0.7", ":", "\n", "                    ", "mask", "[", "index", "]", "=", "0.5", "\n", "", "", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "#print(mask)", "\n", "\n", "adv_loss", "=", "loss_D", "\n", "#aux_net.zero_grad()", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "#print(x.grad)", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "4", "*", "1.0", "*", "mask", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "x", "-", "self", ".", "epsilon", "*", "1.0", ")", ",", "\n", "x", "+", "self", ".", "epsilon", "*", "1.0", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_imt_cifar10.Attack_FeaScatter.__init__": [[194, 212], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_imt_cifar10.Attack_FeaScatter.forward": [[213, 376], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.loads.", "logits_pred_nat.size", "utils.one_hot_tensor_svhn", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_imt_cifar10.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new_imt_cifar10.Attack_FeaScatter.basic_net.train", "attack_methods_new_imt_cifar10.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new_imt_cifar10.Attack_FeaScatter.discriminator", "attack_methods_new_imt_cifar10.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "pickle.loads.zero_grad", "attack_methods_new_imt_cifar10.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_imt_cifar10.Attack_FeaScatter.basic_net", "range", "attack_methods_new_imt_cifar10.Attack_FeaScatter.discriminator", "attack_methods_new_imt_cifar10.Attack_FeaScatter.discriminator", "torch.BCELoss.", "numpy.sum", "numpy.sum", "print", "attack_methods_new_imt_cifar10.Attack_FeaScatter.basic_net.zero_grad", "utils.label_smoothing", "utils.softCrossEntropy.", "pickle.dumps", "pickle.loads", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_cifar10.Attack_FeaScatter.discriminator", "attack_methods_new_imt_cifar10.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "print", "discriminator_loss.backward", "attack_methods_new_imt_cifar10.Attack_FeaScatter.D_optimizer.step", "utils.one_hot_tensor_svhn.size", "utils.label_smoothing.detach", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "discriminator_loss.item", "attack_methods_new_imt_cifar10.Attack_FeaScatter.detach().cpu().numpy", "attack_methods_new_imt_cifar10.Attack_FeaScatter.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "attack_methods_new_imt_cifar10.Attack_FeaScatter.detach().cpu", "attack_methods_new_imt_cifar10.Attack_FeaScatter.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "attack_methods_new_imt_cifar10.Attack_FeaScatter.detach", "attack_methods_new_imt_cifar10.Attack_FeaScatter.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "#discriminator = Discriminator().cuda()", "\n", "\n", "#logits = aux_net(inputs)[0]", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor_svhn", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "#y_gt = one_hot_tensor(targets, num_classes, device)", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "#valid = Variable(torch.rand(x.size(0),1)*0.5 + 0.7).cuda()", "\n", "#fake = Variable(torch.rand(x.size(0),1)*0.3).cuda()", "\n", "\n", "\n", "\n", "logits_fea_nat", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(logits_fea_nat)", "\n", "logits_fea_adv", "=", "self", ".", "discriminator", "(", "test_fea_adv", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "#discriminator_loss = adversarial_criterion(logits_fea_nat, target_real) + adversarial_criterion(logits_fea_adv, target_fake)", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "#discriminator_loss = logits_fea_adv.mean() - logits_fea_nat.mean()", "\n", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "\n", "#discriminator_loss = logits_fea_adv2.mean()-logits_fea_nat2.mean()", "\n", "'''\n                #alpha = torch.rand(x.size(0), 1)\n                #alpha = alpha.expand(x.size(0), test_fea_nat.nelement() / x.size(0)).contiguous().view(x.size(0), 640, 8,8)\n                alpha = torch.rand(x.size(0), 1, 1, 1)\n                alpha = alpha.expand_as(test_fea_nat)\n                alpha = alpha.cuda()\n                #print(alpha.shape)\n                interpolates = alpha * test_fea_nat + ((1 - alpha) * test_fea_adv_2).cuda()\n                interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n                disc_interpolates = self.discriminator(interpolates)\n\n                gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                                          grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n                                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n                gradients = gradients.view(gradients.size(0), -1)\n\n                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n                discriminator_loss += gradient_penalty\n                '''", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "\n", "gan_loss1", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "valid", ")", "\n", "#gan_loss2 = adversarial_criterion(logits_fea_nat2, fake)", "\n", "gan_loss", "=", "gan_loss1", "#+ gan_loss2", "\n", "#gan_loss = -logits_fea_adv2.mean()", "\n", "\n", "#mse_loss = mse(test_fea_nat, test_fea_adv_2)", "\n", "#print('\\n***********MSE:',mse_loss.item(),'***********\\n')", "\n", "#print(logits_fea_nat)", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.ot.sinkhorn_loss_joint_IPOT": [[17, 27], ["ot.get_cost_matrix", "ot.sinkhorn", "C.size", "torch.sum", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.get_cost_matrix", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.sinkhorn"], ["def", "sinkhorn_loss_joint_IPOT", "(", "alpha", ",", "beta", ",", "x_feature", ",", "y_feature", ",", "x_label", ",", "\n", "y_label", ",", "epsilon", ",", "m", ",", "n", ")", ":", "\n", "\n", "    ", "C_fea", "=", "get_cost_matrix", "(", "x_feature", ",", "y_feature", ")", "\n", "C", "=", "C_fea", "\n", "T", "=", "sinkhorn", "(", "C", ",", "0.01", ",", "100", ")", "\n", "# T = IPOT(C, 1)", "\n", "batch_size", "=", "C", ".", "size", "(", "0", ")", "\n", "cost_ot", "=", "torch", ".", "sum", "(", "T", "*", "C", ")", "\n", "return", "cost_ot", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.ot.sinkhorn": [[29, 79], ["C.size", "C.size", "torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.exp", "torch.exp", "torch.exp", "pi.to().float.to().float", "torch.log", "torch.log", "torch.log", "ot.sinkhorn.M"], "function", ["None"], ["", "def", "sinkhorn", "(", "C", ",", "epsilon", ",", "niter", "=", "50", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "m", "=", "C", ".", "size", "(", "0", ")", "\n", "n", "=", "C", ".", "size", "(", "1", ")", "\n", "mu", "=", "Variable", "(", "1.", "/", "m", "*", "torch", ".", "FloatTensor", "(", "m", ")", ".", "fill_", "(", "1", ")", ".", "to", "(", "'cuda'", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "nu", "=", "Variable", "(", "1.", "/", "n", "*", "torch", ".", "FloatTensor", "(", "n", ")", ".", "fill_", "(", "1", ")", ".", "to", "(", "'cuda'", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "\n", "# Parameters of the Sinkhorn algorithm.", "\n", "rho", "=", "1", "# (.5) **2          # unbalanced transport", "\n", "tau", "=", "-", ".8", "# nesterov-like acceleration", "\n", "lam", "=", "rho", "/", "(", "rho", "+", "epsilon", ")", "# Update exponent", "\n", "thresh", "=", "10", "**", "(", "-", "1", ")", "# stopping criterion", "\n", "\n", "# Elementary operations .....................................................................", "\n", "def", "ave", "(", "u", ",", "u1", ")", ":", "\n", "        ", "\"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"", "\n", "return", "tau", "*", "u", "+", "(", "1", "-", "tau", ")", "*", "u1", "\n", "\n", "", "def", "M", "(", "u", ",", "v", ")", ":", "\n", "        ", "\"Modified cost for logarithmic updates\"", "\n", "\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"", "\n", "return", "(", "-", "C", "+", "u", ".", "unsqueeze", "(", "1", ")", "+", "v", ".", "unsqueeze", "(", "0", ")", ")", "/", "epsilon", "\n", "\n", "", "def", "lse", "(", "A", ")", ":", "\n", "        ", "\"log-sum-exp\"", "\n", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "A", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "+", "\n", "1e-6", ")", "# add 10^-6 to prevent NaN", "\n", "\n", "# Actual Sinkhorn loop ......................................................................", "\n", "", "u", ",", "v", ",", "err", "=", "0.", "*", "mu", ",", "0.", "*", "nu", ",", "0.", "\n", "actual_nits", "=", "0", "# to check if algorithm terminates because of threshold or max iterations reached", "\n", "\n", "for", "i", "in", "range", "(", "niter", ")", ":", "\n", "        ", "u1", "=", "u", "# useful to check the update", "\n", "u", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "mu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ")", ".", "squeeze", "(", ")", ")", "+", "u", "\n", "v", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "nu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ".", "t", "(", ")", ")", ".", "squeeze", "(", ")", ")", "+", "v", "\n", "# accelerated unbalanced iterations", "\n", "# u = ave( u, lam * ( epsilon * ( torch.log(mu) - lse(M(u,v)).squeeze()   ) + u ) )", "\n", "# v = ave( v, lam * ( epsilon * ( torch.log(nu) - lse(M(u,v).t()).squeeze() ) + v ) )", "\n", "err", "=", "(", "u", "-", "u1", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "\n", "actual_nits", "+=", "1", "\n", "if", "(", "err", "<", "thresh", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ":", "\n", "            ", "break", "\n", "", "", "U", ",", "V", "=", "u", ",", "v", "\n", "\n", "pi", "=", "torch", ".", "exp", "(", "M", "(", "U", ",", "V", ")", ")", "# Transport plan pi = diag(a)*K*diag(b)", "\n", "pi", "=", "pi", ".", "to", "(", "'cuda'", ")", ".", "float", "(", ")", "\n", "return", "pi", "# return the transport", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.ot.IPOT": [[81, 101], ["cost_matrix.size", "cost_matrix.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.exp", "torch.exp", "torch.exp", "range", "torch.ones().to", "torch.ones().to", "torch.ones().to", "range", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.ones", "torch.ones", "torch.ones", "ot.construct_diag", "ot.construct_diag", "torch.ones", "torch.ones", "torch.ones", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "delta.t"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.construct_diag", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.construct_diag"], ["", "def", "IPOT", "(", "cost_matrix", ",", "beta", "=", "1", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "m", "=", "cost_matrix", ".", "size", "(", "0", ")", "\n", "n", "=", "cost_matrix", ".", "size", "(", "1", ")", "\n", "sigma", "=", "1.0", "/", "n", "*", "torch", ".", "ones", "(", "[", "n", ",", "1", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "T", "=", "torch", ".", "ones", "(", "[", "m", ",", "n", "]", ")", ".", "to", "(", "device", ")", "\n", "A", "=", "torch", ".", "exp", "(", "-", "cost_matrix", "/", "beta", ")", "\n", "\n", "for", "t", "in", "range", "(", "50", ")", ":", "\n", "# BUG: should be elementwise product, * in numpy", "\n", "#Q = torch.mm(A, T)", "\n", "        ", "Q", "=", "A", "*", "T", "# Hardmard product", "\n", "for", "k", "in", "range", "(", "1", ")", ":", "\n", "            ", "delta", "=", "1.0", "/", "(", "m", "*", "torch", ".", "mm", "(", "Q", ",", "sigma", ")", ")", "\n", "sigma", "=", "1.0", "/", "(", "n", "*", "torch", ".", "mm", "(", "delta", ".", "t", "(", ")", ",", "Q", ")", ")", ".", "t", "(", ")", "\n", "#sigma = 1.0 / (n * torch.mv(Q, delta))", "\n", "", "tmp", "=", "torch", ".", "mm", "(", "construct_diag", "(", "torch", ".", "squeeze", "(", "delta", ")", ")", ",", "Q", ")", "\n", "T", "=", "torch", ".", "mm", "(", "tmp", ",", "construct_diag", "(", "torch", ".", "squeeze", "(", "sigma", ")", ")", ")", "\n", "\n", "", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.ot.construct_diag": [[103, 108], ["d.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "d.view", "torch.zeros", "torch.zeros", "torch.zeros", "range", "range"], "function", ["None"], ["", "def", "construct_diag", "(", "d", ")", ":", "\n", "    ", "n", "=", "d", ".", "size", "(", "0", ")", "\n", "x", "=", "torch", ".", "zeros", "(", "[", "n", ",", "n", "]", ")", ".", "to", "(", "d", ".", "device", ")", "\n", "x", "[", "range", "(", "n", ")", ",", "range", "(", "n", ")", "]", "=", "d", ".", "view", "(", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.ot.get_cost_matrix": [[110, 113], ["ot.cost_matrix_cos"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.cost_matrix_cos"], ["", "def", "get_cost_matrix", "(", "x_feature", ",", "y_feature", ")", ":", "\n", "    ", "C_fea", "=", "cost_matrix_cos", "(", "x_feature", ",", "y_feature", ")", "# Wasserstein cost function", "\n", "return", "C_fea", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.ot.cost_matrix_cos": [[115, 127], ["x.unsqueeze", "y.unsqueeze", "torch.CosineSimilarity", "torch.clamp", "torch.clamp", "torch.clamp", "nn.CosineSimilarity."], "function", ["None"], ["", "def", "cost_matrix_cos", "(", "x", ",", "y", ",", "p", "=", "2", ")", ":", "\n", "# return the m*n sized cost matrix", "\n", "    ", "\"Returns the matrix of $|x_i-y_j|^p$.\"", "\n", "# un squeeze differently so that the tensors can broadcast", "\n", "# dim-2 (summed over) is the feature dim", "\n", "x_col", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "y_lin", "=", "y", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "2", ",", "eps", "=", "1e-6", ")", "\n", "c", "=", "torch", ".", "clamp", "(", "1", "-", "cos", "(", "x_col", ",", "y_lin", ")", ",", "min", "=", "0", ")", "\n", "\n", "return", "c", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.fs_eval_cifar10.test": [[163, 200], ["net.eval", "tqdm.tqdm", "enumerate", "print", "time.time", "inputs.detach", "net", "criterion", "criterion.item", "outputs.max", "targets.size", "predicted.eq().sum().item", "tqdm.tqdm.set_description", "inputs.to", "targets.to", "time.time", "str", "print", "predicted.eq().sum", "predicted.eq().sum().item", "targets.size", "predicted.eq", "predicted.eq().sum", "predicted.eq"], "function", ["None"], ["def", "test", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "iterator", "=", "tqdm", "(", "testloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "pert_inputs", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "outputs", ",", "_", "=", "net", "(", "pert_inputs", ",", "targets", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "total", "+=", "batch_size", "\n", "correct_num", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "correct", "+=", "correct_num", "\n", "iterator", ".", "set_description", "(", "\n", "str", "(", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "targets", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"step %d, duration %.2f, test  acc %.2f, avg-acc %.2f, loss %.2f\"", "\n", "%", "(", "batch_idx", ",", "duration", ",", "100.", "*", "correct_num", "/", "batch_size", ",", "\n", "100.", "*", "correct", "/", "total", ",", "test_loss", "/", "total", ")", ")", "\n", "\n", "", "", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "print", "(", "'Val acc:'", ",", "acc", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new.Attack_None.__init__": [[24, 31], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "print", "(", "config", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new.Attack_None.forward": [[32, 39], ["attack_methods_new.Attack_None.basic_net", "attack_methods_new.Attack_None.basic_net.train", "attack_methods_new.Attack_None.basic_net.eval"], "methods", ["None"], ["        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new.Attack_PGD.__init__": [[43, 62], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new.Attack_PGD.forward": [[63, 124], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new.Attack_PGD.basic_net.train", "attack_methods_new.Attack_PGD.basic_net.eval", "attack_methods_new.Attack_PGD.basic_net", "torch.softmax.detach", "attack_methods_new.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "#print(targets)", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ".", "detach", "(", ")", ")", "[", "0", "]", "\n", "\n", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new.Attack_FeaScatter.__init__": [[127, 145], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new.Attack_FeaScatter.forward": [[146, 309], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.loads.", "logits_pred_nat.size", "utils.one_hot_tensor_svhn", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new.Attack_FeaScatter.basic_net.train", "attack_methods_new.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "pickle.loads.zero_grad", "attack_methods_new.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new.Attack_FeaScatter.basic_net", "range", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "numpy.sum", "numpy.sum", "print", "attack_methods_new.Attack_FeaScatter.basic_net.zero_grad", "utils.label_smoothing", "utils.softCrossEntropy.", "pickle.dumps", "pickle.loads", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "print", "discriminator_loss.backward", "attack_methods_new.Attack_FeaScatter.D_optimizer.step", "utils.one_hot_tensor_svhn.size", "utils.label_smoothing.detach", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "discriminator_loss.item", "attack_methods_new.Attack_FeaScatter.detach().cpu().numpy", "attack_methods_new.Attack_FeaScatter.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "attack_methods_new.Attack_FeaScatter.detach().cpu", "attack_methods_new.Attack_FeaScatter.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "attack_methods_new.Attack_FeaScatter.detach", "attack_methods_new.Attack_FeaScatter.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "#discriminator = Discriminator().cuda()", "\n", "\n", "#logits = aux_net(inputs)[0]", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor_svhn", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "#y_gt = one_hot_tensor(targets, num_classes, device)", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "#valid = Variable(torch.rand(x.size(0),1)*0.5 + 0.7).cuda()", "\n", "#fake = Variable(torch.rand(x.size(0),1)*0.3).cuda()", "\n", "\n", "\n", "\n", "logits_fea_nat", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(logits_fea_nat)", "\n", "logits_fea_adv", "=", "self", ".", "discriminator", "(", "test_fea_adv", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "#discriminator_loss = adversarial_criterion(logits_fea_nat, target_real) + adversarial_criterion(logits_fea_adv, target_fake)", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "#discriminator_loss = logits_fea_adv.mean() - logits_fea_nat.mean()", "\n", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "\n", "#discriminator_loss = logits_fea_adv2.mean()-logits_fea_nat2.mean()", "\n", "'''\n                #alpha = torch.rand(x.size(0), 1)\n                #alpha = alpha.expand(x.size(0), test_fea_nat.nelement() / x.size(0)).contiguous().view(x.size(0), 640, 8,8)\n                alpha = torch.rand(x.size(0), 1, 1, 1)\n                alpha = alpha.expand_as(test_fea_nat)\n                alpha = alpha.cuda()\n                #print(alpha.shape)\n                interpolates = alpha * test_fea_nat + ((1 - alpha) * test_fea_adv_2).cuda()\n                interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n                disc_interpolates = self.discriminator(interpolates)\n\n                gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                                          grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n                                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n                gradients = gradients.view(gradients.size(0), -1)\n\n                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n                discriminator_loss += gradient_penalty\n                '''", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "\n", "gan_loss1", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "valid", ")", "\n", "#gan_loss2 = adversarial_criterion(logits_fea_nat2, fake)", "\n", "gan_loss", "=", "gan_loss1", "#+ gan_loss2", "\n", "#gan_loss = -logits_fea_adv2.mean()", "\n", "\n", "#mse_loss = mse(test_fea_nat, test_fea_adv_2)", "\n", "#print('\\n***********MSE:',mse_loss.item(),'***********\\n')", "\n", "#print(logits_fea_nat)", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_cifar10.Attack_None.__init__": [[23, 30], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_cifar10.Attack_None.forward": [[31, 38], ["attack_methods_new_cifar10.Attack_None.basic_net", "attack_methods_new_cifar10.Attack_None.basic_net.train", "attack_methods_new_cifar10.Attack_None.basic_net.eval"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_cifar10.Attack_PGD.__init__": [[42, 61], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_cifar10.Attack_PGD.forward": [[62, 122], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new_cifar10.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_cifar10.Attack_PGD.basic_net.train", "attack_methods_new_cifar10.Attack_PGD.basic_net.eval", "attack_methods_new_cifar10.Attack_PGD.basic_net", "torch.softmax.detach", "attack_methods_new_cifar10.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ".", "detach", "(", ")", ")", "[", "0", "]", "\n", "\n", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_cifar10.Attack_FeaScatter.__init__": [[125, 143], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.attack_methods_new_cifar10.Attack_FeaScatter.forward": [[144, 293], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "pickle.loads.", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "logits_pred_nat.size", "utils.one_hot_tensor", "utils.label_smoothing", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_cifar10.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new_cifar10.Attack_FeaScatter.basic_net.train", "attack_methods_new_cifar10.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "utils.one_hot_tensor.size", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new_cifar10.Attack_FeaScatter.discriminator.zero_grad", "attack_methods_new_cifar10.Attack_FeaScatter.discriminator", "attack_methods_new_cifar10.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "utils.softCrossEntropy.", "utils.softCrossEntropy.", "pickle.loads.zero_grad", "attack_methods_new_cifar10.Attack_FeaScatter.D_optimizer.zero_grad", "attack_methods_new_cifar10.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_cifar10.Attack_FeaScatter.basic_net", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "range", "torch.MSELoss.", "print", "numpy.sum", "numpy.sum", "print", "attack_methods_new_cifar10.Attack_FeaScatter.basic_net.zero_grad", "utils.softCrossEntropy.", "attack_methods_new_cifar10.Attack_FeaScatter.discriminator.zero_grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "pickle.dumps", "pickle.loads", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "utils.label_smoothing.detach", "utils.label_smoothing.detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_cifar10.Attack_FeaScatter.discriminator", "attack_methods_new_cifar10.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "utils.softCrossEntropy.", "utils.softCrossEntropy.", "print", "attack_methods_new_cifar10.Attack_FeaScatter.D_optimizer.zero_grad", "discriminator_loss.backward", "attack_methods_new_cifar10.Attack_FeaScatter.D_optimizer.step", "utils.label_smoothing.detach", "gd_adv[].max", "gd_gan[].max", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "utils.label_smoothing.detach", "utils.label_smoothing.detach", "discriminator_loss.item", "logits_fea_nat2.detach().cpu().numpy", "logits_fea_adv2.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "logits_fea_nat2.detach().cpu", "logits_fea_adv2.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "logits_fea_nat2.detach", "logits_fea_adv2.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "\n", "#logits = aux_net(inputs)[0]", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "alpha", "=", "torch", ".", "rand", "(", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", ")", "\n", "\n", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "logits_pred_nat_D", "=", "torch", ".", "reshape", "(", "logits_pred_nat", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pred", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "\n", "# ot loss in Feature scattering method", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "logits_fea_nat", ",", "D_cla_nat", "=", "self", ".", "discriminator", "(", "logits_pred_nat_D", ")", "\n", "logits_fea_adv", ",", "D_cla_adv", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "\n", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "D_cla_real", "=", "loss_ce", "(", "D_cla_nat", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "D_cla_fake", "=", "loss_ce", "(", "D_cla_adv", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "\n", "\n", "# perturbation of ADLT", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred_2", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "logits_pred_2_D", "=", "torch", ".", "reshape", "(", "logits_pred_2", ",", "[", "x", ".", "size", "(", "0", ")", ",", "10", ",", "1", ",", "1", "]", ")", "\n", "\n", "\n", "# Training the discriminator", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", ",", "D_cla_adv2", "=", "self", ".", "discriminator", "(", "logits_pred_2_D", ".", "detach", "(", ")", ")", "\n", "logits_fea_nat2", ",", "D_cla_nat2", "=", "self", ".", "discriminator", "(", "logits_pred_nat_D", ".", "detach", "(", ")", ")", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "D_cla_real2", "=", "loss_ce", "(", "D_cla_nat2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "D_cla_fake2", "=", "loss_ce", "(", "D_cla_adv2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "+", "D_cla_real2", "+", "D_cla_fake2", "\n", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "# Calculating the loss to minimize the f-divergence in classifier", "\n", "", "gan_loss", "=", "mse", "(", "logits_pred_2_D", ",", "logits_pred_nat_D", ")", "\n", "print", "(", "'\\n--------gan_loss:---------*\\n'", ",", "gan_loss", ")", "\n", "\n", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "# Cross entropy of classification loss", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred_2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "\n", "# Calculating the scale of cross entropy loss and f-divergence loss", "\n", "gd_gan", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "gan_loss", ",", "inputs", "=", "x", ",", "retain_graph", "=", "True", ")", "\n", "gd_adv", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "adv_loss", ",", "inputs", "=", "x", ",", "retain_graph", "=", "True", ")", "\n", "scale", "=", "gd_adv", "[", "0", "]", ".", "max", "(", ")", "/", "gd_gan", "[", "0", "]", ".", "max", "(", ")", "\n", "#print(scale)", "\n", "\n", "\n", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", ",", "scale", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.fs_eval_imt_cifar10.test": [[168, 205], ["net.eval", "tqdm.tqdm", "enumerate", "print", "time.time", "inputs.detach", "net", "criterion", "criterion.item", "outputs.max", "targets.size", "predicted.eq().sum().item", "tqdm.tqdm.set_description", "inputs.to", "targets.to", "time.time", "str", "print", "predicted.eq().sum", "predicted.eq().sum().item", "targets.size", "predicted.eq", "predicted.eq().sum", "predicted.eq"], "function", ["None"], ["def", "test", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "iterator", "=", "tqdm", "(", "testloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "pert_inputs", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "outputs", ",", "_", "=", "net", "(", "pert_inputs", ",", "targets", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "total", "+=", "batch_size", "\n", "correct_num", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "correct", "+=", "correct_num", "\n", "iterator", ".", "set_description", "(", "\n", "str", "(", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "targets", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"step %d, duration %.2f, test  acc %.2f, avg-acc %.2f, loss %.2f\"", "\n", "%", "(", "batch_idx", ",", "duration", ",", "100.", "*", "correct_num", "/", "batch_size", ",", "\n", "100.", "*", "correct", "/", "total", ",", "test_loss", "/", "total", ")", ")", "\n", "\n", "", "", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "print", "(", "'Val acc:'", ",", "acc", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.fs_main_cifar10.print_para": [[181, 187], ["net.named_parameters", "print", "print"], "function", ["None"], ["", "def", "print_para", "(", "net", ")", ":", "\n", "    ", "for", "name", ",", "param", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "requires_grad", ":", "\n", "            ", "print", "(", "name", ")", "\n", "print", "(", "param", ".", "data", ")", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.fs_main_cifar10.train_fun": [[252, 350], ["print", "net.train", "torch.BCELoss", "tqdm.tqdm", "enumerate", "outputs.max", "targets.long.size", "targets.long.long", "predicted.eq().sum().item", "time.time", "optimizer.zero_grad", "net_org", "optimizer.zero_grad", "loss_fs.mean", "print", "loss_fs.mean.backward", "net.named_parameters", "optimizer.step", "loss_fs.mean.item", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "inputs.to", "targets.long.to", "inputs.detach", "loss_fs.item", "time.time", "tqdm.tqdm.set_description", "net_org", "fs_main_cifar10.train_fun.get_acc"], "function", ["None"], ["def", "train_fun", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "print", "(", "'\\nEpoch: %d'", "%", "epoch", ")", "\n", "net", ".", "train", "(", ")", "\n", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "# update learning rate", "\n", "if", "epoch", "<", "args", ".", "decay_epoch1", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "\n", "", "elif", "epoch", "<", "args", ".", "decay_epoch2", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "*", "args", ".", "decay_rate", "\n", "", "else", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "*", "args", ".", "decay_rate", "*", "args", ".", "decay_rate", "\n", "", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "", "def", "get_acc", "(", "outputs", ",", "targets", ")", ":", "\n", "        ", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "=", "targets", ".", "size", "(", "0", ")", "\n", "targets", "=", "targets", ".", "long", "(", ")", "\n", "correct", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "acc", "=", "1.0", "*", "correct", "/", "total", "\n", "return", "acc", "\n", "\n", "", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "iterator", "=", "tqdm", "(", "trainloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "adv_acc", "=", "0", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# forward", "\n", "outputs", ",", "loss_fs", ",", "gan_loss", ",", "scale", "=", "net_org", "(", "inputs", ".", "detach", "(", ")", ",", "targets", ")", "\n", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "loss_fs", ".", "mean", "(", ")", "\n", "print", "(", "'loss_fs:'", ",", "loss_fs", ".", "item", "(", ")", ")", "\n", "#print('gan_loss:', gan_loss.item())", "\n", "loss", "=", "(", "loss", "+", "gan_loss", "*", "scale", "/", "2", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "for", "name", ",", "parms", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "==", "'module.final_layer.weight'", ":", "\n", "                ", "max", "=", "torch", ".", "max", "(", "parms", ".", "grad", ")", "\n", "min", "=", "torch", ".", "min", "(", "parms", ".", "grad", ")", "\n", "diff", "=", "(", "max", "-", "min", ")", "*", "0.3", "\n", "\n", "max_threshold", "=", "max", "-", "diff", "\n", "min_threshold", "=", "min", "+", "diff", "\n", "\n", "parms", ".", "grad", "=", "parms", ".", "grad", ".", "clamp", "(", "min_threshold", ",", "max_threshold", ")", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "train_loss", "=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "if", "adv_acc", "==", "0", ":", "\n", "                ", "adv_acc", "=", "get_acc", "(", "outputs", ",", "targets", ")", "\n", "", "iterator", ".", "set_description", "(", "str", "(", "adv_acc", ")", ")", "\n", "\n", "nat_outputs", ",", "_", "=", "net_org", "(", "inputs", ",", "targets", ",", "attack", "=", "False", ")", "\n", "nat_acc", "=", "get_acc", "(", "nat_outputs", ",", "targets", ")", "\n", "\n", "print", "(", "\n", "\"epoch %d, step %d, lr %.4f, duration %.2f, training nat acc %.2f, training adv acc %.2f, training adv loss %.4f\"", "\n", "%", "(", "epoch", ",", "batch_idx", ",", "lr", ",", "duration", ",", "100", "*", "nat_acc", ",", "\n", "100", "*", "adv_acc", ",", "train_loss", ")", ")", "\n", "\n", "", "", "if", "epoch", "%", "args", ".", "save_epochs", "==", "0", "or", "epoch", ">=", "args", ".", "max_epoch", "-", "2", ":", "\n", "        ", "print", "(", "'Saving..'", ")", "\n", "f_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "(", "'checkpoint-%s'", "%", "epoch", ")", ")", "\n", "state", "=", "{", "\n", "'net'", ":", "net_org", ".", "state_dict", "(", ")", ",", "\n", "# 'optimizer': optimizer.state_dict()", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "args", ".", "model_dir", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "f_path", ")", "\n", "\n", "", "if", "epoch", ">=", "0", ":", "\n", "        ", "print", "(", "'Saving latest @ epoch %s..'", "%", "(", "epoch", ")", ")", "\n", "f_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "'latest'", ")", "\n", "state", "=", "{", "\n", "'net'", ":", "net_org", ".", "state_dict", "(", ")", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'D_optimizer'", ":", "D_optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "args", ".", "model_dir", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "f_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.softCrossEntropy.__init__": [[49, 53], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "super", "(", "softCrossEntropy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reduce", "=", "reduce", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.softCrossEntropy.forward": [[54, 68], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: predictions\n        :param targets: target labels in vector form\n        :return: loss\n        \"\"\"", "\n", "log_likelihood", "=", "-", "F", ".", "log_softmax", "(", "inputs", ",", "dim", "=", "1", ")", "\n", "sample_num", ",", "class_num", "=", "targets", ".", "shape", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "loss", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "log_likelihood", ",", "targets", ")", ")", "/", "sample_num", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "log_likelihood", ",", "targets", ")", ",", "1", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.CWLoss.__init__": [[71, 77], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", ",", "margin", "=", "50", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "super", "(", "CWLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "reduce", "=", "reduce", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.CWLoss.forward": [[78, 98], ["utils.one_hot_tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: predictions\n        :param targets: target labels\n        :return: loss\n        \"\"\"", "\n", "onehot_targets", "=", "one_hot_tensor", "(", "targets", ",", "self", ".", "num_classes", ",", "\n", "targets", ".", "device", ")", "\n", "\n", "self_loss", "=", "torch", ".", "sum", "(", "onehot_targets", "*", "logits", ",", "dim", "=", "1", ")", "\n", "other_loss", "=", "torch", ".", "max", "(", "\n", "(", "1", "-", "onehot_targets", ")", "*", "logits", "-", "onehot_targets", "*", "1000", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "torch", ".", "clamp", "(", "self_loss", "-", "other_loss", "+", "self", ".", "margin", ",", "0", ")", ")", "\n", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "sample_num", "=", "onehot_targets", ".", "shape", "[", "0", "]", "\n", "loss", "=", "loss", "/", "sample_num", "\n", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.one_hot_tensor": [[21, 26], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "y_batch_tensor.size", "numpy.arange", "len"], "function", ["None"], ["def", "one_hot_tensor", "(", "y_batch_tensor", ",", "num_classes", ",", "device", ")", ":", "\n", "    ", "y_tensor", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "y_batch_tensor", ".", "size", "(", "0", ")", ",", "\n", "num_classes", ")", ".", "fill_", "(", "0", ")", "\n", "y_tensor", "[", "np", ".", "arange", "(", "len", "(", "y_batch_tensor", ")", ")", ",", "y_batch_tensor", "]", "=", "1.0", "\n", "return", "y_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.one_hot_tensor_svhn": [[27, 36], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "y_batch_tensor[].long", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "y_batch_tensor[].long.size", "numpy.arange", "len"], "function", ["None"], ["", "def", "one_hot_tensor_svhn", "(", "y_batch_tensor", ",", "num_classes", ",", "device", ")", ":", "\n", "    ", "y_tensor", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "y_batch_tensor", ".", "size", "(", "0", ")", ",", "\n", "num_classes", ")", ".", "fill_", "(", "0", ")", "\n", "y_batch_tensor", "=", "y_batch_tensor", "-", "1.0", "\n", "y_batch_tensor", "=", "y_batch_tensor", "[", ":", ",", "0", "]", ".", "long", "(", ")", "\n", "#print(y_batch_tensor.type())", "\n", "y_tensor", "[", "np", ".", "arange", "(", "len", "(", "y_batch_tensor", ")", ")", ",", "y_batch_tensor", "]", "=", "1.0", "\n", "#print(y_tensor.type())", "\n", "return", "y_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.label_smoothing": [[38, 42], ["None"], "function", ["None"], ["", "def", "label_smoothing", "(", "y_batch_tensor", ",", "num_classes", ",", "delta", ")", ":", "\n", "    ", "y_batch_smooth", "=", "(", "1", "-", "delta", "-", "delta", "/", "(", "num_classes", "-", "1", ")", ")", "*", "y_batch_tensor", "+", "delta", "/", "(", "num_classes", "-", "1", ")", "\n", "return", "y_batch_smooth", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar10.utils.str2bool": [[44, 46], ["v.lower"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "lower", "(", ")", "in", "(", "\"yes\"", ",", "\"true\"", ",", "\"t\"", ",", "\"1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_imt_cifar100.Attack_None.__init__": [[22, 33], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "step_size", "=", "2.0", "/", "255", "*", "2.0", "\n", "self", ".", "epsilon", "=", "8.0", "/", "255", "*", "2.0", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_imt_cifar100.Attack_None.forward": [[34, 75], ["torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "attack_methods_new_imt_cifar100.Attack_None.basic_net", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_imt_cifar100.Attack_None.basic_net.train", "attack_methods_new_imt_cifar100.Attack_None.basic_net.eval", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "attack_methods_new_imt_cifar100.Attack_None.discriminator", "torch.BCELoss.", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "enumerate", "mask.expand_as.expand_as.expand_as", "attack_methods_new_imt_cifar100.Attack_None.D_optimizer.zero_grad", "attack_methods_new_imt_cifar100.Attack_None.discriminator.zero_grad", "adv_loss.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_cifar100.Attack_None.basic_net", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "numpy.ones", "numpy.ones", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "x", "=", "inputs", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "            ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "logits_pert", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "\n", "#------------IMT--------------", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "for", "idxxx", "in", "range", "(", "1", ")", ":", "\n", "            ", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pert", ",", "[", "x", ".", "size", "(", "0", ")", ",", "100", ",", "1", ",", "1", "]", ")", "\n", "logits_fea", ",", "D_cla", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "loss_D", "=", "adversarial_criterion", "(", "logits_fea", ",", "valid", ")", "\n", "mask", "=", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ")", ")", ".", "cuda", "(", ")", "\n", "for", "index", ",", "qq", "in", "enumerate", "(", "logits_fea", ")", ":", "\n", "                ", "if", "0.3", "<", "qq", "<", "0.7", ":", "\n", "                    ", "mask", "[", "index", "]", "=", "0.5", "\n", "", "", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "#print(mask)", "\n", "\n", "adv_loss", "=", "loss_D", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "#print(x.grad)", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "4", "*", "1.0", "*", "mask", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "x", "-", "self", ".", "epsilon", "*", "mask", "*", "1.0", ")", ",", "\n", "x", "+", "self", ".", "epsilon", "*", "mask", "*", "1.0", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "outputs", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_imt_cifar100.Attack_PGD.__init__": [[79, 99], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_imt_cifar100.Attack_PGD.forward": [[100, 194], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new_imt_cifar100.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "attack_methods_new_imt_cifar100.Attack_PGD.basic_net.train", "attack_methods_new_imt_cifar100.Attack_PGD.basic_net.eval", "attack_methods_new_imt_cifar100.Attack_PGD.basic_net", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "attack_methods_new_imt_cifar100.Attack_PGD.discriminator", "torch.BCELoss.", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "enumerate", "mask.expand_as.expand_as.expand_as", "attack_methods_new_imt_cifar100.Attack_PGD.D_optimizer.zero_grad", "pickle.loads.zero_grad", "attack_methods_new_imt_cifar100.Attack_PGD.discriminator.zero_grad", "adv_loss.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.softmax.detach", "attack_methods_new_imt_cifar100.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_cifar100.Attack_PGD.basic_net", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "numpy.ones", "numpy.ones", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "\n", "#--------IMT---------------#", "\n", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "for", "idxxx", "in", "range", "(", "1", ")", ":", "\n", "            ", "zero_gradients", "(", "x", ")", "\n", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pert", ",", "[", "x", ".", "size", "(", "0", ")", ",", "100", ",", "1", ",", "1", "]", ")", "\n", "logits_fea", ",", "D_cla", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "loss_D", "=", "adversarial_criterion", "(", "logits_fea", ",", "valid", ")", "\n", "#print(logits_fea)", "\n", "mask", "=", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ")", ")", ".", "cuda", "(", ")", "\n", "for", "index", ",", "qq", "in", "enumerate", "(", "logits_fea", ")", ":", "\n", "                ", "if", "0.3", "<", "qq", "<", "0.7", ":", "\n", "                    ", "mask", "[", "index", "]", "=", "0.5", "\n", "", "", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "#print(mask)", "\n", "\n", "adv_loss", "=", "loss_D", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "#print(x.grad)", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "4", "*", "mask", "*", "1.0", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "x", "-", "self", ".", "epsilon", "*", "1.0", ")", ",", "\n", "x", "+", "self", ".", "epsilon", "*", "1.0", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "x", ".", "requires_grad_", "(", ")", "\n", "\n", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ")", "[", "0", "]", "\n", "\n", "", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_imt_cifar100.Attack_FeaScatter.__init__": [[197, 215], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_imt_cifar100.Attack_FeaScatter.forward": [[216, 379], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.loads.", "logits_pred_nat.size", "utils.one_hot_tensor_svhn", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_imt_cifar100.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new_imt_cifar100.Attack_FeaScatter.basic_net.train", "attack_methods_new_imt_cifar100.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new_imt_cifar100.Attack_FeaScatter.discriminator", "attack_methods_new_imt_cifar100.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "pickle.loads.zero_grad", "attack_methods_new_imt_cifar100.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_imt_cifar100.Attack_FeaScatter.basic_net", "range", "attack_methods_new_imt_cifar100.Attack_FeaScatter.discriminator", "attack_methods_new_imt_cifar100.Attack_FeaScatter.discriminator", "torch.BCELoss.", "numpy.sum", "numpy.sum", "print", "attack_methods_new_imt_cifar100.Attack_FeaScatter.basic_net.zero_grad", "utils.label_smoothing", "utils.softCrossEntropy.", "pickle.dumps", "pickle.loads", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_imt_cifar100.Attack_FeaScatter.discriminator", "attack_methods_new_imt_cifar100.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "print", "discriminator_loss.backward", "attack_methods_new_imt_cifar100.Attack_FeaScatter.D_optimizer.step", "utils.one_hot_tensor_svhn.size", "utils.label_smoothing.detach", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "discriminator_loss.item", "attack_methods_new_imt_cifar100.Attack_FeaScatter.detach().cpu().numpy", "attack_methods_new_imt_cifar100.Attack_FeaScatter.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "attack_methods_new_imt_cifar100.Attack_FeaScatter.detach().cpu", "attack_methods_new_imt_cifar100.Attack_FeaScatter.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "attack_methods_new_imt_cifar100.Attack_FeaScatter.detach", "attack_methods_new_imt_cifar100.Attack_FeaScatter.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "#discriminator = Discriminator().cuda()", "\n", "\n", "#logits = aux_net(inputs)[0]", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor_svhn", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "#y_gt = one_hot_tensor(targets, num_classes, device)", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "#valid = Variable(torch.rand(x.size(0),1)*0.5 + 0.7).cuda()", "\n", "#fake = Variable(torch.rand(x.size(0),1)*0.3).cuda()", "\n", "\n", "\n", "\n", "logits_fea_nat", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(logits_fea_nat)", "\n", "logits_fea_adv", "=", "self", ".", "discriminator", "(", "test_fea_adv", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "#discriminator_loss = adversarial_criterion(logits_fea_nat, target_real) + adversarial_criterion(logits_fea_adv, target_fake)", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "#discriminator_loss = logits_fea_adv.mean() - logits_fea_nat.mean()", "\n", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "\n", "#discriminator_loss = logits_fea_adv2.mean()-logits_fea_nat2.mean()", "\n", "'''\n                #alpha = torch.rand(x.size(0), 1)\n                #alpha = alpha.expand(x.size(0), test_fea_nat.nelement() / x.size(0)).contiguous().view(x.size(0), 640, 8,8)\n                alpha = torch.rand(x.size(0), 1, 1, 1)\n                alpha = alpha.expand_as(test_fea_nat)\n                alpha = alpha.cuda()\n                #print(alpha.shape)\n                interpolates = alpha * test_fea_nat + ((1 - alpha) * test_fea_adv_2).cuda()\n                interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n                disc_interpolates = self.discriminator(interpolates)\n\n                gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                                          grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n                                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n                gradients = gradients.view(gradients.size(0), -1)\n\n                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n                discriminator_loss += gradient_penalty\n                '''", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "\n", "gan_loss1", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "valid", ")", "\n", "#gan_loss2 = adversarial_criterion(logits_fea_nat2, fake)", "\n", "gan_loss", "=", "gan_loss1", "#+ gan_loss2", "\n", "#gan_loss = -logits_fea_adv2.mean()", "\n", "\n", "#mse_loss = mse(test_fea_nat, test_fea_adv_2)", "\n", "#print('\\n***********MSE:',mse_loss.item(),'***********\\n')", "\n", "#print(logits_fea_nat)", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.sinkhorn_loss_joint_IPOT": [[17, 27], ["ot.get_cost_matrix", "ot.sinkhorn", "C.size", "torch.sum", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.get_cost_matrix", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.sinkhorn"], ["def", "sinkhorn_loss_joint_IPOT", "(", "alpha", ",", "beta", ",", "x_feature", ",", "y_feature", ",", "x_label", ",", "\n", "y_label", ",", "epsilon", ",", "m", ",", "n", ")", ":", "\n", "\n", "    ", "C_fea", "=", "get_cost_matrix", "(", "x_feature", ",", "y_feature", ")", "\n", "C", "=", "C_fea", "\n", "T", "=", "sinkhorn", "(", "C", ",", "0.01", ",", "100", ")", "\n", "# T = IPOT(C, 1)", "\n", "batch_size", "=", "C", ".", "size", "(", "0", ")", "\n", "cost_ot", "=", "torch", ".", "sum", "(", "T", "*", "C", ")", "\n", "return", "cost_ot", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.sinkhorn": [[29, 79], ["C.size", "C.size", "torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.exp", "torch.exp", "torch.exp", "pi.to().float.to().float", "torch.log", "torch.log", "torch.log", "ot.sinkhorn.M"], "function", ["None"], ["", "def", "sinkhorn", "(", "C", ",", "epsilon", ",", "niter", "=", "50", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "m", "=", "C", ".", "size", "(", "0", ")", "\n", "n", "=", "C", ".", "size", "(", "1", ")", "\n", "mu", "=", "Variable", "(", "1.", "/", "m", "*", "torch", ".", "FloatTensor", "(", "m", ")", ".", "fill_", "(", "1", ")", ".", "to", "(", "'cuda'", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "nu", "=", "Variable", "(", "1.", "/", "n", "*", "torch", ".", "FloatTensor", "(", "n", ")", ".", "fill_", "(", "1", ")", ".", "to", "(", "'cuda'", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "\n", "# Parameters of the Sinkhorn algorithm.", "\n", "rho", "=", "1", "# (.5) **2          # unbalanced transport", "\n", "tau", "=", "-", ".8", "# nesterov-like acceleration", "\n", "lam", "=", "rho", "/", "(", "rho", "+", "epsilon", ")", "# Update exponent", "\n", "thresh", "=", "10", "**", "(", "-", "1", ")", "# stopping criterion", "\n", "\n", "# Elementary operations .....................................................................", "\n", "def", "ave", "(", "u", ",", "u1", ")", ":", "\n", "        ", "\"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"", "\n", "return", "tau", "*", "u", "+", "(", "1", "-", "tau", ")", "*", "u1", "\n", "\n", "", "def", "M", "(", "u", ",", "v", ")", ":", "\n", "        ", "\"Modified cost for logarithmic updates\"", "\n", "\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"", "\n", "return", "(", "-", "C", "+", "u", ".", "unsqueeze", "(", "1", ")", "+", "v", ".", "unsqueeze", "(", "0", ")", ")", "/", "epsilon", "\n", "\n", "", "def", "lse", "(", "A", ")", ":", "\n", "        ", "\"log-sum-exp\"", "\n", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "A", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "+", "\n", "1e-6", ")", "# add 10^-6 to prevent NaN", "\n", "\n", "# Actual Sinkhorn loop ......................................................................", "\n", "", "u", ",", "v", ",", "err", "=", "0.", "*", "mu", ",", "0.", "*", "nu", ",", "0.", "\n", "actual_nits", "=", "0", "# to check if algorithm terminates because of threshold or max iterations reached", "\n", "\n", "for", "i", "in", "range", "(", "niter", ")", ":", "\n", "        ", "u1", "=", "u", "# useful to check the update", "\n", "u", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "mu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ")", ".", "squeeze", "(", ")", ")", "+", "u", "\n", "v", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "nu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ".", "t", "(", ")", ")", ".", "squeeze", "(", ")", ")", "+", "v", "\n", "# accelerated unbalanced iterations", "\n", "# u = ave( u, lam * ( epsilon * ( torch.log(mu) - lse(M(u,v)).squeeze()   ) + u ) )", "\n", "# v = ave( v, lam * ( epsilon * ( torch.log(nu) - lse(M(u,v).t()).squeeze() ) + v ) )", "\n", "err", "=", "(", "u", "-", "u1", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "\n", "actual_nits", "+=", "1", "\n", "if", "(", "err", "<", "thresh", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ":", "\n", "            ", "break", "\n", "", "", "U", ",", "V", "=", "u", ",", "v", "\n", "\n", "pi", "=", "torch", ".", "exp", "(", "M", "(", "U", ",", "V", ")", ")", "# Transport plan pi = diag(a)*K*diag(b)", "\n", "pi", "=", "pi", ".", "to", "(", "'cuda'", ")", ".", "float", "(", ")", "\n", "return", "pi", "# return the transport", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.IPOT": [[81, 101], ["cost_matrix.size", "cost_matrix.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.exp", "torch.exp", "torch.exp", "range", "torch.ones().to", "torch.ones().to", "torch.ones().to", "range", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.ones", "torch.ones", "torch.ones", "ot.construct_diag", "ot.construct_diag", "torch.ones", "torch.ones", "torch.ones", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "delta.t"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.construct_diag", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.construct_diag"], ["", "def", "IPOT", "(", "cost_matrix", ",", "beta", "=", "1", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "m", "=", "cost_matrix", ".", "size", "(", "0", ")", "\n", "n", "=", "cost_matrix", ".", "size", "(", "1", ")", "\n", "sigma", "=", "1.0", "/", "n", "*", "torch", ".", "ones", "(", "[", "n", ",", "1", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "T", "=", "torch", ".", "ones", "(", "[", "m", ",", "n", "]", ")", ".", "to", "(", "device", ")", "\n", "A", "=", "torch", ".", "exp", "(", "-", "cost_matrix", "/", "beta", ")", "\n", "\n", "for", "t", "in", "range", "(", "50", ")", ":", "\n", "# BUG: should be elementwise product, * in numpy", "\n", "#Q = torch.mm(A, T)", "\n", "        ", "Q", "=", "A", "*", "T", "# Hardmard product", "\n", "for", "k", "in", "range", "(", "1", ")", ":", "\n", "            ", "delta", "=", "1.0", "/", "(", "m", "*", "torch", ".", "mm", "(", "Q", ",", "sigma", ")", ")", "\n", "sigma", "=", "1.0", "/", "(", "n", "*", "torch", ".", "mm", "(", "delta", ".", "t", "(", ")", ",", "Q", ")", ")", ".", "t", "(", ")", "\n", "#sigma = 1.0 / (n * torch.mv(Q, delta))", "\n", "", "tmp", "=", "torch", ".", "mm", "(", "construct_diag", "(", "torch", ".", "squeeze", "(", "delta", ")", ")", ",", "Q", ")", "\n", "T", "=", "torch", ".", "mm", "(", "tmp", ",", "construct_diag", "(", "torch", ".", "squeeze", "(", "sigma", ")", ")", ")", "\n", "\n", "", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.construct_diag": [[103, 108], ["d.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "d.view", "torch.zeros", "torch.zeros", "torch.zeros", "range", "range"], "function", ["None"], ["", "def", "construct_diag", "(", "d", ")", ":", "\n", "    ", "n", "=", "d", ".", "size", "(", "0", ")", "\n", "x", "=", "torch", ".", "zeros", "(", "[", "n", ",", "n", "]", ")", ".", "to", "(", "d", ".", "device", ")", "\n", "x", "[", "range", "(", "n", ")", ",", "range", "(", "n", ")", "]", "=", "d", ".", "view", "(", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.get_cost_matrix": [[110, 113], ["ot.cost_matrix_cos"], "function", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.cost_matrix_cos"], ["", "def", "get_cost_matrix", "(", "x_feature", ",", "y_feature", ")", ":", "\n", "    ", "C_fea", "=", "cost_matrix_cos", "(", "x_feature", ",", "y_feature", ")", "# Wasserstein cost function", "\n", "return", "C_fea", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.ot.cost_matrix_cos": [[115, 127], ["x.unsqueeze", "y.unsqueeze", "torch.CosineSimilarity", "torch.clamp", "torch.clamp", "torch.clamp", "nn.CosineSimilarity."], "function", ["None"], ["", "def", "cost_matrix_cos", "(", "x", ",", "y", ",", "p", "=", "2", ")", ":", "\n", "# return the m*n sized cost matrix", "\n", "    ", "\"Returns the matrix of $|x_i-y_j|^p$.\"", "\n", "# un squeeze differently so that the tensors can broadcast", "\n", "# dim-2 (summed over) is the feature dim", "\n", "x_col", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "y_lin", "=", "y", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "2", ",", "eps", "=", "1e-6", ")", "\n", "c", "=", "torch", ".", "clamp", "(", "1", "-", "cos", "(", "x_col", ",", "y_lin", ")", ",", "min", "=", "0", ")", "\n", "\n", "return", "c", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_cifar100.Attack_None.__init__": [[23, 30], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_cifar100.Attack_None.forward": [[31, 38], ["attack_methods_new_cifar100.Attack_None.basic_net", "attack_methods_new_cifar100.Attack_None.basic_net.train", "attack_methods_new_cifar100.Attack_None.basic_net.eval"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_cifar100.Attack_PGD.__init__": [[42, 61], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_cifar100.Attack_PGD.forward": [[62, 122], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new_cifar100.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_cifar100.Attack_PGD.basic_net.train", "attack_methods_new_cifar100.Attack_PGD.basic_net.eval", "attack_methods_new_cifar100.Attack_PGD.basic_net", "torch.softmax.detach", "attack_methods_new_cifar100.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ".", "detach", "(", ")", ")", "[", "0", "]", "\n", "\n", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_cifar100.Attack_FeaScatter.__init__": [[125, 143], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new_cifar100.Attack_FeaScatter.forward": [[144, 297], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "pickle.loads.", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "logits_pred_nat.size", "utils.one_hot_tensor", "utils.label_smoothing", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new_cifar100.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new_cifar100.Attack_FeaScatter.basic_net.train", "attack_methods_new_cifar100.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "utils.one_hot_tensor.size", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new_cifar100.Attack_FeaScatter.discriminator.zero_grad", "attack_methods_new_cifar100.Attack_FeaScatter.discriminator", "attack_methods_new_cifar100.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "utils.softCrossEntropy.", "utils.softCrossEntropy.", "pickle.loads.zero_grad", "attack_methods_new_cifar100.Attack_FeaScatter.D_optimizer.zero_grad", "attack_methods_new_cifar100.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new_cifar100.Attack_FeaScatter.basic_net", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "range", "torch.MSELoss.", "print", "numpy.sum", "numpy.sum", "print", "attack_methods_new_cifar100.Attack_FeaScatter.basic_net.zero_grad", "utils.softCrossEntropy.", "attack_methods_new_cifar100.Attack_FeaScatter.discriminator.zero_grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "print", "pickle.dumps", "pickle.loads", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "utils.label_smoothing.detach", "utils.label_smoothing.detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new_cifar100.Attack_FeaScatter.discriminator", "attack_methods_new_cifar100.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "utils.softCrossEntropy.", "utils.softCrossEntropy.", "print", "attack_methods_new_cifar100.Attack_FeaScatter.D_optimizer.zero_grad", "discriminator_loss.backward", "attack_methods_new_cifar100.Attack_FeaScatter.D_optimizer.step", "utils.label_smoothing.detach", "gd_adv[].max", "gd_gan[].max", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "torch.reshape.detach", "utils.label_smoothing.detach", "utils.label_smoothing.detach", "discriminator_loss.item", "logits_fea_nat2.detach().cpu().numpy", "logits_fea_adv2.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "logits_fea_nat2.detach().cpu", "logits_fea_adv2.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "logits_fea_nat2.detach", "logits_fea_adv2.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "alpha", "=", "torch", ".", "rand", "(", "x", ".", "size", "(", "0", ")", ",", "100", ",", "1", ",", "1", ")", "\n", "\n", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "logits_pred_nat_D", "=", "torch", ".", "reshape", "(", "logits_pred_nat", ",", "[", "x", ".", "size", "(", "0", ")", ",", "100", ",", "1", ",", "1", "]", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "logits_pred_D", "=", "torch", ".", "reshape", "(", "logits_pred", ",", "[", "x", ".", "size", "(", "0", ")", ",", "100", ",", "1", ",", "1", "]", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "logits_fea_nat", ",", "D_cla_nat", "=", "self", ".", "discriminator", "(", "logits_pred_nat_D", ")", "\n", "#print(logits_fea_nat.shape)", "\n", "logits_fea_adv", ",", "D_cla_adv", "=", "self", ".", "discriminator", "(", "logits_pred_D", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "D_cla_real", "=", "loss_ce", "(", "D_cla_nat", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "D_cla_fake", "=", "loss_ce", "(", "D_cla_adv", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred_2", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "logits_pred_2_D", "=", "torch", ".", "reshape", "(", "logits_pred_2", ",", "[", "x", ".", "size", "(", "0", ")", ",", "100", ",", "1", ",", "1", "]", ")", "\n", "\n", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", ",", "D_cla_adv2", "=", "self", ".", "discriminator", "(", "logits_pred_2_D", ".", "detach", "(", ")", ")", "\n", "logits_fea_nat2", ",", "D_cla_nat2", "=", "self", ".", "discriminator", "(", "logits_pred_nat_D", ".", "detach", "(", ")", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "D_cla_real2", "=", "loss_ce", "(", "D_cla_nat2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "D_cla_fake2", "=", "loss_ce", "(", "D_cla_adv2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "+", "D_cla_real2", "+", "D_cla_fake2", "\n", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "self", ".", "D_optimizer", ".", "zero_grad", "(", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "", "gan_loss", "=", "mse", "(", "logits_pred_2_D", ",", "logits_pred_nat_D", ")", "\n", "print", "(", "'\\n--------gan_loss:---------*\\n'", ",", "gan_loss", ")", "\n", "\n", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred_2", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "gd_gan", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "gan_loss", ",", "inputs", "=", "x", ",", "retain_graph", "=", "True", ")", "\n", "gd_adv", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "adv_loss", ",", "inputs", "=", "x", ",", "retain_graph", "=", "True", ")", "\n", "\n", "scale", "=", "gd_adv", "[", "0", "]", ".", "max", "(", ")", "/", "gd_gan", "[", "0", "]", ".", "max", "(", ")", "\n", "print", "(", "scale", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", ",", "scale", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new.Attack_None.__init__": [[23, 30], ["torch.Module.__init__", "print", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ")", ":", "\n", "        ", "super", "(", "Attack_None", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new.Attack_None.forward": [[31, 38], ["attack_methods_new.Attack_None.basic_net", "attack_methods_new.Attack_None.basic_net.train", "attack_methods_new.Attack_None.basic_net.eval"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "attack", "=", "None", ",", "batch_idx", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new.Attack_PGD.__init__": [[42, 61], ["torch.Module.__init__", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_PGD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "\n", "reduction", "=", "'none'", ")", "if", "'loss_func'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'loss_func'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new.Attack_PGD.forward": [[62, 123], ["pickle.loads.eval", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "numpy.zeros", "range", "pickle.loads", "pickle.loads.", "logits_pred_nat.float", "pickle.loads.", "outputs.float", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.eval", "attack_methods_new.Attack_PGD.loss_func", "loss.mean.mean.mean", "pickle.loads.zero_grad", "loss.mean.mean.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new.Attack_PGD.basic_net.train", "attack_methods_new.Attack_PGD.basic_net.eval", "attack_methods_new.Attack_PGD.basic_net", "torch.softmax.detach", "attack_methods_new.Attack_PGD.basic_net", "pickle.dumps", "pickle.loads", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "inputs.size", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "pickle.loads.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.dumps", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", "=", "self", ".", "basic_net", "(", "inputs", ")", "[", "0", "]", "\n", "return", "outputs", ",", "None", "\n", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits_pred_nat", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "logits_pred_nat", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "num_classes", "=", "targets_prob", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "#print(targets)", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "if", "self", ".", "rand", ":", "\n", "            ", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "loss_array", "=", "np", ".", "zeros", "(", "(", "inputs", ".", "size", "(", "0", ")", ",", "self", ".", "num_steps", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "logits", "=", "aux_net", "(", "x", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_func", "(", "logits", ",", "y_tensor_adv", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "x_adv", "=", "x", ".", "data", "+", "step_sign", "*", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "\n", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ")", "\n", "\n", "", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pert", "=", "self", ".", "basic_net", "(", "x", ".", "detach", "(", ")", ")", "[", "0", "]", "\n", "\n", "return", "logits_pert", ",", "targets_prob", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new.Attack_FeaScatter.__init__": [[126, 144], ["torch.Module.__init__", "print", "config.keys", "config.keys", "config.keys"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "basic_net", ",", "config", ",", "discriminator", ",", "D_optimizer", ",", "attack_net", "=", "None", ")", ":", "\n", "        ", "super", "(", "Attack_FeaScatter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "basic_net", "=", "basic_net", "\n", "self", ".", "attack_net", "=", "attack_net", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "D_optimizer", "=", "D_optimizer", "\n", "self", ".", "rand", "=", "config", "[", "'random_start'", "]", "\n", "self", ".", "step_size", "=", "config", "[", "'step_size'", "]", "\n", "self", ".", "epsilon", "=", "config", "[", "'epsilon'", "]", "\n", "self", ".", "num_steps", "=", "config", "[", "'num_steps'", "]", "\n", "self", ".", "train_flag", "=", "True", "if", "'train'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'train'", "]", "\n", "self", ".", "box_type", "=", "'white'", "if", "'box_type'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'box_type'", "]", "\n", "self", ".", "ls_factor", "=", "0.1", "if", "'ls_factor'", "not", "in", "config", ".", "keys", "(", "\n", ")", "else", "config", "[", "'ls_factor'", "]", "\n", "\n", "print", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.attack_methods_new.Attack_FeaScatter.forward": [[145, 308], ["pickle.loads.eval", "inputs.size", "pickle.loads.", "logits.size", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "torch.autograd.Variable.detach", "pickle.loads.", "logits_pred_nat.size", "utils.one_hot_tensor_svhn", "utils.softCrossEntropy", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "attack_methods_new.Attack_FeaScatter.basic_net", "pickle.loads", "pickle.loads.", "outputs.float", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "attack_methods_new.Attack_FeaScatter.basic_net.train", "attack_methods_new.Attack_FeaScatter.basic_net.eval", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.Variable.requires_grad_", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "torch.autograd.gradcheck.zero_gradients", "pickle.loads.", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "pickle.loads.zero_grad", "attack_methods_new.Attack_FeaScatter.discriminator.zero_grad", "utils.softCrossEntropy.backward", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attack_methods_new.Attack_FeaScatter.basic_net", "range", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "numpy.sum", "numpy.sum", "print", "attack_methods_new.Attack_FeaScatter.basic_net.zero_grad", "utils.label_smoothing", "utils.softCrossEntropy.", "pickle.dumps", "pickle.loads", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.autograd.Variable.grad.data.fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "attack_methods_new.Attack_FeaScatter.discriminator", "attack_methods_new.Attack_FeaScatter.discriminator", "torch.BCELoss.", "torch.BCELoss.", "print", "discriminator_loss.backward", "attack_methods_new.Attack_FeaScatter.D_optimizer.step", "utils.one_hot_tensor_svhn.size", "utils.label_smoothing.detach", "pickle.dumps", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "discriminator_loss.item", "attack_methods_new.Attack_FeaScatter.detach().cpu().numpy", "attack_methods_new.Attack_FeaScatter.detach().cpu().numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "numpy.ones", "numpy.zeros", "attack_methods_new.Attack_FeaScatter.detach().cpu", "attack_methods_new.Attack_FeaScatter.detach().cpu", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "attack_methods_new.Attack_FeaScatter.detach", "attack_methods_new.Attack_FeaScatter.detach"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn", "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing"], ["", "def", "forward", "(", "self", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "attack", "=", "True", ",", "\n", "targeted_label", "=", "-", "1", ",", "\n", "batch_idx", "=", "0", ")", ":", "\n", "\n", "        ", "if", "not", "attack", ":", "\n", "            ", "outputs", ",", "_", ",", "_", "=", "self", ".", "basic_net", "(", "inputs", ")", "\n", "return", "outputs", ",", "None", "\n", "", "if", "self", ".", "box_type", "==", "'white'", ":", "\n", "            ", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "", "elif", "self", ".", "box_type", "==", "'black'", ":", "\n", "            ", "assert", "self", ".", "attack_net", "is", "not", "None", ",", "\"should provide an additional net in black-box case\"", "\n", "aux_net", "=", "pickle", ".", "loads", "(", "pickle", ".", "dumps", "(", "self", ".", "basic_net", ")", ")", "\n", "\n", "", "aux_net", ".", "eval", "(", ")", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "m", "=", "batch_size", "\n", "n", "=", "batch_size", "\n", "#discriminator = Discriminator().cuda()", "\n", "\n", "#logits = aux_net(inputs)[0]", "\n", "\n", "logits", ",", "_", ",", "test_fea_nat", "=", "aux_net", "(", "inputs", ")", "\n", "num_classes", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "outputs", "=", "aux_net", "(", "inputs", ")", "[", "0", "]", "\n", "targets_prob", "=", "F", ".", "softmax", "(", "outputs", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "y_tensor_adv", "=", "targets", "\n", "step_sign", "=", "1.0", "\n", "\n", "x", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "x_org", "=", "x", ".", "detach", "(", ")", "\n", "x", "=", "x", "+", "torch", ".", "zeros_like", "(", "x", ")", ".", "uniform_", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "\n", "if", "self", ".", "train_flag", ":", "\n", "            ", "self", ".", "basic_net", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "basic_net", ".", "eval", "(", ")", "\n", "\n", "", "logits_pred_nat", ",", "fea_nat", ",", "_", "=", "aux_net", "(", "inputs", ")", "\n", "\n", "num_classes", "=", "logits_pred_nat", ".", "size", "(", "1", ")", "\n", "y_gt", "=", "one_hot_tensor_svhn", "(", "targets", ",", "num_classes", ",", "device", ")", "\n", "#y_gt = one_hot_tensor(targets, num_classes, device)", "\n", "\n", "loss_ce", "=", "softCrossEntropy", "(", ")", "\n", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "mse", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "iter_num", "=", "self", ".", "num_steps", "\n", "ones_const", "=", "Variable", "(", "torch", ".", "ones", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "/", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", ")", "\n", "zero_gradients", "(", "x", ")", "\n", "if", "x", ".", "grad", "is", "not", "None", ":", "\n", "                ", "x", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "logits_pred", ",", "fea", ",", "test_fea_adv", "=", "aux_net", "(", "x", ")", "\n", "\n", "#ot_loss = ot.sinkhorn_loss_joint_IPOT(1, 0.00, logits_pred_nat,logits_pred, None, None, 0.01, m, n)", "\n", "#print(logits_pred_nat.shape)", "\n", "\n", "\n", "valid", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", ")", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "#valid = Variable(torch.rand(x.size(0),1)*0.5 + 0.7).cuda()", "\n", "#fake = Variable(torch.rand(x.size(0),1)*0.3).cuda()", "\n", "\n", "\n", "\n", "logits_fea_nat", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(logits_fea_nat)", "\n", "logits_fea_adv", "=", "self", ".", "discriminator", "(", "test_fea_adv", ")", "\n", "\n", "#print(logits_fea_adv)", "\n", "\n", "#discriminator_loss = adversarial_criterion(logits_fea_nat, target_real) + adversarial_criterion(logits_fea_adv, target_fake)", "\n", "loss_real", "=", "adversarial_criterion", "(", "logits_fea_nat", ",", "valid", ")", "\n", "loss_fake", "=", "adversarial_criterion", "(", "logits_fea_adv", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real", "+", "loss_fake", "\n", "#discriminator_loss = logits_fea_adv.mean() - logits_fea_nat.mean()", "\n", "\n", "\n", "\n", "aux_net", ".", "zero_grad", "(", ")", "\n", "#adv_loss = ot_loss", "\n", "adv_loss", "=", "discriminator_loss", "\n", "self", ".", "discriminator", ".", "zero_grad", "(", ")", "\n", "adv_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "x_adv", "=", "x", ".", "data", "-", "self", ".", "step_size", "*", "torch", ".", "sign", "(", "x", ".", "grad", ".", "data", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "torch", ".", "max", "(", "x_adv", ",", "inputs", "-", "self", ".", "epsilon", ")", ",", "\n", "inputs", "+", "self", ".", "epsilon", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "-", "1.0", ",", "1.0", ")", "\n", "x", "=", "Variable", "(", "x_adv", ",", "requires_grad", "=", "True", ")", "\n", "\n", "\n", "\n", "logits_pred", ",", "fea", ",", "test_fea_adv_2", "=", "self", ".", "basic_net", "(", "x", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "\n", "#self.D_optimizer.zero_grad()", "\n", "                ", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "#print(test_fea_nat.shape)", "\n", "#print(logits_fea_adv2)", "\n", "#print(logits_fea_nat2)", "\n", "loss_real2", "=", "adversarial_criterion", "(", "logits_fea_nat2", ",", "valid", ")", "\n", "loss_fake2", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "fake", ")", "\n", "discriminator_loss", "=", "loss_real2", "+", "loss_fake2", "\n", "#discriminator_loss = logits_fea_adv2.mean()-logits_fea_nat2.mean()", "\n", "'''\n                #alpha = torch.rand(x.size(0), 1)\n                #alpha = alpha.expand(x.size(0), test_fea_nat.nelement() / x.size(0)).contiguous().view(x.size(0), 640, 8,8)\n                alpha = torch.rand(x.size(0), 1, 1, 1)\n                alpha = alpha.expand_as(test_fea_nat)\n                alpha = alpha.cuda()\n                #print(alpha.shape)\n                interpolates = alpha * test_fea_nat + ((1 - alpha) * test_fea_adv_2).cuda()\n                interpolates = autograd.Variable(interpolates, requires_grad=True)\n\n                disc_interpolates = self.discriminator(interpolates)\n\n                gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                                          grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n                                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n                gradients = gradients.view(gradients.size(0), -1)\n\n                gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n                discriminator_loss += gradient_penalty\n                '''", "\n", "\n", "print", "(", "'\\n############D loss:'", ",", "discriminator_loss", ".", "item", "(", ")", ",", "'############\\n'", ")", "\n", "discriminator_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "D_optimizer", ".", "step", "(", ")", "\n", "\n", "", "logits_fea_adv2", "=", "self", ".", "discriminator", "(", "test_fea_adv_2", ")", "\n", "logits_fea_nat2", "=", "self", ".", "discriminator", "(", "test_fea_nat", ")", "\n", "\n", "gan_loss1", "=", "adversarial_criterion", "(", "logits_fea_adv2", ",", "valid", ")", "\n", "#gan_loss2 = adversarial_criterion(logits_fea_nat2, fake)", "\n", "gan_loss", "=", "gan_loss1", "#+ gan_loss2", "\n", "#gan_loss = -logits_fea_adv2.mean()", "\n", "\n", "#mse_loss = mse(test_fea_nat, test_fea_adv_2)", "\n", "#print('\\n***********MSE:',mse_loss.item(),'***********\\n')", "\n", "#print(logits_fea_nat)", "\n", "correct_num_nat", "=", "np", ".", "sum", "(", "logits_fea_nat2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "\n", "correct_num_adv", "=", "np", ".", "sum", "(", "logits_fea_adv2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "<", "0.5", ")", "\n", "correct_num", "=", "correct_num_adv", "+", "correct_num_nat", "\n", "print", "(", "'\\n--------correct_num:'", ",", "correct_num", "/", "120", ",", "'---------*\\n'", ")", "\n", "\n", "self", ".", "basic_net", ".", "zero_grad", "(", ")", "\n", "\n", "y_sm", "=", "utils", ".", "label_smoothing", "(", "y_gt", ",", "y_gt", ".", "size", "(", "1", ")", ",", "self", ".", "ls_factor", ")", "\n", "\n", "adv_loss", "=", "loss_ce", "(", "logits_pred", ",", "y_sm", ".", "detach", "(", ")", ")", "\n", "#print('adv_loss:',torch.autograd.grad(adv_loss,x,retain_graph=True)[0].max(),torch.autograd.grad(adv_loss,x,retain_graph=True)[0].min())", "\n", "#print('gan loss:',torch.max(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]),torch.min(torch.autograd.grad(gan_loss,x,retain_graph=True)[0]))", "\n", "\n", "", "return", "logits_pred", ",", "adv_loss", ",", "gan_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.fs_eval_imt_cifar100.test": [[168, 205], ["net.eval", "tqdm.tqdm", "enumerate", "print", "time.time", "inputs.detach", "net", "criterion", "criterion.item", "outputs.max", "targets.size", "predicted.eq().sum().item", "tqdm.tqdm.set_description", "inputs.to", "targets.to", "time.time", "str", "print", "predicted.eq().sum", "predicted.eq().sum().item", "targets.size", "predicted.eq", "predicted.eq().sum", "predicted.eq"], "function", ["None"], ["def", "test", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "iterator", "=", "tqdm", "(", "testloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "pert_inputs", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "outputs", ",", "_", "=", "net", "(", "pert_inputs", ",", "targets", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "total", "+=", "batch_size", "\n", "correct_num", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "correct", "+=", "correct_num", "\n", "iterator", ".", "set_description", "(", "\n", "str", "(", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "targets", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"step %d, duration %.2f, test  acc %.2f, avg-acc %.2f, loss %.2f\"", "\n", "%", "(", "batch_idx", ",", "duration", ",", "100.", "*", "correct_num", "/", "batch_size", ",", "\n", "100.", "*", "correct", "/", "total", ",", "test_loss", "/", "total", ")", ")", "\n", "\n", "", "", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "print", "(", "'Val acc:'", ",", "acc", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.fs_main_cifar100.print_para": [[181, 187], ["net.named_parameters", "print", "print"], "function", ["None"], ["", "def", "print_para", "(", "net", ")", ":", "\n", "    ", "for", "name", ",", "param", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "requires_grad", ":", "\n", "            ", "print", "(", "name", ")", "\n", "print", "(", "param", ".", "data", ")", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.fs_main_cifar100.train_fun": [[251, 349], ["print", "net.train", "torch.BCELoss", "tqdm.tqdm", "enumerate", "outputs.max", "targets.size", "predicted.eq().sum().item", "time.time", "optimizer.zero_grad", "net_org", "optimizer.zero_grad", "loss_fs.mean", "print", "loss_fs.mean.backward", "net.named_parameters", "optimizer.step", "loss_fs.mean.item", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "inputs.to", "targets.to", "inputs.detach", "loss_fs.item", "time.time", "tqdm.tqdm.set_description", "net_org", "fs_main_cifar100.train_fun.get_acc"], "function", ["None"], ["def", "train_fun", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "print", "(", "'\\nEpoch: %d'", "%", "epoch", ")", "\n", "net", ".", "train", "(", ")", "\n", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "# update learning rate", "\n", "if", "epoch", "<", "args", ".", "decay_epoch1", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "\n", "", "elif", "epoch", "<", "args", ".", "decay_epoch2", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "*", "args", ".", "decay_rate", "\n", "", "else", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "*", "args", ".", "decay_rate", "*", "args", ".", "decay_rate", "\n", "", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "", "def", "get_acc", "(", "outputs", ",", "targets", ")", ":", "\n", "        ", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "acc", "=", "1.0", "*", "correct", "/", "total", "\n", "return", "acc", "\n", "\n", "", "adversarial_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "iterator", "=", "tqdm", "(", "trainloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "adv_acc", "=", "0", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# forward", "\n", "outputs", ",", "loss_fs", ",", "gan_loss", ",", "scale", "=", "net_org", "(", "inputs", ".", "detach", "(", ")", ",", "targets", ")", "\n", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "loss_fs", ".", "mean", "(", ")", "\n", "print", "(", "'loss_fs:'", ",", "loss_fs", ".", "item", "(", ")", ")", "\n", "#print('gan_loss:', gan_loss.item())", "\n", "loss", "=", "(", "loss", "+", "gan_loss", "*", "scale", "/", "10", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "for", "name", ",", "parms", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "==", "'module.final_layer.weight'", ":", "\n", "                ", "max", "=", "torch", ".", "max", "(", "parms", ".", "grad", ")", "\n", "min", "=", "torch", ".", "min", "(", "parms", ".", "grad", ")", "\n", "diff", "=", "(", "max", "-", "min", ")", "*", "0.3", "\n", "\n", "max_threshold", "=", "max", "-", "diff", "\n", "min_threshold", "=", "min", "+", "diff", "\n", "\n", "parms", ".", "grad", "=", "parms", ".", "grad", ".", "clamp", "(", "min_threshold", ",", "max_threshold", ")", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "\n", "train_loss", "=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "if", "adv_acc", "==", "0", ":", "\n", "                ", "adv_acc", "=", "get_acc", "(", "outputs", ",", "targets", ")", "\n", "", "iterator", ".", "set_description", "(", "str", "(", "adv_acc", ")", ")", "\n", "\n", "nat_outputs", ",", "_", "=", "net_org", "(", "inputs", ",", "targets", ",", "attack", "=", "False", ")", "\n", "nat_acc", "=", "get_acc", "(", "nat_outputs", ",", "targets", ")", "\n", "\n", "print", "(", "\n", "\"epoch %d, step %d, lr %.4f, duration %.2f, training nat acc %.2f, training adv acc %.2f, training adv loss %.4f\"", "\n", "%", "(", "epoch", ",", "batch_idx", ",", "lr", ",", "duration", ",", "100", "*", "nat_acc", ",", "\n", "100", "*", "adv_acc", ",", "train_loss", ")", ")", "\n", "\n", "", "", "if", "epoch", "%", "args", ".", "save_epochs", "==", "0", "or", "epoch", ">=", "args", ".", "max_epoch", "-", "2", ":", "\n", "        ", "print", "(", "'Saving..'", ")", "\n", "f_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "(", "'checkpoint-%s'", "%", "epoch", ")", ")", "\n", "state", "=", "{", "\n", "'net'", ":", "net_org", ".", "state_dict", "(", ")", ",", "\n", "# 'optimizer': optimizer.state_dict()", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "args", ".", "model_dir", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "f_path", ")", "\n", "\n", "", "if", "epoch", ">=", "0", ":", "\n", "        ", "print", "(", "'Saving latest @ epoch %s..'", "%", "(", "epoch", ")", ")", "\n", "f_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "'latest'", ")", "\n", "state", "=", "{", "\n", "'net'", ":", "net_org", ".", "state_dict", "(", ")", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'D_optimizer'", ":", "D_optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "args", ".", "model_dir", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "f_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.fs_eval_cifar100.test": [[163, 200], ["net.eval", "tqdm.tqdm", "enumerate", "print", "time.time", "inputs.detach", "net", "criterion", "criterion.item", "outputs.max", "targets.size", "predicted.eq().sum().item", "tqdm.tqdm.set_description", "inputs.to", "targets.to", "time.time", "str", "print", "predicted.eq().sum", "predicted.eq().sum().item", "targets.size", "predicted.eq", "predicted.eq().sum", "predicted.eq"], "function", ["None"], ["def", "test", "(", "epoch", ",", "net", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "iterator", "=", "tqdm", "(", "testloader", ",", "ncols", "=", "0", ",", "leave", "=", "False", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "pert_inputs", "=", "inputs", ".", "detach", "(", ")", "\n", "\n", "outputs", ",", "_", "=", "net", "(", "pert_inputs", ",", "targets", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "total", "+=", "batch_size", "\n", "correct_num", "=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "correct", "+=", "correct_num", "\n", "iterator", ".", "set_description", "(", "\n", "str", "(", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "targets", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_step", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"step %d, duration %.2f, test  acc %.2f, avg-acc %.2f, loss %.2f\"", "\n", "%", "(", "batch_idx", ",", "duration", ",", "100.", "*", "correct_num", "/", "batch_size", ",", "\n", "100.", "*", "correct", "/", "total", ",", "test_loss", "/", "total", ")", ")", "\n", "\n", "", "", "acc", "=", "100.", "*", "correct", "/", "total", "\n", "print", "(", "'Val acc:'", ",", "acc", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.softCrossEntropy.__init__": [[49, 53], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "super", "(", "softCrossEntropy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reduce", "=", "reduce", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.softCrossEntropy.forward": [[54, 68], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: predictions\n        :param targets: target labels in vector form\n        :return: loss\n        \"\"\"", "\n", "log_likelihood", "=", "-", "F", ".", "log_softmax", "(", "inputs", ",", "dim", "=", "1", ")", "\n", "sample_num", ",", "class_num", "=", "targets", ".", "shape", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "loss", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "log_likelihood", ",", "targets", ")", ")", "/", "sample_num", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "log_likelihood", ",", "targets", ")", ",", "1", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__": [[71, 77], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", ",", "margin", "=", "50", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "super", "(", "CWLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "reduce", "=", "reduce", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.CWLoss.forward": [[78, 98], ["utils.one_hot_tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        :param inputs: predictions\n        :param targets: target labels\n        :return: loss\n        \"\"\"", "\n", "onehot_targets", "=", "one_hot_tensor", "(", "targets", ",", "self", ".", "num_classes", ",", "\n", "targets", ".", "device", ")", "\n", "\n", "self_loss", "=", "torch", ".", "sum", "(", "onehot_targets", "*", "logits", ",", "dim", "=", "1", ")", "\n", "other_loss", "=", "torch", ".", "max", "(", "\n", "(", "1", "-", "onehot_targets", ")", "*", "logits", "-", "onehot_targets", "*", "1000", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "torch", ".", "clamp", "(", "self_loss", "-", "other_loss", "+", "self", ".", "margin", ",", "0", ")", ")", "\n", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "sample_num", "=", "onehot_targets", ".", "shape", "[", "0", "]", "\n", "loss", "=", "loss", "/", "sample_num", "\n", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor": [[21, 26], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "y_batch_tensor.size", "numpy.arange", "len"], "function", ["None"], ["def", "one_hot_tensor", "(", "y_batch_tensor", ",", "num_classes", ",", "device", ")", ":", "\n", "    ", "y_tensor", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "y_batch_tensor", ".", "size", "(", "0", ")", ",", "\n", "num_classes", ")", ".", "fill_", "(", "0", ")", "\n", "y_tensor", "[", "np", ".", "arange", "(", "len", "(", "y_batch_tensor", ")", ")", ",", "y_batch_tensor", "]", "=", "1.0", "\n", "return", "y_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.one_hot_tensor_svhn": [[27, 36], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "y_batch_tensor[].long", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "y_batch_tensor[].long.size", "numpy.arange", "len"], "function", ["None"], ["", "def", "one_hot_tensor_svhn", "(", "y_batch_tensor", ",", "num_classes", ",", "device", ")", ":", "\n", "    ", "y_tensor", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "y_batch_tensor", ".", "size", "(", "0", ")", ",", "\n", "num_classes", ")", ".", "fill_", "(", "0", ")", "\n", "y_batch_tensor", "=", "y_batch_tensor", "-", "1.0", "\n", "y_batch_tensor", "=", "y_batch_tensor", "[", ":", ",", "0", "]", ".", "long", "(", ")", "\n", "#print(y_batch_tensor.type())", "\n", "y_tensor", "[", "np", ".", "arange", "(", "len", "(", "y_batch_tensor", ")", ")", ",", "y_batch_tensor", "]", "=", "1.0", "\n", "#print(y_tensor.type())", "\n", "return", "y_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.label_smoothing": [[38, 42], ["None"], "function", ["None"], ["", "def", "label_smoothing", "(", "y_batch_tensor", ",", "num_classes", ",", "delta", ")", ":", "\n", "    ", "y_batch_smooth", "=", "(", "1", "-", "delta", "-", "delta", "/", "(", "num_classes", "-", "1", ")", ")", "*", "y_batch_tensor", "+", "delta", "/", "(", "num_classes", "-", "1", ")", "\n", "return", "y_batch_smooth", "\n", "\n"]], "home.repos.pwc.inspect_result.LitterQ_ATLD-pytorch.cifar100.utils.str2bool": [[44, 46], ["v.lower"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "lower", "(", ")", "in", "(", "\"yes\"", ",", "\"true\"", ",", "\"t\"", ",", "\"1\"", ")", "\n", "\n"]]}