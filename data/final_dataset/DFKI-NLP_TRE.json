{"home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.__init__": [[17, 35], ["datetime.datetime.datetime.now().strftime", "os.path.join", "print", "print", "print", "os.makedirs", "os.path.join", "os.path.join", "open", "open", "f.write", "utils.make_path", "datetime.datetime.datetime.now", "utils.make_path", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path"], ["    ", "def", "__init__", "(", "self", ",", "path_to_log_dir", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d__%H-%M__%f\"", ")", "\n", "self", ".", "_base_path", "=", "join", "(", "path_to_log_dir", ",", "self", ".", "start_time", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Logging to\"", ",", "self", ".", "_base_path", ")", "\n", "print", "(", ")", "\n", "makedirs", "(", "self", ".", "_base_path", ",", "exist_ok", "=", "False", ")", "\n", "\n", "if", "'time'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'time'", "]", "=", "self", ".", "start_time", "\n", "\n", "", "config_file", "=", "join", "(", "self", ".", "_base_path", ",", "'config.jsonl'", ")", "\n", "with", "open", "(", "make_path", "(", "config_file", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "kwargs", ")", "+", "'\\n'", ")", "\n", "\n", "", "log_file", "=", "join", "(", "self", ".", "_base_path", ",", "'logs.jsonl'", ")", "\n", "self", ".", "_log_file", "=", "open", "(", "make_path", "(", "log_file", ")", ",", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log": [[36, 41], ["logging_utils.ResultLogger._log_file.write", "logging_utils.ResultLogger._log_file.flush", "datetime.datetime.datetime.now().strftime", "json.dumps", "datetime.datetime.datetime.now"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'time'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'time'", "]", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d__%H-%M__%f\"", ")", "\n", "", "self", ".", "_log_file", ".", "write", "(", "json", ".", "dumps", "(", "kwargs", ")", "+", "'\\n'", ")", "\n", "self", ".", "_log_file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.get_base_dir": [[42, 44], ["None"], "methods", ["None"], ["", "def", "get_base_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_base_path", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger._write_pred_file": [[45, 54], ["open", "utils.make_path", "zip", "pred_f.write", "pred_f.write"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path"], ["", "@", "staticmethod", "\n", "def", "_write_pred_file", "(", "path_to_file", ",", "labels_pred", ",", "ids", ",", "log_with_id", "=", "True", ")", ":", "\n", "        ", "with", "open", "(", "make_path", "(", "path_to_file", ")", ",", "'w'", ")", "as", "pred_f", ":", "\n", "            ", "if", "log_with_id", ":", "\n", "                ", "for", "id_", ",", "prediction", "in", "zip", "(", "ids", ",", "labels_pred", ")", ":", "\n", "                    ", "pred_f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "id_", ",", "prediction", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "prediction", "in", "labels_pred", ":", "\n", "                    ", "pred_f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "prediction", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_dev_labels": [[55, 58], ["os.path.join", "logging_utils.ResultLogger._write_pred_file"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger._write_pred_file"], ["", "", "", "", "def", "log_dev_labels", "(", "self", ",", "labels_dev", ",", "ids", ")", ":", "\n", "        ", "dev_labels_file", "=", "join", "(", "self", ".", "_base_path", ",", "'dev_labels.txt'", ")", "\n", "self", ".", "_write_pred_file", "(", "dev_labels_file", ",", "labels_dev", ",", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_dev_predictions": [[59, 62], ["os.path.join", "logging_utils.ResultLogger._write_pred_file"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger._write_pred_file"], ["", "def", "log_dev_predictions", "(", "self", ",", "epoch", ",", "labels_pred", ",", "ids", ",", "log_with_id", "=", "True", ")", ":", "\n", "        ", "dev_pred_file", "=", "join", "(", "self", ".", "_base_path", ",", "'predictions'", ",", "'dev'", ",", "'predictions_epoch_{}.txt'", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "_write_pred_file", "(", "dev_pred_file", ",", "labels_pred", ",", "ids", ",", "log_with_id", "=", "log_with_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_test_predictions": [[63, 66], ["os.path.join", "logging_utils.ResultLogger._write_pred_file"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger._write_pred_file"], ["", "def", "log_test_predictions", "(", "self", ",", "epoch", ",", "labels_pred", ",", "ids", ",", "log_with_id", "=", "True", ")", ":", "\n", "        ", "test_pred_file", "=", "join", "(", "self", ".", "_base_path", ",", "'predictions'", ",", "'test'", ",", "'predictions_epoch_{}.txt'", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "_write_pred_file", "(", "test_pred_file", ",", "labels_pred", ",", "ids", ",", "log_with_id", "=", "log_with_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_test_pr_curve": [[67, 160], ["collections.defaultdict", "enumerate", "collections.namedtuple", "collections.defaultdict.items", "sorted", "enumerate", "os.path.join", "os.path.join", "os.path.join", "numpy.save", "numpy.save", "bag_to_mention_mapping[].add", "set", "set.discard", "len", "len", "numpy.max", "enumerate", "precision_values.append", "recall_values.append", "sklearn.metrics.auc", "logging_utils.ResultLogger.log_test_pr_curve.precision_at"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.save", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.save"], ["", "def", "log_test_pr_curve", "(", "self", ",", "epoch", ",", "entity_ids_test", ",", "labels_test", ",", "probs_test", ",", "negative_label_idx", ",", "label_encoder", "=", "None", ")", ":", "\n", "        ", "bag_ids", "=", "[", "e1", "+", "'_'", "+", "e2", "for", "e1", ",", "e2", "in", "entity_ids_test", "]", "\n", "\n", "bag_to_mention_mapping", "=", "defaultdict", "(", "set", ")", "\n", "for", "idx", ",", "bag_id", "in", "enumerate", "(", "bag_ids", ")", ":", "\n", "            ", "bag_to_mention_mapping", "[", "bag_id", "]", ".", "add", "(", "idx", ")", "\n", "\n", "", "num_relation_facts", "=", "0", "\n", "Prediction", "=", "namedtuple", "(", "'Prediction'", ",", "[", "'score'", ",", "'is_correct'", ",", "'bag_id'", ",", "'predicted_label_idx'", ",", "'bag_label_idxs'", ",", "\n", "'predicted_label'", ",", "'bag_labels'", ",", "'bag_size'", "]", ")", "\n", "predictions", "=", "[", "]", "\n", "for", "bag_id", ",", "mention_idxs", "in", "bag_to_mention_mapping", ".", "items", "(", ")", ":", "\n", "# Aggregate and count the labels per bag without the negative label", "\n", "            ", "bag_labels", "=", "set", "(", "labels_test", "[", "list", "(", "mention_idxs", ")", "]", ")", "\n", "bag_labels", ".", "discard", "(", "negative_label_idx", ")", "\n", "num_relation_facts", "+=", "len", "(", "bag_labels", ")", "\n", "bag_size", "=", "len", "(", "mention_idxs", ")", "\n", "\n", "# Use max to aggregate the mention probabilities in the bag", "\n", "mention_probs", "=", "probs_test", "[", "list", "(", "mention_idxs", ")", "]", "\n", "bag_probs", "=", "np", ".", "max", "(", "mention_probs", ",", "axis", "=", "0", ")", "\n", "\n", "# For each bag and positive relation create a prediction", "\n", "for", "relation_idx", ",", "relation_prob", "in", "enumerate", "(", "bag_probs", ")", ":", "\n", "                ", "if", "relation_idx", "==", "negative_label_idx", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "len", "(", "bag_labels", ")", "==", "0", ":", "\n", "                    ", "bag_labels_str", "=", "'NA'", "\n", "bag_label_idxs_str", "=", "negative_label_idx", "\n", "", "else", ":", "\n", "                    ", "if", "label_encoder", ":", "\n", "                        ", "decoded_bag_labels", "=", "[", "label_encoder", ".", "get_item_for_index", "(", "idx", ")", "for", "idx", "in", "bag_labels", "]", "\n", "bag_labels_str", "=", "', '", ".", "join", "(", "decoded_bag_labels", ")", "\n", "", "else", ":", "\n", "                        ", "bag_labels_str", "=", "''", "\n", "\n", "", "bag_label_idxs_str", "=", "', '", ".", "join", "(", "[", "str", "(", "lbl", ")", "for", "lbl", "in", "bag_labels", "]", ")", "\n", "\n", "", "if", "label_encoder", ":", "\n", "                    ", "predicted_label_str", "=", "label_encoder", ".", "get_item_for_index", "(", "relation_idx", ")", "\n", "", "else", ":", "\n", "                    ", "predicted_label_str", "=", "\"\"", "\n", "", "predicted_label_idx_str", "=", "str", "(", "relation_idx", ")", "\n", "\n", "is_correct", "=", "relation_idx", "in", "bag_labels", "\n", "predictions", ".", "append", "(", "Prediction", "(", "score", "=", "relation_prob", ",", "\n", "is_correct", "=", "is_correct", ",", "\n", "bag_id", "=", "bag_id", ",", "\n", "predicted_label_idx", "=", "predicted_label_idx_str", ",", "\n", "bag_label_idxs", "=", "bag_label_idxs_str", ",", "\n", "predicted_label", "=", "predicted_label_str", ",", "\n", "bag_labels", "=", "bag_labels_str", ",", "\n", "bag_size", "=", "bag_size", ")", ")", "\n", "\n", "", "", "predictions", "=", "sorted", "(", "predictions", ",", "key", "=", "attrgetter", "(", "'score'", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "correct", "=", "0", "\n", "precision_values", "=", "[", "]", "\n", "recall_values", "=", "[", "]", "\n", "for", "idx", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "            ", "if", "prediction", ".", "is_correct", ":", "\n", "                ", "correct", "+=", "1", "\n", "", "precision_values", ".", "append", "(", "correct", "/", "(", "idx", "+", "1", ")", ")", "\n", "recall_values", ".", "append", "(", "correct", "/", "num_relation_facts", ")", "\n", "\n", "", "def", "precision_at", "(", "n", ")", ":", "\n", "            ", "return", "(", "sum", "(", "[", "prediction", ".", "is_correct", "for", "prediction", "in", "predictions", "[", ":", "n", "]", "]", ")", "/", "n", ")", "*", "100", "\n", "\n", "", "pr_metrics", "=", "{", "\n", "'P/R AUC'", ":", "auc", "(", "x", "=", "recall_values", ",", "y", "=", "precision_values", ")", ",", "\n", "'Precision@100'", ":", "precision_at", "(", "100", ")", ",", "\n", "'Precision@200'", ":", "precision_at", "(", "200", ")", ",", "\n", "'Precision@500'", ":", "precision_at", "(", "500", ")", "\n", "}", "\n", "\n", "predictions_dir", "=", "join", "(", "self", ".", "_base_path", ",", "'predictions'", ",", "'test'", ")", "\n", "pr_metrics_file_path", "=", "join", "(", "predictions_dir", ",", "'pr_metrics_epoch_{}.jsonl'", ".", "format", "(", "epoch", ")", ")", "\n", "with", "open", "(", "make_path", "(", "pr_metrics_file_path", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "pr_metrics_file", ":", "\n", "            ", "pr_metrics_file", ".", "write", "(", "json", ".", "dumps", "(", "pr_metrics", ")", "+", "'\\n'", ")", "\n", "\n", "", "pr_predictions_file", "=", "join", "(", "predictions_dir", ",", "'predictions_pr_curve_epoch_{}.tsv'", ".", "format", "(", "epoch", ")", ")", "\n", "with", "open", "(", "make_path", "(", "pr_predictions_file", ")", ",", "'w'", ")", "as", "pr_pred_file", ":", "\n", "            ", "tuple_attrs", "=", "[", "'score'", ",", "'is_correct'", ",", "'bag_id'", ",", "'predicted_label_idx'", ",", "\n", "'bag_label_idxs'", ",", "'predicted_label'", ",", "'bag_labels'", ",", "'bag_size'", "]", "\n", "pr_pred_file", ".", "write", "(", "\"\\t\"", ".", "join", "(", "tuple_attrs", ")", "+", "\"\\n\"", ")", "\n", "for", "prediction", "in", "predictions", ":", "\n", "                ", "pred_values", "=", "attrgetter", "(", "*", "tuple_attrs", ")", "(", "prediction", ")", "\n", "pred_values", "=", "[", "str", "(", "val", ")", "for", "val", "in", "pred_values", "]", "\n", "pr_pred_file", ".", "write", "(", "\"\\t\"", ".", "join", "(", "pred_values", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "np", ".", "save", "(", "join", "(", "predictions_dir", ",", "'pr_curve_y_epoch_{}.npy'", ".", "format", "(", "epoch", ")", ")", ",", "precision_values", ")", "\n", "np", ".", "save", "(", "join", "(", "predictions_dir", ",", "'pr_curve_x_epoch_{}.npy'", ".", "format", "(", "epoch", ")", ")", ",", "recall_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.close": [[161, 163], ["logging_utils.ResultLogger._log_file.close"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "_log_file", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.opt.OpenAIAdam.__init__": [[28, 47], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", ",", "schedule", ",", "warmup", ",", "t_total", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-8", ",", "l2", "=", "0", ",", "\n", "vector_l2", "=", "False", ",", "max_grad_norm", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0", "<=", "warmup", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {}\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {}\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {}\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "0.0", "<=", "e", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "l2", "=", "l2", ",", "vector_l2", "=", "vector_l2", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "OpenAIAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.opt.OpenAIAdam.step": [[48, 105], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "schedule_fct", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt", "len", "p.size"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'e'", "]", ")", "\n", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "\n", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "step_size", "=", "lr_scheduled", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "(", "len", "(", "p", ".", "size", "(", ")", ")", ">", "1", "or", "group", "[", "'vector_l2'", "]", ")", "and", "group", "[", "'l2'", "]", ">", "0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "lr_scheduled", "*", "group", "[", "'l2'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.opt.warmup_cosine": [[6, 9], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "(", "0.5", "*", "(", "1", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.opt.warmup_constant": [[10, 13], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.opt.warmup_linear": [[14, 17], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "(", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", ")", "*", "(", "1", "-", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.TextEncoder.__init__": [[44, 52], ["spacy.load", "json.load", "dict", "open", "open().read().split", "tuple", "zip", "text_utils.TextEncoder.encoder.items", "merge.split", "range", "open().read", "len", "open"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load"], ["def", "__init__", "(", "self", ",", "encoder_path", ",", "bpe_path", ")", ":", "\n", "        ", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en'", ",", "disable", "=", "[", "'parser'", ",", "'tagger'", ",", "'ner'", ",", "'textcat'", "]", ")", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "encoder_path", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "bpe_path", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.TextEncoder.bpe": [[53, 95], ["text_utils.get_pairs", "tuple", "min", "tuple", "len", "len", "text_utils.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "text_utils.TextEncoder.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.get_pairs", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "'\\n</w>'", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.TextEncoder.encode": [[96, 138], ["tqdm.tqdm.tqdm", "texts_tokens.append", "texts_tokens.append", "text_utils.TextEncoder.nlp", "spacy.tokens.Doc", "text_utils.TextEncoder.nlp", "spacy.tokens.Doc", "text_utils.text_standardize", "text_tokens.append", "text_tokens.extend", "text_utils.text_standardize", "text_tokens.append", "text_tokens.extend", "ftfy.fix_text", "words.append", "words.append", "token.text.lower", "text_utils.TextEncoder.encoder.get", "ftfy.fix_text", "words.append", "words.append", "token.text.lower", "text_utils.TextEncoder.encoder.get", "token.lower", "text_utils.text_standardize", "token.text.lower", "text_utils.TextEncoder.encoder.get", "token.lower", "text_utils.text_standardize", "token.text.lower", "text_utils.TextEncoder.encoder.get", "ftfy.fix_text", "text_utils.TextEncoder.bpe().split", "ftfy.fix_text", "text_utils.TextEncoder.bpe().split", "text_utils.TextEncoder.bpe", "text_utils.TextEncoder.bpe", "token.text.lower", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.text_standardize", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.text_standardize", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.text_standardize", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.text_standardize", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.TextEncoder.bpe", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.TextEncoder.bpe"], ["", "def", "encode", "(", "self", ",", "texts", ",", "verbose", "=", "True", ",", "use_tokenizer", "=", "False", ",", "special_tokens", "=", "None", ")", ":", "\n", "        ", "texts_tokens", "=", "[", "]", "\n", "if", "verbose", ":", "\n", "            ", "for", "text", "in", "tqdm", "(", "texts", ",", "ncols", "=", "80", ",", "leave", "=", "False", ")", ":", "\n", "                ", "if", "use_tokenizer", ":", "\n", "                    ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "ftfy", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "words", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "                        ", "if", "special_tokens", "is", "not", "None", "and", "token", ".", "lower", "(", ")", "in", "special_tokens", ":", "\n", "                            ", "words", ".", "append", "(", "token", ")", "\n", "", "else", ":", "\n", "                            ", "words", ".", "append", "(", "text_standardize", "(", "ftfy", ".", "fix_text", "(", "token", ")", ")", ")", "\n", "", "", "text", "=", "Doc", "(", "self", ".", "nlp", ".", "vocab", ",", "words", "=", "words", ")", "\n", "\n", "", "text_tokens", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "                    ", "if", "special_tokens", "is", "not", "None", "and", "token", ".", "text", ".", "lower", "(", ")", "in", "special_tokens", ":", "\n", "                        ", "text_tokens", ".", "append", "(", "self", ".", "encoder", ".", "get", "(", "token", ".", "text", ".", "lower", "(", ")", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                        ", "text_tokens", ".", "extend", "(", "[", "self", ".", "encoder", ".", "get", "(", "t", ",", "0", ")", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "texts_tokens", ".", "append", "(", "text_tokens", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "text", "in", "texts", ":", "\n", "                ", "if", "use_tokenizer", ":", "\n", "                    ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "ftfy", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "words", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "                        ", "if", "special_tokens", "is", "not", "None", "and", "token", ".", "lower", "(", ")", "in", "special_tokens", ":", "\n", "                            ", "words", ".", "append", "(", "token", ")", "\n", "", "else", ":", "\n", "                            ", "words", ".", "append", "(", "text_standardize", "(", "ftfy", ".", "fix_text", "(", "token", ")", ")", ")", "\n", "", "", "text", "=", "Doc", "(", "self", ".", "nlp", ".", "vocab", ",", "words", "=", "words", ")", "\n", "", "text_tokens", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "                    ", "if", "special_tokens", "is", "not", "None", "and", "token", ".", "text", ".", "lower", "(", ")", "in", "special_tokens", ":", "\n", "                        ", "text_tokens", ".", "append", "(", "self", ".", "encoder", ".", "get", "(", "token", ".", "text", ".", "lower", "(", ")", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                        ", "text_tokens", ".", "extend", "(", "[", "self", ".", "encoder", ".", "get", "(", "t", ",", "0", ")", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "texts_tokens", ".", "append", "(", "text_tokens", ")", "\n", "", "", "return", "texts_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.__init__": [[145, 153], ["text_utils.Dictionary.add_item"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.add_item"], ["def", "__init__", "(", "self", ",", "add_unk", "=", "True", ")", ":", "\n", "# init dictionaries", "\n", "        ", "self", ".", "item2idx", ":", "Dict", "[", "str", ",", "int", "]", "=", "{", "}", "\n", "self", ".", "idx2item", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\n", "# in order to deal with unknown tokens, add <unk>", "\n", "if", "add_unk", ":", "\n", "            ", "self", ".", "add_item", "(", "'<unk>'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.add_item": [[154, 165], ["item.encode.encode.encode", "text_utils.Dictionary.idx2item.append", "len"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.encode"], ["", "", "def", "add_item", "(", "self", ",", "item", ":", "str", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        add string - if already in dictionary returns its ID. if not in dictionary, it will get a new ID.\n        :param item: a string for which to assign an id\n        :return: ID of string\n        \"\"\"", "\n", "item", "=", "item", ".", "encode", "(", "'utf-8'", ")", "\n", "if", "item", "not", "in", "self", ".", "item2idx", ":", "\n", "            ", "self", ".", "idx2item", ".", "append", "(", "item", ")", "\n", "self", ".", "item2idx", "[", "item", "]", "=", "len", "(", "self", ".", "idx2item", ")", "-", "1", "\n", "", "return", "self", ".", "item2idx", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_idx_for_item": [[166, 177], ["item.encode.encode.encode", "text_utils.Dictionary.item2idx.keys"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.encode"], ["", "def", "get_idx_for_item", "(", "self", ",", "item", ":", "str", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        returns the ID of the string, otherwise 0\n        :param item: string for which ID is requested\n        :return: ID of string, otherwise 0\n        \"\"\"", "\n", "item", "=", "item", ".", "encode", "(", "'utf-8'", ")", "\n", "if", "item", "in", "self", ".", "item2idx", ".", "keys", "(", ")", ":", "\n", "            ", "return", "self", ".", "item2idx", "[", "item", "]", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_items": [[178, 183], ["items.append", "item.decode"], "methods", ["None"], ["", "", "def", "get_items", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "items", "=", "[", "]", "\n", "for", "item", "in", "self", ".", "idx2item", ":", "\n", "            ", "items", ".", "append", "(", "item", ".", "decode", "(", "'UTF-8'", ")", ")", "\n", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.__len__": [[184, 186], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index": [[187, 189], ["text_utils.Dictionary.idx2item[].decode"], "methods", ["None"], ["", "def", "get_item_for_index", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "idx2item", "[", "idx", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.save": [[190, 198], ["open", "pickle.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "savefile", ")", ":", "\n", "        ", "import", "pickle", "\n", "with", "open", "(", "savefile", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "mappings", "=", "{", "\n", "'idx2item'", ":", "self", ".", "idx2item", ",", "\n", "'item2idx'", ":", "self", ".", "item2idx", "\n", "}", "\n", "pickle", ".", "dump", "(", "mappings", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load_from_file": [[199, 210], ["text_utils.Dictionary", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load"], ["", "", "@", "classmethod", "\n", "def", "load_from_file", "(", "cls", ",", "filename", ":", "str", ")", ":", "\n", "        ", "import", "pickle", "\n", "dictionary", ":", "Dictionary", "=", "Dictionary", "(", ")", "\n", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "mappings", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "'latin1'", ")", "\n", "idx2item", "=", "mappings", "[", "'idx2item'", "]", "\n", "item2idx", "=", "mappings", "[", "'item2idx'", "]", "\n", "dictionary", ".", "item2idx", "=", "item2idx", "\n", "dictionary", ".", "idx2item", "=", "idx2item", "\n", "", "return", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load": [[211, 214], ["text_utils.Dictionary.load_from_file"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.DoubleHeadModel.load_from_file"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "name", ":", "str", ")", ":", "\n", "        ", "return", "Dictionary", ".", "load_from_file", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.get_pairs": [[12, 23], ["set", "set.add"], "function", ["None"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.text_standardize": [[24, 38], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "'\u2014'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2013'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2015'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u00b4'", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)'''", ",", "r' \\1 '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\s*\\n\\s*'", ",", "' \\n '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^\\S\\n]+'", ",", "' '", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter.__init__": [[45, 90], ["os.path.exists", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "RuntimeError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "dataset_dir", ",", "output_dir", ",", "subsample", ")", ":", "\n", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "subsample", "=", "subsample", "\n", "\n", "if", "dataset", "==", "\"semeval\"", ":", "\n", "            ", "self", ".", "input_train_file", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "\"SemEval2010_task8_training\"", ",", "\"TRAIN_FILE.TXT\"", ")", "\n", "self", ".", "input_test_file", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "\"SemEval2010_task8_testing_keys\"", ",", "\"TEST_FILE_FULL.TXT\"", ")", "\n", "self", ".", "input_dev_file", "=", "None", "\n", "", "elif", "dataset", "==", "\"kbp37\"", ":", "\n", "            ", "self", ".", "input_train_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataset_dir", ",", "\"train.txt\"", ")", "\n", "self", ".", "input_test_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataset_dir", ",", "\"test.txt\"", ")", "\n", "self", ".", "input_dev_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataset_dir", ",", "\"dev.txt\"", ")", "\n", "", "elif", "dataset", "==", "\"tacred\"", ":", "\n", "            ", "path_to_json_files", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "\"data\"", ",", "\"json\"", ")", "\n", "self", ".", "input_train_file", "=", "os", ".", "path", ".", "join", "(", "path_to_json_files", ",", "\"train.json\"", ")", "\n", "self", ".", "input_test_file", "=", "os", ".", "path", ".", "join", "(", "path_to_json_files", ",", "\"test.json\"", ")", "\n", "self", ".", "input_dev_file", "=", "os", ".", "path", ".", "join", "(", "path_to_json_files", ",", "\"dev.json\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Only the following datasets are supported: \"", "+", "\", \"", ".", "join", "(", "SUPPORTED_DATASETS", ")", ")", "\n", "\n", "", "self", ".", "output_dir", "=", "output_dir", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "self", ".", "input_train_file", ")", ",", "\"Train file not found: {}\"", ".", "format", "(", "self", ".", "input_train_file", ")", "\n", "if", "not", "subsample", ":", "\n", "            ", "self", ".", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"train.jsonl\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "masking_modes", "=", "[", "None", ",", "'grammar'", ",", "'ner'", ",", "'grammar_and_ner'", ",", "'unk'", ",", "'unk_w_position'", "]", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "self", ".", "input_test_file", ")", ",", "\"Test file not found: {}\"", ".", "format", "(", "self", ".", "input_test_file", ")", "\n", "self", ".", "output_test_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"test.jsonl\"", ")", "\n", "\n", "if", "self", ".", "input_dev_file", ":", "\n", "            ", "assert", "os", ".", "path", ".", "exists", "(", "self", ".", "input_dev_file", ")", ",", "\"Test file not found: {}\"", ".", "format", "(", "self", ".", "input_dev_file", ")", "\n", "self", ".", "output_dev_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"dev.jsonl\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_dev_file", "=", "None", "\n", "\n", "", "self", ".", "glove_mapping", "=", "{", "\n", "'-LRB-'", ":", "'('", ",", "\n", "'-RRB-'", ":", "')'", ",", "\n", "'-LSB-'", ":", "'['", ",", "\n", "'-RSB-'", ":", "']'", ",", "\n", "'-LCB-'", ":", "'{'", ",", "\n", "'-RCB-'", ":", "'}'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter.run": [[92, 100], ["print", "os.makedirs", "dataset_converter.DatasetConverter._run_normally", "dataset_converter.DatasetConverter._run_subsampling"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._run_normally", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._run_subsampling"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Converting dataset to jsonl\"", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "not", "self", ".", "subsample", ":", "\n", "            ", "self", ".", "_run_normally", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_run_subsampling", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._run_normally": [[101, 119], ["dataset_converter.DatasetConverter._convert_semeval_format_file", "dataset_converter.DatasetConverter._convert_semeval_format_file", "dataset_converter.DatasetConverter._convert_semeval_format_file", "dataset_converter.DatasetConverter._convert_tacred_format_file", "dataset_converter.DatasetConverter._convert_tacred_format_file", "RuntimeError", "dataset_converter.DatasetConverter._convert_tacred_format_file", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_semeval_format_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_semeval_format_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_semeval_format_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_tacred_format_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_tacred_format_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_tacred_format_file"], ["", "", "def", "_run_normally", "(", "self", ")", ":", "\n", "# Convert the dev and test set", "\n", "        ", "if", "self", ".", "dataset", "in", "[", "'semeval'", ",", "'kbp37'", "]", ":", "\n", "            ", "self", ".", "_convert_semeval_format_file", "(", "self", ".", "input_test_file", ",", "self", ".", "output_test_file", ")", "\n", "if", "self", ".", "output_dev_file", ":", "\n", "                ", "self", ".", "_convert_semeval_format_file", "(", "self", ".", "input_dev_file", ",", "self", ".", "output_dev_file", ")", "\n", "", "", "elif", "self", ".", "dataset", "==", "'tacred'", ":", "\n", "            ", "self", ".", "_convert_tacred_format_file", "(", "self", ".", "input_test_file", ",", "self", ".", "output_test_file", ")", "\n", "self", ".", "_convert_tacred_format_file", "(", "self", ".", "input_dev_file", ",", "self", ".", "output_dev_file", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Unexpected dataset: \"", "+", "self", ".", "dataset", ")", "\n", "\n", "", "if", "self", ".", "dataset", "in", "[", "'semeval'", ",", "'kbp37'", "]", ":", "\n", "            ", "self", ".", "_convert_semeval_format_file", "(", "self", ".", "input_train_file", ",", "self", ".", "output_train_file", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'tacred'", ":", "\n", "            ", "self", ".", "_convert_tacred_format_file", "(", "self", ".", "input_train_file", ",", "self", ".", "output_train_file", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Unexpected dataset: \"", "+", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._run_subsampling": [[120, 187], ["list", "list", "list", "list", "numpy.linspace", "dataset_converter.DatasetConverter._read_tacred_file", "map", "dataset_converter.DatasetConverter._read_tacred_file", "dataset_converter.DatasetConverter._read_tacred_file", "os.path.join", "os.path.join", "os.path.join", "print", "os.path.join", "os.path.join", "operator.itemgetter", "str", "RuntimeError", "open", "os.path.join", "print", "os.path.join", "open", "open", "int", "sklearn.model_selection.train_test_split", "utils.make_path", "ids_file.write", "open", "datasets.SemEval2010Task8.apply_masking_mode", "datasets.SemEval2010Task8.apply_masking_mode", "utils.make_path", "output_file.write", "utils.make_path", "output_file.write", "datasets.SemEval2010Task8.apply_masking_mode", "utils.make_path", "output_file.write", "str", "json.dumps", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._read_tacred_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._read_tacred_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._read_tacred_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.apply_masking_mode", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.apply_masking_mode", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.apply_masking_mode", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path"], ["", "", "def", "_run_subsampling", "(", "self", ")", ":", "\n", "        ", "train_examples", "=", "list", "(", "self", ".", "_read_tacred_file", "(", "self", ".", "input_train_file", ")", ")", "\n", "train_labels", "=", "list", "(", "map", "(", "itemgetter", "(", "'label'", ")", ",", "train_examples", ")", ")", "\n", "dev_examples", "=", "list", "(", "self", ".", "_read_tacred_file", "(", "self", ".", "input_dev_file", ")", ")", "\n", "test_examples", "=", "list", "(", "self", ".", "_read_tacred_file", "(", "self", ".", "input_test_file", ")", ")", "\n", "\n", "for", "sample_ratio", "in", "np", ".", "linspace", "(", ".1", ",", "1.0", ",", "10", ")", ":", "\n", "            ", "sampling_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "output_dir", ",", "str", "(", "int", "(", "sample_ratio", "*", "100", ")", ")", ")", "\n", "subsampled_ids_file", "=", "os", ".", "path", ".", "join", "(", "sampling_dir", ",", "\"sentence_ids\"", ")", "\n", "\n", "if", "self", ".", "dataset", "==", "'tacred'", ":", "\n", "                ", "if", "sample_ratio", "==", "1.0", ":", "\n", "                    ", "subsampled_examples", "=", "train_examples", "\n", "", "else", ":", "\n", "                    ", "subsampled_examples", ",", "_", "=", "train_test_split", "(", "train_examples", ",", "\n", "train_size", "=", "sample_ratio", ",", "\n", "stratify", "=", "train_labels", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Unsupported dataset: \"", "+", "self", ".", "dataset", ")", "\n", "\n", "", "with", "open", "(", "make_path", "(", "subsampled_ids_file", ")", ",", "'w'", ")", "as", "ids_file", ":", "\n", "                ", "for", "example", "in", "subsampled_examples", ":", "\n", "                    ", "ids_file", ".", "write", "(", "str", "(", "example", "[", "'id'", "]", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "for", "masking_mode", "in", "self", ".", "masking_modes", ":", "\n", "                ", "masking_mode_name", "=", "'unmasked'", "if", "masking_mode", "is", "None", "else", "masking_mode", "\n", "masking_dir", "=", "os", ".", "path", ".", "join", "(", "sampling_dir", ",", "masking_mode_name", ")", "\n", "\n", "print", "(", "\"Creating train set with sampling ratio {:.1f} and masking mode {}\"", "\n", ".", "format", "(", "sample_ratio", ",", "masking_mode_name", ")", ")", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "masking_dir", ",", "\"train.jsonl\"", ")", "\n", "\n", "if", "masking_mode", "is", "None", ":", "\n", "                    ", "masked_examples", "=", "subsampled_examples", "\n", "", "else", ":", "\n", "                    ", "masked_examples", "=", "[", "SemEval2010Task8", ".", "apply_masking_mode", "(", "example", ",", "masking_mode", ")", "\n", "for", "example", "in", "subsampled_examples", "]", "\n", "\n", "", "with", "open", "(", "make_path", "(", "output_train_file", ")", ",", "'w'", ")", "as", "output_file", ":", "\n", "                    ", "for", "example", "in", "masked_examples", ":", "\n", "                        ", "output_file", ".", "write", "(", "json", ".", "dumps", "(", "example", ")", "+", "\"\\n\"", ")", "\n", "\n", "# Write dev set with different masking modes", "\n", "", "", "", "", "for", "masking_mode", "in", "self", ".", "masking_modes", ":", "\n", "            ", "masking_mode_name", "=", "'unmasked'", "if", "masking_mode", "is", "None", "else", "masking_mode", "\n", "masking_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "output_dir", ",", "masking_mode_name", ")", "\n", "\n", "print", "(", "\"Creating dev and test set with masking mode {}\"", ".", "format", "(", "masking_mode_name", ")", ")", "\n", "output_dev_file", "=", "os", ".", "path", ".", "join", "(", "masking_dir", ",", "\"dev.jsonl\"", ")", "\n", "output_test_file", "=", "os", ".", "path", ".", "join", "(", "masking_dir", ",", "\"test.jsonl\"", ")", "\n", "\n", "if", "masking_mode", "is", "None", ":", "\n", "                ", "masked_dev_examples", "=", "dev_examples", "\n", "masked_test_examples", "=", "test_examples", "\n", "", "else", ":", "\n", "                ", "masked_dev_examples", "=", "[", "SemEval2010Task8", ".", "apply_masking_mode", "(", "example", ",", "masking_mode", ")", "\n", "for", "example", "in", "dev_examples", "]", "\n", "masked_test_examples", "=", "[", "SemEval2010Task8", ".", "apply_masking_mode", "(", "example", ",", "masking_mode", ")", "\n", "for", "example", "in", "test_examples", "]", "\n", "\n", "", "with", "open", "(", "make_path", "(", "output_dev_file", ")", ",", "'w'", ")", "as", "output_file", ":", "\n", "                ", "for", "example", "in", "masked_dev_examples", ":", "\n", "                    ", "output_file", ".", "write", "(", "json", ".", "dumps", "(", "example", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "with", "open", "(", "make_path", "(", "output_test_file", ")", ",", "'w'", ")", "as", "output_file", ":", "\n", "                ", "for", "example", "in", "masked_test_examples", ":", "\n", "                    ", "output_file", ".", "write", "(", "json", ".", "dumps", "(", "example", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_semeval_format_file": [[188, 213], ["open", "open", "input_file.readline", "input_file.readline.split", "dataset_converter.DatasetConverter._split_tokens", "dataset_converter.DatasetConverter._parse_args", "input_file.readline().strip", "input_file.readline", "input_file.readline", "output_file.write", "tokens_string.strip", "input_file.readline", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._split_tokens", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._parse_args"], ["", "", "", "", "def", "_convert_semeval_format_file", "(", "self", ",", "input_path", ",", "output_path", ",", "sample_ratio", "=", "None", ")", ":", "\n", "        ", "with", "open", "(", "input_path", ",", "mode", "=", "\"r\"", ")", "as", "input_file", ",", "open", "(", "output_path", ",", "mode", "=", "\"w\"", ")", "as", "output_file", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "tokens_line", "=", "input_file", ".", "readline", "(", ")", "\n", "if", "not", "tokens_line", ":", "\n", "                    ", "break", "\n", "\n", "", "(", "index", ",", "tokens_string", ")", "=", "tokens_line", ".", "split", "(", "'\\t'", ",", "maxsplit", "=", "1", ")", "# separate index and tokens", "\n", "tokens_string", "=", "tokens_string", ".", "strip", "(", ")", "[", "1", ":", "-", "1", "]", "# remove quotation marks", "\n", "tokens", "=", "self", ".", "_split_tokens", "(", "tokens_string", ")", "\n", "\n", "tokens", ",", "first_args", ",", "second_args", "=", "self", ".", "_parse_args", "(", "tokens", ")", "\n", "\n", "relation_label", "=", "input_file", ".", "readline", "(", ")", ".", "strip", "(", ")", "# Remove trailing newline", "\n", "_", "=", "input_file", ".", "readline", "(", ")", "# Comment string", "\n", "_", "=", "input_file", ".", "readline", "(", ")", "# Empty line separator", "\n", "\n", "example", "=", "{", "\n", "\"id\"", ":", "index", ",", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"label\"", ":", "relation_label", ",", "\n", "\"entities\"", ":", "[", "first_args", ",", "second_args", "]", "\n", "}", "\n", "\n", "output_file", ".", "write", "(", "json", ".", "dumps", "(", "example", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._split_tokens": [[214, 227], ["tokens_string.replace().replace().replace().replace().replace().replace().replace().replace().replace", "token.strip", "tokens_string.replace().replace().replace().replace().replace().replace().replace().replace", "tokens_string.replace().replace().replace().replace().replace().replace().replace().replace().replace.split", "len", "tokens_string.replace().replace().replace().replace().replace().replace().replace", "token.strip", "tokens_string.replace().replace().replace().replace().replace().replace", "tokens_string.replace().replace().replace().replace().replace", "tokens_string.replace().replace().replace().replace", "tokens_string.replace().replace().replace", "tokens_string.replace().replace", "tokens_string.replace"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "_split_tokens", "(", "tokens_string", ")", ":", "\n", "        ", "prepared_string", "=", "tokens_string", ".", "replace", "(", "\".\"", ",", "\" . \"", ")", ".", "replace", "(", "\"<e1>\"", ",", "\" <e1>\"", ")", ".", "replace", "(", "\"</e1>\"", ",", "\"</e1> \"", ")", ".", "replace", "(", "\"<e2>\"", ",", "\" <e2>\"", ")", ".", "replace", "(", "\"</e2>\"", ",", "\"</e2> \"", ")", ".", "replace", "(", "\",\"", ",", "\" , \"", ")", ".", "replace", "(", "\"'\"", ",", "\" ' \"", ")", ".", "replace", "(", "\"!\"", ",", "\" ! \"", ")", ".", "replace", "(", "\"?\"", ",", "\" ? \"", ")", "\n", "return", "[", "token", ".", "strip", "(", ")", "for", "token", "in", "prepared_string", ".", "split", "(", "\" \"", ")", "if", "len", "(", "token", ".", "strip", "(", ")", ")", ">", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._parse_args": [[228, 232], ["dataset_converter.DatasetConverter._parse_arg", "dataset_converter.DatasetConverter._parse_arg"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._parse_arg", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._parse_arg"], ["", "def", "_parse_args", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "tokens", ",", "first_args", "=", "self", ".", "_parse_arg", "(", "tokens", ",", "'e1'", ")", "\n", "tokens", ",", "second_args", "=", "self", ".", "_parse_arg", "(", "tokens", ",", "'e2'", ")", "\n", "return", "tokens", ",", "first_args", ",", "second_args", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._parse_arg": [[233, 278], ["enumerate", "token.startswith", "token.endswith", "dataset_converter.DatasetConverter._is_empty_token", "dataset_converter.DatasetConverter._is_empty_token", "cleaned_tokens.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._is_empty_token", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._is_empty_token"], ["", "@", "staticmethod", "\n", "def", "_parse_arg", "(", "tokens", ",", "arg_label", ")", ":", "\n", "        ", "\"\"\"\n        Parses a relation argument with the given xml entity label.\n        Returns the tokens without the xml entity label and the token offsets of the argument.\n        \"\"\"", "\n", "start_tag", "=", "'<'", "+", "arg_label", "+", "'>'", "\n", "end_tag", "=", "'</'", "+", "arg_label", "+", "'>'", "\n", "cleaned_tokens", "=", "[", "]", "\n", "\n", "arg_start_idx", "=", "None", "\n", "arg_end_idx", "=", "None", "\n", "\n", "# track the index difference due to removed empty tokens", "\n", "cleaned_tokens_offset", "=", "0", "\n", "\n", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "\n", "            ", "if", "token", ".", "startswith", "(", "start_tag", ")", ":", "\n", "                ", "arg_start_idx", "=", "index", "-", "cleaned_tokens_offset", "\n", "token", "=", "token", "[", "len", "(", "start_tag", ")", ":", "]", "# clean the tag from the token", "\n", "\n", "", "if", "token", ".", "endswith", "(", "end_tag", ")", ":", "\n", "                ", "token", "=", "token", "[", ":", "-", "len", "(", "end_tag", ")", "]", "# clean the tag from the token", "\n", "\n", "# If the current token is now empty, it is going to be removed", "\n", "# and the end offset will be a token earlier", "\n", "if", "DatasetConverter", ".", "_is_empty_token", "(", "token", ")", ":", "\n", "                    ", "arg_end_idx", "=", "index", "-", "cleaned_tokens_offset", "\n", "", "else", ":", "\n", "                    ", "arg_end_idx", "=", "index", "-", "cleaned_tokens_offset", "+", "1", "\n", "\n", "", "", "if", "DatasetConverter", ".", "_is_empty_token", "(", "token", ")", ":", "\n", "                ", "cleaned_tokens_offset", "+=", "1", "\n", "", "else", ":", "\n", "                ", "cleaned_tokens", ".", "append", "(", "token", ")", "\n", "\n", "", "", "assert", "arg_start_idx", "is", "not", "None", "and", "arg_end_idx", "is", "not", "None", ",", "\"Argument offsets could not be found\"", "\n", "\n", "# argument_offsets = []", "\n", "# argument_offsets += list(range(-arg_start_idx, 0))  # Add negative offsets up to the argument", "\n", "# argument_offsets += [0] * (arg_end_idx-arg_start_idx)  # within the argument, all offsets are 0", "\n", "# argument_offsets += list(range(0, len(tokens) - arg_end_idx))  # add positive offsets after the argument", "\n", "\n", "return", "cleaned_tokens", ",", "(", "arg_start_idx", ",", "arg_end_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._convert_tacred_format_file": [[279, 283], ["open", "dataset_converter.DatasetConverter._read_tacred_file", "output_file.write", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._read_tacred_file"], ["", "def", "_convert_tacred_format_file", "(", "self", ",", "input_file", ",", "output_file", ")", ":", "\n", "        ", "with", "open", "(", "output_file", ",", "'w'", ")", "as", "output_file", ":", "\n", "            ", "for", "example", "in", "self", ".", "_read_tacred_file", "(", "input_file", ")", ":", "\n", "                ", "output_file", ".", "write", "(", "json", ".", "dumps", "(", "example", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._read_tacred_file": [[284, 304], ["open", "json.loads", "input_file.readline", "dataset_converter.DatasetConverter.normalize_glove_tokens"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter.normalize_glove_tokens"], ["", "", "", "def", "_read_tacred_file", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "with", "open", "(", "input_file", ",", "'r'", ")", "as", "input_file", ":", "\n", "            ", "input_examples", "=", "json", ".", "loads", "(", "input_file", ".", "readline", "(", ")", ")", "\n", "for", "input_example", "in", "input_examples", ":", "\n", "                ", "tokens", "=", "input_example", "[", "'token'", "]", "\n", "subj_offsets", "=", "(", "input_example", "[", "'subj_start'", "]", ",", "input_example", "[", "'subj_end'", "]", "+", "1", ")", "\n", "obj_offsets", "=", "(", "input_example", "[", "'obj_start'", "]", ",", "input_example", "[", "'obj_end'", "]", "+", "1", ")", "\n", "\n", "tokens", "=", "self", ".", "normalize_glove_tokens", "(", "tokens", ")", "\n", "\n", "output_example", "=", "{", "\n", "\"id\"", ":", "input_example", "[", "'id'", "]", ",", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"label\"", ":", "input_example", "[", "'relation'", "]", ",", "\n", "\"entities\"", ":", "(", "subj_offsets", ",", "obj_offsets", ")", ",", "\n", "\"grammar\"", ":", "(", "'SUBJ'", ",", "'OBJ'", ")", ",", "\n", "\"type\"", ":", "(", "input_example", "[", "'subj_type'", "]", ",", "input_example", "[", "'obj_type'", "]", ")", "\n", "}", "\n", "\n", "yield", "output_example", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter.normalize_glove_tokens": [[305, 310], ["None"], "methods", ["None"], ["", "", "", "def", "normalize_glove_tokens", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "[", "self", ".", "glove_mapping", "[", "token", "]", "\n", "if", "token", "in", "self", ".", "glove_mapping", "\n", "else", "token", "\n", "for", "token", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter._is_empty_token": [[311, 314], ["len", "token.strip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_empty_token", "(", "token", ")", ":", "\n", "        ", "return", "len", "(", "token", ".", "strip", "(", ")", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.main": [[316, 320], ["os.path.exists", "dataset_converter.DatasetConverter", "dataset_converter.DatasetConverter.run"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter.run"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "exists", "(", "args", ".", "dataset_dir", ")", ",", "\"Input directory does not exist\"", "\n", "converter", "=", "DatasetConverter", "(", "args", ".", "dataset", ",", "args", ".", "dataset_dir", ",", "args", ".", "output_dir", ",", "args", ".", "subsample", ")", "\n", "converter", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._remove_label_direction": [[27, 33], ["label.find"], "function", ["None"], ["def", "_remove_label_direction", "(", "label", ")", ":", "\n", "    ", "direction_suffix_start", "=", "label", ".", "find", "(", "'('", ")", "\n", "if", "direction_suffix_start", "!=", "-", "1", ":", "\n", "        ", "return", "label", "[", ":", "direction_suffix_start", "]", "\n", "", "else", ":", "\n", "        ", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._get_max_label_length": [[35, 37], ["max", "len"], "function", ["None"], ["", "", "def", "_get_max_label_length", "(", "labels", ")", ":", "\n", "    ", "return", "max", "(", "[", "len", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._print_labeled_confusion_matrix": [[39, 48], ["sklearn.metrics.confusion_matrix", "numpy.array2string", "relation_extraction._get_max_label_length", "zip", "np.array2string.splitlines", "print", "len"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._get_max_label_length"], ["", "def", "_print_labeled_confusion_matrix", "(", "labels", ",", "labels_dev", ",", "labels_pred_dev", ")", ":", "\n", "    ", "conf_matrix", "=", "confusion_matrix", "(", "labels_dev", ",", "labels_pred_dev", ",", "labels", "=", "labels", ")", "\n", "conf_matrix_str", "=", "np", ".", "array2string", "(", "conf_matrix", ",", "max_line_width", "=", "120", ",", "threshold", "=", "999999", ")", "\n", "\n", "max_label_length", "=", "_get_max_label_length", "(", "labels", ")", "\n", "\n", "for", "(", "label", ",", "matrix_row", ")", "in", "zip", "(", "labels", ",", "conf_matrix_str", ".", "splitlines", "(", ")", ")", ":", "\n", "        ", "n_whitespaces", "=", "(", "max_label_length", "-", "len", "(", "label", ")", ")", "+", "1", "\n", "print", "(", "label", "+", "(", "n_whitespaces", "*", "' '", ")", "+", "matrix_row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._print_undirected_classifcation_scores": [[50, 124], ["list", "dict", "dict", "dict", "dict", "range", "print", "relation_extraction._get_max_label_length", "print", "print", "print", "print", "print", "set", "len", "relation_extraction._remove_label_direction", "relation_extraction._remove_label_direction", "dict.get", "dict.get", "dict.get", "print", "macro_f1_scores.append", "print", "macro_f1_scores.append", "print", "macro_f1_scores.append", "macro_f1_scores_wo_negative.append", "numpy.mean", "numpy.mean", "relation_extraction._remove_label_direction", "macro_f1_scores_wo_negative.append", "macro_f1_scores_wo_negative.append", "len", "dict.get", "dict.get", "dict.get", "dict.get"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._get_max_label_length", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._remove_label_direction", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._remove_label_direction", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._remove_label_direction"], ["", "", "def", "_print_undirected_classifcation_scores", "(", "labels", ",", "negative_label", ",", "labels_dev", ",", "labels_pred_dev", ")", ":", "\n", "    ", "undirected_labels", "=", "list", "(", "set", "(", "[", "_remove_label_direction", "(", "label", ")", "for", "label", "in", "labels", "if", "label", "!=", "'<unk>'", "]", ")", ")", "\n", "\n", "tp_counts", "=", "dict", "(", ")", "\n", "fp_counts", "=", "dict", "(", ")", "\n", "tn_counts", "=", "dict", "(", ")", "\n", "fn_counts", "=", "dict", "(", ")", "\n", "\n", "for", "example_idx", "in", "range", "(", "len", "(", "labels_dev", ")", ")", ":", "\n", "        ", "true_label", "=", "labels_dev", "[", "example_idx", "]", "\n", "pred_label", "=", "labels_pred_dev", "[", "example_idx", "]", "\n", "\n", "undirected_true_label", "=", "_remove_label_direction", "(", "true_label", ")", "\n", "undirected_pred_label", "=", "_remove_label_direction", "(", "pred_label", ")", "\n", "\n", "for", "undirected_label", "in", "undirected_labels", ":", "\n", "# for this label the example is supposed to be a true positive", "\n", "            ", "if", "undirected_label", "==", "undirected_true_label", ":", "\n", "                ", "if", "pred_label", "==", "true_label", ":", "\n", "                    ", "tp_counts", "[", "undirected_label", "]", "=", "tp_counts", ".", "get", "(", "undirected_label", ",", "0", ")", "+", "1", "\n", "", "else", ":", "\n", "                    ", "fn_counts", "[", "undirected_label", "]", "=", "fn_counts", ".", "get", "(", "undirected_label", ",", "0", ")", "+", "1", "\n", "\n", "# for this label the example is supposed to be a true negative", "\n", "", "", "else", ":", "\n", "                ", "if", "undirected_pred_label", "!=", "undirected_label", ":", "\n", "                    ", "tn_counts", "[", "undirected_label", "]", "=", "tn_counts", ".", "get", "(", "undirected_label", ",", "0", ")", "+", "1", "\n", "", "else", ":", "\n", "                    ", "fp_counts", "[", "undirected_label", "]", "=", "fp_counts", ".", "get", "(", "undirected_label", ",", "0", ")", "+", "1", "\n", "\n", "", "", "", "", "macro_f1_scores", "=", "[", "]", "\n", "macro_f1_scores_wo_negative", "=", "[", "]", "\n", "\n", "print", "(", ")", "\n", "max_label_length", "=", "_get_max_label_length", "(", "undirected_labels", ")", "\n", "print", "(", "max_label_length", "*", "' '", "+", "'     P     R    F1'", ")", "\n", "for", "undirected_label", "in", "undirected_labels", ":", "\n", "        ", "tps", "=", "tp_counts", ".", "get", "(", "undirected_label", ",", "0", ")", "\n", "fps", "=", "fp_counts", ".", "get", "(", "undirected_label", ",", "0", ")", "\n", "fns", "=", "fn_counts", ".", "get", "(", "undirected_label", ",", "0", ")", "\n", "\n", "precision_denominator", "=", "tps", "+", "fps", "\n", "recall_denominator", "=", "tps", "+", "fns", "\n", "if", "precision_denominator", "==", "0", "or", "recall_denominator", "==", "0", ":", "\n", "            ", "print", "(", "\"Skipping %s: division by zero, assuming f1 of 0\"", "%", "undirected_label", ")", "\n", "macro_f1_scores", ".", "append", "(", "0", ")", "\n", "if", "undirected_label", "!=", "negative_label", ":", "\n", "                ", "macro_f1_scores_wo_negative", ".", "append", "(", "0", ")", "\n", "", "continue", "\n", "\n", "", "precision", "=", "tps", "/", "precision_denominator", "\n", "recall", "=", "tps", "/", "recall_denominator", "\n", "\n", "f1_denominator", "=", "precision", "+", "recall", "\n", "if", "f1_denominator", "==", "0", ":", "\n", "            ", "print", "(", "\"Skipping %s: division by zero, assuming f1 of 0\"", "%", "undirected_label", ")", "\n", "macro_f1_scores", ".", "append", "(", "0", ")", "\n", "if", "undirected_label", "!=", "negative_label", ":", "\n", "                ", "macro_f1_scores_wo_negative", ".", "append", "(", "0", ")", "\n", "", "continue", "\n", "\n", "", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "f1_denominator", "\n", "\n", "label_padding", "=", "(", "max_label_length", "-", "len", "(", "undirected_label", ")", "-", "1", ")", "*", "' '", "\n", "print", "(", "\"{}{:6.2f}{:6.2f}{:6.2f}\"", ".", "format", "(", "undirected_label", "+", "':'", "+", "label_padding", ",", "precision", ",", "recall", ",", "f1", ")", ")", "\n", "\n", "macro_f1_scores", ".", "append", "(", "f1", ")", "\n", "if", "undirected_label", "!=", "negative_label", ":", "\n", "            ", "macro_f1_scores_wo_negative", ".", "append", "(", "f1", ")", "\n", "\n", "", "", "print", "(", ")", "\n", "print", "(", "\"Per relation macro f1: {:.2f}\"", ".", "format", "(", "np", ".", "mean", "(", "macro_f1_scores", ")", ")", ")", "\n", "print", "(", "\"Per relation macro f1 excluding negative relation: {:.2f}\"", ".", "format", "(", "np", ".", "mean", "(", "macro_f1_scores_wo_negative", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._print_classification_details": [[126, 134], ["label_encoder.get_items", "print", "relation_extraction._print_labeled_confusion_matrix", "relation_extraction._print_undirected_classifcation_scores", "label_encoder.get_item_for_index", "label_encoder.get_item_for_index", "sklearn.metrics.classification_report"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_items", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._print_labeled_confusion_matrix", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._print_undirected_classifcation_scores", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index"], ["", "def", "_print_classification_details", "(", "label_encoder", ",", "label_idxs_dev", ",", "label_idxs_pred_dev", ",", "negative_label", ")", ":", "\n", "    ", "labels", "=", "label_encoder", ".", "get_items", "(", ")", "\n", "labels_dev", "=", "[", "label_encoder", ".", "get_item_for_index", "(", "index", ")", "for", "index", "in", "label_idxs_dev", "]", "\n", "labels_pred_dev", "=", "[", "label_encoder", ".", "get_item_for_index", "(", "index", ")", "for", "index", "in", "label_idxs_pred_dev", "]", "\n", "\n", "print", "(", "classification_report", "(", "labels_dev", ",", "labels_pred_dev", ")", ")", "\n", "_print_labeled_confusion_matrix", "(", "labels", ",", "labels_dev", ",", "labels_pred_dev", ")", "\n", "_print_undirected_classifcation_scores", "(", "labels", ",", "negative_label", ",", "labels_dev", ",", "labels_pred_dev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction.run_epoch": [[136, 234], ["print", "max", "set", "set.discard", "enumerate", "len", "model.eval", "print", "train_utils.iter_apply", "numpy.argmax", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "print", "logger.log", "train_utils.predict", "logger.log_dev_predictions", "len", "int", "label_encoder.get_items", "label_encoder.get_idx_for_item", "train_utils.iter_data", "model.train", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model", "compute_loss_fct", "epoch_labels_pred_train.extend", "epoch_labels_train.extend", "len", "len", "sklearn.metrics.accuracy_score", "relation_extraction._print_classification_details", "label_encoder.get_item_for_index", "train_utils.predict", "logger.log_test_predictions", "numpy.argmax", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "print", "label_encoder.get_item_for_index", "label_encoder.get_idx_for_item", "logger.log_test_pr_curve", "sklearn.utils.shuffle", "torch.tensor", "torch.tensor", "torch.tensor", "clf_logits.detach().cpu", "sklearn.metrics.accuracy_score", "len", "len", "clf_logits.detach", "relation_extraction.train"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_apply", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.log", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.predict", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_dev_predictions", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_items", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_idx_for_item", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_data", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction.train", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction._print_classification_details", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.predict", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_test_predictions", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_idx_for_item", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_test_pr_curve", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction.train"], ["", "def", "run_epoch", "(", "model", ",", "train", ",", "dev", ",", "test", ",", "compute_loss_fct", ",", "batch_size", ",", "device", ",", "epoch", ",", "label_encoder", ",", "logger", ",", "\n", "negative_label", ",", "log_with_id", "=", "True", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "print", "(", "'-'", "*", "100", ")", "\n", "\n", "indices_train", ",", "mask_train", ",", "labels_train", ",", "_", ",", "_", "=", "train", "\n", "\n", "n_batches", "=", "len", "(", "indices_train", ")", "//", "batch_size", "\n", "\n", "current_loss", ":", "float", "=", "0", "\n", "seen_sentences", "=", "0", "\n", "modulo", "=", "max", "(", "1", ",", "int", "(", "n_batches", "/", "10", ")", ")", "\n", "\n", "positive_labels", "=", "set", "(", "label_encoder", ".", "get_items", "(", ")", ")", "\n", "positive_labels", ".", "discard", "(", "negative_label", ")", "\n", "positive_labels", "=", "[", "label_encoder", ".", "get_idx_for_item", "(", "label", ")", "for", "label", "in", "positive_labels", "]", "\n", "\n", "epoch_labels_pred_train", "=", "[", "]", "\n", "epoch_labels_train", "=", "[", "]", "\n", "\n", "# TODO: refactor!", "\n", "for", "batch_no", ",", "(", "batch_indices", ",", "batch_mask", ",", "batch_labels", ")", "in", "enumerate", "(", "iter_data", "(", "\n", "*", "shuffle", "(", "indices_train", ",", "mask_train", ",", "labels_train", ",", "random_state", "=", "np", ".", "random", ")", ",", "\n", "batch_size", "=", "batch_size", ",", "truncate", "=", "True", ",", "verbose", "=", "True", ")", ")", ":", "\n", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "x", "=", "torch", ".", "tensor", "(", "batch_indices", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "y", "=", "torch", ".", "tensor", "(", "batch_labels", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "batch_mask", ")", ".", "to", "(", "device", ")", "\n", "\n", "lm_logits", ",", "clf_logits", "=", "model", "(", "x", ")", "\n", "loss", "=", "compute_loss_fct", "(", "x", ",", "y", ",", "mask", ",", "clf_logits", ",", "lm_logits", ")", "\n", "\n", "epoch_labels_pred_train", ".", "extend", "(", "np", ".", "argmax", "(", "clf_logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "1", ")", ")", "\n", "epoch_labels_train", ".", "extend", "(", "batch_labels", ")", "\n", "\n", "seen_sentences", "+=", "len", "(", "batch_indices", ")", "\n", "current_loss", "+=", "loss", "\n", "\n", "if", "batch_no", "%", "modulo", "==", "0", ":", "\n", "            ", "train_acc", "=", "accuracy_score", "(", "epoch_labels_train", ",", "epoch_labels_pred_train", ")", "*", "100", "\n", "train_micro_f1", "=", "f1_score", "(", "epoch_labels_train", ",", "epoch_labels_pred_train", ",", "average", "=", "'micro'", ",", "labels", "=", "positive_labels", ")", "\n", "train_macro_f1", "=", "f1_score", "(", "epoch_labels_train", ",", "epoch_labels_pred_train", ",", "average", "=", "'macro'", ",", "labels", "=", "positive_labels", ")", "\n", "print", "(", "\"epoch {0} - iter {1}/{2} - loss {3:.8f} - acc {4:.2f} - micro f1 {5:.2f} - macro f1 {6:.2f}\"", "\n", ".", "format", "(", "epoch", ",", "batch_no", ",", "n_batches", ",", "current_loss", "/", "seen_sentences", ",", "train_acc", ",", "train_micro_f1", ",", "train_macro_f1", ")", ")", "\n", "\n", "", "", "current_loss", "/=", "len", "(", "indices_train", ")", "\n", "\n", "# IMPORTANT: Switch to eval mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "indices_dev", ",", "mask_dev", ",", "labels_dev", ",", "ids_dev", ",", "_", "=", "dev", "\n", "\n", "print", "(", "'-'", "*", "100", ")", "\n", "dev_logits", ",", "dev_loss", "=", "iter_apply", "(", "indices_dev", ",", "mask_dev", ",", "labels_dev", ",", "model", ",", "compute_loss_fct", ",", "device", ",", "batch_size", ")", "\n", "\n", "avg_dev_loss", "=", "dev_loss", "/", "len", "(", "indices_dev", ")", "\n", "\n", "label_pred_dev", "=", "np", ".", "argmax", "(", "dev_logits", ",", "1", ")", "\n", "\n", "dev_accuracy", "=", "accuracy_score", "(", "labels_dev", ",", "label_pred_dev", ")", "*", "100.", "\n", "dev_micro_f1", "=", "f1_score", "(", "labels_dev", ",", "label_pred_dev", ",", "average", "=", "'micro'", ",", "labels", "=", "positive_labels", ")", "\n", "dev_macro_f1", "=", "f1_score", "(", "labels_dev", ",", "label_pred_dev", ",", "average", "=", "'macro'", ",", "labels", "=", "positive_labels", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "_print_classification_details", "(", "label_encoder", ",", "labels_dev", ",", "label_pred_dev", ",", "negative_label", ")", "\n", "\n", "", "print", "(", "'EVALUATION: cost: {} | acc: {} | micro f1: {} | macro f1: {}'", ".", "format", "(", "\n", "dev_loss", "/", "len", "(", "indices_dev", ")", ",", "dev_accuracy", ",", "dev_micro_f1", ",", "dev_macro_f1", ")", ")", "\n", "\n", "# save predictions on test dataset per epoch", "\n", "\n", "logger", ".", "log", "(", "train_loss", "=", "current_loss", ",", "\n", "dev_loss", "=", "avg_dev_loss", ",", "\n", "dev_accuracy", "=", "dev_accuracy", ",", "\n", "dev_micro_f1", "=", "dev_micro_f1", ",", "\n", "dev_macro_f1", "=", "dev_macro_f1", ")", "\n", "\n", "label_idxs_pred_dev", ",", "_", "=", "predict", "(", "indices_dev", ",", "model", ",", "device", ",", "batch_size", ")", "\n", "labels_pred_dev", "=", "[", "label_encoder", ".", "get_item_for_index", "(", "label_index", ")", "for", "label_index", "in", "label_idxs_pred_dev", "]", "\n", "logger", ".", "log_dev_predictions", "(", "epoch", ",", "labels_pred_dev", ",", "ids_dev", ",", "log_with_id", "=", "log_with_id", ")", "\n", "\n", "if", "test", "is", "not", "None", ":", "\n", "        ", "indices_test", ",", "_", ",", "labels_test", ",", "ids_test", ",", "entity_ids_test", "=", "test", "\n", "\n", "log_pr_curve", "=", "len", "(", "labels_test", ")", ">", "0", "and", "entity_ids_test", "is", "not", "None", "\n", "\n", "label_idxs_pred_test", ",", "probs_test", "=", "predict", "(", "indices_test", ",", "model", ",", "device", ",", "batch_size", ",", "\n", "compute_probs", "=", "log_pr_curve", ")", "\n", "\n", "labels_pred_test", "=", "[", "label_encoder", ".", "get_item_for_index", "(", "label_index", ")", "for", "label_index", "in", "label_idxs_pred_test", "]", "\n", "logger", ".", "log_test_predictions", "(", "epoch", ",", "labels_pred_test", ",", "ids_test", ",", "log_with_id", "=", "log_with_id", ")", "\n", "\n", "if", "log_pr_curve", ":", "\n", "            ", "negative_label_idx", "=", "label_encoder", ".", "get_idx_for_item", "(", "negative_label", ")", "\n", "logger", ".", "log_test_pr_curve", "(", "epoch", ",", "entity_ids_test", ",", "labels_test", ",", "probs_test", ",", "negative_label_idx", ",", "label_encoder", ")", "\n", "\n", "", "", "return", "avg_dev_loss", ",", "dev_micro_f1", ",", "dev_macro_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction.train": [[236, 372], ["model_pytorch.dotdict", "print", "logging_utils.ResultLogger", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.device", "torch.cuda.device_count", "print", "text_utils.TextEncoder", "text_utils.LabelEncoder", "len", "len", "len", "len", "logging_utils.ResultLogger.log_dev_labels", "len", "model_pytorch.DoubleHeadModel", "torch.nn.CrossEntropyLoss", "opt.OpenAIAdam", "loss.ClassificationLossCompute", "nn.DataParallel.to", "torch.nn.DataParallel", "range", "locals().items", "datasets.SemEval2010Task8.fetch", "datasets.SemEval2010Task8.encode", "min", "datasets.SemEval2010Task8.transform", "ValueError", "max", "len", "nn.DataParallel.parameters", "model_pytorch.load_openai_pretrained_model", "os.path.join", "train_utils.persist_model", "relation_extraction.run_epoch", "torch.cuda.is_available", "ValueError", "len", "len", "logging_utils.ResultLogger.get_base_dir", "locals", "text_utils.LabelEncoder.get_item_for_index", "print", "train_utils.persist_model", "datasets.SemEval2010Task8.max_length"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_dev_labels", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.fetch", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.encode", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.transform", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.load_openai_pretrained_model", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.persist_model", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction.run_epoch", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.get_base_dir", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.persist_model", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.max_length"], ["", "def", "train", "(", "dataset", ",", "data_dir", ",", "log_dir", ",", "max_grad_norm", "=", "1", ",", "learning_rate", "=", "6.25e-5", ",", "learning_rate_warmup", "=", "0.002", ",", "\n", "n_ctx", "=", "512", ",", "n_embd", "=", "768", ",", "n_head", "=", "12", ",", "n_layer", "=", "12", ",", "embd_pdrop", "=", ".1", ",", "lm_coef", "=", ".5", ",", "\n", "attn_pdrop", "=", ".1", ",", "resid_pdrop", "=", ".1", ",", "clf_pdrop", "=", ".1", ",", "word_pdrop", "=", ".0", ",", "l2", "=", "0.01", ",", "vector_l2", "=", "True", ",", "\n", "optimizer", "=", "'adam'", ",", "afn", "=", "'gelu'", ",", "learning_rate_schedule", "=", "'warmup_linear'", ",", "\n", "encoder_path", "=", "'model/encoder_bpe_40000.json'", ",", "bpe_path", "=", "'model/vocab_40000.bpe'", ",", "n_transfer", "=", "12", ",", "\n", "beta1", "=", ".9", ",", "beta2", "=", ".999", ",", "e", "=", "1e-8", ",", "batch_size", "=", "8", ",", "max_epochs", "=", "3", ",", "dev_size", "=", ".1", ",", "seed", "=", "0", ",", "load_pre_trained", "=", "True", ",", "\n", "subsampling_rate", "=", "1.0", ",", "train_set_limit", "=", "None", ",", "dev_file", "=", "None", ",", "dev_set_limit", "=", "None", ",", "skip_test_set", "=", "False", ",", "\n", "verbose_fetcher", "=", "False", ",", "verbose_training", "=", "False", ",", "masking_mode", "=", "None", ",", "write_model", "=", "True", ")", ":", "\n", "\n", "    ", "cfg", "=", "dotdict", "(", "locals", "(", ")", ".", "items", "(", ")", ")", "\n", "print", "(", "cfg", ")", "\n", "\n", "logger", "=", "ResultLogger", "(", "log_dir", ",", "**", "cfg", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "print", "(", "'Device: {} | n_gpu: {}'", ".", "format", "(", "device", ",", "n_gpu", ")", ")", "\n", "\n", "# create / load encoders for text and labels", "\n", "text_encoder", "=", "TextEncoder", "(", "encoder_path", ",", "bpe_path", ")", "\n", "label_encoder", "=", "LabelEncoder", "(", "add_unk", "=", "False", ")", "\n", "\n", "if", "dataset", "==", "'semeval_2010_task8'", ":", "\n", "        ", "predefined_dev_set", "=", "False", "\n", "negative_label", "=", "'Other'", "\n", "log_with_id", "=", "True", "\n", "", "elif", "dataset", "==", "'tacred'", ":", "\n", "        ", "predefined_dev_set", "=", "True", "\n", "dev_size", "=", "None", "\n", "negative_label", "=", "'no_relation'", "\n", "log_with_id", "=", "False", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Dataset '{}' not supported.\"", ".", "format", "(", "dataset", ")", ")", "\n", "\n", "", "encoder", "=", "text_encoder", ".", "encoder", "\n", "encoder", "[", "'_start_'", "]", "=", "len", "(", "encoder", ")", "\n", "encoder", "[", "'_delimiter_'", "]", "=", "len", "(", "encoder", ")", "\n", "encoder", "[", "'_delimiter2_'", "]", "=", "len", "(", "encoder", ")", "\n", "encoder", "[", "'_classify_'", "]", "=", "len", "(", "encoder", ")", "\n", "n_special", "=", "4", "\n", "\n", "if", "dataset", "==", "'tacred'", ":", "\n", "        ", "for", "t", "in", "SemEval2010Task8", ".", "MASKED_ENTITY_TOKENS", ":", "\n", "            ", "text_encoder", ".", "encoder", "[", "t", "]", "=", "len", "(", "text_encoder", ".", "encoder", ")", "\n", "n_special", "+=", "1", "\n", "\n", "# TODO: improve (as a sentence is generally much longer than the two entities)", "\n", "# the input has 3 parts (entity 1, entity 2, sentence) and special tokens", "\n", "# all together should not exceed the context length", "\n", "", "", "max_len", "=", "(", "n_ctx", "-", "n_special", "-", "1", ")", "//", "3", "\n", "\n", "if", "dataset", "==", "'semeval_2010_task8'", "or", "dataset", "==", "'tacred'", ":", "\n", "        ", "corpus", "=", "SemEval2010Task8", ".", "fetch", "(", "data_dir", ",", "dev_size", ",", "seed", ",", "\n", "negative_label", "=", "negative_label", ",", "\n", "subsampling_rate", "=", "subsampling_rate", ",", "\n", "train_set_limit", "=", "train_set_limit", ",", "\n", "dev_set_limit", "=", "dev_set_limit", ",", "\n", "skip_test_set", "=", "skip_test_set", ",", "\n", "predefined_dev_set", "=", "predefined_dev_set", ",", "\n", "verbose", "=", "verbose_fetcher", ",", "\n", "masking_mode", "=", "masking_mode", ",", "\n", "dev_file", "=", "dev_file", ")", "\n", "\n", "corpus", "=", "SemEval2010Task8", ".", "encode", "(", "*", "corpus", ",", "text_encoder", "=", "text_encoder", ",", "label_encoder", "=", "label_encoder", ")", "\n", "n_ctx", "=", "min", "(", "SemEval2010Task8", ".", "max_length", "(", "*", "corpus", ",", "max_len", "=", "max_len", ")", "+", "n_special", "+", "1", ",", "n_ctx", ")", "\n", "transformed_corpus", "=", "SemEval2010Task8", ".", "transform", "(", "*", "corpus", ",", "text_encoder", "=", "text_encoder", ",", "max_length", "=", "max_len", ",", "n_ctx", "=", "n_ctx", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Dataset '{}' not supported.\"", ".", "format", "(", "dataset", ")", ")", "\n", "\n", "", "if", "not", "skip_test_set", ":", "\n", "        ", "train", ",", "dev", ",", "test", "=", "transformed_corpus", "\n", "", "else", ":", "\n", "        ", "train", ",", "dev", "=", "transformed_corpus", "\n", "test", "=", "None", "\n", "\n", "", "_", ",", "_", ",", "labels_dev", ",", "ids_dev", ",", "_", "=", "dev", "\n", "\n", "logger", ".", "log_dev_labels", "(", "\n", "labels_dev", "=", "[", "label_encoder", ".", "get_item_for_index", "(", "label", ")", "for", "label", "in", "labels_dev", "]", ",", "\n", "ids", "=", "ids_dev", ")", "\n", "\n", "batch_size_train", "=", "batch_size", "*", "max", "(", "n_gpu", ",", "1", ")", "\n", "n_updates_total", "=", "(", "len", "(", "train", "[", "0", "]", ")", "//", "batch_size_train", ")", "*", "max_epochs", "\n", "\n", "clf_token", "=", "text_encoder", ".", "encoder", "[", "'_classify_'", "]", "\n", "vocab", "=", "len", "(", "text_encoder", ".", "encoder", ")", "+", "n_ctx", "\n", "n_class", "=", "len", "(", "label_encoder", ")", "\n", "dh_model", "=", "DoubleHeadModel", "(", "cfg", ",", "clf_token", ",", "(", "'classification'", ",", "n_class", ")", ",", "vocab", ",", "n_ctx", ")", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduce", "=", "False", ")", "\n", "model_opt", "=", "OpenAIAdam", "(", "dh_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "learning_rate", ",", "\n", "schedule", "=", "learning_rate_schedule", ",", "\n", "warmup", "=", "learning_rate_warmup", ",", "\n", "t_total", "=", "n_updates_total", ",", "\n", "b1", "=", "beta1", ",", "\n", "b2", "=", "beta2", ",", "\n", "e", "=", "e", ",", "\n", "l2", "=", "l2", ",", "\n", "vector_l2", "=", "vector_l2", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "\n", "compute_loss_fct", "=", "ClassificationLossCompute", "(", "criterion", ",", "\n", "criterion", ",", "\n", "lm_coef", ",", "\n", "model_opt", ")", "\n", "\n", "if", "load_pre_trained", ":", "\n", "        ", "load_openai_pretrained_model", "(", "dh_model", ".", "transformer", ",", "n_ctx", "=", "n_ctx", ",", "n_special", "=", "n_special", ",", "n_transfer", "=", "n_transfer", ")", "\n", "\n", "", "dh_model", ".", "to", "(", "device", ")", "\n", "dh_model", "=", "nn", ".", "DataParallel", "(", "dh_model", ")", "\n", "\n", "if", "write_model", ":", "\n", "        ", "model_dir", "=", "path", ".", "join", "(", "logger", ".", "get_base_dir", "(", ")", ",", "'models'", ")", "\n", "persist_model", "(", "model_dir", ",", "dh_model", ",", "text_encoder", ",", "label_encoder", ")", "\n", "\n", "# run training!", "\n", "", "best_f1", "=", "0.", "\n", "for", "epoch", "in", "range", "(", "1", ",", "max_epochs", "+", "1", ")", ":", "\n", "        ", "dev_loss", ",", "_", ",", "dev_macro_f1", "=", "run_epoch", "(", "dh_model", ",", "train", ",", "dev", ",", "test", ",", "compute_loss_fct", ",", "batch_size", ",", "device", ",", "epoch", ",", "\n", "label_encoder", ",", "logger", ",", "negative_label", ",", "\n", "log_with_id", "=", "log_with_id", ",", "verbose", "=", "verbose_training", ")", "\n", "if", "dev_macro_f1", ">", "best_f1", ":", "\n", "            ", "best_f1", "=", "dev_macro_f1", "\n", "\n", "if", "write_model", ":", "\n", "                ", "print", "(", "f'Saving model at epoch {epoch}. With dev_f1 score of {dev_macro_f1}.'", ")", "\n", "model_file_name", "=", "f'model_epoch-{epoch}_dev-macro-f1-{dev_macro_f1}_'", "f'dev-loss-{dev_loss}_{logger.start_time}.pt'", "\n", "persist_model", "(", "model_dir", ",", "dh_model", ",", "text_encoder", ",", "label_encoder", ",", "model_name", "=", "model_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.relation_extraction.evaluate": [[374, 448], ["model_pytorch.dotdict", "print", "logging_utils.ResultLogger", "torch.device", "train_utils.load_model", "model.to.to", "train_utils.predict", "logging_utils.ResultLogger.log_test_predictions", "logging_utils.ResultLogger.close", "locals().items", "datasets.SemEval2010Task8._load_from_jsonl", "datasets.SemEval2010Task8.encode", "ValueError", "label_encoder.get_item_for_index", "sklearn.metrics.accuracy_score", "list", "os.path.join", "analysis_util.evaluate_semeval2010_task8", "print", "list", "list.remove", "sklearn.metrics.precision_recall_fscore_support", "print", "label_encoder.get_idx_for_item", "logging_utils.ResultLogger.log_test_pr_curve", "torch.cuda.is_available", "datasets.SemEval2010Task8.transform", "ValueError", "zip", "tempfile.NamedTemporaryFile", "input_files.append", "tempfile.NamedTemporaryFile.file.close", "os.path.dirname", "sorted", "label_encoder.get_idx_for_item", "locals", "label_encoder.get_item_for_index", "zip", "open", "os.path.realpath", "set", "f.write"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.load_model", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.predict", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_test_predictions", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.close", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.encode", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.evaluate_semeval2010_task8", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_idx_for_item", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.logging_utils.ResultLogger.log_test_pr_curve", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.transform", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.close", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_idx_for_item", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.get_item_for_index"], ["", "", "", "", "def", "evaluate", "(", "dataset", ",", "test_file", ",", "log_dir", ",", "save_dir", ",", "model_file", "=", "'model.pt'", ",", "batch_size", "=", "8", ",", "masking_mode", "=", "None", ")", ":", "\n", "    ", "cfg", "=", "dotdict", "(", "locals", "(", ")", ".", "items", "(", ")", ")", "\n", "print", "(", "cfg", ")", "\n", "\n", "logger", "=", "ResultLogger", "(", "log_dir", ",", "**", "cfg", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "model", ",", "text_encoder", ",", "label_encoder", "=", "load_model", "(", "save_dir", ",", "model_file", "=", "model_file", ")", "\n", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "n_special", "=", "4", "\n", "\n", "n_ctx", "=", "model", ".", "n_ctx", "\n", "max_len", "=", "512", "//", "3", "\n", "\n", "if", "dataset", "==", "'semeval_2010_task8'", "or", "dataset", "==", "'tacred'", ":", "\n", "        ", "test", "=", "SemEval2010Task8", ".", "_load_from_jsonl", "(", "test_file", ",", "is_test", "=", "False", ",", "masking_mode", "=", "masking_mode", ")", "\n", "test", "=", "SemEval2010Task8", ".", "encode", "(", "test", ",", "text_encoder", "=", "text_encoder", ",", "label_encoder", "=", "label_encoder", ")", "\n", "test", "=", "SemEval2010Task8", ".", "transform", "(", "*", "test", ",", "text_encoder", "=", "text_encoder", ",", "max_length", "=", "max_len", ",", "n_ctx", "=", "n_ctx", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Dataset '{}' not supported.\"", ".", "format", "(", "dataset", ")", ")", "\n", "\n", "", "if", "dataset", "==", "'semeval_2010_task8'", ":", "\n", "        ", "negative_label", "=", "'Other'", "\n", "", "elif", "dataset", "==", "'tacred'", ":", "\n", "        ", "negative_label", "=", "'no_relation'", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Dataset '{}' not supported.\"", ".", "format", "(", "dataset", ")", ")", "\n", "\n", "", "indices_test", ",", "_", ",", "label_idxs_test", ",", "ids_test", ",", "entity_ids_test", "=", "test", "\n", "\n", "log_pr_curve", "=", "entity_ids_test", "is", "not", "None", "\n", "\n", "label_idxs_pred", ",", "probs_test", "=", "predict", "(", "indices_test", ",", "model", ",", "device", ",", "batch_size", ",", "compute_probs", "=", "log_pr_curve", ")", "\n", "labels_pred_test", "=", "[", "label_encoder", ".", "get_item_for_index", "(", "label_index", ")", "for", "label_index", "in", "label_idxs_pred", "]", "\n", "logger", ".", "log_test_predictions", "(", "0", ",", "labels_pred_test", ",", "ids_test", ")", "\n", "\n", "test_accuracy", "=", "accuracy_score", "(", "label_idxs_test", ",", "label_idxs_pred", ")", "*", "100.", "\n", "\n", "if", "dataset", "==", "'semeval_2010_task8'", ":", "\n", "        ", "id_labels_true", "=", "[", "(", "id_", ",", "label_encoder", ".", "get_item_for_index", "(", "label_index", ")", ")", "for", "id_", ",", "label_index", "in", "zip", "(", "ids_test", ",", "label_idxs_test", ")", "]", "\n", "id_labels_pred", "=", "list", "(", "zip", "(", "ids_test", ",", "labels_pred_test", ")", ")", "\n", "\n", "input_files", "=", "[", "]", "\n", "for", "id_labels", "in", "[", "id_labels_true", ",", "id_labels_pred", "]", ":", "\n", "            ", "tmp_file", "=", "NamedTemporaryFile", "(", "delete", "=", "True", ")", "\n", "input_files", ".", "append", "(", "tmp_file", ")", "\n", "with", "open", "(", "tmp_file", ".", "name", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "for", "id_", ",", "label", "in", "id_labels", ":", "\n", "                    ", "f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "id_", ",", "label", ")", ")", "\n", "", "", "tmp_file", ".", "file", ".", "close", "(", ")", "\n", "\n", "", "path_to_eval_script", "=", "path", ".", "join", "(", "path", ".", "dirname", "(", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'analysis/semeval/semeval2010_task8_scorer-v1.2.pl'", ")", "\n", "\n", "test_f1", "=", "evaluate_semeval2010_task8", "(", "id_labels_true_file", "=", "input_files", "[", "0", "]", ".", "name", ",", "\n", "id_labels_pred_file", "=", "input_files", "[", "1", "]", ".", "name", ",", "\n", "eval_script", "=", "path_to_eval_script", ")", "\n", "print", "(", "f'TEST: ACC: {test_accuracy} | F1: {test_f1}'", ")", "\n", "\n", "", "else", ":", "\n", "        ", "labels", "=", "list", "(", "sorted", "(", "set", "(", "label_idxs_test", ")", ")", ")", "\n", "labels", ".", "remove", "(", "label_encoder", ".", "get_idx_for_item", "(", "negative_label", ")", ")", "\n", "\n", "test_precision", ",", "test_recall", ",", "test_f1", ",", "_", "=", "precision_recall_fscore_support", "(", "\n", "label_idxs_test", ",", "label_idxs_pred", ",", "average", "=", "'micro'", ",", "labels", "=", "labels", ")", "\n", "print", "(", "f'TEST: ACC: {test_accuracy} | P: {test_precision} | R: {test_recall} | F1: {test_f1}'", ")", "\n", "\n", "", "if", "log_pr_curve", ":", "\n", "        ", "negative_label_idx", "=", "label_encoder", ".", "get_idx_for_item", "(", "negative_label", ")", "\n", "logger", ".", "log_test_pr_curve", "(", "0", ",", "entity_ids_test", ",", "label_idxs_test", ",", "probs_test", ",", "negative_label_idx", ",", "label_encoder", ")", "\n", "\n", "", "logger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.loss.MultipleChoiceLossCompute.__init__": [[6, 11], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lm_criterion", ",", "clf_criterion", ",", "lm_coef", ",", "opt", "=", "None", ")", ":", "\n", "        ", "self", ".", "lm_criterion", "=", "lm_criterion", "\n", "self", ".", "clf_criterion", "=", "clf_criterion", "\n", "self", ".", "lm_coef", "=", "lm_coef", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.loss.MultipleChoiceLossCompute.__call__": [[12, 35], ["loss.MultipleChoiceLossCompute.clf_criterion", "loss.MultipleChoiceLossCompute.sum.backward", "loss.MultipleChoiceLossCompute.sum.item", "X[].contiguous().view", "M.view.view.view", "loss.MultipleChoiceLossCompute.lm_criterion", "lm_losses.view.view.view", "loss.MultipleChoiceLossCompute.sum", "loss.MultipleChoiceLossCompute.opt.step", "loss.MultipleChoiceLossCompute.opt.zero_grad", "M.view.view.size", "lm_losses.view.view.sum", "torch.sum", "loss.MultipleChoiceLossCompute.sum", "X[].contiguous", "X.size", "X.size", "X.size", "lm_losses.view.view.sum"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.opt.OpenAIAdam.step"], ["", "def", "__call__", "(", "self", ",", "X", ",", "Y", ",", "M", ",", "clf_logits", ",", "lm_logits", "=", "None", ",", "only_return_losses", "=", "False", ")", ":", "\n", "# Language modeling loss", "\n", "        ", "if", "lm_logits", "is", "not", "None", ":", "\n", "            ", "x_shifted", "=", "X", "[", ":", ",", ":", ",", "1", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "# Shape: 252", "\n", "M", "=", "M", ".", "view", "(", "-", "1", ",", "M", ".", "size", "(", "2", ")", ")", "\n", "lm_losses", "=", "self", ".", "lm_criterion", "(", "lm_logits", ",", "x_shifted", ")", "\n", "lm_losses", "=", "lm_losses", ".", "view", "(", "X", ".", "size", "(", "0", ")", "*", "X", ".", "size", "(", "1", ")", ",", "X", ".", "size", "(", "2", ")", "-", "1", ")", "\n", "lm_losses", "=", "lm_losses", "*", "M", "[", ":", ",", "1", ":", "]", "\n", "lm_losses", "=", "lm_losses", ".", "sum", "(", "1", ")", "/", "torch", ".", "sum", "(", "M", "[", ":", ",", "1", ":", "]", ",", "1", ")", "\n", "# Classification loss", "\n", "", "clf_losses", "=", "self", ".", "clf_criterion", "(", "clf_logits", ",", "Y", ")", "\n", "if", "only_return_losses", ":", "\n", "            ", "return", "(", "clf_losses", ",", "lm_losses", ")", "if", "lm_logits", "is", "not", "None", "else", "clf_losses", "\n", "\n", "", "if", "self", ".", "lm_coef", ">", "0", "and", "lm_logits", "is", "not", "None", ":", "\n", "            ", "train_loss", "=", "clf_losses", ".", "sum", "(", ")", "+", "self", ".", "lm_coef", "*", "lm_losses", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "train_loss", "=", "clf_losses", ".", "sum", "(", ")", "\n", "", "train_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "opt", ".", "step", "(", ")", "\n", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "", "return", "train_loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.loss.ClassificationLossCompute.__init__": [[39, 44], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lm_criterion", ",", "clf_criterion", ",", "lm_coef", ",", "opt", "=", "None", ")", ":", "\n", "        ", "self", ".", "lm_criterion", "=", "lm_criterion", "\n", "self", ".", "clf_criterion", "=", "clf_criterion", "\n", "self", ".", "lm_coef", "=", "lm_coef", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.loss.ClassificationLossCompute.__call__": [[45, 75], ["loss.ClassificationLossCompute.clf_criterion", "loss.ClassificationLossCompute.sum.backward", "loss.ClassificationLossCompute.sum.item", "X[].contiguous().view", "M.view.view.view", "loss.ClassificationLossCompute.lm_criterion", "lm_losses.view.view.view", "loss.ClassificationLossCompute.sum", "loss.ClassificationLossCompute.opt.step", "loss.ClassificationLossCompute.opt.zero_grad", "M.view.view.size", "lm_losses.view.view.sum", "torch.sum", "loss.ClassificationLossCompute.sum", "X[].contiguous", "X.size", "X.size", "X.size", "lm_losses.view.view.sum"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.opt.OpenAIAdam.step"], ["", "def", "__call__", "(", "self", ",", "X", ",", "Y", ",", "M", ",", "clf_logits", ",", "lm_logits", "=", "None", ",", "only_return_losses", "=", "False", ")", ":", "\n", "# Language modeling loss", "\n", "#if lm_logits is not None:", "\n", "#    x_shifted = X[:, 1:, 0].contiguous().view(-1)", "\n", "#    M         = M.view(-1, M.size(-1))", "\n", "#    lm_losses = self.lm_criterion(lm_logits, x_shifted)", "\n", "#    lm_losses = lm_losses.view(X.size(0), X.size(-2) - 1)", "\n", "#    lm_losses = lm_losses * M[:, 1:]", "\n", "#    lm_losses = lm_losses.sum(1) / torch.sum(M[:, 1:], 1)", "\n", "        ", "if", "lm_logits", "is", "not", "None", ":", "\n", "            ", "x_shifted", "=", "X", "[", ":", ",", ":", ",", "1", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "# Shape: 252", "\n", "M", "=", "M", ".", "view", "(", "-", "1", ",", "M", ".", "size", "(", "2", ")", ")", "\n", "lm_losses", "=", "self", ".", "lm_criterion", "(", "lm_logits", ",", "x_shifted", ")", "\n", "lm_losses", "=", "lm_losses", ".", "view", "(", "X", ".", "size", "(", "0", ")", "*", "X", ".", "size", "(", "1", ")", ",", "X", ".", "size", "(", "2", ")", "-", "1", ")", "\n", "lm_losses", "=", "lm_losses", "*", "M", "[", ":", ",", "1", ":", "]", "\n", "lm_losses", "=", "lm_losses", ".", "sum", "(", "1", ")", "/", "torch", ".", "sum", "(", "M", "[", ":", ",", "1", ":", "]", ",", "1", ")", "\n", "# Classification loss", "\n", "", "clf_losses", "=", "self", ".", "clf_criterion", "(", "clf_logits", ",", "Y", ")", "\n", "if", "only_return_losses", ":", "\n", "            ", "return", "(", "clf_losses", ",", "lm_losses", ")", "if", "lm_logits", "is", "not", "None", "else", "clf_losses", "\n", "\n", "", "if", "self", ".", "lm_coef", ">", "0", "and", "lm_logits", "is", "not", "None", ":", "\n", "            ", "train_loss", "=", "clf_losses", ".", "sum", "(", ")", "+", "self", ".", "lm_coef", "*", "lm_losses", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "train_loss", "=", "clf_losses", ".", "sum", "(", ")", "\n", "", "train_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "opt", ".", "step", "(", ")", "\n", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "", "return", "train_loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.read_log_file": [[11, 28], ["open", "enumerate", "os.path.join", "json.loads", "logs.append"], "function", ["None"], ["def", "read_log_file", "(", "experiment_dir", ",", "log_file_name", "=", "'logs.jsonl'", ")", ":", "\n", "    ", "logs", "=", "[", "]", "\n", "with", "open", "(", "join", "(", "experiment_dir", ",", "log_file_name", ")", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "epoch", ",", "log", "in", "enumerate", "(", "f", ",", "start", "=", "1", ")", ":", "\n", "            ", "epoch_log", "=", "json", ".", "loads", "(", "log", ")", "\n", "\n", "epoch_log", "[", "'epoch'", "]", "=", "epoch", "\n", "\n", "dev_micro_f1", "=", "epoch_log", "[", "'dev_micro_f1'", "]", "\n", "epoch_log", "[", "'dev_micro_f1'", "]", "=", "dev_micro_f1", "*", "100.", "\n", "\n", "dev_macro_f1", "=", "epoch_log", "[", "'dev_macro_f1'", "]", "\n", "epoch_log", "[", "'dev_macro_f1'", "]", "=", "dev_macro_f1", "*", "100.", "\n", "\n", "logs", ".", "append", "(", "epoch_log", ")", "\n", "\n", "", "", "return", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.read_config_file": [[30, 33], ["open", "json.loads", "os.path.join", "next"], "function", ["None"], ["", "def", "read_config_file", "(", "experiment_dir", ",", "config_file_name", "=", "'config.jsonl'", ")", ":", "\n", "    ", "with", "open", "(", "join", "(", "experiment_dir", ",", "config_file_name", ")", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "loads", "(", "next", "(", "f", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.read_experiment_logs": [[35, 59], ["analysis_util.read_experiment_logs.list_experiment_dirs"], "function", ["None"], ["", "", "def", "read_experiment_logs", "(", "experiments_dir", ",", "filter_empty_logs", "=", "True", ")", ":", "\n", "    ", "def", "list_experiment_dirs", "(", "path", ")", ":", "\n", "        ", "dirs", "=", "[", "join", "(", "path", ",", "d", ")", "for", "d", "in", "listdir", "(", "path", ")", "if", "isdir", "(", "join", "(", "path", ",", "d", ")", ")", "]", "\n", "return", "[", "d", "for", "d", "in", "dirs", "if", "exists", "(", "join", "(", "d", ",", "'logs.jsonl'", ")", ")", "]", "\n", "\n", "", "experiment_dirs", "=", "list_experiment_dirs", "(", "experiments_dir", ")", "\n", "\n", "experiments", "=", "{", "}", "\n", "for", "experiment_dir", "in", "experiment_dirs", ":", "\n", "        ", "experiment_name", "=", "basename", "(", "experiment_dir", ")", "\n", "\n", "config", "=", "read_config_file", "(", "experiment_dir", ")", "\n", "logs", "=", "read_log_file", "(", "experiment_dir", ")", "\n", "\n", "if", "filter_empty_logs", "and", "not", "logs", ":", "\n", "            ", "continue", "\n", "\n", "", "experiments", "[", "experiment_name", "]", "=", "{", "\n", "'experiment_dir'", ":", "experiment_dir", ",", "\n", "'config'", ":", "config", ",", "\n", "'logs'", ":", "logs", "\n", "}", "\n", "\n", "", "return", "experiments", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.add_official_scorer_metrics": [[61, 96], ["experiments.items", "os.path.join", "os.path.join", "os.path.join", "analysis_util.evaluate_semeval2010_task8", "analysis_util.evaluate_semeval2010_task8"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.evaluate_semeval2010_task8", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.evaluate_semeval2010_task8"], ["", "def", "add_official_scorer_metrics", "(", "experiments", ",", "path_to_eval_script", ",", "path_to_test_answers", ")", ":", "\n", "    ", "for", "experiment_name", ",", "experiment", "in", "experiments", ".", "items", "(", ")", ":", "\n", "        ", "experiment_dir", "=", "experiment", "[", "'experiment_dir'", "]", "\n", "config", "=", "experiment", "[", "'config'", "]", "\n", "logs", "=", "experiment", "[", "'logs'", "]", "\n", "\n", "if", "config", "[", "'dataset'", "]", "==", "'semeval_2010_task8'", ":", "\n", "            ", "dev_id_labels_true_file", "=", "join", "(", "experiment_dir", ",", "'dev_labels.txt'", ")", "\n", "test_id_labels_true_file", "=", "path_to_test_answers", "\n", "\n", "for", "log", "in", "logs", ":", "\n", "                ", "epoch", "=", "log", "[", "'epoch'", "]", "\n", "\n", "dev_id_labels_pred_file", "=", "join", "(", "experiment_dir", ",", "f'predictions/dev/predictions_epoch_{epoch}.txt'", ")", "\n", "test_id_labels_pred_file", "=", "join", "(", "experiment_dir", ",", "f'predictions/test/predictions_epoch_{epoch}.txt'", ")", "\n", "\n", "dev_precision_official", ",", "dev_recall_official", ",", "dev_f1_official", "=", "evaluate_semeval2010_task8", "(", "id_labels_true_file", "=", "dev_id_labels_true_file", ",", "\n", "id_labels_pred_file", "=", "dev_id_labels_pred_file", ",", "\n", "eval_script", "=", "path_to_eval_script", ")", "\n", "\n", "test_precision_official", ",", "test_recall_official", ",", "test_f1_official", "=", "evaluate_semeval2010_task8", "(", "id_labels_true_file", "=", "test_id_labels_true_file", ",", "\n", "id_labels_pred_file", "=", "test_id_labels_pred_file", ",", "\n", "eval_script", "=", "path_to_eval_script", ")", "\n", "\n", "log", "[", "'dev_precision_official'", "]", "=", "dev_precision_official", "\n", "log", "[", "'dev_recall_official'", "]", "=", "dev_recall_official", "\n", "log", "[", "'dev_f1_official'", "]", "=", "dev_f1_official", "\n", "\n", "log", "[", "'test_precision_official'", "]", "=", "test_precision_official", "\n", "log", "[", "'test_recall_official'", "]", "=", "test_recall_official", "\n", "log", "[", "'test_f1_official'", "]", "=", "test_f1_official", "\n", "\n", "", "", "", "return", "experiments", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.evaluate_semeval2010_task8": [[105, 132], ["subprocess.run", "re.search", "re.search", "re.search.span", "re.search.group", "re.search", "re.search", "re.search", "float", "float", "float", "re.search.group", "re.search.group", "re.search.group"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.dataset_converter.DatasetConverter.run"], ["def", "evaluate_semeval2010_task8", "(", "id_labels_true_file", ",", "id_labels_pred_file", ",", "eval_script", ")", ":", "\n", "    ", "p", "=", "run", "(", "[", "eval_script", ",", "id_labels_true_file", ",", "id_labels_pred_file", "]", ",", "stdout", "=", "PIPE", ",", "encoding", "=", "'utf-8'", ")", "\n", "report", "=", "p", ".", "stdout", "\n", "\n", "official_result_match", "=", "re", ".", "search", "(", "OFFICIAL_RESULT_REGEX", ",", "report", ")", "\n", "\n", "if", "official_result_match", ":", "\n", "        ", "result_start", "=", "official_result_match", ".", "span", "(", "0", ")", "[", "1", "]", "\n", "match", "=", "re", ".", "search", "(", "RESULT_LINE_REGEX", ",", "report", "[", "result_start", ":", "]", ")", "\n", "\n", "precision", "=", "None", "\n", "recall", "=", "None", "\n", "f1", "=", "None", "\n", "if", "match", ":", "\n", "            ", "result_line", "=", "match", ".", "group", "(", "1", ")", "\n", "precision_match", "=", "re", ".", "search", "(", "PRECISION_REGEX", ",", "result_line", ")", "\n", "recall_match", "=", "re", ".", "search", "(", "RECALL_REGEX", ",", "result_line", ")", "\n", "f1_match", "=", "re", ".", "search", "(", "F1_REGEX", ",", "result_line", ")", "\n", "\n", "if", "precision_match", ":", "\n", "                ", "precision", "=", "float", "(", "precision_match", ".", "group", "(", "1", ")", ")", "\n", "", "if", "recall_match", ":", "\n", "                ", "recall", "=", "float", "(", "recall_match", ".", "group", "(", "1", ")", ")", "\n", "", "if", "f1_match", ":", "\n", "                ", "f1", "=", "float", "(", "f1_match", ".", "group", "(", "1", ")", ")", "\n", "\n", "", "", "", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.experiments_to_dataframe": [[134, 149], ["experiments.items", "all_configs.append", "all_logs.extend", "pandas.DataFrame", "pandas.DataFrame"], "function", ["None"], ["", "def", "experiments_to_dataframe", "(", "experiments", ")", ":", "\n", "    ", "all_logs", "=", "[", "]", "\n", "all_configs", "=", "[", "]", "\n", "for", "experiment_name", ",", "experiment", "in", "experiments", ".", "items", "(", ")", ":", "\n", "        ", "config", "=", "experiment", "[", "'config'", "]", "\n", "logs", "=", "experiment", "[", "'logs'", "]", "\n", "\n", "config", "[", "'experiment'", "]", "=", "experiment_name", "\n", "all_configs", ".", "append", "(", "config", ")", "\n", "\n", "for", "log", "in", "logs", ":", "\n", "            ", "log", "[", "'experiment'", "]", "=", "experiment_name", "\n", "", "all_logs", ".", "extend", "(", "logs", ")", "\n", "\n", "", "return", "pd", ".", "DataFrame", "(", "all_logs", ")", ",", "pd", ".", "DataFrame", "(", "all_configs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.load_experiments_df": [[151, 156], ["analysis_util.read_experiment_logs", "analysis_util.experiments_to_dataframe", "df_configs.set_index().join().reset_index", "df_configs.set_index().join", "df_logs.set_index", "df_configs.set_index"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.read_experiment_logs", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.analysis_util.experiments_to_dataframe"], ["", "def", "load_experiments_df", "(", "log_dir", ")", ":", "\n", "    ", "experiment_logs", "=", "read_experiment_logs", "(", "log_dir", ")", "\n", "df_logs", ",", "df_configs", "=", "experiments_to_dataframe", "(", "experiment_logs", ")", "\n", "experiments_df", "=", "df_configs", ".", "set_index", "(", "'time'", ")", ".", "join", "(", "df_logs", ".", "set_index", "(", "'experiment'", ")", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "return", "experiments_df", "\n", "", ""]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_data": [[16, 34], ["float", "len", "min", "tqdm.tqdm", "open", "range", "len"], "function", ["None"], ["def", "iter_data", "(", "*", "datas", ",", "batch_size", "=", "128", ",", "truncate", "=", "False", ",", "verbose", "=", "False", ",", "max_batches", "=", "float", "(", "\"inf\"", ")", ")", ":", "\n", "    ", "n_samples", "=", "len", "(", "datas", "[", "0", "]", ")", "\n", "if", "truncate", ":", "\n", "        ", "n_samples", "=", "(", "n_samples", "//", "batch_size", ")", "*", "batch_size", "\n", "", "n_samples", "=", "min", "(", "n_samples", ",", "max_batches", "*", "batch_size", ")", "\n", "\n", "n_batches", "=", "0", "\n", "if", "verbose", ":", "\n", "        ", "f", "=", "sys", ".", "stderr", "\n", "", "else", ":", "\n", "        ", "f", "=", "open", "(", "os", ".", "devnull", ",", "'w'", ")", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "n_samples", ",", "batch_size", ")", ",", "total", "=", "n_samples", "//", "batch_size", ",", "file", "=", "f", ",", "ncols", "=", "80", ",", "leave", "=", "False", ")", ":", "\n", "        ", "if", "n_batches", ">=", "max_batches", ":", "raise", "StopIteration", "\n", "if", "len", "(", "datas", ")", "==", "1", ":", "\n", "            ", "yield", "datas", "[", "0", "]", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "            ", "yield", "(", "d", "[", "i", ":", "i", "+", "batch_size", "]", "for", "d", "in", "datas", ")", "\n", "", "n_batches", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_apply": [[36, 54], ["torch.no_grad", "model.eval", "train_utils.iter_data", "numpy.concatenate", "len", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model", "loss_fct", "np.concatenate.append", "loss_fct.sum().item", "clf_logits.to().numpy", "torch.tensor", "torch.tensor", "torch.tensor", "loss_fct.sum", "clf_logits.to"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_data"], ["", "", "def", "iter_apply", "(", "X", ",", "M", ",", "Y", ",", "model", ",", "loss_fct", ",", "device", ",", "batch_size", ")", ":", "\n", "    ", "logits", "=", "[", "]", "\n", "cost", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "for", "x", ",", "m", ",", "y", "in", "iter_data", "(", "X", ",", "M", ",", "Y", ",", "batch_size", "=", "batch_size", ",", "truncate", "=", "False", ",", "verbose", "=", "True", ")", ":", "\n", "            ", "n", "=", "len", "(", "x", ")", "\n", "x", "=", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "y", "=", "torch", ".", "tensor", "(", "y", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "m", "=", "torch", ".", "tensor", "(", "m", ")", ".", "to", "(", "device", ")", "\n", "_", ",", "clf_logits", "=", "model", "(", "x", ")", "\n", "#clf_logits *= n", "\n", "clf_losses", "=", "loss_fct", "(", "x", ",", "y", ",", "m", ",", "clf_logits", ",", "only_return_losses", "=", "True", ")", "\n", "clf_losses", "*=", "n", "\n", "logits", ".", "append", "(", "clf_logits", ".", "to", "(", "\"cpu\"", ")", ".", "numpy", "(", ")", ")", "\n", "cost", "+=", "clf_losses", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "logits", "=", "np", ".", "concatenate", "(", "logits", ",", "0", ")", "\n", "", "return", "logits", ",", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_predict": [[56, 74], ["numpy.concatenate", "torch.no_grad", "model.eval", "train_utils.iter_data", "numpy.concatenate", "torch.tensor().to", "model", "np.concatenate.append", "np.concatenate.append", "clf_logits.to().numpy", "torch.tensor", "torch.nn.functional.softmax().to().numpy", "clf_logits.to", "torch.nn.functional.softmax().to", "torch.nn.functional.softmax"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_data"], ["", "def", "iter_predict", "(", "X", ",", "model", ",", "device", ",", "batch_size", ",", "compute_probs", "=", "False", ")", ":", "\n", "    ", "logits", "=", "[", "]", "\n", "probs", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "for", "x", "in", "iter_data", "(", "X", ",", "batch_size", "=", "batch_size", ",", "truncate", "=", "False", ",", "verbose", "=", "True", ")", ":", "\n", "            ", "x", "=", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "_", ",", "clf_logits", "=", "model", "(", "x", ")", "\n", "if", "compute_probs", ":", "\n", "                ", "probs", ".", "append", "(", "softmax", "(", "clf_logits", ",", "dim", "=", "1", ")", ".", "to", "(", "\"cpu\"", ")", ".", "numpy", "(", ")", ")", "\n", "", "logits", ".", "append", "(", "clf_logits", ".", "to", "(", "\"cpu\"", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "logits", "=", "np", ".", "concatenate", "(", "logits", ",", "0", ")", "\n", "\n", "if", "compute_probs", ":", "\n", "        ", "probs", "=", "np", ".", "concatenate", "(", "probs", ",", "0", ")", "\n", "return", "logits", ",", "probs", "\n", "", "else", ":", "\n", "        ", "return", "logits", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.predict": [[76, 82], ["train_utils.iter_predict", "pred_fn", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.iter_predict"], ["", "", "def", "predict", "(", "X", ",", "model", ",", "device", ",", "batch_size", ",", "compute_probs", "=", "False", ")", ":", "\n", "    ", "pred_fn", "=", "lambda", "x", ":", "np", ".", "argmax", "(", "x", ",", "1", ")", "\n", "logits", ",", "probs", "=", "iter_predict", "(", "X", ",", "model", ",", "device", ",", "batch_size", ",", "compute_probs", "=", "compute_probs", ")", "\n", "predictions", "=", "pred_fn", "(", "logits", ")", "\n", "\n", "return", "predictions", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.persist_model": [[84, 90], ["model.module.save_to_file", "utils.make_path", "open", "pickle.dump", "open", "pickle.dump", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.DoubleHeadModel.save_to_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path"], ["", "def", "persist_model", "(", "save_dir", ",", "model", ",", "text_encoder", ",", "label_encoder", ",", "model_name", "=", "'model.pt'", ")", ":", "\n", "    ", "model", ".", "module", ".", "save_to_file", "(", "make_path", "(", "join", "(", "save_dir", ",", "model_name", ")", ")", ")", "\n", "with", "open", "(", "join", "(", "save_dir", ",", "'text_encoder.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "text_encoder", ",", "f", ")", "\n", "", "with", "open", "(", "join", "(", "save_dir", ",", "'label_encoder.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "label_encoder", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.train_utils.load_model": [[92, 102], ["model_pytorch.DoubleHeadModel.load_from_file", "os.path.join", "open", "pickle.load", "open", "pickle.load", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.DoubleHeadModel.load_from_file", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load"], ["", "", "def", "load_model", "(", "save_dir", ",", "model_file", "=", "'model.pt'", ",", "text_encoder_file", "=", "'text_encoder.pkl'", ",", "\n", "label_encoder_file", "=", "'label_encoder.pkl'", ")", ":", "\n", "\n", "    ", "model", "=", "DoubleHeadModel", ".", "load_from_file", "(", "join", "(", "save_dir", ",", "model_file", ")", ")", "\n", "with", "open", "(", "join", "(", "save_dir", ",", "text_encoder_file", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "text_encoder", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "join", "(", "save_dir", ",", "label_encoder_file", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "label_encoder", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "model", ",", "text_encoder", ",", "label_encoder", "\n", "", ""]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.WordDropout.__init__": [[33, 36], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "dropout_rate", "=", "0.05", ")", ":", "\n", "        ", "super", "(", "WordDropout", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.WordDropout.forward": [[37, 45], ["x.data.new().bernoulli_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "mask.expand_as.expand_as.expand_as", "x.data.new", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "not", "self", ".", "dropout_rate", ":", "\n", "            ", "return", "x", "\n", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "1", ")", ".", "bernoulli_", "(", "1", "-", "self", ".", "dropout_rate", ")", "\n", "mask", "=", "torch", ".", "autograd", ".", "Variable", "(", "m", ",", "requires_grad", "=", "False", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.LayerNorm.__init__": [[50, 55], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "n_state", ",", "e", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "g", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "n_state", ")", ")", "\n", "self", ".", "b", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "n_state", ")", ")", "\n", "self", ".", "e", "=", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.LayerNorm.forward": [[56, 61], ["x.mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "u", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "s", "=", "(", "x", "-", "u", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "u", ")", "/", "torch", ".", "sqrt", "(", "s", "+", "self", ".", "e", ")", "\n", "return", "self", ".", "g", "*", "x", "+", "self", ".", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Conv1D.__init__": [[64, 75], ["torch.Module.__init__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.normal_", "torch.init.normal_", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "rf", ",", "nx", ")", ":", "\n", "        ", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rf", "=", "rf", "\n", "self", ".", "nf", "=", "nf", "\n", "if", "rf", "==", "1", ":", "# faster 1x1 conv", "\n", "            ", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "w", "=", "Parameter", "(", "w", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "", "else", ":", "# was used to train LM", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Conv1D.forward": [[76, 84], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "rf", "==", "1", ":", "\n", "            ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "b", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "w", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.__init__": [[87, 100], ["torch.Module.__init__", "model_pytorch.Attention.register_buffer", "model_pytorch.Conv1D", "model_pytorch.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "cfg", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "cfg", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "'b'", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "cfg", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "1", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention._attn": [[101, 109], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "model_pytorch.Attention.attn_dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.Softmax", "torch.Softmax", "math.sqrt", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "w", "=", "w", "*", "self", ".", "b", "+", "-", "1e9", "*", "(", "1", "-", "self", ".", "b", ")", "# TF implem method: mask_attn_weights", "\n", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "return", "torch", ".", "matmul", "(", "w", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.merge_heads": [[110, 114], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.split_heads": [[115, 122], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.forward": [[123, 134], ["model_pytorch.Attention.c_attn", "model_pytorch.Attention.split", "model_pytorch.Attention.split_heads", "model_pytorch.Attention.split_heads", "model_pytorch.Attention.split_heads", "model_pytorch.Attention._attn", "model_pytorch.Attention.merge_heads", "model_pytorch.Attention.c_proj", "model_pytorch.Attention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.split_heads", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.split_heads", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.split_heads", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention._attn", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "a", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ")", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.MLP.__init__": [[137, 144], ["torch.Module.__init__", "model_pytorch.Conv1D", "model_pytorch.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "cfg", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "cfg", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "1", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT_FNS", "[", "cfg", ".", "afn", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.MLP.forward": [[145, 149], ["model_pytorch.MLP.act", "model_pytorch.MLP.c_proj", "model_pytorch.MLP.dropout", "model_pytorch.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Block.__init__": [[152, 159], ["torch.Module.__init__", "model_pytorch.Attention", "model_pytorch.LayerNorm", "model_pytorch.MLP", "model_pytorch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "cfg", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "cfg", ".", "n_embd", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "cfg", ",", "scale", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "cfg", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.Block.forward": [[160, 166], ["model_pytorch.Block.attn", "model_pytorch.Block.ln_1", "model_pytorch.Block.mlp", "model_pytorch.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "a", "=", "self", ".", "attn", "(", "x", ")", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.TransformerModel.__init__": [[171, 181], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "model_pytorch.WordDropout", "model_pytorch.Block", "torch.ModuleList", "torch.ModuleList", "torch.init.normal_", "torch.init.normal_", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "vocab", "=", "40990", ",", "n_ctx", "=", "512", ")", ":", "\n", "        ", "super", "(", "TransformerModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "vocab", ",", "cfg", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "cfg", ".", "embd_pdrop", ")", "\n", "self", ".", "word_drop", "=", "WordDropout", "(", "cfg", ".", "word_pdrop", ")", "\n", "block", "=", "Block", "(", "n_ctx", ",", "cfg", ",", "scale", "=", "True", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "block", ")", "for", "_", "in", "range", "(", "cfg", ".", "n_layer", ")", "]", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.TransformerModel.forward": [[182, 191], ["model_pytorch.TransformerModel.view", "model_pytorch.TransformerModel.word_drop", "model_pytorch.TransformerModel.embed", "model_pytorch.TransformerModel.sum", "model_pytorch.TransformerModel.size", "model_pytorch.TransformerModel.size", "block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "2", ")", ",", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "word_drop", "(", "x", ")", "\n", "e", "=", "self", ".", "embed", "(", "x", ")", "\n", "# Add the position information to the input embeddings", "\n", "h", "=", "e", ".", "sum", "(", "dim", "=", "2", ")", "\n", "for", "block", "in", "self", ".", "h", ":", "\n", "            ", "h", "=", "block", "(", "h", ")", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.LMHead.__init__": [[196, 202], ["torch.Module.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "LMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "cfg", ".", "n_embd", "\n", "embed_shape", "=", "model", ".", "embed", ".", "weight", ".", "shape", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "embed_shape", "[", "1", "]", ",", "embed_shape", "[", "0", "]", ",", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "model", ".", "embed", ".", "weight", "# Tied weights", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.LMHead.forward": [[203, 208], ["h[].contiguous().view", "model_pytorch.LMHead.decoder", "h[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ")", ":", "\n", "# Truncated Language modeling logits (we remove the last token)", "\n", "        ", "h_trunc", "=", "h", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "n_embd", ")", "\n", "lm_logits", "=", "self", ".", "decoder", "(", "h_trunc", ")", "\n", "return", "lm_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.MultipleChoiceHead.__init__": [[213, 222], ["torch.Module.__init__", "torch.Dropout2d", "torch.Dropout2d", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "clf_token", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "MultipleChoiceHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "cfg", ".", "n_embd", "\n", "self", ".", "clf_token", "=", "clf_token", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout2d", "(", "cfg", ".", "clf_pdrop", ")", "# To reproduce the noise_shape parameter of TF implementation", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "cfg", ".", "n_embd", ",", "1", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.MultipleChoiceHead.forward": [[223, 238], ["h.view", "x[].contiguous().view", "clf_h.contiguous().view.contiguous().view.view", "model_pytorch.MultipleChoiceHead.dropout().transpose", "clf_h.contiguous().view.contiguous().view.contiguous().view", "model_pytorch.MultipleChoiceHead.linear", "model_pytorch.MultipleChoiceHead.view", "x.size", "x.size", "x[].contiguous", "model_pytorch.MultipleChoiceHead.dropout", "clf_h.contiguous().view.contiguous().view.contiguous", "clf_h.contiguous().view.contiguous().view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "x", ")", ":", "\n", "# Classification logits", "\n", "        ", "clf_h", "=", "h", ".", "view", "(", "-", "1", ",", "self", ".", "n_embd", ")", "\n", "flat", "=", "x", "[", "...", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "clf_h", "=", "clf_h", "[", "flat", "==", "self", ".", "clf_token", ",", ":", "]", "\n", "clf_h", "=", "clf_h", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ",", "self", ".", "n_embd", ",", "1", ")", "\n", "# This double transposition is there to replicate the behavior", "\n", "# of the noise_shape argument in the tensorflow", "\n", "# implementation.  For more details, see", "\n", "# https://github.com/huggingface/pytorch-openai-transformer-lm/issues/11", "\n", "clf_h", "=", "self", ".", "dropout", "(", "clf_h", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "clf_h", "=", "clf_h", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "n_embd", ")", "\n", "clf_logits", "=", "self", ".", "linear", "(", "clf_h", ")", "\n", "\n", "return", "clf_logits", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.ClfHead.__init__": [[244, 253], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "clf_token", ",", "cfg", ",", "n_class", ")", ":", "\n", "        ", "super", "(", "ClfHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "cfg", ".", "n_embd", "\n", "self", ".", "clf_token", "=", "clf_token", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "clf_pdrop", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "cfg", ".", "n_embd", ",", "n_class", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.ClfHead.forward": [[254, 262], ["h.view", "x[].contiguous().view", "model_pytorch.ClfHead.dropout", "model_pytorch.ClfHead.linear", "x[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "x", ")", ":", "\n", "        ", "clf_h", "=", "h", ".", "view", "(", "-", "1", ",", "self", ".", "n_embd", ")", "\n", "flat", "=", "x", "[", "...", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "clf_h", "=", "clf_h", "[", "flat", "==", "self", ".", "clf_token", ",", ":", "]", "\n", "clf_h", "=", "self", ".", "dropout", "(", "clf_h", ")", "\n", "clf_logits", "=", "self", ".", "linear", "(", "clf_h", ")", "\n", "\n", "return", "clf_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.SimilarityHead.__init__": [[267, 276], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "clf_token", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "SimilarityHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "cfg", ".", "n_embd", "\n", "self", ".", "clf_token", "=", "clf_token", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "cfg", ".", "clf_pdrop", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "cfg", ".", "n_embd", ",", "1", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.SimilarityHead.forward": [[277, 286], ["h.view", "x[].contiguous().view", "model_pytorch.SimilarityHead.dropout", "sim_h.sum.sum.sum", "model_pytorch.SimilarityHead.linear", "x[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "x", ")", ":", "\n", "        ", "sim_h", "=", "h", ".", "view", "(", "-", "1", ",", "self", ".", "n_embd", ")", "\n", "flat", "=", "x", "[", "...", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "sim_h", "=", "sim_h", "[", "flat", "==", "self", ".", "clf_token", ",", ":", "]", "\n", "sim_h", "=", "self", ".", "dropout", "(", "sim_h", ")", "\n", "sim_h", "=", "sim_h", ".", "sum", "(", "dim", "=", "1", ")", "\n", "sim_logits", "=", "self", ".", "linear", "(", "sim_h", ")", "\n", "\n", "return", "sim_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.DoubleHeadModel.__init__": [[289, 317], ["torch.Module.__init__", "model_pytorch.TransformerModel", "model_pytorch.LMHead", "isinstance", "model_pytorch.MultipleChoiceHead", "isinstance", "model_pytorch.ClfHead", "ValueError", "model_pytorch.SimilarityHead", "len", "model_pytorch.ClfHead", "ValueError"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "clf_token", ",", "task_head_type", ",", "vocab", "=", "40990", ",", "n_ctx", "=", "512", ")", ":", "\n", "        ", "super", "(", "DoubleHeadModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "clf_token", "=", "clf_token", "\n", "self", ".", "task_head_type", "=", "task_head_type", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "\n", "self", ".", "transformer", "=", "TransformerModel", "(", "cfg", ",", "vocab", "=", "vocab", ",", "n_ctx", "=", "n_ctx", ")", "\n", "self", ".", "lm_head", "=", "LMHead", "(", "self", ".", "transformer", ",", "cfg", ")", "\n", "if", "isinstance", "(", "task_head_type", ",", "str", ")", ":", "\n", "            ", "if", "task_head_type", "==", "'multiple_choice'", ":", "\n", "                ", "self", ".", "task_head", "=", "MultipleChoiceHead", "(", "clf_token", ",", "cfg", ")", "\n", "", "elif", "task_head_type", "==", "'similarity'", ":", "\n", "                ", "self", ".", "task_head", "=", "SimilarityHead", "(", "clf_token", ",", "cfg", ")", "\n", "", "elif", "task_head_type", "==", "'inference'", ":", "\n", "# the three classes correspond to entailment, contradiction and neutral.", "\n", "                ", "self", ".", "task_head", "=", "ClfHead", "(", "clf_token", ",", "cfg", ",", "3", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"task_head_type is expected to be 'multiple_choice' \"", "\n", "\"'similarity', 'inference' or ('classification', n_class) \"", "\n", "f\"got {task_head_type}.\"", ")", "\n", "", "", "elif", "isinstance", "(", "task_head_type", ",", "collections", ".", "abc", ".", "Sequence", ")", "and", "len", "(", "task_head_type", ")", "==", "2", "and", "task_head_type", "[", "0", "]", "==", "'classification'", ":", "\n", "            ", "n_class", "=", "task_head_type", "[", "1", "]", "\n", "self", ".", "task_head", "=", "ClfHead", "(", "clf_token", ",", "cfg", ",", "n_class", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"task_head_type is expected to be 'multiple_choice' \"", "\n", "\"'similarity', 'inference' or ('classification', n_class) \"", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.DoubleHeadModel.forward": [[320, 326], ["model_pytorch.DoubleHeadModel.transformer", "model_pytorch.DoubleHeadModel.lm_head", "model_pytorch.DoubleHeadModel.task_head"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "transformer", "(", "x", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "h", ")", "\n", "task_logits", "=", "self", ".", "task_head", "(", "h", ",", "x", ")", "\n", "\n", "return", "lm_logits", ",", "task_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.DoubleHeadModel.save_to_file": [[328, 342], ["torch.save", "torch.save", "torch.save", "torch.save", "model_pytorch.DoubleHeadModel.state_dict", "dict"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.save", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.save", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.save", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.save"], ["", "def", "save_to_file", "(", "self", ",", "model_file", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Saves the current model to the provided file.\n        :param model_file: the model file\n        \"\"\"", "\n", "model_state", "=", "{", "\n", "'state_dict'", ":", "self", ".", "state_dict", "(", ")", ",", "\n", "'cfg'", ":", "dict", "(", "self", ".", "cfg", ")", ",", "\n", "'clf_token'", ":", "self", ".", "clf_token", ",", "\n", "'task_head_type'", ":", "self", ".", "task_head_type", ",", "\n", "'vocab'", ":", "self", ".", "vocab", ",", "\n", "'n_ctx'", ":", "self", ".", "n_ctx", "\n", "}", "\n", "torch", ".", "save", "(", "model_state", ",", "model_file", ",", "pickle_protocol", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.DoubleHeadModel.load_from_file": [[343, 371], ["warnings.filterwarnings", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "warnings.filterwarnings", "model_pytorch.DoubleHeadModel", "DoubleHeadModel.load_state_dict", "DoubleHeadModel.eval", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "model_pytorch.dotdict"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "load_from_file", "(", "cls", ",", "model_file", ")", ":", "\n", "        ", "\"\"\"\n        Loads the model from the given file.\n        :param model_file: the model file\n        :return: the loaded text classifier model\n        \"\"\"", "\n", "\n", "# ATTENTION: suppressing torch serialization warnings. This needs to be taken out once we sort out recursive", "\n", "# serialization of torch objects", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "state", "=", "torch", ".", "load", "(", "model_file", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "torch", ".", "load", "(", "model_file", ",", "map_location", "=", "{", "'cuda:0'", ":", "'cpu'", "}", ")", "\n", "", "warnings", ".", "filterwarnings", "(", "\"default\"", ")", "\n", "\n", "model", "=", "DoubleHeadModel", "(", "\n", "cfg", "=", "dotdict", "(", "state", "[", "'cfg'", "]", ")", ",", "\n", "clf_token", "=", "state", "[", "'clf_token'", "]", ",", "\n", "task_head_type", "=", "state", "[", "'task_head_type'", "]", ",", "\n", "vocab", "=", "state", "[", "'vocab'", "]", ",", "\n", "n_ctx", "=", "state", "[", "'n_ctx'", "]", "\n", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "state", "[", "'state_dict'", "]", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.gelu": [[14, 16], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.swish": [[18, 20], ["torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.model_pytorch.load_openai_pretrained_model": [[373, 432], ["print", "json.load", "json.load", "numpy.cumsum", "torch.from_numpy", "torch.from_numpy", "zip", "open", "open", "numpy.load", "numpy.split", "param.reshape", "numpy.concatenate", "numpy.concatenate", "arr.squeeze", "name.split.split", "torch.from_numpy", "torch.from_numpy", "numpy.prod", "range", "numpy.concatenate", "zip", "re.fullmatch", "getattr", "re.split", "len", "int", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.load"], ["", "", "def", "load_openai_pretrained_model", "(", "model", ",", "n_ctx", "=", "-", "1", ",", "n_special", "=", "-", "1", ",", "n_transfer", "=", "12", ",", "n_embd", "=", "768", ",", "path", "=", "'./model/'", ",", "\n", "path_names", "=", "'./'", ")", ":", "\n", "# Load weights from TF model", "\n", "    ", "print", "(", "\"Loading weights...\"", ")", "\n", "names", "=", "json", ".", "load", "(", "open", "(", "path_names", "+", "'parameters_names.json'", ")", ")", "\n", "shapes", "=", "json", ".", "load", "(", "open", "(", "path", "+", "'params_shapes.json'", ")", ")", "\n", "offsets", "=", "np", ".", "cumsum", "(", "[", "np", ".", "prod", "(", "shape", ")", "for", "shape", "in", "shapes", "]", ")", "\n", "init_params", "=", "[", "np", ".", "load", "(", "path", "+", "'params_{}.npy'", ".", "format", "(", "n", ")", ")", "for", "n", "in", "range", "(", "10", ")", "]", "\n", "init_params", "=", "np", ".", "split", "(", "np", ".", "concatenate", "(", "init_params", ",", "0", ")", ",", "offsets", ")", "[", ":", "-", "1", "]", "\n", "init_params", "=", "[", "param", ".", "reshape", "(", "shape", ")", "for", "param", ",", "shape", "in", "zip", "(", "init_params", ",", "shapes", ")", "]", "\n", "if", "n_ctx", ">", "0", ":", "\n", "        ", "init_params", "[", "0", "]", "=", "init_params", "[", "0", "]", "[", ":", "n_ctx", "]", "\n", "", "if", "n_special", ">", "0", ":", "\n", "        ", "init_params", "[", "0", "]", "=", "np", ".", "concatenate", "(", "\n", "[", "init_params", "[", "1", "]", ",", "\n", "(", "np", ".", "random", ".", "randn", "(", "n_special", ",", "n_embd", ")", "*", "0.02", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "init_params", "[", "0", "]", "\n", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "        ", "init_params", "[", "0", "]", "=", "np", ".", "concatenate", "(", "\n", "[", "init_params", "[", "1", "]", ",", "\n", "init_params", "[", "0", "]", "\n", "]", ",", "0", ")", "\n", "", "del", "init_params", "[", "1", "]", "\n", "if", "n_transfer", "==", "-", "1", ":", "\n", "        ", "n_transfer", "=", "0", "\n", "", "else", ":", "\n", "        ", "n_transfer", "=", "1", "+", "n_transfer", "*", "12", "\n", "", "init_params", "=", "[", "arr", ".", "squeeze", "(", ")", "for", "arr", "in", "init_params", "]", "\n", "\n", "try", ":", "\n", "        ", "assert", "model", ".", "embed", ".", "weight", ".", "shape", "==", "init_params", "[", "0", "]", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "e", ".", "args", "+=", "(", "model", ".", "embed", ".", "weight", ".", "shape", ",", "init_params", "[", "0", "]", ".", "shape", ")", "\n", "raise", "\n", "\n", "", "model", ".", "embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "0", "]", ")", "\n", "\n", "for", "name", ",", "ip", "in", "zip", "(", "names", "[", "1", ":", "n_transfer", "]", ",", "init_params", "[", "1", ":", "n_transfer", "]", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "assert", "name", "[", "-", "2", ":", "]", "==", "\":0\"", "\n", "name", "=", "name", "[", ":", "-", "2", "]", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "ip", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "ip", ".", "shape", ")", "\n", "raise", "\n", "", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "ip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.__init__": [[51, 56], ["open", "utils.ResultLogger.f_log.write", "time.time", "utils.make_path", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'time'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'time'", "]", "=", "time", ".", "time", "(", ")", "\n", "", "self", ".", "f_log", "=", "open", "(", "make_path", "(", "path", ")", ",", "'w'", ")", "\n", "self", ".", "f_log", ".", "write", "(", "json", ".", "dumps", "(", "kwargs", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.log": [[57, 62], ["utils.ResultLogger.f_log.write", "utils.ResultLogger.f_log.flush", "time.time", "json.dumps"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'time'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'time'", "]", "=", "time", ".", "time", "(", ")", "\n", "", "self", ".", "f_log", ".", "write", "(", "json", ".", "dumps", "(", "kwargs", ")", "+", "'\\n'", ")", "\n", "self", ".", "f_log", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.close": [[63, 65], ["utils.ResultLogger.f_log.close"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.ResultLogger.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "f_log", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.stsb_label_encoding": [[9, 21], ["numpy.zeros().astype", "enumerate", "range", "numpy.zeros", "numpy.floor", "len", "numpy.floor", "numpy.floor", "numpy.floor"], "function", ["None"], ["def", "stsb_label_encoding", "(", "labels", ",", "nclass", "=", "6", ")", ":", "\n", "    ", "\"\"\"\n    Label encoding from Tree LSTM paper (Tai, Socher, Manning)\n    \"\"\"", "\n", "Y", "=", "np", ".", "zeros", "(", "(", "len", "(", "labels", ")", ",", "nclass", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "for", "j", ",", "y", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "nclass", ")", ":", "\n", "            ", "if", "i", "==", "np", ".", "floor", "(", "y", ")", "+", "1", ":", "\n", "                ", "Y", "[", "j", ",", "i", "]", "=", "y", "-", "np", ".", "floor", "(", "y", ")", "\n", "", "if", "i", "==", "np", ".", "floor", "(", "y", ")", ":", "\n", "                ", "Y", "[", "j", ",", "i", "]", "=", "np", ".", "floor", "(", "y", ")", "-", "y", "+", "1", "\n", "", "", "", "return", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.np_softmax": [[22, 27], ["numpy.exp", "numpy.max", "numpy.sum"], "function", ["None"], ["", "def", "np_softmax", "(", "x", ",", "t", "=", "1", ")", ":", "\n", "    ", "x", "=", "x", "/", "t", "\n", "x", "=", "x", "-", "np", ".", "max", "(", "x", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "ex", "=", "np", ".", "exp", "(", "x", ")", "\n", "return", "ex", "/", "np", ".", "sum", "(", "ex", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.make_path": [[28, 33], ["os.path.dirname", "os.makedirs", "os.path.exists"], "function", ["None"], ["", "def", "make_path", "(", "f", ")", ":", "\n", "    ", "d", "=", "os", ".", "path", ".", "dirname", "(", "f", ")", "\n", "if", "d", "and", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "d", ")", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils._identity_init": [[34, 40], ["w.reshape.astype", "numpy.eye", "len", "w.reshape.reshape"], "function", ["None"], ["", "def", "_identity_init", "(", "shape", ",", "dtype", ",", "partition_info", ",", "scale", ")", ":", "\n", "    ", "n", "=", "shape", "[", "-", "1", "]", "\n", "w", "=", "np", ".", "eye", "(", "n", ")", "*", "scale", "\n", "if", "len", "(", "[", "s", "for", "s", "in", "shape", "if", "s", "!=", "1", "]", ")", "==", "2", ":", "\n", "        ", "w", "=", "w", ".", "reshape", "(", "shape", ")", "\n", "", "return", "w", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.identity_init": [[41, 43], ["functools.partial"], "function", ["None"], ["", "def", "identity_init", "(", "scale", "=", "1.0", ")", ":", "\n", "    ", "return", "partial", "(", "_identity_init", ",", "scale", "=", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils._np_init": [[44, 46], ["None"], "function", ["None"], ["", "def", "_np_init", "(", "shape", ",", "dtype", ",", "partition_info", ",", "w", ")", ":", "\n", "    ", "return", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.np_init": [[47, 49], ["functools.partial"], "function", ["None"], ["", "def", "np_init", "(", "w", ")", ":", "\n", "    ", "return", "partial", "(", "_np_init", ",", "w", "=", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.flatten": [[66, 68], ["None"], "function", ["None"], ["", "", "def", "flatten", "(", "outer", ")", ":", "\n", "    ", "return", "[", "el", "for", "inner", "in", "outer", "for", "el", "in", "inner", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.utils.remove_none": [[69, 71], ["None"], "function", ["None"], ["", "def", "remove_none", "(", "l", ")", ":", "\n", "    ", "return", "[", "e", "for", "e", "in", "l", "if", "e", "is", "not", "None", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._subsample": [[37, 51], ["zip", "zip", "subsampled_dataset.append", "random.random.random", "subsampled_dataset.append"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "_subsample", "(", "sentences", ",", "entities", ",", "labels", ",", "ids", ",", "negative_label", ",", "subsampling_rate", ")", ":", "\n", "        ", "subsampled_dataset", "=", "[", "]", "\n", "dataset", "=", "zip", "(", "sentences", ",", "entities", ",", "labels", ",", "ids", ")", "\n", "\n", "for", "example", "in", "dataset", ":", "\n", "            ", "label", "=", "example", "[", "2", "]", "\n", "if", "label", "==", "negative_label", ":", "\n", "                ", "if", "random", "(", ")", "<", "subsampling_rate", ":", "\n", "                    ", "subsampled_dataset", ".", "append", "(", "example", ")", "\n", "", "", "else", ":", "\n", "                ", "subsampled_dataset", ".", "append", "(", "example", ")", "\n", "\n", "", "", "return", "zip", "(", "*", "subsampled_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._mask_entities": [[52, 68], ["semeval_2010_task8.SemEval2010Task8._replace_tokens", "semeval_2010_task8.SemEval2010Task8._replace_tokens", "semeval_2010_task8.SemEval2010Task8._replace_tokens", "semeval_2010_task8.SemEval2010Task8._replace_tokens"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._replace_tokens", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._replace_tokens", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._replace_tokens", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._replace_tokens"], ["", "@", "staticmethod", "\n", "def", "_mask_entities", "(", "tokens", ",", "entity_offsets", ",", "first_entity_replace", ",", "second_entity_replace", ")", ":", "\n", "        ", "first_entity", ",", "second_entity", "=", "entity_offsets", "\n", "\n", "if", "first_entity", "[", "0", "]", ">", "second_entity", "[", "0", "]", ":", "\n", "            ", "tokens", ",", "first_entity", ",", "token_diff", "=", "SemEval2010Task8", ".", "_replace_tokens", "(", "tokens", ",", "first_entity", ",", "first_entity_replace", ")", "\n", "tokens", ",", "second_entity", ",", "token_diff", "=", "SemEval2010Task8", ".", "_replace_tokens", "(", "tokens", ",", "second_entity", ",", "second_entity_replace", ")", "\n", "\n", "first_entity", "=", "(", "first_entity", "[", "0", "]", "-", "token_diff", ",", "first_entity", "[", "1", "]", "-", "token_diff", ")", "\n", "", "else", ":", "\n", "            ", "tokens", ",", "second_entity", ",", "token_diff", "=", "SemEval2010Task8", ".", "_replace_tokens", "(", "tokens", ",", "second_entity", ",", "second_entity_replace", ")", "\n", "tokens", ",", "first_entity", ",", "token_diff", "=", "SemEval2010Task8", ".", "_replace_tokens", "(", "tokens", ",", "first_entity", ",", "first_entity_replace", ")", "\n", "\n", "second_entity", "=", "(", "second_entity", "[", "0", "]", "-", "token_diff", ",", "second_entity", "[", "1", "]", "-", "token_diff", ")", "\n", "\n", "", "return", "tokens", ",", "(", "first_entity", ",", "second_entity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._replace_tokens": [[69, 76], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_replace_tokens", "(", "tokens", ",", "token_offsets", ",", "token", ")", ":", "\n", "        ", "token_diff", "=", "token_offsets", "[", "1", "]", "-", "token_offsets", "[", "0", "]", "-", "1", "\n", "tokens", "=", "tokens", "[", ":", "token_offsets", "[", "0", "]", "]", "+", "[", "token", "]", "+", "tokens", "[", "token_offsets", "[", "1", "]", ":", "]", "\n", "token_offsets", "=", "(", "token_offsets", "[", "0", "]", ",", "token_offsets", "[", "0", "]", "+", "1", ")", "\n", "\n", "return", "tokens", ",", "token_offsets", ",", "token_diff", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._load_from_jsonl": [[77, 97], ["open", "f.readlines", "json.loads", "sentences.append", "entities.append", "ids.append", "semeval_2010_task8.SemEval2010Task8.apply_masking_mode", "labels.append"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.apply_masking_mode"], ["", "@", "staticmethod", "\n", "def", "_load_from_jsonl", "(", "path_to_file", ",", "is_test", "=", "True", ",", "masking_mode", "=", "None", ")", ":", "\n", "        ", "sentences", "=", "[", "]", "\n", "entities", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "ids", "=", "[", "]", "\n", "with", "open", "(", "path_to_file", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "example", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "if", "masking_mode", "is", "not", "None", ":", "\n", "                    ", "example", "=", "SemEval2010Task8", ".", "apply_masking_mode", "(", "example", ",", "masking_mode", ")", "\n", "\n", "", "sentences", ".", "append", "(", "example", "[", "'tokens'", "]", ")", "\n", "entities", ".", "append", "(", "example", "[", "'entities'", "]", ")", "\n", "if", "not", "is_test", ":", "\n", "                    ", "labels", ".", "append", "(", "example", "[", "'label'", "]", ")", "\n", "", "ids", ".", "append", "(", "example", "[", "'id'", "]", ")", "\n", "\n", "", "", "return", "sentences", ",", "entities", ",", "labels", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.fetch": [[98, 154], ["semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "sklearn.model_selection.train_test_split", "semeval_2010_task8.SemEval2010Task8._subsample", "zip", "zip", "collections.Counter", "print", "print", "print", "collections.Counter.items", "print", "semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "os.path.join", "os.path.join", "os.path.join", "list", "list", "print", "print", "print", "print", "os.path.join", "zip", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._load_from_jsonl", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._subsample", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._load_from_jsonl"], ["", "@", "staticmethod", "\n", "def", "fetch", "(", "path_to_data", ",", "dev_size", ",", "seed", ",", "train_file", "=", "'train.jsonl'", ",", "test_file", "=", "'test.jsonl'", ",", "negative_label", "=", "None", ",", "\n", "subsampling_rate", "=", "1.0", ",", "train_set_limit", "=", "None", ",", "dev_set_limit", "=", "None", ",", "verbose", "=", "False", ",", "skip_test_set", "=", "False", ",", "\n", "predefined_dev_set", "=", "False", ",", "dev_file", "=", "None", ",", "masking_mode", "=", "None", ")", ":", "\n", "\n", "        ", "if", "predefined_dev_set", ":", "\n", "            ", "if", "not", "dev_file", ":", "\n", "                ", "dev_file", "=", "'dev.jsonl'", "\n", "\n", "", "sentences_train", ",", "entities_train", ",", "labels_train", ",", "ids_train", "=", "SemEval2010Task8", ".", "_load_from_jsonl", "(", "join", "(", "path_to_data", ",", "train_file", ")", ",", "is_test", "=", "False", ",", "masking_mode", "=", "masking_mode", ")", "\n", "sentences_dev", ",", "entities_dev", ",", "labels_dev", ",", "ids_dev", "=", "SemEval2010Task8", ".", "_load_from_jsonl", "(", "join", "(", "path_to_data", ",", "dev_file", ")", ",", "is_test", "=", "False", ",", "masking_mode", "=", "masking_mode", ")", "\n", "", "else", ":", "\n", "            ", "sentences_train_dev", ",", "entities_train_dev", ",", "labels_train_dev", ",", "ids_train_dev", "=", "SemEval2010Task8", ".", "_load_from_jsonl", "(", "join", "(", "path_to_data", ",", "train_file", ")", ",", "is_test", "=", "False", ",", "masking_mode", "=", "masking_mode", ")", "\n", "sentences_train", ",", "sentences_dev", ",", "entities_train", ",", "entities_dev", ",", "labels_train", ",", "labels_dev", ",", "ids_train", ",", "ids_dev", "=", "train_test_split", "(", "sentences_train_dev", ",", "entities_train_dev", ",", "labels_train_dev", ",", "ids_train_dev", ",", "test_size", "=", "dev_size", ",", "random_state", "=", "seed", ")", "\n", "\n", "", "if", "subsampling_rate", "<", "1.0", ":", "\n", "            ", "assert", "negative_label", "is", "not", "None", ",", "\"Negative class label required for subsampling\"", "\n", "sentences_train", ",", "entities_train", ",", "labels_train", ",", "ids_train", "=", "SemEval2010Task8", ".", "_subsample", "(", "sentences_train", ",", "entities_train", ",", "labels_train", ",", "ids_train", ",", "negative_label", ",", "subsampling_rate", ")", "\n", "\n", "", "if", "train_set_limit", ":", "\n", "            ", "train_set", "=", "list", "(", "zip", "(", "sentences_train", ",", "entities_train", ",", "labels_train", ",", "ids_train", ")", ")", "[", ":", "train_set_limit", "]", "\n", "sentences_train", ",", "entities_train", ",", "labels_train", ",", "ids_train", "=", "zip", "(", "*", "train_set", ")", "\n", "\n", "", "if", "dev_set_limit", ":", "\n", "            ", "dev_set", "=", "list", "(", "zip", "(", "sentences_dev", ",", "entities_dev", ",", "labels_dev", ",", "ids_dev", ")", ")", "[", ":", "dev_set_limit", "]", "\n", "sentences_dev", ",", "entities_dev", ",", "labels_dev", ",", "ids_dev", "=", "zip", "(", "*", "dev_set", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "train_label_counter", "=", "Counter", "(", "labels_train", ")", "\n", "print", "(", ")", "\n", "print", "(", "\"Train set size: {}\"", ".", "format", "(", "len", "(", "ids_train", ")", ")", ")", "\n", "print", "(", "\"Train set distribution:\"", ")", "\n", "for", "(", "label", ",", "count", ")", "in", "train_label_counter", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "\"{}: {}\"", ".", "format", "(", "label", ",", "count", ")", ")", "\n", "", "print", "(", ")", "\n", "\n", "if", "dev_set_limit", ":", "\n", "                ", "print", "(", ")", "\n", "print", "(", "\"Dev set size: {}\"", ".", "format", "(", "len", "(", "ids_dev", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n", "", "", "if", "not", "skip_test_set", ":", "\n", "            ", "sentences_test", ",", "entities_test", ",", "labels_test", ",", "ids_test", "=", "SemEval2010Task8", ".", "_load_from_jsonl", "(", "join", "(", "path_to_data", ",", "test_file", ")", ",", "is_test", "=", "True", ",", "masking_mode", "=", "masking_mode", ")", "\n", "\n", "return", "(", "sentences_train", ",", "entities_train", ",", "labels_train", ",", "ids_train", ")", ",", "(", "sentences_dev", ",", "entities_dev", ",", "labels_dev", ",", "ids_dev", ")", ",", "(", "sentences_test", ",", "entities_test", ",", "labels_test", ",", "ids_test", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "sentences_train", ",", "entities_train", ",", "labels_train", ",", "ids_train", ")", ",", "(", "sentences_dev", ",", "entities_dev", ",", "labels_dev", ",", "ids_dev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.encode": [[156, 190], ["fields.append", "zip", "fields.append", "fields.append", "fields.append", "fields.append", "encoded_splits.append", "text_encoder.encode", "encoded_entities.append", "isinstance", "numpy.asarray", "encoded_entity.append", "encoded_labels.append", "encoded_labels.append", "label_encoder.add_item", "text_encoder.encode"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.encode", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.None.text_utils.Dictionary.add_item", "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.encode"], ["", "", "@", "staticmethod", "\n", "def", "encode", "(", "*", "splits", ",", "text_encoder", ",", "label_encoder", ")", ":", "\n", "        ", "encoded_splits", "=", "[", "]", "\n", "for", "split", "in", "splits", ":", "\n", "            ", "fields", "=", "[", "]", "\n", "# encode sentence tokens", "\n", "fields", ".", "append", "(", "text_encoder", ".", "encode", "(", "split", "[", "0", "]", ",", "special_tokens", "=", "SemEval2010Task8", ".", "MASKED_ENTITY_TOKENS", ")", ")", "\n", "\n", "# encode entities", "\n", "encoded_entities", "=", "[", "]", "\n", "for", "sentence", ",", "entities", "in", "zip", "(", "split", "[", "0", "]", ",", "split", "[", "1", "]", ")", ":", "\n", "                ", "encoded_entity", "=", "[", "]", "\n", "for", "start", ",", "end", "in", "entities", ":", "\n", "                    ", "encoded_entity", ".", "append", "(", "text_encoder", ".", "encode", "(", "[", "sentence", "[", "start", ":", "end", "]", "]", ",", "special_tokens", "=", "SemEval2010Task8", ".", "MASKED_ENTITY_TOKENS", ")", "[", "0", "]", ")", "\n", "", "encoded_entities", ".", "append", "(", "encoded_entity", ")", "\n", "", "fields", ".", "append", "(", "encoded_entities", ")", "\n", "\n", "# encode labels, if present", "\n", "encoded_labels", "=", "[", "]", "\n", "for", "label", "in", "split", "[", "2", "]", ":", "\n", "                ", "if", "isinstance", "(", "label", ",", "str", ")", ":", "\n", "                    ", "encoded_labels", ".", "append", "(", "label_encoder", ".", "add_item", "(", "label", ")", ")", "\n", "", "else", ":", "\n", "                    ", "encoded_labels", ".", "append", "(", "label", ")", "\n", "", "", "fields", ".", "append", "(", "np", ".", "asarray", "(", "encoded_labels", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n", "# pass through ids", "\n", "fields", ".", "append", "(", "split", "[", "3", "]", ")", "\n", "\n", "# Add a none value for entity ids of datasets, that are not evaluated on a bag-level", "\n", "fields", ".", "append", "(", "None", ")", "\n", "\n", "encoded_splits", ".", "append", "(", "fields", ")", "\n", "", "return", "encoded_splits", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.transform": [[191, 234], ["tuple", "len", "numpy.zeros", "numpy.zeros", "len", "enumerate", "numpy.arange", "semeval_2010_task8.SemEval2010Task8.transform"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.transform"], ["", "def", "transform", "(", "*", "splits", ",", "text_encoder", ",", "max_length", ",", "n_ctx", ",", "format", "=", "'entities_first'", ")", ":", "\n", "# TODO: add different input format", "\n", "# TODO: maybe max_length should be different for sentence and entities", "\n", "\n", "        ", "def", "transform", "(", "sentences", ",", "entities", ")", ":", "\n", "            ", "batch_size", "=", "len", "(", "sentences", ")", "\n", "\n", "batch_indices", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "n_ctx", ",", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "batch_mask", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "n_ctx", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "encoder", "=", "text_encoder", ".", "encoder", "\n", "start", "=", "encoder", "[", "'_start_'", "]", "\n", "delimiter", "=", "encoder", "[", "'_delimiter_'", "]", "\n", "delimiter2", "=", "encoder", "[", "'_delimiter2_'", "]", "\n", "clf_token", "=", "encoder", "[", "'_classify_'", "]", "\n", "\n", "n_vocab", "=", "len", "(", "encoder", ")", "\n", "\n", "for", "i", ",", "(", "sentence", ",", "entities", ")", ",", "in", "enumerate", "(", "zip", "(", "sentences", ",", "entities", ")", ")", ":", "\n", "                ", "input_sentence", "=", "[", "start", "]", "\n", "\n", "for", "entity", "in", "entities", ":", "\n", "                    ", "input_sentence", ".", "extend", "(", "entity", "[", ":", "max_length", "]", ")", "\n", "input_sentence", ".", "append", "(", "delimiter", ")", "\n", "\n", "", "input_sentence", "[", "-", "1", "]", "=", "delimiter2", "\n", "\n", "input_sentence", "=", "input_sentence", "+", "sentence", "[", ":", "max_length", "]", "+", "[", "clf_token", "]", "\n", "input_sentence_length", "=", "len", "(", "input_sentence", ")", "\n", "\n", "batch_indices", "[", "i", ",", "0", ",", ":", "input_sentence_length", ",", "0", "]", "=", "input_sentence", "\n", "batch_mask", "[", "i", ",", "0", ",", ":", "input_sentence_length", "]", "=", "1", "\n", "\n", "# Position information that is added to the input embeddings in the TransformerModel", "\n", "", "batch_indices", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "np", ".", "arange", "(", "n_vocab", ",", "n_vocab", "+", "n_ctx", ")", "\n", "return", "batch_indices", ",", "batch_mask", "\n", "\n", "", "transformed_splits", "=", "[", "]", "\n", "for", "sentences", ",", "entities", ",", "labels", ",", "ids", ",", "_", "in", "splits", ":", "\n", "            ", "batch_indices", ",", "batch_mask", "=", "transform", "(", "sentences", ",", "entities", ")", "\n", "transformed_splits", ".", "append", "(", "(", "batch_indices", ",", "batch_mask", ",", "labels", ",", "ids", ",", "None", ")", ")", "\n", "\n", "", "return", "tuple", "(", "transformed_splits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.max_length": [[235, 242], ["max", "len", "zip", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "max_length", "(", "*", "splits", ",", "max_len", ")", ":", "\n", "# TODO: do not clip the sentences to max_len, if the entities are smaller than max_len", "\n", "        ", "return", "max", "(", "[", "\n", "len", "(", "sentence", "[", ":", "max_len", "]", ")", "+", "len", "(", "entities", "[", "0", "]", "[", ":", "max_len", "]", ")", "+", "len", "(", "entities", "[", "1", "]", "[", ":", "max_len", "]", ")", "\n", "for", "split", "in", "splits", "\n", "for", "sentence", ",", "entities", "in", "zip", "(", "*", "split", "[", "0", ":", "2", "]", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8.apply_masking_mode": [[244, 272], ["masking_mode.lower.lower.lower", "example.copy.copy.copy", "semeval_2010_task8.SemEval2010Task8._mask_entities", "zip", "ValueError"], "methods", ["home.repos.pwc.inspect_result.DFKI-NLP_TRE.datasets.semeval_2010_task8.SemEval2010Task8._mask_entities"], ["", "@", "staticmethod", "\n", "def", "apply_masking_mode", "(", "example", ",", "masking_mode", ")", ":", "\n", "        ", "masking_mode", "=", "masking_mode", ".", "lower", "(", ")", "\n", "\n", "# TODO: that's kind of unsafe", "\n", "if", "'grammar'", "in", "example", ":", "\n", "            ", "grammar_type", "=", "example", "[", "'grammar'", "]", "\n", "", "if", "'type'", "in", "example", ":", "\n", "            ", "ner_type", "=", "example", "[", "'type'", "]", "\n", "\n", "", "if", "masking_mode", "==", "'grammar'", ":", "\n", "            ", "first_entity_replace", ",", "second_entity_replace", "=", "[", "f'_{g}_'", "for", "g", "in", "grammar_type", "]", "\n", "", "elif", "masking_mode", "==", "'ner'", ":", "\n", "            ", "first_entity_replace", ",", "second_entity_replace", "=", "[", "f'_{n}_'", "for", "n", "in", "ner_type", "]", "\n", "", "elif", "masking_mode", "==", "'grammar_and_ner'", ":", "\n", "            ", "first_entity_replace", ",", "second_entity_replace", "=", "[", "f'{g}-{n}'", "for", "g", ",", "n", "in", "zip", "(", "grammar_type", ",", "ner_type", ")", "]", "\n", "", "elif", "masking_mode", "==", "'unk'", ":", "\n", "            ", "first_entity_replace", ",", "second_entity_replace", "=", "SemEval2010Task8", ".", "UNK_TYPES", "[", "0", "]", ",", "SemEval2010Task8", ".", "UNK_TYPES", "[", "0", "]", "\n", "", "elif", "masking_mode", "==", "'unk_w_position'", ":", "\n", "            ", "first_entity_replace", ",", "second_entity_replace", "=", "SemEval2010Task8", ".", "UNK_POS_TYPES", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Masking mode '{masking_mode}' not supported.\"", ")", "\n", "\n", "", "example", "=", "example", ".", "copy", "(", ")", "\n", "example", "[", "'tokens'", "]", ",", "example", "[", "'entities'", "]", "=", "SemEval2010Task8", ".", "_mask_entities", "(", "\n", "example", "[", "'tokens'", "]", ",", "example", "[", "'entities'", "]", ",", "first_entity_replace", ",", "second_entity_replace", ")", "\n", "\n", "return", "example", "\n", "", "", ""]]}