{"home.repos.pwc.inspect_result.obss_sahi.None.setup.get_long_description": [[8, 12], ["os.path.abspath", "os.path.dirname", "io.open", "f.read", "os.path.join"], "function", ["None"], ["def", "get_long_description", "(", ")", ":", "\n", "    ", "base_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ")", "\n", "with", "io", ".", "open", "(", "os", ".", "path", ".", "join", "(", "base_dir", ",", "\"README.md\"", ")", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "return", "f", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.None.setup.get_requirements": [[14, 17], ["open", "f.read().splitlines", "f.read"], "function", ["None"], ["", "", "def", "get_requirements", "(", ")", ":", "\n", "    ", "with", "open", "(", "\"requirements.txt\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "return", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.None.setup.get_version": [[19, 24], ["os.path.abspath", "os.path.join", "os.path.dirname", "io.open", "re.search().group", "re.search", "f.read"], "function", ["None"], ["", "", "def", "get_version", "(", ")", ":", "\n", "    ", "current_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ")", "\n", "version_file", "=", "os", ".", "path", ".", "join", "(", "current_dir", ",", "\"sahi\"", ",", "\"__init__.py\"", ")", "\n", "with", "io", ".", "open", "(", "version_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "return", "re", ".", "search", "(", "r'^__version__ = [\\'\"]([^\\'\"]*)[\\'\"]'", ",", "f", ".", "read", "(", ")", ",", "re", ".", "M", ")", ".", "group", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SlicedImage.__init__": [[138, 150], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "image", ",", "coco_image", ",", "starting_pixel", ")", ":", "\n", "        ", "\"\"\"\n        image: np.array\n            Sliced image.\n        coco_image: CocoImage\n            Coco styled image object that belong to sliced image.\n        starting_pixel: list of list of int\n            Starting pixel coordinates of the sliced image.\n        \"\"\"", "\n", "self", ".", "image", "=", "image", "\n", "self", ".", "coco_image", "=", "coco_image", "\n", "self", ".", "starting_pixel", "=", "starting_pixel", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.__init__": [[153, 165], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "original_image_size", "=", "None", ",", "image_dir", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        sliced_image_list: list of SlicedImage\n        image_dir: str\n            Directory of the sliced image exports.\n        original_image_size: list of int\n            Size of the unsliced original image in [height, width]\n        \"\"\"", "\n", "self", ".", "_sliced_image_list", ":", "List", "[", "SlicedImage", "]", "=", "[", "]", "\n", "self", ".", "original_image_height", "=", "original_image_size", "[", "0", "]", "\n", "self", ".", "original_image_width", "=", "original_image_size", "[", "1", "]", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.add_sliced_image": [[166, 171], ["slicing.SliceImageResult._sliced_image_list.append", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "add_sliced_image", "(", "self", ",", "sliced_image", ":", "SlicedImage", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "sliced_image", ",", "SlicedImage", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"sliced_image must be a SlicedImage instance\"", ")", "\n", "\n", "", "self", ".", "_sliced_image_list", ".", "append", "(", "sliced_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.sliced_image_list": [[172, 175], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sliced_image_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sliced_image_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.images": [[176, 187], ["images.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "images", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns sliced images.\n\n        Returns:\n            images: a list of np.array\n        \"\"\"", "\n", "images", "=", "[", "]", "\n", "for", "sliced_image", "in", "self", ".", "_sliced_image_list", ":", "\n", "            ", "images", ".", "append", "(", "sliced_image", ".", "image", ")", "\n", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.coco_images": [[188, 199], ["coco_images.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "coco_images", "(", "self", ")", "->", "List", "[", "CocoImage", "]", ":", "\n", "        ", "\"\"\"Returns CocoImage representation of SliceImageResult.\n\n        Returns:\n            coco_images: a list of CocoImage\n        \"\"\"", "\n", "coco_images", ":", "List", "=", "[", "]", "\n", "for", "sliced_image", "in", "self", ".", "_sliced_image_list", ":", "\n", "            ", "coco_images", ".", "append", "(", "sliced_image", ".", "coco_image", ")", "\n", "", "return", "coco_images", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.starting_pixels": [[200, 211], ["starting_pixels.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "starting_pixels", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns a list of starting pixels for each slice.\n\n        Returns:\n            starting_pixels: a list of starting pixel coords [x,y]\n        \"\"\"", "\n", "starting_pixels", "=", "[", "]", "\n", "for", "sliced_image", "in", "self", ".", "_sliced_image_list", ":", "\n", "            ", "starting_pixels", ".", "append", "(", "sliced_image", ".", "starting_pixel", ")", "\n", "", "return", "starting_pixels", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.filenames": [[212, 223], ["filenames.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "filenames", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns a list of filenames for each slice.\n\n        Returns:\n            filenames: a list of filenames as str\n        \"\"\"", "\n", "filenames", "=", "[", "]", "\n", "for", "sliced_image", "in", "self", ".", "_sliced_image_list", ":", "\n", "            ", "filenames", ".", "append", "(", "sliced_image", ".", "coco_image", ".", "file_name", ")", "\n", "", "return", "filenames", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.__len__": [[224, 226], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_sliced_image_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.get_slice_bboxes": [[30, 82], ["int", "int", "min", "min", "max", "max", "slice_bboxes.append", "slice_bboxes.append"], "function", ["None"], ["def", "get_slice_bboxes", "(", "\n", "image_height", ":", "int", ",", "\n", "image_width", ":", "int", ",", "\n", "slice_height", ":", "int", "=", "512", ",", "\n", "slice_width", ":", "int", "=", "512", ",", "\n", "overlap_height_ratio", ":", "int", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "int", "=", "0.2", ",", "\n", ")", "->", "List", "[", "List", "[", "int", "]", "]", ":", "\n", "    ", "\"\"\"Slices `image_pil` in crops.\n    Corner values of each slice will be generated using the `slice_height`,\n    `slice_width`, `overlap_height_ratio` and `overlap_width_ratio` arguments.\n\n    Args:\n        image_height (int): Height of the original image.\n        image_width (int): Width of the original image.\n        slice_height (int): Height of each slice. Default 512.\n        slice_width (int): Width of each slice. Default 512.\n        overlap_height_ratio(float): Fractional overlap in height of each\n            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n            overlap of 20 pixels). Default 0.2.\n        overlap_width_ratio(float): Fractional overlap in width of each\n            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n            overlap of 20 pixels). Default 0.2.\n\n    Returns:\n        List[List[int]]: List of 4 corner coordinates for each N slices.\n            [\n                [slice_0_left, slice_0_top, slice_0_right, slice_0_bottom],\n                ...\n                [slice_N_left, slice_N_top, slice_N_right, slice_N_bottom]\n            ]\n    \"\"\"", "\n", "slice_bboxes", "=", "[", "]", "\n", "y_max", "=", "y_min", "=", "0", "\n", "y_overlap", "=", "int", "(", "overlap_height_ratio", "*", "slice_height", ")", "\n", "x_overlap", "=", "int", "(", "overlap_width_ratio", "*", "slice_width", ")", "\n", "while", "y_max", "<", "image_height", ":", "\n", "        ", "x_min", "=", "x_max", "=", "0", "\n", "y_max", "=", "y_min", "+", "slice_height", "\n", "while", "x_max", "<", "image_width", ":", "\n", "            ", "x_max", "=", "x_min", "+", "slice_width", "\n", "if", "y_max", ">", "image_height", "or", "x_max", ">", "image_width", ":", "\n", "                ", "xmax", "=", "min", "(", "image_width", ",", "x_max", ")", "\n", "ymax", "=", "min", "(", "image_height", ",", "y_max", ")", "\n", "xmin", "=", "max", "(", "0", ",", "xmax", "-", "slice_width", ")", "\n", "ymin", "=", "max", "(", "0", ",", "ymax", "-", "slice_height", ")", "\n", "slice_bboxes", ".", "append", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "", "else", ":", "\n", "                ", "slice_bboxes", ".", "append", "(", "[", "x_min", ",", "y_min", ",", "x_max", ",", "y_max", "]", ")", "\n", "", "x_min", "=", "x_max", "-", "x_overlap", "\n", "", "y_min", "=", "y_max", "-", "y_overlap", "\n", "", "return", "slice_bboxes", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.annotation_inside_slice": [[84, 110], ["None"], "function", ["None"], ["", "def", "annotation_inside_slice", "(", "annotation", ":", "Dict", ",", "slice_bbox", ":", "List", "[", "int", "]", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Check whether annotation coordinates lie inside slice coordinates.\n\n    Args:\n        annotation (dict): Single annotation entry in COCO format.\n        slice_bbox (List[int]): Generated from `get_slice_bboxes`.\n            Format for each slice bbox: [x_min, y_min, x_max, y_max].\n\n    Returns:\n        (bool): True if any annotation coordinate lies inside slice.\n    \"\"\"", "\n", "left", ",", "top", ",", "width", ",", "height", "=", "annotation", "[", "\"bbox\"", "]", "\n", "\n", "right", "=", "left", "+", "width", "\n", "bottom", "=", "top", "+", "height", "\n", "\n", "if", "left", ">=", "slice_bbox", "[", "2", "]", ":", "\n", "        ", "return", "False", "\n", "", "if", "top", ">=", "slice_bbox", "[", "3", "]", ":", "\n", "        ", "return", "False", "\n", "", "if", "right", "<=", "slice_bbox", "[", "0", "]", ":", "\n", "        ", "return", "False", "\n", "", "if", "bottom", "<=", "slice_bbox", "[", "1", "]", ":", "\n", "        ", "return", "False", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.process_coco_annotations": [[112, 135], ["slicing.annotation_inside_slice", "coco_annotation.get_sliced_coco_annotation", "sliced_coco_annotation_list.append"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.annotation_inside_slice", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.get_sliced_coco_annotation"], ["", "def", "process_coco_annotations", "(", "coco_annotation_list", ":", "List", "[", "CocoAnnotation", "]", ",", "slice_bbox", ":", "List", "[", "int", "]", ",", "min_area_ratio", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Slices and filters given list of CocoAnnotation objects with given\n    'slice_bbox' and 'min_area_ratio'.\n\n    Args:\n        coco_annotation_list (List[CocoAnnotation])\n        slice_bbox (List[int]): Generated from `get_slice_bboxes`.\n            Format for each slice bbox: [x_min, y_min, x_max, y_max].\n        min_area_ratio (float): If the cropped annotation area to original\n            annotation ratio is smaller than this value, the annotation is\n            filtered out. Default 0.1.\n\n    Returns:\n        (List[CocoAnnotation]): Sliced annotations.\n    \"\"\"", "\n", "\n", "sliced_coco_annotation_list", ":", "List", "[", "CocoAnnotation", "]", "=", "[", "]", "\n", "for", "coco_annotation", "in", "coco_annotation_list", ":", "\n", "        ", "if", "annotation_inside_slice", "(", "coco_annotation", ".", "json", ",", "slice_bbox", ")", ":", "\n", "            ", "sliced_coco_annotation", "=", "coco_annotation", ".", "get_sliced_coco_annotation", "(", "slice_bbox", ")", "\n", "if", "sliced_coco_annotation", ".", "area", "/", "coco_annotation", ".", "area", ">=", "min_area_ratio", ":", "\n", "                ", "sliced_coco_annotation_list", ".", "append", "(", "sliced_coco_annotation", ")", "\n", "", "", "", "return", "sliced_coco_annotation_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_image": [[228, 375], ["sahi.utils.cv.read_image_as_pil", "verboselog", "slicing.get_slice_bboxes", "time.time", "slicing.SliceImageResult", "numpy.asarray", "verboselog", "sahi.utils.cv.read_image_as_pil", "str", "sahi.utils.cv.read_image_as_pil.save", "verboselog", "pathlib.Path().mkdir", "RuntimeError", "sahi.utils.coco.CocoImage", "slicing.SlicedImage", "slicing.SliceImageResult.add_sliced_image", "concurrent.futures.ThreadPoolExecutor", "concurrent.futures.ThreadPoolExecutor.map", "str", "slicing.process_coco_annotations", "map", "str", "pathlib.Path", "pathlib.Path", "sahi.utils.coco.CocoImage.add_annotation", "len", "pathlib.Path", "str", "str"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.get_slice_bboxes", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.SliceImageResult.add_sliced_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.process_coco_annotations", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation"], ["", "", "def", "slice_image", "(", "\n", "image", ":", "Union", "[", "str", ",", "Image", ".", "Image", "]", ",", "\n", "coco_annotation_list", ":", "Optional", "[", "CocoAnnotation", "]", "=", "None", ",", "\n", "output_file_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "slice_height", ":", "int", "=", "512", ",", "\n", "slice_width", ":", "int", "=", "512", ",", "\n", "overlap_height_ratio", ":", "float", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "float", "=", "0.2", ",", "\n", "min_area_ratio", ":", "float", "=", "0.1", ",", "\n", "out_ext", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", "->", "SliceImageResult", ":", "\n", "\n", "    ", "\"\"\"Slice a large image into smaller windows. If output_file_name is given export\n    sliced images.\n\n    Args:\n        image (str or PIL.Image): File path of image or Pillow Image to be sliced.\n        coco_annotation_list (CocoAnnotation): List of CocoAnnotation objects.\n        output_file_name (str, optional): Root name of output files (coordinates will\n            be appended to this)\n        output_dir (str, optional): Output directory\n        slice_height (int): Height of each slice. Default 512.\n        slice_width (int): Width of each slice. Default 512.\n        overlap_height_ratio (float): Fractional overlap in height of each\n            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n            overlap of 20 pixels). Default 0.2.\n        overlap_width_ratio (float): Fractional overlap in width of each\n            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n            overlap of 20 pixels). Default 0.2.\n        min_area_ratio (float): If the cropped annotation area to original annotation\n            ratio is smaller than this value, the annotation is filtered out. Default 0.1.\n        out_ext (str, optional): Extension of saved images. Default is the\n            original suffix.\n        verbose (bool, optional): Switch to print relevant values to screen.\n            Default 'False'.\n\n    Returns:\n        sliced_image_result: SliceImageResult:\n                                sliced_image_list: list of SlicedImage\n                                image_dir: str\n                                    Directory of the sliced image exports.\n                                original_image_size: list of int\n                                    Size of the unsliced original image in [height, width]\n        num_total_invalid_segmentation: int\n            Number of invalid segmentation annotations.\n    \"\"\"", "\n", "\n", "# define verboseprint", "\n", "verboselog", "=", "logger", ".", "info", "if", "verbose", "else", "lambda", "*", "a", ",", "**", "k", ":", "None", "\n", "\n", "def", "_export_single_slice", "(", "image", ":", "np", ".", "ndarray", ",", "output_dir", ":", "str", ",", "slice_file_name", ":", "str", ")", ":", "\n", "        ", "image_pil", "=", "read_image_as_pil", "(", "image", ")", "\n", "slice_file_path", "=", "str", "(", "Path", "(", "output_dir", ")", "/", "slice_file_name", ")", "\n", "# export sliced image", "\n", "image_pil", ".", "save", "(", "slice_file_path", ")", "\n", "verboselog", "(", "\"sliced image path: \"", "+", "slice_file_path", ")", "\n", "\n", "# create outdir if not present", "\n", "", "if", "output_dir", "is", "not", "None", ":", "\n", "        ", "Path", "(", "output_dir", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# read image", "\n", "", "image_pil", "=", "read_image_as_pil", "(", "image", ")", "\n", "verboselog", "(", "\"image.shape: \"", "+", "str", "(", "image_pil", ".", "size", ")", ")", "\n", "\n", "image_width", ",", "image_height", "=", "image_pil", ".", "size", "\n", "if", "not", "(", "image_width", "!=", "0", "and", "image_height", "!=", "0", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"invalid image size: {image_pil.size} for 'slice_image'.\"", ")", "\n", "", "slice_bboxes", "=", "get_slice_bboxes", "(", "\n", "image_height", "=", "image_height", ",", "\n", "image_width", "=", "image_width", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", ")", "\n", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "n_ims", "=", "0", "\n", "\n", "# init images and annotations lists", "\n", "sliced_image_result", "=", "SliceImageResult", "(", "original_image_size", "=", "[", "image_height", ",", "image_width", "]", ",", "image_dir", "=", "output_dir", ")", "\n", "\n", "image_pil_arr", "=", "np", ".", "asarray", "(", "image_pil", ")", "\n", "# iterate over slices", "\n", "for", "slice_bbox", "in", "slice_bboxes", ":", "\n", "        ", "n_ims", "+=", "1", "\n", "\n", "# extract image", "\n", "tlx", "=", "slice_bbox", "[", "0", "]", "\n", "tly", "=", "slice_bbox", "[", "1", "]", "\n", "brx", "=", "slice_bbox", "[", "2", "]", "\n", "bry", "=", "slice_bbox", "[", "3", "]", "\n", "image_pil_slice", "=", "image_pil_arr", "[", "tly", ":", "bry", ",", "tlx", ":", "brx", "]", "\n", "\n", "# process annotations if coco_annotations is given", "\n", "if", "coco_annotation_list", "is", "not", "None", ":", "\n", "            ", "sliced_coco_annotation_list", "=", "process_coco_annotations", "(", "coco_annotation_list", ",", "slice_bbox", ",", "min_area_ratio", ")", "\n", "\n", "# set image file suffixes", "\n", "", "slice_suffixes", "=", "\"_\"", ".", "join", "(", "map", "(", "str", ",", "slice_bbox", ")", ")", "\n", "if", "out_ext", ":", "\n", "            ", "suffix", "=", "out_ext", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "suffix", "=", "Path", "(", "image_pil", ".", "filename", ")", ".", "suffix", "\n", "", "except", "AttributeError", ":", "\n", "                ", "suffix", "=", "\".jpg\"", "\n", "\n", "# set image file name and path", "\n", "", "", "slice_file_name", "=", "f\"{output_file_name}_{slice_suffixes}{suffix}\"", "\n", "\n", "# create coco image", "\n", "slice_width", "=", "slice_bbox", "[", "2", "]", "-", "slice_bbox", "[", "0", "]", "\n", "slice_height", "=", "slice_bbox", "[", "3", "]", "-", "slice_bbox", "[", "1", "]", "\n", "coco_image", "=", "CocoImage", "(", "file_name", "=", "slice_file_name", ",", "height", "=", "slice_height", ",", "width", "=", "slice_width", ")", "\n", "\n", "# append coco annotations (if present) to coco image", "\n", "if", "coco_annotation_list", ":", "\n", "            ", "for", "coco_annotation", "in", "sliced_coco_annotation_list", ":", "\n", "                ", "coco_image", ".", "add_annotation", "(", "coco_annotation", ")", "\n", "\n", "# create sliced image and append to sliced_image_result", "\n", "", "", "sliced_image", "=", "SlicedImage", "(", "\n", "image", "=", "image_pil_slice", ",", "\n", "coco_image", "=", "coco_image", ",", "\n", "starting_pixel", "=", "[", "slice_bbox", "[", "0", "]", ",", "slice_bbox", "[", "1", "]", "]", ",", "\n", ")", "\n", "sliced_image_result", ".", "add_sliced_image", "(", "sliced_image", ")", "\n", "\n", "# export slices if output directory is provided", "\n", "", "if", "output_file_name", "and", "output_dir", ":", "\n", "        ", "conc_exec", "=", "concurrent", ".", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "MAX_WORKERS", ")", "\n", "conc_exec", ".", "map", "(", "\n", "_export_single_slice", ",", "\n", "sliced_image_result", ".", "images", ",", "\n", "[", "output_dir", "]", "*", "len", "(", "sliced_image_result", ")", ",", "\n", "sliced_image_result", ".", "filenames", ",", "\n", ")", "\n", "\n", "", "verboselog", "(", "\n", "\"Num slices: \"", "+", "str", "(", "n_ims", ")", "+", "\" slice_height: \"", "+", "str", "(", "slice_height", ")", "+", "\" slice_width: \"", "+", "str", "(", "slice_width", ")", ",", "\n", ")", "\n", "\n", "return", "sliced_image_result", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_coco": [[377, 469], ["sahi.utils.file.load_json", "sahi.utils.coco.Coco.from_coco_dict_or_path", "tqdm.tqdm", "sahi.utils.coco.create_coco_dict", "os.path.join", "sahi.utils.file.save_json", "slicing.slice_image", "sliced_coco_images.extend", "pathlib.Path", "logger.warning", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.create_coco_dict", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_image", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.extend"], ["", "def", "slice_coco", "(", "\n", "coco_annotation_file_path", ":", "str", ",", "\n", "image_dir", ":", "str", ",", "\n", "output_coco_annotation_file_name", ":", "str", ",", "\n", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "ignore_negative_samples", ":", "bool", "=", "False", ",", "\n", "slice_height", ":", "int", "=", "512", ",", "\n", "slice_width", ":", "int", "=", "512", ",", "\n", "overlap_height_ratio", ":", "float", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "float", "=", "0.2", ",", "\n", "min_area_ratio", ":", "float", "=", "0.1", ",", "\n", "out_ext", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", "->", "List", "[", "Union", "[", "Dict", ",", "str", "]", "]", ":", "\n", "\n", "    ", "\"\"\"\n    Slice large images given in a directory, into smaller windows. If out_name is given export sliced images and coco file.\n\n    Args:\n        coco_annotation_file_pat (str): Location of the coco annotation file\n        image_dir (str): Base directory for the images\n        output_coco_annotation_file_name (str): File name of the exported coco\n            datatset json.\n        output_dir (str, optional): Output directory\n        ignore_negative_samples (bool): If True, images without annotations\n            are ignored. Defaults to False.\n        slice_height (int): Height of each slice. Default 512.\n        slice_width (int): Width of each slice. Default 512.\n        overlap_height_ratio (float): Fractional overlap in height of each\n            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n            overlap of 20 pixels). Default 0.2.\n        overlap_width_ratio (float): Fractional overlap in width of each\n            slice (e.g. an overlap of 0.2 for a slice of size 100 yields an\n            overlap of 20 pixels). Default 0.2.\n        min_area_ratio (float): If the cropped annotation area to original annotation\n            ratio is smaller than this value, the annotation is filtered out. Default 0.1.\n        out_ext (str, optional): Extension of saved images. Default is the\n            original suffix.\n        verbose (bool, optional): Switch to print relevant values to screen.\n            Default 'False'.\n\n    Returns:\n        coco_dict: dict\n            COCO dict for sliced images and annotations\n        save_path: str\n            Path to the saved coco file\n    \"\"\"", "\n", "\n", "# read coco file", "\n", "coco_dict", ":", "Dict", "=", "load_json", "(", "coco_annotation_file_path", ")", "\n", "# create image_id_to_annotation_list mapping", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_dict", ")", "\n", "# init sliced coco_utils.CocoImage list", "\n", "sliced_coco_images", ":", "List", "=", "[", "]", "\n", "\n", "# iterate over images and slice", "\n", "for", "coco_image", "in", "tqdm", "(", "coco", ".", "images", ")", ":", "\n", "# get image path", "\n", "        ", "image_path", ":", "str", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "coco_image", ".", "file_name", ")", "\n", "# get annotation json list corresponding to selected coco image", "\n", "# slice image", "\n", "try", ":", "\n", "            ", "slice_image_result", "=", "slice_image", "(", "\n", "image", "=", "image_path", ",", "\n", "coco_annotation_list", "=", "coco_image", ".", "annotations", ",", "\n", "output_file_name", "=", "Path", "(", "coco_image", ".", "file_name", ")", ".", "stem", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "min_area_ratio", "=", "min_area_ratio", ",", "\n", "out_ext", "=", "out_ext", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "# append slice outputs", "\n", "sliced_coco_images", ".", "extend", "(", "slice_image_result", ".", "coco_images", ")", "\n", "", "except", "TopologicalError", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Invalid annotation found, skipping this image: {image_path}\"", ")", "\n", "\n", "# create and save coco dict", "\n", "", "", "coco_dict", "=", "create_coco_dict", "(", "\n", "sliced_coco_images", ",", "\n", "coco_dict", "[", "\"categories\"", "]", ",", "\n", "ignore_negative_samples", "=", "ignore_negative_samples", ",", "\n", ")", "\n", "save_path", "=", "\"\"", "\n", "if", "output_coco_annotation_file_name", "and", "output_dir", ":", "\n", "        ", "save_path", "=", "Path", "(", "output_dir", ")", "/", "(", "output_coco_annotation_file_name", "+", "\"_coco.json\"", ")", "\n", "save_json", "(", "coco_dict", ",", "save_path", ")", "\n", "\n", "", "return", "coco_dict", ",", "save_path", "\n", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.__init__": [[23, 41], ["int", "int", "int", "int", "Exception"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "box", ":", "List", "[", "int", "]", ",", "shift_amount", ":", "List", "[", "int", "]", "=", "[", "0", ",", "0", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            box: List[int]\n                [minx, miny, maxx, maxy]\n            shift_amount: List[int]\n                To shift the box and mask predictions from sliced image\n                to full sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "if", "box", "[", "0", "]", "<", "0", "or", "box", "[", "1", "]", "<", "0", "or", "box", "[", "2", "]", "<", "0", "or", "box", "[", "3", "]", "<", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Box coords [minx, miny, maxx, maxy] cannot be negative\"", ")", "\n", "", "self", ".", "minx", "=", "int", "(", "box", "[", "0", "]", ")", "\n", "self", ".", "miny", "=", "int", "(", "box", "[", "1", "]", ")", "\n", "self", ".", "maxx", "=", "int", "(", "box", "[", "2", "]", ")", "\n", "self", ".", "maxy", "=", "int", "(", "box", "[", "3", "]", ")", "\n", "\n", "self", ".", "shift_x", "=", "shift_amount", "[", "0", "]", "\n", "self", ".", "shift_y", "=", "shift_amount", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.shift_amount": [[42, 48], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shift_amount", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the shift amount of the bbox slice as [shift_x, shift_y]\n        \"\"\"", "\n", "return", "[", "self", ".", "shift_x", ",", "self", ".", "shift_y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_expanded_box": [[49, 60], ["int", "int", "max", "max", "annotation.BoundingBox", "min", "min"], "methods", ["None"], ["", "def", "get_expanded_box", "(", "self", ",", "ratio", "=", "0.1", ",", "max_x", "=", "None", ",", "max_y", "=", "None", ")", ":", "\n", "        ", "w", "=", "self", ".", "maxx", "-", "self", ".", "minx", "\n", "h", "=", "self", ".", "maxy", "-", "self", ".", "miny", "\n", "y_mar", "=", "int", "(", "w", "*", "ratio", ")", "\n", "x_mar", "=", "int", "(", "h", "*", "ratio", ")", "\n", "maxx", "=", "min", "(", "max_x", ",", "self", ".", "maxx", "+", "x_mar", ")", "if", "max_x", "else", "self", ".", "maxx", "+", "x_mar", "\n", "minx", "=", "max", "(", "0", ",", "self", ".", "minx", "-", "x_mar", ")", "\n", "maxy", "=", "min", "(", "max_y", ",", "self", ".", "maxy", "+", "y_mar", ")", "if", "max_y", "else", "self", ".", "maxy", "+", "y_mar", "\n", "miny", "=", "max", "(", "0", ",", "self", ".", "miny", "-", "y_mar", ")", "\n", "box", "=", "[", "minx", ",", "miny", ",", "maxx", ",", "maxy", "]", "\n", "return", "BoundingBox", "(", "box", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.to_coco_bbox": [[61, 66], ["None"], "methods", ["None"], ["", "def", "to_coco_bbox", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns: [xmin, ymin, width, height]\n        \"\"\"", "\n", "return", "[", "self", ".", "minx", ",", "self", ".", "miny", ",", "self", ".", "maxx", "-", "self", ".", "minx", ",", "self", ".", "maxy", "-", "self", ".", "miny", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.to_voc_bbox": [[67, 72], ["None"], "methods", ["None"], ["", "def", "to_voc_bbox", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns: [xmin, ymin, xmax, ymax]\n        \"\"\"", "\n", "return", "[", "self", ".", "minx", ",", "self", ".", "miny", ",", "self", ".", "maxx", ",", "self", ".", "maxy", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_shifted_box": [[73, 84], ["annotation.BoundingBox"], "methods", ["None"], ["", "def", "get_shifted_box", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns: shifted BoundingBox\n        \"\"\"", "\n", "box", "=", "[", "\n", "self", ".", "minx", "+", "self", ".", "shift_x", ",", "\n", "self", ".", "miny", "+", "self", ".", "shift_y", ",", "\n", "self", ".", "maxx", "+", "self", ".", "shift_x", ",", "\n", "self", ".", "maxy", "+", "self", ".", "shift_y", ",", "\n", "]", "\n", "return", "BoundingBox", "(", "box", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.__repr__": [[85, 87], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"BoundingBox: <{(self.minx, self.miny, self.maxx, self.maxy)}, w: {self.maxx - self.minx}, h: {self.maxy - self.miny}>\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Category.__init__": [[94, 108], ["isinstance", "TypeError", "isinstance", "TypeError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "id", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            id: int\n                ID of the object category\n            name: str\n                Name of the object category\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "id", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"id should be integer\"", ")", "\n", "", "if", "not", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"name should be string\"", ")", "\n", "", "self", ".", "id", "=", "id", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Category.__repr__": [[109, 111], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"Category: <id: {self.id}, name: {self.name}>\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.from_float_mask": [[114, 139], ["cls"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "from_float_mask", "(", "\n", "cls", ",", "\n", "mask", ",", "\n", "full_shape", "=", "None", ",", "\n", "mask_threshold", ":", "float", "=", "0.5", ",", "\n", "shift_amount", ":", "list", "=", "[", "0", ",", "0", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            mask: np.ndarray of np.float elements\n                Mask values between 0 and 1 (should have a shape of height*width)\n            mask_threshold: float\n                Value to threshold mask pixels between 0 and 1\n            shift_amount: List\n                To shift the box and mask predictions from sliced image\n                to full sized image, should be in the form of [shift_x, shift_y]\n            full_shape: List\n                Size of the full image after shifting, should be in the form of [height, width]\n        \"\"\"", "\n", "bool_mask", "=", "mask", ">", "mask_threshold", "\n", "return", "cls", "(", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.from_coco_segmentation": [[141, 172], ["sahi.utils.cv.get_bool_mask_from_coco_segmentation", "cls", "ValueError"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bool_mask_from_coco_segmentation"], ["", "@", "classmethod", "\n", "def", "from_coco_segmentation", "(", "\n", "cls", ",", "\n", "segmentation", ",", "\n", "full_shape", "=", "None", ",", "\n", "shift_amount", ":", "list", "=", "[", "0", ",", "0", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Init Mask from coco segmentation representation.\n\n        Args:\n            segmentation : List[List]\n                [\n                    [x1, y1, x2, y2, x3, y3, ...],\n                    [x1, y1, x2, y2, x3, y3, ...],\n                    ...\n                ]\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "# confirm full_shape is given", "\n", "if", "full_shape", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"full_shape must be provided\"", ")", "\n", "", "bool_mask", "=", "get_bool_mask_from_coco_segmentation", "(", "segmentation", ",", "height", "=", "full_shape", "[", "0", "]", ",", "width", "=", "full_shape", "[", "1", "]", ")", "\n", "return", "cls", "(", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.__init__": [[174, 213], ["len", "bool_mask.astype"], "methods", ["None"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "bool_mask", "=", "None", ",", "\n", "full_shape", "=", "None", ",", "\n", "shift_amount", ":", "list", "=", "[", "0", ",", "0", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            bool_mask: np.ndarray with bool elements\n                2D mask of object, should have a shape of height*width\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "\n", "if", "len", "(", "bool_mask", ")", ">", "0", ":", "\n", "            ", "has_bool_mask", "=", "True", "\n", "", "else", ":", "\n", "            ", "has_bool_mask", "=", "False", "\n", "\n", "", "if", "has_bool_mask", ":", "\n", "            ", "self", ".", "bool_mask", "=", "bool_mask", ".", "astype", "(", "bool", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bool_mask", "=", "None", "\n", "\n", "", "self", ".", "shift_x", "=", "shift_amount", "[", "0", "]", "\n", "self", ".", "shift_y", "=", "shift_amount", "[", "1", "]", "\n", "\n", "if", "full_shape", ":", "\n", "            ", "self", ".", "full_shape_height", "=", "full_shape", "[", "0", "]", "\n", "self", ".", "full_shape_width", "=", "full_shape", "[", "1", "]", "\n", "", "elif", "has_bool_mask", ":", "\n", "            ", "self", ".", "full_shape_height", "=", "self", ".", "bool_mask", ".", "shape", "[", "0", "]", "\n", "self", ".", "full_shape_width", "=", "self", ".", "bool_mask", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "full_shape_height", "=", "None", "\n", "self", ".", "full_shape_width", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.shape": [[214, 220], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns mask shape as [height, width]\n        \"\"\"", "\n", "return", "[", "self", ".", "bool_mask", ".", "shape", "[", "0", "]", ",", "self", ".", "bool_mask", ".", "shape", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.full_shape": [[221, 227], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "full_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns full mask shape after shifting as [height, width]\n        \"\"\"", "\n", "return", "[", "self", ".", "full_shape_height", ",", "self", ".", "full_shape_width", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.shift_amount": [[228, 234], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shift_amount", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the shift amount of the mask slice as [shift_x, shift_y]\n        \"\"\"", "\n", "return", "[", "self", ".", "shift_x", ",", "self", ".", "shift_y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.get_shifted_mask": [[235, 265], ["numpy.full", "annotation.Mask", "ValueError", "min", "min"], "methods", ["None"], ["", "def", "get_shifted_mask", "(", "self", ")", ":", "\n", "# Confirm full_shape is specified", "\n", "        ", "if", "(", "self", ".", "full_shape_height", "is", "None", ")", "or", "(", "self", ".", "full_shape_width", "is", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"full_shape is None\"", ")", "\n", "# init full mask", "\n", "", "mask_fullsized", "=", "np", ".", "full", "(", "\n", "(", "\n", "self", ".", "full_shape_height", ",", "\n", "self", ".", "full_shape_width", ",", "\n", ")", ",", "\n", "0", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", ")", "\n", "\n", "# arrange starting ending indexes", "\n", "starting_pixel", "=", "[", "self", ".", "shift_x", ",", "self", ".", "shift_y", "]", "\n", "ending_pixel", "=", "[", "\n", "min", "(", "starting_pixel", "[", "0", "]", "+", "self", ".", "bool_mask", ".", "shape", "[", "1", "]", ",", "self", ".", "full_shape_width", ")", ",", "\n", "min", "(", "starting_pixel", "[", "1", "]", "+", "self", ".", "bool_mask", ".", "shape", "[", "0", "]", ",", "self", ".", "full_shape_height", ")", ",", "\n", "]", "\n", "\n", "# convert sliced mask to full mask", "\n", "mask_fullsized", "[", "starting_pixel", "[", "1", "]", ":", "ending_pixel", "[", "1", "]", ",", "starting_pixel", "[", "0", "]", ":", "ending_pixel", "[", "0", "]", "]", "=", "self", ".", "bool_mask", "[", "\n", ":", "ending_pixel", "[", "1", "]", "-", "starting_pixel", "[", "1", "]", ",", ":", "ending_pixel", "[", "0", "]", "-", "starting_pixel", "[", "0", "]", "\n", "]", "\n", "\n", "return", "Mask", "(", "\n", "mask_fullsized", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "self", ".", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.to_coco_segmentation": [[267, 278], ["sahi.utils.cv.get_coco_segmentation_from_bool_mask"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_coco_segmentation_from_bool_mask"], ["", "def", "to_coco_segmentation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns boolean mask as coco segmentation:\n        [\n            [x1, y1, x2, y2, x3, y3, ...],\n            [x1, y1, x2, y2, x3, y3, ...],\n            ...\n        ]\n        \"\"\"", "\n", "coco_segmentation", "=", "get_coco_segmentation_from_bool_mask", "(", "self", ".", "bool_mask", ")", "\n", "return", "coco_segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.from_bool_mask": [[285, 316], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_bool_mask", "(", "\n", "cls", ",", "\n", "bool_mask", ",", "\n", "category_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "category_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates ObjectAnnotation from bool_mask (2D np.ndarray)\n\n        Args:\n            bool_mask: np.ndarray with bool elements\n                2D mask of object, should have a shape of height*width\n            category_id: int\n                ID of the object category\n            category_name: str\n                Name of the object category\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "return", "cls", "(", "\n", "category_id", "=", "category_id", ",", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.from_coco_segmentation": [[318, 359], ["sahi.utils.cv.get_bool_mask_from_coco_segmentation", "cls"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bool_mask_from_coco_segmentation"], ["", "@", "classmethod", "\n", "def", "from_coco_segmentation", "(", "\n", "cls", ",", "\n", "segmentation", ",", "\n", "full_shape", ":", "List", "[", "int", "]", ",", "\n", "category_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "category_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates ObjectAnnotation from coco segmentation:\n        [\n            [x1, y1, x2, y2, x3, y3, ...],\n            [x1, y1, x2, y2, x3, y3, ...],\n            ...\n        ]\n\n        Args:\n            segmentation: List[List]\n                [\n                    [x1, y1, x2, y2, x3, y3, ...],\n                    [x1, y1, x2, y2, x3, y3, ...],\n                    ...\n                ]\n            category_id: int\n                ID of the object category\n            category_name: str\n                Name of the object category\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "bool_mask", "=", "get_bool_mask_from_coco_segmentation", "(", "segmentation", ",", "width", "=", "full_shape", "[", "1", "]", ",", "height", "=", "full_shape", "[", "0", "]", ")", "\n", "return", "cls", "(", "\n", "category_id", "=", "category_id", ",", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.from_coco_bbox": [[361, 397], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_coco_bbox", "(", "\n", "cls", ",", "\n", "bbox", ":", "List", "[", "int", "]", ",", "\n", "category_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "category_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates ObjectAnnotation from coco bbox [minx, miny, width, height]\n\n        Args:\n            bbox: List\n                [minx, miny, width, height]\n            category_id: int\n                ID of the object category\n            category_name: str\n                Name of the object category\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "xmin", "=", "bbox", "[", "0", "]", "\n", "ymin", "=", "bbox", "[", "1", "]", "\n", "xmax", "=", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", "\n", "ymax", "=", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", "\n", "bbox", "=", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", "\n", "return", "cls", "(", "\n", "category_id", "=", "category_id", ",", "\n", "bbox", "=", "bbox", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.from_coco_annotation_dict": [[399, 437], ["cls.from_coco_segmentation", "cls.from_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox"], ["", "@", "classmethod", "\n", "def", "from_coco_annotation_dict", "(", "\n", "cls", ",", "\n", "annotation_dict", ":", "Dict", ",", "\n", "full_shape", ":", "List", "[", "int", "]", ",", "\n", "category_name", ":", "str", "=", "None", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates ObjectAnnotation object from category name and COCO formatted\n        annotation dict (with fields \"bbox\", \"segmentation\", \"category_id\").\n\n        Args:\n            annotation_dict: dict\n                COCO formatted annotation dict (with fields \"bbox\", \"segmentation\", \"category_id\")\n            category_name: str\n                Category name of the annotation\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "if", "annotation_dict", "[", "\"segmentation\"", "]", ":", "\n", "            ", "return", "cls", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "annotation_dict", "[", "\"segmentation\"", "]", ",", "\n", "category_id", "=", "annotation_dict", "[", "\"category_id\"", "]", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "cls", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "annotation_dict", "[", "\"bbox\"", "]", ",", "\n", "category_id", "=", "annotation_dict", "[", "\"category_id\"", "]", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.from_shapely_annotation": [[439, 472], ["sahi.utils.cv.get_bool_mask_from_coco_segmentation", "cls", "annotation.to_coco_segmentation"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bool_mask_from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation"], ["", "", "@", "classmethod", "\n", "def", "from_shapely_annotation", "(", "\n", "cls", ",", "\n", "annotation", ",", "\n", "full_shape", ":", "List", "[", "int", "]", ",", "\n", "category_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "category_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates ObjectAnnotation from shapely_utils.ShapelyAnnotation\n\n        Args:\n            annotation: shapely_utils.ShapelyAnnotation\n            category_id: int\n                ID of the object category\n            category_name: str\n                Name of the object category\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n        \"\"\"", "\n", "bool_mask", "=", "get_bool_mask_from_coco_segmentation", "(", "\n", "annotation", ".", "to_coco_segmentation", "(", ")", ",", "width", "=", "full_shape", "[", "1", "]", ",", "height", "=", "full_shape", "[", "0", "]", "\n", ")", "\n", "return", "cls", "(", "\n", "category_id", "=", "category_id", ",", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.from_imantics_annotation": [[474, 498], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_imantics_annotation", "(", "\n", "cls", ",", "\n", "annotation", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates ObjectAnnotation from imantics.annotation.Annotation\n\n        Args:\n            annotation: imantics.annotation.Annotation\n            shift_amount: List\n                To shift the box and mask predictions from sliced image to full\n                sized image, should be in the form of [shift_x, shift_y]\n            full_shape: List\n                Size of the full image, should be in the form of [height, width]\n        \"\"\"", "\n", "return", "cls", "(", "\n", "category_id", "=", "annotation", ".", "category", ".", "id", ",", "\n", "bool_mask", "=", "annotation", ".", "mask", ".", "array", ",", "\n", "category_name", "=", "annotation", ".", "category", ".", "name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.__init__": [[500, 566], ["max", "max", "annotation.BoundingBox", "annotation.Category", "isinstance", "ValueError", "ValueError", "annotation.Mask", "sahi.utils.cv.get_bbox_from_bool_mask", "min", "min", "str", "ValueError"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bbox_from_bool_mask"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "bbox", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "bool_mask", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "category_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "category_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            bbox: List\n                [minx, miny, maxx, maxy]\n            bool_mask: np.ndarray with bool elements\n                2D mask of object, should have a shape of height*width\n            category_id: int\n                ID of the object category\n            category_name: str\n                Name of the object category\n            shift_amount: List\n                To shift the box and mask predictions from sliced image\n                to full sized image, should be in the form of [shift_x, shift_y]\n            full_shape: List\n                Size of the full image after shifting, should be in\n                the form of [height, width]\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "category_id", ",", "int", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"category_id must be an integer\"", ")", "\n", "", "if", "(", "bbox", "is", "None", ")", "and", "(", "bool_mask", "is", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"you must provide a bbox or bool_mask\"", ")", "\n", "\n", "", "if", "bool_mask", "is", "not", "None", ":", "\n", "            ", "self", ".", "mask", "=", "Mask", "(", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "bbox_from_bool_mask", "=", "get_bbox_from_bool_mask", "(", "bool_mask", ")", "\n", "# https://github.com/obss/sahi/issues/235", "\n", "if", "bbox_from_bool_mask", "is", "not", "None", ":", "\n", "                ", "bbox", "=", "bbox_from_bool_mask", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid boolean mask.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "mask", "=", "None", "\n", "\n", "# make sure bbox coords lie inside [0, image_size]", "\n", "", "xmin", "=", "max", "(", "bbox", "[", "0", "]", ",", "0", ")", "\n", "ymin", "=", "max", "(", "bbox", "[", "1", "]", ",", "0", ")", "\n", "if", "full_shape", ":", "\n", "            ", "xmax", "=", "min", "(", "bbox", "[", "2", "]", ",", "full_shape", "[", "1", "]", ")", "\n", "ymax", "=", "min", "(", "bbox", "[", "3", "]", ",", "full_shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "xmax", "=", "bbox", "[", "2", "]", "\n", "ymax", "=", "bbox", "[", "3", "]", "\n", "", "bbox", "=", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", "\n", "# set bbox", "\n", "self", ".", "bbox", "=", "BoundingBox", "(", "bbox", ",", "shift_amount", ")", "\n", "\n", "category_name", "=", "category_name", "if", "category_name", "else", "str", "(", "category_id", ")", "\n", "self", ".", "category", "=", "Category", "(", "\n", "id", "=", "category_id", ",", "\n", "name", "=", "category_name", ",", "\n", ")", "\n", "\n", "self", ".", "merged", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.to_coco_annotation": [[567, 584], ["sahi.utils.coco.CocoAnnotation.from_coco_segmentation", "sahi.utils.coco.CocoAnnotation.from_coco_bbox", "annotation.ObjectAnnotation.mask.to_coco_segmentation", "annotation.ObjectAnnotation.bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "to_coco_annotation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns sahi.utils.coco.CocoAnnotation representation of ObjectAnnotation.\n        \"\"\"", "\n", "if", "self", ".", "mask", ":", "\n", "            ", "coco_annotation", "=", "CocoAnnotation", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "self", ".", "mask", ".", "to_coco_segmentation", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "coco_annotation", "=", "CocoAnnotation", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", ")", "\n", "", "return", "coco_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.to_coco_prediction": [[585, 604], ["sahi.utils.coco.CocoPrediction.from_coco_segmentation", "sahi.utils.coco.CocoPrediction.from_coco_bbox", "annotation.ObjectAnnotation.mask.to_coco_segmentation", "annotation.ObjectAnnotation.bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "to_coco_prediction", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns sahi.utils.coco.CocoPrediction representation of ObjectAnnotation.\n        \"\"\"", "\n", "if", "self", ".", "mask", ":", "\n", "            ", "coco_prediction", "=", "CocoPrediction", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "self", ".", "mask", ".", "to_coco_segmentation", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "score", "=", "1", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "coco_prediction", "=", "CocoPrediction", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "score", "=", "1", ",", "\n", ")", "\n", "", "return", "coco_prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.to_shapely_annotation": [[605, 618], ["sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "annotation.ObjectAnnotation.mask.to_coco_segmentation", "annotation.ObjectAnnotation.bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "to_shapely_annotation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns sahi.utils.shapely.ShapelyAnnotation representation of ObjectAnnotation.\n        \"\"\"", "\n", "if", "self", ".", "mask", ":", "\n", "            ", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "self", ".", "mask", ".", "to_coco_segmentation", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", ")", "\n", "", "return", "shapely_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.to_imantics_annotation": [[619, 642], ["imantics.Category", "imantics.Mask.create", "imantics.annotation.Annotation.from_mask", "imantics.BBox.create", "imantics.annotation.Annotation.from_bbox", "ImportError", "annotation.ObjectAnnotation.bbox.to_voc_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["", "def", "to_imantics_annotation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns imantics.annotation.Annotation representation of ObjectAnnotation.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "imantics", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please run \"pip install -U imantics\" '", "\"to install imantics first for imantics conversion.\"", "\n", ")", "\n", "\n", "", "imantics_category", "=", "imantics", ".", "Category", "(", "id", "=", "self", ".", "category", ".", "id", ",", "name", "=", "self", ".", "category", ".", "name", ")", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "imantics_mask", "=", "imantics", ".", "Mask", ".", "create", "(", "self", ".", "mask", ".", "bool_mask", ")", "\n", "imantics_annotation", "=", "imantics", ".", "annotation", ".", "Annotation", ".", "from_mask", "(", "\n", "mask", "=", "imantics_mask", ",", "category", "=", "imantics_category", "\n", ")", "\n", "", "else", ":", "\n", "            ", "imantics_bbox", "=", "imantics", ".", "BBox", ".", "create", "(", "self", ".", "bbox", ".", "to_voc_bbox", "(", ")", ")", "\n", "imantics_annotation", "=", "imantics", ".", "annotation", ".", "Annotation", ".", "from_bbox", "(", "\n", "bbox", "=", "imantics_bbox", ",", "category", "=", "imantics_category", "\n", ")", "\n", "", "return", "imantics_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy": [[643, 648], ["copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "def", "deepcopy", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns: deepcopy of current ObjectAnnotation instance\n        \"\"\"", "\n", "return", "copy", ".", "deepcopy", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.get_empty_mask": [[649, 652], ["annotation.Mask"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_empty_mask", "(", "cls", ")", ":", "\n", "        ", "return", "Mask", "(", "bool_mask", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.get_shifted_object_annotation": [[653, 671], ["annotation.ObjectAnnotation", "annotation.ObjectAnnotation", "annotation.ObjectAnnotation.bbox.get_shifted_box().to_voc_bbox", "annotation.ObjectAnnotation.bbox.get_shifted_box().to_voc_bbox", "annotation.ObjectAnnotation.mask.get_shifted_mask", "annotation.ObjectAnnotation.mask.get_shifted_mask", "annotation.ObjectAnnotation.bbox.get_shifted_box", "annotation.ObjectAnnotation.bbox.get_shifted_box"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.get_shifted_mask", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.get_shifted_mask", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_shifted_box", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_shifted_box"], ["", "def", "get_shifted_object_annotation", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mask", ":", "\n", "            ", "return", "ObjectAnnotation", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "get_shifted_box", "(", ")", ".", "to_voc_bbox", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "bool_mask", "=", "self", ".", "mask", ".", "get_shifted_mask", "(", ")", ".", "bool_mask", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "self", ".", "mask", ".", "get_shifted_mask", "(", ")", ".", "full_shape", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "ObjectAnnotation", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "get_shifted_box", "(", ")", ".", "to_voc_bbox", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "bool_mask", "=", "None", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.__repr__": [[673, 678], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"ObjectAnnotation<\n    bbox: {self.bbox},\n    mask: {self.mask},\n    category: {self.category}>\"\"\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.sahi.cli.app": [[29, 32], ["fire.Fire"], "function", ["None"], ["def", "app", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"Cli app.\"\"\"", "\n", "fire", ".", "Fire", "(", "sahi_app", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.predict.get_prediction": [[50, 115], ["dict", "sahi.utils.cv.read_image_as_pil", "time.time", "detection_model.perform_inference", "time.time", "detection_model.convert_original_predictions", "sahi.prediction.PredictionResult", "numpy.ascontiguousarray", "time.time", "postprocess", "time.time", "print"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions"], ["def", "get_prediction", "(", "\n", "image", ",", "\n", "detection_model", ",", "\n", "shift_amount", ":", "list", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", ":", "Optional", "[", "PostprocessPredictions", "]", "=", "None", ",", "\n", "verbose", ":", "int", "=", "0", ",", "\n", ")", "->", "PredictionResult", ":", "\n", "    ", "\"\"\"\n    Function for performing prediction for given image using given detection_model.\n\n    Arguments:\n        image: str or np.ndarray\n            Location of image or numpy image matrix to slice\n        detection_model: model.DetectionMode\n        shift_amount: List\n            To shift the box and mask predictions from sliced image to full\n            sized image, should be in the form of [shift_x, shift_y]\n        full_shape: List\n            Size of the full image, should be in the form of [height, width]\n        postprocess: sahi.postprocess.combine.PostprocessPredictions\n        verbose: int\n            0: no print (default)\n            1: print prediction duration\n\n    Returns:\n        A dict with fields:\n            object_prediction_list: a list of ObjectPrediction\n            durations_in_seconds: a dict containing elapsed times for profiling\n    \"\"\"", "\n", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "# read image as pil", "\n", "image_as_pil", "=", "read_image_as_pil", "(", "image", ")", "\n", "# get prediction", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "detection_model", ".", "perform_inference", "(", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ")", "\n", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "time_end", "\n", "\n", "# process prediction", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "# works only with 1 batch", "\n", "detection_model", ".", "convert_original_predictions", "(", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "object_prediction_list", ":", "List", "[", "ObjectPrediction", "]", "=", "detection_model", ".", "object_prediction_list", "\n", "\n", "# postprocess matching predictions", "\n", "if", "postprocess", "is", "not", "None", ":", "\n", "        ", "object_prediction_list", "=", "postprocess", "(", "object_prediction_list", ")", "\n", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"postprocess\"", "]", "=", "time_end", "\n", "\n", "if", "verbose", "==", "1", ":", "\n", "        ", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "", "return", "PredictionResult", "(", "\n", "image", "=", "image", ",", "object_prediction_list", "=", "object_prediction_list", ",", "durations_in_seconds", "=", "durations_in_seconds", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.predict.get_sliced_prediction": [[118, 279], ["dict", "time.time", "sahi.slicing.slice_image", "len", "postprocess_constructor", "int", "range", "sahi.prediction.PredictionResult", "time.time", "POSTPROCESS_NAME_TO_CLASS.keys", "ValueError", "tqdm.tqdm.write", "range", "predict.get_prediction", "predict.get_prediction", "postprocess.extend", "print", "print", "len", "postprocess_constructor.", "time.time", "ValueError", "image_list.append", "shift_amount_list.append", "postprocess_constructor.", "postprocess.append", "len", "list", "object_prediction.get_shifted_object_prediction", "POSTPROCESS_NAME_TO_CLASS.keys"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_image", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.extend", "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.get_shifted_object_prediction"], ["", "def", "get_sliced_prediction", "(", "\n", "image", ",", "\n", "detection_model", "=", "None", ",", "\n", "slice_height", ":", "int", "=", "512", ",", "\n", "slice_width", ":", "int", "=", "512", ",", "\n", "overlap_height_ratio", ":", "float", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "float", "=", "0.2", ",", "\n", "perform_standard_pred", ":", "bool", "=", "True", ",", "\n", "postprocess_type", ":", "str", "=", "\"GREEDYNMM\"", ",", "\n", "postprocess_match_metric", ":", "str", "=", "\"IOS\"", ",", "\n", "postprocess_match_threshold", ":", "float", "=", "0.5", ",", "\n", "postprocess_class_agnostic", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", "merge_buffer_length", ":", "int", "=", "None", ",", "\n", ")", "->", "PredictionResult", ":", "\n", "    ", "\"\"\"\n    Function for slice image + get predicion for each slice + combine predictions in full image.\n\n    Args:\n        image: str or np.ndarray\n            Location of image or numpy image matrix to slice\n        detection_model: model.DetectionModel\n        slice_height: int\n            Height of each slice.  Defaults to ``512``.\n        slice_width: int\n            Width of each slice.  Defaults to ``512``.\n        overlap_height_ratio: float\n            Fractional overlap in height of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        overlap_width_ratio: float\n            Fractional overlap in width of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        perform_standard_pred: bool\n            Perform a standard prediction on top of sliced predictions to increase large object\n            detection accuracy. Default: True.\n        postprocess_type: str\n            Type of the postprocess to be used after sliced inference while merging/eliminating predictions.\n            Options are 'NMM', 'GRREDYNMM' or 'NMS'. Default is 'GRREDYNMM'.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_threshold: float\n            Sliced predictions having higher iou than postprocess_match_threshold will be\n            postprocessed after sliced prediction.\n        postprocess_class_agnostic: bool\n            If True, postprocess will ignore category ids.\n        verbose: int\n            0: no print\n            1: print number of slices (default)\n            2: print number of slices and slice/prediction durations\n        merge_buffer_length: int\n            The length of buffer for slices to be used during sliced prediction, which is suitable for low memory.\n            It may affect the AP if it is specified. The higher the amount, the closer results to the non-buffered.\n            scenario. See [the discussion](https://github.com/obss/sahi/pull/445).\n\n    Returns:\n        A Dict with fields:\n            object_prediction_list: a list of sahi.prediction.ObjectPrediction\n            durations_in_seconds: a dict containing elapsed times for profiling\n    \"\"\"", "\n", "\n", "# for profiling", "\n", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "# currently only 1 batch supported", "\n", "num_batch", "=", "1", "\n", "\n", "# create slices from full image", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "slice_image_result", "=", "slice_image", "(", "\n", "image", "=", "image", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", ")", "\n", "num_slices", "=", "len", "(", "slice_image_result", ")", "\n", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "=", "time_end", "\n", "\n", "# init match postprocess instance", "\n", "if", "postprocess_type", "not", "in", "POSTPROCESS_NAME_TO_CLASS", ".", "keys", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"postprocess_type should be one of {list(POSTPROCESS_NAME_TO_CLASS.keys())} but given as {postprocess_type}\"", "\n", ")", "\n", "", "elif", "postprocess_type", "==", "\"UNIONMERGE\"", ":", "\n", "# deprecated in v0.9.3", "\n", "        ", "raise", "ValueError", "(", "\"'UNIONMERGE' postprocess_type is deprecated, use 'GREEDYNMM' instead.\"", ")", "\n", "", "postprocess_constructor", "=", "POSTPROCESS_NAME_TO_CLASS", "[", "postprocess_type", "]", "\n", "postprocess", "=", "postprocess_constructor", "(", "\n", "match_threshold", "=", "postprocess_match_threshold", ",", "\n", "match_metric", "=", "postprocess_match_metric", ",", "\n", "class_agnostic", "=", "postprocess_class_agnostic", ",", "\n", ")", "\n", "\n", "# create prediction input", "\n", "num_group", "=", "int", "(", "num_slices", "/", "num_batch", ")", "\n", "if", "verbose", "==", "1", "or", "verbose", "==", "2", ":", "\n", "        ", "tqdm", ".", "write", "(", "f\"Performing prediction on {num_slices} number of slices.\"", ")", "\n", "", "object_prediction_list", "=", "[", "]", "\n", "# perform sliced prediction", "\n", "for", "group_ind", "in", "range", "(", "num_group", ")", ":", "\n", "# prepare batch (currently supports only 1 batch)", "\n", "        ", "image_list", "=", "[", "]", "\n", "shift_amount_list", "=", "[", "]", "\n", "for", "image_ind", "in", "range", "(", "num_batch", ")", ":", "\n", "            ", "image_list", ".", "append", "(", "slice_image_result", ".", "images", "[", "group_ind", "*", "num_batch", "+", "image_ind", "]", ")", "\n", "shift_amount_list", ".", "append", "(", "slice_image_result", ".", "starting_pixels", "[", "group_ind", "*", "num_batch", "+", "image_ind", "]", ")", "\n", "# perform batch prediction", "\n", "", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image_list", "[", "0", "]", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "shift_amount_list", "[", "0", "]", ",", "\n", "full_shape", "=", "[", "\n", "slice_image_result", ".", "original_image_height", ",", "\n", "slice_image_result", ".", "original_image_width", ",", "\n", "]", ",", "\n", ")", "\n", "# convert sliced predictions to full predictions", "\n", "for", "object_prediction", "in", "prediction_result", ".", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ":", "# if not empty", "\n", "                ", "object_prediction_list", ".", "append", "(", "object_prediction", ".", "get_shifted_object_prediction", "(", ")", ")", "\n", "\n", "# merge matching predictions during sliced prediction", "\n", "", "", "if", "merge_buffer_length", "is", "not", "None", "and", "len", "(", "object_prediction_list", ")", ">", "merge_buffer_length", ":", "\n", "            ", "object_prediction_list", "=", "postprocess", "(", "object_prediction_list", ")", "\n", "\n", "# perform standard prediction", "\n", "", "", "if", "num_slices", ">", "1", "and", "perform_standard_pred", ":", "\n", "        ", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", "=", "None", ",", "\n", ")", "\n", "object_prediction_list", ".", "extend", "(", "prediction_result", ".", "object_prediction_list", ")", "\n", "\n", "", "if", "verbose", "==", "2", ":", "\n", "        ", "print", "(", "\n", "\"Slicing performed in\"", ",", "\n", "durations_in_seconds", "[", "\"slice\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "# merge matching predictions", "\n", "", "if", "len", "(", "object_prediction_list", ")", ">", "1", ":", "\n", "        ", "object_prediction_list", "=", "postprocess", "(", "object_prediction_list", ")", "\n", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "time_end", "\n", "\n", "return", "PredictionResult", "(", "\n", "image", "=", "image", ",", "object_prediction_list", "=", "object_prediction_list", ",", "durations_in_seconds", "=", "durations_in_seconds", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.predict.predict": [[282, 652], ["dict", "sahi.utils.file.Path", "time.time", "enumerate", "ValueError", "logger.warning", "sahi.utils.file.increment_path", "sahi.utils.file.Path.mkdir", "sahi.utils.coco.Coco.from_coco_dict_or_path", "os.path.isdir", "sahi.auto_model.AutoDetectionModel.from_pretrained", "AutoDetectionModel.from_pretrained.load_model", "time.time", "tqdm.tqdm", "sahi.utils.cv.read_image_as_pil", "time.time", "str", "sahi.utils.file.save_json", "print", "print", "print", "print", "str", "sahi.utils.file.list_files", "os.path.isdir", "sahi.utils.file.Path", "predict.get_sliced_prediction", "predict.get_prediction", "tqdm.tqdm.write", "str", "sahi.utils.cv.crop_object_predictions", "str", "sahi.utils.file.save_pickle", "str", "sahi.utils.cv.visualize_object_predictions", "sahi.utils.cv.cv2.imshow", "sahi.utils.cv.cv2.waitKey", "time.time", "print", "sahi.utils.file.Path", "sahi.utils.cv.get_video_reader", "sahi.utils.file.Path", "str", "NotImplementedError", "object_prediction.to_coco_prediction", "str", "sahi.utils.cv.visualize_object_predictions", "sahi.utils.cv.visualize_object_predictions", "numpy.ascontiguousarray", "output_video_writer.write", "sahi.utils.file.Path", "sahi.utils.file.Path", "sahi.utils.file.Path", "str().split", "sahi.utils.file.Path", "coco_json.append", "sahi.prediction.ObjectPrediction.from_coco_annotation_dict", "object_prediction_gt_list.append", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "str", "str", "sahi.utils.file.Path", "sahi.utils.file.Path", "str", "sahi.utils.file.Path", "sahi.utils.file.Path", "sahi.utils.file.Path", "sahi.utils.file.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.increment_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json", "home.repos.pwc.inspect_result.obss_sahi.utils.file.list_files", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.crop_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_pickle", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_video_reader", "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.to_coco_prediction", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.from_coco_annotation_dict"], ["", "def", "predict", "(", "\n", "detection_model", ":", "DetectionModel", "=", "None", ",", "\n", "model_type", ":", "str", "=", "\"mmdet\"", ",", "\n", "model_path", ":", "str", "=", "None", ",", "\n", "model_config_path", ":", "str", "=", "None", ",", "\n", "model_confidence_threshold", ":", "float", "=", "0.25", ",", "\n", "model_device", ":", "str", "=", "None", ",", "\n", "model_category_mapping", ":", "dict", "=", "None", ",", "\n", "model_category_remapping", ":", "dict", "=", "None", ",", "\n", "source", ":", "str", "=", "None", ",", "\n", "no_standard_prediction", ":", "bool", "=", "False", ",", "\n", "no_sliced_prediction", ":", "bool", "=", "False", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", "slice_height", ":", "int", "=", "512", ",", "\n", "slice_width", ":", "int", "=", "512", ",", "\n", "overlap_height_ratio", ":", "float", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "float", "=", "0.2", ",", "\n", "postprocess_type", ":", "str", "=", "\"GREEDYNMM\"", ",", "\n", "postprocess_match_metric", ":", "str", "=", "\"IOS\"", ",", "\n", "postprocess_match_threshold", ":", "float", "=", "0.5", ",", "\n", "postprocess_class_agnostic", ":", "bool", "=", "False", ",", "\n", "novisual", ":", "bool", "=", "False", ",", "\n", "view_video", ":", "bool", "=", "False", ",", "\n", "frame_skip_interval", ":", "int", "=", "0", ",", "\n", "export_pickle", ":", "bool", "=", "False", ",", "\n", "export_crop", ":", "bool", "=", "False", ",", "\n", "dataset_json_path", ":", "bool", "=", "None", ",", "\n", "project", ":", "str", "=", "\"runs/predict\"", ",", "\n", "name", ":", "str", "=", "\"exp\"", ",", "\n", "visual_bbox_thickness", ":", "int", "=", "None", ",", "\n", "visual_text_size", ":", "float", "=", "None", ",", "\n", "visual_text_thickness", ":", "int", "=", "None", ",", "\n", "visual_export_format", ":", "str", "=", "\"png\"", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", "return_dict", ":", "bool", "=", "False", ",", "\n", "force_postprocess_type", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Performs prediction for all present images in given folder.\n\n    Args:\n        detection_model: sahi.model.DetectionModel\n            Optionally provide custom DetectionModel to be used for inference. When provided,\n            model_type, model_path, config_path, model_device, model_category_mapping, image_size\n            params will be ignored\n        model_type: str\n            mmdet for 'MmdetDetectionModel', 'yolov5' for 'Yolov5DetectionModel'.\n        model_path: str\n            Path for the model weight\n        model_config_path: str\n            Path for the detection model config file\n        model_confidence_threshold: float\n            All predictions with score < model_confidence_threshold will be discarded.\n        model_device: str\n            Torch device, \"cpu\" or \"cuda\"\n        model_category_mapping: dict\n            Mapping from category id (str) to category name (str) e.g. {\"1\": \"pedestrian\"}\n        model_category_remapping: dict: str to int\n            Remap category ids after performing inference\n        source: str\n            Folder directory that contains images or path of the image to be predicted. Also video to be predicted.\n        no_standard_prediction: bool\n            Dont perform standard prediction. Default: False.\n        no_sliced_prediction: bool\n            Dont perform sliced prediction. Default: False.\n        image_size: int\n            Input image size for each inference (image is scaled by preserving asp. rat.).\n        slice_height: int\n            Height of each slice.  Defaults to ``512``.\n        slice_width: int\n            Width of each slice.  Defaults to ``512``.\n        overlap_height_ratio: float\n            Fractional overlap in height of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        overlap_width_ratio: float\n            Fractional overlap in width of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        postprocess_type: str\n            Type of the postprocess to be used after sliced inference while merging/eliminating predictions.\n            Options are 'NMM', 'GRREDYNMM' or 'NMS'. Default is 'GRREDYNMM'.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_threshold: float\n            Sliced predictions having higher iou than postprocess_match_threshold will be\n            postprocessed after sliced prediction.\n        postprocess_class_agnostic: bool\n            If True, postprocess will ignore category ids.\n        novisual: bool\n            Dont export predicted video/image visuals.\n        view_video: bool\n            View result of prediction during video inference.\n        frame_skip_interval: int\n            If view_video or export_visual is slow, you can process one frames of 3(for exp: --frame_skip_interval=3).\n        export_pickle: bool\n            Export predictions as .pickle\n        export_crop: bool\n            Export predictions as cropped images.\n        dataset_json_path: str\n            If coco file path is provided, detection results will be exported in coco json format.\n        project: str\n            Save results to project/name.\n        name: str\n            Save results to project/name.\n        visual_bbox_thickness: int\n        visual_text_size: float\n        visual_text_thickness: int\n        visual_export_format: str\n            Can be specified as 'jpg' or 'png'\n        verbose: int\n            0: no print\n            1: print slice/prediction durations, number of slices\n            2: print model loading/file exporting durations\n        return_dict: bool\n            If True, returns a dict with 'export_dir' field.\n        force_postprocess_type: bool\n            If True, auto postprocess check will e disabled\n    \"\"\"", "\n", "# assert prediction type", "\n", "if", "no_standard_prediction", "and", "no_sliced_prediction", ":", "\n", "        ", "raise", "ValueError", "(", "\"'no_standard_prediction' and 'no_sliced_prediction' cannot be True at the same time.\"", ")", "\n", "\n", "# auto postprocess type", "\n", "", "if", "not", "force_postprocess_type", "and", "model_confidence_threshold", "<", "LOW_MODEL_CONFIDENCE", "and", "postprocess_type", "!=", "\"NMS\"", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"Switching postprocess type/metric to NMS/IOU since confidence threshold is low ({model_confidence_threshold}).\"", "\n", ")", "\n", "postprocess_type", "=", "\"NMS\"", "\n", "postprocess_match_metric", "=", "\"IOU\"", "\n", "\n", "# for profiling", "\n", "", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "# init export directories", "\n", "save_dir", "=", "Path", "(", "increment_path", "(", "Path", "(", "project", ")", "/", "name", ",", "exist_ok", "=", "False", ")", ")", "# increment run", "\n", "crop_dir", "=", "save_dir", "/", "\"crops\"", "\n", "visual_dir", "=", "save_dir", "/", "\"visuals\"", "\n", "visual_with_gt_dir", "=", "save_dir", "/", "\"visuals_with_gt\"", "\n", "pickle_dir", "=", "save_dir", "/", "\"pickles\"", "\n", "if", "not", "novisual", "or", "export_pickle", "or", "export_crop", "or", "dataset_json_path", "is", "not", "None", ":", "\n", "        ", "save_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# make dir", "\n", "\n", "# init image iterator", "\n", "# TODO: rewrite this as iterator class as in https://github.com/ultralytics/yolov5/blob/d059d1da03aee9a3c0059895aa4c7c14b7f25a9e/utils/datasets.py#L178", "\n", "", "source_is_video", "=", "False", "\n", "num_frames", "=", "None", "\n", "if", "dataset_json_path", ":", "\n", "        ", "coco", ":", "Coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "dataset_json_path", ")", "\n", "image_iterator", "=", "[", "str", "(", "Path", "(", "source", ")", "/", "Path", "(", "coco_image", ".", "file_name", ")", ")", "for", "coco_image", "in", "coco", ".", "images", "]", "\n", "coco_json", "=", "[", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "source", ")", ":", "\n", "        ", "image_iterator", "=", "list_files", "(", "\n", "directory", "=", "source", ",", "\n", "contains", "=", "IMAGE_EXTENSIONS", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "", "elif", "Path", "(", "source", ")", ".", "suffix", "in", "VIDEO_EXTENSIONS", ":", "\n", "        ", "source_is_video", "=", "True", "\n", "read_video_frame", ",", "output_video_writer", ",", "video_file_name", ",", "num_frames", "=", "get_video_reader", "(", "\n", "source", ",", "save_dir", ",", "frame_skip_interval", ",", "not", "novisual", ",", "view_video", "\n", ")", "\n", "image_iterator", "=", "read_video_frame", "\n", "", "else", ":", "\n", "        ", "image_iterator", "=", "[", "source", "]", "\n", "\n", "# init model instance", "\n", "", "time_start", "=", "time", ".", "time", "(", ")", "\n", "if", "detection_model", "is", "None", ":", "\n", "        ", "detection_model", "=", "AutoDetectionModel", ".", "from_pretrained", "(", "\n", "model_type", "=", "model_type", ",", "\n", "model_path", "=", "model_path", ",", "\n", "config_path", "=", "model_config_path", ",", "\n", "confidence_threshold", "=", "model_confidence_threshold", ",", "\n", "device", "=", "model_device", ",", "\n", "category_mapping", "=", "model_category_mapping", ",", "\n", "category_remapping", "=", "model_category_remapping", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "image_size", ",", "\n", ")", "\n", "detection_model", ".", "load_model", "(", ")", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", "=", "time_end", "\n", "\n", "# iterate over source images", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "0", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "=", "0", "\n", "\n", "input_type_str", "=", "\"video frames\"", "if", "source_is_video", "else", "\"images\"", "\n", "for", "ind", ",", "image_path", "in", "enumerate", "(", "\n", "tqdm", "(", "image_iterator", ",", "f\"Performing inference on {input_type_str}\"", ",", "total", "=", "num_frames", ")", "\n", ")", ":", "\n", "# get filename", "\n", "        ", "if", "source_is_video", ":", "\n", "            ", "video_name", "=", "Path", "(", "source", ")", ".", "stem", "\n", "relative_filepath", "=", "video_name", "+", "\"_frame_\"", "+", "str", "(", "ind", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "source", ")", ":", "# preserve source folder structure in export", "\n", "            ", "relative_filepath", "=", "str", "(", "Path", "(", "image_path", ")", ")", ".", "split", "(", "str", "(", "Path", "(", "source", ")", ")", ")", "[", "-", "1", "]", "\n", "relative_filepath", "=", "relative_filepath", "[", "1", ":", "]", "if", "relative_filepath", "[", "0", "]", "==", "os", ".", "sep", "else", "relative_filepath", "\n", "", "else", ":", "# no process if source is single file", "\n", "            ", "relative_filepath", "=", "Path", "(", "image_path", ")", ".", "name", "\n", "\n", "", "filename_without_extension", "=", "Path", "(", "relative_filepath", ")", ".", "stem", "\n", "\n", "# load image", "\n", "image_as_pil", "=", "read_image_as_pil", "(", "image_path", ")", "\n", "\n", "# perform prediction", "\n", "if", "not", "no_sliced_prediction", ":", "\n", "# get sliced prediction", "\n", "            ", "prediction_result", "=", "get_sliced_prediction", "(", "\n", "image", "=", "image_as_pil", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "perform_standard_pred", "=", "not", "no_standard_prediction", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_metric", "=", "postprocess_match_metric", ",", "\n", "postprocess_match_threshold", "=", "postprocess_match_threshold", ",", "\n", "postprocess_class_agnostic", "=", "postprocess_class_agnostic", ",", "\n", "verbose", "=", "1", "if", "verbose", "else", "0", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"slice\"", "]", "\n", "", "else", ":", "\n", "# get standard prediction", "\n", "            ", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image_as_pil", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", "=", "None", ",", "\n", "verbose", "=", "0", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "", "durations_in_seconds", "[", "\"prediction\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"prediction\"", "]", "\n", "# Show prediction time", "\n", "if", "verbose", ":", "\n", "            ", "tqdm", ".", "write", "(", "\n", "\"Prediction time is: {:.2f} ms\"", ".", "format", "(", "prediction_result", ".", "durations_in_seconds", "[", "\"prediction\"", "]", "*", "1000", ")", "\n", ")", "\n", "\n", "", "if", "dataset_json_path", ":", "\n", "            ", "if", "source_is_video", "is", "True", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"Video input type not supported with coco formatted dataset json\"", ")", "\n", "\n", "# append predictions in coco format", "\n", "", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "                ", "coco_prediction", "=", "object_prediction", ".", "to_coco_prediction", "(", ")", "\n", "coco_prediction", ".", "image_id", "=", "coco", ".", "images", "[", "ind", "]", ".", "id", "\n", "coco_prediction_json", "=", "coco_prediction", ".", "json", "\n", "if", "coco_prediction_json", "[", "\"bbox\"", "]", ":", "\n", "                    ", "coco_json", ".", "append", "(", "coco_prediction_json", ")", "\n", "", "", "if", "not", "novisual", ":", "\n", "# convert ground truth annotations to object_prediction_list", "\n", "                ", "coco_image", ":", "CocoImage", "=", "coco", ".", "images", "[", "ind", "]", "\n", "object_prediction_gt_list", ":", "List", "[", "ObjectPrediction", "]", "=", "[", "]", "\n", "for", "coco_annotation", "in", "coco_image", ".", "annotations", ":", "\n", "                    ", "coco_annotation_dict", "=", "coco_annotation", ".", "json", "\n", "category_name", "=", "coco_annotation", ".", "category_name", "\n", "full_shape", "=", "[", "coco_image", ".", "height", ",", "coco_image", ".", "width", "]", "\n", "object_prediction_gt", "=", "ObjectPrediction", ".", "from_coco_annotation_dict", "(", "\n", "annotation_dict", "=", "coco_annotation_dict", ",", "category_name", "=", "category_name", ",", "full_shape", "=", "full_shape", "\n", ")", "\n", "object_prediction_gt_list", ".", "append", "(", "object_prediction_gt", ")", "\n", "# export visualizations with ground truths", "\n", "", "output_dir", "=", "str", "(", "visual_with_gt_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", ")", "\n", "color", "=", "(", "0", ",", "255", ",", "0", ")", "# original annotations in green", "\n", "result", "=", "visualize_object_predictions", "(", "\n", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ",", "\n", "object_prediction_list", "=", "object_prediction_gt_list", ",", "\n", "rect_th", "=", "visual_bbox_thickness", ",", "\n", "text_size", "=", "visual_text_size", ",", "\n", "text_th", "=", "visual_text_thickness", ",", "\n", "color", "=", "color", ",", "\n", "output_dir", "=", "None", ",", "\n", "file_name", "=", "None", ",", "\n", "export_format", "=", "None", ",", "\n", ")", "\n", "color", "=", "(", "255", ",", "0", ",", "0", ")", "# model predictions in red", "\n", "_", "=", "visualize_object_predictions", "(", "\n", "result", "[", "\"image\"", "]", ",", "\n", "object_prediction_list", "=", "object_prediction_list", ",", "\n", "rect_th", "=", "visual_bbox_thickness", ",", "\n", "text_size", "=", "visual_text_size", ",", "\n", "text_th", "=", "visual_text_thickness", ",", "\n", "color", "=", "color", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "file_name", "=", "filename_without_extension", ",", "\n", "export_format", "=", "visual_export_format", ",", "\n", ")", "\n", "\n", "", "", "time_start", "=", "time", ".", "time", "(", ")", "\n", "# export prediction boxes", "\n", "if", "export_crop", ":", "\n", "            ", "output_dir", "=", "str", "(", "crop_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", ")", "\n", "crop_object_predictions", "(", "\n", "image", "=", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ",", "\n", "object_prediction_list", "=", "object_prediction_list", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "file_name", "=", "filename_without_extension", ",", "\n", "export_format", "=", "visual_export_format", ",", "\n", ")", "\n", "# export prediction list as pickle", "\n", "", "if", "export_pickle", ":", "\n", "            ", "save_path", "=", "str", "(", "pickle_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", "/", "(", "filename_without_extension", "+", "\".pickle\"", ")", ")", "\n", "save_pickle", "(", "data", "=", "object_prediction_list", ",", "save_path", "=", "save_path", ")", "\n", "\n", "# export visualization", "\n", "", "if", "not", "novisual", "or", "view_video", ":", "\n", "            ", "output_dir", "=", "str", "(", "visual_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", ")", "\n", "result", "=", "visualize_object_predictions", "(", "\n", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ",", "\n", "object_prediction_list", "=", "object_prediction_list", ",", "\n", "rect_th", "=", "visual_bbox_thickness", ",", "\n", "text_size", "=", "visual_text_size", ",", "\n", "text_th", "=", "visual_text_thickness", ",", "\n", "output_dir", "=", "output_dir", "if", "not", "source_is_video", "else", "None", ",", "\n", "file_name", "=", "filename_without_extension", ",", "\n", "export_format", "=", "visual_export_format", ",", "\n", ")", "\n", "if", "not", "novisual", "and", "source_is_video", ":", "# export video", "\n", "                ", "output_video_writer", ".", "write", "(", "result", "[", "\"image\"", "]", ")", "\n", "\n", "# render video inference", "\n", "", "", "if", "view_video", ":", "\n", "            ", "cv2", ".", "imshow", "(", "\"Prediction of {}\"", ".", "format", "(", "str", "(", "video_file_name", ")", ")", ",", "result", "[", "\"image\"", "]", ")", "\n", "cv2", ".", "waitKey", "(", "1", ")", "\n", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"export_files\"", "]", "=", "time_end", "\n", "\n", "# export coco results", "\n", "", "if", "dataset_json_path", ":", "\n", "        ", "save_path", "=", "str", "(", "save_dir", "/", "\"result.json\"", ")", "\n", "save_json", "(", "coco_json", ",", "save_path", ")", "\n", "\n", "", "if", "not", "novisual", "or", "export_pickle", "or", "export_crop", "or", "dataset_json_path", "is", "not", "None", ":", "\n", "        ", "print", "(", "f\"Prediction results are successfully exported to {save_dir}\"", ")", "\n", "\n", "# print prediction duration", "\n", "", "if", "verbose", "==", "2", ":", "\n", "        ", "print", "(", "\n", "\"Model loaded in\"", ",", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Slicing performed in\"", ",", "\n", "durations_in_seconds", "[", "\"slice\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "if", "not", "novisual", ":", "\n", "            ", "print", "(", "\n", "\"Exporting performed in\"", ",", "\n", "durations_in_seconds", "[", "\"export_files\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "", "", "if", "return_dict", ":", "\n", "        ", "return", "{", "\"export_dir\"", ":", "save_dir", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.predict.predict_fiftyone": [[654, 843], ["sahi.utils.import_utils.check_requirements", "dict", "create_fiftyone_dataset_from_coco_file", "time.time", "sahi.auto_model.AutoDetectionModel.from_pretrained", "AutoDetectionModel.from_pretrained.load_model", "fo.launch_app", "create_fiftyone_dataset_from_coco_file.evaluate_detections", "create_fiftyone_dataset_from_coco_file.count_values", "dataset.evaluate_detections.print_report", "create_fiftyone_dataset_from_coco_file.load_evaluation_view", "dataset.load_evaluation_view.sort_by", "ValueError", "time.time", "fo.ProgressBar", "pb", "print", "print", "print", "sorted", "time.sleep", "fo.Detections", "sample.save", "predict.get_sliced_prediction", "predict.get_prediction", "get_prediction.to_fiftyone_detections"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.to_fiftyone_detections"], ["", "", "@", "check_requirements", "(", "[", "\"fiftyone\"", "]", ")", "\n", "def", "predict_fiftyone", "(", "\n", "model_type", ":", "str", "=", "\"mmdet\"", ",", "\n", "model_path", ":", "str", "=", "None", ",", "\n", "model_config_path", ":", "str", "=", "None", ",", "\n", "model_confidence_threshold", ":", "float", "=", "0.25", ",", "\n", "model_device", ":", "str", "=", "None", ",", "\n", "model_category_mapping", ":", "dict", "=", "None", ",", "\n", "model_category_remapping", ":", "dict", "=", "None", ",", "\n", "dataset_json_path", ":", "str", "=", "None", ",", "\n", "image_dir", ":", "str", "=", "None", ",", "\n", "no_standard_prediction", ":", "bool", "=", "False", ",", "\n", "no_sliced_prediction", ":", "bool", "=", "False", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", "slice_height", ":", "int", "=", "256", ",", "\n", "slice_width", ":", "int", "=", "256", ",", "\n", "overlap_height_ratio", ":", "float", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "float", "=", "0.2", ",", "\n", "postprocess_type", ":", "str", "=", "\"GREEDYNMM\"", ",", "\n", "postprocess_match_metric", ":", "str", "=", "\"IOS\"", ",", "\n", "postprocess_match_threshold", ":", "float", "=", "0.5", ",", "\n", "postprocess_class_agnostic", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Performs prediction for all present images in given folder.\n\n    Args:\n        model_type: str\n            mmdet for 'MmdetDetectionModel', 'yolov5' for 'Yolov5DetectionModel'.\n        model_path: str\n            Path for the model weight\n        model_config_path: str\n            Path for the detection model config file\n        model_confidence_threshold: float\n            All predictions with score < model_confidence_threshold will be discarded.\n        model_device: str\n            Torch device, \"cpu\" or \"cuda\"\n        model_category_mapping: dict\n            Mapping from category id (str) to category name (str) e.g. {\"1\": \"pedestrian\"}\n        model_category_remapping: dict: str to int\n            Remap category ids after performing inference\n        dataset_json_path: str\n            If coco file path is provided, detection results will be exported in coco json format.\n        image_dir: str\n            Folder directory that contains images or path of the image to be predicted.\n        no_standard_prediction: bool\n            Dont perform standard prediction. Default: False.\n        no_sliced_prediction: bool\n            Dont perform sliced prediction. Default: False.\n        image_size: int\n            Input image size for each inference (image is scaled by preserving asp. rat.).\n        slice_height: int\n            Height of each slice.  Defaults to ``256``.\n        slice_width: int\n            Width of each slice.  Defaults to ``256``.\n        overlap_height_ratio: float\n            Fractional overlap in height of each window (e.g. an overlap of 0.2 for a window\n            of size 256 yields an overlap of 51 pixels).\n            Default to ``0.2``.\n        overlap_width_ratio: float\n            Fractional overlap in width of each window (e.g. an overlap of 0.2 for a window\n            of size 256 yields an overlap of 51 pixels).\n            Default to ``0.2``.\n        postprocess_type: str\n            Type of the postprocess to be used after sliced inference while merging/eliminating predictions.\n            Options are 'NMM', 'GRREDYNMM' or 'NMS'. Default is 'GRREDYNMM'.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_threshold: float\n            Sliced predictions having higher iou than postprocess_match_threshold will be\n            postprocessed after sliced prediction.\n        postprocess_class_agnostic: bool\n            If True, postprocess will ignore category ids.\n        verbose: int\n            0: no print\n            1: print slice/prediction durations, number of slices, model loading/file exporting durations\n    \"\"\"", "\n", "from", "sahi", ".", "utils", ".", "fiftyone", "import", "create_fiftyone_dataset_from_coco_file", ",", "fo", "\n", "\n", "# assert prediction type", "\n", "if", "no_standard_prediction", "and", "no_sliced_prediction", ":", "\n", "        ", "raise", "ValueError", "(", "\"'no_standard_pred' and 'no_sliced_prediction' cannot be True at the same time.\"", ")", "\n", "# for profiling", "\n", "", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "dataset", "=", "create_fiftyone_dataset_from_coco_file", "(", "image_dir", ",", "dataset_json_path", ")", "\n", "\n", "# init model instance", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "detection_model", "=", "AutoDetectionModel", ".", "from_pretrained", "(", "\n", "model_type", "=", "model_type", ",", "\n", "model_path", "=", "model_path", ",", "\n", "config_path", "=", "model_config_path", ",", "\n", "confidence_threshold", "=", "model_confidence_threshold", ",", "\n", "device", "=", "model_device", ",", "\n", "category_mapping", "=", "model_category_mapping", ",", "\n", "category_remapping", "=", "model_category_remapping", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "image_size", ",", "\n", ")", "\n", "detection_model", ".", "load_model", "(", ")", "\n", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", "=", "time_end", "\n", "\n", "# iterate over source images", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "0", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "=", "0", "\n", "# Add predictions to samples", "\n", "with", "fo", ".", "ProgressBar", "(", ")", "as", "pb", ":", "\n", "        ", "for", "sample", "in", "pb", "(", "dataset", ")", ":", "\n", "# perform prediction", "\n", "            ", "if", "not", "no_sliced_prediction", ":", "\n", "# get sliced prediction", "\n", "                ", "prediction_result", "=", "get_sliced_prediction", "(", "\n", "image", "=", "sample", ".", "filepath", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "perform_standard_pred", "=", "not", "no_standard_prediction", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_threshold", "=", "postprocess_match_threshold", ",", "\n", "postprocess_match_metric", "=", "postprocess_match_metric", ",", "\n", "postprocess_class_agnostic", "=", "postprocess_class_agnostic", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"slice\"", "]", "\n", "", "else", ":", "\n", "# get standard prediction", "\n", "                ", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "sample", ".", "filepath", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", "=", "None", ",", "\n", "verbose", "=", "0", ",", "\n", ")", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"prediction\"", "]", "\n", "\n", "# Save predictions to dataset", "\n", "", "sample", "[", "model_type", "]", "=", "fo", ".", "Detections", "(", "detections", "=", "prediction_result", ".", "to_fiftyone_detections", "(", ")", ")", "\n", "sample", ".", "save", "(", ")", "\n", "\n", "# print prediction duration", "\n", "", "", "if", "verbose", "==", "1", ":", "\n", "        ", "print", "(", "\n", "\"Model loaded in\"", ",", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Slicing performed in\"", ",", "\n", "durations_in_seconds", "[", "\"slice\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "# visualize results", "\n", "", "session", "=", "fo", ".", "launch_app", "(", ")", "\n", "session", ".", "dataset", "=", "dataset", "\n", "# Evaluate the predictions", "\n", "results", "=", "dataset", ".", "evaluate_detections", "(", "\n", "model_type", ",", "\n", "gt_field", "=", "\"ground_truth\"", ",", "\n", "eval_key", "=", "\"eval\"", ",", "\n", "iou", "=", "postprocess_match_threshold", ",", "\n", "compute_mAP", "=", "True", ",", "\n", ")", "\n", "# Get the 10 most common classes in the dataset", "\n", "counts", "=", "dataset", ".", "count_values", "(", "\"ground_truth.detections.label\"", ")", "\n", "classes_top10", "=", "sorted", "(", "counts", ",", "key", "=", "counts", ".", "get", ",", "reverse", "=", "True", ")", "[", ":", "10", "]", "\n", "# Print a classification report for the top-10 classes", "\n", "results", ".", "print_report", "(", "classes", "=", "classes_top10", ")", "\n", "# Load the view on which we ran the `eval` evaluation", "\n", "eval_view", "=", "dataset", ".", "load_evaluation_view", "(", "\"eval\"", ")", "\n", "# Show samples with most false positives", "\n", "session", ".", "view", "=", "eval_view", ".", "sort_by", "(", "\"eval_fp\"", ",", "reverse", "=", "True", ")", "\n", "while", "1", ":", "\n", "        ", "time", ".", "sleep", "(", "3", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained": [[16, 74], ["sahi.utils.file.import_model_class", "sahi.utils.file.import_model_class."], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.import_model_class"], ["    ", "@", "staticmethod", "\n", "def", "from_pretrained", "(", "\n", "model_type", ":", "str", ",", "\n", "model_path", ":", "str", ",", "\n", "config_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "mask_threshold", ":", "float", "=", "0.5", ",", "\n", "confidence_threshold", ":", "float", "=", "0.3", ",", "\n", "category_mapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "category_remapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "load_at_init", ":", "bool", "=", "True", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Loads a DetectionModel from given path.\n\n        Args:\n            model_type: str\n                Name of the detection framework (example: \"yolov5\", \"mmdet\", \"detectron2\")\n            model_path: str\n                Path of the Layer model (ex. '/sahi/yolo/models/yolov5')\n            config_path: str\n                Path of the config file (ex. 'mmdet/configs/cascade_rcnn_r50_fpn_1x.py')\n            device: str\n                Device, \"cpu\" or \"cuda:0\"\n            mask_threshold: float\n                Value to threshold mask pixels, should be between 0 and 1\n            confidence_threshold: float\n                All predictions with score < confidence_threshold will be discarded\n            category_mapping: dict: str to str\n                Mapping from category id (str) to category name (str) e.g. {\"1\": \"pedestrian\"}\n            category_remapping: dict: str to int\n                Remap category ids based on category names, after performing inference e.g. {\"car\": 3}\n            load_at_init: bool\n                If True, automatically loads the model at initalization\n            image_size: int\n                Inference input size.\n        Returns:\n            Returns an instance of a DetectionModel\n        Raises:\n            ImportError: If given {model_type} framework is not installed\n        \"\"\"", "\n", "\n", "model_class_name", "=", "MODEL_TYPE_TO_MODEL_CLASS_NAME", "[", "model_type", "]", "\n", "DetectionModel", "=", "import_model_class", "(", "model_class_name", ")", "\n", "\n", "return", "DetectionModel", "(", "\n", "model_path", "=", "model_path", ",", "\n", "config_path", "=", "config_path", ",", "\n", "device", "=", "device", ",", "\n", "mask_threshold", "=", "mask_threshold", ",", "\n", "confidence_threshold", "=", "confidence_threshold", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "category_remapping", "=", "category_remapping", ",", "\n", "load_at_init", "=", "load_at_init", ",", "\n", "image_size", "=", "image_size", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_layer": [[76, 134], ["sahi.utils.import_utils.check_requirements", "layer.get_model().get_train", "sahi.utils.file.import_model_class", "sahi.utils.file.import_model_class.", "Exception", "layer.get_model", "type"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.utils.file.import_model_class"], ["", "@", "staticmethod", "\n", "@", "check_requirements", "(", "[", "\"layer\"", "]", ")", "\n", "def", "from_layer", "(", "\n", "model_path", ":", "str", ",", "\n", "no_cache", ":", "bool", "=", "False", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "mask_threshold", ":", "float", "=", "0.5", ",", "\n", "confidence_threshold", ":", "float", "=", "0.3", ",", "\n", "category_mapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "category_remapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Loads a DetectionModel from Layer. You can pass additional parameters in the name to retrieve a specific version\n        of the model with format: ``model_path:major_version.minor_version``\n        By default, this function caches models locally when possible.\n        Args:\n            model_path: str\n                Path of the Layer model (ex. '/sahi/yolo/models/yolov5')\n            no_cache: bool\n                If True, force model fetch from the remote location.\n            device: str\n                Device, \"cpu\" or \"cuda:0\"\n            mask_threshold: float\n                Value to threshold mask pixels, should be between 0 and 1\n            confidence_threshold: float\n                All predictions with score < confidence_threshold will be discarded\n            category_mapping: dict: str to str\n                Mapping from category id (str) to category name (str) e.g. {\"1\": \"pedestrian\"}\n            category_remapping: dict: str to int\n                Remap category ids based on category names, after performing inference e.g. {\"car\": 3}\n            image_size: int\n                Inference input size.\n        Returns:\n            Returns an instance of a DetectionModel\n        Raises:\n            ImportError: If Layer is not installed in your environment\n            ValueError: If model path does not match expected pattern: organization_name/project_name/models/model_name\n        \"\"\"", "\n", "import", "layer", "\n", "\n", "layer_model", "=", "layer", ".", "get_model", "(", "name", "=", "model_path", ",", "no_cache", "=", "no_cache", ")", ".", "get_train", "(", ")", "\n", "if", "layer_model", ".", "__class__", ".", "__module__", "in", "[", "\"yolov5.models.common\"", ",", "\"models.common\"", "]", ":", "\n", "            ", "model_type", "=", "\"yolov5\"", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"Unsupported model: {type(layer_model)}. Only YOLOv5 models are supported.\"", ")", "\n", "\n", "", "model_class_name", "=", "MODEL_TYPE_TO_MODEL_CLASS_NAME", "[", "model_type", "]", "\n", "DetectionModel", "=", "import_model_class", "(", "model_class_name", ")", "\n", "\n", "return", "DetectionModel", "(", "\n", "model", "=", "layer_model", ",", "\n", "device", "=", "device", ",", "\n", "mask_threshold", "=", "mask_threshold", ",", "\n", "confidence_threshold", "=", "confidence_threshold", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "category_remapping", "=", "category_remapping", ",", "\n", "image_size", "=", "image_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionScore.__init__": [[17, 27], ["copy.deepcopy().tolist", "type", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["    ", "def", "__init__", "(", "self", ",", "value", ":", "float", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            score: prediction score between 0 and 1\n        \"\"\"", "\n", "# if score is a numpy object, convert it to python variable", "\n", "if", "type", "(", "value", ")", ".", "__module__", "==", "\"numpy\"", ":", "\n", "            ", "value", "=", "copy", ".", "deepcopy", "(", "value", ")", ".", "tolist", "(", ")", "\n", "# set score", "\n", "", "self", ".", "value", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionScore.is_greater_than_threshold": [[28, 33], ["None"], "methods", ["None"], ["", "def", "is_greater_than_threshold", "(", "self", ",", "threshold", ")", ":", "\n", "        ", "\"\"\"\n        Check if score is greater than threshold\n        \"\"\"", "\n", "return", "self", ".", "value", ">", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionScore.__repr__": [[34, 36], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"PredictionScore: <value: {self.value}>\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.__init__": [[43, 82], ["prediction.PredictionScore", "sahi.annotation.ObjectAnnotation.__init__"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "bbox", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "category_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "category_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "bool_mask", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "score", ":", "Optional", "[", "float", "]", "=", "0", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates ObjectPrediction from bbox, score, category_id, category_name, bool_mask.\n\n        Arguments:\n            bbox: list\n                [minx, miny, maxx, maxy]\n            score: float\n                Prediction score between 0 and 1\n            category_id: int\n                ID of the object category\n            category_name: str\n                Name of the object category\n            bool_mask: np.ndarray\n                2D boolean mask array. Should be None if model doesn't output segmentation mask.\n            shift_amount: list\n                To shift the box and mask predictions from sliced image\n                to full sized image, should be in the form of [shift_x, shift_y]\n            full_shape: list\n                Size of the full image after shifting, should be in\n                the form of [height, width]\n        \"\"\"", "\n", "self", ".", "score", "=", "PredictionScore", "(", "score", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.get_shifted_object_prediction": [[84, 109], ["prediction.ObjectPrediction", "prediction.ObjectPrediction", "prediction.ObjectPrediction.bbox.get_shifted_box().to_voc_bbox", "prediction.ObjectPrediction.bbox.get_shifted_box().to_voc_bbox", "prediction.ObjectPrediction.mask.get_shifted_mask", "prediction.ObjectPrediction.mask.get_shifted_mask", "prediction.ObjectPrediction.bbox.get_shifted_box", "prediction.ObjectPrediction.bbox.get_shifted_box"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.get_shifted_mask", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.Mask.get_shifted_mask", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_shifted_box", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_shifted_box"], ["", "def", "get_shifted_object_prediction", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns shifted version ObjectPrediction.\n        Shifts bbox and mask coords.\n        Used for mapping sliced predictions over full image.\n        \"\"\"", "\n", "if", "self", ".", "mask", ":", "\n", "            ", "return", "ObjectPrediction", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "get_shifted_box", "(", ")", ".", "to_voc_bbox", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "score", "=", "self", ".", "score", ".", "value", ",", "\n", "bool_mask", "=", "self", ".", "mask", ".", "get_shifted_mask", "(", ")", ".", "bool_mask", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "self", ".", "mask", ".", "get_shifted_mask", "(", ")", ".", "full_shape", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "ObjectPrediction", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "get_shifted_box", "(", ")", ".", "to_voc_bbox", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "score", "=", "self", ".", "score", ".", "value", ",", "\n", "bool_mask", "=", "None", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.to_coco_prediction": [[111, 132], ["sahi.utils.coco.CocoPrediction.from_coco_segmentation", "sahi.utils.coco.CocoPrediction.from_coco_bbox", "prediction.ObjectPrediction.mask.to_coco_segmentation", "prediction.ObjectPrediction.bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "", "def", "to_coco_prediction", "(", "self", ",", "image_id", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns sahi.utils.coco.CocoPrediction representation of ObjectAnnotation.\n        \"\"\"", "\n", "if", "self", ".", "mask", ":", "\n", "            ", "coco_prediction", "=", "CocoPrediction", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "self", ".", "mask", ".", "to_coco_segmentation", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "score", "=", "self", ".", "score", ".", "value", ",", "\n", "image_id", "=", "image_id", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "coco_prediction", "=", "CocoPrediction", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "self", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", "category_id", "=", "self", ".", "category", ".", "id", ",", "\n", "category_name", "=", "self", ".", "category", ".", "name", ",", "\n", "score", "=", "self", ".", "score", ".", "value", ",", "\n", "image_id", "=", "image_id", ",", "\n", ")", "\n", "", "return", "coco_prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.to_fiftyone_detection": [[133, 146], ["prediction.ObjectPrediction.bbox.to_voc_bbox", "fo.Detection", "ImportError"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["", "def", "to_fiftyone_detection", "(", "self", ",", "image_height", ":", "int", ",", "image_width", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Returns fiftyone.Detection representation of ObjectPrediction.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "fiftyone", "as", "fo", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "'Please run \"pip install -U fiftyone\" to install fiftyone first for fiftyone conversion.'", ")", "\n", "\n", "", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "self", ".", "bbox", ".", "to_voc_bbox", "(", ")", "\n", "rel_box", "=", "[", "x1", "/", "image_width", ",", "y1", "/", "image_height", ",", "(", "x2", "-", "x1", ")", "/", "image_width", ",", "(", "y2", "-", "y1", ")", "/", "image_height", "]", "\n", "fiftyone_detection", "=", "fo", ".", "Detection", "(", "label", "=", "self", ".", "category", ".", "name", ",", "bounding_box", "=", "rel_box", ",", "confidence", "=", "self", ".", "score", ".", "value", ")", "\n", "return", "fiftyone_detection", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.__repr__": [[147, 153], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"ObjectPrediction<\n    bbox: {self.bbox},\n    mask: {self.mask},\n    score: {self.score},\n    category: {self.category}>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.__init__": [[156, 166], ["sahi.utils.cv.read_image_as_pil"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "object_prediction_list", ":", "List", "[", "ObjectPrediction", "]", ",", "\n", "image", ":", "Union", "[", "Image", ".", "Image", ",", "str", ",", "np", ".", "ndarray", "]", ",", "\n", "durations_in_seconds", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "image", ":", "Image", ".", "Image", "=", "read_image_as_pil", "(", "image", ")", "\n", "self", ".", "image_width", ",", "self", ".", "image_height", "=", "self", ".", "image", ".", "size", "\n", "self", ".", "object_prediction_list", ":", "List", "[", "ObjectPrediction", "]", "=", "object_prediction_list", "\n", "self", ".", "durations_in_seconds", "=", "durations_in_seconds", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.export_visuals": [[167, 191], ["sahi.utils.file.Path().mkdir", "sahi.utils.cv.visualize_object_predictions", "sahi.utils.file.Path", "numpy.ascontiguousarray"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions"], ["", "def", "export_visuals", "(", "\n", "self", ",", "export_dir", ":", "str", ",", "text_size", ":", "float", "=", "None", ",", "rect_th", ":", "int", "=", "None", ",", "file_name", ":", "str", "=", "\"prediction_visual\"", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            export_dir: directory for resulting visualization to be exported\n            text_size: size of the category name over box\n            rect_th: rectangle thickness\n            file_name: saving name\n        Returns:\n\n        \"\"\"", "\n", "Path", "(", "export_dir", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "visualize_object_predictions", "(", "\n", "image", "=", "np", ".", "ascontiguousarray", "(", "self", ".", "image", ")", ",", "\n", "object_prediction_list", "=", "self", ".", "object_prediction_list", ",", "\n", "rect_th", "=", "rect_th", ",", "\n", "text_size", "=", "text_size", ",", "\n", "text_th", "=", "None", ",", "\n", "color", "=", "None", ",", "\n", "output_dir", "=", "export_dir", ",", "\n", "file_name", "=", "file_name", ",", "\n", "export_format", "=", "\"png\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.to_coco_annotations": [[193, 198], ["coco_annotation_list.append", "object_prediction.to_coco_prediction"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.to_coco_prediction"], ["", "def", "to_coco_annotations", "(", "self", ")", ":", "\n", "        ", "coco_annotation_list", "=", "[", "]", "\n", "for", "object_prediction", "in", "self", ".", "object_prediction_list", ":", "\n", "            ", "coco_annotation_list", ".", "append", "(", "object_prediction", ".", "to_coco_prediction", "(", ")", ".", "json", ")", "\n", "", "return", "coco_annotation_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.to_coco_predictions": [[199, 204], ["coco_prediction_list.append", "object_prediction.to_coco_prediction"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.to_coco_prediction"], ["", "def", "to_coco_predictions", "(", "self", ",", "image_id", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "coco_prediction_list", "=", "[", "]", "\n", "for", "object_prediction", "in", "self", ".", "object_prediction_list", ":", "\n", "            ", "coco_prediction_list", ".", "append", "(", "object_prediction", ".", "to_coco_prediction", "(", "image_id", "=", "image_id", ")", ".", "json", ")", "\n", "", "return", "coco_prediction_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.to_imantics_annotations": [[205, 210], ["imantics_annotation_list.append", "object_prediction.to_imantics_annotation"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.to_imantics_annotation"], ["", "def", "to_imantics_annotations", "(", "self", ")", ":", "\n", "        ", "imantics_annotation_list", "=", "[", "]", "\n", "for", "object_prediction", "in", "self", ".", "object_prediction_list", ":", "\n", "            ", "imantics_annotation_list", ".", "append", "(", "object_prediction", ".", "to_imantics_annotation", "(", ")", ")", "\n", "", "return", "imantics_annotation_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.to_fiftyone_detections": [[211, 223], ["fiftyone_detection_list.append", "ImportError", "object_prediction.to_fiftyone_detection"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.to_fiftyone_detection"], ["", "def", "to_fiftyone_detections", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "fiftyone", "as", "fo", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "'Please run \"pip install -U fiftyone\" to install fiftyone first for fiftyone conversion.'", ")", "\n", "\n", "", "fiftyone_detection_list", ":", "List", "[", "fo", ".", "Detection", "]", "=", "[", "]", "\n", "for", "object_prediction", "in", "self", ".", "object_prediction_list", ":", "\n", "            ", "fiftyone_detection_list", ".", "append", "(", "\n", "object_prediction", ".", "to_fiftyone_detection", "(", "image_height", "=", "self", ".", "image_height", ",", "image_width", "=", "self", ".", "image_width", ")", "\n", ")", "\n", "", "return", "fiftyone_detection_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.__init__": [[21, 78], ["sahi.utils.torch.is_torch_cuda_available", "model.DetectionModel.set_model", "model.DetectionModel.load_model"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.torch.is_torch_cuda_available", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.set_model", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "model", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "config_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "mask_threshold", ":", "float", "=", "0.5", ",", "\n", "confidence_threshold", ":", "float", "=", "0.3", ",", "\n", "category_mapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "category_remapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "load_at_init", ":", "bool", "=", "True", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Init object detection/instance segmentation model.\n        Args:\n            model_path: str\n                Path for the instance segmentation model weight\n            config_path: str\n                Path for the mmdetection instance segmentation model config file\n            device: str\n                Torch device, \"cpu\" or \"cuda\"\n            mask_threshold: float\n                Value to threshold mask pixels, should be between 0 and 1\n            confidence_threshold: float\n                All predictions with score < confidence_threshold will be discarded\n            category_mapping: dict: str to str\n                Mapping from category id (str) to category name (str) e.g. {\"1\": \"pedestrian\"}\n            category_remapping: dict: str to int\n                Remap category ids based on category names, after performing inference e.g. {\"car\": 3}\n            load_at_init: bool\n                If True, automatically loads the model at initalization\n            image_size: int\n                Inference input size.\n        \"\"\"", "\n", "self", ".", "model_path", "=", "model_path", "\n", "self", ".", "config_path", "=", "config_path", "\n", "self", ".", "model", "=", "None", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "mask_threshold", "=", "mask_threshold", "\n", "self", ".", "confidence_threshold", "=", "confidence_threshold", "\n", "self", ".", "category_mapping", "=", "category_mapping", "\n", "self", ".", "category_remapping", "=", "category_remapping", "\n", "self", ".", "image_size", "=", "image_size", "\n", "self", ".", "_original_predictions", "=", "None", "\n", "self", ".", "_object_prediction_list_per_image", "=", "None", "\n", "\n", "# automatically set device if its None", "\n", "if", "not", "(", "self", ".", "device", ")", ":", "\n", "            ", "self", ".", "device", "=", "\"cuda:0\"", "if", "is_torch_cuda_available", "(", ")", "else", "\"cpu\"", "\n", "\n", "# automatically load model if load_at_init is True", "\n", "", "if", "load_at_init", ":", "\n", "            ", "if", "model", ":", "\n", "                ", "self", ".", "set_model", "(", "model", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "load_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.load_model": [[79, 86], ["NotImplementedError"], "methods", ["None"], ["", "", "", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function should be implemented in a way that detection model\n        should be initialized and set to self.model.\n        (self.model_path, self.config_path, and self.device should be utilized)\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.set_model": [[87, 95], ["NotImplementedError"], "methods", ["None"], ["", "def", "set_model", "(", "self", ",", "model", ":", "Any", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        This function should be implemented to instantiate a DetectionModel out of an already loaded model\n        Args:\n            model: Any\n                Loaded model\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.unload_model": [[96, 105], ["sahi.utils.import_utils.is_available", "empty_cuda_cache"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.is_available", "home.repos.pwc.inspect_result.obss_sahi.utils.torch.empty_cuda_cache"], ["", "def", "unload_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Unloads the model from CPU/GPU.\n        \"\"\"", "\n", "self", ".", "model", "=", "None", "\n", "if", "is_available", "(", "\"torch\"", ")", ":", "\n", "            ", "from", "sahi", ".", "utils", ".", "torch", "import", "empty_cuda_cache", "\n", "\n", "empty_cuda_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.perform_inference": [[106, 115], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "perform_inference", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        This function should be implemented in a way that prediction should be\n        performed using self.model and the prediction result should be set to self._original_predictions.\n        Args:\n            image: np.ndarray\n                A numpy array that contains the image to be predicted.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel._create_object_prediction_list_from_original_predictions": [[116, 134], ["NotImplementedError"], "methods", ["None"], ["", "def", "_create_object_prediction_list_from_original_predictions", "(", "\n", "self", ",", "\n", "shift_amount_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "[", "[", "0", ",", "0", "]", "]", ",", "\n", "full_shape_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        This function should be implemented in a way that self._original_predictions should\n        be converted to a list of prediction.ObjectPrediction and set to\n        self._object_prediction_list. self.mask_threshold can also be utilized.\n        Args:\n            shift_amount_list: list of list\n                To shift the box and mask predictions from sliced image to full sized image, should\n                be in the form of List[[shift_x, shift_y],[shift_x, shift_y],...]\n            full_shape_list: list of list\n                Size of the full image after shifting, should be in the form of\n                List[[height, width],[height, width],...]\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel._apply_category_remapping": [[135, 148], ["ValueError", "str"], "methods", ["None"], ["", "def", "_apply_category_remapping", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Applies category remapping based on mapping given in self.category_remapping\n        \"\"\"", "\n", "# confirm self.category_remapping is not None", "\n", "if", "self", ".", "category_remapping", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"self.category_remapping cannot be None\"", ")", "\n", "# remap categories", "\n", "", "for", "object_prediction_list", "in", "self", ".", "_object_prediction_list_per_image", ":", "\n", "            ", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "                ", "old_category_id_str", "=", "str", "(", "object_prediction", ".", "category", ".", "id", ")", "\n", "new_category_id_int", "=", "self", ".", "category_remapping", "[", "old_category_id_str", "]", "\n", "object_prediction", ".", "category", ".", "id", "=", "new_category_id_int", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions": [[149, 169], ["model.DetectionModel._create_object_prediction_list_from_original_predictions", "model.DetectionModel._apply_category_remapping"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel._create_object_prediction_list_from_original_predictions", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel._apply_category_remapping"], ["", "", "", "def", "convert_original_predictions", "(", "\n", "self", ",", "\n", "shift_amount", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Converts original predictions of the detection model to a list of\n        prediction.ObjectPrediction object. Should be called after perform_inference().\n        Args:\n            shift_amount: list\n                To shift the box and mask predictions from sliced image to full sized image, should be in the form of [shift_x, shift_y]\n            full_shape: list\n                Size of the full image after shifting, should be in the form of [height, width]\n        \"\"\"", "\n", "self", ".", "_create_object_prediction_list_from_original_predictions", "(", "\n", "shift_amount_list", "=", "shift_amount", ",", "\n", "full_shape_list", "=", "full_shape", ",", "\n", ")", "\n", "if", "self", ".", "category_remapping", ":", "\n", "            ", "self", ".", "_apply_category_remapping", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.object_prediction_list": [[170, 173], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "object_prediction_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_object_prediction_list_per_image", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.object_prediction_list_per_image": [[174, 177], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "object_prediction_list_per_image", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_object_prediction_list_per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.original_predictions": [[178, 181], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "original_predictions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_original_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.MmdetDetectionModel.load_model": [[185, 216], ["init_detector", "ImportError", "str", "enumerate"], "methods", ["None"], ["    ", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Detection model is initialized and set to self.model.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "mmdet", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please run \"pip install -U mmcv mmdet\" '", "\"to install MMDetection first for MMDetection inference.\"", "\n", ")", "\n", "\n", "", "from", "mmdet", ".", "apis", "import", "init_detector", "\n", "\n", "# create model", "\n", "model", "=", "init_detector", "(", "\n", "config", "=", "self", ".", "config_path", ",", "\n", "checkpoint", "=", "self", ".", "model_path", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# update model image size", "\n", "if", "self", ".", "image_size", "is", "not", "None", ":", "\n", "            ", "model", ".", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "1", "]", "[", "\"img_scale\"", "]", "=", "(", "self", ".", "image_size", ",", "self", ".", "image_size", ")", "\n", "\n", "# set self.model", "\n", "", "self", ".", "model", "=", "model", "\n", "\n", "# set category_mapping", "\n", "if", "not", "self", ".", "category_mapping", ":", "\n", "            ", "category_mapping", "=", "{", "str", "(", "ind", ")", ":", "category_name", "for", "ind", ",", "category_name", "in", "enumerate", "(", "self", ".", "category_names", ")", "}", "\n", "self", ".", "category_mapping", "=", "category_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.MmdetDetectionModel.perform_inference": [[217, 247], ["isinstance", "inference_detector", "ValueError", "isinstance", "ImportError"], "methods", ["None"], ["", "", "def", "perform_inference", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Prediction is performed using self.model and the prediction result is set to self._original_predictions.\n        Args:\n            image: np.ndarray\n                A numpy array that contains the image to be predicted. 3 channel image should be in RGB order.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "mmdet", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please run \"pip install -U mmcv mmdet\" '", "\"to install MMDetection first for MMDetection inference.\"", "\n", ")", "\n", "\n", "# Confirm model is loaded", "\n", "", "if", "self", ".", "model", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Model is not loaded, load it by calling .load_model()\"", ")", "\n", "# Supports only batch of 1", "\n", "", "from", "mmdet", ".", "apis", "import", "inference_detector", "\n", "\n", "# perform inference", "\n", "if", "isinstance", "(", "image", ",", "np", ".", "ndarray", ")", ":", "\n", "# https://github.com/obss/sahi/issues/265", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "# compatibility with sahi v0.8.15", "\n", "", "if", "not", "isinstance", "(", "image", ",", "list", ")", ":", "\n", "            ", "image", "=", "[", "image", "]", "\n", "", "prediction_result", "=", "inference_detector", "(", "self", ".", "model", ",", "image", ")", "\n", "\n", "self", ".", "_original_predictions", "=", "prediction_result", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.MmdetDetectionModel.num_categories": [[248, 258], ["isinstance", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_categories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns number of categories\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "model", ".", "CLASSES", ",", "str", ")", ":", "\n", "            ", "num_categories", "=", "1", "\n", "", "else", ":", "\n", "            ", "num_categories", "=", "len", "(", "self", ".", "model", ".", "CLASSES", ")", "\n", "", "return", "num_categories", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.MmdetDetectionModel.has_mask": [[259, 266], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns if model output contains segmentation mask\n        \"\"\"", "\n", "has_mask", "=", "self", ".", "model", ".", "with_mask", "\n", "return", "has_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.MmdetDetectionModel.category_names": [[267, 274], ["type"], "methods", ["None"], ["", "@", "property", "\n", "def", "category_names", "(", "self", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "model", ".", "CLASSES", ")", "==", "str", ":", "\n", "# https://github.com/open-mmlab/mmdetection/pull/4973", "\n", "            ", "return", "(", "self", ".", "model", ".", "CLASSES", ",", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "model", ".", "CLASSES", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.MmdetDetectionModel._create_object_prediction_list_from_original_predictions": [[275, 369], ["sahi.utils.compatibility.fix_shift_amount_list", "sahi.utils.compatibility.fix_full_shape_list", "enumerate", "range", "object_prediction_list_per_image.append", "len", "range", "max", "max", "max", "max", "sahi.prediction.ObjectPrediction", "object_prediction_list.append", "min", "min", "min", "min", "logger.warning", "str", "sahi.utils.cv.get_bbox_from_bool_mask"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_shift_amount_list", "home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_full_shape_list", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bbox_from_bool_mask"], ["", "", "def", "_create_object_prediction_list_from_original_predictions", "(", "\n", "self", ",", "\n", "shift_amount_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "[", "[", "0", ",", "0", "]", "]", ",", "\n", "full_shape_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        self._original_predictions is converted to a list of prediction.ObjectPrediction and set to\n        self._object_prediction_list_per_image.\n        Args:\n            shift_amount_list: list of list\n                To shift the box and mask predictions from sliced image to full sized image, should\n                be in the form of List[[shift_x, shift_y],[shift_x, shift_y],...]\n            full_shape_list: list of list\n                Size of the full image after shifting, should be in the form of\n                List[[height, width],[height, width],...]\n        \"\"\"", "\n", "original_predictions", "=", "self", ".", "_original_predictions", "\n", "category_mapping", "=", "self", ".", "category_mapping", "\n", "\n", "# compatilibty for sahi v0.8.15", "\n", "shift_amount_list", "=", "fix_shift_amount_list", "(", "shift_amount_list", ")", "\n", "full_shape_list", "=", "fix_full_shape_list", "(", "full_shape_list", ")", "\n", "\n", "# parse boxes and masks from predictions", "\n", "num_categories", "=", "self", ".", "num_categories", "\n", "object_prediction_list_per_image", "=", "[", "]", "\n", "for", "image_ind", ",", "original_prediction", "in", "enumerate", "(", "original_predictions", ")", ":", "\n", "            ", "shift_amount", "=", "shift_amount_list", "[", "image_ind", "]", "\n", "full_shape", "=", "None", "if", "full_shape_list", "is", "None", "else", "full_shape_list", "[", "image_ind", "]", "\n", "\n", "if", "self", ".", "has_mask", ":", "\n", "                ", "boxes", "=", "original_prediction", "[", "0", "]", "\n", "masks", "=", "original_prediction", "[", "1", "]", "\n", "", "else", ":", "\n", "                ", "boxes", "=", "original_prediction", "\n", "\n", "", "object_prediction_list", "=", "[", "]", "\n", "\n", "# process predictions", "\n", "for", "category_id", "in", "range", "(", "num_categories", ")", ":", "\n", "                ", "category_boxes", "=", "boxes", "[", "category_id", "]", "\n", "if", "self", ".", "has_mask", ":", "\n", "                    ", "category_masks", "=", "masks", "[", "category_id", "]", "\n", "", "num_category_predictions", "=", "len", "(", "category_boxes", ")", "\n", "\n", "for", "category_predictions_ind", "in", "range", "(", "num_category_predictions", ")", ":", "\n", "                    ", "bbox", "=", "category_boxes", "[", "category_predictions_ind", "]", "[", ":", "4", "]", "\n", "score", "=", "category_boxes", "[", "category_predictions_ind", "]", "[", "4", "]", "\n", "category_name", "=", "category_mapping", "[", "str", "(", "category_id", ")", "]", "\n", "\n", "# ignore low scored predictions", "\n", "if", "score", "<", "self", ".", "confidence_threshold", ":", "\n", "                        ", "continue", "\n", "\n", "# parse prediction mask", "\n", "", "if", "self", ".", "has_mask", ":", "\n", "                        ", "bool_mask", "=", "category_masks", "[", "category_predictions_ind", "]", "\n", "# check if mask is valid", "\n", "# https://github.com/obss/sahi/issues/389", "\n", "if", "get_bbox_from_bool_mask", "(", "bool_mask", ")", "is", "None", ":", "\n", "                            ", "continue", "\n", "", "", "else", ":", "\n", "                        ", "bool_mask", "=", "None", "\n", "\n", "# fix negative box coords", "\n", "", "bbox", "[", "0", "]", "=", "max", "(", "0", ",", "bbox", "[", "0", "]", ")", "\n", "bbox", "[", "1", "]", "=", "max", "(", "0", ",", "bbox", "[", "1", "]", ")", "\n", "bbox", "[", "2", "]", "=", "max", "(", "0", ",", "bbox", "[", "2", "]", ")", "\n", "bbox", "[", "3", "]", "=", "max", "(", "0", ",", "bbox", "[", "3", "]", ")", "\n", "\n", "# fix out of image box coords", "\n", "if", "full_shape", "is", "not", "None", ":", "\n", "                        ", "bbox", "[", "0", "]", "=", "min", "(", "full_shape", "[", "1", "]", ",", "bbox", "[", "0", "]", ")", "\n", "bbox", "[", "1", "]", "=", "min", "(", "full_shape", "[", "0", "]", ",", "bbox", "[", "1", "]", ")", "\n", "bbox", "[", "2", "]", "=", "min", "(", "full_shape", "[", "1", "]", ",", "bbox", "[", "2", "]", ")", "\n", "bbox", "[", "3", "]", "=", "min", "(", "full_shape", "[", "0", "]", ",", "bbox", "[", "3", "]", ")", "\n", "\n", "# ignore invalid predictions", "\n", "", "if", "not", "(", "bbox", "[", "0", "]", "<", "bbox", "[", "2", "]", ")", "or", "not", "(", "bbox", "[", "1", "]", "<", "bbox", "[", "3", "]", ")", ":", "\n", "                        ", "logger", ".", "warning", "(", "f\"ignoring invalid prediction with bbox: {bbox}\"", ")", "\n", "continue", "\n", "\n", "", "object_prediction", "=", "ObjectPrediction", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "score", "=", "score", ",", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "object_prediction_list", ".", "append", "(", "object_prediction", ")", "\n", "", "", "object_prediction_list_per_image", ".", "append", "(", "object_prediction_list", ")", "\n", "", "self", ".", "_object_prediction_list_per_image", "=", "object_prediction_list_per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Yolov5DetectionModel.load_model": [[373, 384], ["yolov5.load", "yolov5.load.Yolov5DetectionModel.set_model", "TypeError"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.set_model"], ["    ", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Detection model is initialized and set to self.model.\n        \"\"\"", "\n", "import", "yolov5", "\n", "\n", "try", ":", "\n", "            ", "model", "=", "yolov5", ".", "load", "(", "self", ".", "model_path", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "set_model", "(", "model", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "TypeError", "(", "\"model_path is not a valid yolov5 model path: \"", ",", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Yolov5DetectionModel.set_model": [[385, 403], ["Exception", "str", "enumerate", "type"], "methods", ["None"], ["", "", "def", "set_model", "(", "self", ",", "model", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        Sets the underlying YOLOv5 model.\n        Args:\n            model: Any\n                A YOLOv5 model\n        \"\"\"", "\n", "\n", "if", "model", ".", "__class__", ".", "__module__", "not", "in", "[", "\"yolov5.models.common\"", ",", "\"models.common\"", "]", ":", "\n", "            ", "raise", "Exception", "(", "f\"Not a yolov5 model: {type(model)}\"", ")", "\n", "\n", "", "model", ".", "conf", "=", "self", ".", "confidence_threshold", "\n", "self", ".", "model", "=", "model", "\n", "\n", "# set category_mapping", "\n", "if", "not", "self", ".", "category_mapping", ":", "\n", "            ", "category_mapping", "=", "{", "str", "(", "ind", ")", ":", "category_name", "for", "ind", ",", "category_name", "in", "enumerate", "(", "self", ".", "category_names", ")", "}", "\n", "self", ".", "category_mapping", "=", "category_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Yolov5DetectionModel.perform_inference": [[404, 421], ["ValueError", "model.Yolov5DetectionModel.model", "model.Yolov5DetectionModel.model"], "methods", ["None"], ["", "", "def", "perform_inference", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Prediction is performed using self.model and the prediction result is set to self._original_predictions.\n        Args:\n            image: np.ndarray\n                A numpy array that contains the image to be predicted. 3 channel image should be in RGB order.\n        \"\"\"", "\n", "\n", "# Confirm model is loaded", "\n", "if", "self", ".", "model", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Model is not loaded, load it by calling .load_model()\"", ")", "\n", "", "if", "self", ".", "image_size", "is", "not", "None", ":", "\n", "            ", "prediction_result", "=", "self", ".", "model", "(", "image", ",", "size", "=", "self", ".", "image_size", ")", "\n", "", "else", ":", "\n", "            ", "prediction_result", "=", "self", ".", "model", "(", "image", ")", "\n", "\n", "", "self", ".", "_original_predictions", "=", "prediction_result", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Yolov5DetectionModel.num_categories": [[422, 428], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_categories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns number of categories\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "model", ".", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Yolov5DetectionModel.has_mask": [[429, 436], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns if model output contains segmentation mask\n        \"\"\"", "\n", "has_mask", "=", "self", ".", "model", ".", "with_mask", "\n", "return", "has_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Yolov5DetectionModel.category_names": [[437, 440], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "category_names", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Yolov5DetectionModel._create_object_prediction_list_from_original_predictions": [[441, 512], ["sahi.utils.compatibility.fix_shift_amount_list", "sahi.utils.compatibility.fix_full_shape_list", "enumerate", "image_predictions_in_xyxy_format.cpu().detach().numpy", "object_prediction_list_per_image.append", "int", "int", "int", "int", "int", "max", "max", "max", "max", "sahi.prediction.ObjectPrediction", "object_prediction_list.append", "image_predictions_in_xyxy_format.cpu().detach", "min", "min", "min", "min", "logger.warning", "str", "image_predictions_in_xyxy_format.cpu"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_shift_amount_list", "home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_full_shape_list"], ["", "def", "_create_object_prediction_list_from_original_predictions", "(", "\n", "self", ",", "\n", "shift_amount_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "[", "[", "0", ",", "0", "]", "]", ",", "\n", "full_shape_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        self._original_predictions is converted to a list of prediction.ObjectPrediction and set to\n        self._object_prediction_list_per_image.\n        Args:\n            shift_amount_list: list of list\n                To shift the box and mask predictions from sliced image to full sized image, should\n                be in the form of List[[shift_x, shift_y],[shift_x, shift_y],...]\n            full_shape_list: list of list\n                Size of the full image after shifting, should be in the form of\n                List[[height, width],[height, width],...]\n        \"\"\"", "\n", "original_predictions", "=", "self", ".", "_original_predictions", "\n", "\n", "# compatilibty for sahi v0.8.15", "\n", "shift_amount_list", "=", "fix_shift_amount_list", "(", "shift_amount_list", ")", "\n", "full_shape_list", "=", "fix_full_shape_list", "(", "full_shape_list", ")", "\n", "\n", "# handle all predictions", "\n", "object_prediction_list_per_image", "=", "[", "]", "\n", "for", "image_ind", ",", "image_predictions_in_xyxy_format", "in", "enumerate", "(", "original_predictions", ".", "xyxy", ")", ":", "\n", "            ", "shift_amount", "=", "shift_amount_list", "[", "image_ind", "]", "\n", "full_shape", "=", "None", "if", "full_shape_list", "is", "None", "else", "full_shape_list", "[", "image_ind", "]", "\n", "object_prediction_list", "=", "[", "]", "\n", "\n", "# process predictions", "\n", "for", "prediction", "in", "image_predictions_in_xyxy_format", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ":", "\n", "                ", "x1", "=", "int", "(", "prediction", "[", "0", "]", ")", "\n", "y1", "=", "int", "(", "prediction", "[", "1", "]", ")", "\n", "x2", "=", "int", "(", "prediction", "[", "2", "]", ")", "\n", "y2", "=", "int", "(", "prediction", "[", "3", "]", ")", "\n", "bbox", "=", "[", "x1", ",", "y1", ",", "x2", ",", "y2", "]", "\n", "score", "=", "prediction", "[", "4", "]", "\n", "category_id", "=", "int", "(", "prediction", "[", "5", "]", ")", "\n", "category_name", "=", "self", ".", "category_mapping", "[", "str", "(", "category_id", ")", "]", "\n", "\n", "# fix negative box coords", "\n", "bbox", "[", "0", "]", "=", "max", "(", "0", ",", "bbox", "[", "0", "]", ")", "\n", "bbox", "[", "1", "]", "=", "max", "(", "0", ",", "bbox", "[", "1", "]", ")", "\n", "bbox", "[", "2", "]", "=", "max", "(", "0", ",", "bbox", "[", "2", "]", ")", "\n", "bbox", "[", "3", "]", "=", "max", "(", "0", ",", "bbox", "[", "3", "]", ")", "\n", "\n", "# fix out of image box coords", "\n", "if", "full_shape", "is", "not", "None", ":", "\n", "                    ", "bbox", "[", "0", "]", "=", "min", "(", "full_shape", "[", "1", "]", ",", "bbox", "[", "0", "]", ")", "\n", "bbox", "[", "1", "]", "=", "min", "(", "full_shape", "[", "0", "]", ",", "bbox", "[", "1", "]", ")", "\n", "bbox", "[", "2", "]", "=", "min", "(", "full_shape", "[", "1", "]", ",", "bbox", "[", "2", "]", ")", "\n", "bbox", "[", "3", "]", "=", "min", "(", "full_shape", "[", "0", "]", ",", "bbox", "[", "3", "]", ")", "\n", "\n", "# ignore invalid predictions", "\n", "", "if", "not", "(", "bbox", "[", "0", "]", "<", "bbox", "[", "2", "]", ")", "or", "not", "(", "bbox", "[", "1", "]", "<", "bbox", "[", "3", "]", ")", ":", "\n", "                    ", "logger", ".", "warning", "(", "f\"ignoring invalid prediction with bbox: {bbox}\"", ")", "\n", "continue", "\n", "\n", "", "object_prediction", "=", "ObjectPrediction", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "score", "=", "score", ",", "\n", "bool_mask", "=", "None", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "object_prediction_list", ".", "append", "(", "object_prediction", ")", "\n", "", "object_prediction_list_per_image", ".", "append", "(", "object_prediction_list", ")", "\n", "\n", "", "self", ".", "_object_prediction_list_per_image", "=", "object_prediction_list_per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Detectron2DetectionModel.load_model": [[516, 567], ["get_cfg", "DefaultPredictor", "model_zoo.get_config_file", "get_cfg.merge_from_file", "model_zoo.get_checkpoint_url", "list", "print", "MetadataCatalog.get", "DefaultPredictor.Detectron2DetectionModel.category_mapping.values", "get_cfg.merge_from_file", "str", "logger.warning", "enumerate", "str", "str", "range", "enumerate"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge_from_file", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge_from_file"], ["    ", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "from", "detectron2", ".", "config", "import", "get_cfg", "\n", "from", "detectron2", ".", "data", "import", "MetadataCatalog", "\n", "from", "detectron2", ".", "engine", "import", "DefaultPredictor", "\n", "from", "detectron2", ".", "model_zoo", "import", "model_zoo", "\n", "\n", "cfg", "=", "get_cfg", "(", ")", "\n", "\n", "try", ":", "# try to load from model zoo", "\n", "            ", "config_file", "=", "model_zoo", ".", "get_config_file", "(", "self", ".", "config_path", ")", "\n", "cfg", ".", "merge_from_file", "(", "config_file", ")", "\n", "cfg", ".", "MODEL", ".", "WEIGHTS", "=", "model_zoo", ".", "get_checkpoint_url", "(", "self", ".", "config_path", ")", "\n", "", "except", "Exception", "as", "e", ":", "# try to load from local", "\n", "            ", "print", "(", "e", ")", "\n", "if", "self", ".", "config_path", "is", "not", "None", ":", "\n", "                ", "cfg", ".", "merge_from_file", "(", "self", ".", "config_path", ")", "\n", "", "cfg", ".", "MODEL", ".", "WEIGHTS", "=", "self", ".", "model_path", "\n", "\n", "# set model device", "\n", "", "cfg", ".", "MODEL", ".", "DEVICE", "=", "self", ".", "device", "\n", "# set input image size", "\n", "if", "self", ".", "image_size", "is", "not", "None", ":", "\n", "            ", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", "=", "self", ".", "image_size", "\n", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", "=", "self", ".", "image_size", "\n", "# init predictor", "\n", "", "model", "=", "DefaultPredictor", "(", "cfg", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "\n", "# detectron2 category mapping", "\n", "if", "self", ".", "category_mapping", "is", "None", ":", "\n", "            ", "try", ":", "# try to parse category names from metadata", "\n", "                ", "metadata", "=", "MetadataCatalog", ".", "get", "(", "cfg", ".", "DATASETS", ".", "TRAIN", "[", "0", "]", ")", "\n", "category_names", "=", "metadata", ".", "thing_classes", "\n", "self", ".", "category_names", "=", "category_names", "\n", "self", ".", "category_mapping", "=", "{", "\n", "str", "(", "ind", ")", ":", "category_name", "for", "ind", ",", "category_name", "in", "enumerate", "(", "self", ".", "category_names", ")", "\n", "}", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "logger", ".", "warning", "(", "e", ")", "\n", "# https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#update-the-config-for-new-datasets", "\n", "if", "cfg", ".", "MODEL", ".", "META_ARCHITECTURE", "==", "\"RetinaNet\"", ":", "\n", "                    ", "num_categories", "=", "cfg", ".", "MODEL", ".", "RETINANET", ".", "NUM_CLASSES", "\n", "", "else", ":", "# fasterrcnn/maskrcnn etc", "\n", "                    ", "num_categories", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", "\n", "", "self", ".", "category_names", "=", "[", "str", "(", "category_id", ")", "for", "category_id", "in", "range", "(", "num_categories", ")", "]", "\n", "self", ".", "category_mapping", "=", "{", "\n", "str", "(", "ind", ")", ":", "category_name", "for", "ind", ",", "category_name", "in", "enumerate", "(", "self", ".", "category_names", ")", "\n", "}", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "category_names", "=", "list", "(", "self", ".", "category_mapping", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Detectron2DetectionModel.perform_inference": [[568, 587], ["model.Detectron2DetectionModel.model", "RuntimeError", "isinstance"], "methods", ["None"], ["", "", "def", "perform_inference", "(", "self", ",", "image", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Prediction is performed using self.model and the prediction result is set to self._original_predictions.\n        Args:\n            image: np.ndarray\n                A numpy array that contains the image to be predicted. 3 channel image should be in RGB order.\n        \"\"\"", "\n", "\n", "# Confirm model is loaded", "\n", "if", "self", ".", "model", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Model is not loaded, load it by calling .load_model()\"", ")", "\n", "\n", "", "if", "isinstance", "(", "image", ",", "np", ".", "ndarray", ")", "and", "self", ".", "model", ".", "input_format", "==", "\"BGR\"", ":", "\n", "# convert RGB image to BGR format", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "", "prediction_result", "=", "self", ".", "model", "(", "image", ")", "\n", "\n", "self", ".", "_original_predictions", "=", "prediction_result", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Detectron2DetectionModel.num_categories": [[588, 595], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_categories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns number of categories\n        \"\"\"", "\n", "num_categories", "=", "len", "(", "self", ".", "category_mapping", ")", "\n", "return", "num_categories", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.Detectron2DetectionModel._create_object_prediction_list_from_original_predictions": [[596, 674], ["isinstance", "original_predictions[].pred_boxes.tensor.tolist", "original_predictions[].scores.tolist", "original_predictions[].pred_classes.tolist", "range", "isinstance", "original_predictions[].pred_masks.tolist", "len", "sahi.prediction.ObjectPrediction", "object_prediction_list.append", "numpy.array", "sahi.utils.cv.get_bbox_from_bool_mask", "str"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bbox_from_bool_mask"], ["", "def", "_create_object_prediction_list_from_original_predictions", "(", "\n", "self", ",", "\n", "shift_amount_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "[", "[", "0", ",", "0", "]", "]", ",", "\n", "full_shape_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        self._original_predictions is converted to a list of prediction.ObjectPrediction and set to\n        self._object_prediction_list_per_image.\n        Args:\n            shift_amount_list: list of list\n                To shift the box and mask predictions from sliced image to full sized image, should\n                be in the form of List[[shift_x, shift_y],[shift_x, shift_y],...]\n            full_shape_list: list of list\n                Size of the full image after shifting, should be in the form of\n                List[[height, width],[height, width],...]\n        \"\"\"", "\n", "original_predictions", "=", "self", ".", "_original_predictions", "\n", "\n", "# compatilibty for sahi v0.8.15", "\n", "if", "isinstance", "(", "shift_amount_list", "[", "0", "]", ",", "int", ")", ":", "\n", "            ", "shift_amount_list", "=", "[", "shift_amount_list", "]", "\n", "", "if", "full_shape_list", "is", "not", "None", "and", "isinstance", "(", "full_shape_list", "[", "0", "]", ",", "int", ")", ":", "\n", "            ", "full_shape_list", "=", "[", "full_shape_list", "]", "\n", "\n", "# parse boxes, masks, scores, category_ids from predictions", "\n", "", "boxes", "=", "original_predictions", "[", "\"instances\"", "]", ".", "pred_boxes", ".", "tensor", ".", "tolist", "(", ")", "\n", "scores", "=", "original_predictions", "[", "\"instances\"", "]", ".", "scores", ".", "tolist", "(", ")", "\n", "category_ids", "=", "original_predictions", "[", "\"instances\"", "]", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "\n", "# check if predictions contain mask", "\n", "try", ":", "\n", "            ", "masks", "=", "original_predictions", "[", "\"instances\"", "]", ".", "pred_masks", ".", "tolist", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "masks", "=", "None", "\n", "\n", "# create object_prediction_list", "\n", "", "object_prediction_list_per_image", "=", "[", "]", "\n", "object_prediction_list", "=", "[", "]", "\n", "\n", "# detectron2 DefaultPredictor supports single image", "\n", "shift_amount", "=", "shift_amount_list", "[", "0", "]", "\n", "full_shape", "=", "None", "if", "full_shape_list", "is", "None", "else", "full_shape_list", "[", "0", "]", "\n", "\n", "for", "ind", "in", "range", "(", "len", "(", "boxes", ")", ")", ":", "\n", "            ", "score", "=", "scores", "[", "ind", "]", "\n", "if", "score", "<", "self", ".", "confidence_threshold", ":", "\n", "                ", "continue", "\n", "\n", "", "category_id", "=", "category_ids", "[", "ind", "]", "\n", "\n", "if", "masks", "is", "None", ":", "\n", "                ", "bbox", "=", "boxes", "[", "ind", "]", "\n", "mask", "=", "None", "\n", "", "else", ":", "\n", "                ", "mask", "=", "np", ".", "array", "(", "masks", "[", "ind", "]", ")", "\n", "\n", "# check if mask is valid", "\n", "# https://github.com/obss/sahi/issues/389", "\n", "if", "get_bbox_from_bool_mask", "(", "mask", ")", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "bbox", "=", "None", "\n", "\n", "", "", "object_prediction", "=", "ObjectPrediction", "(", "\n", "bbox", "=", "bbox", ",", "\n", "bool_mask", "=", "mask", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "self", ".", "category_mapping", "[", "str", "(", "category_id", ")", "]", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "score", "=", "score", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "object_prediction_list", ".", "append", "(", "object_prediction", ")", "\n", "\n", "# detectron2 DefaultPredictor supports single image", "\n", "", "object_prediction_list_per_image", "=", "[", "object_prediction_list", "]", "\n", "\n", "self", ".", "_object_prediction_list_per_image", "=", "object_prediction_list_per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.__init__": [[680, 707], ["model.DetectionModel.__init__"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "model", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "feature_extractor", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "config_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "mask_threshold", ":", "float", "=", "0.5", ",", "\n", "confidence_threshold", ":", "float", "=", "0.3", ",", "\n", "category_mapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "category_remapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "load_at_init", ":", "bool", "=", "True", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "_feature_extractor", "=", "feature_extractor", "\n", "self", ".", "_image_shapes", "=", "[", "]", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model_path", ",", "\n", "model", ",", "\n", "config_path", ",", "\n", "device", ",", "\n", "mask_threshold", ",", "\n", "confidence_threshold", ",", "\n", "category_mapping", ",", "\n", "category_remapping", ",", "\n", "load_at_init", ",", "\n", "image_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.feature_extractor": [[709, 712], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "feature_extractor", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_feature_extractor", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.image_shapes": [[713, 716], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shapes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_image_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.num_categories": [[717, 723], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_categories", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns number of categories\n        \"\"\"", "\n", "return", "self", ".", "model", ".", "config", ".", "num_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.load_model": [[724, 735], ["AutoModelForObjectDetection.from_pretrained", "AutoModelForObjectDetection.from_pretrained.HuggingfaceDetectionModel.set_model", "AutoFeatureExtractor.from_pretrained", "AutoFeatureExtractor.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.set_model", "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained", "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "from", "transformers", "import", "AutoFeatureExtractor", ",", "AutoModelForObjectDetection", "\n", "\n", "model", "=", "AutoModelForObjectDetection", ".", "from_pretrained", "(", "self", ".", "model_path", ")", "\n", "if", "self", ".", "image_size", "is", "not", "None", ":", "\n", "            ", "feature_extractor", "=", "AutoFeatureExtractor", ".", "from_pretrained", "(", "\n", "self", ".", "model_path", ",", "size", "=", "self", ".", "image_size", ",", "do_resize", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "            ", "feature_extractor", "=", "AutoFeatureExtractor", ".", "from_pretrained", "(", "self", ".", "model_path", ")", "\n", "", "self", ".", "set_model", "(", "model", ",", "feature_extractor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.set_model": [[736, 751], ["model.HuggingfaceDetectionModel.model.to", "ValueError", "ValueError"], "methods", ["None"], ["", "def", "set_model", "(", "self", ",", "model", ":", "Any", ",", "feature_extractor", ":", "Any", "=", "None", ")", ":", "\n", "        ", "feature_extractor", "=", "feature_extractor", "or", "self", ".", "feature_extractor", "\n", "if", "feature_extractor", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "f\"'feature_extractor' is required to be set, got {feature_extractor}.\"", ")", "\n", "", "elif", "(", "\n", "\"ObjectDetection\"", "not", "in", "model", ".", "__class__", ".", "__name__", "\n", "or", "\"FeatureExtractor\"", "not", "in", "feature_extractor", ".", "__class__", ".", "__name__", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Given 'model' is not an ObjectDetectionModel or 'feature_extractor' is not a valid FeatureExtractor.\"", "\n", ")", "\n", "", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "_feature_extractor", "=", "feature_extractor", "\n", "self", ".", "category_mapping", "=", "self", ".", "model", ".", "config", ".", "id2label", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.perform_inference": [[752, 777], ["isinstance", "RuntimeError", "torch.no_grad", "model.HuggingfaceDetectionModel.feature_extractor", "model.HuggingfaceDetectionModel.pixel_values.to", "hasattr", "model.HuggingfaceDetectionModel.model", "model.HuggingfaceDetectionModel.pixel_mask.to"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.feature_extractor"], ["", "def", "perform_inference", "(", "self", ",", "image", ":", "Union", "[", "List", ",", "np", ".", "ndarray", "]", ")", ":", "\n", "        ", "\"\"\"\n        Prediction is performed using self.model and the prediction result is set to self._original_predictions.\n        Args:\n            image: np.ndarray\n                A numpy array that contains the image to be predicted. 3 channel image should be in RGB order.\n        \"\"\"", "\n", "import", "torch", "\n", "\n", "# Confirm model is loaded", "\n", "if", "self", ".", "model", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Model is not loaded, load it by calling .load_model()\"", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "self", ".", "feature_extractor", "(", "images", "=", "image", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "inputs", "[", "\"pixel_values\"", "]", "=", "inputs", ".", "pixel_values", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "hasattr", "(", "inputs", ",", "\"pixel_mask\"", ")", ":", "\n", "                ", "inputs", "[", "\"pixel_mask\"", "]", "=", "inputs", ".", "pixel_mask", ".", "to", "(", "self", ".", "device", ")", "\n", "", "outputs", "=", "self", ".", "model", "(", "**", "inputs", ")", "\n", "\n", "", "if", "isinstance", "(", "image", ",", "list", ")", ":", "\n", "            ", "self", ".", "_image_shapes", "=", "[", "img", ".", "shape", "for", "img", "in", "image", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_image_shapes", "=", "[", "image", ".", "shape", "]", "\n", "", "self", ".", "_original_predictions", "=", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.get_valid_predictions": [[778, 793], ["logits.softmax", "logits.softmax.argmax", "torch.where", "torch.where", "torch.where.logical_and", "logits.softmax.max"], "methods", ["None"], ["", "def", "get_valid_predictions", "(", "\n", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "pred_boxes", ":", "torch", ".", "Tensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "import", "torch", "\n", "\n", "probs", "=", "logits", ".", "softmax", "(", "-", "1", ")", "\n", "scores", "=", "probs", ".", "max", "(", "-", "1", ")", ".", "values", "\n", "cat_ids", "=", "probs", ".", "argmax", "(", "-", "1", ")", "\n", "valid_detections", "=", "torch", ".", "where", "(", "cat_ids", "<", "self", ".", "num_categories", ",", "1", ",", "0", ")", "\n", "valid_confidences", "=", "torch", ".", "where", "(", "scores", ">=", "self", ".", "confidence_threshold", ",", "1", ",", "0", ")", "\n", "valid_mask", "=", "valid_detections", ".", "logical_and", "(", "valid_confidences", ")", "\n", "scores", "=", "scores", "[", "valid_mask", "]", "\n", "cat_ids", "=", "cat_ids", "[", "valid_mask", "]", "\n", "boxes", "=", "pred_boxes", "[", "valid_mask", "]", "\n", "return", "scores", ",", "cat_ids", ",", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel._create_object_prediction_list_from_original_predictions": [[794, 862], ["sahi.utils.compatibility.fix_shift_amount_list", "sahi.utils.compatibility.fix_full_shape_list", "range", "model.HuggingfaceDetectionModel.get_valid_predictions", "range", "object_prediction_list_per_image.append", "len", "cat_ids[].item", "boxes[].tolist", "list", "max", "max", "min", "min", "sahi.prediction.ObjectPrediction", "object_prediction_list.append", "pybboxes.convert_bbox", "int", "int", "scores[].item"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_shift_amount_list", "home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_full_shape_list", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.HuggingfaceDetectionModel.get_valid_predictions", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "_create_object_prediction_list_from_original_predictions", "(", "\n", "self", ",", "\n", "shift_amount_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "[", "[", "0", ",", "0", "]", "]", ",", "\n", "full_shape_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        self._original_predictions is converted to a list of prediction.ObjectPrediction and set to\n        self._object_prediction_list_per_image.\n        Args:\n            shift_amount_list: list of list\n                To shift the box and mask predictions from sliced image to full sized image, should\n                be in the form of List[[shift_x, shift_y],[shift_x, shift_y],...]\n            full_shape_list: list of list\n                Size of the full image after shifting, should be in the form of\n                List[[height, width],[height, width],...]\n        \"\"\"", "\n", "original_predictions", "=", "self", ".", "_original_predictions", "\n", "\n", "# compatilibty for sahi v0.8.15", "\n", "shift_amount_list", "=", "fix_shift_amount_list", "(", "shift_amount_list", ")", "\n", "full_shape_list", "=", "fix_full_shape_list", "(", "full_shape_list", ")", "\n", "\n", "n_image", "=", "original_predictions", ".", "logits", ".", "shape", "[", "0", "]", "\n", "object_prediction_list_per_image", "=", "[", "]", "\n", "for", "image_ind", "in", "range", "(", "n_image", ")", ":", "\n", "            ", "image_height", ",", "image_width", ",", "_", "=", "self", ".", "image_shapes", "[", "image_ind", "]", "\n", "scores", ",", "cat_ids", ",", "boxes", "=", "self", ".", "get_valid_predictions", "(", "\n", "logits", "=", "original_predictions", ".", "logits", "[", "image_ind", "]", ",", "pred_boxes", "=", "original_predictions", ".", "pred_boxes", "[", "image_ind", "]", "\n", ")", "\n", "\n", "# create object_prediction_list", "\n", "object_prediction_list", "=", "[", "]", "\n", "\n", "shift_amount", "=", "shift_amount_list", "[", "image_ind", "]", "\n", "full_shape", "=", "None", "if", "full_shape_list", "is", "None", "else", "full_shape_list", "[", "image_ind", "]", "\n", "\n", "for", "ind", "in", "range", "(", "len", "(", "boxes", ")", ")", ":", "\n", "                ", "category_id", "=", "cat_ids", "[", "ind", "]", ".", "item", "(", ")", "\n", "yolo_bbox", "=", "boxes", "[", "ind", "]", ".", "tolist", "(", ")", "\n", "bbox", "=", "list", "(", "\n", "pbf", ".", "convert_bbox", "(", "\n", "yolo_bbox", ",", "\n", "from_type", "=", "\"yolo\"", ",", "\n", "to_type", "=", "\"voc\"", ",", "\n", "image_size", "=", "(", "image_width", ",", "image_height", ")", ",", "\n", "return_values", "=", "True", ",", "\n", ")", "\n", ")", "\n", "\n", "# fix negative box coords", "\n", "bbox", "[", "0", "]", "=", "max", "(", "0", ",", "int", "(", "bbox", "[", "0", "]", ")", ")", "\n", "bbox", "[", "1", "]", "=", "max", "(", "0", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", "\n", "bbox", "[", "2", "]", "=", "min", "(", "bbox", "[", "2", "]", ",", "image_width", ")", "\n", "bbox", "[", "3", "]", "=", "min", "(", "bbox", "[", "3", "]", ",", "image_height", ")", "\n", "\n", "object_prediction", "=", "ObjectPrediction", "(", "\n", "bbox", "=", "bbox", ",", "\n", "bool_mask", "=", "None", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "self", ".", "category_mapping", "[", "category_id", "]", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "score", "=", "scores", "[", "ind", "]", ".", "item", "(", ")", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "object_prediction_list", ".", "append", "(", "object_prediction", ")", "\n", "", "object_prediction_list_per_image", ".", "append", "(", "object_prediction_list", ")", "\n", "\n", "", "self", ".", "_object_prediction_list_per_image", "=", "object_prediction_list_per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.__init__": [[866, 891], ["model.DetectionModel.__init__"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "model", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "config_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "mask_threshold", ":", "float", "=", "0.5", ",", "\n", "confidence_threshold", ":", "float", "=", "0.3", ",", "\n", "category_mapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "category_remapping", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "load_at_init", ":", "bool", "=", "True", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "model_path", "=", "model_path", ",", "\n", "model", "=", "model", ",", "\n", "config_path", "=", "config_path", ",", "\n", "device", "=", "device", ",", "\n", "mask_threshold", "=", "mask_threshold", ",", "\n", "confidence_threshold", "=", "confidence_threshold", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "category_remapping", "=", "category_remapping", ",", "\n", "load_at_init", "=", "load_at_init", ",", "\n", "image_size", "=", "image_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model": [[893, 935], ["model.TorchVisionDetectionModel.set_model", "yaml.safe_load.get", "yaml.safe_load.get", "logger.warning", "logger.warning", "logger.warning", "model.load_state_dict", "open", "torch.load", "TypeError", "yaml.safe_load", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.set_model"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "import", "torch", "\n", "\n", "from", "sahi", ".", "utils", ".", "torchvision", "import", "MODEL_NAME_TO_CONSTRUCTOR", "\n", "\n", "# read config params", "\n", "model_name", "=", "None", "\n", "num_classes", "=", "None", "\n", "if", "self", ".", "config_path", "is", "not", "None", ":", "\n", "            ", "import", "yaml", "\n", "\n", "with", "open", "(", "self", ".", "config_path", ",", "\"r\"", ")", "as", "stream", ":", "\n", "                ", "try", ":", "\n", "                    ", "config", "=", "yaml", ".", "safe_load", "(", "stream", ")", "\n", "", "except", "yaml", ".", "YAMLError", "as", "exc", ":", "\n", "                    ", "raise", "RuntimeError", "(", "exc", ")", "\n", "\n", "", "", "model_name", "=", "config", ".", "get", "(", "\"model_name\"", ",", "None", ")", "\n", "num_classes", "=", "config", ".", "get", "(", "\"num_classes\"", ",", "None", ")", "\n", "\n", "# complete params if not provided in config", "\n", "", "if", "not", "model_name", ":", "\n", "            ", "model_name", "=", "\"fasterrcnn_resnet50_fpn\"", "\n", "logger", ".", "warning", "(", "f\"model_name not provided in config, using default model_type: {model_name}'\"", ")", "\n", "", "if", "num_classes", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"num_classes not provided in config, using default num_classes: 91\"", ")", "\n", "num_classes", "=", "91", "\n", "", "if", "self", ".", "model_path", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"model_path not provided in config, using pretrained weights and default num_classes: 91.\"", ")", "\n", "pretrained", "=", "True", "\n", "num_classes", "=", "91", "\n", "", "else", ":", "\n", "            ", "pretrained", "=", "False", "\n", "\n", "# load model", "\n", "", "model", "=", "MODEL_NAME_TO_CONSTRUCTOR", "[", "model_name", "]", "(", "num_classes", "=", "num_classes", ",", "pretrained", "=", "pretrained", ")", "\n", "try", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "model_path", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "TypeError", "(", "\"model_path is not a valid torchvision model path: \"", ",", "e", ")", "\n", "\n", "", "self", ".", "set_model", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.set_model": [[936, 953], ["model.eval", "model.to", "str", "range", "len"], "methods", ["None"], ["", "def", "set_model", "(", "self", ",", "model", ":", "Any", ")", ":", "\n", "        ", "\"\"\"\n        Sets the underlying TorchVision model.\n        Args:\n            model: Any\n                A TorchVision model\n        \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "self", ".", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# set category_mapping", "\n", "from", "sahi", ".", "utils", ".", "torchvision", "import", "COCO_CLASSES", "\n", "\n", "if", "self", ".", "category_mapping", "is", "None", ":", "\n", "            ", "category_names", "=", "{", "str", "(", "i", ")", ":", "COCO_CLASSES", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "COCO_CLASSES", ")", ")", "}", "\n", "self", ".", "category_mapping", "=", "category_names", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference": [[954, 980], ["to_float_tensor", "image.to.to.to", "model.TorchVisionDetectionModel.model", "min", "max"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.torch.to_float_tensor"], ["", "", "def", "perform_inference", "(", "self", ",", "image", ":", "np", ".", "ndarray", ",", "image_size", ":", "int", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Prediction is performed using self.model and the prediction result is set to self._original_predictions.\n        Args:\n            image: np.ndarray\n                A numpy array that contains the image to be predicted. 3 channel image should be in RGB order.\n            image_size: int\n                Inference input size.\n        \"\"\"", "\n", "from", "sahi", ".", "utils", ".", "torch", "import", "to_float_tensor", "\n", "\n", "# arrange model input size", "\n", "if", "self", ".", "image_size", "is", "not", "None", ":", "\n", "# get min and max of image height and width", "\n", "            ", "min_shape", ",", "max_shape", "=", "min", "(", "image", ".", "shape", "[", ":", "2", "]", ")", ",", "max", "(", "image", ".", "shape", "[", ":", "2", "]", ")", "\n", "# torchvision resize transform scales the shorter dimension to the target size", "\n", "# we want to scale the longer dimension to the target size", "\n", "image_size", "=", "self", ".", "image_size", "*", "min_shape", "/", "max_shape", "\n", "self", ".", "model", ".", "transform", ".", "min_size", "=", "(", "image_size", ",", ")", "# default is (800,)", "\n", "self", ".", "model", ".", "transform", ".", "max_size", "=", "image_size", "# default is 1333", "\n", "\n", "", "image", "=", "to_float_tensor", "(", "image", ")", "\n", "image", "=", "image", ".", "to", "(", "self", ".", "device", ")", "\n", "prediction_result", "=", "self", ".", "model", "(", "[", "image", "]", ")", "\n", "\n", "self", ".", "_original_predictions", "=", "prediction_result", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.num_categories": [[981, 987], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_categories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns number of categories\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "category_mapping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.has_mask": [[988, 994], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns if model output contains segmentation mask\n        \"\"\"", "\n", "return", "self", ".", "model", ".", "with_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.category_names": [[995, 998], ["list", "model.TorchVisionDetectionModel.category_mapping.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "category_names", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "category_mapping", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel._create_object_prediction_list_from_original_predictions": [[999, 1068], ["isinstance", "isinstance", "image_predictions[].cpu().detach().numpy", "list", "list", "image_predictions.get", "range", "object_prediction_list_per_image.append", "numpy.where", "[].cpu().detach().numpy", "[].cpu().detach().numpy", "list", "len", "sahi.prediction.ObjectPrediction", "object_prediction_list.append", "image_predictions[].cpu().detach", "[].cpu().detach().numpy", "numpy.array", "[].cpu().detach", "[].cpu().detach", "int", "image_predictions[].cpu", "[].cpu().detach", "[].cpu", "[].cpu", "str", "[].cpu", "int"], "methods", ["None"], ["", "def", "_create_object_prediction_list_from_original_predictions", "(", "\n", "self", ",", "\n", "shift_amount_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "[", "[", "0", ",", "0", "]", "]", ",", "\n", "full_shape_list", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        self._original_predictions is converted to a list of prediction.ObjectPrediction and set to\n        self._object_prediction_list_per_image.\n        Args:\n            shift_amount_list: list of list\n                To shift the box and mask predictions from sliced image to full sized image, should\n                be in the form of List[[shift_x, shift_y],[shift_x, shift_y],...]\n            full_shape_list: list of list\n                Size of the full image after shifting, should be in the form of\n                List[[height, width],[height, width],...]\n        \"\"\"", "\n", "original_predictions", "=", "self", ".", "_original_predictions", "\n", "\n", "# compatilibty for sahi v0.8.20", "\n", "if", "isinstance", "(", "shift_amount_list", "[", "0", "]", ",", "int", ")", ":", "\n", "            ", "shift_amount_list", "=", "[", "shift_amount_list", "]", "\n", "", "if", "full_shape_list", "is", "not", "None", "and", "isinstance", "(", "full_shape_list", "[", "0", "]", ",", "int", ")", ":", "\n", "            ", "full_shape_list", "=", "[", "full_shape_list", "]", "\n", "\n", "", "for", "image_predictions", "in", "original_predictions", ":", "\n", "            ", "object_prediction_list_per_image", "=", "[", "]", "\n", "\n", "# get indices of boxes with score > confidence_threshold", "\n", "scores", "=", "image_predictions", "[", "\"scores\"", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "selected_indices", "=", "np", ".", "where", "(", "scores", ">", "self", ".", "confidence_threshold", ")", "[", "0", "]", "\n", "\n", "# parse boxes, masks, scores, category_ids from predictions", "\n", "category_ids", "=", "list", "(", "image_predictions", "[", "\"labels\"", "]", "[", "selected_indices", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "boxes", "=", "list", "(", "image_predictions", "[", "\"boxes\"", "]", "[", "selected_indices", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "scores", "=", "scores", "[", "selected_indices", "]", "\n", "\n", "# check if predictions contain mask", "\n", "masks", "=", "image_predictions", ".", "get", "(", "\"masks\"", ",", "None", ")", "\n", "if", "masks", "is", "not", "None", ":", "\n", "                ", "masks", "=", "list", "(", "image_predictions", "[", "\"masks\"", "]", "[", "selected_indices", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "masks", "=", "None", "\n", "\n", "# create object_prediction_list", "\n", "", "object_prediction_list", "=", "[", "]", "\n", "\n", "shift_amount", "=", "shift_amount_list", "[", "0", "]", "\n", "full_shape", "=", "None", "if", "full_shape_list", "is", "None", "else", "full_shape_list", "[", "0", "]", "\n", "\n", "for", "ind", "in", "range", "(", "len", "(", "boxes", ")", ")", ":", "\n", "\n", "                ", "if", "masks", "is", "not", "None", ":", "\n", "                    ", "mask", "=", "np", ".", "array", "(", "masks", "[", "ind", "]", ")", "\n", "", "else", ":", "\n", "                    ", "mask", "=", "None", "\n", "\n", "", "object_prediction", "=", "ObjectPrediction", "(", "\n", "bbox", "=", "boxes", "[", "ind", "]", ",", "\n", "bool_mask", "=", "mask", ",", "\n", "category_id", "=", "int", "(", "category_ids", "[", "ind", "]", ")", ",", "\n", "category_name", "=", "self", ".", "category_mapping", "[", "str", "(", "int", "(", "category_ids", "[", "ind", "]", ")", ")", "]", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "score", "=", "scores", "[", "ind", "]", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "object_prediction_list", ".", "append", "(", "object_prediction", ")", "\n", "", "object_prediction_list_per_image", ".", "append", "(", "object_prediction_list", ")", "\n", "\n", "", "self", ".", "_object_prediction_list_per_image", "=", "object_prediction_list_per_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotTextFile.__init__": [[18, 26], ["os.path.join", "os.path.exists", "os.makedirs"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "save_dir", ":", "str", "=", "\".\"", ",", "save_name", ":", "str", "=", "\"gt\"", ")", ":", "\n", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "\n", "", "self", ".", "out_file_name", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "save_name", "+", "\".txt\"", ")", "\n", "\n", "self", ".", "frame_number", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotTextFile.update": [[27, 63], ["open", "open.close", "str", "str", "str", "str", "str", "str", "open.write", "open.write", "int", "int"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "predictions", ":", "List", "[", "TrackedObject", "]", ",", "frame_number", ":", "int", "=", "None", ")", ":", "\n", "        ", "if", "frame_number", "is", "None", ":", "\n", "            ", "frame_number", "=", "self", ".", "frame_number", "\n", "", "\"\"\"\n        Write tracked object information in the output file (for this frame), in the format\n        frame_number, id, bb_left, bb_top, bb_width, bb_height, 1, -1, -1, -1\n        \"\"\"", "\n", "text_file", "=", "open", "(", "self", ".", "out_file_name", ",", "\"a+\"", ")", "\n", "\n", "for", "obj", "in", "predictions", ":", "\n", "            ", "frame_str", "=", "str", "(", "int", "(", "frame_number", ")", ")", "\n", "id_str", "=", "str", "(", "int", "(", "obj", ".", "id", ")", ")", "\n", "bb_left_str", "=", "str", "(", "(", "obj", ".", "estimate", "[", "0", ",", "0", "]", ")", ")", "\n", "bb_top_str", "=", "str", "(", "(", "obj", ".", "estimate", "[", "0", ",", "1", "]", ")", ")", "# [0,1]", "\n", "bb_width_str", "=", "str", "(", "(", "obj", ".", "estimate", "[", "1", ",", "0", "]", "-", "obj", ".", "estimate", "[", "0", ",", "0", "]", ")", ")", "\n", "bb_height_str", "=", "str", "(", "(", "obj", ".", "estimate", "[", "1", ",", "1", "]", "-", "obj", ".", "estimate", "[", "0", ",", "1", "]", ")", ")", "\n", "row_text_out", "=", "(", "\n", "frame_str", "\n", "+", "\",\"", "\n", "+", "id_str", "\n", "+", "\",\"", "\n", "+", "bb_left_str", "\n", "+", "\",\"", "\n", "+", "bb_top_str", "\n", "+", "\",\"", "\n", "+", "bb_width_str", "\n", "+", "\",\"", "\n", "+", "bb_height_str", "\n", "+", "\",1,-1,-1,-1\"", "\n", ")", "\n", "text_file", ".", "write", "(", "row_text_out", ")", "\n", "text_file", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "self", ".", "frame_number", "+=", "1", "\n", "\n", "text_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotAnnotation.__init__": [[70, 80], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "bbox", ":", "List", "[", "int", "]", ",", "track_id", ":", "Optional", "[", "int", "]", "=", "-", "1", ",", "score", ":", "Optional", "[", "float", "]", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            bbox (List[int]): [x_min, y_min, width, height]\n            track_id: (Optional[int]): track id of the annotation\n            score (Optional[float])\n        \"\"\"", "\n", "self", ".", "bbox", "=", "bbox", "\n", "self", ".", "track_id", "=", "track_id", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotFrame.__init__": [[84, 87], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "file_name", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "annotation_list", ":", "List", "[", "MotAnnotation", "]", "=", "[", "]", "\n", "self", ".", "file_name", "=", "file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotFrame.add_annotation": [[88, 92], ["mot.MotFrame.annotation_list.append", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "add_annotation", "(", "self", ",", "detection", ":", "MotAnnotation", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "detection", ",", "MotAnnotation", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"'detection' should be a MotAnnotation object.\"", ")", "\n", "", "self", ".", "annotation_list", ".", "append", "(", "detection", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotFrame.to_norfair_detections": [[93, 124], ["norfair_detections.append", "numpy.array", "Detection", "numpy.array", "numpy.array", "ValueError", "numpy.array"], "methods", ["None"], ["", "def", "to_norfair_detections", "(", "self", ",", "track_points", ":", "str", "=", "\"bbox\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            track_points (str): 'centroid' or 'bbox'. Defaults to 'bbox'.\n        \"\"\"", "\n", "from", "norfair", "import", "Detection", "\n", "\n", "norfair_detections", ":", "List", "[", "Detection", "]", "=", "[", "]", "\n", "# convert all detections to norfair detections", "\n", "for", "annotation", "in", "self", ".", "annotation_list", ":", "\n", "# calculate bbox points", "\n", "            ", "xmin", "=", "annotation", ".", "bbox", "[", "0", "]", "\n", "ymin", "=", "annotation", ".", "bbox", "[", "1", "]", "\n", "xmax", "=", "annotation", ".", "bbox", "[", "0", "]", "+", "annotation", ".", "bbox", "[", "2", "]", "\n", "ymax", "=", "annotation", ".", "bbox", "[", "1", "]", "+", "annotation", ".", "bbox", "[", "3", "]", "\n", "scores", "=", "None", "\n", "# calculate points as bbox or centroid", "\n", "if", "track_points", "==", "\"bbox\"", ":", "\n", "                ", "points", "=", "np", ".", "array", "(", "[", "[", "xmin", ",", "ymin", "]", ",", "[", "xmax", ",", "ymax", "]", "]", ")", "# bbox", "\n", "if", "annotation", ".", "score", "is", "not", "None", ":", "\n", "                    ", "scores", "=", "np", ".", "array", "(", "[", "annotation", ".", "score", ",", "annotation", ".", "score", "]", ")", "\n", "\n", "", "", "elif", "track_points", "==", "\"centroid\"", ":", "\n", "                ", "points", "=", "np", ".", "array", "(", "[", "(", "xmin", "+", "xmax", ")", "/", "2", ",", "(", "ymin", "+", "ymax", ")", "/", "2", "]", ")", "# centroid", "\n", "if", "annotation", ".", "score", "is", "not", "None", ":", "\n", "                    ", "scores", "=", "np", ".", "array", "(", "[", "annotation", ".", "score", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"'track_points' should be one of ['centroid', 'bbox'].\"", ")", "\n", "# create norfair formatted detection", "\n", "", "norfair_detections", ".", "append", "(", "Detection", "(", "points", "=", "points", ",", "scores", "=", "scores", ")", ")", "\n", "", "return", "norfair_detections", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotFrame.to_norfair_trackedobjects": [[125, 184], ["Tracker", "Detection", "TrackedObject", "tracked_object_list.append", "ValueError", "numpy.array", "numpy.ones", "numpy.array", "numpy.array", "ValueError", "numpy.array"], "methods", ["None"], ["", "def", "to_norfair_trackedobjects", "(", "self", ",", "track_points", ":", "str", "=", "\"bbox\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            track_points (str): 'centroid' or 'bbox'. Defaults to 'bbox'.\n        \"\"\"", "\n", "from", "norfair", "import", "Detection", ",", "Tracker", "\n", "from", "norfair", ".", "tracker", "import", "TrackedObject", "\n", "\n", "tracker", "=", "Tracker", "(", "\n", "distance_function", "=", "euclidean_distance", ",", "\n", "distance_threshold", "=", "30", ",", "\n", "detection_threshold", "=", "0", ",", "\n", "hit_counter_max", "=", "12", ",", "\n", "pointwise_hit_counter_max", "=", "4", ",", "\n", ")", "\n", "\n", "tracked_object_list", ":", "List", "[", "TrackedObject", "]", "=", "[", "]", "\n", "# convert all detections to norfair detections", "\n", "for", "annotation", "in", "self", ".", "annotation_list", ":", "\n", "# ensure annotation.track_id is not None", "\n", "            ", "if", "annotation", ".", "track_id", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"to_norfair_trackedobjects() requires annotation.track_id to be set.\"", ")", "\n", "# calculate bbox points", "\n", "", "xmin", "=", "annotation", ".", "bbox", "[", "0", "]", "\n", "ymin", "=", "annotation", ".", "bbox", "[", "1", "]", "\n", "xmax", "=", "annotation", ".", "bbox", "[", "0", "]", "+", "annotation", ".", "bbox", "[", "2", "]", "\n", "ymax", "=", "annotation", ".", "bbox", "[", "1", "]", "+", "annotation", ".", "bbox", "[", "3", "]", "\n", "track_id", "=", "annotation", ".", "track_id", "\n", "scores", "=", "None", "\n", "# calculate points as bbox or centroid", "\n", "if", "track_points", "==", "\"bbox\"", ":", "\n", "                ", "points", "=", "np", ".", "array", "(", "[", "[", "xmin", ",", "ymin", "]", ",", "[", "xmax", ",", "ymax", "]", "]", ")", "# bbox", "\n", "if", "annotation", ".", "score", "is", "not", "None", ":", "\n", "                    ", "scores", "=", "np", ".", "array", "(", "[", "annotation", ".", "score", ",", "annotation", ".", "score", "]", ")", "\n", "\n", "", "", "elif", "track_points", "==", "\"centroid\"", ":", "\n", "                ", "points", "=", "np", ".", "array", "(", "[", "(", "xmin", "+", "xmax", ")", "/", "2", ",", "(", "ymin", "+", "ymax", ")", "/", "2", "]", ")", "# centroid", "\n", "if", "annotation", ".", "score", "is", "not", "None", ":", "\n", "                    ", "scores", "=", "np", ".", "array", "(", "[", "annotation", ".", "score", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"'track_points' should be one of ['centroid', 'bbox'].\"", ")", "\n", "# create norfair formatted detection", "\n", "", "detection", "=", "Detection", "(", "points", "=", "points", ",", "scores", "=", "scores", ")", "\n", "# create trackedobject from norfair detection", "\n", "tracked_object", "=", "TrackedObject", "(", "\n", "detection", ",", "\n", "tracker", ".", "hit_counter_max", ",", "\n", "tracker", ".", "initialization_delay", ",", "\n", "pointwise_hit_counter_max", "=", "tracker", ".", "pointwise_hit_counter_max", ",", "\n", "detection_threshold", "=", "tracker", ".", "detection_threshold", ",", "\n", "period", "=", "1", ",", "\n", "filter_factory", "=", "tracker", ".", "filter_factory", ",", "\n", "past_detections_length", "=", "0", ",", "\n", ")", "\n", "tracked_object", ".", "id", "=", "track_id", "\n", "tracked_object", ".", "point_hit_counter", "=", "np", ".", "ones", "(", "tracked_object", ".", "num_points", ")", "*", "1", "\n", "# append to tracked_object_list", "\n", "tracked_object_list", ".", "append", "(", "tracked_object", ")", "\n", "", "return", "tracked_object_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.__init__": [[188, 218], ["dict"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "name", ":", "str", "=", "\"sequence_name\"", ",", "\n", "frame_rate", ":", "Optional", "[", "int", "]", "=", "30", ",", "\n", "image_height", ":", "int", "=", "720", ",", "\n", "image_width", ":", "int", "=", "1280", ",", "\n", "tracker_kwargs", ":", "Optional", "[", "Dict", "]", "=", "dict", "(", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            name (str): Name of the video file.\n            frame_rate (int): FPS of the video.\n            image_height (int): Frame height of the video.\n            image_width (int): Frame width of the video.\n            tracker_kwargs (dict): a dict contains the tracker keys as below:\n                - max_distance_between_points (int)\n                - min_detection_threshold (float)\n                - hit_inertia_min (int)\n                - hit_inertia_max (int)\n                - point_transience (int)\n                For details: https://github.com/tryolabs/norfair/tree/master/docs#arguments\n        \"\"\"", "\n", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "frame_rate", "=", "frame_rate", "\n", "self", ".", "image_height", "=", "image_height", "\n", "self", ".", "image_width", "=", "image_width", "\n", "self", ".", "tracker_kwargs", "=", "tracker_kwargs", "\n", "\n", "self", ".", "frame_list", ":", "List", "[", "MotFrame", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo._create_info_file": [[219, 239], ["filepath.parent.mkdir", "pathlib.Path", "open", "file.write", "file.write", "file.write", "file.write", "file.write", "file.write", "file.write", "str"], "methods", ["None"], ["", "def", "_create_info_file", "(", "self", ",", "seq_length", ":", "int", ",", "export_dir", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            seq_length (int): Number of frames present in video (seqLength parameter in seqinfo.ini)\n                For details: https://github.com/tryolabs/norfair/issues/42#issuecomment-819211873\n            export_dir (str): Folder directory that will contain exported file.\n        \"\"\"", "\n", "# set file path", "\n", "filepath", "=", "Path", "(", "export_dir", ")", "/", "\"seqinfo.ini\"", "\n", "# create folder directory if not exists", "\n", "filepath", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "# create seqinfo.ini file with seqLength", "\n", "with", "open", "(", "str", "(", "filepath", ")", ",", "\"w\"", ")", "as", "file", ":", "\n", "            ", "file", ".", "write", "(", "\"[Sequence]\\n\"", ")", "\n", "file", ".", "write", "(", "f\"name={self.name}\\n\"", ")", "\n", "file", ".", "write", "(", "f\"imDir=img1\\n\"", ")", "\n", "file", ".", "write", "(", "f\"frameRate={self.frame_rate}\\n\"", ")", "\n", "file", ".", "write", "(", "f\"seqLength={seq_length}\\n\"", ")", "\n", "file", ".", "write", "(", "f\"imWidth={self.image_width}\\n\"", ")", "\n", "file", ".", "write", "(", "f\"imHeight={self.image_height}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo._create_frame_symlinks": [[240, 284], ["img1.mkdir", "pathlib.Path", "os.path.isabs", "str", "os.symlink", "os.path.abspath", "isinstance", "TypeError", "print", "pathlib.Path", "str", "os.path.abspath", "str", "pathlib.Path", "print", "pathlib.Path().is_file", "ValueError", "pathlib.Path", "ValueError", "str", "pathlib.Path().is_file", "ValueError", "pathlib.Path", "str", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "type", "pathlib.Path", "pathlib.Path", "pathlib.Path", "len", "str", "str", "pathlib.Path"], "methods", ["None"], ["", "", "def", "_create_frame_symlinks", "(", "self", ",", "images_dir", ":", "str", ",", "export_dir", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            images_dir (str): Image directory of source data to be converted.\n            export_dir (str): Symlink directory that will contain symbolic links\n                              pointing to source image files.\n        \"\"\"", "\n", "\n", "i", "=", "1", "\n", "\n", "img1", "=", "Path", "(", "os", ".", "path", ".", "abspath", "(", "export_dir", ")", ")", "/", "\"img1/\"", "\n", "img1", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "for", "mot_frame", "in", "self", ".", "frame_list", ":", "\n", "            ", "if", "not", "isinstance", "(", "mot_frame", ".", "file_name", ",", "str", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f\"mot_frame.file_name expected to be string but got: {type(mot_frame.file_name)}\"", ")", "\n", "\n", "", "if", "not", "Path", "(", "mot_frame", ".", "file_name", ")", ".", "suffix", ":", "\n", "                ", "print", "(", "f\"image file has no suffix, skipping it: '{mot_frame.file_name}'\"", ")", "\n", "return", "\n", "", "elif", "Path", "(", "mot_frame", ".", "file_name", ")", ".", "suffix", "not", "in", "[", "\".jpg\"", ",", "\".jpeg\"", ",", "\".bmp\"", ",", "\".gif\"", ",", "\".png\"", ",", "\".tiff\"", "]", ":", "\n", "                ", "print", "(", "f\"image file has incorrect suffix, skipping it: '{mot_frame.file_name}'\"", ")", "\n", "return", "\n", "# set source and mot image paths", "\n", "", "suffix", "=", "Path", "(", "mot_frame", ".", "file_name", ")", ".", "suffix", "\n", "\n", "if", "os", ".", "path", ".", "isabs", "(", "mot_frame", ".", "file_name", ")", ":", "\n", "                ", "if", "not", "Path", "(", "mot_frame", ".", "file_name", ")", ".", "is_file", "(", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"there is not any image file in path: {str(Path(mot_frame.file_name))}\"", ")", "\n", "", "source_image_path", "=", "str", "(", "Path", "(", "mot_frame", ".", "file_name", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "not", "images_dir", ":", "\n", "                    ", "raise", "ValueError", "(", "\"you have to specify `images_dir` for mot conversion.\"", ")", "\n", "", "source_image_path_tmp", "=", "os", ".", "path", ".", "abspath", "(", "str", "(", "Path", "(", "images_dir", ")", "/", "mot_frame", ".", "file_name", ")", ")", "\n", "if", "not", "Path", "(", "source_image_path_tmp", ")", ".", "is_file", "(", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"there is not any image file in path: {source_image_path_tmp}\"", ")", "\n", "", "source_image_path", "=", "str", "(", "Path", "(", "source_image_path_tmp", ")", ")", "\n", "\n", "# generate symlink names as indicated at https://arxiv.org/pdf/1603.00831.pdf", "\n", "", "frame_link_name", "=", "\"0\"", "*", "(", "6", "-", "len", "(", "str", "(", "i", ")", ")", ")", "+", "str", "(", "i", ")", "+", "suffix", "\n", "\n", "mot_image_path", "=", "str", "(", "Path", "(", "export_dir", ")", "/", "Path", "(", "\"img1\"", ")", "/", "Path", "(", "frame_link_name", ")", ")", "\n", "os", ".", "symlink", "(", "source_image_path", ",", "mot_image_path", ")", "\n", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.add_frame": [[285, 289], ["mot.MotVideo.frame_list.append", "isinstance", "TypeError", "type", "mot.MotFrame"], "methods", ["None"], ["", "", "def", "add_frame", "(", "self", ",", "frame", ":", "MotFrame", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "frame", ",", "type", "(", "MotFrame", "(", ")", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"'frame' should be a MotFrame object.\"", ")", "\n", "", "self", ".", "frame_list", ".", "append", "(", "frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.export": [[290, 350], ["str", "Tracker", "ValueError", "sahi.utils.file.increment_path", "os.path.join", "mot.MotTextFile", "mot_text_file.update", "os.path.join", "mot.MotVideo._create_info_file", "pathlib.Path", "os.path.join", "mot.MotTextFile", "mot.MotVideo.tracker_kwargs.get", "mot.MotVideo.tracker_kwargs.get", "mot.MotVideo.tracker_kwargs.get", "mot.MotVideo.tracker_kwargs.get", "mot.MotVideo.tracker_kwargs.get", "mot.MotVideo.tracker_kwargs.get", "mot.MotVideo.tracker_kwargs.get", "mot_frame.to_norfair_detections", "Tracker.update", "mot_frame.to_norfair_trackedobjects", "mot.MotVideo._create_frame_symlinks", "print", "FilterPyKalmanFilterFactory"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.increment_path", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotTextFile.update", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo._create_info_file", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotFrame.to_norfair_detections", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotTextFile.update", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotFrame.to_norfair_trackedobjects", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo._create_frame_symlinks"], ["", "def", "export", "(", "\n", "self", ",", "\n", "images_dir", ":", "str", "=", "None", ",", "\n", "export_dir", ":", "str", "=", "\"runs/mot\"", ",", "\n", "type", ":", "str", "=", "\"gt\"", ",", "\n", "use_tracker", ":", "bool", "=", "None", ",", "\n", "exist_ok", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            export_dir (str): Folder directory that will contain exported mot challenge formatted data.\n            type (str): Type of the MOT challenge export. 'gt' for groundturth data export, 'det' for detection data export.\n            use_tracker (bool): Determines whether to apply kalman based tracker over frame detections or not.\n                Default is True for type='gt'.\n                It is always False for type='det'.\n            exist_ok (bool): If True overwrites given directory.\n        \"\"\"", "\n", "from", "norfair", "import", "Detection", ",", "Tracker", "\n", "from", "norfair", ".", "filter", "import", "FilterPyKalmanFilterFactory", "\n", "\n", "if", "type", "not", "in", "[", "\"gt\"", ",", "\"det\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"'type' can be one of ['gt', 'det'], you provided: {type}\"", ")", "\n", "", "export_dir", ":", "str", "=", "str", "(", "increment_path", "(", "Path", "(", "export_dir", ")", ",", "exist_ok", "=", "exist_ok", ")", ")", "\n", "\n", "if", "type", "==", "\"gt\"", ":", "\n", "            ", "gt_dir", "=", "os", ".", "path", ".", "join", "(", "export_dir", ",", "self", ".", "name", "if", "self", ".", "name", "else", "\"\"", ",", "\"gt\"", ")", "\n", "mot_text_file", ":", "MotTextFile", "=", "MotTextFile", "(", "save_dir", "=", "gt_dir", ",", "save_name", "=", "\"gt\"", ")", "\n", "if", "not", "use_tracker", ":", "\n", "                ", "use_tracker", "=", "True", "\n", "", "", "elif", "type", "==", "\"det\"", ":", "\n", "            ", "det_dir", "=", "os", ".", "path", ".", "join", "(", "export_dir", ",", "self", ".", "name", "if", "self", ".", "name", "else", "\"\"", ",", "\"det\"", ")", "\n", "mot_text_file", ":", "MotTextFile", "=", "MotTextFile", "(", "save_dir", "=", "det_dir", ",", "save_name", "=", "\"det\"", ")", "\n", "use_tracker", "=", "False", "\n", "\n", "", "tracker", "=", "Tracker", "(", "\n", "distance_function", "=", "self", ".", "tracker_kwargs", ".", "get", "(", "\"distance_function\"", ",", "euclidean_distance", ")", ",", "\n", "distance_threshold", "=", "self", ".", "tracker_kwargs", ".", "get", "(", "\"distance_threshold\"", ",", "50", ")", ",", "\n", "hit_counter_max", "=", "self", ".", "tracker_kwargs", ".", "get", "(", "\"hit_counter_max\"", ",", "1", ")", ",", "\n", "initialization_delay", "=", "self", ".", "tracker_kwargs", ".", "get", "(", "\"initialization_delay\"", ",", "0", ")", ",", "\n", "detection_threshold", "=", "self", ".", "tracker_kwargs", ".", "get", "(", "\"detection_threshold\"", ",", "0", ")", ",", "\n", "pointwise_hit_counter_max", "=", "self", ".", "tracker_kwargs", ".", "get", "(", "\"pointwise_hit_counter_max\"", ",", "4", ")", ",", "\n", "filter_factory", "=", "self", ".", "tracker_kwargs", ".", "get", "(", "\"filter_factory\"", ",", "FilterPyKalmanFilterFactory", "(", "R", "=", "0.2", ")", ")", ",", "\n", ")", "\n", "\n", "for", "mot_frame", "in", "self", ".", "frame_list", ":", "\n", "            ", "if", "use_tracker", ":", "\n", "                ", "norfair_detections", ":", "List", "[", "Detection", "]", "=", "mot_frame", ".", "to_norfair_detections", "(", "track_points", "=", "\"bbox\"", ")", "\n", "tracked_objects", "=", "tracker", ".", "update", "(", "detections", "=", "norfair_detections", ")", "\n", "", "else", ":", "\n", "                ", "tracked_objects", "=", "mot_frame", ".", "to_norfair_trackedobjects", "(", "track_points", "=", "\"bbox\"", ")", "\n", "", "mot_text_file", ".", "update", "(", "predictions", "=", "tracked_objects", ")", "\n", "\n", "", "if", "type", "==", "\"gt\"", ":", "\n", "            ", "info_dir", "=", "os", ".", "path", ".", "join", "(", "export_dir", ",", "self", ".", "name", "if", "self", ".", "name", "else", "\"\"", ")", "\n", "self", ".", "_create_info_file", "(", "seq_length", "=", "mot_text_file", ".", "frame_number", ",", "export_dir", "=", "info_dir", ")", "\n", "# create symlinks if mot frames contain file_name", "\n", "if", "self", ".", "frame_list", "[", "0", "]", ".", "file_name", ":", "\n", "                ", "self", ".", "_create_frame_symlinks", "(", "images_dir", "=", "images_dir", ",", "export_dir", "=", "info_dir", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"skipping frame symlink creation since file_name is not set for mot frames\"", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.mot.euclidean_distance": [[65, 67], ["numpy.linalg.norm"], "function", ["None"], ["", "", "def", "euclidean_distance", "(", "detection", ",", "tracked_object", ")", ":", "\n", "    ", "return", "np", ".", "linalg", ".", "norm", "(", "detection", ".", "points", "-", "tracked_object", ".", "estimate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.__init__": [[33, 37], ["int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "id", "=", "None", ",", "name", "=", "None", ",", "supercategory", "=", "None", ")", ":", "\n", "        ", "self", ".", "id", "=", "int", "(", "id", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "supercategory", "=", "supercategory", "if", "supercategory", "else", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.from_coco_category": [[38, 51], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_coco_category", "(", "cls", ",", "category", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoCategory object using coco category.\n\n        Args:\n            category: Dict\n                {\"supercategory\": \"person\", \"id\": 1, \"name\": \"person\"},\n        \"\"\"", "\n", "return", "cls", "(", "\n", "id", "=", "category", "[", "\"id\"", "]", ",", "\n", "name", "=", "category", "[", "\"name\"", "]", ",", "\n", "supercategory", "=", "category", "[", "\"supercategory\"", "]", "if", "\"supercategory\"", "in", "category", "else", "category", "[", "\"name\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.json": [[53, 59], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"id\"", ":", "self", ".", "id", ",", "\n", "\"name\"", ":", "self", ".", "name", ",", "\n", "\"supercategory\"", ":", "self", ".", "supercategory", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.__repr__": [[61, 66], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"CocoCategory<\n    id: {self.id},\n    name: {self.name},\n    supercategory: {self.supercategory}>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.from_coco_segmentation": [[73, 93], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_coco_segmentation", "(", "cls", ",", "segmentation", ",", "category_id", ",", "category_name", ",", "iscrowd", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoAnnotation object using coco segmentation.\n\n        Args:\n            segmentation: List[List]\n                [[1, 1, 325, 125, 250, 200, 5, 200]]\n            category_id: int\n                Category id of the annotation\n            category_name: str\n                Category name of the annotation\n            iscrowd: int\n                0 or 1\n        \"\"\"", "\n", "return", "cls", "(", "\n", "segmentation", "=", "segmentation", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.from_coco_bbox": [[95, 115], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_coco_bbox", "(", "cls", ",", "bbox", ",", "category_id", ",", "category_name", ",", "iscrowd", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoAnnotation object using coco bbox\n\n        Args:\n            bbox: List\n                [xmin, ymin, width, height]\n            category_id: int\n                Category id of the annotation\n            category_name: str\n                Category name of the annotation\n            iscrowd: int\n                0 or 1\n        \"\"\"", "\n", "return", "cls", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.from_coco_annotation_dict": [[117, 152], ["annotation_dict.__contains__", "logger.warning", "annotation_dict.__contains__", "cls", "cls", "isinstance"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_coco_annotation_dict", "(", "cls", ",", "annotation_dict", ":", "Dict", ",", "category_name", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoAnnotation object from category name and COCO formatted\n        annotation dict (with fields \"bbox\", \"segmentation\", \"category_id\").\n\n        Args:\n            category_name: str\n                Category name of the annotation\n            annotation_dict: dict\n                COCO formatted annotation dict (with fields \"bbox\", \"segmentation\", \"category_id\")\n        \"\"\"", "\n", "if", "annotation_dict", ".", "__contains__", "(", "\"segmentation\"", ")", "and", "not", "isinstance", "(", "annotation_dict", "[", "\"segmentation\"", "]", ",", "list", ")", ":", "\n", "            ", "has_rle_segmentation", "=", "True", "\n", "logger", ".", "warning", "(", "\n", "f\"Segmentation annotation for id {annotation_dict['id']} is skipped since RLE segmentation format is not supported.\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "has_rle_segmentation", "=", "False", "\n", "\n", "", "if", "(", "\n", "annotation_dict", ".", "__contains__", "(", "\"segmentation\"", ")", "\n", "and", "annotation_dict", "[", "\"segmentation\"", "]", "\n", "and", "not", "has_rle_segmentation", "\n", ")", ":", "\n", "            ", "return", "cls", "(", "\n", "segmentation", "=", "annotation_dict", "[", "\"segmentation\"", "]", ",", "\n", "category_id", "=", "annotation_dict", "[", "\"category_id\"", "]", ",", "\n", "category_name", "=", "category_name", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "cls", "(", "\n", "bbox", "=", "annotation_dict", "[", "\"bbox\"", "]", ",", "\n", "category_id", "=", "annotation_dict", "[", "\"category_id\"", "]", ",", "\n", "category_name", "=", "category_name", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.from_shapely_annotation": [[154, 180], ["cls", "shapely_annotation.to_coco_segmentation"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation"], ["", "", "@", "classmethod", "\n", "def", "from_shapely_annotation", "(", "\n", "cls", ",", "\n", "shapely_annotation", ":", "ShapelyAnnotation", ",", "\n", "category_id", ":", "int", ",", "\n", "category_name", ":", "str", ",", "\n", "iscrowd", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoAnnotation object from ShapelyAnnotation object.\n\n        Args:\n            shapely_annotation (ShapelyAnnotation)\n            category_id (int): Category id of the annotation\n            category_name (str): Category name of the annotation\n            iscrowd (int): 0 or 1\n        \"\"\"", "\n", "coco_annotation", "=", "cls", "(", "\n", "bbox", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", ")", "\n", "coco_annotation", ".", "_segmentation", "=", "shapely_annotation", ".", "to_coco_segmentation", "(", ")", "\n", "coco_annotation", ".", "_shapely_annotation", "=", "shapely_annotation", "\n", "return", "coco_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.__init__": [[181, 222], ["ValueError", "sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "round"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "segmentation", "=", "None", ",", "\n", "bbox", "=", "None", ",", "\n", "category_id", "=", "None", ",", "\n", "category_name", "=", "None", ",", "\n", "image_id", "=", "None", ",", "\n", "iscrowd", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates coco annotation object using bbox or segmentation\n\n        Args:\n            segmentation: List[List]\n                [[1, 1, 325, 125, 250, 200, 5, 200]]\n            bbox: List\n                [xmin, ymin, width, height]\n            category_id: int\n                Category id of the annotation\n            category_name: str\n                Category name of the annotation\n            image_id: int\n                Image ID of the annotation\n            iscrowd: int\n                0 or 1\n        \"\"\"", "\n", "if", "bbox", "is", "None", "and", "segmentation", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"you must provide a bbox or polygon\"", ")", "\n", "\n", "", "self", ".", "_segmentation", "=", "segmentation", "\n", "bbox", "=", "[", "round", "(", "point", ")", "for", "point", "in", "bbox", "]", "if", "bbox", "else", "bbox", "\n", "self", ".", "_category_id", "=", "category_id", "\n", "self", ".", "_category_name", "=", "category_name", "\n", "self", ".", "_image_id", "=", "image_id", "\n", "self", ".", "_iscrowd", "=", "iscrowd", "\n", "\n", "if", "self", ".", "_segmentation", ":", "\n", "            ", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_segmentation", "(", "segmentation", "=", "self", ".", "_segmentation", ")", "\n", "", "else", ":", "\n", "            ", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_bbox", "(", "bbox", "=", "bbox", ")", "\n", "", "self", ".", "_shapely_annotation", "=", "shapely_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.get_sliced_coco_annotation": [[223, 231], ["sahi.utils.shapely.box", "coco.CocoAnnotation._shapely_annotation.get_intersection", "coco.CocoAnnotation.from_shapely_annotation"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.get_intersection", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.from_shapely_annotation"], ["", "def", "get_sliced_coco_annotation", "(", "self", ",", "slice_bbox", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "shapely_polygon", "=", "box", "(", "slice_bbox", "[", "0", "]", ",", "slice_bbox", "[", "1", "]", ",", "slice_bbox", "[", "2", "]", ",", "slice_bbox", "[", "3", "]", ")", "\n", "intersection_shapely_annotation", "=", "self", ".", "_shapely_annotation", ".", "get_intersection", "(", "shapely_polygon", ")", "\n", "return", "CocoAnnotation", ".", "from_shapely_annotation", "(", "\n", "intersection_shapely_annotation", ",", "\n", "category_id", "=", "self", ".", "category_id", ",", "\n", "category_name", "=", "self", ".", "category_name", ",", "\n", "iscrowd", "=", "self", ".", "iscrowd", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.area": [[233, 239], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "area", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns area of annotation polygon (or bbox if no polygon available)\n        \"\"\"", "\n", "return", "self", ".", "_shapely_annotation", ".", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.bbox": [[240, 246], ["coco.CocoAnnotation._shapely_annotation.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "@", "property", "\n", "def", "bbox", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns coco formatted bbox of the annotation as [xmin, ymin, width, height]\n        \"\"\"", "\n", "return", "self", ".", "_shapely_annotation", ".", "to_coco_bbox", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.segmentation": [[247, 256], ["coco.CocoAnnotation._shapely_annotation.to_coco_segmentation"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation"], ["", "@", "property", "\n", "def", "segmentation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns coco formatted segmentation of the annotation as [[1, 1, 325, 125, 250, 200, 5, 200]]\n        \"\"\"", "\n", "if", "self", ".", "_segmentation", ":", "\n", "            ", "return", "self", ".", "_shapely_annotation", ".", "to_coco_segmentation", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.category_id": [[264, 269], ["isinstance", "Exception"], "methods", ["None"], ["", "@", "category_id", ".", "setter", "\n", "def", "category_id", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "i", ",", "int", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"category_id must be an integer\"", ")", "\n", "", "self", ".", "_category_id", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.image_id": [[277, 282], ["isinstance", "Exception"], "methods", ["None"], ["", "@", "image_id", ".", "setter", "\n", "def", "image_id", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "i", ",", "int", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"image_id must be an integer\"", ")", "\n", "", "self", ".", "_image_id", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.category_name": [[290, 295], ["isinstance", "Exception"], "methods", ["None"], ["", "@", "category_name", ".", "setter", "\n", "def", "category_name", "(", "self", ",", "n", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "n", ",", "str", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"category_name must be a string\"", ")", "\n", "", "self", ".", "_category_name", "=", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.iscrowd": [[296, 302], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iscrowd", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns iscrowd info of the annotation\n        \"\"\"", "\n", "return", "self", ".", "_iscrowd", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.json": [[303, 312], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"image_id\"", ":", "self", ".", "image_id", ",", "\n", "\"bbox\"", ":", "self", ".", "bbox", ",", "\n", "\"category_id\"", ":", "self", ".", "category_id", ",", "\n", "\"segmentation\"", ":", "self", ".", "segmentation", ",", "\n", "\"iscrowd\"", ":", "self", ".", "iscrowd", ",", "\n", "\"area\"", ":", "self", ".", "area", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.serialize": [[314, 316], ["print"], "methods", ["None"], ["", "def", "serialize", "(", "self", ")", ":", "\n", "        ", "print", "(", "\".serialize() is deprectaed, use .json instead\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.__repr__": [[317, 326], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"CocoAnnotation<\n    image_id: {self.image_id},\n    bbox: {self.bbox},\n    segmentation: {self.segmentation},\n    category_id: {self.category_id},\n    category_name: {self.category_name},\n    iscrowd: {self.iscrowd},\n    area: {self.area}>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.from_coco_segmentation": [[333, 357], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_coco_segmentation", "(", "cls", ",", "segmentation", ",", "category_id", ",", "category_name", ",", "score", ",", "iscrowd", "=", "0", ",", "image_id", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoAnnotation object using coco segmentation.\n\n        Args:\n            segmentation: List[List]\n                [[1, 1, 325, 125, 250, 200, 5, 200]]\n            category_id: int\n                Category id of the annotation\n            category_name: str\n                Category name of the annotation\n            score: float\n                Prediction score between 0 and 1\n            iscrowd: int\n                0 or 1\n        \"\"\"", "\n", "return", "cls", "(", "\n", "segmentation", "=", "segmentation", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "score", "=", "score", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", "image_id", "=", "image_id", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.from_coco_bbox": [[359, 383], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_coco_bbox", "(", "cls", ",", "bbox", ",", "category_id", ",", "category_name", ",", "score", ",", "iscrowd", "=", "0", ",", "image_id", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoAnnotation object using coco bbox\n\n        Args:\n            bbox: List\n                [xmin, ymin, width, height]\n            category_id: int\n                Category id of the annotation\n            category_name: str\n                Category name of the annotation\n            score: float\n                Prediction score between 0 and 1\n            iscrowd: int\n                0 or 1\n        \"\"\"", "\n", "return", "cls", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "score", "=", "score", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", "image_id", "=", "image_id", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.from_coco_annotation_dict": [[385, 413], ["cls", "cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_coco_annotation_dict", "(", "cls", ",", "category_name", ",", "annotation_dict", ",", "score", ",", "image_id", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoAnnotation object from category name and COCO formatted\n        annotation dict (with fields \"bbox\", \"segmentation\", \"category_id\").\n\n        Args:\n            category_name: str\n                Category name of the annotation\n            annotation_dict: dict\n                COCO formatted annotation dict (with fields \"bbox\", \"segmentation\", \"category_id\")\n            score: float\n                Prediction score between 0 and 1\n        \"\"\"", "\n", "if", "annotation_dict", "[", "\"segmentation\"", "]", ":", "\n", "            ", "return", "cls", "(", "\n", "segmentation", "=", "annotation_dict", "[", "\"segmentation\"", "]", ",", "\n", "category_id", "=", "annotation_dict", "[", "\"category_id\"", "]", ",", "\n", "category_name", "=", "category_name", ",", "\n", "score", "=", "score", ",", "\n", "image_id", "=", "image_id", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "cls", "(", "\n", "bbox", "=", "annotation_dict", "[", "\"bbox\"", "]", ",", "\n", "category_id", "=", "annotation_dict", "[", "\"category_id\"", "]", ",", "\n", "category_name", "=", "category_name", ",", "\n", "image_id", "=", "image_id", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.__init__": [[415, 451], ["coco.CocoAnnotation.__init__"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__"], ["", "", "def", "__init__", "(", "\n", "self", ",", "\n", "segmentation", "=", "None", ",", "\n", "bbox", "=", "None", ",", "\n", "category_id", "=", "None", ",", "\n", "category_name", "=", "None", ",", "\n", "image_id", "=", "None", ",", "\n", "score", "=", "None", ",", "\n", "iscrowd", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            segmentation: List[List]\n                [[1, 1, 325, 125, 250, 200, 5, 200]]\n            bbox: List\n                [xmin, ymin, width, height]\n            category_id: int\n                Category id of the annotation\n            category_name: str\n                Category name of the annotation\n            image_id: int\n                Image ID of the annotation\n            score: float\n                Prediction score between 0 and 1\n            iscrowd: int\n                0 or 1\n        \"\"\"", "\n", "self", ".", "score", "=", "score", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "segmentation", "=", "segmentation", ",", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "image_id", "=", "image_id", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.json": [[453, 464], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"image_id\"", ":", "self", ".", "image_id", ",", "\n", "\"bbox\"", ":", "self", ".", "bbox", ",", "\n", "\"score\"", ":", "self", ".", "score", ",", "\n", "\"category_id\"", ":", "self", ".", "category_id", ",", "\n", "\"category_name\"", ":", "self", ".", "category_name", ",", "\n", "\"segmentation\"", ":", "self", ".", "segmentation", ",", "\n", "\"iscrowd\"", ":", "self", ".", "iscrowd", ",", "\n", "\"area\"", ":", "self", ".", "area", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.serialize": [[466, 468], ["print"], "methods", ["None"], ["", "def", "serialize", "(", "self", ")", ":", "\n", "        ", "print", "(", "\".serialize() is deprectaed, use .json instead\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.__repr__": [[469, 479], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"CocoPrediction<\n    image_id: {self.image_id},\n    bbox: {self.bbox},\n    segmentation: {self.segmentation},\n    score: {self.score},\n    category_id: {self.category_id},\n    category_name: {self.category_name},\n    iscrowd: {self.iscrowd},\n    area: {self.area}>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidAnnotation.__init__": [[487, 523], ["coco.CocoAnnotation.__init__"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "bbox", "=", "None", ",", "\n", "category_id", "=", "None", ",", "\n", "category_name", "=", "None", ",", "\n", "image_id", "=", "None", ",", "\n", "instance_id", "=", "None", ",", "\n", "iscrowd", "=", "0", ",", "\n", "id", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            bbox: List\n                [xmin, ymin, width, height]\n            category_id: int\n                Category id of the annotation\n            category_name: str\n                Category name of the annotation\n            image_id: int\n                Image ID of the annotation\n            instance_id: int\n                Used for tracking\n            iscrowd: int\n                0 or 1\n            id: int\n                Annotation id\n        \"\"\"", "\n", "super", "(", "CocoVidAnnotation", ",", "self", ")", ".", "__init__", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "image_id", "=", "image_id", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", ")", "\n", "self", ".", "instance_id", "=", "instance_id", "\n", "self", ".", "id", "=", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidAnnotation.json": [[524, 536], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"id\"", ":", "self", ".", "id", ",", "\n", "\"image_id\"", ":", "self", ".", "image_id", ",", "\n", "\"bbox\"", ":", "self", ".", "bbox", ",", "\n", "\"segmentation\"", ":", "self", ".", "segmentation", ",", "\n", "\"category_id\"", ":", "self", ".", "category_id", ",", "\n", "\"category_name\"", ":", "self", ".", "category_name", ",", "\n", "\"instance_id\"", ":", "self", ".", "instance_id", ",", "\n", "\"iscrowd\"", ":", "self", ".", "iscrowd", ",", "\n", "\"area\"", ":", "self", ".", "area", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidAnnotation.__repr__": [[538, 549], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"CocoAnnotation<\n    id: {self.id},\n    image_id: {self.image_id},\n    bbox: {self.bbox},\n    segmentation: {self.segmentation},\n    category_id: {self.category_id},\n    category_name: {self.category_name},\n    instance_id: {self.instance_id},\n    iscrowd: {self.iscrowd},\n    area: {self.area}>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.from_coco_image_dict": [[552, 566], ["cls"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "from_coco_image_dict", "(", "cls", ",", "image_dict", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoImage object from COCO formatted image dict (with fields \"id\", \"file_name\", \"height\" and \"weight\").\n\n        Args:\n            image_dict: dict\n                COCO formatted image dict (with fields \"id\", \"file_name\", \"height\" and \"weight\")\n        \"\"\"", "\n", "return", "cls", "(", "\n", "id", "=", "image_dict", "[", "\"id\"", "]", ",", "\n", "file_name", "=", "image_dict", "[", "\"file_name\"", "]", ",", "\n", "height", "=", "image_dict", "[", "\"height\"", "]", ",", "\n", "width", "=", "image_dict", "[", "\"width\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.__init__": [[568, 588], ["int", "int", "int"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "file_name", ":", "str", ",", "height", ":", "int", ",", "width", ":", "int", ",", "id", ":", "int", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoImage object\n\n        Args:\n            id : int\n                Image id\n            file_name : str\n                Image path\n            height : int\n                Image height in pixels\n            width : int\n                Image width in pixels\n        \"\"\"", "\n", "self", ".", "id", "=", "int", "(", "id", ")", "if", "id", "else", "id", "\n", "self", ".", "file_name", "=", "file_name", "\n", "self", ".", "height", "=", "int", "(", "height", ")", "\n", "self", ".", "width", "=", "int", "(", "width", ")", "\n", "self", ".", "annotations", "=", "[", "]", "# list of CocoAnnotation that belong to this image", "\n", "self", ".", "predictions", "=", "[", "]", "# list of CocoPrediction that belong to this image", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.add_annotation": [[589, 599], ["coco.CocoImage.annotations.append", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "add_annotation", "(", "self", ",", "annotation", ")", ":", "\n", "        ", "\"\"\"\n        Adds annotation to this CocoImage instance\n\n        annotation : CocoAnnotation\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "annotation", ",", "CocoAnnotation", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"annotation must be a CocoAnnotation instance\"", ")", "\n", "", "self", ".", "annotations", ".", "append", "(", "annotation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.add_prediction": [[600, 610], ["coco.CocoImage.predictions.append", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "add_prediction", "(", "self", ",", "prediction", ")", ":", "\n", "        ", "\"\"\"\n        Adds prediction to this CocoImage instance\n\n        prediction : CocoPrediction\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "prediction", ",", "CocoPrediction", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"prediction must be a CocoPrediction instance\"", ")", "\n", "", "self", ".", "predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.json": [[611, 618], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"id\"", ":", "self", ".", "id", ",", "\n", "\"file_name\"", ":", "self", ".", "file_name", ",", "\n", "\"height\"", ":", "self", ".", "height", ",", "\n", "\"width\"", ":", "self", ".", "width", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.__repr__": [[620, 628], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"CocoImage<\n    id: {self.id},\n    file_name: {self.file_name},\n    height: {self.height},\n    width: {self.width},\n    annotations: List[CocoAnnotation],\n    predictions: List[CocoPrediction]>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.__init__": [[636, 665], ["coco.CocoImage.__init__"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "file_name", ",", "\n", "height", ",", "\n", "width", ",", "\n", "video_id", "=", "None", ",", "\n", "frame_id", "=", "None", ",", "\n", "id", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoVidImage object\n\n        Args:\n            id: int\n                Image id\n            file_name: str\n                Image path\n            height: int\n                Image height in pixels\n            width: int\n                Image width in pixels\n            frame_id: int\n                0-indexed frame id\n            video_id: int\n                Video id\n        \"\"\"", "\n", "super", "(", "CocoVidImage", ",", "self", ")", ".", "__init__", "(", "file_name", "=", "file_name", ",", "height", "=", "height", ",", "width", "=", "width", ",", "id", "=", "id", ")", "\n", "self", ".", "frame_id", "=", "frame_id", "\n", "self", ".", "video_id", "=", "video_id", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.from_coco_image": [[666, 685], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_coco_image", "(", "cls", ",", "coco_image", ",", "video_id", "=", "None", ",", "frame_id", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoVidImage object using CocoImage object.\n        Args:\n            coco_image: CocoImage\n            frame_id: int\n                0-indexed frame id\n            video_id: int\n                Video id\n\n        \"\"\"", "\n", "return", "cls", "(", "\n", "file_name", "=", "coco_image", ".", "file_name", ",", "\n", "height", "=", "coco_image", ".", "height", ",", "\n", "width", "=", "coco_image", ".", "width", ",", "\n", "id", "=", "coco_image", ".", "id", ",", "\n", "video_id", "=", "video_id", ",", "\n", "frame_id", "=", "frame_id", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation": [[687, 696], ["coco.CocoVidImage.annotations.append", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "add_annotation", "(", "self", ",", "annotation", ")", ":", "\n", "        ", "\"\"\"\n        Adds annotation to this CocoImage instance\n        annotation : CocoVidAnnotation\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "annotation", ",", "CocoVidAnnotation", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"annotation must be a CocoVidAnnotation instance\"", ")", "\n", "", "self", ".", "annotations", ".", "append", "(", "annotation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.json": [[697, 706], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"file_name\"", ":", "self", ".", "file_name", ",", "\n", "\"height\"", ":", "self", ".", "height", ",", "\n", "\"width\"", ":", "self", ".", "width", ",", "\n", "\"id\"", ":", "self", ".", "id", ",", "\n", "\"video_id\"", ":", "self", ".", "video_id", ",", "\n", "\"frame_id\"", ":", "self", ".", "frame_id", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.__repr__": [[708, 717], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"CocoVidImage<\n    file_name: {self.file_name},\n    height: {self.height},\n    width: {self.width},\n    id: {self.id},\n    video_id: {self.video_id},\n    frame_id: {self.frame_id},\n    annotations: List[CocoVidAnnotation]>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVideo.__init__": [[725, 754], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "name", ":", "str", ",", "\n", "id", ":", "int", "=", "None", ",", "\n", "fps", ":", "float", "=", "None", ",", "\n", "height", ":", "int", "=", "None", ",", "\n", "width", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoVideo object\n\n        Args:\n            name: str\n                Video name\n            id: int\n                Video id\n            fps: float\n                Video fps\n            height: int\n                Video height in pixels\n            width: int\n                Video width in pixels\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "id", "=", "id", "\n", "self", ".", "fps", "=", "fps", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "images", "=", "[", "]", "# list of CocoImage that belong to this video", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVideo.add_image": [[755, 765], ["coco.CocoVideo.images.append", "isinstance", "TypeError", "CocoVidImage.from_coco_image"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.from_coco_image"], ["", "def", "add_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"\n        Adds image to this CocoVideo instance\n        Args:\n            image: CocoImage\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "image", ",", "CocoImage", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"image must be a CocoImage instance\"", ")", "\n", "", "self", ".", "images", ".", "append", "(", "CocoVidImage", ".", "from_coco_image", "(", "image", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVideo.add_cocovidimage": [[766, 776], ["coco.CocoVideo.images.append", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "add_cocovidimage", "(", "self", ",", "cocovidimage", ")", ":", "\n", "        ", "\"\"\"\n        Adds CocoVidImage to this CocoVideo instance\n        Args:\n            cocovidimage: CocoVidImage\n        \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cocovidimage", ",", "CocoVidImage", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"cocovidimage must be a CocoVidImage instance\"", ")", "\n", "", "self", ".", "images", ".", "append", "(", "cocovidimage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVideo.json": [[777, 785], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"name\"", ":", "self", ".", "name", ",", "\n", "\"id\"", ":", "self", ".", "id", ",", "\n", "\"fps\"", ":", "self", ".", "fps", ",", "\n", "\"height\"", ":", "self", ".", "height", ",", "\n", "\"width\"", ":", "self", ".", "width", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVideo.__repr__": [[787, 795], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"\"\"CocoVideo<\n    id: {self.id},\n    name: {self.name},\n    fps: {self.fps},\n    height: {self.height},\n    width: {self.width},\n    images: List[CocoVidImage]>\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.__init__": [[798, 835], ["ValueError"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "name", "=", "None", ",", "\n", "image_dir", "=", "None", ",", "\n", "remapping_dict", "=", "None", ",", "\n", "ignore_negative_samples", "=", "False", ",", "\n", "clip_bboxes_to_img_dims", "=", "False", ",", "\n", "image_id_setting", "=", "\"auto\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates Coco object.\n\n        Args:\n            name: str\n                Name of the Coco dataset, it determines exported json name.\n            image_dir: str\n                Base file directory that contains dataset images. Required for dataset merging.\n            remapping_dict: dict\n                {1:0, 2:1} maps category id 1 to 0 and category id 2 to 1\n            ignore_negative_samples: bool\n                If True ignores images without annotations in all operations.\n            image_id_setting: str\n                how to assign image ids while exporting can be\n                    auto --> will assign id from scratch (<CocoImage>.id will be ignored)\n                    manual --> you will need to provide image ids in <CocoImage> instances (<CocoImage>.id can not be None)\n        \"\"\"", "\n", "if", "image_id_setting", "not", "in", "[", "\"auto\"", ",", "\"manual\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"image_id_setting must be either 'auto' or 'manual'\"", ")", "\n", "", "self", ".", "name", "=", "name", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "remapping_dict", "=", "remapping_dict", "\n", "self", ".", "ignore_negative_samples", "=", "ignore_negative_samples", "\n", "self", ".", "categories", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "self", ".", "_stats", "=", "None", "\n", "self", ".", "clip_bboxes_to_img_dims", "=", "clip_bboxes_to_img_dims", "\n", "self", ".", "image_id_setting", "=", "image_id_setting", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_categories_from_coco_category_list": [[836, 856], ["coco.Coco.add_category", "coco.Coco.remapping_dict.keys", "CocoCategory.from_coco_category"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_category", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.from_coco_category"], ["", "def", "add_categories_from_coco_category_list", "(", "self", ",", "coco_category_list", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoCategory object using coco category list.\n\n        Args:\n            coco_category_list: List[Dict]\n                [\n                    {\"supercategory\": \"person\", \"id\": 1, \"name\": \"person\"},\n                    {\"supercategory\": \"vehicle\", \"id\": 2, \"name\": \"bicycle\"}\n                ]\n        \"\"\"", "\n", "\n", "for", "coco_category", "in", "coco_category_list", ":", "\n", "            ", "if", "self", ".", "remapping_dict", "is", "not", "None", ":", "\n", "                ", "for", "source_id", "in", "self", ".", "remapping_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "coco_category", "[", "\"id\"", "]", "==", "source_id", ":", "\n", "                        ", "target_id", "=", "self", ".", "remapping_dict", "[", "source_id", "]", "\n", "coco_category", "[", "\"id\"", "]", "=", "target_id", "\n", "\n", "", "", "", "self", ".", "add_category", "(", "CocoCategory", ".", "from_coco_category", "(", "coco_category", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_category": [[857, 869], ["coco.Coco.categories.append", "isinstance", "TypeError"], "methods", ["None"], ["", "", "def", "add_category", "(", "self", ",", "category", ")", ":", "\n", "        ", "\"\"\"\n        Adds category to this Coco instance\n\n        Args:\n            category: CocoCategory\n        \"\"\"", "\n", "\n", "# assert type(category) == CocoCategory, \"category must be a CocoCategory instance\"", "\n", "if", "not", "isinstance", "(", "category", ",", "CocoCategory", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"category must be a CocoCategory instance\"", ")", "\n", "", "self", ".", "categories", ".", "append", "(", "category", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image": [[870, 881], ["coco.Coco.images.append", "ValueError"], "methods", ["None"], ["", "def", "add_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"\n        Adds image to this Coco instance\n\n        Args:\n            image: CocoImage\n        \"\"\"", "\n", "\n", "if", "self", ".", "image_id_setting", "==", "\"manual\"", "and", "image", ".", "id", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"image id should be manually set for image_id_setting='manual'\"", ")", "\n", "", "self", ".", "images", ".", "append", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.update_categories": [[882, 938], ["coco.Coco", "copy.deepcopy", "desired_name2id.keys", "copy.deepcopy", "coco.CocoCategory", "coco.Coco.add_category", "CocoImage.from_coco_image_dict", "coco.Coco.add_image", "desired_name2id.keys", "str", "os.path.abspath", "CocoImage.from_coco_image_dict.add_annotation", "pathlib.Path", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_category", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.from_coco_image_dict", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation"], ["", "def", "update_categories", "(", "self", ",", "desired_name2id", ",", "update_image_filenames", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Rearranges category mapping of given COCO object based on given desired_name2id.\n        Can also be used to filter some of the categories.\n\n        Args:\n            desired_name2id: dict\n                {\"big_vehicle\": 1, \"car\": 2, \"human\": 3}\n            update_image_filenames: bool\n                If True, updates coco image file_names with absolute file paths.\n        \"\"\"", "\n", "# init vars", "\n", "currentid2desiredid_mapping", "=", "{", "}", "\n", "updated_coco", "=", "Coco", "(", "\n", "name", "=", "self", ".", "name", ",", "\n", "image_dir", "=", "self", ".", "image_dir", ",", "\n", "remapping_dict", "=", "self", ".", "remapping_dict", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", ")", "\n", "# create category id mapping (currentid2desiredid_mapping)", "\n", "for", "coco_category", "in", "copy", ".", "deepcopy", "(", "self", ".", "categories", ")", ":", "\n", "            ", "current_category_id", "=", "coco_category", ".", "id", "\n", "current_category_name", "=", "coco_category", ".", "name", "\n", "if", "current_category_name", "in", "desired_name2id", ".", "keys", "(", ")", ":", "\n", "                ", "currentid2desiredid_mapping", "[", "current_category_id", "]", "=", "desired_name2id", "[", "current_category_name", "]", "\n", "", "else", ":", "\n", "# ignore categories that are not included in desired_name2id", "\n", "                ", "currentid2desiredid_mapping", "[", "current_category_id", "]", "=", "None", "\n", "\n", "# add updated categories", "\n", "", "", "for", "name", "in", "desired_name2id", ".", "keys", "(", ")", ":", "\n", "            ", "updated_coco_category", "=", "CocoCategory", "(", "id", "=", "desired_name2id", "[", "name", "]", ",", "name", "=", "name", ",", "supercategory", "=", "name", ")", "\n", "updated_coco", ".", "add_category", "(", "updated_coco_category", ")", "\n", "\n", "# add updated images & annotations", "\n", "", "for", "coco_image", "in", "copy", ".", "deepcopy", "(", "self", ".", "images", ")", ":", "\n", "            ", "updated_coco_image", "=", "CocoImage", ".", "from_coco_image_dict", "(", "coco_image", ".", "json", ")", "\n", "# update filename to abspath", "\n", "file_name_is_abspath", "=", "True", "if", "os", ".", "path", ".", "abspath", "(", "coco_image", ".", "file_name", ")", "==", "coco_image", ".", "file_name", "else", "False", "\n", "if", "update_image_filenames", "and", "not", "file_name_is_abspath", ":", "\n", "                ", "updated_coco_image", ".", "file_name", "=", "str", "(", "Path", "(", "os", ".", "path", ".", "abspath", "(", "self", ".", "image_dir", ")", ")", "/", "coco_image", ".", "file_name", ")", "\n", "# update annotations", "\n", "", "for", "coco_annotation", "in", "coco_image", ".", "annotations", ":", "\n", "                ", "current_category_id", "=", "coco_annotation", ".", "category_id", "\n", "desired_category_id", "=", "currentid2desiredid_mapping", "[", "current_category_id", "]", "\n", "# append annotations with category id present in desired_name2id", "\n", "if", "desired_category_id", "is", "not", "None", ":", "\n", "# update cetegory id", "\n", "                    ", "coco_annotation", ".", "category_id", "=", "desired_category_id", "\n", "# append updated annotation to target coco dict", "\n", "updated_coco_image", ".", "add_annotation", "(", "coco_annotation", ")", "\n", "", "", "updated_coco", ".", "add_image", "(", "updated_coco_image", ")", "\n", "\n", "# overwrite instance", "\n", "", "self", ".", "__class__", "=", "updated_coco", ".", "__class__", "\n", "self", ".", "__dict__", "=", "updated_coco", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.merge": [[939, 986], ["coco.Coco.images.extend", "ValueError", "coco.update_categories", "print", "print", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.extend", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "def", "merge", "(", "self", ",", "coco", ",", "desired_name2id", "=", "None", ",", "verbose", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Combines the images/annotations/categories of given coco object with current one.\n\n        Args:\n            coco : sahi.utils.coco.Coco instance\n                A COCO dataset object\n            desired_name2id : dict\n                {\"human\": 1, \"car\": 2, \"big_vehicle\": 3}\n            verbose: bool\n                If True, merging info is printed\n        \"\"\"", "\n", "if", "self", ".", "image_dir", "is", "None", "or", "coco", ".", "image_dir", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"image_dir should be provided for merging.\"", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "if", "not", "desired_name2id", ":", "\n", "                ", "print", "(", "\"'desired_name2id' is not specified, combining all categories.\"", ")", "\n", "\n", "# create desired_name2id by combining all categories, if desired_name2id is not specified", "\n", "", "", "coco1", "=", "self", "\n", "coco2", "=", "coco", "\n", "category_ind", "=", "0", "\n", "if", "desired_name2id", "is", "None", ":", "\n", "            ", "desired_name2id", "=", "{", "}", "\n", "for", "coco", "in", "[", "coco1", ",", "coco2", "]", ":", "\n", "                ", "temp_categories", "=", "copy", ".", "deepcopy", "(", "coco", ".", "json_categories", ")", "\n", "for", "temp_category", "in", "temp_categories", ":", "\n", "                    ", "if", "temp_category", "[", "\"name\"", "]", "not", "in", "desired_name2id", ":", "\n", "                        ", "desired_name2id", "[", "temp_category", "[", "\"name\"", "]", "]", "=", "category_ind", "\n", "category_ind", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "continue", "\n", "\n", "# update categories and image paths", "\n", "", "", "", "", "for", "coco", "in", "[", "coco1", ",", "coco2", "]", ":", "\n", "            ", "coco", ".", "update_categories", "(", "desired_name2id", "=", "desired_name2id", ",", "update_image_filenames", "=", "True", ")", "\n", "\n", "# combine images and categories", "\n", "", "coco1", ".", "images", ".", "extend", "(", "coco2", ".", "images", ")", "\n", "self", ".", "images", ":", "List", "[", "CocoImage", "]", "=", "coco1", ".", "images", "\n", "self", ".", "categories", "=", "coco1", ".", "categories", "\n", "\n", "# print categories", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\n", "\"Categories are formed as:\\n\"", ",", "\n", "self", ".", "json_categories", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path": [[988, 1073], ["cls", "coco.get_coco_with_clipped_bboxes.get_coco_with_clipped_bboxes.add_categories_from_coco_category_list", "coco.get_imageid2annotationlist_mapping", "set", "tqdm.tqdm.tqdm", "type", "TypeError", "type", "sahi.utils.file.load_json", "CocoImage.from_coco_image_dict", "coco.get_coco_with_clipped_bboxes.get_coco_with_clipped_bboxes.add_image", "coco.get_coco_with_clipped_bboxes.get_coco_with_clipped_bboxes.get_coco_with_clipped_bboxes", "print", "image_id_set.add", "CocoAnnotation.from_coco_annotation_dict", "CocoImage.from_coco_image_dict.add_annotation"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_categories_from_coco_category_list", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.get_imageid2annotationlist_mapping", "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.from_coco_image_dict", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_coco_with_clipped_bboxes", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.from_coco_annotation_dict", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation"], ["", "", "@", "classmethod", "\n", "def", "from_coco_dict_or_path", "(", "\n", "cls", ",", "\n", "coco_dict_or_path", ":", "Union", "[", "Dict", ",", "str", "]", ",", "\n", "image_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "remapping_dict", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "ignore_negative_samples", ":", "bool", "=", "False", ",", "\n", "clip_bboxes_to_img_dims", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates coco object from COCO formatted dict or COCO dataset file path.\n\n        Args:\n            coco_dict_or_path: dict/str or List[dict/str]\n                COCO formatted dict or COCO dataset file path\n                List of COCO formatted dict or COCO dataset file path\n            image_dir: str\n                Base file directory that contains dataset images. Required for merging and yolov5 conversion.\n            remapping_dict: dict\n                {1:0, 2:1} maps category id 1 to 0 and category id 2 to 1\n            ignore_negative_samples: bool\n                If True ignores images without annotations in all operations.\n            clip_bboxes_to_img_dims: bool = False\n                Limits bounding boxes to image dimensions.\n\n        Properties:\n            images: list of CocoImage\n            category_mapping: dict\n        \"\"\"", "\n", "# init coco object", "\n", "coco", "=", "cls", "(", "\n", "image_dir", "=", "image_dir", ",", "\n", "remapping_dict", "=", "remapping_dict", ",", "\n", "ignore_negative_samples", "=", "ignore_negative_samples", ",", "\n", "clip_bboxes_to_img_dims", "=", "clip_bboxes_to_img_dims", ",", "\n", ")", "\n", "\n", "if", "type", "(", "coco_dict_or_path", ")", "not", "in", "[", "str", ",", "dict", "]", ":", "\n", "            ", "raise", "TypeError", "(", "\"coco_dict_or_path should be a dict or str\"", ")", "\n", "\n", "# load coco dict if path is given", "\n", "", "if", "type", "(", "coco_dict_or_path", ")", "==", "str", ":", "\n", "            ", "coco_dict", "=", "load_json", "(", "coco_dict_or_path", ")", "\n", "", "else", ":", "\n", "            ", "coco_dict", "=", "coco_dict_or_path", "\n", "\n", "# arrange image id to annotation id mapping", "\n", "", "coco", ".", "add_categories_from_coco_category_list", "(", "coco_dict", "[", "\"categories\"", "]", ")", "\n", "image_id_to_annotation_list", "=", "get_imageid2annotationlist_mapping", "(", "coco_dict", ")", "\n", "category_mapping", "=", "coco", ".", "category_mapping", "\n", "\n", "# https://github.com/obss/sahi/issues/98", "\n", "image_id_set", ":", "Set", "=", "set", "(", ")", "\n", "\n", "for", "coco_image_dict", "in", "tqdm", "(", "coco_dict", "[", "\"images\"", "]", ",", "\"Loading coco annotations\"", ")", ":", "\n", "            ", "coco_image", "=", "CocoImage", ".", "from_coco_image_dict", "(", "coco_image_dict", ")", "\n", "image_id", "=", "coco_image_dict", "[", "\"id\"", "]", "\n", "# https://github.com/obss/sahi/issues/98", "\n", "if", "image_id", "in", "image_id_set", ":", "\n", "                ", "print", "(", "f\"duplicate image_id: {image_id}, will be ignored.\"", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                ", "image_id_set", ".", "add", "(", "image_id", ")", "\n", "# select annotations of the image", "\n", "", "annotation_list", "=", "image_id_to_annotation_list", "[", "image_id", "]", "\n", "for", "coco_annotation_dict", "in", "annotation_list", ":", "\n", "# apply category remapping if remapping_dict is provided", "\n", "                ", "if", "coco", ".", "remapping_dict", "is", "not", "None", ":", "\n", "# apply category remapping (id:id)", "\n", "                    ", "category_id", "=", "coco", ".", "remapping_dict", "[", "coco_annotation_dict", "[", "\"category_id\"", "]", "]", "\n", "# update category id", "\n", "coco_annotation_dict", "[", "\"category_id\"", "]", "=", "category_id", "\n", "", "else", ":", "\n", "                    ", "category_id", "=", "coco_annotation_dict", "[", "\"category_id\"", "]", "\n", "# get category name (id:name)", "\n", "", "category_name", "=", "category_mapping", "[", "category_id", "]", "\n", "coco_annotation", "=", "CocoAnnotation", ".", "from_coco_annotation_dict", "(", "\n", "category_name", "=", "category_name", ",", "annotation_dict", "=", "coco_annotation_dict", "\n", ")", "\n", "coco_image", ".", "add_annotation", "(", "coco_annotation", ")", "\n", "", "coco", ".", "add_image", "(", "coco_image", ")", "\n", "\n", "", "if", "clip_bboxes_to_img_dims", ":", "\n", "            ", "coco", "=", "coco", ".", "get_coco_with_clipped_bboxes", "(", ")", "\n", "", "return", "coco", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.json_categories": [[1074, 1080], ["categories.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "json_categories", "(", "self", ")", ":", "\n", "        ", "categories", "=", "[", "]", "\n", "for", "category", "in", "self", ".", "categories", ":", "\n", "            ", "categories", ".", "append", "(", "category", ".", "json", ")", "\n", "", "return", "categories", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.category_mapping": [[1081, 1087], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "category_mapping", "(", "self", ")", ":", "\n", "        ", "category_mapping", "=", "{", "}", "\n", "for", "category", "in", "self", ".", "categories", ":", "\n", "            ", "category_mapping", "[", "category", ".", "id", "]", "=", "category", ".", "name", "\n", "", "return", "category_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.json": [[1088, 1095], ["coco.create_coco_dict"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.create_coco_dict"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "return", "create_coco_dict", "(", "\n", "images", "=", "self", ".", "images", ",", "\n", "categories", "=", "self", ".", "json_categories", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", "image_id_setting", "=", "self", ".", "image_id_setting", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.prediction_array": [[1097, 1103], ["coco.create_coco_prediction_array"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.create_coco_prediction_array"], ["", "@", "property", "\n", "def", "prediction_array", "(", "self", ")", ":", "\n", "        ", "return", "create_coco_prediction_array", "(", "\n", "images", "=", "self", ".", "images", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", "image_id_setting", "=", "self", ".", "image_id_setting", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.stats": [[1105, 1110], ["coco.Coco.calculate_stats"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.calculate_stats"], ["", "@", "property", "\n", "def", "stats", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "_stats", ":", "\n", "            ", "self", ".", "calculate_stats", "(", ")", "\n", "", "return", "self", ".", "_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.calculate_stats": [[1111, 1182], ["len", "len", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "float", "float", "len", "dict", "len", "len", "collections.Counter", "collections.Counter"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "def", "calculate_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Iterates over all annotations and calculates total number of\n        \"\"\"", "\n", "# init all stats", "\n", "num_annotations", "=", "0", "\n", "num_images", "=", "len", "(", "self", ".", "images", ")", "\n", "num_negative_images", "=", "0", "\n", "num_categories", "=", "len", "(", "self", ".", "json_categories", ")", "\n", "category_name_to_zero", "=", "{", "category", "[", "\"name\"", "]", ":", "0", "for", "category", "in", "self", ".", "json_categories", "}", "\n", "category_name_to_inf", "=", "{", "category", "[", "\"name\"", "]", ":", "float", "(", "\"inf\"", ")", "for", "category", "in", "self", ".", "json_categories", "}", "\n", "num_images_per_category", "=", "copy", ".", "deepcopy", "(", "category_name_to_zero", ")", "\n", "num_annotations_per_category", "=", "copy", ".", "deepcopy", "(", "category_name_to_zero", ")", "\n", "min_annotation_area_per_category", "=", "copy", ".", "deepcopy", "(", "category_name_to_inf", ")", "\n", "max_annotation_area_per_category", "=", "copy", ".", "deepcopy", "(", "category_name_to_zero", ")", "\n", "min_num_annotations_in_image", "=", "float", "(", "\"inf\"", ")", "\n", "max_num_annotations_in_image", "=", "0", "\n", "total_annotation_area", "=", "0", "\n", "min_annotation_area", "=", "1e10", "\n", "max_annotation_area", "=", "0", "\n", "for", "image", "in", "self", ".", "images", ":", "\n", "            ", "image_contains_category", "=", "{", "}", "\n", "for", "annotation", "in", "image", ".", "annotations", ":", "\n", "                ", "annotation_area", "=", "annotation", ".", "area", "\n", "total_annotation_area", "+=", "annotation_area", "\n", "num_annotations_per_category", "[", "annotation", ".", "category_name", "]", "+=", "1", "\n", "image_contains_category", "[", "annotation", ".", "category_name", "]", "=", "1", "\n", "# update min&max annotation area", "\n", "if", "annotation_area", ">", "max_annotation_area", ":", "\n", "                    ", "max_annotation_area", "=", "annotation_area", "\n", "", "if", "annotation_area", "<", "min_annotation_area", ":", "\n", "                    ", "min_annotation_area", "=", "annotation_area", "\n", "", "if", "annotation_area", ">", "max_annotation_area_per_category", "[", "annotation", ".", "category_name", "]", ":", "\n", "                    ", "max_annotation_area_per_category", "[", "annotation", ".", "category_name", "]", "=", "annotation_area", "\n", "", "if", "annotation_area", "<", "min_annotation_area_per_category", "[", "annotation", ".", "category_name", "]", ":", "\n", "                    ", "min_annotation_area_per_category", "[", "annotation", ".", "category_name", "]", "=", "annotation_area", "\n", "# update num_negative_images", "\n", "", "", "if", "len", "(", "image", ".", "annotations", ")", "==", "0", ":", "\n", "                ", "num_negative_images", "+=", "1", "\n", "# update num_annotations", "\n", "", "num_annotations", "+=", "len", "(", "image", ".", "annotations", ")", "\n", "# update num_images_per_category", "\n", "num_images_per_category", "=", "dict", "(", "Counter", "(", "num_images_per_category", ")", "+", "Counter", "(", "image_contains_category", ")", ")", "\n", "# update min&max_num_annotations_in_image", "\n", "num_annotations_in_image", "=", "len", "(", "image", ".", "annotations", ")", "\n", "if", "num_annotations_in_image", ">", "max_num_annotations_in_image", ":", "\n", "                ", "max_num_annotations_in_image", "=", "num_annotations_in_image", "\n", "", "if", "num_annotations_in_image", "<", "min_num_annotations_in_image", ":", "\n", "                ", "min_num_annotations_in_image", "=", "num_annotations_in_image", "\n", "", "", "if", "(", "num_images", "-", "num_negative_images", ")", ">", "0", ":", "\n", "            ", "avg_num_annotations_in_image", "=", "num_annotations", "/", "(", "num_images", "-", "num_negative_images", ")", "\n", "avg_annotation_area", "=", "total_annotation_area", "/", "num_annotations", "\n", "", "else", ":", "\n", "            ", "avg_num_annotations_in_image", "=", "0", "\n", "avg_annotation_area", "=", "0", "\n", "\n", "", "self", ".", "_stats", "=", "{", "\n", "\"num_images\"", ":", "num_images", ",", "\n", "\"num_annotations\"", ":", "num_annotations", ",", "\n", "\"num_categories\"", ":", "num_categories", ",", "\n", "\"num_negative_images\"", ":", "num_negative_images", ",", "\n", "\"num_images_per_category\"", ":", "num_images_per_category", ",", "\n", "\"num_annotations_per_category\"", ":", "num_annotations_per_category", ",", "\n", "\"min_num_annotations_in_image\"", ":", "min_num_annotations_in_image", ",", "\n", "\"max_num_annotations_in_image\"", ":", "max_num_annotations_in_image", ",", "\n", "\"avg_num_annotations_in_image\"", ":", "avg_num_annotations_in_image", ",", "\n", "\"min_annotation_area\"", ":", "min_annotation_area", ",", "\n", "\"max_annotation_area\"", ":", "max_annotation_area", ",", "\n", "\"avg_annotation_area\"", ":", "avg_annotation_area", ",", "\n", "\"min_annotation_area_per_category\"", ":", "min_annotation_area_per_category", ",", "\n", "\"max_annotation_area_per_category\"", ":", "max_annotation_area_per_category", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.split_coco_as_train_val": [[1184, 1227], ["numpy.random.seed", "len", "copy.deepcopy", "numpy.random.shuffle", "int", "coco.Coco", "coco.Coco"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "def", "split_coco_as_train_val", "(", "self", ",", "train_split_rate", "=", "0.9", ",", "numpy_seed", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Split images into train-val and returns them as sahi.utils.coco.Coco objects.\n\n        Args:\n            train_split_rate: float\n            numpy_seed: int\n                To fix the numpy seed.\n\n        Returns:\n            result : dict\n                {\n                    \"train_coco\": \"\",\n                    \"val_coco\": \"\",\n                }\n        \"\"\"", "\n", "# fix numpy numpy seed", "\n", "np", ".", "random", ".", "seed", "(", "numpy_seed", ")", "\n", "\n", "# divide images", "\n", "num_images", "=", "len", "(", "self", ".", "images", ")", "\n", "shuffled_images", "=", "copy", ".", "deepcopy", "(", "self", ".", "images", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "shuffled_images", ")", "\n", "num_train", "=", "int", "(", "num_images", "*", "train_split_rate", ")", "\n", "train_images", "=", "shuffled_images", "[", ":", "num_train", "]", "\n", "val_images", "=", "shuffled_images", "[", "num_train", ":", "]", "\n", "\n", "# form train val coco objects", "\n", "train_coco", "=", "Coco", "(", "\n", "name", "=", "self", ".", "name", "if", "self", ".", "name", "else", "\"split\"", "+", "\"_train\"", ",", "\n", "image_dir", "=", "self", ".", "image_dir", ",", "\n", ")", "\n", "train_coco", ".", "images", "=", "train_images", "\n", "train_coco", ".", "categories", "=", "self", ".", "categories", "\n", "\n", "val_coco", "=", "Coco", "(", "name", "=", "self", ".", "name", "if", "self", ".", "name", "else", "\"split\"", "+", "\"_val\"", ",", "image_dir", "=", "self", ".", "image_dir", ")", "\n", "val_coco", ".", "images", "=", "val_images", "\n", "val_coco", ".", "categories", "=", "self", ".", "categories", "\n", "\n", "# return result", "\n", "return", "{", "\n", "\"train_coco\"", ":", "train_coco", ",", "\n", "\"val_coco\"", ":", "val_coco", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.export_as_yolov5": [[1229, 1315], ["str", "coco.Coco.split_coco_as_train_val", "train_dir.mkdir", "val_dir.mkdir", "coco.export_yolov5_images_and_txts_from_coco_object", "coco.export_yolov5_images_and_txts_from_coco_object", "str", "str", "len", "list", "open", "yaml.dump", "ImportError", "pathlib.Path", "pathlib.Path", "coco.Coco.category_mapping.values", "pathlib.Path", "ValueError", "os.path.abspath", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.split_coco_as_train_val", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_yolov5_images_and_txts_from_coco_object", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_yolov5_images_and_txts_from_coco_object"], ["", "def", "export_as_yolov5", "(", "self", ",", "output_dir", ",", "train_split_rate", "=", "1", ",", "numpy_seed", "=", "0", ",", "mp", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Exports current COCO dataset in ultralytics/yolov5 format.\n        Creates train val folders with image symlinks and txt files and a data yaml file.\n\n        Args:\n            output_dir: str\n                Export directory.\n            train_split_rate: float\n                If given 1, will be exported as train split.\n                If given 0, will be exported as val split.\n                If in between 0-1, both train/val splits will be calculated and exported.\n            numpy_seed: int\n                To fix the numpy seed.\n            mp: bool\n                If True, multiprocess mode is on.\n                Should be called in 'if __name__ == __main__:' block.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please run \"pip install -U pyyaml\" '", "\"to install yaml first for yolov5 formatted exporting.\"", "\n", ")", "\n", "\n", "# set split_mode", "\n", "", "if", "0", "<", "train_split_rate", "and", "train_split_rate", "<", "1", ":", "\n", "            ", "split_mode", "=", "\"TRAINVAL\"", "\n", "", "elif", "train_split_rate", "==", "0", ":", "\n", "            ", "split_mode", "=", "\"VAL\"", "\n", "", "elif", "train_split_rate", "==", "1", ":", "\n", "            ", "split_mode", "=", "\"TRAIN\"", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"train_split_rate cannot be <0 or >1\"", ")", "\n", "\n", "# split dataset", "\n", "", "if", "split_mode", "==", "\"TRAINVAL\"", ":", "\n", "            ", "result", "=", "self", ".", "split_coco_as_train_val", "(", "\n", "train_split_rate", "=", "train_split_rate", ",", "\n", "numpy_seed", "=", "numpy_seed", ",", "\n", ")", "\n", "train_coco", "=", "result", "[", "\"train_coco\"", "]", "\n", "val_coco", "=", "result", "[", "\"val_coco\"", "]", "\n", "", "elif", "split_mode", "==", "\"TRAIN\"", ":", "\n", "            ", "train_coco", "=", "self", "\n", "val_coco", "=", "None", "\n", "", "elif", "split_mode", "==", "\"VAL\"", ":", "\n", "            ", "train_coco", "=", "None", "\n", "val_coco", "=", "self", "\n", "\n", "# create train val image dirs", "\n", "", "train_dir", "=", "\"\"", "\n", "val_dir", "=", "\"\"", "\n", "if", "split_mode", "in", "[", "\"TRAINVAL\"", ",", "\"TRAIN\"", "]", ":", "\n", "            ", "train_dir", "=", "Path", "(", "os", ".", "path", ".", "abspath", "(", "output_dir", ")", ")", "/", "\"train/\"", "\n", "train_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# create dir", "\n", "", "if", "split_mode", "in", "[", "\"TRAINVAL\"", ",", "\"VAL\"", "]", ":", "\n", "            ", "val_dir", "=", "Path", "(", "os", ".", "path", ".", "abspath", "(", "output_dir", ")", ")", "/", "\"val/\"", "\n", "val_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# create dir", "\n", "\n", "# create image symlinks and annotation txts", "\n", "", "if", "split_mode", "in", "[", "\"TRAINVAL\"", ",", "\"TRAIN\"", "]", ":", "\n", "            ", "export_yolov5_images_and_txts_from_coco_object", "(", "\n", "output_dir", "=", "train_dir", ",", "\n", "coco", "=", "train_coco", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", "mp", "=", "mp", ",", "\n", ")", "\n", "", "if", "split_mode", "in", "[", "\"TRAINVAL\"", ",", "\"VAL\"", "]", ":", "\n", "            ", "export_yolov5_images_and_txts_from_coco_object", "(", "\n", "output_dir", "=", "val_dir", ",", "\n", "coco", "=", "val_coco", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", "mp", "=", "mp", ",", "\n", ")", "\n", "\n", "# create yolov5 data yaml", "\n", "", "data", "=", "{", "\n", "\"train\"", ":", "str", "(", "train_dir", ")", ",", "\n", "\"val\"", ":", "str", "(", "val_dir", ")", ",", "\n", "\"nc\"", ":", "len", "(", "self", ".", "category_mapping", ")", ",", "\n", "\"names\"", ":", "list", "(", "self", ".", "category_mapping", ".", "values", "(", ")", ")", ",", "\n", "}", "\n", "yaml_path", "=", "str", "(", "Path", "(", "output_dir", ")", "/", "\"data.yml\"", ")", "\n", "with", "open", "(", "yaml_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "yaml", ".", "dump", "(", "data", ",", "outfile", ",", "default_flow_style", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_subsampled_coco": [[1316, 1384], ["coco.Coco", "Coco.add_categories_from_coco_category_list", "range", "range", "len", "coco.Coco.add_image", "collections.defaultdict", "collections.defaultdict", "len", "coco.Coco.add_image", "images_that_contain_category.append", "images_that_doesnt_contain_category.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_categories_from_coco_category_list", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image"], ["", "", "def", "get_subsampled_coco", "(", "self", ",", "subsample_ratio", ":", "int", "=", "2", ",", "category_id", ":", "int", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Subsamples images with subsample_ratio and returns as sahi.utils.coco.Coco object.\n\n        Args:\n            subsample_ratio: int\n                10 means take every 10th image with its annotations\n            category_id: int\n                subsample only images containing given category_id, if -1 then subsamples negative samples\n        Returns:\n            subsampled_coco: sahi.utils.coco.Coco\n        \"\"\"", "\n", "subsampled_coco", "=", "Coco", "(", "\n", "name", "=", "self", ".", "name", ",", "\n", "image_dir", "=", "self", ".", "image_dir", ",", "\n", "remapping_dict", "=", "self", ".", "remapping_dict", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", ")", "\n", "subsampled_coco", ".", "add_categories_from_coco_category_list", "(", "self", ".", "json_categories", ")", "\n", "\n", "if", "category_id", "is", "not", "None", ":", "\n", "# get images that contain given category id", "\n", "            ", "images_that_contain_category", ":", "List", "[", "CocoImage", "]", "=", "[", "]", "\n", "for", "image", "in", "self", ".", "images", ":", "\n", "                ", "category_id_to_contains", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "annotation", ":", "CocoAnnotation", "\n", "for", "annotation", "in", "image", ".", "annotations", ":", "\n", "                    ", "category_id_to_contains", "[", "annotation", ".", "category_id", "]", "=", "1", "\n", "", "if", "category_id_to_contains", "[", "category_id", "]", ":", "\n", "                    ", "add_this_image", "=", "True", "\n", "", "elif", "category_id", "==", "-", "1", "and", "len", "(", "image", ".", "annotations", ")", "==", "0", ":", "\n", "# if category_id is given as -1, select negative samples", "\n", "                    ", "add_this_image", "=", "True", "\n", "", "else", ":", "\n", "                    ", "add_this_image", "=", "False", "\n", "\n", "", "if", "add_this_image", ":", "\n", "                    ", "images_that_contain_category", ".", "append", "(", "image", ")", "\n", "\n", "# get images that does not contain given category id", "\n", "", "", "images_that_doesnt_contain_category", ":", "List", "[", "CocoImage", "]", "=", "[", "]", "\n", "for", "image", "in", "self", ".", "images", ":", "\n", "                ", "category_id_to_contains", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "annotation", ":", "CocoAnnotation", "\n", "for", "annotation", "in", "image", ".", "annotations", ":", "\n", "                    ", "category_id_to_contains", "[", "annotation", ".", "category_id", "]", "=", "1", "\n", "", "if", "category_id_to_contains", "[", "category_id", "]", ":", "\n", "                    ", "add_this_image", "=", "False", "\n", "", "elif", "category_id", "==", "-", "1", "and", "len", "(", "image", ".", "annotations", ")", "==", "0", ":", "\n", "# if category_id is given as -1, dont select negative samples", "\n", "                    ", "add_this_image", "=", "False", "\n", "", "else", ":", "\n", "                    ", "add_this_image", "=", "True", "\n", "\n", "", "if", "add_this_image", ":", "\n", "                    ", "images_that_doesnt_contain_category", ".", "append", "(", "image", ")", "\n", "\n", "", "", "", "if", "category_id", ":", "\n", "            ", "selected_images", "=", "images_that_contain_category", "\n", "# add images that does not contain given category without subsampling", "\n", "for", "image_ind", "in", "range", "(", "len", "(", "images_that_doesnt_contain_category", ")", ")", ":", "\n", "                ", "subsampled_coco", ".", "add_image", "(", "images_that_doesnt_contain_category", "[", "image_ind", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "selected_images", "=", "self", ".", "images", "\n", "", "for", "image_ind", "in", "range", "(", "0", ",", "len", "(", "selected_images", ")", ",", "subsample_ratio", ")", ":", "\n", "            ", "subsampled_coco", ".", "add_image", "(", "selected_images", "[", "image_ind", "]", ")", "\n", "\n", "", "return", "subsampled_coco", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_upsampled_coco": [[1385, 1429], ["coco.Coco", "Coco.add_categories_from_coco_category_list", "range", "range", "len", "collections.defaultdict", "coco.Coco.add_image", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_categories_from_coco_category_list", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image"], ["", "def", "get_upsampled_coco", "(", "self", ",", "upsample_ratio", ":", "int", "=", "2", ",", "category_id", ":", "int", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Upsamples images with upsample_ratio and returns as sahi.utils.coco.Coco object.\n\n        Args:\n            upsample_ratio: int\n                10 means copy each sample 10 times\n            category_id: int\n                upsample only images containing given category_id, if -1 then upsamples negative samples\n        Returns:\n            upsampled_coco: sahi.utils.coco.Coco\n        \"\"\"", "\n", "upsampled_coco", "=", "Coco", "(", "\n", "name", "=", "self", ".", "name", ",", "\n", "image_dir", "=", "self", ".", "image_dir", ",", "\n", "remapping_dict", "=", "self", ".", "remapping_dict", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", ")", "\n", "upsampled_coco", ".", "add_categories_from_coco_category_list", "(", "self", ".", "json_categories", ")", "\n", "for", "ind", "in", "range", "(", "upsample_ratio", ")", ":", "\n", "            ", "for", "image_ind", "in", "range", "(", "len", "(", "self", ".", "images", ")", ")", ":", "\n", "# calculate add_this_image", "\n", "                ", "if", "category_id", "is", "not", "None", ":", "\n", "                    ", "category_id_to_contains", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "annotation", ":", "CocoAnnotation", "\n", "for", "annotation", "in", "self", ".", "images", "[", "image_ind", "]", ".", "annotations", ":", "\n", "                        ", "category_id_to_contains", "[", "annotation", ".", "category_id", "]", "=", "1", "\n", "", "if", "category_id_to_contains", "[", "category_id", "]", ":", "\n", "                        ", "add_this_image", "=", "True", "\n", "", "elif", "category_id", "==", "-", "1", "and", "len", "(", "self", ".", "images", "[", "image_ind", "]", ".", "annotations", ")", "==", "0", ":", "\n", "# if category_id is given as -1, select negative samples", "\n", "                        ", "add_this_image", "=", "True", "\n", "", "elif", "ind", "==", "0", ":", "\n", "# in first iteration add all images", "\n", "                        ", "add_this_image", "=", "True", "\n", "", "else", ":", "\n", "                        ", "add_this_image", "=", "False", "\n", "", "", "else", ":", "\n", "                    ", "add_this_image", "=", "True", "\n", "\n", "", "if", "add_this_image", ":", "\n", "                    ", "upsampled_coco", ".", "add_image", "(", "self", ".", "images", "[", "image_ind", "]", ")", "\n", "\n", "", "", "", "return", "upsampled_coco", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_area_filtered_coco": [[1430, 1469], ["float", "coco.Coco", "Coco.add_categories_from_coco_category_list", "coco.Coco.add_image", "intervals_per_category.keys"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_categories_from_coco_category_list", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image"], ["", "def", "get_area_filtered_coco", "(", "self", ",", "min", "=", "0", ",", "max", "=", "float", "(", "\"inf\"", ")", ",", "intervals_per_category", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Filters annotation areas with given min and max values and returns remaining\n        images as sahi.utils.coco.Coco object.\n\n        Args:\n            min: int\n                minimum allowed area\n            max: int\n                maximum allowed area\n            intervals_per_category: dict of dicts\n                {\n                    \"human\": {\"min\": 20, \"max\": 10000},\n                    \"vehicle\": {\"min\": 50, \"max\": 15000},\n                }\n        Returns:\n            area_filtered_coco: sahi.utils.coco.Coco\n        \"\"\"", "\n", "area_filtered_coco", "=", "Coco", "(", "\n", "name", "=", "self", ".", "name", ",", "\n", "image_dir", "=", "self", ".", "image_dir", ",", "\n", "remapping_dict", "=", "self", ".", "remapping_dict", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", ")", "\n", "area_filtered_coco", ".", "add_categories_from_coco_category_list", "(", "self", ".", "json_categories", ")", "\n", "for", "image", "in", "self", ".", "images", ":", "\n", "            ", "is_valid_image", "=", "True", "\n", "for", "annotation", "in", "image", ".", "annotations", ":", "\n", "                ", "if", "intervals_per_category", "is", "not", "None", "and", "annotation", ".", "category_name", "in", "intervals_per_category", ".", "keys", "(", ")", ":", "\n", "                    ", "category_based_min", "=", "intervals_per_category", "[", "annotation", ".", "category_name", "]", "[", "\"min\"", "]", "\n", "category_based_max", "=", "intervals_per_category", "[", "annotation", ".", "category_name", "]", "[", "\"max\"", "]", "\n", "if", "annotation", ".", "area", "<", "category_based_min", "or", "annotation", ".", "area", ">", "category_based_max", ":", "\n", "                        ", "is_valid_image", "=", "False", "\n", "", "", "if", "annotation", ".", "area", "<", "min", "or", "annotation", ".", "area", ">", "max", ":", "\n", "                    ", "is_valid_image", "=", "False", "\n", "", "", "if", "is_valid_image", ":", "\n", "                ", "area_filtered_coco", ".", "add_image", "(", "image", ")", "\n", "\n", "", "", "return", "area_filtered_coco", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_coco_with_clipped_bboxes": [[1470, 1505], ["Coco.Coco", "Coco.add_categories_from_coco_category_list", "Coco.CocoImage", "Coco.Coco.add_image", "annotation_inside_slice", "coco_ann.get_sliced_coco_annotation", "sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "Coco.CocoAnnotation", "Coco.CocoImage.add_annotation"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_categories_from_coco_category_list", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.annotation_inside_slice", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoAnnotation.get_sliced_coco_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation"], ["", "def", "get_coco_with_clipped_bboxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Limits overflowing bounding boxes to image dimensions.\n        \"\"\"", "\n", "from", "sahi", ".", "slicing", "import", "annotation_inside_slice", "\n", "\n", "coco", "=", "Coco", "(", "\n", "name", "=", "self", ".", "name", ",", "\n", "image_dir", "=", "self", ".", "image_dir", ",", "\n", "remapping_dict", "=", "self", ".", "remapping_dict", ",", "\n", "ignore_negative_samples", "=", "self", ".", "ignore_negative_samples", ",", "\n", ")", "\n", "coco", ".", "add_categories_from_coco_category_list", "(", "self", ".", "json_categories", ")", "\n", "\n", "for", "coco_img", "in", "self", ".", "images", ":", "\n", "            ", "img_dims", "=", "[", "0", ",", "0", ",", "coco_img", ".", "width", ",", "coco_img", ".", "height", "]", "\n", "coco_image", "=", "CocoImage", "(", "\n", "file_name", "=", "coco_img", ".", "file_name", ",", "height", "=", "coco_img", ".", "height", ",", "width", "=", "coco_img", ".", "width", ",", "id", "=", "coco_img", ".", "id", "\n", ")", "\n", "for", "coco_ann", "in", "coco_img", ".", "annotations", ":", "\n", "                ", "ann_dict", ":", "Dict", "=", "coco_ann", ".", "json", "\n", "if", "annotation_inside_slice", "(", "annotation", "=", "ann_dict", ",", "slice_bbox", "=", "img_dims", ")", ":", "\n", "                    ", "shapely_ann", "=", "coco_ann", ".", "get_sliced_coco_annotation", "(", "img_dims", ")", "\n", "bbox", "=", "ShapelyAnnotation", ".", "to_coco_bbox", "(", "shapely_ann", ".", "_shapely_annotation", ")", "\n", "coco_ann_from_shapely", "=", "CocoAnnotation", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "coco_ann", ".", "category_id", ",", "\n", "category_name", "=", "coco_ann", ".", "category_name", ",", "\n", "image_id", "=", "coco_ann", ".", "image_id", ",", "\n", ")", "\n", "coco_image", ".", "add_annotation", "(", "coco_ann_from_shapely", ")", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "coco", ".", "add_image", "(", "coco_image", ")", "\n", "", "return", "coco", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.DatasetClassCounts.frequencies": [[2051, 2054], ["coco.DatasetClassCounts.counts.items"], "methods", ["None"], ["def", "frequencies", "(", "self", ")", ":", "\n", "        ", "\"\"\"calculates the frequenct of images that contain each category\"\"\"", "\n", "return", "{", "cid", ":", "count", "/", "self", ".", "total_images", "for", "cid", ",", "count", "in", "self", ".", "counts", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.DatasetClassCounts.__add__": [[2055, 2064], ["coco.DatasetClassCounts.counts.items", "coco.DatasetClassCounts", "set", "set", "o.counts.keys", "coco.DatasetClassCounts.counts.keys", "o.counts.get"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "o", ")", ":", "\n", "        ", "total", "=", "self", ".", "total_images", "+", "o", ".", "total_images", "\n", "exclusive_keys", "=", "set", "(", "o", ".", "counts", ".", "keys", "(", ")", ")", "-", "set", "(", "self", ".", "counts", ".", "keys", "(", ")", ")", "\n", "counts", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "counts", ".", "items", "(", ")", ":", "\n", "            ", "counts", "[", "k", "]", "=", "v", "+", "o", ".", "counts", ".", "get", "(", "k", ",", "0", ")", "\n", "", "for", "k", "in", "exclusive_keys", ":", "\n", "            ", "counts", "[", "k", "]", "=", "o", ".", "counts", "[", "k", "]", "\n", "", "return", "DatasetClassCounts", "(", "counts", ",", "total", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.__init__": [[2093, 2107], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "None", ",", "remapping_dict", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoVid object.\n\n        Args:\n            name: str\n                Name of the CocoVid dataset, it determines exported json name.\n            remapping_dict: dict\n                {1:0, 2:1} maps category id 1 to 0 and category id 2 to 1\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "remapping_dict", "=", "remapping_dict", "\n", "self", ".", "categories", "=", "[", "]", "\n", "self", ".", "videos", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_categories_from_coco_category_list": [[2108, 2128], ["coco.CocoVid.add_category", "coco.CocoVid.remapping_dict.keys", "CocoCategory.from_coco_category"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_category", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.from_coco_category"], ["", "def", "add_categories_from_coco_category_list", "(", "self", ",", "coco_category_list", ")", ":", "\n", "        ", "\"\"\"\n        Creates CocoCategory object using coco category list.\n\n        Args:\n            coco_category_list: List[Dict]\n                [\n                    {\"supercategory\": \"person\", \"id\": 1, \"name\": \"person\"},\n                    {\"supercategory\": \"vehicle\", \"id\": 2, \"name\": \"bicycle\"}\n                ]\n        \"\"\"", "\n", "\n", "for", "coco_category", "in", "coco_category_list", ":", "\n", "            ", "if", "self", ".", "remapping_dict", "is", "not", "None", ":", "\n", "                ", "for", "source_id", "in", "self", ".", "remapping_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "coco_category", "[", "\"id\"", "]", "==", "source_id", ":", "\n", "                        ", "target_id", "=", "self", ".", "remapping_dict", "[", "source_id", "]", "\n", "coco_category", "[", "\"id\"", "]", "=", "target_id", "\n", "\n", "", "", "", "self", ".", "add_category", "(", "CocoCategory", ".", "from_coco_category", "(", "coco_category", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_category": [[2129, 2140], ["coco.CocoVid.categories.append", "type", "TypeError"], "methods", ["None"], ["", "", "def", "add_category", "(", "self", ",", "category", ")", ":", "\n", "        ", "\"\"\"\n        Adds category to this CocoVid instance\n\n        Args:\n            category: CocoCategory\n        \"\"\"", "\n", "\n", "if", "type", "(", "category", ")", "!=", "CocoCategory", ":", "\n", "            ", "raise", "TypeError", "(", "\"category must be a CocoCategory instance\"", ")", "\n", "", "self", ".", "categories", ".", "append", "(", "category", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.json_categories": [[2141, 2147], ["categories.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "json_categories", "(", "self", ")", ":", "\n", "        ", "categories", "=", "[", "]", "\n", "for", "category", "in", "self", ".", "categories", ":", "\n", "            ", "categories", ".", "append", "(", "category", ".", "json", ")", "\n", "", "return", "categories", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.category_mapping": [[2148, 2154], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "category_mapping", "(", "self", ")", ":", "\n", "        ", "category_mapping", "=", "{", "}", "\n", "for", "category", "in", "self", ".", "categories", ":", "\n", "            ", "category_mapping", "[", "category", ".", "id", "]", "=", "category", ".", "name", "\n", "", "return", "category_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_video": [[2155, 2166], ["coco.CocoVid.videos.append", "type", "TypeError"], "methods", ["None"], ["", "def", "add_video", "(", "self", ",", "video", ")", ":", "\n", "        ", "\"\"\"\n        Adds video to this CocoVid instance\n\n        Args:\n            video: CocoVideo\n        \"\"\"", "\n", "\n", "if", "type", "(", "video", ")", "!=", "CocoVideo", ":", "\n", "            ", "raise", "TypeError", "(", "\"video must be a CocoVideo instance\"", ")", "\n", "", "self", ".", "videos", ".", "append", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.json": [[2167, 2209], ["coco_dict[].append", "set", "copy.deepcopy", "len", "coco_dict[].append", "copy.deepcopy", "copy.deepcopy", "set.add", "coco_dict[].append", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "@", "property", "\n", "def", "json", "(", "self", ")", ":", "\n", "        ", "coco_dict", "=", "{", "\n", "\"videos\"", ":", "[", "]", ",", "\n", "\"images\"", ":", "[", "]", ",", "\n", "\"annotations\"", ":", "[", "]", ",", "\n", "\"categories\"", ":", "self", ".", "json_categories", ",", "\n", "}", "\n", "annotation_id", "=", "1", "\n", "image_id", "=", "1", "\n", "video_id", "=", "1", "\n", "global_instance_id", "=", "1", "\n", "for", "coco_video", "in", "self", ".", "videos", ":", "\n", "            ", "coco_video", ".", "id", "=", "video_id", "\n", "coco_dict", "[", "\"videos\"", "]", ".", "append", "(", "coco_video", ".", "json", ")", "\n", "\n", "frame_id", "=", "0", "\n", "instance_id_set", "=", "set", "(", ")", "\n", "for", "cocovid_image", "in", "coco_video", ".", "images", ":", "\n", "                ", "cocovid_image", ".", "id", "=", "image_id", "\n", "cocovid_image", ".", "frame_id", "=", "frame_id", "\n", "cocovid_image", ".", "video_id", "=", "coco_video", ".", "id", "\n", "coco_dict", "[", "\"images\"", "]", ".", "append", "(", "cocovid_image", ".", "json", ")", "\n", "\n", "for", "cocovid_annotation", "in", "cocovid_image", ".", "annotations", ":", "\n", "                    ", "instance_id_set", ".", "add", "(", "cocovid_annotation", ".", "instance_id", ")", "\n", "cocovid_annotation", ".", "instance_id", "+=", "global_instance_id", "\n", "\n", "cocovid_annotation", ".", "id", "=", "annotation_id", "\n", "cocovid_annotation", ".", "image_id", "=", "cocovid_image", ".", "id", "\n", "coco_dict", "[", "\"annotations\"", "]", ".", "append", "(", "cocovid_annotation", ".", "json", ")", "\n", "\n", "# increment annotation_id", "\n", "annotation_id", "=", "copy", ".", "deepcopy", "(", "annotation_id", "+", "1", ")", "\n", "# increment image_id and frame_id", "\n", "", "image_id", "=", "copy", ".", "deepcopy", "(", "image_id", "+", "1", ")", "\n", "frame_id", "=", "copy", ".", "deepcopy", "(", "frame_id", "+", "1", ")", "\n", "# increment video_id and global_instance_id", "\n", "", "video_id", "=", "copy", ".", "deepcopy", "(", "video_id", "+", "1", ")", "\n", "global_instance_id", "+=", "len", "(", "instance_id_set", ")", "\n", "\n", "", "return", "coco_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_yolov5_images_and_txts_from_coco_object": [[1507, 1535], ["print", "tqdm.tqdm", "multiprocessing.Pool", "pool.starmap", "coco.export_single_yolov5_image_and_corresponding_txt", "tqdm.tqdm", "len"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_single_yolov5_image_and_corresponding_txt"], ["", "", "def", "export_yolov5_images_and_txts_from_coco_object", "(", "output_dir", ",", "coco", ",", "ignore_negative_samples", "=", "False", ",", "mp", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Creates image symlinks and annotation txts in yolo format from coco dataset.\n\n    Args:\n        output_dir: str\n            Export directory.\n        coco: sahi.utils.coco.Coco\n            Initialized Coco object that contains images and categories.\n        ignore_negative_samples: bool\n            If True ignores images without annotations in all operations.\n        mp: bool\n            If True, multiprocess mode is on.\n            Should be called in 'if __name__ == __main__:' block.\n    \"\"\"", "\n", "\n", "print", "(", "\"generating image symlinks and annotation files for yolov5...\"", ")", ",", "\n", "if", "mp", ":", "\n", "        ", "with", "Pool", "(", "processes", "=", "48", ")", "as", "pool", ":", "\n", "            ", "args", "=", "[", "(", "coco_image", ",", "coco", ".", "image_dir", ",", "output_dir", ",", "ignore_negative_samples", ")", "for", "coco_image", "in", "coco", ".", "images", "]", "\n", "pool", ".", "starmap", "(", "\n", "export_single_yolov5_image_and_corresponding_txt", ",", "\n", "tqdm", "(", "args", ",", "total", "=", "len", "(", "args", ")", ")", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "coco_image", "in", "tqdm", "(", "coco", ".", "images", ")", ":", "\n", "            ", "export_single_yolov5_image_and_corresponding_txt", "(", "\n", "coco_image", ",", "coco", ".", "image_dir", ",", "output_dir", ",", "ignore_negative_samples", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_single_yolov5_image_and_corresponding_txt": [[1538, 1608], ["pathlib.Path().is_file", "str", "copy.deepcopy", "pathlib.Path().is_file", "os.symlink", "str.replace", "len", "print", "os.path.abspath", "os.path.abspath", "str", "pathlib.Path", "open", "pathlib.Path", "print", "pathlib.Path", "ValueError", "str", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "str", "outfile.write", "pathlib.Path", "pathlib.Path", "pathlib.Path", "str", "str"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "", "", "def", "export_single_yolov5_image_and_corresponding_txt", "(", "\n", "coco_image", ",", "coco_image_dir", ",", "output_dir", ",", "ignore_negative_samples", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Generates yolov5 formatted image symlink and annotation txt file.\n\n    Args:\n        coco_image: sahi.utils.coco.CocoImage\n        coco_image_dir: str\n        output_dir: str\n            Export directory.\n        ignore_negative_samples: bool\n            If True ignores images without annotations in all operations.\n    \"\"\"", "\n", "if", "not", "ignore_negative_samples", "or", "len", "(", "coco_image", ".", "annotations", ")", ">", "0", ":", "\n", "# skip images without suffix", "\n", "# https://github.com/obss/sahi/issues/114", "\n", "        ", "if", "Path", "(", "coco_image", ".", "file_name", ")", ".", "suffix", "==", "\"\"", ":", "\n", "            ", "print", "(", "f\"image file has no suffix, skipping it: '{coco_image.file_name}'\"", ")", "\n", "return", "\n", "", "elif", "Path", "(", "coco_image", ".", "file_name", ")", ".", "suffix", "in", "[", "\".txt\"", "]", ":", "# TODO: extend this list", "\n", "            ", "print", "(", "f\"image file has incorrect suffix, skipping it: '{coco_image.file_name}'\"", ")", "\n", "return", "\n", "# set coco and yolo image paths", "\n", "", "if", "Path", "(", "coco_image", ".", "file_name", ")", ".", "is_file", "(", ")", ":", "\n", "            ", "coco_image_path", "=", "os", ".", "path", ".", "abspath", "(", "coco_image", ".", "file_name", ")", "\n", "", "else", ":", "\n", "            ", "if", "coco_image_dir", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"You have to specify image_dir of Coco object for yolov5 conversion.\"", ")", "\n", "\n", "", "coco_image_path", "=", "os", ".", "path", ".", "abspath", "(", "str", "(", "Path", "(", "coco_image_dir", ")", "/", "coco_image", ".", "file_name", ")", ")", "\n", "\n", "", "yolo_image_path_temp", "=", "str", "(", "Path", "(", "output_dir", ")", "/", "Path", "(", "coco_image", ".", "file_name", ")", ".", "name", ")", "\n", "# increment target file name if already present", "\n", "yolo_image_path", "=", "copy", ".", "deepcopy", "(", "yolo_image_path_temp", ")", "\n", "name_increment", "=", "2", "\n", "while", "Path", "(", "yolo_image_path", ")", ".", "is_file", "(", ")", ":", "\n", "            ", "parent_dir", "=", "Path", "(", "yolo_image_path_temp", ")", ".", "parent", "\n", "filename", "=", "Path", "(", "yolo_image_path_temp", ")", ".", "stem", "\n", "filesuffix", "=", "Path", "(", "yolo_image_path_temp", ")", ".", "suffix", "\n", "filename", "=", "filename", "+", "\"_\"", "+", "str", "(", "name_increment", ")", "\n", "yolo_image_path", "=", "str", "(", "parent_dir", "/", "(", "filename", "+", "filesuffix", ")", ")", "\n", "name_increment", "+=", "1", "\n", "# create a symbolic link pointing to coco_image_path named yolo_image_path", "\n", "", "os", ".", "symlink", "(", "coco_image_path", ",", "yolo_image_path", ")", "\n", "# calculate annotation normalization ratios", "\n", "width", "=", "coco_image", ".", "width", "\n", "height", "=", "coco_image", ".", "height", "\n", "dw", "=", "1.0", "/", "(", "width", ")", "\n", "dh", "=", "1.0", "/", "(", "height", ")", "\n", "# set annotation filepath", "\n", "image_file_suffix", "=", "Path", "(", "yolo_image_path", ")", ".", "suffix", "\n", "yolo_annotation_path", "=", "yolo_image_path", ".", "replace", "(", "image_file_suffix", ",", "\".txt\"", ")", "\n", "# create annotation file", "\n", "annotations", "=", "coco_image", ".", "annotations", "\n", "with", "open", "(", "yolo_annotation_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "for", "annotation", "in", "annotations", ":", "\n", "# convert coco bbox to yolo bbox", "\n", "                ", "x_center", "=", "annotation", ".", "bbox", "[", "0", "]", "+", "annotation", ".", "bbox", "[", "2", "]", "/", "2.0", "\n", "y_center", "=", "annotation", ".", "bbox", "[", "1", "]", "+", "annotation", ".", "bbox", "[", "3", "]", "/", "2.0", "\n", "bbox_width", "=", "annotation", ".", "bbox", "[", "2", "]", "\n", "bbox_height", "=", "annotation", ".", "bbox", "[", "3", "]", "\n", "x_center", "=", "x_center", "*", "dw", "\n", "y_center", "=", "y_center", "*", "dh", "\n", "bbox_width", "=", "bbox_width", "*", "dw", "\n", "bbox_height", "=", "bbox_height", "*", "dh", "\n", "category_id", "=", "annotation", ".", "category_id", "\n", "yolo_bbox", "=", "(", "x_center", ",", "y_center", ",", "bbox_width", ",", "bbox_height", ")", "\n", "# save yolo annotation", "\n", "outfile", ".", "write", "(", "str", "(", "category_id", ")", "+", "\" \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "value", ")", "for", "value", "in", "yolo_bbox", "]", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories": [[1610, 1670], ["copy.deepcopy", "desired_name2id.keys", "categories.append", "desired_name2id.keys", "coco_target[].append"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "", "", "", "def", "update_categories", "(", "desired_name2id", ":", "dict", ",", "coco_dict", ":", "dict", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Rearranges category mapping of given COCO dictionary based on given category_mapping.\n    Can also be used to filter some of the categories.\n\n    Arguments:\n    ---------\n        desired_name2id : dict\n            {\"big_vehicle\": 1, \"car\": 2, \"human\": 3}\n        coco_dict : dict\n            COCO formatted dictionary.\n    Returns:\n    ---------\n        coco_target : dict\n            COCO dict with updated/filtred categories.\n    \"\"\"", "\n", "# so that original variable doesnt get affected", "\n", "coco_source", "=", "copy", ".", "deepcopy", "(", "coco_dict", ")", "\n", "\n", "# init target coco dict", "\n", "coco_target", "=", "{", "\"images\"", ":", "[", "]", ",", "\"annotations\"", ":", "[", "]", ",", "\"categories\"", ":", "[", "]", "}", "\n", "\n", "# init vars", "\n", "currentid2desiredid_mapping", "=", "{", "}", "\n", "# create category id mapping (currentid2desiredid_mapping)", "\n", "for", "category", "in", "coco_source", "[", "\"categories\"", "]", ":", "\n", "        ", "current_category_id", "=", "category", "[", "\"id\"", "]", "\n", "current_category_name", "=", "category", "[", "\"name\"", "]", "\n", "if", "current_category_name", "in", "desired_name2id", ".", "keys", "(", ")", ":", "\n", "            ", "currentid2desiredid_mapping", "[", "current_category_id", "]", "=", "desired_name2id", "[", "current_category_name", "]", "\n", "", "else", ":", "\n", "# ignore categories that are not included in desired_name2id", "\n", "            ", "currentid2desiredid_mapping", "[", "current_category_id", "]", "=", "-", "1", "\n", "\n", "# update annotations", "\n", "", "", "for", "annotation", "in", "coco_source", "[", "\"annotations\"", "]", ":", "\n", "        ", "current_category_id", "=", "annotation", "[", "\"category_id\"", "]", "\n", "desired_category_id", "=", "currentid2desiredid_mapping", "[", "current_category_id", "]", "\n", "# append annotations with category id present in desired_name2id", "\n", "if", "desired_category_id", "!=", "-", "1", ":", "\n", "# update cetegory id", "\n", "            ", "annotation", "[", "\"category_id\"", "]", "=", "desired_category_id", "\n", "# append updated annotation to target coco dict", "\n", "coco_target", "[", "\"annotations\"", "]", ".", "append", "(", "annotation", ")", "\n", "\n", "# create desired categories", "\n", "", "", "categories", "=", "[", "]", "\n", "for", "name", "in", "desired_name2id", ".", "keys", "(", ")", ":", "\n", "        ", "category", "=", "{", "}", "\n", "category", "[", "\"name\"", "]", "=", "category", "[", "\"supercategory\"", "]", "=", "name", "\n", "category", "[", "\"id\"", "]", "=", "desired_name2id", "[", "name", "]", "\n", "categories", ".", "append", "(", "category", ")", "\n", "\n", "# update categories", "\n", "", "coco_target", "[", "\"categories\"", "]", "=", "categories", "\n", "\n", "# update images", "\n", "coco_target", "[", "\"images\"", "]", "=", "coco_source", "[", "\"images\"", "]", "\n", "\n", "return", "coco_target", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories_from_file": [[1672, 1691], ["sahi.utils.file.load_json", "coco.update_categories", "sahi.utils.file.save_json"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json"], ["", "def", "update_categories_from_file", "(", "desired_name2id", ":", "dict", ",", "coco_path", ":", "str", ",", "save_path", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Rearranges category mapping of a COCO dictionary in coco_path based on given category_mapping.\n    Can also be used to filter some of the categories.\n    Arguments:\n    ---------\n        desired_name2id : dict\n            {\"human\": 1, \"car\": 2, \"big_vehicle\": 3}\n        coco_path : str\n            \"dirname/coco.json\"\n    \"\"\"", "\n", "# load source coco dict", "\n", "coco_source", "=", "load_json", "(", "coco_path", ")", "\n", "\n", "# update categories", "\n", "coco_target", "=", "update_categories", "(", "desired_name2id", ",", "coco_source", ")", "\n", "\n", "# save modified coco file", "\n", "save_json", "(", "coco_target", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge": [[1693, 1741], ["copy.deepcopy", "copy.deepcopy", "numpy.array().max", "numpy.array().max", "coco.update_categories", "coco.update_categories", "coco.update_categories", "merged_coco_dict[].append", "merged_coco_dict[].append", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories"], ["", "def", "merge", "(", "coco_dict1", ":", "dict", ",", "coco_dict2", ":", "dict", ",", "desired_name2id", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Combines 2 coco formatted annotations dicts, and returns the combined coco dict.\n\n    Arguments:\n    ---------\n        coco_dict1 : dict\n            First coco dictionary.\n        coco_dict2 : dict\n            Second coco dictionary.\n        desired_name2id : dict\n            {\"human\": 1, \"car\": 2, \"big_vehicle\": 3}\n    Returns:\n    ---------\n        merged_coco_dict : dict\n            Merged COCO dict.\n    \"\"\"", "\n", "\n", "# copy input dicts so that original dicts are not affected", "\n", "temp_coco_dict1", "=", "copy", ".", "deepcopy", "(", "coco_dict1", ")", "\n", "temp_coco_dict2", "=", "copy", ".", "deepcopy", "(", "coco_dict2", ")", "\n", "\n", "# rearrange categories if any desired_name2id mapping is given", "\n", "if", "desired_name2id", "is", "not", "None", ":", "\n", "        ", "temp_coco_dict1", "=", "update_categories", "(", "desired_name2id", ",", "temp_coco_dict1", ")", "\n", "temp_coco_dict2", "=", "update_categories", "(", "desired_name2id", ",", "temp_coco_dict2", ")", "\n", "\n", "# rearrange categories of the second coco based on first, if their categories are not the same", "\n", "", "if", "temp_coco_dict1", "[", "\"categories\"", "]", "!=", "temp_coco_dict2", "[", "\"categories\"", "]", ":", "\n", "        ", "desired_name2id", "=", "{", "category", "[", "\"name\"", "]", ":", "category", "[", "\"id\"", "]", "for", "category", "in", "temp_coco_dict1", "[", "\"categories\"", "]", "}", "\n", "temp_coco_dict2", "=", "update_categories", "(", "desired_name2id", ",", "temp_coco_dict2", ")", "\n", "\n", "# calculate first image and annotation index of the second coco file", "\n", "", "max_image_id", "=", "np", ".", "array", "(", "[", "image", "[", "\"id\"", "]", "for", "image", "in", "coco_dict1", "[", "\"images\"", "]", "]", ")", ".", "max", "(", ")", "\n", "max_annotation_id", "=", "np", ".", "array", "(", "[", "annotation", "[", "\"id\"", "]", "for", "annotation", "in", "coco_dict1", "[", "\"annotations\"", "]", "]", ")", ".", "max", "(", ")", "\n", "\n", "merged_coco_dict", "=", "temp_coco_dict1", "\n", "\n", "for", "image", "in", "temp_coco_dict2", "[", "\"images\"", "]", ":", "\n", "        ", "image", "[", "\"id\"", "]", "+=", "max_image_id", "+", "1", "\n", "merged_coco_dict", "[", "\"images\"", "]", ".", "append", "(", "image", ")", "\n", "\n", "", "for", "annotation", "in", "temp_coco_dict2", "[", "\"annotations\"", "]", ":", "\n", "        ", "annotation", "[", "\"image_id\"", "]", "+=", "max_image_id", "+", "1", "\n", "annotation", "[", "\"id\"", "]", "+=", "max_annotation_id", "+", "1", "\n", "merged_coco_dict", "[", "\"annotations\"", "]", ".", "append", "(", "annotation", ")", "\n", "\n", "", "return", "merged_coco_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge_from_list": [[1743, 1791], ["enumerate", "print", "print", "copy.deepcopy", "copy.deepcopy", "coco.merge"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge"], ["", "def", "merge_from_list", "(", "coco_dict_list", ",", "desired_name2id", "=", "None", ",", "verbose", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Combines a list of coco formatted annotations dicts, and returns the combined coco dict.\n\n    Arguments:\n    ---------\n        coco_dict_list: list of dict\n            A list of coco dicts\n        desired_name2id: dict\n            {\"human\": 1, \"car\": 2, \"big_vehicle\": 3}\n        verbose: bool\n            If True, merging info is printed\n    Returns:\n    ---------\n        merged_coco_dict: dict\n            Merged COCO dict.\n    \"\"\"", "\n", "if", "verbose", ":", "\n", "        ", "if", "not", "desired_name2id", ":", "\n", "            ", "print", "(", "\"'desired_name2id' is not specified, combining all categories.\"", ")", "\n", "\n", "# create desired_name2id by combinin all categories, if desired_name2id is not specified", "\n", "", "", "if", "desired_name2id", "is", "None", ":", "\n", "        ", "desired_name2id", "=", "{", "}", "\n", "ind", "=", "0", "\n", "for", "coco_dict", "in", "coco_dict_list", ":", "\n", "            ", "temp_categories", "=", "copy", ".", "deepcopy", "(", "coco_dict", "[", "\"categories\"", "]", ")", "\n", "for", "temp_category", "in", "temp_categories", ":", "\n", "                ", "if", "temp_category", "[", "\"name\"", "]", "not", "in", "desired_name2id", ":", "\n", "                    ", "desired_name2id", "[", "temp_category", "[", "\"name\"", "]", "]", "=", "ind", "\n", "ind", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "", "", "for", "ind", ",", "coco_dict", "in", "enumerate", "(", "coco_dict_list", ")", ":", "\n", "        ", "if", "ind", "==", "0", ":", "\n", "            ", "merged_coco_dict", "=", "copy", ".", "deepcopy", "(", "coco_dict", ")", "\n", "", "else", ":", "\n", "            ", "merged_coco_dict", "=", "merge", "(", "merged_coco_dict", ",", "coco_dict", ",", "desired_name2id", ")", "\n", "\n", "# print categories", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\n", "\"Categories are formed as:\\n\"", ",", "\n", "merged_coco_dict", "[", "\"categories\"", "]", ",", "\n", ")", "\n", "\n", "", "return", "merged_coco_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge_from_file": [[1793, 1816], ["sahi.utils.file.load_json", "sahi.utils.file.load_json", "coco.merge", "sahi.utils.file.save_json"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json"], ["", "def", "merge_from_file", "(", "coco_path1", ":", "str", ",", "coco_path2", ":", "str", ",", "save_path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Combines 2 coco formatted annotations files given their paths, and saves the combined file to save_path.\n\n    Arguments:\n    ---------\n        coco_path1 : str\n            Path for the first coco file.\n        coco_path2 : str\n            Path for the second coco file.\n        save_path : str\n            \"dirname/coco.json\"\n    \"\"\"", "\n", "\n", "# load coco files to be combined", "\n", "coco_dict1", "=", "load_json", "(", "coco_path1", ")", "\n", "coco_dict2", "=", "load_json", "(", "coco_path2", ")", "\n", "\n", "# merge coco dicts", "\n", "merged_coco_dict", "=", "merge", "(", "coco_dict1", ",", "coco_dict2", ")", "\n", "\n", "# save merged coco dict", "\n", "save_json", "(", "merged_coco_dict", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.get_imageid2annotationlist_mapping": [[1818, 1854], ["collections.defaultdict", "print", "image_id_to_annotation_list[].append"], "function", ["None"], ["", "def", "get_imageid2annotationlist_mapping", "(", "\n", "coco_dict", ":", "dict", ",", "\n", ")", "->", "Dict", "[", "int", ",", "List", "[", "CocoAnnotation", "]", "]", ":", "\n", "    ", "\"\"\"\n    Get image_id to annotationlist mapping for faster indexing.\n\n    Arguments\n    ---------\n        coco_dict : dict\n            coco dict with fields \"images\", \"annotations\", \"categories\"\n    Returns\n    -------\n        image_id_to_annotation_list : dict\n        {\n            1: [CocoAnnotation, CocoAnnotation, CocoAnnotation],\n            2: [CocoAnnotation]\n        }\n\n        where\n        CocoAnnotation = {\n            'area': 2795520,\n            'bbox': [491.0, 1035.0, 153.0, 182.0],\n            'category_id': 1,\n            'id': 1,\n            'image_id': 1,\n            'iscrowd': 0,\n            'segmentation': [[491.0, 1035.0, 644.0, 1035.0, 644.0, 1217.0, 491.0, 1217.0]]\n        }\n    \"\"\"", "\n", "image_id_to_annotation_list", ":", "Dict", "=", "defaultdict", "(", "list", ")", "\n", "print", "(", "\"indexing coco dataset annotations...\"", ")", "\n", "for", "annotation", "in", "coco_dict", "[", "\"annotations\"", "]", ":", "\n", "        ", "image_id", "=", "annotation", "[", "\"image_id\"", "]", "\n", "image_id_to_annotation_list", "[", "image_id", "]", ".", "append", "(", "annotation", ")", "\n", "\n", "", "return", "image_id_to_annotation_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.create_coco_dict": [[1856, 1929], ["dict", "ValueError", "len", "coco_dict[].append", "coco_dict[].append", "ValueError"], "function", ["None"], ["", "def", "create_coco_dict", "(", "images", ",", "categories", ",", "ignore_negative_samples", "=", "False", ",", "image_id_setting", "=", "\"auto\"", ")", ":", "\n", "    ", "\"\"\"\n    Creates COCO dict with fields \"images\", \"annotations\", \"categories\".\n\n    Arguments\n    ---------\n        images : List of CocoImage containing a list of CocoAnnotation\n        categories : List of Dict\n            COCO categories\n        ignore_negative_samples : Bool\n            If True, images without annotations are ignored\n        image_id_setting: str\n            how to assign image ids while exporting can be\n                auto --> will assign id from scratch (<CocoImage>.id will be ignored)\n                manual --> you will need to provide image ids in <CocoImage> instances (<CocoImage>.id can not be None)\n    Returns\n    -------\n        coco_dict : Dict\n            COCO dict with fields \"images\", \"annotations\", \"categories\"\n    \"\"\"", "\n", "# assertion of parameters", "\n", "if", "image_id_setting", "not", "in", "[", "\"auto\"", ",", "\"manual\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "f\"'image_id_setting' should be one of ['auto', 'manual']\"", ")", "\n", "\n", "# define accumulators", "\n", "", "image_index", "=", "1", "\n", "annotation_id", "=", "1", "\n", "coco_dict", "=", "dict", "(", "images", "=", "[", "]", ",", "annotations", "=", "[", "]", ",", "categories", "=", "categories", ")", "\n", "for", "coco_image", "in", "images", ":", "\n", "# get coco annotations", "\n", "        ", "coco_annotations", "=", "coco_image", ".", "annotations", "\n", "# get num annotations", "\n", "num_annotations", "=", "len", "(", "coco_annotations", ")", "\n", "# if ignore_negative_samples is True and no annotations, skip image", "\n", "if", "ignore_negative_samples", "and", "num_annotations", "==", "0", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "# get image_id", "\n", "            ", "if", "image_id_setting", "==", "\"auto\"", ":", "\n", "                ", "image_id", "=", "image_index", "\n", "image_index", "+=", "1", "\n", "", "elif", "image_id_setting", "==", "\"manual\"", ":", "\n", "                ", "if", "coco_image", ".", "id", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"'coco_image.id' should be set manually when image_id_setting == 'manual'\"", ")", "\n", "", "image_id", "=", "coco_image", ".", "id", "\n", "\n", "# create coco image object", "\n", "", "out_image", "=", "{", "\n", "\"height\"", ":", "coco_image", ".", "height", ",", "\n", "\"width\"", ":", "coco_image", ".", "width", ",", "\n", "\"id\"", ":", "image_id", ",", "\n", "\"file_name\"", ":", "coco_image", ".", "file_name", ",", "\n", "}", "\n", "coco_dict", "[", "\"images\"", "]", ".", "append", "(", "out_image", ")", "\n", "\n", "# do the same for image annotations", "\n", "for", "coco_annotation", "in", "coco_annotations", ":", "\n", "# create coco annotation object", "\n", "                ", "out_annotation", "=", "{", "\n", "\"iscrowd\"", ":", "0", ",", "\n", "\"image_id\"", ":", "image_id", ",", "\n", "\"bbox\"", ":", "coco_annotation", ".", "bbox", ",", "\n", "\"segmentation\"", ":", "coco_annotation", ".", "segmentation", ",", "\n", "\"category_id\"", ":", "coco_annotation", ".", "category_id", ",", "\n", "\"id\"", ":", "annotation_id", ",", "\n", "\"area\"", ":", "coco_annotation", ".", "area", ",", "\n", "}", "\n", "coco_dict", "[", "\"annotations\"", "]", ".", "append", "(", "out_annotation", ")", "\n", "# increment annotation id", "\n", "annotation_id", "+=", "1", "\n", "\n", "# return coco dict", "\n", "", "", "", "return", "coco_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.create_coco_prediction_array": [[1931, 1994], ["ValueError", "len", "enumerate", "predictions_array.append", "ValueError"], "function", ["None"], ["", "def", "create_coco_prediction_array", "(", "images", ",", "ignore_negative_samples", "=", "False", ",", "image_id_setting", "=", "\"auto\"", ")", ":", "\n", "    ", "\"\"\"\n    Creates COCO prediction array which is list of predictions\n\n    Arguments\n    ---------\n        images : List of CocoImage containing a list of CocoAnnotation\n        ignore_negative_samples : Bool\n            If True, images without predictions are ignored\n        image_id_setting: str\n            how to assign image ids while exporting can be\n                auto --> will assign id from scratch (<CocoImage>.id will be ignored)\n                manual --> you will need to provide image ids in <CocoImage> instances (<CocoImage>.id can not be None)\n    Returns\n    -------\n        coco_prediction_array : List\n            COCO predictions array\n    \"\"\"", "\n", "# assertion of parameters", "\n", "if", "image_id_setting", "not", "in", "[", "\"auto\"", ",", "\"manual\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "f\"'image_id_setting' should be one of ['auto', 'manual']\"", ")", "\n", "# define accumulators", "\n", "", "image_index", "=", "1", "\n", "prediction_id", "=", "1", "\n", "predictions_array", "=", "[", "]", "\n", "for", "coco_image", "in", "images", ":", "\n", "# get coco predictions", "\n", "        ", "coco_predictions", "=", "coco_image", ".", "predictions", "\n", "# get num predictions", "\n", "num_predictions", "=", "len", "(", "coco_predictions", ")", "\n", "# if ignore_negative_samples is True and no annotations, skip image", "\n", "if", "ignore_negative_samples", "and", "num_predictions", "==", "0", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "# get image_id", "\n", "            ", "if", "image_id_setting", "==", "\"auto\"", ":", "\n", "                ", "image_id", "=", "image_index", "\n", "image_index", "+=", "1", "\n", "", "elif", "image_id_setting", "==", "\"manual\"", ":", "\n", "                ", "if", "coco_image", ".", "id", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"'coco_image.id' should be set manually when image_id_setting == 'manual'\"", ")", "\n", "", "image_id", "=", "coco_image", ".", "id", "\n", "\n", "# create coco prediction object", "\n", "", "for", "prediction_index", ",", "coco_prediction", "in", "enumerate", "(", "coco_predictions", ")", ":", "\n", "# create coco prediction object", "\n", "                ", "out_prediction", "=", "{", "\n", "\"id\"", ":", "prediction_id", ",", "\n", "\"image_id\"", ":", "image_id", ",", "\n", "\"bbox\"", ":", "coco_prediction", ".", "bbox", ",", "\n", "\"score\"", ":", "coco_prediction", ".", "score", ",", "\n", "\"category_id\"", ":", "coco_prediction", ".", "category_id", ",", "\n", "\"segmentation\"", ":", "coco_prediction", ".", "segmentation", ",", "\n", "\"iscrowd\"", ":", "coco_prediction", ".", "iscrowd", ",", "\n", "\"area\"", ":", "coco_prediction", ".", "area", ",", "\n", "}", "\n", "predictions_array", ".", "append", "(", "out_prediction", ")", "\n", "\n", "# increment prediction id", "\n", "prediction_id", "+=", "1", "\n", "\n", "# return predictions array", "\n", "", "", "", "return", "predictions_array", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.add_bbox_and_area_to_coco": [[1996, 2042], ["sahi.utils.file.load_json", "copy.deepcopy", "enumerate", "sahi.utils.file.save_json", "list", "sahi.utils.shapely.get_shapely_multipolygon", "coco_polygons.extend", "round", "round", "round", "round", "min", "min", "max", "max"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_multipolygon", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.extend"], ["", "def", "add_bbox_and_area_to_coco", "(", "\n", "source_coco_path", ":", "str", "=", "\"\"", ",", "\n", "target_coco_path", ":", "str", "=", "\"\"", ",", "\n", "add_bbox", ":", "bool", "=", "True", ",", "\n", "add_area", ":", "bool", "=", "True", ",", "\n", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Takes single coco dataset file path, calculates and fills bbox and area fields of the annotations\n    and exports the updated coco dict.\n    Returns:\n    coco_dict : dict\n        Updated coco dict\n    \"\"\"", "\n", "coco_dict", "=", "load_json", "(", "source_coco_path", ")", "\n", "coco_dict", "=", "copy", ".", "deepcopy", "(", "coco_dict", ")", "\n", "\n", "annotations", "=", "coco_dict", "[", "\"annotations\"", "]", "\n", "for", "ind", ",", "annotation", "in", "enumerate", "(", "annotations", ")", ":", "\n", "# assign annotation bbox", "\n", "        ", "if", "add_bbox", ":", "\n", "            ", "coco_polygons", "=", "[", "]", "\n", "[", "coco_polygons", ".", "extend", "(", "coco_polygon", ")", "for", "coco_polygon", "in", "annotation", "[", "\"segmentation\"", "]", "]", "\n", "minx", ",", "miny", ",", "maxx", ",", "maxy", "=", "list", "(", "\n", "[", "\n", "min", "(", "coco_polygons", "[", "0", ":", ":", "2", "]", ")", ",", "\n", "min", "(", "coco_polygons", "[", "1", ":", ":", "2", "]", ")", ",", "\n", "max", "(", "coco_polygons", "[", "0", ":", ":", "2", "]", ")", ",", "\n", "max", "(", "coco_polygons", "[", "1", ":", ":", "2", "]", ")", ",", "\n", "]", "\n", ")", "\n", "x", ",", "y", ",", "width", ",", "height", "=", "(", "\n", "round", "(", "minx", ")", ",", "\n", "round", "(", "miny", ")", ",", "\n", "round", "(", "maxx", "-", "minx", ")", ",", "\n", "round", "(", "maxy", "-", "miny", ")", ",", "\n", ")", "\n", "annotations", "[", "ind", "]", "[", "\"bbox\"", "]", "=", "[", "x", ",", "y", ",", "width", ",", "height", "]", "\n", "\n", "# assign annotation area", "\n", "", "if", "add_area", ":", "\n", "            ", "shapely_multipolygon", "=", "get_shapely_multipolygon", "(", "coco_segmentation", "=", "annotation", "[", "\"segmentation\"", "]", ")", "\n", "annotations", "[", "ind", "]", "[", "\"area\"", "]", "=", "shapely_multipolygon", ".", "area", "\n", "\n", "", "", "coco_dict", "[", "\"annotations\"", "]", "=", "annotations", "\n", "save_json", "(", "coco_dict", ",", "target_coco_path", ")", "\n", "return", "coco_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.count_images_with_category": [[2066, 2090], ["collections.defaultdict", "sahi.utils.file.load_json", "collections.defaultdict", "collections.defaultdict.items", "dict", "len", "coco.DatasetClassCounts", "image_category_2_count.items", "collections.defaultdict.keys", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json"], ["", "", "def", "count_images_with_category", "(", "coco_file_path", ")", ":", "\n", "    ", "\"\"\"Reads a coco dataset file and returns an DatasetClassCounts object\n     that stores the number of images that include each category in a dataset\n    Returns: DatasetClassCounts object\n    coco_file_path : str\n        path to coco dataset file\n    \"\"\"", "\n", "\n", "image_id_2_category_2_count", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "lambda", ":", "0", ")", ")", "\n", "coco", "=", "load_json", "(", "coco_file_path", ")", "\n", "for", "annotation", "in", "coco", "[", "\"annotations\"", "]", ":", "\n", "        ", "image_id", "=", "annotation", "[", "\"image_id\"", "]", "\n", "cid", "=", "annotation", "[", "\"category_id\"", "]", "\n", "image_id_2_category_2_count", "[", "image_id", "]", "[", "cid", "]", "=", "image_id_2_category_2_count", "[", "image_id", "]", "[", "cid", "]", "+", "1", "\n", "\n", "", "category_2_count", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "for", "image_id", ",", "image_category_2_count", "in", "image_id_2_category_2_count", ".", "items", "(", ")", ":", "\n", "        ", "for", "cid", ",", "count", "in", "image_category_2_count", ".", "items", "(", ")", ":", "\n", "            ", "if", "count", ">", "0", ":", "\n", "                ", "category_2_count", "[", "cid", "]", "=", "category_2_count", "[", "cid", "]", "+", "1", "\n", "\n", "", "", "", "category_2_count", "=", "dict", "(", "category_2_count", ")", "\n", "total_images", "=", "len", "(", "image_id_2_category_2_count", ".", "keys", "(", ")", ")", "\n", "return", "DatasetClassCounts", "(", "category_2_count", ",", "total_images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.remove_invalid_coco_results": [[2211, 2266], ["isinstance", "sahi.utils.file.load_json", "isinstance", "isinstance", "fixed_result_list.append", "TypeError", "sahi.utils.file.load_json", "isinstance", "print", "print", "TypeError", "print"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json"], ["", "", "def", "remove_invalid_coco_results", "(", "result_list_or_path", ":", "Union", "[", "List", ",", "str", "]", ",", "dataset_dict_or_path", ":", "Union", "[", "Dict", ",", "str", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Removes invalid predictions from coco result such as:\n        - negative bbox value\n        - extreme bbox value\n\n    Args:\n        result_list_or_path: path or list for coco result json\n        dataset_dict_or_path (optional): path or dict for coco dataset json\n    \"\"\"", "\n", "\n", "# prepare coco results", "\n", "if", "isinstance", "(", "result_list_or_path", ",", "str", ")", ":", "\n", "        ", "result_list", "=", "load_json", "(", "result_list_or_path", ")", "\n", "", "elif", "isinstance", "(", "result_list_or_path", ",", "list", ")", ":", "\n", "        ", "result_list", "=", "result_list_or_path", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'incorrect type for \"result_list_or_path\"'", ")", "\n", "\n", "# prepare image info from coco dataset", "\n", "", "if", "dataset_dict_or_path", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "dataset_dict_or_path", ",", "str", ")", ":", "\n", "            ", "dataset_dict", "=", "load_json", "(", "dataset_dict_or_path", ")", "\n", "", "elif", "isinstance", "(", "dataset_dict_or_path", ",", "dict", ")", ":", "\n", "            ", "dataset_dict", "=", "dataset_dict_or_path", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'incorrect type for \"dataset_dict\"'", ")", "\n", "", "image_id_to_height", "=", "{", "}", "\n", "image_id_to_width", "=", "{", "}", "\n", "for", "coco_image", "in", "dataset_dict", "[", "\"images\"", "]", ":", "\n", "            ", "image_id_to_height", "[", "coco_image", "[", "\"id\"", "]", "]", "=", "coco_image", "[", "\"height\"", "]", "\n", "image_id_to_width", "[", "coco_image", "[", "\"id\"", "]", "]", "=", "coco_image", "[", "\"width\"", "]", "\n", "\n", "# remove invalid predictions", "\n", "", "", "fixed_result_list", "=", "[", "]", "\n", "for", "coco_result", "in", "result_list", ":", "\n", "        ", "bbox", "=", "coco_result", "[", "\"bbox\"", "]", "\n", "# ignore invalid predictions", "\n", "if", "not", "bbox", ":", "\n", "            ", "print", "(", "\"ignoring invalid prediction with empty bbox\"", ")", "\n", "continue", "\n", "", "if", "bbox", "[", "0", "]", "<", "0", "or", "bbox", "[", "1", "]", "<", "0", "or", "bbox", "[", "2", "]", "<", "0", "or", "bbox", "[", "3", "]", "<", "0", ":", "\n", "            ", "print", "(", "f\"ignoring invalid prediction with bbox: {bbox}\"", ")", "\n", "continue", "\n", "", "if", "dataset_dict_or_path", "is", "not", "None", ":", "\n", "            ", "if", "(", "\n", "bbox", "[", "1", "]", ">", "image_id_to_height", "[", "coco_result", "[", "\"image_id\"", "]", "]", "\n", "or", "bbox", "[", "3", "]", ">", "image_id_to_height", "[", "coco_result", "[", "\"image_id\"", "]", "]", "\n", "or", "bbox", "[", "0", "]", ">", "image_id_to_width", "[", "coco_result", "[", "\"image_id\"", "]", "]", "\n", "or", "bbox", "[", "2", "]", ">", "image_id_to_width", "[", "coco_result", "[", "\"image_id\"", "]", "]", "\n", ")", ":", "\n", "                ", "print", "(", "f\"ignoring invalid prediction with bbox: {bbox}\"", ")", "\n", "continue", "\n", "", "", "fixed_result_list", ".", "append", "(", "coco_result", ")", "\n", "", "return", "fixed_result_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_coco_as_yolov5": [[2268, 2349], ["train_dir.mkdir", "val_dir.mkdir", "coco.export_yolov5_images_and_txts_from_coco_object", "coco.export_yolov5_images_and_txts_from_coco_object", "str", "ValueError", "train_coco.split_coco_as_train_val", "pathlib.Path", "pathlib.Path", "str", "str", "len", "list", "open", "yaml.dump", "ImportError", "ValueError", "os.path.abspath", "os.path.abspath", "train_coco.category_mapping.values", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_yolov5_images_and_txts_from_coco_object", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_yolov5_images_and_txts_from_coco_object", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.split_coco_as_train_val"], ["", "def", "export_coco_as_yolov5", "(", "\n", "output_dir", ":", "str", ",", "train_coco", ":", "Coco", "=", "None", ",", "val_coco", ":", "Coco", "=", "None", ",", "train_split_rate", ":", "float", "=", "0.9", ",", "numpy_seed", "=", "0", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Exports current COCO dataset in ultralytics/yolov5 format.\n    Creates train val folders with image symlinks and txt files and a data yaml file.\n\n    Args:\n        output_dir: str\n            Export directory.\n        train_coco: Coco\n            coco object for training\n        val_coco: Coco\n            coco object for val\n        train_split_rate: float\n            train split rate between 0 and 1. will be used when val_coco is None.\n        numpy_seed: int\n            To fix the numpy seed.\n\n    Returns:\n        yaml_path: str\n            Path for the exported yolov5 data.yml\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "        ", "raise", "ImportError", "(", "'Please run \"pip install -U pyyaml\" '", "\"to install yaml first for yolov5 formatted exporting.\"", ")", "\n", "\n", "# set split_mode", "\n", "", "if", "train_coco", "and", "not", "val_coco", ":", "\n", "        ", "split_mode", "=", "True", "\n", "", "elif", "train_coco", "and", "val_coco", ":", "\n", "        ", "split_mode", "=", "False", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"'train_coco' have to be provided\"", ")", "\n", "\n", "# check train_split_rate", "\n", "", "if", "split_mode", "and", "not", "(", "0", "<", "train_split_rate", "<", "1", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"train_split_rate cannot be <0 or >1\"", ")", "\n", "\n", "# split dataset", "\n", "", "if", "split_mode", ":", "\n", "        ", "result", "=", "train_coco", ".", "split_coco_as_train_val", "(", "\n", "train_split_rate", "=", "train_split_rate", ",", "\n", "numpy_seed", "=", "numpy_seed", ",", "\n", ")", "\n", "train_coco", "=", "result", "[", "\"train_coco\"", "]", "\n", "val_coco", "=", "result", "[", "\"val_coco\"", "]", "\n", "\n", "# create train val image dirs", "\n", "", "train_dir", "=", "Path", "(", "os", ".", "path", ".", "abspath", "(", "output_dir", ")", ")", "/", "\"train/\"", "\n", "train_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# create dir", "\n", "val_dir", "=", "Path", "(", "os", ".", "path", ".", "abspath", "(", "output_dir", ")", ")", "/", "\"val/\"", "\n", "val_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# create dir", "\n", "\n", "# create image symlinks and annotation txts", "\n", "export_yolov5_images_and_txts_from_coco_object", "(", "\n", "output_dir", "=", "train_dir", ",", "\n", "coco", "=", "train_coco", ",", "\n", "ignore_negative_samples", "=", "train_coco", ".", "ignore_negative_samples", ",", "\n", "mp", "=", "False", ",", "\n", ")", "\n", "export_yolov5_images_and_txts_from_coco_object", "(", "\n", "output_dir", "=", "val_dir", ",", "\n", "coco", "=", "val_coco", ",", "\n", "ignore_negative_samples", "=", "val_coco", ".", "ignore_negative_samples", ",", "\n", "mp", "=", "False", ",", "\n", ")", "\n", "\n", "# create yolov5 data yaml", "\n", "data", "=", "{", "\n", "\"train\"", ":", "str", "(", "train_dir", ")", ",", "\n", "\"val\"", ":", "str", "(", "val_dir", ")", ",", "\n", "\"nc\"", ":", "len", "(", "train_coco", ".", "category_mapping", ")", ",", "\n", "\"names\"", ":", "list", "(", "train_coco", ".", "category_mapping", ".", "values", "(", ")", ")", ",", "\n", "}", "\n", "yaml_path", "=", "str", "(", "Path", "(", "output_dir", ")", "/", "\"data.yml\"", ")", "\n", "with", "open", "(", "yaml_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "dump", "(", "data", ",", "outfile", ",", "default_flow_style", "=", "None", ")", "\n", "\n", "", "return", "yaml_path", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_coco_as_yolov5_via_yml": [[2351, 2408], ["coco.export_coco_as_yolov5", "open", "yaml.safe_load", "Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path", "ImportError", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_coco_as_yolov5", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path"], ["", "def", "export_coco_as_yolov5_via_yml", "(", "yml_path", ":", "str", ",", "output_dir", ":", "str", ",", "train_split_rate", ":", "float", "=", "0.9", ",", "numpy_seed", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Exports current COCO dataset in ultralytics/yolov5 format.\n    Creates train val folders with image symlinks and txt files and a data yaml file.\n    Uses a yml file as input.\n\n    Args:\n        yml_path: str\n            file should contain these fields:\n                train_json_path: str\n                train_image_dir: str\n                val_json_path: str\n                val_image_dir: str\n        output_dir: str\n            Export directory.\n        train_split_rate: float\n            train split rate between 0 and 1. will be used when val_json_path is None.\n        numpy_seed: int\n            To fix the numpy seed.\n\n    Returns:\n        yaml_path: str\n            Path for the exported yolov5 data.yml\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "        ", "raise", "ImportError", "(", "'Please run \"pip install -U pyyaml\" '", "\"to install yaml first for yolov5 formatted exporting.\"", ")", "\n", "\n", "", "with", "open", "(", "yml_path", ",", "\"r\"", ")", "as", "stream", ":", "\n", "        ", "config_dict", "=", "yaml", ".", "safe_load", "(", "stream", ")", "\n", "\n", "", "if", "config_dict", "[", "\"train_json_path\"", "]", ":", "\n", "        ", "if", "not", "config_dict", "[", "\"train_image_dir\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{yml_path} is missing `train_image_dir`\"", ")", "\n", "", "train_coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "\n", "config_dict", "[", "\"train_json_path\"", "]", ",", "image_dir", "=", "config_dict", "[", "\"train_image_dir\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "        ", "train_coco", "=", "None", "\n", "\n", "", "if", "config_dict", "[", "\"val_json_path\"", "]", ":", "\n", "        ", "if", "not", "config_dict", "[", "\"val_image_dir\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{yml_path} is missing `val_image_dir`\"", ")", "\n", "", "val_coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "config_dict", "[", "\"val_json_path\"", "]", ",", "image_dir", "=", "config_dict", "[", "\"val_image_dir\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "val_coco", "=", "None", "\n", "\n", "", "yaml_path", "=", "export_coco_as_yolov5", "(", "\n", "output_dir", "=", "output_dir", ",", "\n", "train_coco", "=", "train_coco", ",", "\n", "val_coco", "=", "val_coco", ",", "\n", "train_split_rate", "=", "train_split_rate", ",", "\n", "numpy_seed", "=", "numpy_seed", ",", "\n", ")", "\n", "\n", "return", "yaml_path", "\n", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.NumpyEncoder.default": [[47, 56], ["isinstance", "int", "isinstance", "float", "isinstance", "obj.tolist", "super().default"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.utils.file.NumpyEncoder.default"], ["    ", "def", "default", "(", "self", ",", "obj", ")", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "np", ".", "integer", ")", ":", "\n", "            ", "return", "int", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "floating", ")", ":", "\n", "            ", "return", "float", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "obj", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", "NumpyEncoder", ",", "self", ")", ".", "default", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.unzip": [[17, 28], ["zipfile.ZipFile", "zf.extractall"], "function", ["None"], ["def", "unzip", "(", "file_path", ":", "str", ",", "dest_dir", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Unzips compressed .zip file.\n    Example inputs:\n        file_path: 'data/01_alb_id.zip'\n        dest_dir: 'data/'\n    \"\"\"", "\n", "\n", "# unzip file", "\n", "with", "zipfile", ".", "ZipFile", "(", "file_path", ")", "as", "zf", ":", "\n", "        ", "zf", ".", "extractall", "(", "dest_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json": [[30, 43], ["pathlib.Path().parent.mkdir", "open", "json.dump", "pathlib.Path"], "function", ["None"], ["", "", "def", "save_json", "(", "data", ",", "save_path", ")", ":", "\n", "    ", "\"\"\"\n    Saves json formatted data (given as \"data\") as save_path\n    Example inputs:\n        data: {\"image_id\": 5}\n        save_path: \"dirname/coco.json\"\n    \"\"\"", "\n", "# create dir if not present", "\n", "Path", "(", "save_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# export as json", "\n", "with", "open", "(", "save_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "data", ",", "outfile", ",", "separators", "=", "(", "\",\"", ",", "\":\"", ")", ",", "cls", "=", "NumpyEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json": [[58, 70], ["open", "json.load"], "function", ["None"], ["", "", "", "def", "load_json", "(", "load_path", ":", "str", ",", "encoding", ":", "str", "=", "\"utf-8\"", ")", ":", "\n", "    ", "\"\"\"\n    Loads json formatted data (given as \"data\") from load_path\n    Encoding type can be specified with 'encoding' argument\n\n    Example inputs:\n        load_path: \"dirname/coco.json\"\n    \"\"\"", "\n", "# read from path", "\n", "with", "open", "(", "load_path", ",", "encoding", "=", "encoding", ")", "as", "json_file", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "json_file", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.list_files": [[72, 110], ["os.listdir", "len", "verboseprint", "any", "pathlib.Path", "os.path.join", "filepath_list.append", "str"], "function", ["None"], ["", "def", "list_files", "(", "\n", "directory", ":", "str", ",", "\n", "contains", ":", "list", "=", "[", "\".json\"", "]", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", ")", "->", "list", ":", "\n", "    ", "\"\"\"\n    Walk given directory and return a list of file path with desired extension\n\n    Args:\n        directory: str\n            \"data/coco/\"\n        contains: list\n            A list of strings to check if the target file contains them, example: [\"coco.png\", \".jpg\", \"jpeg\"]\n        verbose: int\n            0: no print\n            1: print number of files\n\n    Returns:\n        filepath_list : list\n            List of file paths\n    \"\"\"", "\n", "# define verboseprint", "\n", "verboseprint", "=", "print", "if", "verbose", "else", "lambda", "*", "a", ",", "**", "k", ":", "None", "\n", "\n", "filepath_list", "=", "[", "]", "\n", "\n", "for", "file", "in", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "# check if filename contains any of the terms given in contains list", "\n", "        ", "if", "any", "(", "strtocheck", "in", "file", "for", "strtocheck", "in", "contains", ")", ":", "\n", "            ", "filepath", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "file", ")", "\n", "filepath_list", ".", "append", "(", "filepath", ")", "\n", "\n", "", "", "number_of_files", "=", "len", "(", "filepath_list", ")", "\n", "folder_name", "=", "Path", "(", "directory", ")", ".", "name", "\n", "\n", "verboseprint", "(", "f\"There are {str(number_of_files)} listed files in folder: {folder_name}/\"", ")", "\n", "\n", "return", "filepath_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.list_files_recursively": [[112, 155], ["os.walk", "len", "verboseprint", "directory.split", "any", "os.path.join", "abs_filepath_list.append", "relative_filepath_list.append", "os.path.join.split"], "function", ["None"], ["", "def", "list_files_recursively", "(", "directory", ":", "str", ",", "contains", ":", "list", "=", "[", "\".json\"", "]", ",", "verbose", ":", "str", "=", "True", ")", "->", "(", "list", ",", "list", ")", ":", "\n", "    ", "\"\"\"\n    Walk given directory recursively and return a list of file path with desired extension\n\n    Arguments\n    -------\n        directory : str\n            \"data/coco/\"\n        contains : list\n            A list of strings to check if the target file contains them, example: [\"coco.png\", \".jpg\", \"jpeg\"]\n        verbose : bool\n            If true, prints some results\n    Returns\n    -------\n        relative_filepath_list : list\n            List of file paths relative to given directory\n        abs_filepath_list : list\n            List of absolute file paths\n    \"\"\"", "\n", "\n", "# define verboseprint", "\n", "verboseprint", "=", "print", "if", "verbose", "else", "lambda", "*", "a", ",", "**", "k", ":", "None", "\n", "\n", "# walk directories recursively and find json files", "\n", "abs_filepath_list", "=", "[", "]", "\n", "relative_filepath_list", "=", "[", "]", "\n", "\n", "# r=root, d=directories, f=files", "\n", "for", "r", ",", "_", ",", "f", "in", "os", ".", "walk", "(", "directory", ")", ":", "\n", "        ", "for", "file", "in", "f", ":", "\n", "# check if filename contains any of the terms given in contains list", "\n", "            ", "if", "any", "(", "strtocheck", "in", "file", "for", "strtocheck", "in", "contains", ")", ":", "\n", "                ", "abs_filepath", "=", "os", ".", "path", ".", "join", "(", "r", ",", "file", ")", "\n", "abs_filepath_list", ".", "append", "(", "abs_filepath", ")", "\n", "relative_filepath", "=", "abs_filepath", ".", "split", "(", "directory", ")", "[", "-", "1", "]", "\n", "relative_filepath_list", ".", "append", "(", "relative_filepath", ")", "\n", "\n", "", "", "", "number_of_files", "=", "len", "(", "relative_filepath_list", ")", "\n", "folder_name", "=", "directory", ".", "split", "(", "os", ".", "sep", ")", "[", "-", "1", "]", "\n", "\n", "verboseprint", "(", "\"There are {} listed files in folder {}.\"", ".", "format", "(", "number_of_files", ",", "folder_name", ")", ")", "\n", "\n", "return", "relative_filepath_list", ",", "abs_filepath_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.get_base_filename": [[157, 164], ["ntpath.basename", "os.path.splitext"], "function", ["None"], ["", "def", "get_base_filename", "(", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Takes a file path, returns (base_filename_with_extension, base_filename_without_extension)\n    \"\"\"", "\n", "base_filename_with_extension", "=", "ntpath", ".", "basename", "(", "path", ")", "\n", "base_filename_without_extension", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "base_filename_with_extension", ")", "\n", "return", "base_filename_with_extension", ",", "base_filename_without_extension", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.get_file_extension": [[166, 169], ["os.path.splitext"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ":", "str", ")", ":", "\n", "    ", "filename", ",", "file_extension", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "\n", "return", "file_extension", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_pickle": [[171, 181], ["open", "pickle.load"], "function", ["None"], ["", "def", "load_pickle", "(", "load_path", ")", ":", "\n", "    ", "\"\"\"\n    Loads pickle formatted data (given as \"data\") from load_path\n    Example inputs:\n        load_path: \"dirname/coco.pickle\"\n    \"\"\"", "\n", "# read from path", "\n", "with", "open", "(", "load_path", ")", "as", "json_file", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "json_file", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_pickle": [[183, 196], ["pathlib.Path().parent.mkdir", "open", "pickle.dump", "pathlib.Path"], "function", ["None"], ["", "def", "save_pickle", "(", "data", ",", "save_path", ")", ":", "\n", "    ", "\"\"\"\n    Saves pickle formatted data (given as \"data\") as save_path\n    Example inputs:\n        data: {\"image_id\": 5}\n        save_path: \"dirname/coco.pickle\"\n    \"\"\"", "\n", "# create dir if not present", "\n", "Path", "(", "save_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# export as json", "\n", "with", "open", "(", "save_path", ",", "\"wb\"", ")", "as", "outfile", ":", "\n", "        ", "pickle", ".", "dump", "(", "data", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.import_model_class": [[198, 211], ["__import__", "getattr"], "function", ["None"], ["", "", "def", "import_model_class", "(", "class_name", ")", ":", "\n", "    ", "\"\"\"\n    Imports a predefined detection class by class name.\n\n    Args:\n        model_name: str\n            Name of the detection model class (example: \"MmdetDetectionModel\")\n    Returns:\n        class_: class with given path\n    \"\"\"", "\n", "module", "=", "__import__", "(", "\"sahi.model\"", ",", "fromlist", "=", "[", "class_name", "]", ")", "\n", "class_", "=", "getattr", "(", "module", ",", "class_name", ")", "\n", "return", "class_", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.increment_path": [[213, 224], ["pathlib.Path", "str", "glob.glob", "pathlib.Path.exists", "pathlib.Path.exists", "re.search", "int", "max", "m.groups"], "function", ["None"], ["", "def", "increment_path", "(", "path", ",", "exist_ok", "=", "True", ",", "sep", "=", "\"\"", ")", ":", "\n", "# Increment path, i.e. runs/exp --> runs/exp{sep}0, runs/exp{sep}1 etc.", "\n", "    ", "path", "=", "Path", "(", "path", ")", "# os-agnostic", "\n", "if", "(", "path", ".", "exists", "(", ")", "and", "exist_ok", ")", "or", "(", "not", "path", ".", "exists", "(", ")", ")", ":", "\n", "        ", "return", "str", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "dirs", "=", "glob", ".", "glob", "(", "f\"{path}{sep}*\"", ")", "# similar paths", "\n", "matches", "=", "[", "re", ".", "search", "(", "rf\"%s{sep}(\\d+)\"", "%", "path", ".", "stem", ",", "d", ")", "for", "d", "in", "dirs", "]", "\n", "i", "=", "[", "int", "(", "m", ".", "groups", "(", ")", "[", "0", "]", ")", "for", "m", "in", "matches", "if", "m", "]", "# indices", "\n", "n", "=", "max", "(", "i", ")", "+", "1", "if", "i", "else", "2", "# increment number", "\n", "return", "f\"{path}{sep}{n}\"", "# update path", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.file.download_from_url": [[226, 234], ["pathlib.Path().parent.mkdir", "os.path.exists", "urllib.request.urlretrieve", "pathlib.Path"], "function", ["None"], ["", "", "def", "download_from_url", "(", "from_url", ":", "str", ",", "to_path", ":", "str", ")", ":", "\n", "\n", "    ", "Path", "(", "to_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "to_path", ")", ":", "\n", "        ", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "from_url", ",", "\n", "to_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.mmdet_version_as_integer": [[12, 16], ["int", "mmdet.__version__.replace"], "function", ["None"], ["def", "mmdet_version_as_integer", "(", ")", ":", "\n", "    ", "import", "mmdet", "\n", "\n", "return", "int", "(", "mmdet", ".", "__version__", ".", "replace", "(", "\".\"", ",", "\"\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_cascade_mask_rcnn_model": [[33, 41], ["pathlib.Path().parent.mkdir", "sahi.utils.file.download_from_url", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.download_from_url"], ["", "def", "download_mmdet_cascade_mask_rcnn_model", "(", "destination_path", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "\n", "    ", "if", "destination_path", "is", "None", ":", "\n", "        ", "destination_path", "=", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_MODEL_PATH", "\n", "\n", "", "Path", "(", "destination_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "download_from_url", "(", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_MODEL_URL", ",", "destination_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_retinanet_model": [[43, 51], ["pathlib.Path().parent.mkdir", "sahi.utils.file.download_from_url", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.download_from_url"], ["", "def", "download_mmdet_retinanet_model", "(", "destination_path", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "\n", "    ", "if", "destination_path", "is", "None", ":", "\n", "        ", "destination_path", "=", "MmdetTestConstants", ".", "MMDET_RETINANET_MODEL_PATH", "\n", "\n", "", "Path", "(", "destination_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "download_from_url", "(", "MmdetTestConstants", ".", "MMDET_RETINANET_MODEL_URL", ",", "destination_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_yolox_tiny_model": [[53, 61], ["pathlib.Path().parent.mkdir", "sahi.utils.file.download_from_url", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.download_from_url"], ["", "def", "download_mmdet_yolox_tiny_model", "(", "destination_path", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "\n", "    ", "if", "destination_path", "is", "None", ":", "\n", "        ", "destination_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_MODEL_PATH", "\n", "\n", "", "Path", "(", "destination_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "download_from_url", "(", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_MODEL_URL", ",", "destination_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_config": [[63, 193], ["configs_dir.mkdir", "model_config_dir.mkdir", "str", "os.path.abspath", "pathlib.Path", "pathlib.Path", "pathlib.Path().exists", "pathlib.Path", "pathlib.Path.mkdir", "main_config_dir.mkdir", "str", "urllib.request.urlretrieve", "sys.path.insert", "importlib.import_module", "sys.path.pop", "Config.fromfile", "Config.fromfile.dump", "shutil.rmtree", "pathlib.Path", "str", "os.path.splitext", "isinstance", "config_path.parent.mkdir", "urllib.request.urlretrieve", "sys.path.insert", "importlib.import_module", "sys.path.pop", "print", "pathlib.Path", "importlib.import_module.__dict__.items", "str", "str", "os.path.splitext", "secondary_config_dict.get", "name.startswith", "importlib.import_module.__dict__.items", "isinstance", "config_path.parent.mkdir", "urllib.request.urlretrieve", "pathlib.Path", "name.startswith", "str", "os.path.abspath"], "function", ["None"], ["", "def", "download_mmdet_config", "(", "\n", "model_name", ":", "str", "=", "\"cascade_rcnn\"", ",", "\n", "config_file_name", ":", "str", "=", "\"cascade_mask_rcnn_r50_fpn_1x_coco.py\"", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Merges config files starting from given main config file name. Saves as single file.\n\n    Args:\n        model_name (str): mmdet model name. check https://github.com/open-mmlab/mmdetection/tree/master/configs.\n        config_file_name (str): mdmet config file name.\n        verbose (bool): if True, print save path.\n\n    Returns:\n        (str) abs path of the downloaded config file.\n    \"\"\"", "\n", "\n", "# get mmdet version", "\n", "from", "mmdet", "import", "__version__", "\n", "\n", "mmdet_ver", "=", "\"v\"", "+", "__version__", "\n", "\n", "# set main config url", "\n", "base_config_url", "=", "(", "\n", "\"https://raw.githubusercontent.com/open-mmlab/mmdetection/\"", "+", "mmdet_ver", "+", "\"/configs/\"", "+", "model_name", "+", "\"/\"", "\n", ")", "\n", "main_config_url", "=", "base_config_url", "+", "config_file_name", "\n", "\n", "# set final config dirs", "\n", "configs_dir", "=", "Path", "(", "\"mmdet_configs\"", ")", "/", "mmdet_ver", "\n", "model_config_dir", "=", "configs_dir", "/", "model_name", "\n", "\n", "# create final config dir", "\n", "configs_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "model_config_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# get final config file name", "\n", "filename", "=", "Path", "(", "main_config_url", ")", ".", "name", "\n", "\n", "# set final config file path", "\n", "final_config_path", "=", "str", "(", "model_config_dir", "/", "filename", ")", "\n", "\n", "if", "not", "Path", "(", "final_config_path", ")", ".", "exists", "(", ")", ":", "\n", "# set config dirs", "\n", "        ", "temp_configs_dir", "=", "Path", "(", "\"temp_mmdet_configs\"", ")", "\n", "main_config_dir", "=", "temp_configs_dir", "/", "model_name", "\n", "\n", "# create config dirs", "\n", "temp_configs_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "main_config_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# get main config file name", "\n", "filename", "=", "Path", "(", "main_config_url", ")", ".", "name", "\n", "\n", "# set main config file path", "\n", "main_config_path", "=", "str", "(", "main_config_dir", "/", "filename", ")", "\n", "\n", "# download main config file", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "main_config_url", ",", "\n", "main_config_path", ",", "\n", ")", "\n", "\n", "# read main config file", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "str", "(", "main_config_dir", ")", ")", "\n", "temp_module_name", "=", "path", ".", "splitext", "(", "filename", ")", "[", "0", "]", "\n", "mod", "=", "import_module", "(", "temp_module_name", ")", "\n", "sys", ".", "path", ".", "pop", "(", "0", ")", "\n", "config_dict", "=", "{", "name", ":", "value", "for", "name", ",", "value", "in", "mod", ".", "__dict__", ".", "items", "(", ")", "if", "not", "name", ".", "startswith", "(", "\"__\"", ")", "}", "\n", "\n", "# handle when config_dict[\"_base_\"] is string", "\n", "if", "not", "isinstance", "(", "config_dict", "[", "\"_base_\"", "]", ",", "list", ")", ":", "\n", "            ", "config_dict", "[", "\"_base_\"", "]", "=", "[", "config_dict", "[", "\"_base_\"", "]", "]", "\n", "\n", "# iterate over secondary config files", "\n", "", "for", "secondary_config_file_path", "in", "config_dict", "[", "\"_base_\"", "]", ":", "\n", "# set config url", "\n", "            ", "config_url", "=", "base_config_url", "+", "secondary_config_file_path", "\n", "config_path", "=", "main_config_dir", "/", "secondary_config_file_path", "\n", "\n", "# create secondary config dir", "\n", "config_path", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# download secondary config files", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "config_url", ",", "\n", "str", "(", "config_path", ")", ",", "\n", ")", "\n", "\n", "# read secondary config file", "\n", "secondary_config_dir", "=", "config_path", ".", "parent", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "str", "(", "secondary_config_dir", ")", ")", "\n", "temp_module_name", "=", "path", ".", "splitext", "(", "Path", "(", "config_path", ")", ".", "name", ")", "[", "0", "]", "\n", "mod", "=", "import_module", "(", "temp_module_name", ")", "\n", "sys", ".", "path", ".", "pop", "(", "0", ")", "\n", "secondary_config_dict", "=", "{", "name", ":", "value", "for", "name", ",", "value", "in", "mod", ".", "__dict__", ".", "items", "(", ")", "if", "not", "name", ".", "startswith", "(", "\"__\"", ")", "}", "\n", "\n", "# go deeper if there are more steps", "\n", "if", "secondary_config_dict", ".", "get", "(", "\"_base_\"", ")", "is", "not", "None", ":", "\n", "# handle when config_dict[\"_base_\"] is string", "\n", "                ", "if", "not", "isinstance", "(", "secondary_config_dict", "[", "\"_base_\"", "]", ",", "list", ")", ":", "\n", "                    ", "secondary_config_dict", "[", "\"_base_\"", "]", "=", "[", "secondary_config_dict", "[", "\"_base_\"", "]", "]", "\n", "\n", "# iterate over third config files", "\n", "", "for", "third_config_file_path", "in", "secondary_config_dict", "[", "\"_base_\"", "]", ":", "\n", "# set config url", "\n", "                    ", "config_url", "=", "base_config_url", "+", "third_config_file_path", "\n", "config_path", "=", "main_config_dir", "/", "third_config_file_path", "\n", "\n", "# create secondary config dir", "\n", "config_path", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "# download secondary config files", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "config_url", ",", "\n", "str", "(", "config_path", ")", ",", "\n", ")", "\n", "\n", "# dump final config as single file", "\n", "", "", "", "from", "mmcv", "import", "Config", "\n", "\n", "config", "=", "Config", ".", "fromfile", "(", "main_config_path", ")", "\n", "config", ".", "dump", "(", "final_config_path", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "f\"mmdet config file has been downloaded to {path.abspath(final_config_path)}\"", ")", "\n", "\n", "# remove temp config dir", "\n", "", "shutil", ".", "rmtree", "(", "temp_configs_dir", ")", "\n", "\n", "", "return", "path", ".", "abspath", "(", "final_config_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.Colors.__init__": [[23, 48], ["len", "cv.Colors.hex2rgb"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.Colors.hex2rgb"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "hex", "=", "(", "\n", "\"FF3838\"", ",", "\n", "\"2C99A8\"", ",", "\n", "\"FF701F\"", ",", "\n", "\"6473FF\"", ",", "\n", "\"CFD231\"", ",", "\n", "\"48F90A\"", ",", "\n", "\"92CC17\"", ",", "\n", "\"3DDB86\"", ",", "\n", "\"1A9334\"", ",", "\n", "\"00D4BB\"", ",", "\n", "\"FF9D97\"", ",", "\n", "\"00C2FF\"", ",", "\n", "\"344593\"", ",", "\n", "\"FFB21D\"", ",", "\n", "\"0018EC\"", ",", "\n", "\"8438FF\"", ",", "\n", "\"520085\"", ",", "\n", "\"CB38FF\"", ",", "\n", "\"FF95C8\"", ",", "\n", "\"FF37C7\"", ",", "\n", ")", "\n", "self", ".", "palette", "=", "[", "self", ".", "hex2rgb", "(", "\"#\"", "+", "c", ")", "for", "c", "in", "hex", "]", "\n", "self", ".", "n", "=", "len", "(", "self", ".", "palette", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.Colors.__call__": [[49, 52], ["int"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "i", ",", "bgr", "=", "False", ")", ":", "\n", "        ", "c", "=", "self", ".", "palette", "[", "int", "(", "i", ")", "%", "self", ".", "n", "]", "\n", "return", "(", "c", "[", "2", "]", ",", "c", "[", "1", "]", ",", "c", "[", "0", "]", ")", "if", "bgr", "else", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.Colors.hex2rgb": [[53, 56], ["tuple", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "hex2rgb", "(", "h", ")", ":", "# rgb order", "\n", "        ", "return", "tuple", "(", "int", "(", "h", "[", "1", "+", "i", ":", "1", "+", "i", "+", "2", "]", ",", "16", ")", "for", "i", "in", "(", "0", ",", "2", ",", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.crop_object_predictions": [[58, 95], ["sahi.utils.file.Path().mkdir", "enumerate", "object_prediction.deepcopy.deepcopy", "object_prediction.deepcopy.bbox.to_voc_bbox", "copy.deepcopy", "os.path.join", "cv2.imwrite", "sahi.utils.file.Path", "cv2.cvtColor", "int", "int", "int", "int", "str", "str"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "", "def", "crop_object_predictions", "(", "\n", "image", ":", "np", ".", "ndarray", ",", "\n", "object_prediction_list", ",", "\n", "output_dir", ":", "str", "=", "\"\"", ",", "\n", "file_name", ":", "str", "=", "\"prediction_visual\"", ",", "\n", "export_format", ":", "str", "=", "\"png\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Crops bounding boxes over the source image and exports it to output folder.\n    Arguments:\n        object_predictions: a list of prediction.ObjectPrediction\n        output_dir: directory for resulting visualization to be exported\n        file_name: exported file will be saved as: output_dir+file_name+\".png\"\n        export_format: can be specified as 'jpg' or 'png'\n    \"\"\"", "\n", "# create output folder if not present", "\n", "Path", "(", "output_dir", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "# add bbox and mask to image if present", "\n", "for", "ind", ",", "object_prediction", "in", "enumerate", "(", "object_prediction_list", ")", ":", "\n", "# deepcopy object_prediction_list so that original is not altered", "\n", "        ", "object_prediction", "=", "object_prediction", ".", "deepcopy", "(", ")", "\n", "bbox", "=", "object_prediction", ".", "bbox", ".", "to_voc_bbox", "(", ")", "\n", "category_id", "=", "object_prediction", ".", "category", ".", "id", "\n", "# crop detections", "\n", "# deepcopy crops so that original is not altered", "\n", "cropped_img", "=", "copy", ".", "deepcopy", "(", "\n", "image", "[", "\n", "int", "(", "bbox", "[", "1", "]", ")", ":", "int", "(", "bbox", "[", "3", "]", ")", ",", "\n", "int", "(", "bbox", "[", "0", "]", ")", ":", "int", "(", "bbox", "[", "2", "]", ")", ",", "\n", ":", ",", "\n", "]", "\n", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\n", "file_name", "+", "\"_box\"", "+", "str", "(", "ind", ")", "+", "\"_class\"", "+", "str", "(", "category_id", ")", "+", "\".\"", "+", "export_format", ",", "\n", ")", "\n", "cv2", ".", "imwrite", "(", "save_path", ",", "cv2", ".", "cvtColor", "(", "cropped_img", ",", "cv2", ".", "COLOR_RGB2BGR", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.convert_image_to": [[97, 108], ["cv2.imread", "os.path.splitext", "cv2.imwrite", "cv2.cvtColor"], "function", ["None"], ["", "", "def", "convert_image_to", "(", "read_path", ",", "extension", ":", "str", "=", "\"jpg\"", ",", "grayscale", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Reads image from path and saves as given extension.\n    \"\"\"", "\n", "image", "=", "cv2", ".", "imread", "(", "read_path", ")", "\n", "pre", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "read_path", ")", "\n", "if", "grayscale", ":", "\n", "        ", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "pre", "=", "pre", "+", "\"_gray\"", "\n", "", "save_path", "=", "pre", "+", "\".\"", "+", "extension", "\n", "cv2", ".", "imwrite", "(", "save_path", ",", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_large_image": [[110, 127], ["cv2.imread", "cv2.cvtColor", "skimage.io.imread().astype", "ImportError", "skimage.io.imread"], "function", ["None"], ["", "def", "read_large_image", "(", "image_path", ":", "str", ")", ":", "\n", "    ", "use_cv2", "=", "True", "\n", "# read image, cv2 fails on large files", "\n", "try", ":", "\n", "# convert to rgb (cv2 reads in bgr)", "\n", "        ", "img_cv2", "=", "cv2", ".", "imread", "(", "image_path", ",", "1", ")", "\n", "image0", "=", "cv2", ".", "cvtColor", "(", "img_cv2", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "", "except", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "skimage", ".", "io", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please run \"pip install -U scikit-image\" '", "\"to install scikit-image first for large image handling.\"", "\n", ")", "\n", "", "image0", "=", "skimage", ".", "io", ".", "imread", "(", "image_path", ",", "as_grey", "=", "False", ")", ".", "astype", "(", "np", ".", "uint8", ")", "# [::-1]", "\n", "use_cv2", "=", "False", "\n", "", "return", "image0", ",", "use_cv2", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image": [[129, 138], ["cv2.imread", "cv2.cvtColor"], "function", ["None"], ["", "def", "read_image", "(", "image_path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Loads image as numpy array from given path.\n    \"\"\"", "\n", "# read image", "\n", "image", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "# return image", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil": [[140, 181], ["isinstance", "isinstance", "isinstance", "PIL.Image.open().convert", "PIL.Image.fromarray", "TypeError", "cv.exif_transpose", "skimage.io.imread().astype", "PIL.Image.open", "len", "PIL.Image.fromarray", "ImportError", "skimage.io.imread", "PIL.Image.fromarray", "str().startswith", "PIL.Image.fromarray", "TypeError", "requests.get", "str"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.exif_transpose"], ["", "def", "read_image_as_pil", "(", "image", ":", "Union", "[", "Image", ".", "Image", ",", "str", ",", "np", ".", "ndarray", "]", ",", "exif_fix", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Loads an image as PIL.Image.Image.\n\n    Args:\n        image : Can be image path or url (str), numpy image (np.ndarray) or PIL.Image\n    \"\"\"", "\n", "# https://stackoverflow.com/questions/56174099/how-to-load-images-larger-than-max-image-pixels-with-pil", "\n", "Image", ".", "MAX_IMAGE_PIXELS", "=", "None", "\n", "\n", "if", "isinstance", "(", "image", ",", "Image", ".", "Image", ")", ":", "\n", "        ", "image_pil", "=", "image", "\n", "", "elif", "isinstance", "(", "image", ",", "str", ")", ":", "\n", "# read image if str image path is provided", "\n", "        ", "try", ":", "\n", "            ", "image_pil", "=", "Image", ".", "open", "(", "\n", "requests", ".", "get", "(", "image", ",", "stream", "=", "True", ")", ".", "raw", "if", "str", "(", "image", ")", ".", "startswith", "(", "\"http\"", ")", "else", "image", "\n", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "if", "exif_fix", ":", "\n", "                ", "image_pil", "=", "exif_transpose", "(", "image_pil", ")", "\n", "", "", "except", ":", "# handle large/tiff image reading", "\n", "            ", "try", ":", "\n", "                ", "import", "skimage", ".", "io", "\n", "", "except", "ImportError", ":", "\n", "                ", "raise", "ImportError", "(", "\"Please run 'pip install -U scikit-image imagecodecs' for large image handling.\"", ")", "\n", "", "image_sk", "=", "skimage", ".", "io", ".", "imread", "(", "image", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "if", "len", "(", "image_sk", ".", "shape", ")", "==", "2", ":", "# b&w", "\n", "                ", "image_pil", "=", "Image", ".", "fromarray", "(", "image_sk", ",", "mode", "=", "\"1\"", ")", "\n", "", "elif", "image_sk", ".", "shape", "[", "2", "]", "==", "4", ":", "# rgba", "\n", "                ", "image_pil", "=", "Image", ".", "fromarray", "(", "image_sk", ",", "mode", "=", "\"RGBA\"", ")", "\n", "", "elif", "image_sk", ".", "shape", "[", "2", "]", "==", "3", ":", "# rgb", "\n", "                ", "image_pil", "=", "Image", ".", "fromarray", "(", "image_sk", ",", "mode", "=", "\"RGB\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "f\"image with shape: {image_sk.shape[3]} is not supported.\"", ")", "\n", "", "", "", "elif", "isinstance", "(", "image", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "image", ".", "shape", "[", "0", "]", "<", "5", ":", "# image in CHW", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "", "image_pil", "=", "Image", ".", "fromarray", "(", "image", ")", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "\"read image with 'pillow' using 'Image.open()'\"", ")", "\n", "", "return", "image_pil", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.select_random_color": [[183, 201], ["random.randrange"], "function", ["None"], ["", "def", "select_random_color", "(", ")", ":", "\n", "    ", "\"\"\"\n    Selects random color.\n    \"\"\"", "\n", "colors", "=", "[", "\n", "[", "0", ",", "255", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "255", "]", ",", "\n", "[", "255", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "255", ",", "255", "]", ",", "\n", "[", "255", ",", "255", ",", "0", "]", ",", "\n", "[", "255", ",", "0", ",", "255", "]", ",", "\n", "[", "80", ",", "70", ",", "180", "]", ",", "\n", "[", "250", ",", "80", ",", "190", "]", ",", "\n", "[", "245", ",", "145", ",", "50", "]", ",", "\n", "[", "70", ",", "150", ",", "250", "]", ",", "\n", "[", "50", ",", "190", ",", "190", "]", ",", "\n", "]", "\n", "return", "colors", "[", "random", ".", "randrange", "(", "0", ",", "10", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.apply_color_mask": [[203, 214], ["numpy.zeros_like().astype", "numpy.zeros_like().astype", "numpy.zeros_like().astype", "numpy.stack", "numpy.zeros_like", "numpy.zeros_like", "numpy.zeros_like"], "function", ["None"], ["", "def", "apply_color_mask", "(", "image", ":", "np", ".", "ndarray", ",", "color", ":", "tuple", ")", ":", "\n", "    ", "\"\"\"\n    Applies color mask to given input image.\n    \"\"\"", "\n", "r", "=", "np", ".", "zeros_like", "(", "image", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "g", "=", "np", ".", "zeros_like", "(", "image", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "b", "=", "np", ".", "zeros_like", "(", "image", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "(", "r", "[", "image", "==", "1", "]", ",", "g", "[", "image", "==", "1", "]", ",", "b", "[", "image", "==", "1", "]", ")", "=", "color", "\n", "colored_mask", "=", "np", ".", "stack", "(", "[", "r", ",", "g", ",", "b", "]", ",", "axis", "=", "2", ")", "\n", "return", "colored_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_video_reader": [[216, 312], ["os.path.basename", "cv2.VideoCapture", "int", "cv2.VideoCapture.get", "int", "int", "int", "cv2.VideoWriter_fourcc", "cv2.VideoWriter", "cv.get_video_reader.read_video_frame"], "function", ["None"], ["", "def", "get_video_reader", "(", "\n", "source", ":", "str", ",", "\n", "save_dir", ":", "str", ",", "\n", "frame_skip_interval", ":", "int", ",", "\n", "export_visual", ":", "bool", "=", "False", ",", "\n", "view_visual", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Creates OpenCV video capture object from given video file path.\n\n    Args:\n        source: Video file path\n        save_dir: Video export directory\n        frame_skip_interval: Frame skip interval\n        export_visual: Set True if you want to export visuals\n        view_visual: Set True if you want to render visual\n\n    Returns:\n        iterator: Pillow Image\n        video_writer: cv2.VideoWriter\n        video_file_name: video name with extension\n    \"\"\"", "\n", "# get video name with extension", "\n", "video_file_name", "=", "os", ".", "path", ".", "basename", "(", "source", ")", "\n", "# get video from video path", "\n", "video_capture", "=", "cv2", ".", "VideoCapture", "(", "source", ")", "\n", "\n", "num_frames", "=", "int", "(", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "if", "view_visual", ":", "\n", "        ", "num_frames", "/=", "frame_skip_interval", "+", "1", "\n", "num_frames", "=", "int", "(", "num_frames", ")", "\n", "\n", "", "def", "read_video_frame", "(", "video_capture", ",", "frame_skip_interval", ")", ":", "\n", "        ", "if", "view_visual", ":", "\n", "            ", "cv2", ".", "imshow", "(", "\"Prediction of {}\"", ".", "format", "(", "str", "(", "video_file_name", ")", ")", ",", "cv2", ".", "WINDOW_AUTOSIZE", ")", "\n", "\n", "while", "video_capture", ".", "isOpened", ":", "\n", "\n", "                ", "frame_num", "=", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ")", "\n", "video_capture", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "frame_num", "+", "frame_skip_interval", ")", "\n", "\n", "k", "=", "cv2", ".", "waitKey", "(", "20", ")", "\n", "frame_num", "=", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ")", "\n", "\n", "if", "k", "==", "27", ":", "\n", "                    ", "print", "(", "\n", "\"\\n===========================Closing===========================\"", "\n", ")", "# Exit the prediction, Key = Esc", "\n", "exit", "(", ")", "\n", "", "if", "k", "==", "100", ":", "\n", "                    ", "frame_num", "+=", "100", "# Skip 100 frames, Key = d", "\n", "", "if", "k", "==", "97", ":", "\n", "                    ", "frame_num", "-=", "100", "# Prev 100 frames, Key = a", "\n", "", "if", "k", "==", "103", ":", "\n", "                    ", "frame_num", "+=", "20", "# Skip 20 frames, Key = g", "\n", "", "if", "k", "==", "102", ":", "\n", "                    ", "frame_num", "-=", "20", "# Prev 20 frames, Key = f", "\n", "", "video_capture", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "frame_num", ")", "\n", "\n", "ret", ",", "frame", "=", "video_capture", ".", "read", "(", ")", "\n", "if", "not", "ret", ":", "\n", "                    ", "print", "(", "\"\\n=========================== Video Ended ===========================\"", ")", "\n", "break", "\n", "", "yield", "Image", ".", "fromarray", "(", "frame", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "while", "video_capture", ".", "isOpened", ":", "\n", "                ", "frame_num", "=", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ")", "\n", "video_capture", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "frame_num", "+", "frame_skip_interval", ")", "\n", "\n", "ret", ",", "frame", "=", "video_capture", ".", "read", "(", ")", "\n", "if", "not", "ret", ":", "\n", "                    ", "print", "(", "\"\\n=========================== Video Ended ===========================\"", ")", "\n", "break", "\n", "", "yield", "Image", ".", "fromarray", "(", "frame", ")", "\n", "\n", "", "", "", "if", "export_visual", ":", "\n", "# get video properties and create VideoWriter object", "\n", "        ", "if", "frame_skip_interval", "!=", "0", ":", "\n", "            ", "fps", "=", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "# original fps of video", "\n", "# The fps of export video is increasing during view_image because frame is skipped", "\n", "fps", "=", "(", "\n", "fps", "/", "frame_skip_interval", "\n", ")", "# How many time_interval equals to original fps. One time_interval skip x frames.", "\n", "", "else", ":", "\n", "            ", "fps", "=", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "\n", "", "w", "=", "int", "(", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "h", "=", "int", "(", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "size", "=", "(", "w", ",", "h", ")", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "\"mp4v\"", ")", "\n", "video_writer", "=", "cv2", ".", "VideoWriter", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "video_file_name", ")", ",", "fourcc", ",", "fps", ",", "size", ")", "\n", "", "else", ":", "\n", "        ", "video_writer", "=", "None", "\n", "\n", "", "return", "read_video_frame", "(", "video_capture", ",", "frame_skip_interval", ")", ",", "video_writer", ",", "video_file_name", ",", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_prediction": [[314, 395], ["time.time", "copy.deepcopy", "range", "cv.Colors", "max", "max", "len", "copy.deepcopy", "cv2.rectangle", "cv2.rectangle", "cv2.putText", "sahi.utils.file.Path().mkdir", "os.path.join", "cv2.imwrite", "time.time", "round", "Colors.", "copy.deepcopy", "cv.apply_color_mask", "cv2.addWeighted", "cv2.getTextSize", "cv2.cvtColor", "numpy.squeeze", "int", "int", "int", "int", "sahi.utils.file.Path", "sum"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.apply_color_mask"], ["", "def", "visualize_prediction", "(", "\n", "image", ":", "np", ".", "ndarray", ",", "\n", "boxes", ":", "List", "[", "List", "]", ",", "\n", "classes", ":", "List", "[", "str", "]", ",", "\n", "masks", ":", "Optional", "[", "List", "[", "np", ".", "ndarray", "]", "]", "=", "None", ",", "\n", "rect_th", ":", "float", "=", "None", ",", "\n", "text_size", ":", "float", "=", "None", ",", "\n", "text_th", ":", "float", "=", "None", ",", "\n", "color", ":", "tuple", "=", "None", ",", "\n", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "file_name", ":", "Optional", "[", "str", "]", "=", "\"prediction_visual\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Visualizes prediction classes, bounding boxes over the source image\n    and exports it to output folder.\n    \"\"\"", "\n", "elapsed_time", "=", "time", ".", "time", "(", ")", "\n", "# deepcopy image so that original is not altered", "\n", "image", "=", "copy", ".", "deepcopy", "(", "image", ")", "\n", "# select predefined classwise color palette if not specified", "\n", "if", "color", "is", "None", ":", "\n", "        ", "colors", "=", "Colors", "(", ")", "\n", "", "else", ":", "\n", "        ", "colors", "=", "None", "\n", "# set rect_th for boxes", "\n", "", "rect_th", "=", "rect_th", "or", "max", "(", "round", "(", "sum", "(", "image", ".", "shape", ")", "/", "2", "*", "0.003", ")", ",", "2", ")", "\n", "# set text_th for category names", "\n", "text_th", "=", "text_th", "or", "max", "(", "rect_th", "-", "1", ",", "1", ")", "\n", "# set text_size for category names", "\n", "text_size", "=", "text_size", "or", "rect_th", "/", "3", "\n", "# add bbox and mask to image if present", "\n", "for", "i", "in", "range", "(", "len", "(", "boxes", ")", ")", ":", "\n", "# deepcopy boxso that original is not altered", "\n", "        ", "box", "=", "copy", ".", "deepcopy", "(", "boxes", "[", "i", "]", ")", "\n", "class_", "=", "classes", "[", "i", "]", "\n", "\n", "# set color", "\n", "if", "colors", "is", "not", "None", ":", "\n", "            ", "color", "=", "colors", "(", "class_", ")", "\n", "# visualize masks if present", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "# deepcopy mask so that original is not altered", "\n", "            ", "mask", "=", "copy", ".", "deepcopy", "(", "masks", "[", "i", "]", ")", "\n", "# draw mask", "\n", "rgb_mask", "=", "apply_color_mask", "(", "np", ".", "squeeze", "(", "mask", ")", ",", "color", ")", "\n", "image", "=", "cv2", ".", "addWeighted", "(", "image", ",", "1", ",", "rgb_mask", ",", "0.7", ",", "0", ")", "\n", "# set bbox points", "\n", "", "p1", ",", "p2", "=", "(", "int", "(", "box", "[", "0", "]", ")", ",", "int", "(", "box", "[", "1", "]", ")", ")", ",", "(", "int", "(", "box", "[", "2", "]", ")", ",", "int", "(", "box", "[", "3", "]", ")", ")", "\n", "# visualize boxes", "\n", "cv2", ".", "rectangle", "(", "\n", "image", ",", "\n", "p1", ",", "\n", "p2", ",", "\n", "color", "=", "color", ",", "\n", "thickness", "=", "rect_th", ",", "\n", ")", "\n", "# arange bounding box text location", "\n", "label", "=", "f\"{class_}\"", "\n", "w", ",", "h", "=", "cv2", ".", "getTextSize", "(", "label", ",", "0", ",", "fontScale", "=", "text_size", ",", "thickness", "=", "text_th", ")", "[", "0", "]", "# label width, height", "\n", "outside", "=", "p1", "[", "1", "]", "-", "h", "-", "3", ">=", "0", "# label fits outside box", "\n", "p2", "=", "p1", "[", "0", "]", "+", "w", ",", "p1", "[", "1", "]", "-", "h", "-", "3", "if", "outside", "else", "p1", "[", "1", "]", "+", "h", "+", "3", "\n", "# add bounding box text", "\n", "cv2", ".", "rectangle", "(", "image", ",", "p1", ",", "p2", ",", "color", ",", "-", "1", ",", "cv2", ".", "LINE_AA", ")", "# filled", "\n", "cv2", ".", "putText", "(", "\n", "image", ",", "\n", "label", ",", "\n", "(", "p1", "[", "0", "]", ",", "p1", "[", "1", "]", "-", "2", "if", "outside", "else", "p1", "[", "1", "]", "+", "h", "+", "2", ")", ",", "\n", "0", ",", "\n", "text_size", ",", "\n", "(", "255", ",", "255", ",", "255", ")", ",", "\n", "thickness", "=", "text_th", ",", "\n", ")", "\n", "", "if", "output_dir", ":", "\n", "# create output folder if not present", "\n", "        ", "Path", "(", "output_dir", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "# save inference result", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "file_name", "+", "\".png\"", ")", "\n", "cv2", ".", "imwrite", "(", "save_path", ",", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_RGB2BGR", ")", ")", "\n", "\n", "", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "elapsed_time", "\n", "return", "{", "\"image\"", ":", "image", ",", "\"elapsed_time\"", ":", "elapsed_time", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions": [[397, 491], ["time.time", "copy.deepcopy", "cv.Colors", "max", "max", "object_prediction.deepcopy.deepcopy", "object_prediction.deepcopy.bbox.to_voc_bbox", "cv2.rectangle", "cv2.rectangle", "cv2.putText", "sahi.utils.file.Path().mkdir", "str", "cv2.imwrite", "time.time", "round", "Colors.", "cv.apply_color_mask", "cv2.addWeighted", "cv2.getTextSize", "cv2.cvtColor", "int", "int", "int", "int", "sahi.utils.file.Path", "sahi.utils.file.Path", "sum"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.apply_color_mask"], ["", "def", "visualize_object_predictions", "(", "\n", "image", ":", "np", ".", "array", ",", "\n", "object_prediction_list", ",", "\n", "rect_th", ":", "int", "=", "None", ",", "\n", "text_size", ":", "float", "=", "None", ",", "\n", "text_th", ":", "float", "=", "None", ",", "\n", "color", ":", "tuple", "=", "None", ",", "\n", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "file_name", ":", "str", "=", "\"prediction_visual\"", ",", "\n", "export_format", ":", "str", "=", "\"png\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Visualizes prediction category names, bounding boxes over the source image\n    and exports it to output folder.\n    Arguments:\n        object_prediction_list: a list of prediction.ObjectPrediction\n        rect_th: rectangle thickness\n        text_size: size of the category name over box\n        text_th: text thickness\n        color: annotation color in the form: (0, 255, 0)\n        output_dir: directory for resulting visualization to be exported\n        file_name: exported file will be saved as: output_dir+file_name+\".png\"\n        export_format: can be specified as 'jpg' or 'png'\n    \"\"\"", "\n", "elapsed_time", "=", "time", ".", "time", "(", ")", "\n", "# deepcopy image so that original is not altered", "\n", "image", "=", "copy", ".", "deepcopy", "(", "image", ")", "\n", "# select predefined classwise color palette if not specified", "\n", "if", "color", "is", "None", ":", "\n", "        ", "colors", "=", "Colors", "(", ")", "\n", "", "else", ":", "\n", "        ", "colors", "=", "None", "\n", "# set rect_th for boxes", "\n", "", "rect_th", "=", "rect_th", "or", "max", "(", "round", "(", "sum", "(", "image", ".", "shape", ")", "/", "2", "*", "0.001", ")", ",", "1", ")", "\n", "# set text_th for category names", "\n", "text_th", "=", "text_th", "or", "max", "(", "rect_th", "-", "1", ",", "1", ")", "\n", "# set text_size for category names", "\n", "text_size", "=", "text_size", "or", "rect_th", "/", "3", "\n", "# add bbox and mask to image if present", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "# deepcopy object_prediction_list so that original is not altered", "\n", "        ", "object_prediction", "=", "object_prediction", ".", "deepcopy", "(", ")", "\n", "\n", "bbox", "=", "object_prediction", ".", "bbox", ".", "to_voc_bbox", "(", ")", "\n", "category_name", "=", "object_prediction", ".", "category", ".", "name", "\n", "score", "=", "object_prediction", ".", "score", ".", "value", "\n", "\n", "# set color", "\n", "if", "colors", "is", "not", "None", ":", "\n", "            ", "color", "=", "colors", "(", "object_prediction", ".", "category", ".", "id", ")", "\n", "# visualize masks if present", "\n", "", "if", "object_prediction", ".", "mask", "is", "not", "None", ":", "\n", "# deepcopy mask so that original is not altered", "\n", "            ", "mask", "=", "object_prediction", ".", "mask", ".", "bool_mask", "\n", "# draw mask", "\n", "rgb_mask", "=", "apply_color_mask", "(", "mask", ",", "color", ")", "\n", "image", "=", "cv2", ".", "addWeighted", "(", "image", ",", "1", ",", "rgb_mask", ",", "0.4", ",", "0", ")", "\n", "# set bbox points", "\n", "", "p1", ",", "p2", "=", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", ",", "(", "int", "(", "bbox", "[", "2", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", "\n", "# visualize boxes", "\n", "cv2", ".", "rectangle", "(", "\n", "image", ",", "\n", "p1", ",", "\n", "p2", ",", "\n", "color", "=", "color", ",", "\n", "thickness", "=", "rect_th", ",", "\n", ")", "\n", "# arange bounding box text location", "\n", "label", "=", "f\"{category_name} {score:.2f}\"", "\n", "w", ",", "h", "=", "cv2", ".", "getTextSize", "(", "label", ",", "0", ",", "fontScale", "=", "text_size", ",", "thickness", "=", "text_th", ")", "[", "0", "]", "# label width, height", "\n", "outside", "=", "p1", "[", "1", "]", "-", "h", "-", "3", ">=", "0", "# label fits outside box", "\n", "p2", "=", "p1", "[", "0", "]", "+", "w", ",", "p1", "[", "1", "]", "-", "h", "-", "3", "if", "outside", "else", "p1", "[", "1", "]", "+", "h", "+", "3", "\n", "# add bounding box text", "\n", "cv2", ".", "rectangle", "(", "image", ",", "p1", ",", "p2", ",", "color", ",", "-", "1", ",", "cv2", ".", "LINE_AA", ")", "# filled", "\n", "cv2", ".", "putText", "(", "\n", "image", ",", "\n", "label", ",", "\n", "(", "p1", "[", "0", "]", ",", "p1", "[", "1", "]", "-", "2", "if", "outside", "else", "p1", "[", "1", "]", "+", "h", "+", "2", ")", ",", "\n", "0", ",", "\n", "text_size", ",", "\n", "(", "255", ",", "255", ",", "255", ")", ",", "\n", "thickness", "=", "text_th", ",", "\n", ")", "\n", "\n", "# export if output_dir is present", "\n", "", "if", "output_dir", "is", "not", "None", ":", "\n", "# export image with predictions", "\n", "        ", "Path", "(", "output_dir", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "# save inference result", "\n", "save_path", "=", "str", "(", "Path", "(", "output_dir", ")", "/", "(", "file_name", "+", "\".\"", "+", "export_format", ")", ")", "\n", "cv2", ".", "imwrite", "(", "save_path", ",", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_RGB2BGR", ")", ")", "\n", "\n", "", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "elapsed_time", "\n", "return", "{", "\"image\"", ":", "image", ",", "\"elapsed_time\"", ":", "elapsed_time", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_coco_segmentation_from_bool_mask": [[493, 516], ["numpy.squeeze", "cv2.copyMakeBorder.astype", "cv2.copyMakeBorder", "cv2.findContours", "polygon.flatten().tolist", "len", "len", "coco_segmentation.append", "polygon.flatten"], "function", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "get_coco_segmentation_from_bool_mask", "(", "bool_mask", ")", ":", "\n", "    ", "\"\"\"\n    Convert boolean mask to coco segmentation format\n    [\n        [x1, y1, x2, y2, x3, y3, ...],\n        [x1, y1, x2, y2, x3, y3, ...],\n        ...\n    ]\n    \"\"\"", "\n", "# Generate polygons from mask", "\n", "mask", "=", "np", ".", "squeeze", "(", "bool_mask", ")", "\n", "mask", "=", "mask", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "mask", "=", "cv2", ".", "copyMakeBorder", "(", "mask", ",", "1", ",", "1", ",", "1", ",", "1", ",", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "0", ")", "\n", "polygons", "=", "cv2", ".", "findContours", "(", "mask", ",", "cv2", ".", "RETR_LIST", ",", "cv2", ".", "CHAIN_APPROX_SIMPLE", ",", "offset", "=", "(", "-", "1", ",", "-", "1", ")", ")", "\n", "polygons", "=", "polygons", "[", "0", "]", "if", "len", "(", "polygons", ")", "==", "2", "else", "polygons", "[", "1", "]", "\n", "# Convert polygon to coco segmentation", "\n", "coco_segmentation", "=", "[", "]", "\n", "for", "polygon", "in", "polygons", ":", "\n", "        ", "segmentation", "=", "polygon", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "# at least 3 points needed for a polygon", "\n", "if", "len", "(", "segmentation", ")", ">=", "6", ":", "\n", "            ", "coco_segmentation", ".", "append", "(", "segmentation", ")", "\n", "", "", "return", "coco_segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bool_mask_from_coco_segmentation": [[518, 528], ["numpy.zeros", "cv2.fillPoly", "cv2.fillPoly.astype", "numpy.array().reshape().round().astype", "numpy.array().reshape().round", "numpy.array().reshape", "numpy.array"], "function", ["None"], ["", "def", "get_bool_mask_from_coco_segmentation", "(", "coco_segmentation", ",", "width", ",", "height", ")", ":", "\n", "    ", "\"\"\"\n    Convert coco segmentation to 2D boolean mask of given height and width\n    \"\"\"", "\n", "size", "=", "[", "height", ",", "width", "]", "\n", "points", "=", "[", "np", ".", "array", "(", "point", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", ".", "round", "(", ")", ".", "astype", "(", "int", ")", "for", "point", "in", "coco_segmentation", "]", "\n", "bool_mask", "=", "np", ".", "zeros", "(", "size", ")", "\n", "bool_mask", "=", "cv2", ".", "fillPoly", "(", "bool_mask", ",", "points", ",", "1", ")", "\n", "bool_mask", ".", "astype", "(", "bool", ")", "\n", "return", "bool_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_bbox_from_bool_mask": [[530, 549], ["numpy.any", "numpy.any", "numpy.any", "numpy.any", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "get_bbox_from_bool_mask", "(", "bool_mask", ")", ":", "\n", "    ", "\"\"\"\n    Generate voc bbox ([xmin, ymin, xmax, ymax]) from given bool_mask (2D np.ndarray)\n    \"\"\"", "\n", "rows", "=", "np", ".", "any", "(", "bool_mask", ",", "axis", "=", "1", ")", "\n", "cols", "=", "np", ".", "any", "(", "bool_mask", ",", "axis", "=", "0", ")", "\n", "\n", "if", "not", "np", ".", "any", "(", "rows", ")", "or", "not", "np", ".", "any", "(", "cols", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "", "ymin", ",", "ymax", "=", "np", ".", "where", "(", "rows", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "xmin", ",", "xmax", "=", "np", ".", "where", "(", "cols", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "width", "=", "xmax", "-", "xmin", "\n", "height", "=", "ymax", "-", "ymin", "\n", "\n", "if", "width", "==", "0", "or", "height", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.normalize_numpy_image": [[551, 556], ["numpy.max"], "function", ["None"], ["", "def", "normalize_numpy_image", "(", "image", ":", "np", ".", "ndarray", ")", ":", "\n", "    ", "\"\"\"\n    Normalizes numpy image\n    \"\"\"", "\n", "return", "image", "/", "np", ".", "max", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.ipython_display": [[558, 571], ["cv2.cvtColor", "cv2.imencode", "IPython.display.Image", "IPython.display.display"], "function", ["None"], ["", "def", "ipython_display", "(", "image", ":", "np", ".", "ndarray", ")", ":", "\n", "    ", "\"\"\"\n    Displays numpy image in notebook.\n\n    If input image is in range 0..1, please first multiply img by 255\n    Assumes image is ndarray of shape [height, width, channels] where channels can be 1, 3 or 4\n    \"\"\"", "\n", "import", "IPython", "\n", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "_", ",", "ret", "=", "cv2", ".", "imencode", "(", "\".png\"", ",", "image", ")", "\n", "i", "=", "IPython", ".", "display", ".", "Image", "(", "data", "=", "ret", ")", "\n", "IPython", ".", "display", ".", "display", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.cv.exif_transpose": [[573, 597], ["image.transpose.getexif", "image.getexif.get", "image.transpose.transpose", "image.getexif.tobytes"], "function", ["None"], ["", "def", "exif_transpose", "(", "image", ":", "Image", ".", "Image", ")", ":", "\n", "    ", "\"\"\"\n    Transpose a PIL image accordingly if it has an EXIF Orientation tag.\n    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose()\n    :param image: The image to transpose.\n    :return: An image.\n    \"\"\"", "\n", "exif", "=", "image", ".", "getexif", "(", ")", "\n", "orientation", "=", "exif", ".", "get", "(", "0x0112", ",", "1", ")", "# default 1", "\n", "if", "orientation", ">", "1", ":", "\n", "        ", "method", "=", "{", "\n", "2", ":", "Image", ".", "FLIP_LEFT_RIGHT", ",", "\n", "3", ":", "Image", ".", "ROTATE_180", ",", "\n", "4", ":", "Image", ".", "FLIP_TOP_BOTTOM", ",", "\n", "5", ":", "Image", ".", "TRANSPOSE", ",", "\n", "6", ":", "Image", ".", "ROTATE_270", ",", "\n", "7", ":", "Image", ".", "TRANSVERSE", ",", "\n", "8", ":", "Image", ".", "ROTATE_90", ",", "\n", "}", ".", "get", "(", "orientation", ")", "\n", "if", "method", "is", "not", "None", ":", "\n", "            ", "image", "=", "image", ".", "transpose", "(", "method", ")", "\n", "del", "exif", "[", "0x0112", "]", "\n", "image", ".", "info", "[", "\"exif\"", "]", "=", "exif", ".", "tobytes", "(", ")", "\n", "", "", "return", "image", "\n", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model": [[18, 29], ["pathlib.Path().parent.mkdir", "os.path.exists", "urllib.request.urlretrieve", "pathlib.Path"], "function", ["None"], ["", "def", "download_yolov5n_model", "(", "destination_path", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "\n", "    ", "if", "destination_path", "is", "None", ":", "\n", "        ", "destination_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", "\n", "\n", "", "Path", "(", "destination_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "destination_path", ")", ":", "\n", "        ", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_URL", ",", "\n", "destination_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5s6_model": [[32, 43], ["pathlib.Path().parent.mkdir", "os.path.exists", "urllib.request.urlretrieve", "pathlib.Path"], "function", ["None"], ["", "", "def", "download_yolov5s6_model", "(", "destination_path", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "\n", "    ", "if", "destination_path", "is", "None", ":", "\n", "        ", "destination_path", "=", "Yolov5TestConstants", ".", "YOLOV5S6_MODEL_PATH", "\n", "\n", "", "Path", "(", "destination_path", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "destination_path", ")", ":", "\n", "        ", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "Yolov5TestConstants", ".", "YOLOV5S6_MODEL_URL", ",", "\n", "destination_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation": [[57, 70], ["shapely.get_shapely_multipolygon", "cls"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_multipolygon"], ["@", "classmethod", "\n", "def", "from_coco_segmentation", "(", "cls", ",", "segmentation", ",", "slice_bbox", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Init ShapelyAnnotation from coco segmentation.\n\n        segmentation : List[List]\n            [[1, 1, 325, 125, 250, 200, 5, 200]]\n        slice_bbox (List[int]): [xmin, ymin, width, height]\n            Should have the same format as the output of the get_bbox_from_shapely function.\n            Is used to calculate sliced coco coordinates.\n        \"\"\"", "\n", "shapely_multipolygon", "=", "get_shapely_multipolygon", "(", "segmentation", ")", "\n", "return", "cls", "(", "multipolygon", "=", "shapely_multipolygon", ",", "slice_bbox", "=", "slice_bbox", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox": [[71, 83], ["shapely.get_shapely_box", "shapely.geometry.MultiPolygon", "cls"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_box"], ["", "@", "classmethod", "\n", "def", "from_coco_bbox", "(", "cls", ",", "bbox", ":", "List", "[", "int", "]", ",", "slice_bbox", ":", "List", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Init ShapelyAnnotation from coco bbox.\n\n        bbox (List[int]): [xmin, ymin, width, height]\n        slice_bbox (List[int]): [x_min, y_min, x_max, y_max] Is used\n            to calculate sliced coco coordinates.\n        \"\"\"", "\n", "shapely_polygon", "=", "get_shapely_box", "(", "x", "=", "bbox", "[", "0", "]", ",", "y", "=", "bbox", "[", "1", "]", ",", "width", "=", "bbox", "[", "2", "]", ",", "height", "=", "bbox", "[", "3", "]", ")", "\n", "shapely_multipolygon", "=", "MultiPolygon", "(", "[", "shapely_polygon", "]", ")", "\n", "return", "cls", "(", "multipolygon", "=", "shapely_multipolygon", ",", "slice_bbox", "=", "slice_bbox", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.__init__": [[84, 87], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "multipolygon", ":", "MultiPolygon", ",", "slice_bbox", "=", "None", ")", ":", "\n", "        ", "self", ".", "multipolygon", "=", "multipolygon", "\n", "self", ".", "slice_bbox", "=", "slice_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.multipolygon": [[96, 105], ["None"], "methods", ["None"], ["", "@", "multipolygon", ".", "setter", "\n", "def", "multipolygon", "(", "self", ",", "multipolygon", ":", "MultiPolygon", ")", ":", "\n", "        ", "self", ".", "__multipolygon", "=", "multipolygon", "\n", "# calculate areas of all polygons", "\n", "area", "=", "0", "\n", "for", "shapely_polygon", "in", "multipolygon", ".", "geoms", ":", "\n", "            ", "area", "+=", "shapely_polygon", ".", "area", "\n", "# set instance area", "\n", "", "self", ".", "__area", "=", "area", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.area": [[92, 95], ["int"], "methods", ["None"], ["", "@", "property", "\n", "def", "area", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "self", ".", "__area", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_list": [[106, 133], ["list_of_list_of_points.append", "list", "zip"], "methods", ["None"], ["", "def", "to_list", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        [\n            [(x1, y1), (x2, y2), (x3, y3), ...],\n            [(x1, y1), (x2, y2), (x3, y3), ...],\n            ...\n        ]\n        \"\"\"", "\n", "list_of_list_of_points", ":", "List", "=", "[", "]", "\n", "for", "shapely_polygon", "in", "self", ".", "multipolygon", ".", "geoms", ":", "\n", "# create list_of_points for selected shapely_polygon", "\n", "            ", "if", "shapely_polygon", ".", "area", "!=", "0", ":", "\n", "                ", "x_coords", "=", "shapely_polygon", ".", "exterior", ".", "coords", ".", "xy", "[", "0", "]", "\n", "y_coords", "=", "shapely_polygon", ".", "exterior", ".", "coords", ".", "xy", "[", "1", "]", "\n", "# fix coord by slice_bbox", "\n", "if", "self", ".", "slice_bbox", ":", "\n", "                    ", "minx", "=", "self", ".", "slice_bbox", "[", "0", "]", "\n", "miny", "=", "self", ".", "slice_bbox", "[", "1", "]", "\n", "x_coords", "=", "[", "x_coord", "-", "minx", "for", "x_coord", "in", "x_coords", "]", "\n", "y_coords", "=", "[", "y_coord", "-", "miny", "for", "y_coord", "in", "y_coords", "]", "\n", "", "list_of_points", "=", "list", "(", "zip", "(", "x_coords", ",", "y_coords", ")", ")", "\n", "", "else", ":", "\n", "                ", "list_of_points", "=", "[", "]", "\n", "# append list_of_points to list_of_list_of_points", "\n", "", "list_of_list_of_points", ".", "append", "(", "list_of_points", ")", "\n", "# return result", "\n", "", "return", "list_of_list_of_points", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation": [[134, 167], ["coco_segmentation.append", "int", "int", "round", "len"], "methods", ["None"], ["", "def", "to_coco_segmentation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        [\n            [x1, y1, x2, y2, x3, y3, ...],\n            [x1, y1, x2, y2, x3, y3, ...],\n            ...\n        ]\n        \"\"\"", "\n", "coco_segmentation", ":", "List", "=", "[", "]", "\n", "for", "shapely_polygon", "in", "self", ".", "multipolygon", ".", "geoms", ":", "\n", "# create list_of_points for selected shapely_polygon", "\n", "            ", "if", "shapely_polygon", ".", "area", "!=", "0", ":", "\n", "                ", "x_coords", "=", "shapely_polygon", ".", "exterior", ".", "coords", ".", "xy", "[", "0", "]", "\n", "y_coords", "=", "shapely_polygon", ".", "exterior", ".", "coords", ".", "xy", "[", "1", "]", "\n", "# fix coord by slice_bbox", "\n", "if", "self", ".", "slice_bbox", ":", "\n", "                    ", "minx", "=", "self", ".", "slice_bbox", "[", "0", "]", "\n", "miny", "=", "self", ".", "slice_bbox", "[", "1", "]", "\n", "x_coords", "=", "[", "x_coord", "-", "minx", "for", "x_coord", "in", "x_coords", "]", "\n", "y_coords", "=", "[", "y_coord", "-", "miny", "for", "y_coord", "in", "y_coords", "]", "\n", "# convert intersection to coco style segmentation annotation", "\n", "", "coco_polygon", "=", "[", "None", "]", "*", "len", "(", "x_coords", ")", "*", "2", "\n", "coco_polygon", "[", "0", ":", ":", "2", "]", "=", "[", "int", "(", "coord", ")", "for", "coord", "in", "x_coords", "]", "\n", "coco_polygon", "[", "1", ":", ":", "2", "]", "=", "[", "int", "(", "coord", ")", "for", "coord", "in", "y_coords", "]", "\n", "", "else", ":", "\n", "                ", "coco_polygon", "=", "[", "]", "\n", "# remove if first and last points are duplicate", "\n", "", "if", "coco_polygon", "[", ":", "2", "]", "==", "coco_polygon", "[", "-", "2", ":", "]", ":", "\n", "                ", "del", "coco_polygon", "[", "-", "2", ":", "]", "\n", "# append coco_polygon to coco_segmentation", "\n", "", "coco_polygon", "=", "[", "round", "(", "point", ")", "for", "point", "in", "coco_polygon", "]", "if", "coco_polygon", "else", "coco_polygon", "\n", "coco_segmentation", ".", "append", "(", "coco_polygon", ")", "\n", "", "return", "coco_segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_opencv_contours": [[168, 194], ["opencv_contours.append", "range", "int", "int", "len"], "methods", ["None"], ["", "def", "to_opencv_contours", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        [\n            [[[1, 1]], [[325, 125]], [[250, 200]], [[5, 200]]],\n            [[[1, 1]], [[325, 125]], [[250, 200]], [[5, 200]]]\n        ]\n        \"\"\"", "\n", "opencv_contours", ":", "List", "=", "[", "]", "\n", "for", "shapely_polygon", "in", "self", ".", "multipolygon", ".", "geoms", ":", "\n", "# create opencv_contour for selected shapely_polygon", "\n", "            ", "if", "shapely_polygon", ".", "area", "!=", "0", ":", "\n", "                ", "x_coords", "=", "shapely_polygon", ".", "exterior", ".", "coords", ".", "xy", "[", "0", "]", "\n", "y_coords", "=", "shapely_polygon", ".", "exterior", ".", "coords", ".", "xy", "[", "1", "]", "\n", "# fix coord by slice_bbox", "\n", "if", "self", ".", "slice_bbox", ":", "\n", "                    ", "minx", "=", "self", ".", "slice_bbox", "[", "0", "]", "\n", "miny", "=", "self", ".", "slice_bbox", "[", "1", "]", "\n", "x_coords", "=", "[", "x_coord", "-", "minx", "for", "x_coord", "in", "x_coords", "]", "\n", "y_coords", "=", "[", "y_coord", "-", "miny", "for", "y_coord", "in", "y_coords", "]", "\n", "", "opencv_contour", "=", "[", "[", "[", "int", "(", "x_coords", "[", "ind", "]", ")", ",", "int", "(", "y_coords", "[", "ind", "]", ")", "]", "]", "for", "ind", "in", "range", "(", "len", "(", "x_coords", ")", ")", "]", "\n", "", "else", ":", "\n", "                ", "opencv_contour", ":", "List", "=", "[", "]", "\n", "# append opencv_contour to opencv_contours", "\n", "", "opencv_contours", ".", "append", "(", "opencv_contour", ")", "\n", "# return result", "\n", "", "return", "opencv_contours", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox": [[195, 210], ["shapely.get_bbox_from_shapely", "round", "round", "round", "round"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_bbox_from_shapely"], ["", "def", "to_coco_bbox", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        [xmin, ymin, width, height]\n        \"\"\"", "\n", "if", "self", ".", "multipolygon", ".", "area", "!=", "0", ":", "\n", "            ", "coco_bbox", ",", "_", "=", "get_bbox_from_shapely", "(", "self", ".", "multipolygon", ")", "\n", "# fix coord by slice box", "\n", "if", "self", ".", "slice_bbox", ":", "\n", "                ", "minx", "=", "round", "(", "self", ".", "slice_bbox", "[", "0", "]", ")", "\n", "miny", "=", "round", "(", "self", ".", "slice_bbox", "[", "1", "]", ")", "\n", "coco_bbox", "[", "0", "]", "=", "round", "(", "coco_bbox", "[", "0", "]", "-", "minx", ")", "\n", "coco_bbox", "[", "1", "]", "=", "round", "(", "coco_bbox", "[", "1", "]", "-", "miny", ")", "\n", "", "", "else", ":", "\n", "            ", "coco_bbox", ":", "List", "=", "[", "]", "\n", "", "return", "coco_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox": [[211, 228], ["shapely.get_bbox_from_shapely", "round", "round", "round", "round"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_bbox_from_shapely"], ["", "def", "to_voc_bbox", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        [xmin, ymin, xmax, ymax]\n        \"\"\"", "\n", "if", "self", ".", "multipolygon", ".", "area", "!=", "0", ":", "\n", "            ", "_", ",", "voc_bbox", "=", "get_bbox_from_shapely", "(", "self", ".", "multipolygon", ")", "\n", "# fix coord by slice box", "\n", "if", "self", ".", "slice_bbox", ":", "\n", "                ", "minx", "=", "self", ".", "slice_bbox", "[", "0", "]", "\n", "miny", "=", "self", ".", "slice_bbox", "[", "1", "]", "\n", "voc_bbox", "[", "0", "]", "=", "round", "(", "voc_bbox", "[", "0", "]", "-", "minx", ")", "\n", "voc_bbox", "[", "2", "]", "=", "round", "(", "voc_bbox", "[", "2", "]", "-", "minx", ")", "\n", "voc_bbox", "[", "1", "]", "=", "round", "(", "voc_bbox", "[", "1", "]", "-", "miny", ")", "\n", "voc_bbox", "[", "3", "]", "=", "round", "(", "voc_bbox", "[", "3", "]", "-", "miny", ")", "\n", "", "", "else", ":", "\n", "            ", "voc_bbox", "=", "[", "]", "\n", "", "return", "voc_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.get_convex_hull_shapely_annotation": [[229, 233], ["shapely.geometry.MultiPolygon", "shapely.ShapelyAnnotation"], "methods", ["None"], ["", "def", "get_convex_hull_shapely_annotation", "(", "self", ")", ":", "\n", "        ", "shapely_multipolygon", "=", "MultiPolygon", "(", "[", "self", ".", "multipolygon", ".", "convex_hull", "]", ")", "\n", "shapely_annotation", "=", "ShapelyAnnotation", "(", "shapely_multipolygon", ")", "\n", "return", "shapely_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.get_simplified_shapely_annotation": [[234, 238], ["shapely.geometry.MultiPolygon", "shapely.ShapelyAnnotation", "shapely.ShapelyAnnotation.multipolygon.simplify"], "methods", ["None"], ["", "def", "get_simplified_shapely_annotation", "(", "self", ",", "tolerance", "=", "1", ")", ":", "\n", "        ", "shapely_multipolygon", "=", "MultiPolygon", "(", "[", "self", ".", "multipolygon", ".", "simplify", "(", "tolerance", ")", "]", ")", "\n", "shapely_annotation", "=", "ShapelyAnnotation", "(", "shapely_multipolygon", ")", "\n", "return", "shapely_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.get_buffered_shapely_annotation": [[239, 264], ["shapely.ShapelyAnnotation.multipolygon.buffer", "shapely.ShapelyAnnotation", "shapely.geometry.MultiPolygon"], "methods", ["None"], ["", "def", "get_buffered_shapely_annotation", "(", "\n", "self", ",", "\n", "distance", "=", "3", ",", "\n", "resolution", "=", "16", ",", "\n", "quadsegs", "=", "None", ",", "\n", "cap_style", "=", "CAP_STYLE", ".", "round", ",", "\n", "join_style", "=", "JOIN_STYLE", ".", "round", ",", "\n", "mitre_limit", "=", "5.0", ",", "\n", "single_sided", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Approximates the present polygon to have a valid polygon shape.\n        For more, check: https://shapely.readthedocs.io/en/stable/manual.html#object.buffer\n        \"\"\"", "\n", "buffered_polygon", "=", "self", ".", "multipolygon", ".", "buffer", "(", "\n", "distance", "=", "distance", ",", "\n", "resolution", "=", "resolution", ",", "\n", "quadsegs", "=", "quadsegs", ",", "\n", "cap_style", "=", "cap_style", ",", "\n", "join_style", "=", "join_style", ",", "\n", "mitre_limit", "=", "mitre_limit", ",", "\n", "single_sided", "=", "single_sided", ",", "\n", ")", "\n", "shapely_annotation", "=", "ShapelyAnnotation", "(", "MultiPolygon", "(", "[", "buffered_polygon", "]", ")", ")", "\n", "return", "shapely_annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.get_intersection": [[265, 292], ["shapely.ShapelyAnnotation.multipolygon.intersection", "shapely.ShapelyAnnotation", "shapely.get_bbox_from_shapely", "shapely.geometry.MultiPolygon", "len", "shapely.geometry.MultiPolygon"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_bbox_from_shapely"], ["", "def", "get_intersection", "(", "self", ",", "polygon", ":", "Polygon", ")", ":", "\n", "        ", "\"\"\"\n        Accepts shapely polygon object and returns the intersection in ShapelyAnnotation format\n        \"\"\"", "\n", "# convert intersection polygon to list of tuples", "\n", "intersection", "=", "self", ".", "multipolygon", ".", "intersection", "(", "polygon", ")", "\n", "# if polygon is box then set slice_box property", "\n", "if", "(", "\n", "len", "(", "polygon", ".", "exterior", ".", "xy", "[", "0", "]", ")", "==", "5", "\n", "and", "polygon", ".", "exterior", ".", "xy", "[", "0", "]", "[", "0", "]", "==", "polygon", ".", "exterior", ".", "xy", "[", "0", "]", "[", "1", "]", "\n", "and", "polygon", ".", "exterior", ".", "xy", "[", "0", "]", "[", "2", "]", "==", "polygon", ".", "exterior", ".", "xy", "[", "0", "]", "[", "3", "]", "\n", ")", ":", "\n", "            ", "coco_bbox", ",", "voc_bbox", "=", "get_bbox_from_shapely", "(", "polygon", ")", "\n", "slice_bbox", "=", "coco_bbox", "\n", "", "else", ":", "\n", "            ", "slice_bbox", "=", "None", "\n", "# convert intersection to multipolygon", "\n", "", "if", "intersection", ".", "geom_type", "==", "\"Polygon\"", ":", "\n", "            ", "intersection_multipolygon", "=", "MultiPolygon", "(", "[", "intersection", "]", ")", "\n", "", "elif", "intersection", ".", "geom_type", "==", "\"MultiPolygon\"", ":", "\n", "            ", "intersection_multipolygon", "=", "intersection", "\n", "", "else", ":", "\n", "            ", "intersection_multipolygon", "=", "MultiPolygon", "(", "[", "]", ")", "\n", "# create shapely annotation from intersection multipolygon", "\n", "", "intersection_shapely_annotation", "=", "ShapelyAnnotation", "(", "intersection_multipolygon", ",", "slice_bbox", ")", "\n", "\n", "return", "intersection_shapely_annotation", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_box": [[9, 20], ["shapely.geometry.box"], "function", ["None"], ["def", "get_shapely_box", "(", "x", ":", "int", ",", "y", ":", "int", ",", "width", ":", "int", ",", "height", ":", "int", ")", "->", "Polygon", ":", "\n", "    ", "\"\"\"\n    Accepts coco style bbox coords and converts it to shapely box object\n    \"\"\"", "\n", "minx", "=", "x", "\n", "miny", "=", "y", "\n", "maxx", "=", "x", "+", "width", "\n", "maxy", "=", "y", "+", "height", "\n", "shapely_box", "=", "box", "(", "minx", ",", "miny", ",", "maxx", ",", "maxy", ")", "\n", "\n", "return", "shapely_box", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_multipolygon": [[22, 34], ["shapely.geometry.MultiPolygon", "list", "shapely.geometry.Polygon", "polygon_list.append", "zip"], "function", ["None"], ["", "def", "get_shapely_multipolygon", "(", "coco_segmentation", ":", "List", "[", "List", "]", ")", "->", "MultiPolygon", ":", "\n", "    ", "\"\"\"\n    Accepts coco style polygon coords and converts it to shapely multipolygon object\n    \"\"\"", "\n", "polygon_list", "=", "[", "]", "\n", "for", "coco_polygon", "in", "coco_segmentation", ":", "\n", "        ", "point_list", "=", "list", "(", "zip", "(", "coco_polygon", "[", "0", ":", ":", "2", "]", ",", "coco_polygon", "[", "1", ":", ":", "2", "]", ")", ")", "\n", "shapely_polygon", "=", "Polygon", "(", "point_list", ")", "\n", "polygon_list", ".", "append", "(", "shapely_polygon", ")", "\n", "", "shapely_multipolygon", "=", "MultiPolygon", "(", "polygon_list", ")", "\n", "\n", "return", "shapely_multipolygon", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_bbox_from_shapely": [[36, 49], ["round", "round"], "function", ["None"], ["", "def", "get_bbox_from_shapely", "(", "shapely_object", ")", ":", "\n", "    ", "\"\"\"\n    Accepts shapely box/poly object and returns its bounding box in coco and voc formats\n    \"\"\"", "\n", "minx", ",", "miny", ",", "maxx", ",", "maxy", "=", "shapely_object", ".", "bounds", "\n", "width", "=", "maxx", "-", "minx", "\n", "height", "=", "maxy", "-", "miny", "\n", "coco_bbox", "=", "[", "minx", ",", "miny", ",", "width", ",", "height", "]", "\n", "coco_bbox", "=", "[", "round", "(", "point", ")", "for", "point", "in", "coco_bbox", "]", "if", "coco_bbox", "else", "coco_bbox", "\n", "voc_bbox", "=", "[", "minx", ",", "miny", ",", "maxx", ",", "maxy", "]", "\n", "voc_bbox", "=", "[", "round", "(", "point", ")", "for", "point", "in", "voc_bbox", "]", "if", "voc_bbox", "else", "voc_bbox", "\n", "\n", "return", "coco_bbox", ",", "voc_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info": [[16, 38], ["import_utils.is_available", "_importlib_metadata.version", "logger.info", "importlib.import_module"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.is_available"], ["def", "get_package_info", "(", "package_name", ":", "str", ",", "verbose", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Returns the package version as a string and the package name as a string.\n    \"\"\"", "\n", "_is_available", "=", "is_available", "(", "package_name", ")", "\n", "\n", "if", "_is_available", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "importlib", ".", "metadata", "as", "_importlib_metadata", "\n", "\n", "_version", "=", "_importlib_metadata", ".", "version", "(", "package_name", ")", "\n", "", "except", "(", "ModuleNotFoundError", ",", "AttributeError", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "_version", "=", "importlib", ".", "import_module", "(", "package_name", ")", ".", "__version__", "\n", "", "except", "AttributeError", ":", "\n", "                ", "_version", "=", "\"unknown\"", "\n", "", "", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "f\"{package_name} version {_version} is available.\"", ")", "\n", "", "", "else", ":", "\n", "        ", "_version", "=", "\"N/A\"", "\n", "\n", "", "return", "_is_available", ",", "_version", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.print_enviroment_info": [[40, 54], ["import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info", "import_utils.get_package_info"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.get_package_info"], ["", "def", "print_enviroment_info", "(", ")", ":", "\n", "    ", "_torch_available", ",", "_torch_version", "=", "get_package_info", "(", "\"torch\"", ")", "\n", "_torchvision_available", ",", "_torchvision_version", "=", "get_package_info", "(", "\"torchvision\"", ")", "\n", "_tensorflow_available", ",", "_tensorflow_version", "=", "get_package_info", "(", "\"tensorflow\"", ")", "\n", "_tensorflow_hub_available", ",", "_tensorflow_hub_version", "=", "get_package_info", "(", "\"tensorflow-hub\"", ")", "\n", "_yolov5_available", ",", "_yolov5_version", "=", "get_package_info", "(", "\"yolov5\"", ")", "\n", "_mmdet_available", ",", "_mmdet_version", "=", "get_package_info", "(", "\"mmdet\"", ")", "\n", "_mmcv_available", ",", "_mmcv_version", "=", "get_package_info", "(", "\"mmcv\"", ")", "\n", "_detectron2_available", ",", "_detectron2_version", "=", "get_package_info", "(", "\"detectron2\"", ")", "\n", "_transformers_available", ",", "_transformers_version", "=", "get_package_info", "(", "\"transformers\"", ")", "\n", "_timm_available", ",", "_timm_version", "=", "get_package_info", "(", "\"timm\"", ")", "\n", "_layer_available", ",", "_layer_version", "=", "get_package_info", "(", "\"layer\"", ")", "\n", "_fiftyone_available", ",", "_fiftyone_version", "=", "get_package_info", "(", "\"fiftyone\"", ")", "\n", "_norfair_available", ",", "_norfair_version", "=", "get_package_info", "(", "\"norfair\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.is_available": [[56, 58], ["importlib.util.find_spec"], "function", ["None"], ["", "def", "is_available", "(", "module_name", ":", "str", ")", ":", "\n", "    ", "return", "importlib", ".", "util", ".", "find_spec", "(", "module_name", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements": [[60, 72], ["ImportError", "importlib.util.find_spec", "missing_packages.append"], "function", ["None"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "check_requirements", "(", "package_names", ")", ":", "\n", "    ", "\"\"\"\n    Raise error if module is not installed.\n    \"\"\"", "\n", "missing_packages", "=", "[", "]", "\n", "for", "package_name", "in", "package_names", ":", "\n", "        ", "if", "importlib", ".", "util", ".", "find_spec", "(", "package_name", ")", "is", "None", ":", "\n", "            ", "missing_packages", ".", "append", "(", "package_name", ")", "\n", "", "", "if", "missing_packages", ":", "\n", "        ", "raise", "ImportError", "(", "f\"The following packages are required to use this module: {missing_packages}\"", ")", "\n", "", "yield", "\n", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.detectron2.export_cfg_as_yaml": [[10, 22], ["pathlib.Path().parent.mkdir", "open", "f.write", "cfg.dump", "pathlib.Path"], "function", ["None"], ["", "def", "export_cfg_as_yaml", "(", "cfg", ",", "export_path", ":", "str", "=", "\"config.yaml\"", ")", ":", "\n", "    ", "\"\"\"\n    Exports Detectron2 config object in yaml format so that it can be used later.\n    Args:\n        cfg (detectron2.config.CfgNode): Detectron2 config object.\n        export_path (str): Path to export the Detectron2 config.\n    Related Detectron2 doc: https://detectron2.readthedocs.io/en/stable/modules/config.html#detectron2.config.CfgNode.dump\n    \"\"\"", "\n", "Path", "(", "export_path", ")", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "with", "open", "(", "export_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "cfg", ".", "dump", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.torch.empty_cuda_cache": [[8, 16], ["sahi.utils.import_utils.check_requirements", "torch.is_torch_cuda_available", "torch.cuda.empty_cache", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.utils.torch.is_torch_cuda_available"], ["@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "empty_cuda_cache", "(", ")", ":", "\n", "    ", "if", "is_torch_cuda_available", "(", ")", ":", "\n", "        ", "import", "torch", "\n", "\n", "return", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"CUDA not available.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.torch.to_float_tensor": [[18, 36], ["sahi.utils.import_utils.check_requirements", "torch.from_numpy().float.transpose", "torch.from_numpy().float", "torch.from_numpy().float.max", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements"], ["", "", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "to_float_tensor", "(", "img", ")", ":", "\n", "    ", "\"\"\"\n    Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range\n    [0, 255] to a torch.FloatTensor of shape (C x H x W).\n    Args:\n        img: np.ndarray\n    Returns:\n        torch.tensor\n    \"\"\"", "\n", "import", "torch", "\n", "\n", "img", "=", "img", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "img", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "float", "(", ")", "\n", "if", "img", ".", "max", "(", ")", ">", "1", ":", "\n", "        ", "img", "/=", "255", "\n", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.torch.torch_to_numpy": [[38, 46], ["sahi.utils.import_utils.check_requirements", "img.numpy.numpy", "img.numpy.transpose", "img.numpy.max"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "torch_to_numpy", "(", "img", ")", ":", "\n", "    ", "import", "torch", "\n", "\n", "img", "=", "img", ".", "numpy", "(", ")", "\n", "if", "img", ".", "max", "(", ")", ">", "1", ":", "\n", "        ", "img", "/=", "255", "\n", "", "return", "img", ".", "transpose", "(", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.torch.is_torch_cuda_available": [[48, 56], ["sahi.utils.import_utils.check_requirements", "sahi.utils.import_utils.is_available", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.is_available", "home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.is_available"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "is_torch_cuda_available", "(", ")", ":", "\n", "    ", "if", "is_available", "(", "\"torch\"", ")", ":", "\n", "        ", "import", "torch", "\n", "\n", "return", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_shift_amount_list": [[1, 6], ["isinstance"], "function", ["None"], ["def", "fix_shift_amount_list", "(", "shift_amount_list", ")", ":", "\n", "# compatilibty for sahi v0.8.15", "\n", "    ", "if", "isinstance", "(", "shift_amount_list", "[", "0", "]", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "        ", "shift_amount_list", "=", "[", "shift_amount_list", "]", "\n", "", "return", "shift_amount_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.utils.compatibility.fix_full_shape_list": [[8, 13], ["isinstance"], "function", ["None"], ["", "def", "fix_full_shape_list", "(", "full_shape_list", ")", ":", "\n", "# compatilibty for sahi v0.8.15", "\n", "    ", "if", "full_shape_list", "is", "not", "None", "and", "isinstance", "(", "full_shape_list", "[", "0", "]", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "        ", "full_shape_list", "=", "[", "full_shape_list", "]", "\n", "", "return", "full_shape_list", "\n", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._makeplot": [[23, 75], ["range", "len", "ps_curve.insert", "plt.figure", "plt.subplot", "range", "plt.xlabel", "plt.ylabel", "plt.xlim", "plt.ylim", "plt.title", "plt.legend", "str", "plt.figure.savefig", "plt.close", "export_path_list.append", "len", "aps.append", "numpy.zeros", "len", "plt.subplot.plot", "plt.subplot.fill_between", "numpy.zeros", "enumerate", "ps_curve.append", "ps_curve.append", "ps_[].mean", "numpy.array", "pathlib.Path", "ps_threshold[].mean", "str"], "function", ["None"], ["def", "_makeplot", "(", "rs", ",", "ps", ",", "outDir", ",", "class_name", ",", "iou_type", ")", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "export_path_list", "=", "[", "]", "\n", "\n", "areaNames", "=", "[", "\"allarea\"", ",", "\"small\"", ",", "\"medium\"", ",", "\"large\"", "]", "\n", "types", "=", "[", "\"C75\"", ",", "\"C50\"", ",", "\"Loc\"", ",", "\"Sim\"", ",", "\"Oth\"", ",", "\"BG\"", ",", "\"FN\"", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "areaNames", ")", ")", ":", "\n", "        ", "area_ps", "=", "ps", "[", "...", ",", "i", ",", "0", "]", "\n", "figure_title", "=", "iou_type", "+", "\"-\"", "+", "class_name", "+", "\"-\"", "+", "areaNames", "[", "i", "]", "\n", "aps", "=", "[", "]", "\n", "ps_curve", "=", "[", "]", "\n", "for", "ps_", "in", "area_ps", ":", "\n", "# calculate precision recal curves", "\n", "            ", "if", "ps_", ".", "ndim", ">", "1", ":", "\n", "                ", "ps_mean", "=", "np", ".", "zeros", "(", "(", "ps_", ".", "shape", "[", "0", "]", ",", ")", ")", "\n", "for", "ind", ",", "ps_threshold", "in", "enumerate", "(", "ps_", ")", ":", "\n", "                    ", "ps_mean", "[", "ind", "]", "=", "ps_threshold", "[", "ps_threshold", ">", "-", "1", "]", ".", "mean", "(", ")", "\n", "", "ps_curve", ".", "append", "(", "ps_mean", ")", "\n", "", "else", ":", "\n", "                ", "ps_curve", ".", "append", "(", "ps_", ")", "\n", "# calculate ap", "\n", "", "if", "len", "(", "ps_", "[", "ps_", ">", "-", "1", "]", ")", ":", "\n", "                ", "ap", "=", "ps_", "[", "ps_", ">", "-", "1", "]", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "ap", "=", "np", ".", "array", "(", "0", ")", "\n", "", "aps", ".", "append", "(", "ap", ")", "\n", "", "ps_curve", ".", "insert", "(", "0", ",", "np", ".", "zeros", "(", "ps_curve", "[", "0", "]", ".", "shape", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "111", ")", "\n", "for", "k", "in", "range", "(", "len", "(", "types", ")", ")", ":", "\n", "            ", "ax", ".", "plot", "(", "rs", ",", "ps_curve", "[", "k", "+", "1", "]", ",", "color", "=", "[", "0", ",", "0", ",", "0", "]", ",", "linewidth", "=", "0.5", ")", "\n", "ax", ".", "fill_between", "(", "\n", "rs", ",", "\n", "ps_curve", "[", "k", "]", ",", "\n", "ps_curve", "[", "k", "+", "1", "]", ",", "\n", "color", "=", "COLOR_PALETTE", "[", "k", "]", ",", "\n", "label", "=", "str", "(", "f\"[{aps[k]:.3f}]\"", "+", "types", "[", "k", "]", ")", ",", "\n", ")", "\n", "", "plt", ".", "xlabel", "(", "\"recall\"", ")", "\n", "plt", ".", "ylabel", "(", "\"precision\"", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "1.0", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1.0", ")", "\n", "plt", ".", "title", "(", "figure_title", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "# plt.show()", "\n", "export_path", "=", "str", "(", "Path", "(", "outDir", ")", "/", "f\"{figure_title}.png\"", ")", "\n", "fig", ".", "savefig", "(", "export_path", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "export_path_list", ".", "append", "(", "export_path", ")", "\n", "", "return", "export_path_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._autolabel": [[77, 93], ["rect.get_height", "ax.annotate", "rect.get_x", "rect.get_width"], "function", ["None"], ["", "def", "_autolabel", "(", "ax", ",", "rects", ",", "is_percent", "=", "True", ")", ":", "\n", "    ", "\"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"", "\n", "for", "rect", "in", "rects", ":", "\n", "        ", "height", "=", "rect", ".", "get_height", "(", ")", "\n", "if", "is_percent", "and", "height", ">", "0", "and", "height", "<=", "1", ":", "# for percent values", "\n", "            ", "text_label", "=", "\"{:2.0f}\"", ".", "format", "(", "height", "*", "100", ")", "\n", "", "else", ":", "\n", "            ", "text_label", "=", "\"{:2.0f}\"", ".", "format", "(", "height", ")", "\n", "", "ax", ".", "annotate", "(", "\n", "text_label", ",", "\n", "xy", "=", "(", "rect", ".", "get_x", "(", ")", "+", "rect", ".", "get_width", "(", ")", "/", "2", ",", "height", ")", ",", "\n", "xytext", "=", "(", "0", ",", "3", ")", ",", "# 3 points vertical offset", "\n", "textcoords", "=", "\"offset points\"", ",", "\n", "ha", "=", "\"center\"", ",", "\n", "va", "=", "\"bottom\"", ",", "\n", "fontsize", "=", "\"x-small\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._makebarplot": [[96, 144], ["plt.subplots", "numpy.arange", "range", "ax.set_ylabel", "ax.set_title", "ax.set_xticks", "ax.set_xticklabels", "ax.legend", "str", "fig.savefig", "plt.close", "len", "rects_list.append", "coco_error_analysis._autolabel", "len", "len", "aps.append", "ax.bar", "pathlib.Path", "ps_[].mean", "numpy.array", "len", "len"], "function", ["home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._autolabel"], ["", "", "def", "_makebarplot", "(", "rs", ",", "ps", ",", "outDir", ",", "class_name", ",", "iou_type", ")", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "areaNames", "=", "[", "\"allarea\"", ",", "\"small\"", ",", "\"medium\"", ",", "\"large\"", "]", "\n", "types", "=", "[", "\"C75\"", ",", "\"C50\"", ",", "\"Loc\"", ",", "\"Sim\"", ",", "\"Oth\"", ",", "\"BG\"", ",", "\"FN\"", "]", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "x", "=", "np", ".", "arange", "(", "len", "(", "areaNames", ")", ")", "# the areaNames locations", "\n", "width", "=", "0.60", "# the width of the bars", "\n", "rects_list", "=", "[", "]", "\n", "figure_title", "=", "iou_type", "+", "\"-\"", "+", "class_name", "+", "\"-\"", "+", "\"ap bar plot\"", "\n", "for", "k", "in", "range", "(", "len", "(", "types", ")", "-", "1", ")", ":", "\n", "        ", "type_ps", "=", "ps", "[", "k", ",", "...", ",", "0", "]", "\n", "# calculate ap", "\n", "aps", "=", "[", "]", "\n", "for", "ps_", "in", "type_ps", ".", "T", ":", "\n", "            ", "if", "len", "(", "ps_", "[", "ps_", ">", "-", "1", "]", ")", ":", "\n", "                ", "ap", "=", "ps_", "[", "ps_", ">", "-", "1", "]", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "ap", "=", "np", ".", "array", "(", "0", ")", "\n", "", "aps", ".", "append", "(", "ap", ")", "\n", "# create bars", "\n", "", "rects_list", ".", "append", "(", "\n", "ax", ".", "bar", "(", "\n", "x", "-", "width", "/", "2", "+", "(", "k", "+", "1", ")", "*", "width", "/", "len", "(", "types", ")", ",", "\n", "aps", ",", "\n", "width", "/", "len", "(", "types", ")", ",", "\n", "label", "=", "types", "[", "k", "]", ",", "\n", "color", "=", "COLOR_PALETTE", "[", "k", "]", ",", "\n", ")", "\n", ")", "\n", "\n", "# Add some text for labels, title and custom x-axis tick labels, etc.", "\n", "", "ax", ".", "set_ylabel", "(", "\"Mean Average Precision (mAP)\"", ")", "\n", "ax", ".", "set_title", "(", "figure_title", ")", "\n", "ax", ".", "set_xticks", "(", "x", ")", "\n", "ax", ".", "set_xticklabels", "(", "areaNames", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "\n", "# Add score texts over bars", "\n", "for", "rects", "in", "rects_list", ":", "\n", "        ", "_autolabel", "(", "ax", ",", "rects", ")", "\n", "\n", "# Save plot", "\n", "", "export_path", "=", "str", "(", "Path", "(", "outDir", ")", "/", "f\"{figure_title}.png\"", ")", "\n", "fig", ".", "savefig", "(", "export_path", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "return", "export_path", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._get_gt_area_group_numbers": [[146, 159], ["dict", "dict.fromkeys", "str", "zip", "str"], "function", ["None"], ["", "def", "_get_gt_area_group_numbers", "(", "cocoEval", ")", ":", "\n", "    ", "areaRng", "=", "cocoEval", ".", "params", ".", "areaRng", "\n", "areaRngStr", "=", "[", "str", "(", "aRng", ")", "for", "aRng", "in", "areaRng", "]", "\n", "areaRngLbl", "=", "cocoEval", ".", "params", ".", "areaRngLbl", "\n", "areaRngStr2areaRngLbl", "=", "dict", "(", "zip", "(", "areaRngStr", ",", "areaRngLbl", ")", ")", "\n", "areaRngLbl2Number", "=", "dict", ".", "fromkeys", "(", "areaRngLbl", ",", "0", ")", "\n", "for", "evalImg", "in", "cocoEval", ".", "evalImgs", ":", "\n", "        ", "if", "evalImg", ":", "\n", "            ", "for", "gtIgnore", "in", "evalImg", "[", "\"gtIgnore\"", "]", ":", "\n", "                ", "if", "not", "gtIgnore", ":", "\n", "                    ", "aRngLbl", "=", "areaRngStr2areaRngLbl", "[", "str", "(", "evalImg", "[", "\"aRng\"", "]", ")", "]", "\n", "areaRngLbl2Number", "[", "aRngLbl", "]", "+=", "1", "\n", "", "", "", "", "return", "areaRngLbl2Number", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._make_gt_area_group_numbers_plot": [[161, 193], ["coco_error_analysis._get_gt_area_group_numbers", "_get_gt_area_group_numbers.keys", "plt.subplots", "numpy.arange", "ax.bar", "ax.set_ylabel", "ax.set_title", "ax.set_xticks", "ax.set_xticklabels", "coco_error_analysis._autolabel", "str", "fig.tight_layout", "fig.savefig", "plt.close", "print", "len", "_get_gt_area_group_numbers.values", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._get_gt_area_group_numbers", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._autolabel"], ["", "def", "_make_gt_area_group_numbers_plot", "(", "cocoEval", ",", "outDir", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "areaRngLbl2Number", "=", "_get_gt_area_group_numbers", "(", "cocoEval", ")", "\n", "areaRngLbl", "=", "areaRngLbl2Number", ".", "keys", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"number of annotations per area group:\"", ",", "areaRngLbl2Number", ")", "\n", "\n", "# Init figure", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "x", "=", "np", ".", "arange", "(", "len", "(", "areaRngLbl", ")", ")", "# the areaNames locations", "\n", "width", "=", "0.60", "# the width of the bars", "\n", "figure_title", "=", "\"number of annotations per area group\"", "\n", "\n", "rects", "=", "ax", ".", "bar", "(", "x", ",", "areaRngLbl2Number", ".", "values", "(", ")", ",", "width", ")", "\n", "\n", "# Add some text for labels, title and custom x-axis tick labels, etc.", "\n", "ax", ".", "set_ylabel", "(", "\"Number of annotations\"", ")", "\n", "ax", ".", "set_title", "(", "figure_title", ")", "\n", "ax", ".", "set_xticks", "(", "x", ")", "\n", "ax", ".", "set_xticklabels", "(", "areaRngLbl", ")", "\n", "\n", "# Add score texts over bars", "\n", "_autolabel", "(", "ax", ",", "rects", ",", "is_percent", "=", "False", ")", "\n", "\n", "# Save plot", "\n", "export_path", "=", "str", "(", "Path", "(", "outDir", ")", "/", "f\"{figure_title}.png\"", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "export_path", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "return", "export_path", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._make_gt_area_histogram_plot": [[195, 220], ["plt.subplots", "ax.hist", "ax.set_xlabel", "ax.set_ylabel", "ax.set_title", "str", "fig.tight_layout", "fig.savefig", "plt.close", "numpy.sqrt", "cocoEval.cocoGt.anns.values", "pathlib.Path"], "function", ["None"], ["", "def", "_make_gt_area_histogram_plot", "(", "cocoEval", ",", "outDir", ")", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "n_bins", "=", "100", "\n", "areas", "=", "[", "ann", "[", "\"area\"", "]", "for", "ann", "in", "cocoEval", ".", "cocoGt", ".", "anns", ".", "values", "(", ")", "]", "\n", "\n", "# init figure", "\n", "figure_title", "=", "\"gt annotation areas histogram plot\"", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "# Set the number of bins", "\n", "ax", ".", "hist", "(", "np", ".", "sqrt", "(", "areas", ")", ",", "bins", "=", "n_bins", ")", "\n", "\n", "# Add some text for labels, title and custom x-axis tick labels, etc.", "\n", "ax", ".", "set_xlabel", "(", "\"Squareroot Area\"", ")", "\n", "ax", ".", "set_ylabel", "(", "\"Number of annotations\"", ")", "\n", "ax", ".", "set_title", "(", "figure_title", ")", "\n", "\n", "# Save plot", "\n", "export_path", "=", "str", "(", "Path", "(", "outDir", ")", "/", "f\"{figure_title}.png\"", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "export_path", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "return", "export_path", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._analyze_individual_category": [[222, 284], ["print", "copy.deepcopy", "cocoGt.getImgIds", "copy.deepcopy.createIndex", "copy.deepcopy", "copy.deepcopy.getCatIds", "enumerate", "COCOeval", "COCOeval.evaluate", "COCOeval.accumulate", "copy.deepcopy", "enumerate", "COCOeval", "COCOeval.evaluate", "COCOeval.accumulate", "cocoGt.loadCats", "cocoGt.loadCats", "copy.deepcopy", "copy.deepcopy", "select_dt_anns.append"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation.evaluate", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation.evaluate", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy"], ["", "def", "_analyze_individual_category", "(", "k", ",", "cocoDt", ",", "cocoGt", ",", "catId", ",", "iou_type", ",", "areas", "=", "None", ",", "max_detections", "=", "None", ",", "COCOeval", "=", "None", ")", ":", "\n", "    ", "nm", "=", "cocoGt", ".", "loadCats", "(", "catId", ")", "[", "0", "]", "\n", "print", "(", "f'--------------analyzing {k + 1}-{nm[\"name\"]}---------------'", ")", "\n", "ps_", "=", "{", "}", "\n", "dt", "=", "copy", ".", "deepcopy", "(", "cocoDt", ")", "\n", "nm", "=", "cocoGt", ".", "loadCats", "(", "catId", ")", "[", "0", "]", "\n", "imgIds", "=", "cocoGt", ".", "getImgIds", "(", ")", "\n", "dt_anns", "=", "dt", ".", "dataset", "[", "\"annotations\"", "]", "\n", "select_dt_anns", "=", "[", "]", "\n", "for", "ann", "in", "dt_anns", ":", "\n", "        ", "if", "ann", "[", "\"category_id\"", "]", "==", "catId", ":", "\n", "            ", "select_dt_anns", ".", "append", "(", "ann", ")", "\n", "", "", "dt", ".", "dataset", "[", "\"annotations\"", "]", "=", "select_dt_anns", "\n", "dt", ".", "createIndex", "(", ")", "\n", "# compute precision but ignore superclass confusion", "\n", "gt", "=", "copy", ".", "deepcopy", "(", "cocoGt", ")", "\n", "child_catIds", "=", "gt", ".", "getCatIds", "(", "supNms", "=", "[", "nm", "[", "\"supercategory\"", "]", "]", ")", "\n", "for", "idx", ",", "ann", "in", "enumerate", "(", "gt", ".", "dataset", "[", "\"annotations\"", "]", ")", ":", "\n", "        ", "if", "ann", "[", "\"category_id\"", "]", "in", "child_catIds", "and", "ann", "[", "\"category_id\"", "]", "!=", "catId", ":", "\n", "            ", "gt", ".", "dataset", "[", "\"annotations\"", "]", "[", "idx", "]", "[", "\"ignore\"", "]", "=", "1", "\n", "gt", ".", "dataset", "[", "\"annotations\"", "]", "[", "idx", "]", "[", "\"iscrowd\"", "]", "=", "1", "\n", "gt", ".", "dataset", "[", "\"annotations\"", "]", "[", "idx", "]", "[", "\"category_id\"", "]", "=", "catId", "\n", "", "", "cocoEval", "=", "COCOeval", "(", "gt", ",", "copy", ".", "deepcopy", "(", "dt", ")", ",", "iou_type", ")", "\n", "cocoEval", ".", "params", ".", "imgIds", "=", "imgIds", "\n", "cocoEval", ".", "params", ".", "maxDets", "=", "[", "max_detections", "]", "\n", "cocoEval", ".", "params", ".", "iouThrs", "=", "[", "0.1", "]", "\n", "cocoEval", ".", "params", ".", "useCats", "=", "1", "\n", "if", "areas", ":", "\n", "        ", "cocoEval", ".", "params", ".", "areaRng", "=", "[", "\n", "[", "0", "**", "2", ",", "areas", "[", "2", "]", "]", ",", "\n", "[", "0", "**", "2", ",", "areas", "[", "0", "]", "]", ",", "\n", "[", "areas", "[", "0", "]", ",", "areas", "[", "1", "]", "]", ",", "\n", "[", "areas", "[", "1", "]", ",", "areas", "[", "2", "]", "]", ",", "\n", "]", "\n", "", "cocoEval", ".", "evaluate", "(", ")", "\n", "cocoEval", ".", "accumulate", "(", ")", "\n", "ps_supercategory", "=", "cocoEval", ".", "eval", "[", "\"precision\"", "]", "[", "0", ",", ":", ",", "catId", ",", ":", ",", ":", "]", "\n", "ps_", "[", "\"ps_supercategory\"", "]", "=", "ps_supercategory", "\n", "# compute precision but ignore any class confusion", "\n", "gt", "=", "copy", ".", "deepcopy", "(", "cocoGt", ")", "\n", "for", "idx", ",", "ann", "in", "enumerate", "(", "gt", ".", "dataset", "[", "\"annotations\"", "]", ")", ":", "\n", "        ", "if", "ann", "[", "\"category_id\"", "]", "!=", "catId", ":", "\n", "            ", "gt", ".", "dataset", "[", "\"annotations\"", "]", "[", "idx", "]", "[", "\"ignore\"", "]", "=", "1", "\n", "gt", ".", "dataset", "[", "\"annotations\"", "]", "[", "idx", "]", "[", "\"iscrowd\"", "]", "=", "1", "\n", "gt", ".", "dataset", "[", "\"annotations\"", "]", "[", "idx", "]", "[", "\"category_id\"", "]", "=", "catId", "\n", "", "", "cocoEval", "=", "COCOeval", "(", "gt", ",", "copy", ".", "deepcopy", "(", "dt", ")", ",", "iou_type", ")", "\n", "cocoEval", ".", "params", ".", "imgIds", "=", "imgIds", "\n", "cocoEval", ".", "params", ".", "maxDets", "=", "[", "max_detections", "]", "\n", "cocoEval", ".", "params", ".", "iouThrs", "=", "[", "0.1", "]", "\n", "cocoEval", ".", "params", ".", "useCats", "=", "1", "\n", "if", "areas", ":", "\n", "        ", "cocoEval", ".", "params", ".", "areaRng", "=", "[", "\n", "[", "0", "**", "2", ",", "areas", "[", "2", "]", "]", ",", "\n", "[", "0", "**", "2", ",", "areas", "[", "0", "]", "]", ",", "\n", "[", "areas", "[", "0", "]", ",", "areas", "[", "1", "]", "]", ",", "\n", "[", "areas", "[", "1", "]", ",", "areas", "[", "2", "]", "]", ",", "\n", "]", "\n", "", "cocoEval", ".", "evaluate", "(", ")", "\n", "cocoEval", ".", "accumulate", "(", ")", "\n", "ps_allcategory", "=", "cocoEval", ".", "eval", "[", "\"precision\"", "]", "[", "0", ",", ":", ",", "catId", ",", ":", ",", ":", "]", "\n", "ps_", "[", "\"ps_allcategory\"", "]", "=", "ps_allcategory", "\n", "return", "k", ",", "ps_", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._analyse_results": [[286, 415], ["os.path.dirname", "COCO", "COCO.loadRes", "COCO.getImgIds", "print", "str", "os.path.exists", "print", "os.makedirs", "os.path.dirname", "COCOeval", "COCOeval.evaluate", "COCOeval.accumulate", "COCO.getCatIds", "enumerate", "list", "len", "numpy.zeros", "enumerate", "numpy.vstack", "enumerate", "coco_error_analysis._makeplot", "ValueError", "len", "ValueError", "pathlib.Path", "os.path.exists", "print", "os.makedirs", "copy.deepcopy", "copy.deepcopy", "COCO.getImgIds", "multiprocessing.Pool", "pool.starmap", "print", "nm[].replace().replace", "coco_error_analysis._makeplot", "coco_error_analysis._makebarplot", "coco_error_analysis._make_gt_area_group_numbers_plot", "coco_error_analysis._make_gt_area_histogram_plot", "len", "present_cat_ids.append", "numpy.zeros", "COCO.loadCats", "ValueError", "coco_error_analysis._makebarplot", "enumerate", "nm[].replace"], "function", ["home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation.evaluate", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._makeplot", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._makeplot", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._makebarplot", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._make_gt_area_group_numbers_plot", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._make_gt_area_histogram_plot", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._makebarplot"], ["", "def", "_analyse_results", "(", "\n", "res_file", ",", "\n", "ann_file", ",", "\n", "res_types", ",", "\n", "out_dir", "=", "None", ",", "\n", "extraplots", "=", "None", ",", "\n", "areas", "=", "None", ",", "\n", "max_detections", "=", "500", ",", "\n", "COCO", "=", "None", ",", "\n", "COCOeval", "=", "None", ",", "\n", ")", ":", "\n", "    ", "for", "res_type", "in", "res_types", ":", "\n", "        ", "if", "res_type", "not", "in", "[", "\"bbox\"", ",", "\"segm\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"res_type {res_type} is not supported\"", ")", "\n", "", "", "if", "areas", "is", "not", "None", ":", "\n", "        ", "if", "len", "(", "areas", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"3 integers should be specified as areas,representing 3 area regions\"", ")", "\n", "\n", "", "", "if", "out_dir", "is", "None", ":", "\n", "        ", "out_dir", "=", "Path", "(", "res_file", ")", ".", "parent", "\n", "out_dir", "=", "str", "(", "out_dir", "/", "\"coco_error_analysis\"", ")", "\n", "\n", "", "directory", "=", "os", ".", "path", ".", "dirname", "(", "out_dir", "+", "\"/\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "print", "(", "f\"-------------create {out_dir}-----------------\"", ")", "\n", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n", "", "result_type_to_export_paths", "=", "{", "}", "\n", "\n", "cocoGt", "=", "COCO", "(", "ann_file", ")", "\n", "cocoDt", "=", "cocoGt", ".", "loadRes", "(", "res_file", ")", "\n", "imgIds", "=", "cocoGt", ".", "getImgIds", "(", ")", "\n", "for", "res_type", "in", "res_types", ":", "\n", "        ", "res_out_dir", "=", "out_dir", "+", "\"/\"", "+", "res_type", "+", "\"/\"", "\n", "res_directory", "=", "os", ".", "path", ".", "dirname", "(", "res_out_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "res_directory", ")", ":", "\n", "            ", "print", "(", "f\"-------------create {res_out_dir}-----------------\"", ")", "\n", "os", ".", "makedirs", "(", "res_directory", ")", "\n", "", "iou_type", "=", "res_type", "\n", "cocoEval", "=", "COCOeval", "(", "copy", ".", "deepcopy", "(", "cocoGt", ")", ",", "copy", ".", "deepcopy", "(", "cocoDt", ")", ",", "iou_type", ")", "\n", "cocoEval", ".", "params", ".", "imgIds", "=", "imgIds", "\n", "cocoEval", ".", "params", ".", "iouThrs", "=", "[", "0.75", ",", "0.5", ",", "0.1", "]", "\n", "cocoEval", ".", "params", ".", "maxDets", "=", "[", "max_detections", "]", "\n", "if", "areas", "is", "not", "None", ":", "\n", "            ", "cocoEval", ".", "params", ".", "areaRng", "=", "[", "\n", "[", "0", "**", "2", ",", "areas", "[", "2", "]", "]", ",", "\n", "[", "0", "**", "2", ",", "areas", "[", "0", "]", "]", ",", "\n", "[", "areas", "[", "0", "]", ",", "areas", "[", "1", "]", "]", ",", "\n", "[", "areas", "[", "1", "]", ",", "areas", "[", "2", "]", "]", ",", "\n", "]", "\n", "", "cocoEval", ".", "evaluate", "(", ")", "\n", "cocoEval", ".", "accumulate", "(", ")", "\n", "\n", "present_cat_ids", "=", "[", "]", "\n", "catIds", "=", "cocoGt", ".", "getCatIds", "(", ")", "\n", "for", "k", ",", "catId", "in", "enumerate", "(", "catIds", ")", ":", "\n", "            ", "image_ids", "=", "cocoGt", ".", "getImgIds", "(", "catIds", "=", "[", "catId", "]", ")", "\n", "if", "len", "(", "image_ids", ")", "!=", "0", ":", "\n", "                ", "present_cat_ids", ".", "append", "(", "catId", ")", "\n", "", "", "matrix_shape", "=", "list", "(", "cocoEval", ".", "eval", "[", "\"precision\"", "]", ".", "shape", ")", "\n", "matrix_shape", "[", "2", "]", "=", "len", "(", "present_cat_ids", ")", "\n", "ps", "=", "np", ".", "zeros", "(", "matrix_shape", ")", "\n", "\n", "for", "k", ",", "catId", "in", "enumerate", "(", "present_cat_ids", ")", ":", "\n", "            ", "ps", "[", ":", ",", ":", ",", "k", ",", ":", ",", ":", "]", "=", "cocoEval", ".", "eval", "[", "\"precision\"", "]", "[", ":", ",", ":", ",", "catId", ",", ":", ",", ":", "]", "\n", "", "ps", "=", "np", ".", "vstack", "(", "[", "ps", ",", "np", ".", "zeros", "(", "(", "4", ",", "*", "ps", ".", "shape", "[", "1", ":", "]", ")", ")", "]", ")", "\n", "\n", "recThrs", "=", "cocoEval", ".", "params", ".", "recThrs", "\n", "with", "Pool", "(", "processes", "=", "48", ")", "as", "pool", ":", "\n", "            ", "args", "=", "[", "\n", "(", "k", ",", "cocoDt", ",", "cocoGt", ",", "catId", ",", "iou_type", ",", "areas", ",", "max_detections", ",", "COCOeval", ")", "\n", "for", "k", ",", "catId", "in", "enumerate", "(", "present_cat_ids", ")", "\n", "]", "\n", "analyze_results", "=", "pool", ".", "starmap", "(", "_analyze_individual_category", ",", "args", ")", "\n", "\n", "", "classname_to_export_path_list", "=", "{", "}", "\n", "for", "k", ",", "catId", "in", "enumerate", "(", "present_cat_ids", ")", ":", "\n", "\n", "            ", "nm", "=", "cocoGt", ".", "loadCats", "(", "catId", ")", "[", "0", "]", "\n", "print", "(", "f'--------------saving {k + 1}-{nm[\"name\"]}---------------'", ")", "\n", "analyze_result", "=", "analyze_results", "[", "k", "]", "\n", "if", "k", "!=", "analyze_result", "[", "0", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"k {k} != analyze_result[0] {analyze_result[0]}\"", ")", "\n", "", "ps_supercategory", "=", "analyze_result", "[", "1", "]", "[", "\"ps_supercategory\"", "]", "\n", "ps_allcategory", "=", "analyze_result", "[", "1", "]", "[", "\"ps_allcategory\"", "]", "\n", "# compute precision but ignore superclass confusion", "\n", "ps", "[", "3", ",", ":", ",", "k", ",", ":", ",", ":", "]", "=", "ps_supercategory", "\n", "# compute precision but ignore any class confusion", "\n", "ps", "[", "4", ",", ":", ",", "k", ",", ":", ",", ":", "]", "=", "ps_allcategory", "\n", "# fill in background and false negative errors and plot", "\n", "ps", "[", "5", ",", ":", ",", "k", ",", ":", ",", ":", "]", "[", "ps", "[", "4", ",", ":", ",", "k", ",", ":", ",", ":", "]", "==", "-", "1", "]", "=", "-", "1", "\n", "ps", "[", "5", ",", ":", ",", "k", ",", ":", ",", ":", "]", "[", "ps", "[", "4", ",", ":", ",", "k", ",", ":", ",", ":", "]", ">", "0", "]", "=", "1", "\n", "ps", "[", "6", ",", ":", ",", "k", ",", ":", ",", ":", "]", "=", "1.0", "\n", "\n", "normalized_class_name", "=", "nm", "[", "\"name\"", "]", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", ".", "replace", "(", "os", ".", "sep", ",", "\"_\"", ")", "\n", "\n", "curve_export_path_list", "=", "_makeplot", "(", "recThrs", ",", "ps", "[", ":", ",", ":", ",", "k", "]", ",", "res_out_dir", ",", "normalized_class_name", ",", "iou_type", ")", "\n", "\n", "if", "extraplots", ":", "\n", "                ", "bar_plot_path", "=", "_makebarplot", "(", "recThrs", ",", "ps", "[", ":", ",", ":", ",", "k", "]", ",", "res_out_dir", ",", "normalized_class_name", ",", "iou_type", ")", "\n", "", "else", ":", "\n", "                ", "bar_plot_path", "=", "None", "\n", "", "classname_to_export_path_list", "[", "nm", "[", "\"name\"", "]", "]", "=", "{", "\n", "\"curves\"", ":", "curve_export_path_list", ",", "\n", "\"bar_plot\"", ":", "bar_plot_path", ",", "\n", "}", "\n", "\n", "", "curve_export_path_list", "=", "_makeplot", "(", "recThrs", ",", "ps", ",", "res_out_dir", ",", "\"allclass\"", ",", "iou_type", ")", "\n", "if", "extraplots", ":", "\n", "            ", "bar_plot_path", "=", "_makebarplot", "(", "recThrs", ",", "ps", ",", "res_out_dir", ",", "\"allclass\"", ",", "iou_type", ")", "\n", "gt_area_group_numbers_plot_path", "=", "_make_gt_area_group_numbers_plot", "(", "\n", "cocoEval", "=", "cocoEval", ",", "outDir", "=", "res_out_dir", ",", "verbose", "=", "True", "\n", ")", "\n", "gt_area_histogram_plot_path", "=", "_make_gt_area_histogram_plot", "(", "cocoEval", "=", "cocoEval", ",", "outDir", "=", "res_out_dir", ")", "\n", "", "else", ":", "\n", "            ", "bar_plot_path", ",", "gt_area_group_numbers_plot_path", ",", "gt_area_histogram_plot_path", "=", "None", ",", "None", ",", "None", "\n", "\n", "", "result_type_to_export_paths", "[", "res_type", "]", "=", "{", "\n", "\"classwise\"", ":", "classname_to_export_path_list", ",", "\n", "\"overall\"", ":", "{", "\n", "\"bar_plot\"", ":", "bar_plot_path", ",", "\n", "\"curves\"", ":", "curve_export_path_list", ",", "\n", "\"gt_area_group_numbers\"", ":", "gt_area_group_numbers_plot_path", ",", "\n", "\"gt_area_histogram\"", ":", "gt_area_histogram_plot_path", ",", "\n", "}", ",", "\n", "}", "\n", "", "print", "(", "f\"COCO error analysis results are successfully exported to {out_dir}\"", ")", "\n", "\n", "return", "result_type_to_export_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis.analyse": [[417, 465], ["coco_error_analysis._analyse_results", "ModuleNotFoundError", "ModuleNotFoundError"], "function", ["home.repos.pwc.inspect_result.obss_sahi.scripts.coco_error_analysis._analyse_results"], ["", "def", "analyse", "(", "\n", "dataset_json_path", ":", "str", ",", "\n", "result_json_path", ":", "str", ",", "\n", "out_dir", ":", "str", "=", "None", ",", "\n", "type", ":", "str", "=", "\"bbox\"", ",", "\n", "no_extraplots", ":", "bool", "=", "False", ",", "\n", "areas", ":", "List", "[", "int", "]", "=", "[", "1024", ",", "9216", ",", "10000000000", "]", ",", "\n", "max_detections", ":", "int", "=", "500", ",", "\n", "return_dict", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        dataset_json_path (str): file path for the coco dataset json file\n        result_json_paths (str): file path for the coco result json file\n        out_dir (str): dir to save analyse result images\n        no_extraplots (bool): dont export export extra bar/stat plots\n        type (str): 'bbox' or 'mask'\n        areas (List[int]): area regions for coco evaluation calculations\n        max_detections (int): Maximum number of detections to consider for AP alculation. Default: 500\n        return_dict (bool): If True, returns a dict export paths.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "from", "pycocotools", ".", "cocoeval", "import", "COCOeval", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "        ", "raise", "ModuleNotFoundError", "(", "\n", "'Please run \"pip install -U pycocotools\" '", "\"to install pycocotools first for coco evaluation.\"", "\n", ")", "\n", "", "try", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "        ", "raise", "ModuleNotFoundError", "(", "\n", "'Please run \"pip install -U matplotlib\" '", "\"to install matplotlib first for visualization.\"", "\n", ")", "\n", "\n", "", "result", "=", "_analyse_results", "(", "\n", "result_json_path", ",", "\n", "dataset_json_path", ",", "\n", "res_types", "=", "[", "type", "]", ",", "\n", "out_dir", "=", "out_dir", ",", "\n", "extraplots", "=", "not", "no_extraplots", ",", "\n", "areas", "=", "areas", ",", "\n", "max_detections", "=", "max_detections", ",", "\n", "COCO", "=", "COCO", ",", "\n", "COCOeval", "=", "COCOeval", ",", "\n", ")", "\n", "if", "return_dict", ":", "\n", "        ", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction": [[51, 122], ["dict", "sahi.utils.cv.read_image_as_pil", "time.time", "detection_model.perform_inference", "time.time", "detection_model.convert_original_predictions", "sahi.prediction.PredictionResult", "warnings.warn", "numpy.ascontiguousarray", "time.time", "postprocess", "time.time", "print"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions"], ["image", ",", "\n", "detection_model", ",", "\n", "shift_amount", ":", "list", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", ":", "Optional", "[", "PostprocessPredictions", "]", "=", "None", ",", "\n", "verbose", ":", "int", "=", "0", ",", "\n", ")", "->", "PredictionResult", ":", "\n", "    ", "\"\"\"\n    Function for performing prediction for given image using given detection_model.\n\n    Arguments:\n        image: str or np.ndarray\n            Location of image or numpy image matrix to slice\n        detection_model: model.DetectionMode\n        shift_amount: List\n            To shift the box and mask predictions from sliced image to full\n            sized image, should be in the form of [shift_x, shift_y]\n        full_shape: List\n            Size of the full image, should be in the form of [height, width]\n        postprocess: sahi.postprocess.combine.PostprocessPredictions\n        verbose: int\n            0: no print (default)\n            1: print prediction duration\n\n    Returns:\n        A dict with fields:\n            object_prediction_list: a list of ObjectPrediction\n            durations_in_seconds: a dict containing elapsed times for profiling\n    \"\"\"", "\n", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "# read image as pil", "\n", "image_as_pil", "=", "read_image_as_pil", "(", "image", ")", "\n", "# get prediction", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "detection_model", ".", "perform_inference", "(", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ")", "\n", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "time_end", "\n", "\n", "# process prediction", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "# works only with 1 batch", "\n", "detection_model", ".", "convert_original_predictions", "(", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "object_prediction_list", ":", "List", "[", "ObjectPrediction", "]", "=", "detection_model", ".", "object_prediction_list", "\n", "\n", "# postprocess matching predictions", "\n", "if", "postprocess", "is", "not", "None", ":", "\n", "        ", "object_prediction_list", "=", "postprocess", "(", "object_prediction_list", ")", "\n", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"postprocess\"", "]", "=", "time_end", "\n", "\n", "if", "verbose", "==", "1", ":", "\n", "        ", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "", "return", "PredictionResult", "(", "\n", "image", "=", "image", ",", "object_prediction_list", "=", "object_prediction_list", ",", "durations_in_seconds", "=", "durations_in_seconds", "\n", ")", "\n", "\n", "\n", "", "def", "get_sliced_prediction", "(", "\n", "image", ",", "\n", "detection_model", "=", "None", ",", "\n", "slice_height", ":", "int", "=", "512", ",", "\n", "slice_width", ":", "int", "=", "512", ",", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction": [[125, 293], ["dict", "time.time", "sahi.slicing.slice_image", "len", "postprocess_constructor", "int", "range", "sahi.prediction.PredictionResult", "warnings.warn", "time.time", "POSTPROCESS_NAME_TO_CLASS.keys", "ValueError", "tqdm.tqdm.write", "range", "predict.get_prediction", "predict.get_prediction", "postprocess.extend", "print", "print", "len", "postprocess_constructor.", "time.time", "ValueError", "image_list.append", "shift_amount_list.append", "postprocess_constructor.", "postprocess.append", "len", "list", "object_prediction.get_shifted_object_prediction", "POSTPROCESS_NAME_TO_CLASS.keys"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_image", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.extend", "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.get_shifted_object_prediction"], ["perform_standard_pred", ":", "bool", "=", "True", ",", "\n", "postprocess_type", ":", "str", "=", "\"GREEDYNMM\"", ",", "\n", "postprocess_match_metric", ":", "str", "=", "\"IOS\"", ",", "\n", "postprocess_match_threshold", ":", "float", "=", "0.5", ",", "\n", "postprocess_class_agnostic", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", "merge_buffer_length", ":", "int", "=", "None", ",", "\n", ")", "->", "PredictionResult", ":", "\n", "    ", "\"\"\"\n    Function for slice image + get predicion for each slice + combine predictions in full image.\n\n    Args:\n        image: str or np.ndarray\n            Location of image or numpy image matrix to slice\n        detection_model: model.DetectionModel\n        slice_height: int\n            Height of each slice.  Defaults to ``512``.\n        slice_width: int\n            Width of each slice.  Defaults to ``512``.\n        overlap_height_ratio: float\n            Fractional overlap in height of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        overlap_width_ratio: float\n            Fractional overlap in width of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        perform_standard_pred: bool\n            Perform a standard prediction on top of sliced predictions to increase large object\n            detection accuracy. Default: True.\n        postprocess_type: str\n            Type of the postprocess to be used after sliced inference while merging/eliminating predictions.\n            Options are 'NMM', 'GRREDYNMM' or 'NMS'. Default is 'GRREDYNMM'.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_threshold: float\n            Sliced predictions having higher iou than postprocess_match_threshold will be\n            postprocessed after sliced prediction.\n        postprocess_class_agnostic: bool\n            If True, postprocess will ignore category ids.\n        verbose: int\n            0: no print\n            1: print number of slices (default)\n            2: print number of slices and slice/prediction durations\n        merge_buffer_length: int\n            The length of buffer for slices to be used during sliced prediction, which is suitable for low memory.\n            It may affect the AP if it is specified. The higher the amount, the closer results to the non-buffered.\n            scenario. See [the discussion](https://github.com/obss/sahi/pull/445).\n\n    Returns:\n        A Dict with fields:\n            object_prediction_list: a list of sahi.prediction.ObjectPrediction\n            durations_in_seconds: a dict containing elapsed times for profiling\n    \"\"\"", "\n", "\n", "# for profiling", "\n", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "# currently only 1 batch supported", "\n", "num_batch", "=", "1", "\n", "\n", "# create slices from full image", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "slice_image_result", "=", "slice_image", "(", "\n", "image", "=", "image", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", ")", "\n", "num_slices", "=", "len", "(", "slice_image_result", ")", "\n", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "=", "time_end", "\n", "\n", "# init match postprocess instance", "\n", "if", "postprocess_type", "not", "in", "POSTPROCESS_NAME_TO_CLASS", ".", "keys", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"postprocess_type should be one of {list(POSTPROCESS_NAME_TO_CLASS.keys())} but given as {postprocess_type}\"", "\n", ")", "\n", "", "elif", "postprocess_type", "==", "\"UNIONMERGE\"", ":", "\n", "# deprecated in v0.9.3", "\n", "        ", "raise", "ValueError", "(", "\"'UNIONMERGE' postprocess_type is deprecated, use 'GREEDYNMM' instead.\"", ")", "\n", "", "postprocess_constructor", "=", "POSTPROCESS_NAME_TO_CLASS", "[", "postprocess_type", "]", "\n", "postprocess", "=", "postprocess_constructor", "(", "\n", "match_threshold", "=", "postprocess_match_threshold", ",", "\n", "match_metric", "=", "postprocess_match_metric", ",", "\n", "class_agnostic", "=", "postprocess_class_agnostic", ",", "\n", ")", "\n", "\n", "# create prediction input", "\n", "num_group", "=", "int", "(", "num_slices", "/", "num_batch", ")", "\n", "if", "verbose", "==", "1", "or", "verbose", "==", "2", ":", "\n", "        ", "tqdm", ".", "write", "(", "f\"Performing prediction on {num_slices} number of slices.\"", ")", "\n", "", "object_prediction_list", "=", "[", "]", "\n", "# perform sliced prediction", "\n", "for", "group_ind", "in", "range", "(", "num_group", ")", ":", "\n", "# prepare batch (currently supports only 1 batch)", "\n", "        ", "image_list", "=", "[", "]", "\n", "shift_amount_list", "=", "[", "]", "\n", "for", "image_ind", "in", "range", "(", "num_batch", ")", ":", "\n", "            ", "image_list", ".", "append", "(", "slice_image_result", ".", "images", "[", "group_ind", "*", "num_batch", "+", "image_ind", "]", ")", "\n", "shift_amount_list", ".", "append", "(", "slice_image_result", ".", "starting_pixels", "[", "group_ind", "*", "num_batch", "+", "image_ind", "]", ")", "\n", "# perform batch prediction", "\n", "", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image_list", "[", "0", "]", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "shift_amount_list", "[", "0", "]", ",", "\n", "full_shape", "=", "[", "\n", "slice_image_result", ".", "original_image_height", ",", "\n", "slice_image_result", ".", "original_image_width", ",", "\n", "]", ",", "\n", ")", "\n", "# convert sliced predictions to full predictions", "\n", "for", "object_prediction", "in", "prediction_result", ".", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ":", "# if not empty", "\n", "                ", "object_prediction_list", ".", "append", "(", "object_prediction", ".", "get_shifted_object_prediction", "(", ")", ")", "\n", "\n", "# merge matching predictions during sliced prediction", "\n", "", "", "if", "merge_buffer_length", "is", "not", "None", "and", "len", "(", "object_prediction_list", ")", ">", "merge_buffer_length", ":", "\n", "            ", "object_prediction_list", "=", "postprocess", "(", "object_prediction_list", ")", "\n", "\n", "# perform standard prediction", "\n", "", "", "if", "num_slices", ">", "1", "and", "perform_standard_pred", ":", "\n", "        ", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", "=", "None", ",", "\n", ")", "\n", "object_prediction_list", ".", "extend", "(", "prediction_result", ".", "object_prediction_list", ")", "\n", "\n", "", "if", "verbose", "==", "2", ":", "\n", "        ", "print", "(", "\n", "\"Slicing performed in\"", ",", "\n", "durations_in_seconds", "[", "\"slice\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "# merge matching predictions", "\n", "", "if", "len", "(", "object_prediction_list", ")", ">", "1", ":", "\n", "        ", "object_prediction_list", "=", "postprocess", "(", "object_prediction_list", ")", "\n", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "time_end", "\n", "\n", "return", "PredictionResult", "(", "\n", "image", "=", "image", ",", "object_prediction_list", "=", "object_prediction_list", ",", "durations_in_seconds", "=", "durations_in_seconds", "\n", ")", "\n", "\n", "\n", "", "def", "predict", "(", "\n", "detection_model", ":", "DetectionModel", "=", "None", ",", "\n", "model_type", ":", "str", "=", "\"mmdet\"", ",", "\n", "model_path", ":", "str", "=", "None", ",", "\n", "model_config_path", ":", "str", "=", "None", ",", "\n", "model_confidence_threshold", ":", "float", "=", "0.25", ",", "\n", "model_device", ":", "str", "=", "None", ",", "\n", "model_category_mapping", ":", "dict", "=", "None", ",", "\n", "model_category_remapping", ":", "dict", "=", "None", ",", "\n", "source", ":", "str", "=", "None", ",", "\n", "no_standard_prediction", ":", "bool", "=", "False", ",", "\n", "no_sliced_prediction", ":", "bool", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.predict": [[296, 663], ["dict", "sahi.utils.file.Path", "time.time", "enumerate", "ValueError", "logger.warning", "sahi.utils.file.increment_path", "sahi.utils.file.Path.mkdir", "sahi.utils.coco.Coco.from_coco_dict_or_path", "os.path.isdir", "sahi.auto_model.AutoDetectionModel.from_pretrained", "AutoDetectionModel.from_pretrained.load_model", "time.time", "tqdm.tqdm", "sahi.utils.cv.read_image_as_pil", "tqdm.tqdm.write", "time.time", "str", "sahi.utils.file.save_json", "print", "print", "print", "print", "str", "sahi.utils.file.list_files", "os.path.isdir", "sahi.utils.file.Path", "predict.get_sliced_prediction", "predict.get_prediction", "str", "sahi.utils.cv.crop_object_predictions", "str", "sahi.utils.file.save_pickle", "str", "sahi.utils.cv.visualize_object_predictions", "sahi.utils.cv.cv2.imshow", "sahi.utils.cv.cv2.waitKey", "time.time", "print", "sahi.utils.file.Path", "sahi.utils.cv.get_video_reader", "sahi.utils.file.Path", "str", "NotImplementedError", "object_prediction.to_coco_prediction", "str", "sahi.utils.cv.visualize_object_predictions", "sahi.utils.cv.visualize_object_predictions", "numpy.ascontiguousarray", "output_video_writer.write", "sahi.utils.file.Path", "sahi.utils.file.Path", "sahi.utils.file.Path", "str().split", "sahi.utils.file.Path", "coco_json.append", "sahi.prediction.ObjectPrediction.from_coco_annotation_dict", "object_prediction_gt_list.append", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "str", "str", "sahi.utils.file.Path", "sahi.utils.file.Path", "str", "sahi.utils.file.Path", "sahi.utils.file.Path", "sahi.utils.file.Path", "sahi.utils.file.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.increment_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image_as_pil", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json", "home.repos.pwc.inspect_result.obss_sahi.utils.file.list_files", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.crop_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_pickle", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.get_video_reader", "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.ObjectPrediction.to_coco_prediction", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.visualize_object_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.from_coco_annotation_dict"], ["slice_width", ":", "int", "=", "512", ",", "\n", "overlap_height_ratio", ":", "float", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "float", "=", "0.2", ",", "\n", "postprocess_type", ":", "str", "=", "\"GREEDYNMM\"", ",", "\n", "postprocess_match_metric", ":", "str", "=", "\"IOS\"", ",", "\n", "postprocess_match_threshold", ":", "float", "=", "0.5", ",", "\n", "postprocess_class_agnostic", ":", "bool", "=", "False", ",", "\n", "novisual", ":", "bool", "=", "False", ",", "\n", "view_video", ":", "bool", "=", "False", ",", "\n", "frame_skip_interval", ":", "int", "=", "0", ",", "\n", "export_pickle", ":", "bool", "=", "False", ",", "\n", "export_crop", ":", "bool", "=", "False", ",", "\n", "dataset_json_path", ":", "bool", "=", "None", ",", "\n", "project", ":", "str", "=", "\"runs/predict\"", ",", "\n", "name", ":", "str", "=", "\"exp\"", ",", "\n", "visual_bbox_thickness", ":", "int", "=", "None", ",", "\n", "visual_text_size", ":", "float", "=", "None", ",", "\n", "visual_text_thickness", ":", "int", "=", "None", ",", "\n", "visual_export_format", ":", "str", "=", "\"png\"", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", "return_dict", ":", "bool", "=", "False", ",", "\n", "force_postprocess_type", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Performs prediction for all present images in given folder.\n\n    Args:\n        detection_model: sahi.model.DetectionModel\n            Optionally provide custom DetectionModel to be used for inference. When provided,\n            model_type, model_path, config_path, model_device, model_category_mapping, image_size\n            params will be ignored\n        model_type: str\n            mmdet for 'MmdetDetectionModel', 'yolov5' for 'Yolov5DetectionModel'.\n        model_path: str\n            Path for the model weight\n        model_config_path: str\n            Path for the detection model config file\n        model_confidence_threshold: float\n            All predictions with score < model_confidence_threshold will be discarded.\n        model_device: str\n            Torch device, \"cpu\" or \"cuda\"\n        model_category_mapping: dict\n            Mapping from category id (str) to category name (str) e.g. {\"1\": \"pedestrian\"}\n        model_category_remapping: dict: str to int\n            Remap category ids after performing inference\n        source: str\n            Folder directory that contains images or path of the image to be predicted. Also video to be predicted.\n        no_standard_prediction: bool\n            Dont perform standard prediction. Default: False.\n        no_sliced_prediction: bool\n            Dont perform sliced prediction. Default: False.\n        image_size: int\n            Input image size for each inference (image is scaled by preserving asp. rat.).\n        slice_height: int\n            Height of each slice.  Defaults to ``512``.\n        slice_width: int\n            Width of each slice.  Defaults to ``512``.\n        overlap_height_ratio: float\n            Fractional overlap in height of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        overlap_width_ratio: float\n            Fractional overlap in width of each window (e.g. an overlap of 0.2 for a window\n            of size 512 yields an overlap of 102 pixels).\n            Default to ``0.2``.\n        postprocess_type: str\n            Type of the postprocess to be used after sliced inference while merging/eliminating predictions.\n            Options are 'NMM', 'GRREDYNMM' or 'NMS'. Default is 'GRREDYNMM'.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_threshold: float\n            Sliced predictions having higher iou than postprocess_match_threshold will be\n            postprocessed after sliced prediction.\n        postprocess_class_agnostic: bool\n            If True, postprocess will ignore category ids.\n        novisual: bool\n            Dont export predicted video/image visuals.\n        view_video: bool\n            View result of prediction during video inference.\n        frame_skip_interval: int\n            If view_video or export_visual is slow, you can process one frames of 3(for exp: --frame_skip_interval=3).\n        export_pickle: bool\n            Export predictions as .pickle\n        export_crop: bool\n            Export predictions as cropped images.\n        dataset_json_path: str\n            If coco file path is provided, detection results will be exported in coco json format.\n        project: str\n            Save results to project/name.\n        name: str\n            Save results to project/name.\n        visual_bbox_thickness: int\n        visual_text_size: float\n        visual_text_thickness: int\n        visual_export_format: str\n            Can be specified as 'jpg' or 'png'\n        verbose: int\n            0: no print\n            1: print slice/prediction durations, number of slices\n            2: print model loading/file exporting durations\n        return_dict: bool\n            If True, returns a dict with 'export_dir' field.\n        force_postprocess_type: bool\n            If True, auto postprocess check will e disabled\n    \"\"\"", "\n", "# assert prediction type", "\n", "if", "no_standard_prediction", "and", "no_sliced_prediction", ":", "\n", "        ", "raise", "ValueError", "(", "\"'no_standard_prediction' and 'no_sliced_prediction' cannot be True at the same time.\"", ")", "\n", "\n", "# auto postprocess type", "\n", "", "if", "not", "force_postprocess_type", "and", "model_confidence_threshold", "<", "LOW_MODEL_CONFIDENCE", "and", "postprocess_type", "!=", "\"NMS\"", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"Switching postprocess type/metric to NMS/IOU since confidence threshold is low ({model_confidence_threshold}).\"", "\n", ")", "\n", "postprocess_type", "=", "\"NMS\"", "\n", "postprocess_match_metric", "=", "\"IOU\"", "\n", "\n", "# for profiling", "\n", "", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "# init export directories", "\n", "save_dir", "=", "Path", "(", "increment_path", "(", "Path", "(", "project", ")", "/", "name", ",", "exist_ok", "=", "False", ")", ")", "# increment run", "\n", "crop_dir", "=", "save_dir", "/", "\"crops\"", "\n", "visual_dir", "=", "save_dir", "/", "\"visuals\"", "\n", "visual_with_gt_dir", "=", "save_dir", "/", "\"visuals_with_gt\"", "\n", "pickle_dir", "=", "save_dir", "/", "\"pickles\"", "\n", "if", "not", "novisual", "or", "export_pickle", "or", "export_crop", "or", "dataset_json_path", "is", "not", "None", ":", "\n", "        ", "save_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# make dir", "\n", "\n", "# init image iterator", "\n", "# TODO: rewrite this as iterator class as in https://github.com/ultralytics/yolov5/blob/d059d1da03aee9a3c0059895aa4c7c14b7f25a9e/utils/datasets.py#L178", "\n", "", "source_is_video", "=", "False", "\n", "num_frames", "=", "None", "\n", "if", "dataset_json_path", ":", "\n", "        ", "coco", ":", "Coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "dataset_json_path", ")", "\n", "image_iterator", "=", "[", "str", "(", "Path", "(", "source", ")", "/", "Path", "(", "coco_image", ".", "file_name", ")", ")", "for", "coco_image", "in", "coco", ".", "images", "]", "\n", "coco_json", "=", "[", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "source", ")", ":", "\n", "        ", "image_iterator", "=", "list_files", "(", "\n", "directory", "=", "source", ",", "\n", "contains", "=", "IMAGE_EXTENSIONS", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "", "elif", "Path", "(", "source", ")", ".", "suffix", "in", "VIDEO_EXTENSIONS", ":", "\n", "        ", "source_is_video", "=", "True", "\n", "read_video_frame", ",", "output_video_writer", ",", "video_file_name", ",", "num_frames", "=", "get_video_reader", "(", "\n", "source", ",", "save_dir", ",", "frame_skip_interval", ",", "not", "novisual", ",", "view_video", "\n", ")", "\n", "image_iterator", "=", "read_video_frame", "\n", "", "else", ":", "\n", "        ", "image_iterator", "=", "[", "source", "]", "\n", "\n", "# init model instance", "\n", "", "time_start", "=", "time", ".", "time", "(", ")", "\n", "if", "detection_model", "is", "None", ":", "\n", "        ", "detection_model", "=", "AutoDetectionModel", ".", "from_pretrained", "(", "\n", "model_type", "=", "model_type", ",", "\n", "model_path", "=", "model_path", ",", "\n", "config_path", "=", "model_config_path", ",", "\n", "confidence_threshold", "=", "model_confidence_threshold", ",", "\n", "device", "=", "model_device", ",", "\n", "category_mapping", "=", "model_category_mapping", ",", "\n", "category_remapping", "=", "model_category_remapping", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "image_size", ",", "\n", ")", "\n", "detection_model", ".", "load_model", "(", ")", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", "=", "time_end", "\n", "\n", "# iterate over source images", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "0", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "=", "0", "\n", "\n", "input_type_str", "=", "\"video frames\"", "if", "source_is_video", "else", "\"images\"", "\n", "for", "ind", ",", "image_path", "in", "enumerate", "(", "\n", "tqdm", "(", "image_iterator", ",", "f\"Performing inference on {input_type_str}\"", ",", "total", "=", "num_frames", ")", "\n", ")", ":", "\n", "# get filename", "\n", "        ", "if", "source_is_video", ":", "\n", "            ", "video_name", "=", "Path", "(", "source", ")", ".", "stem", "\n", "relative_filepath", "=", "video_name", "+", "\"_frame_\"", "+", "str", "(", "ind", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "source", ")", ":", "# preserve source folder structure in export", "\n", "            ", "relative_filepath", "=", "str", "(", "Path", "(", "image_path", ")", ")", ".", "split", "(", "str", "(", "Path", "(", "source", ")", ")", ")", "[", "-", "1", "]", "\n", "relative_filepath", "=", "relative_filepath", "[", "1", ":", "]", "if", "relative_filepath", "[", "0", "]", "==", "os", ".", "sep", "else", "relative_filepath", "\n", "", "else", ":", "# no process if source is single file", "\n", "            ", "relative_filepath", "=", "Path", "(", "image_path", ")", ".", "name", "\n", "\n", "", "filename_without_extension", "=", "Path", "(", "relative_filepath", ")", ".", "stem", "\n", "\n", "# load image", "\n", "image_as_pil", "=", "read_image_as_pil", "(", "image_path", ")", "\n", "\n", "# perform prediction", "\n", "if", "not", "no_sliced_prediction", ":", "\n", "# get sliced prediction", "\n", "            ", "prediction_result", "=", "get_sliced_prediction", "(", "\n", "image", "=", "image_as_pil", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "perform_standard_pred", "=", "not", "no_standard_prediction", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_metric", "=", "postprocess_match_metric", ",", "\n", "postprocess_match_threshold", "=", "postprocess_match_threshold", ",", "\n", "postprocess_class_agnostic", "=", "postprocess_class_agnostic", ",", "\n", "verbose", "=", "1", "if", "verbose", "else", "0", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"slice\"", "]", "\n", "", "else", ":", "\n", "# get standard prediction", "\n", "            ", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image_as_pil", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", "=", "None", ",", "\n", "verbose", "=", "0", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "", "durations_in_seconds", "[", "\"prediction\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"prediction\"", "]", "\n", "# Show prediction time", "\n", "if", "verbose", ":", "\n", "            ", "tqdm", ".", "write", "(", "\n", "\"Prediction time is: {:.2f} ms\"", ".", "format", "(", "prediction_result", ".", "durations_in_seconds", "[", "\"prediction\"", "]", "*", "1000", ")", "\n", ")", "\n", "\n", "", "if", "dataset_json_path", ":", "\n", "            ", "if", "source_is_video", "is", "True", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"Video input type not supported with coco formatted dataset json\"", ")", "\n", "\n", "# append predictions in coco format", "\n", "", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "                ", "coco_prediction", "=", "object_prediction", ".", "to_coco_prediction", "(", ")", "\n", "coco_prediction", ".", "image_id", "=", "coco", ".", "images", "[", "ind", "]", ".", "id", "\n", "coco_prediction_json", "=", "coco_prediction", ".", "json", "\n", "if", "coco_prediction_json", "[", "\"bbox\"", "]", ":", "\n", "                    ", "coco_json", ".", "append", "(", "coco_prediction_json", ")", "\n", "", "", "if", "not", "novisual", ":", "\n", "# convert ground truth annotations to object_prediction_list", "\n", "                ", "coco_image", ":", "CocoImage", "=", "coco", ".", "images", "[", "ind", "]", "\n", "object_prediction_gt_list", ":", "List", "[", "ObjectPrediction", "]", "=", "[", "]", "\n", "for", "coco_annotation", "in", "coco_image", ".", "annotations", ":", "\n", "                    ", "coco_annotation_dict", "=", "coco_annotation", ".", "json", "\n", "category_name", "=", "coco_annotation", ".", "category_name", "\n", "full_shape", "=", "[", "coco_image", ".", "height", ",", "coco_image", ".", "width", "]", "\n", "object_prediction_gt", "=", "ObjectPrediction", ".", "from_coco_annotation_dict", "(", "\n", "annotation_dict", "=", "coco_annotation_dict", ",", "category_name", "=", "category_name", ",", "full_shape", "=", "full_shape", "\n", ")", "\n", "object_prediction_gt_list", ".", "append", "(", "object_prediction_gt", ")", "\n", "# export visualizations with ground truths", "\n", "", "output_dir", "=", "str", "(", "visual_with_gt_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", ")", "\n", "color", "=", "(", "0", ",", "255", ",", "0", ")", "# original annotations in green", "\n", "result", "=", "visualize_object_predictions", "(", "\n", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ",", "\n", "object_prediction_list", "=", "object_prediction_gt_list", ",", "\n", "rect_th", "=", "visual_bbox_thickness", ",", "\n", "text_size", "=", "visual_text_size", ",", "\n", "text_th", "=", "visual_text_thickness", ",", "\n", "color", "=", "color", ",", "\n", "output_dir", "=", "None", ",", "\n", "file_name", "=", "None", ",", "\n", "export_format", "=", "None", ",", "\n", ")", "\n", "color", "=", "(", "255", ",", "0", ",", "0", ")", "# model predictions in red", "\n", "_", "=", "visualize_object_predictions", "(", "\n", "result", "[", "\"image\"", "]", ",", "\n", "object_prediction_list", "=", "object_prediction_list", ",", "\n", "rect_th", "=", "visual_bbox_thickness", ",", "\n", "text_size", "=", "visual_text_size", ",", "\n", "text_th", "=", "visual_text_thickness", ",", "\n", "color", "=", "color", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "file_name", "=", "filename_without_extension", ",", "\n", "export_format", "=", "visual_export_format", ",", "\n", ")", "\n", "\n", "", "", "time_start", "=", "time", ".", "time", "(", ")", "\n", "# export prediction boxes", "\n", "if", "export_crop", ":", "\n", "            ", "output_dir", "=", "str", "(", "crop_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", ")", "\n", "crop_object_predictions", "(", "\n", "image", "=", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ",", "\n", "object_prediction_list", "=", "object_prediction_list", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "file_name", "=", "filename_without_extension", ",", "\n", "export_format", "=", "visual_export_format", ",", "\n", ")", "\n", "# export prediction list as pickle", "\n", "", "if", "export_pickle", ":", "\n", "            ", "save_path", "=", "str", "(", "pickle_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", "/", "(", "filename_without_extension", "+", "\".pickle\"", ")", ")", "\n", "save_pickle", "(", "data", "=", "object_prediction_list", ",", "save_path", "=", "save_path", ")", "\n", "\n", "# export visualization", "\n", "", "if", "not", "novisual", "or", "view_video", ":", "\n", "            ", "output_dir", "=", "str", "(", "visual_dir", "/", "Path", "(", "relative_filepath", ")", ".", "parent", ")", "\n", "result", "=", "visualize_object_predictions", "(", "\n", "np", ".", "ascontiguousarray", "(", "image_as_pil", ")", ",", "\n", "object_prediction_list", "=", "object_prediction_list", ",", "\n", "rect_th", "=", "visual_bbox_thickness", ",", "\n", "text_size", "=", "visual_text_size", ",", "\n", "text_th", "=", "visual_text_thickness", ",", "\n", "output_dir", "=", "output_dir", "if", "not", "source_is_video", "else", "None", ",", "\n", "file_name", "=", "filename_without_extension", ",", "\n", "export_format", "=", "visual_export_format", ",", "\n", ")", "\n", "if", "not", "novisual", "and", "source_is_video", ":", "# export video", "\n", "                ", "output_video_writer", ".", "write", "(", "result", "[", "\"image\"", "]", ")", "\n", "\n", "# render video inference", "\n", "", "", "if", "view_video", ":", "\n", "            ", "cv2", ".", "imshow", "(", "\"Prediction of {}\"", ".", "format", "(", "str", "(", "video_file_name", ")", ")", ",", "result", "[", "\"image\"", "]", ")", "\n", "cv2", ".", "waitKey", "(", "1", ")", "\n", "\n", "", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"export_files\"", "]", "=", "time_end", "\n", "\n", "# export coco results", "\n", "", "if", "dataset_json_path", ":", "\n", "        ", "save_path", "=", "str", "(", "save_dir", "/", "\"result.json\"", ")", "\n", "save_json", "(", "coco_json", ",", "save_path", ")", "\n", "\n", "", "if", "not", "novisual", "or", "export_pickle", "or", "export_crop", "or", "dataset_json_path", "is", "not", "None", ":", "\n", "        ", "print", "(", "f\"Prediction results are successfully exported to {save_dir}\"", ")", "\n", "\n", "# print prediction duration", "\n", "", "if", "verbose", "==", "2", ":", "\n", "        ", "print", "(", "\n", "\"Model loaded in\"", ",", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Slicing performed in\"", ",", "\n", "durations_in_seconds", "[", "\"slice\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "if", "not", "novisual", ":", "\n", "            ", "print", "(", "\n", "\"Exporting performed in\"", ",", "\n", "durations_in_seconds", "[", "\"export_files\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "", "", "if", "return_dict", ":", "\n", "        ", "return", "{", "\"export_dir\"", ":", "save_dir", "}", "\n", "\n", "\n", "", "", "@", "check_requirements", "(", "[", "\"fiftyone\"", "]", ")", "\n", "def", "predict_fiftyone", "(", "\n", "model_type", ":", "str", "=", "\"mmdet\"", ",", "\n", "model_path", ":", "str", "=", "None", ",", "\n", "model_config_path", ":", "str", "=", "None", ",", "\n", "model_confidence_threshold", ":", "float", "=", "0.25", ",", "\n", "model_device", ":", "str", "=", "None", ",", "\n", "model_category_mapping", ":", "dict", "=", "None", ",", "\n", "model_category_remapping", ":", "dict", "=", "None", ",", "\n", "dataset_json_path", ":", "str", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.predict_fiftyone": [[665, 854], ["sahi.utils.import_utils.check_requirements", "dict", "create_fiftyone_dataset_from_coco_file", "time.time", "sahi.auto_model.AutoDetectionModel.from_pretrained", "AutoDetectionModel.from_pretrained.load_model", "fo.launch_app", "create_fiftyone_dataset_from_coco_file.evaluate_detections", "create_fiftyone_dataset_from_coco_file.count_values", "dataset.evaluate_detections.print_report", "create_fiftyone_dataset_from_coco_file.load_evaluation_view", "dataset.load_evaluation_view.sort_by", "ValueError", "time.time", "fo.ProgressBar", "pb", "print", "print", "print", "sorted", "time.sleep", "fo.Detections", "sample.save", "predict.get_sliced_prediction", "predict.get_prediction", "get_prediction.to_fiftyone_detections"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionResult.to_fiftyone_detections"], ["no_standard_prediction", ":", "bool", "=", "False", ",", "\n", "no_sliced_prediction", ":", "bool", "=", "False", ",", "\n", "image_size", ":", "int", "=", "None", ",", "\n", "slice_height", ":", "int", "=", "256", ",", "\n", "slice_width", ":", "int", "=", "256", ",", "\n", "overlap_height_ratio", ":", "float", "=", "0.2", ",", "\n", "overlap_width_ratio", ":", "float", "=", "0.2", ",", "\n", "postprocess_type", ":", "str", "=", "\"GREEDYNMM\"", ",", "\n", "postprocess_match_metric", ":", "str", "=", "\"IOS\"", ",", "\n", "postprocess_match_threshold", ":", "float", "=", "0.5", ",", "\n", "postprocess_class_agnostic", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Performs prediction for all present images in given folder.\n\n    Args:\n        model_type: str\n            mmdet for 'MmdetDetectionModel', 'yolov5' for 'Yolov5DetectionModel'.\n        model_path: str\n            Path for the model weight\n        model_config_path: str\n            Path for the detection model config file\n        model_confidence_threshold: float\n            All predictions with score < model_confidence_threshold will be discarded.\n        model_device: str\n            Torch device, \"cpu\" or \"cuda\"\n        model_category_mapping: dict\n            Mapping from category id (str) to category name (str) e.g. {\"1\": \"pedestrian\"}\n        model_category_remapping: dict: str to int\n            Remap category ids after performing inference\n        dataset_json_path: str\n            If coco file path is provided, detection results will be exported in coco json format.\n        image_dir: str\n            Folder directory that contains images or path of the image to be predicted.\n        no_standard_prediction: bool\n            Dont perform standard prediction. Default: False.\n        no_sliced_prediction: bool\n            Dont perform sliced prediction. Default: False.\n        image_size: int\n            Input image size for each inference (image is scaled by preserving asp. rat.).\n        slice_height: int\n            Height of each slice.  Defaults to ``256``.\n        slice_width: int\n            Width of each slice.  Defaults to ``256``.\n        overlap_height_ratio: float\n            Fractional overlap in height of each window (e.g. an overlap of 0.2 for a window\n            of size 256 yields an overlap of 51 pixels).\n            Default to ``0.2``.\n        overlap_width_ratio: float\n            Fractional overlap in width of each window (e.g. an overlap of 0.2 for a window\n            of size 256 yields an overlap of 51 pixels).\n            Default to ``0.2``.\n        postprocess_type: str\n            Type of the postprocess to be used after sliced inference while merging/eliminating predictions.\n            Options are 'NMM', 'GRREDYNMM' or 'NMS'. Default is 'GRREDYNMM'.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_metric: str\n            Metric to be used during object prediction matching after sliced prediction.\n            'IOU' for intersection over union, 'IOS' for intersection over smaller area.\n        postprocess_match_threshold: float\n            Sliced predictions having higher iou than postprocess_match_threshold will be\n            postprocessed after sliced prediction.\n        postprocess_class_agnostic: bool\n            If True, postprocess will ignore category ids.\n        verbose: int\n            0: no print\n            1: print slice/prediction durations, number of slices, model loading/file exporting durations\n    \"\"\"", "\n", "from", "sahi", ".", "utils", ".", "fiftyone", "import", "create_fiftyone_dataset_from_coco_file", ",", "fo", "\n", "\n", "# assert prediction type", "\n", "if", "no_standard_prediction", "and", "no_sliced_prediction", ":", "\n", "        ", "raise", "ValueError", "(", "\"'no_standard_pred' and 'no_sliced_prediction' cannot be True at the same time.\"", ")", "\n", "# for profiling", "\n", "", "durations_in_seconds", "=", "dict", "(", ")", "\n", "\n", "dataset", "=", "create_fiftyone_dataset_from_coco_file", "(", "image_dir", ",", "dataset_json_path", ")", "\n", "\n", "# init model instance", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "detection_model", "=", "AutoDetectionModel", ".", "from_pretrained", "(", "\n", "model_type", "=", "model_type", ",", "\n", "model_path", "=", "model_path", ",", "\n", "config_path", "=", "model_config_path", ",", "\n", "confidence_threshold", "=", "model_confidence_threshold", ",", "\n", "device", "=", "model_device", ",", "\n", "category_mapping", "=", "model_category_mapping", ",", "\n", "category_remapping", "=", "model_category_remapping", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "image_size", ",", "\n", ")", "\n", "detection_model", ".", "load_model", "(", ")", "\n", "time_end", "=", "time", ".", "time", "(", ")", "-", "time_start", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", "=", "time_end", "\n", "\n", "# iterate over source images", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "=", "0", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "=", "0", "\n", "# Add predictions to samples", "\n", "with", "fo", ".", "ProgressBar", "(", ")", "as", "pb", ":", "\n", "        ", "for", "sample", "in", "pb", "(", "dataset", ")", ":", "\n", "# perform prediction", "\n", "            ", "if", "not", "no_sliced_prediction", ":", "\n", "# get sliced prediction", "\n", "                ", "prediction_result", "=", "get_sliced_prediction", "(", "\n", "image", "=", "sample", ".", "filepath", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "perform_standard_pred", "=", "not", "no_standard_prediction", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_threshold", "=", "postprocess_match_threshold", ",", "\n", "postprocess_match_metric", "=", "postprocess_match_metric", ",", "\n", "postprocess_class_agnostic", "=", "postprocess_class_agnostic", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "durations_in_seconds", "[", "\"slice\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"slice\"", "]", "\n", "", "else", ":", "\n", "# get standard prediction", "\n", "                ", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "sample", ".", "filepath", ",", "\n", "detection_model", "=", "detection_model", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", "=", "None", ",", "\n", "verbose", "=", "0", ",", "\n", ")", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", "+=", "prediction_result", ".", "durations_in_seconds", "[", "\"prediction\"", "]", "\n", "\n", "# Save predictions to dataset", "\n", "", "sample", "[", "model_type", "]", "=", "fo", ".", "Detections", "(", "detections", "=", "prediction_result", ".", "to_fiftyone_detections", "(", ")", ")", "\n", "sample", ".", "save", "(", ")", "\n", "\n", "# print prediction duration", "\n", "", "", "if", "verbose", "==", "1", ":", "\n", "        ", "print", "(", "\n", "\"Model loaded in\"", ",", "\n", "durations_in_seconds", "[", "\"model_load\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Slicing performed in\"", ",", "\n", "durations_in_seconds", "[", "\"slice\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "print", "(", "\n", "\"Prediction performed in\"", ",", "\n", "durations_in_seconds", "[", "\"prediction\"", "]", ",", "\n", "\"seconds.\"", ",", "\n", ")", "\n", "\n", "# visualize results", "\n", "", "session", "=", "fo", ".", "launch_app", "(", ")", "\n", "session", ".", "dataset", "=", "dataset", "\n", "# Evaluate the predictions", "\n", "results", "=", "dataset", ".", "evaluate_detections", "(", "\n", "model_type", ",", "\n", "gt_field", "=", "\"ground_truth\"", ",", "\n", "eval_key", "=", "\"eval\"", ",", "\n", "iou", "=", "postprocess_match_threshold", ",", "\n", "compute_mAP", "=", "True", ",", "\n", ")", "\n", "# Get the 10 most common classes in the dataset", "\n", "counts", "=", "dataset", ".", "count_values", "(", "\"ground_truth.detections.label\"", ")", "\n", "classes_top10", "=", "sorted", "(", "counts", ",", "key", "=", "counts", ".", "get", ",", "reverse", "=", "True", ")", "[", ":", "10", "]", "\n", "# Print a classification report for the top-10 classes", "\n", "results", ".", "print_report", "(", "classes", "=", "classes_top10", ")", "\n", "# Load the view on which we ran the `eval` evaluation", "\n", "eval_view", "=", "dataset", ".", "load_evaluation_view", "(", "\"eval\"", ")", "\n", "# Show samples with most false positives", "\n", "session", ".", "view", "=", "eval_view", ".", "sort_by", "(", "\"eval_fp\"", ",", "reverse", "=", "True", ")", "\n", "while", "1", ":", "\n", "        ", "time", ".", "sleep", "(", "3", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco2fiftyone.main": [[10, 77], ["create_fiftyone_dataset_from_coco_file", "fo.launch_app", "zip", "create_fiftyone_dataset_from_coco_file.evaluate_detections", "create_fiftyone_dataset_from_coco_file.load_evaluation_view", "dataset.load_evaluation_view.sort_by", "print", "time.sleep", "sahi.utils.file.load_json", "coco_result_list.append", "result_name_list.append", "add_coco_labels", "pathlib.Path", "str"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json"], ["def", "main", "(", "\n", "image_dir", ":", "str", ",", "\n", "dataset_json_path", ":", "str", ",", "\n", "*", "result_json_paths", ",", "\n", "iou_thresh", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): directory for coco images\n        dataset_json_path (str): file path for the coco dataset json file\n        result_json_paths (str): one or more paths for the coco result json file\n        iou_thresh (float): iou threshold for coco evaluation\n    \"\"\"", "\n", "\n", "from", "sahi", ".", "utils", ".", "fiftyone", "import", "add_coco_labels", ",", "create_fiftyone_dataset_from_coco_file", ",", "fo", "\n", "\n", "coco_result_list", "=", "[", "]", "\n", "result_name_list", "=", "[", "]", "\n", "if", "result_json_paths", ":", "\n", "        ", "for", "result_json_path", "in", "result_json_paths", ":", "\n", "            ", "coco_result", "=", "load_json", "(", "result_json_path", ")", "\n", "coco_result_list", ".", "append", "(", "coco_result", ")", "\n", "\n", "# use file names as fiftyone name, create unique names if duplicate", "\n", "result_name_temp", "=", "Path", "(", "result_json_path", ")", ".", "stem", "\n", "result_name", "=", "result_name_temp", "\n", "name_increment", "=", "2", "\n", "while", "result_name", "in", "result_name_list", ":", "\n", "                ", "result_name", "=", "result_name_temp", "+", "\"_\"", "+", "str", "(", "name_increment", ")", "\n", "name_increment", "+=", "1", "\n", "", "result_name_list", ".", "append", "(", "result_name", ")", "\n", "\n", "", "", "dataset", "=", "create_fiftyone_dataset_from_coco_file", "(", "image_dir", ",", "dataset_json_path", ")", "\n", "\n", "# submit detections if coco result is given", "\n", "if", "result_json_paths", ":", "\n", "        ", "for", "result_name", ",", "coco_result", "in", "zip", "(", "result_name_list", ",", "coco_result_list", ")", ":", "\n", "            ", "add_coco_labels", "(", "dataset", ",", "result_name", ",", "coco_result", ",", "coco_id_field", "=", "\"gt_coco_id\"", ")", "\n", "\n", "# visualize results", "\n", "", "", "session", "=", "fo", ".", "launch_app", "(", ")", "\n", "session", ".", "dataset", "=", "dataset", "\n", "\n", "# order by false positives if any coco result is given", "\n", "if", "result_json_paths", ":", "\n", "# Evaluate the predictions", "\n", "        ", "first_coco_result_name", "=", "result_name_list", "[", "0", "]", "\n", "_", "=", "dataset", ".", "evaluate_detections", "(", "\n", "first_coco_result_name", ",", "\n", "gt_field", "=", "\"gt_detections\"", ",", "\n", "eval_key", "=", "f\"{first_coco_result_name}_eval\"", ",", "\n", "iou", "=", "iou_thresh", ",", "\n", "compute_mAP", "=", "False", ",", "\n", ")", "\n", "# Get the 10 most common classes in the dataset", "\n", "# counts = dataset.count_values(\"gt_detections.detections.label\")", "\n", "# classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]", "\n", "# Print a classification report for the top-10 classes", "\n", "# results.print_report(classes=classes_top10)", "\n", "# Load the view on which we ran the `eval` evaluation", "\n", "eval_view", "=", "dataset", ".", "load_evaluation_view", "(", "f\"{first_coco_result_name}_eval\"", ")", "\n", "# Show samples with most false positives", "\n", "session", ".", "view", "=", "eval_view", ".", "sort_by", "(", "f\"{first_coco_result_name}_eval_fp\"", ",", "reverse", "=", "True", ")", "\n", "\n", "print", "(", "\"SAHI has successfully launched a Fiftyone app \"", "f\"at http://localhost:{fo.config.default_app_port}\"", ")", "\n", "", "while", "1", ":", "\n", "        ", "time", ".", "sleep", "(", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.predict_fiftyone.main": [[6, 8], ["fire.Fire"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "fire", ".", "Fire", "(", "predict_fiftyone", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco2yolov5.main": [[7, 40], ["sahi.utils.file.Path", "sahi.utils.coco.Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path.export_as_yolov5", "print", "sahi.utils.file.increment_path", "str", "sahi.utils.file.Path"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.export_as_yolov5", "home.repos.pwc.inspect_result.obss_sahi.utils.file.increment_path"], ["def", "main", "(", "\n", "image_dir", ":", "str", ",", "\n", "dataset_json_path", ":", "str", ",", "\n", "train_split", ":", "str", "=", "0.9", ",", "\n", "project", ":", "str", "=", "\"runs/coco2yolov5\"", ",", "\n", "name", ":", "str", "=", "\"exp\"", ",", "\n", "seed", ":", "str", "=", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        images_dir (str): directory for coco images\n        dataset_json_path (str): file path for the coco json file to be converted\n        train_split (str): set the training split ratio\n        project (str): save results to project/name\n        name (str): save results to project/name\"\n        seed (int): fix the seed for reproducibility\n    \"\"\"", "\n", "\n", "# increment run", "\n", "save_dir", "=", "Path", "(", "increment_path", "(", "Path", "(", "project", ")", "/", "name", ",", "exist_ok", "=", "False", ")", ")", "\n", "# load coco dict", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "\n", "coco_dict_or_path", "=", "dataset_json_path", ",", "\n", "image_dir", "=", "image_dir", ",", "\n", ")", "\n", "# export as yolov5", "\n", "coco", ".", "export_as_yolov5", "(", "\n", "output_dir", "=", "str", "(", "save_dir", ")", ",", "\n", "train_split_rate", "=", "train_split", ",", "\n", "numpy_seed", "=", "seed", ",", "\n", ")", "\n", "\n", "print", "(", "f\"COCO to YOLOv5 conversion results are successfully exported to {save_dir}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize": [[13, 58], ["len", "numpy.mean", "print", "print", "enumerate", "enumerate", "iStr.format", "iStr.format", "numpy.where", "numpy.where"], "function", ["None"], ["def", "_cocoeval_summarize", "(", "\n", "cocoeval", ",", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "catIdx", "=", "None", ",", "areaRng", "=", "\"all\"", ",", "maxDets", "=", "100", ",", "catName", "=", "\"\"", ",", "nameStrLen", "=", "None", "\n", ")", ":", "\n", "    ", "p", "=", "cocoeval", ".", "params", "\n", "if", "catName", ":", "\n", "        ", "iStr", "=", "\" {:<18} {} {:<{nameStrLen}} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}\"", "\n", "nameStr", "=", "catName", "\n", "", "else", ":", "\n", "        ", "iStr", "=", "\" {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}\"", "\n", "", "titleStr", "=", "\"Average Precision\"", "if", "ap", "==", "1", "else", "\"Average Recall\"", "\n", "typeStr", "=", "\"(AP)\"", "if", "ap", "==", "1", "else", "\"(AR)\"", "\n", "iouStr", "=", "\"{:0.2f}:{:0.2f}\"", ".", "format", "(", "p", ".", "iouThrs", "[", "0", "]", ",", "p", ".", "iouThrs", "[", "-", "1", "]", ")", "if", "iouThr", "is", "None", "else", "\"{:0.2f}\"", ".", "format", "(", "iouThr", ")", "\n", "\n", "aind", "=", "[", "i", "for", "i", ",", "aRng", "in", "enumerate", "(", "p", ".", "areaRngLbl", ")", "if", "aRng", "==", "areaRng", "]", "\n", "mind", "=", "[", "i", "for", "i", ",", "mDet", "in", "enumerate", "(", "p", ".", "maxDets", ")", "if", "mDet", "==", "maxDets", "]", "\n", "if", "ap", "==", "1", ":", "\n", "# dimension of precision: [TxRxKxAxM]", "\n", "        ", "s", "=", "cocoeval", ".", "eval", "[", "\"precision\"", "]", "\n", "# IoU", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "            ", "t", "=", "np", ".", "where", "(", "iouThr", "==", "p", ".", "iouThrs", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "if", "catIdx", "is", "not", "None", ":", "\n", "            ", "s", "=", "s", "[", ":", ",", ":", ",", "catIdx", ",", "aind", ",", "mind", "]", "\n", "", "else", ":", "\n", "            ", "s", "=", "s", "[", ":", ",", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "", "else", ":", "\n", "# dimension of recall: [TxKxAxM]", "\n", "        ", "s", "=", "cocoeval", ".", "eval", "[", "\"recall\"", "]", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "            ", "t", "=", "np", ".", "where", "(", "iouThr", "==", "p", ".", "iouThrs", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "if", "catIdx", "is", "not", "None", ":", "\n", "            ", "s", "=", "s", "[", ":", ",", "catIdx", ",", "aind", ",", "mind", "]", "\n", "", "else", ":", "\n", "            ", "s", "=", "s", "[", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "", "if", "len", "(", "s", "[", "s", ">", "-", "1", "]", ")", "==", "0", ":", "\n", "        ", "mean_s", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "mean_s", "=", "np", ".", "mean", "(", "s", "[", "s", ">", "-", "1", "]", ")", "\n", "", "if", "catName", ":", "\n", "        ", "print", "(", "iStr", ".", "format", "(", "titleStr", ",", "typeStr", ",", "nameStr", ",", "iouStr", ",", "areaRng", ",", "maxDets", ",", "mean_s", ",", "nameStrLen", "=", "nameStrLen", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "iStr", ".", "format", "(", "titleStr", ",", "typeStr", ",", "iouStr", ",", "areaRng", ",", "maxDets", ",", "mean_s", ")", ")", "\n", "", "return", "mean_s", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation.evaluate_core": [[60, 344], ["collections.OrderedDict", "COCO", "list", "pathlib.Path().mkdir", "str", "print", "isinstance", "numpy.linspace", "COCO.cats.keys", "print", "COCOeval", "COCOeval.evaluate", "COCOeval.accumulate", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "numpy.append", "open", "json.dump", "KeyError", "isinstance", "len", "ValueError", "open", "json.load", "COCO.loadRes", "enumerate", "enumerate", "min", "list", "itertools.zip_longest", "terminaltables.AsciiTable", "print", "float", "pathlib.Path", "pathlib.Path", "pathlib.Path", "int", "warnings.simplefilter", "warnings.warn", "print", "len", "ValueError", "len", "COCO.getImgIds", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "coco_evaluation._cocoeval_summarize", "results_per_category.append", "results_per_category.append", "results_per_category.append", "results_per_category.append", "results_per_category.append", "results_per_category.append", "results_per_category.append", "results_per_category.append", "itertools.chain", "numpy.round", "x.pop", "isinstance", "isinstance", "KeyError", "COCO.loadCats", "len", "COCO.loadCats", "len", "len", "range", "float", "float", "float", "float", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation.evaluate", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize", "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation._cocoeval_summarize"], ["", "def", "evaluate_core", "(", "\n", "dataset_path", ",", "\n", "result_path", ",", "\n", "metric", ":", "str", "=", "\"bbox\"", ",", "\n", "classwise", ":", "bool", "=", "False", ",", "\n", "max_detections", ":", "int", "=", "500", ",", "\n", "iou_thrs", "=", "None", ",", "\n", "metric_items", "=", "None", ",", "\n", "out_dir", ":", "str", "=", "None", ",", "\n", "areas", ":", "List", "[", "int", "]", "=", "[", "1024", ",", "9216", ",", "10000000000", "]", ",", "\n", "COCO", "=", "None", ",", "\n", "COCOeval", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Evaluation in COCO protocol.\n    Args:\n        dataset_path (str): COCO dataset json path.\n        result_path (str): COCO result json path.\n        metric (str | list[str]): Metrics to be evaluated. Options are\n            'bbox', 'segm', 'proposal'.\n        classwise (bool): Whether to evaluating the AP for each class.\n        max_detections (int): Maximum number of detections to consider for AP\n            calculation.\n            Default: 500\n        iou_thrs (List[float], optional): IoU threshold used for\n            evaluating recalls/mAPs. If set to a list, the average of all\n            IoUs will also be computed. If not specified, [0.50, 0.55,\n            0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] will be used.\n            Default: None.\n        metric_items (list[str] | str, optional): Metric items that will\n            be returned. If not specified, ``['AR@10', 'AR@100',\n            'AR@500', 'AR_s@500', 'AR_m@500', 'AR_l@500' ]`` will be\n            used when ``metric=='proposal'``, ``['mAP', 'mAP50', 'mAP75',\n            'mAP_s', 'mAP_m', 'mAP_l', 'mAP50_s', 'mAP50_m', 'mAP50_l']``\n            will be used when ``metric=='bbox' or metric=='segm'``.\n        out_dir (str): Directory to save evaluation result json.\n        areas (List[int]): area regions for coco evaluation calculations\n    Returns:\n        dict:\n            eval_results (dict[str, float]): COCO style evaluation metric.\n            export_path (str): Path for the exported eval result json.\n\n    \"\"\"", "\n", "\n", "metrics", "=", "metric", "if", "isinstance", "(", "metric", ",", "list", ")", "else", "[", "metric", "]", "\n", "allowed_metrics", "=", "[", "\"bbox\"", ",", "\"segm\"", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "            ", "raise", "KeyError", "(", "f\"metric {metric} is not supported\"", ")", "\n", "", "", "if", "iou_thrs", "is", "None", ":", "\n", "        ", "iou_thrs", "=", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "int", "(", "np", ".", "round", "(", "(", "0.95", "-", "0.5", ")", "/", "0.05", ")", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "", "if", "metric_items", "is", "not", "None", ":", "\n", "        ", "if", "not", "isinstance", "(", "metric_items", ",", "list", ")", ":", "\n", "            ", "metric_items", "=", "[", "metric_items", "]", "\n", "", "", "if", "areas", "is", "not", "None", ":", "\n", "        ", "if", "len", "(", "areas", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"3 integers should be specified as areas, representing 3 area regions\"", ")", "\n", "", "", "eval_results", "=", "OrderedDict", "(", ")", "\n", "cocoGt", "=", "COCO", "(", "dataset_path", ")", "\n", "cat_ids", "=", "list", "(", "cocoGt", ".", "cats", ".", "keys", "(", ")", ")", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "msg", "=", "f\"Evaluating {metric}...\"", "\n", "msg", "=", "\"\\n\"", "+", "msg", "\n", "print", "(", "msg", ")", "\n", "\n", "iou_type", "=", "metric", "\n", "with", "open", "(", "result_path", ")", "as", "json_file", ":", "\n", "            ", "results", "=", "json", ".", "load", "(", "json_file", ")", "\n", "", "try", ":", "\n", "            ", "if", "iou_type", "==", "\"segm\"", ":", "\n", "# Refer to https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py#L331  # noqa", "\n", "# When evaluating mask AP, if the results contain bbox,", "\n", "# cocoapi will use the box area instead of the mask area", "\n", "# for calculating the instance area. Though the overall AP", "\n", "# is not affected, this leads to different", "\n", "# small/medium/large mask AP results.", "\n", "                ", "for", "x", "in", "results", ":", "\n", "                    ", "x", ".", "pop", "(", "\"bbox\"", ")", "\n", "", "warnings", ".", "simplefilter", "(", "\"once\"", ")", "\n", "warnings", ".", "warn", "(", "\n", "'The key \"bbox\" is deleted for more accurate mask AP '", "\n", "\"of small/medium/large instances since v2.12.0. This \"", "\n", "\"does not change the overall mAP calculation.\"", ",", "\n", "UserWarning", ",", "\n", ")", "\n", "", "cocoDt", "=", "cocoGt", ".", "loadRes", "(", "results", ")", "\n", "", "except", "IndexError", ":", "\n", "            ", "print", "(", "\"The testing results of the whole dataset is empty.\"", ")", "\n", "break", "\n", "\n", "", "cocoEval", "=", "COCOeval", "(", "cocoGt", ",", "cocoDt", ",", "iou_type", ")", "\n", "if", "areas", "is", "not", "None", ":", "\n", "            ", "cocoEval", ".", "params", ".", "areaRng", "=", "[", "\n", "[", "0", "**", "2", ",", "areas", "[", "2", "]", "]", ",", "\n", "[", "0", "**", "2", ",", "areas", "[", "0", "]", "]", ",", "\n", "[", "areas", "[", "0", "]", ",", "areas", "[", "1", "]", "]", ",", "\n", "[", "areas", "[", "1", "]", ",", "areas", "[", "2", "]", "]", ",", "\n", "]", "\n", "", "cocoEval", ".", "params", ".", "catIds", "=", "cat_ids", "\n", "cocoEval", ".", "params", ".", "maxDets", "=", "[", "max_detections", "]", "\n", "cocoEval", ".", "params", ".", "iouThrs", "=", "(", "\n", "[", "iou_thrs", "]", "if", "not", "isinstance", "(", "iou_thrs", ",", "list", ")", "and", "not", "isinstance", "(", "iou_thrs", ",", "np", ".", "ndarray", ")", "else", "iou_thrs", "\n", ")", "\n", "# mapping of cocoEval.stats", "\n", "coco_metric_names", "=", "{", "\n", "\"mAP\"", ":", "0", ",", "\n", "\"mAP75\"", ":", "1", ",", "\n", "\"mAP50\"", ":", "2", ",", "\n", "\"mAP_s\"", ":", "3", ",", "\n", "\"mAP_m\"", ":", "4", ",", "\n", "\"mAP_l\"", ":", "5", ",", "\n", "\"mAP50_s\"", ":", "6", ",", "\n", "\"mAP50_m\"", ":", "7", ",", "\n", "\"mAP50_l\"", ":", "8", ",", "\n", "\"AR_s\"", ":", "9", ",", "\n", "\"AR_m\"", ":", "10", ",", "\n", "\"AR_l\"", ":", "11", ",", "\n", "}", "\n", "if", "metric_items", "is", "not", "None", ":", "\n", "            ", "for", "metric_item", "in", "metric_items", ":", "\n", "                ", "if", "metric_item", "not", "in", "coco_metric_names", ":", "\n", "                    ", "raise", "KeyError", "(", "f\"metric item {metric_item} is not supported\"", ")", "\n", "\n", "", "", "", "cocoEval", ".", "evaluate", "(", ")", "\n", "cocoEval", ".", "accumulate", "(", ")", "\n", "# calculate mAP50_s/m/l", "\n", "mAP", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"all\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP50", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "0.5", ",", "areaRng", "=", "\"all\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP75", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "0.75", ",", "areaRng", "=", "\"all\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP50_s", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "0.5", ",", "areaRng", "=", "\"small\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP50_m", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "0.5", ",", "areaRng", "=", "\"medium\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP50_l", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "0.5", ",", "areaRng", "=", "\"large\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP_s", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"small\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP_m", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"medium\"", ",", "maxDets", "=", "max_detections", ")", "\n", "mAP_l", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"large\"", ",", "maxDets", "=", "max_detections", ")", "\n", "AR_s", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "0", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"small\"", ",", "maxDets", "=", "max_detections", ")", "\n", "AR_m", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "0", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"medium\"", ",", "maxDets", "=", "max_detections", ")", "\n", "AR_l", "=", "_cocoeval_summarize", "(", "cocoEval", ",", "ap", "=", "0", ",", "iouThr", "=", "None", ",", "areaRng", "=", "\"large\"", ",", "maxDets", "=", "max_detections", ")", "\n", "cocoEval", ".", "stats", "=", "np", ".", "append", "(", "\n", "[", "mAP", ",", "mAP75", ",", "mAP50", ",", "mAP_s", ",", "mAP_m", ",", "mAP_l", ",", "mAP50_s", ",", "mAP50_m", ",", "mAP50_l", ",", "AR_s", ",", "AR_m", ",", "AR_l", "]", ",", "0", "\n", ")", "\n", "\n", "if", "classwise", ":", "# Compute per-category AP", "\n", "# Compute per-category AP", "\n", "# from https://github.com/facebookresearch/detectron2/", "\n", "            ", "precisions", "=", "cocoEval", ".", "eval", "[", "\"precision\"", "]", "\n", "# precision: (iou, recall, cls, area range, max dets)", "\n", "if", "len", "(", "cat_ids", ")", "!=", "precisions", ".", "shape", "[", "2", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"The number of categories {len(cat_ids)} is not equal to the number of precisions {precisions.shape[2]}\"", "\n", ")", "\n", "", "max_cat_name_len", "=", "0", "\n", "for", "idx", ",", "catId", "in", "enumerate", "(", "cat_ids", ")", ":", "\n", "                ", "nm", "=", "cocoGt", ".", "loadCats", "(", "catId", ")", "[", "0", "]", "\n", "cat_name_len", "=", "len", "(", "nm", "[", "\"name\"", "]", ")", "\n", "max_cat_name_len", "=", "cat_name_len", "if", "cat_name_len", ">", "max_cat_name_len", "else", "max_cat_name_len", "\n", "\n", "", "results_per_category", "=", "[", "]", "\n", "for", "idx", ",", "catId", "in", "enumerate", "(", "cat_ids", ")", ":", "\n", "# skip if no image with this category", "\n", "                ", "image_ids", "=", "cocoGt", ".", "getImgIds", "(", "catIds", "=", "[", "catId", "]", ")", "\n", "if", "len", "(", "image_ids", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "# area range index 0: all area ranges", "\n", "# max dets index -1: typically 100 per image", "\n", "", "nm", "=", "cocoGt", ".", "loadCats", "(", "catId", ")", "[", "0", "]", "\n", "ap", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"all\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "ap_s", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"small\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "ap_m", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"medium\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "ap_l", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"large\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "ap50", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "iouThr", "=", "0.5", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"all\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "ap50_s", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "iouThr", "=", "0.5", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"small\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "ap50_m", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "iouThr", "=", "0.5", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"medium\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "ap50_l", "=", "_cocoeval_summarize", "(", "\n", "cocoEval", ",", "\n", "ap", "=", "1", ",", "\n", "iouThr", "=", "0.5", ",", "\n", "catIdx", "=", "idx", ",", "\n", "areaRng", "=", "\"large\"", ",", "\n", "maxDets", "=", "max_detections", ",", "\n", "catName", "=", "nm", "[", "\"name\"", "]", ",", "\n", "nameStrLen", "=", "max_cat_name_len", ",", "\n", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP'", ",", "f\"{float(ap):0.3f}\"", ")", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP_s'", ",", "f\"{float(ap_s):0.3f}\"", ")", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP_m'", ",", "f\"{float(ap_m):0.3f}\"", ")", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP_l'", ",", "f\"{float(ap_l):0.3f}\"", ")", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP50'", ",", "f\"{float(ap50):0.3f}\"", ")", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP50_s'", ",", "f\"{float(ap50_s):0.3f}\"", ")", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP50_m'", ",", "f\"{float(ap50_m):0.3f}\"", ")", ")", "\n", "results_per_category", ".", "append", "(", "(", "f'{metric}_{nm[\"name\"]}_mAP50_l'", ",", "f\"{float(ap50_l):0.3f}\"", ")", ")", "\n", "\n", "", "num_columns", "=", "min", "(", "6", ",", "len", "(", "results_per_category", ")", "*", "2", ")", "\n", "results_flatten", "=", "list", "(", "itertools", ".", "chain", "(", "*", "results_per_category", ")", ")", "\n", "headers", "=", "[", "\"category\"", ",", "\"AP\"", "]", "*", "(", "num_columns", "//", "2", ")", "\n", "results_2d", "=", "itertools", ".", "zip_longest", "(", "*", "[", "results_flatten", "[", "i", ":", ":", "num_columns", "]", "for", "i", "in", "range", "(", "num_columns", ")", "]", ")", "\n", "table_data", "=", "[", "headers", "]", "\n", "table_data", "+=", "[", "result", "for", "result", "in", "results_2d", "]", "\n", "table", "=", "AsciiTable", "(", "table_data", ")", "\n", "print", "(", "\"\\n\"", "+", "table", ".", "table", ")", "\n", "\n", "", "if", "metric_items", "is", "None", ":", "\n", "            ", "metric_items", "=", "[", "\"mAP\"", ",", "\"mAP50\"", ",", "\"mAP75\"", ",", "\"mAP_s\"", ",", "\"mAP_m\"", ",", "\"mAP_l\"", ",", "\"mAP50_s\"", ",", "\"mAP50_m\"", ",", "\"mAP50_l\"", "]", "\n", "\n", "", "for", "metric_item", "in", "metric_items", ":", "\n", "            ", "key", "=", "f\"{metric}_{metric_item}\"", "\n", "val", "=", "float", "(", "f\"{cocoEval.stats[coco_metric_names[metric_item]]:.3f}\"", ")", "\n", "eval_results", "[", "key", "]", "=", "val", "\n", "", "ap", "=", "cocoEval", ".", "stats", "\n", "eval_results", "[", "f\"{metric}_mAP_copypaste\"", "]", "=", "(", "\n", "f\"{ap[0]:.3f} {ap[1]:.3f} {ap[2]:.3f} {ap[3]:.3f} \"", "\n", "f\"{ap[4]:.3f} {ap[5]:.3f} {ap[6]:.3f} {ap[7]:.3f} \"", "\n", "f\"{ap[8]:.3f}\"", "\n", ")", "\n", "if", "classwise", ":", "\n", "            ", "eval_results", "[", "\"results_per_category\"", "]", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "results_per_category", "}", "\n", "# set save path", "\n", "", "", "if", "not", "out_dir", ":", "\n", "        ", "out_dir", "=", "Path", "(", "result_path", ")", ".", "parent", "\n", "", "Path", "(", "out_dir", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "export_path", "=", "str", "(", "Path", "(", "out_dir", ")", "/", "\"eval.json\"", ")", "\n", "# export as json", "\n", "with", "open", "(", "export_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "eval_results", ",", "outfile", ",", "indent", "=", "4", ",", "separators", "=", "(", "\",\"", ",", "\":\"", ")", ")", "\n", "", "print", "(", "f\"COCO evaluation results are successfully exported to {export_path}\"", ")", "\n", "return", "{", "\"eval_results\"", ":", "eval_results", ",", "\"export_path\"", ":", "export_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation.evaluate": [[346, 392], ["coco_evaluation.evaluate_core", "ModuleNotFoundError"], "function", ["home.repos.pwc.inspect_result.obss_sahi.scripts.coco_evaluation.evaluate_core"], ["", "def", "evaluate", "(", "\n", "dataset_json_path", ":", "str", ",", "\n", "result_json_path", ":", "str", ",", "\n", "out_dir", ":", "str", "=", "None", ",", "\n", "type", ":", "str", "=", "\"bbox\"", ",", "\n", "classwise", ":", "bool", "=", "False", ",", "\n", "max_detections", ":", "int", "=", "500", ",", "\n", "iou_thrs", ":", "Union", "[", "List", "[", "float", "]", ",", "float", "]", "=", "None", ",", "\n", "areas", ":", "List", "[", "int", "]", "=", "[", "1024", ",", "9216", ",", "10000000000", "]", ",", "\n", "return_dict", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        dataset_json_path (str): file path for the coco dataset json file\n        result_json_path (str): file path for the coco result json file\n        out_dir (str): dir to save eval result\n        type (bool): 'bbox' or 'segm'\n        classwise (bool): whether to evaluate the AP for each class\n        max_detections (int): Maximum number of detections to consider for AP alculation. Default: 500\n        iou_thrs (float): IoU threshold used for evaluating recalls/mAPs\n        areas (List[int]): area regions for coco evaluation calculations\n        return_dict (bool): If True, returns a dict with 'eval_results' 'export_path' fields.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "from", "pycocotools", ".", "cocoeval", "import", "COCOeval", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "        ", "raise", "ModuleNotFoundError", "(", "\n", "'Please run \"pip install -U pycocotools\" '", "\"to install pycocotools first for coco evaluation.\"", "\n", ")", "\n", "\n", "# perform coco eval", "\n", "", "result", "=", "evaluate_core", "(", "\n", "dataset_json_path", ",", "\n", "result_json_path", ",", "\n", "type", ",", "\n", "classwise", ",", "\n", "max_detections", ",", "\n", "iou_thrs", ",", "\n", "out_dir", "=", "out_dir", ",", "\n", "areas", "=", "areas", ",", "\n", "COCO", "=", "COCO", ",", "\n", "COCOeval", "=", "COCOeval", ",", "\n", ")", "\n", "if", "return_dict", ":", "\n", "        ", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.scripts.slice_coco.slice": [[9, 64], ["isinstance", "print", "str", "sahi.utils.file.Path().name.replace", "sahi.slicing.slice_coco", "os.path.join", "sahi.utils.file.save_json", "print", "sahi.utils.file.Path", "sahi.utils.file.Path", "str", "str().replace", "sahi.utils.file.Path", "str", "str().replace", "str", "str"], "function", ["home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_coco", "home.repos.pwc.inspect_result.obss_sahi.utils.file.save_json"], ["def", "slice", "(", "\n", "image_dir", ":", "str", ",", "\n", "dataset_json_path", ":", "str", ",", "\n", "slice_size", ":", "int", "=", "512", ",", "\n", "overlap_ratio", ":", "float", "=", "0.2", ",", "\n", "ignore_negative_samples", ":", "bool", "=", "False", ",", "\n", "output_dir", ":", "str", "=", "\"runs/slice_coco\"", ",", "\n", "min_area_ratio", ":", "float", "=", "0.1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        image_dir (str): directory for coco images\n        dataset_json_path (str): file path for the coco dataset json file\n        slice_size (int)\n        overlap_ratio (float): slice overlap ratio\n        ignore_negative_samples (bool): ignore images without annotation\n        output_dir (str): output export dir\n        min_area_ratio (float): If the cropped annotation area to original\n            annotation ratio is smaller than this value, the annotation\n            is filtered out. Default 0.1.\n    \"\"\"", "\n", "\n", "# assure slice_size is list", "\n", "slice_size_list", "=", "slice_size", "\n", "if", "isinstance", "(", "slice_size_list", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "        ", "slice_size_list", "=", "[", "slice_size_list", "]", "\n", "\n", "# slice coco dataset images and annotations", "\n", "", "print", "(", "\"Slicing step is starting...\"", ")", "\n", "for", "slice_size", "in", "slice_size_list", ":", "\n", "# in format: train_images_512_01", "\n", "        ", "output_images_folder_name", "=", "(", "\n", "Path", "(", "dataset_json_path", ")", ".", "stem", "+", "f\"_images_{str(slice_size)}_{str(overlap_ratio).replace('.','')}\"", "\n", ")", "\n", "output_images_dir", "=", "str", "(", "Path", "(", "output_dir", ")", "/", "output_images_folder_name", ")", "\n", "sliced_coco_name", "=", "Path", "(", "dataset_json_path", ")", ".", "name", ".", "replace", "(", "\n", "\".json\"", ",", "f\"_{str(slice_size)}_{str(overlap_ratio).replace('.','')}\"", "\n", ")", "\n", "coco_dict", ",", "coco_path", "=", "slice_coco", "(", "\n", "coco_annotation_file_path", "=", "dataset_json_path", ",", "\n", "image_dir", "=", "image_dir", ",", "\n", "output_coco_annotation_file_name", "=", "\"\"", ",", "\n", "output_dir", "=", "output_images_dir", ",", "\n", "ignore_negative_samples", "=", "ignore_negative_samples", ",", "\n", "slice_height", "=", "slice_size", ",", "\n", "slice_width", "=", "slice_size", ",", "\n", "min_area_ratio", "=", "min_area_ratio", ",", "\n", "overlap_height_ratio", "=", "overlap_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_ratio", ",", "\n", "out_ext", "=", "\".jpg\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "output_coco_annotation_file_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "sliced_coco_name", "+", "\".json\"", ")", "\n", "save_json", "(", "coco_dict", ",", "output_coco_annotation_file_path", ")", "\n", "print", "(", "f\"Sliced dataset for 'slice_size: {slice_size}' is exported to {output_dir}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.PostprocessPredictions.__init__": [[460, 469], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", "match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "class_agnostic", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "match_threshold", "=", "match_threshold", "\n", "self", ".", "class_agnostic", "=", "class_agnostic", "\n", "self", ".", "match_metric", "=", "match_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.PostprocessPredictions.__call__": [[470, 472], ["NotImplementedError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.NMSPostprocess.__call__": [[475, 495], ["sahi.postprocess.utils.ObjectPredictionList", "sahi.postprocess.utils.ObjectPredictionList.totensor", "object_prediction_list[].tolist", "combine.nms", "combine.batched_nms", "isinstance"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.totensor", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.nms", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.batched_nms"], ["    ", "def", "__call__", "(", "\n", "self", ",", "\n", "object_predictions", ":", "List", "[", "ObjectPrediction", "]", ",", "\n", ")", ":", "\n", "        ", "object_prediction_list", "=", "ObjectPredictionList", "(", "object_predictions", ")", "\n", "object_predictions_as_torch", "=", "object_prediction_list", ".", "totensor", "(", ")", "\n", "if", "self", ".", "class_agnostic", ":", "\n", "            ", "keep", "=", "nms", "(", "\n", "object_predictions_as_torch", ",", "match_threshold", "=", "self", ".", "match_threshold", ",", "match_metric", "=", "self", ".", "match_metric", "\n", ")", "\n", "", "else", ":", "\n", "            ", "keep", "=", "batched_nms", "(", "\n", "object_predictions_as_torch", ",", "match_threshold", "=", "self", ".", "match_threshold", ",", "match_metric", "=", "self", ".", "match_metric", "\n", ")", "\n", "\n", "", "selected_object_predictions", "=", "object_prediction_list", "[", "keep", "]", ".", "tolist", "(", ")", "\n", "if", "not", "isinstance", "(", "selected_object_predictions", ",", "list", ")", ":", "\n", "            ", "selected_object_predictions", "=", "[", "selected_object_predictions", "]", "\n", "\n", "", "return", "selected_object_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.NMMPostprocess.__call__": [[498, 532], ["sahi.postprocess.utils.ObjectPredictionList", "sahi.postprocess.utils.ObjectPredictionList.totensor", "batched_nmm.items", "combine.nmm", "combine.batched_nmm", "selected_object_predictions.append", "sahi.postprocess.utils.has_match", "object_prediction_list[].tolist", "object_prediction_list[].tolist", "object_prediction_list[].tolist", "sahi.postprocess.utils.merge_object_prediction_pair", "object_prediction_list[].tolist", "object_prediction_list[].tolist"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.totensor", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.nmm", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.batched_nmm", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.has_match", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.merge_object_prediction_pair", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["    ", "def", "__call__", "(", "\n", "self", ",", "\n", "object_predictions", ":", "List", "[", "ObjectPrediction", "]", ",", "\n", ")", ":", "\n", "        ", "object_prediction_list", "=", "ObjectPredictionList", "(", "object_predictions", ")", "\n", "object_predictions_as_torch", "=", "object_prediction_list", ".", "totensor", "(", ")", "\n", "if", "self", ".", "class_agnostic", ":", "\n", "            ", "keep_to_merge_list", "=", "nmm", "(", "\n", "object_predictions_as_torch", ",", "\n", "match_threshold", "=", "self", ".", "match_threshold", ",", "\n", "match_metric", "=", "self", ".", "match_metric", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "keep_to_merge_list", "=", "batched_nmm", "(", "\n", "object_predictions_as_torch", ",", "\n", "match_threshold", "=", "self", ".", "match_threshold", ",", "\n", "match_metric", "=", "self", ".", "match_metric", ",", "\n", ")", "\n", "\n", "", "selected_object_predictions", "=", "[", "]", "\n", "for", "keep_ind", ",", "merge_ind_list", "in", "keep_to_merge_list", ".", "items", "(", ")", ":", "\n", "            ", "for", "merge_ind", "in", "merge_ind_list", ":", "\n", "                ", "if", "has_match", "(", "\n", "object_prediction_list", "[", "keep_ind", "]", ".", "tolist", "(", ")", ",", "\n", "object_prediction_list", "[", "merge_ind", "]", ".", "tolist", "(", ")", ",", "\n", "self", ".", "match_metric", ",", "\n", "self", ".", "match_threshold", ",", "\n", ")", ":", "\n", "                    ", "object_prediction_list", "[", "keep_ind", "]", "=", "merge_object_prediction_pair", "(", "\n", "object_prediction_list", "[", "keep_ind", "]", ".", "tolist", "(", ")", ",", "object_prediction_list", "[", "merge_ind", "]", ".", "tolist", "(", ")", "\n", ")", "\n", "", "", "selected_object_predictions", ".", "append", "(", "object_prediction_list", "[", "keep_ind", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "", "return", "selected_object_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.GreedyNMMPostprocess.__call__": [[535, 569], ["sahi.postprocess.utils.ObjectPredictionList", "sahi.postprocess.utils.ObjectPredictionList.totensor", "batched_greedy_nmm.items", "combine.greedy_nmm", "combine.batched_greedy_nmm", "selected_object_predictions.append", "sahi.postprocess.utils.has_match", "object_prediction_list[].tolist", "object_prediction_list[].tolist", "object_prediction_list[].tolist", "sahi.postprocess.utils.merge_object_prediction_pair", "object_prediction_list[].tolist", "object_prediction_list[].tolist"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.totensor", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.greedy_nmm", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.batched_greedy_nmm", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.has_match", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.merge_object_prediction_pair", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["    ", "def", "__call__", "(", "\n", "self", ",", "\n", "object_predictions", ":", "List", "[", "ObjectPrediction", "]", ",", "\n", ")", ":", "\n", "        ", "object_prediction_list", "=", "ObjectPredictionList", "(", "object_predictions", ")", "\n", "object_predictions_as_torch", "=", "object_prediction_list", ".", "totensor", "(", ")", "\n", "if", "self", ".", "class_agnostic", ":", "\n", "            ", "keep_to_merge_list", "=", "greedy_nmm", "(", "\n", "object_predictions_as_torch", ",", "\n", "match_threshold", "=", "self", ".", "match_threshold", ",", "\n", "match_metric", "=", "self", ".", "match_metric", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "keep_to_merge_list", "=", "batched_greedy_nmm", "(", "\n", "object_predictions_as_torch", ",", "\n", "match_threshold", "=", "self", ".", "match_threshold", ",", "\n", "match_metric", "=", "self", ".", "match_metric", ",", "\n", ")", "\n", "\n", "", "selected_object_predictions", "=", "[", "]", "\n", "for", "keep_ind", ",", "merge_ind_list", "in", "keep_to_merge_list", ".", "items", "(", ")", ":", "\n", "            ", "for", "merge_ind", "in", "merge_ind_list", ":", "\n", "                ", "if", "has_match", "(", "\n", "object_prediction_list", "[", "keep_ind", "]", ".", "tolist", "(", ")", ",", "\n", "object_prediction_list", "[", "merge_ind", "]", ".", "tolist", "(", ")", ",", "\n", "self", ".", "match_metric", ",", "\n", "self", ".", "match_threshold", ",", "\n", ")", ":", "\n", "                    ", "object_prediction_list", "[", "keep_ind", "]", "=", "merge_object_prediction_pair", "(", "\n", "object_prediction_list", "[", "keep_ind", "]", ".", "tolist", "(", ")", ",", "object_prediction_list", "[", "merge_ind", "]", ".", "tolist", "(", ")", "\n", ")", "\n", "", "", "selected_object_predictions", ".", "append", "(", "object_prediction_list", "[", "keep_ind", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "", "return", "selected_object_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.LSNMSPostprocess.__call__": [[573, 605], ["logger.warning", "sahi.postprocess.utils.ObjectPredictionList", "sahi.postprocess.utils.ObjectPredictionList.tonumpy", "object_predictions_as_numpy[].astype", "combine.nms", "object_prediction_list[].tolist", "NotImplementedError", "isinstance", "ModuleNotFoundError"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tonumpy", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.nms", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["    ", "def", "__call__", "(", "\n", "self", ",", "\n", "object_predictions", ":", "List", "[", "ObjectPrediction", "]", ",", "\n", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "lsnms", "import", "nms", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "            ", "raise", "ModuleNotFoundError", "(", "\n", "'Please run \"pip install lsnms>0.3.1\" to install lsnms first for lsnms utilities.'", "\n", ")", "\n", "\n", "", "if", "self", ".", "match_metric", "==", "\"IOS\"", ":", "\n", "            ", "NotImplementedError", "(", "f\"match_metric={self.match_metric} is not supported for LSNMSPostprocess\"", ")", "\n", "\n", "", "logger", ".", "warning", "(", "\"LSNMSPostprocess is experimental and not recommended to use.\"", ")", "\n", "\n", "object_prediction_list", "=", "ObjectPredictionList", "(", "object_predictions", ")", "\n", "object_predictions_as_numpy", "=", "object_prediction_list", ".", "tonumpy", "(", ")", "\n", "\n", "boxes", "=", "object_predictions_as_numpy", "[", ":", ",", ":", "4", "]", "\n", "scores", "=", "object_predictions_as_numpy", "[", ":", ",", "4", "]", "\n", "class_ids", "=", "object_predictions_as_numpy", "[", ":", ",", "5", "]", ".", "astype", "(", "\"uint8\"", ")", "\n", "\n", "keep", "=", "nms", "(", "\n", "boxes", ",", "scores", ",", "iou_threshold", "=", "self", ".", "match_threshold", ",", "class_ids", "=", "None", "if", "self", ".", "class_agnostic", "else", "class_ids", "\n", ")", "\n", "\n", "selected_object_predictions", "=", "object_prediction_list", "[", "keep", "]", ".", "tolist", "(", ")", "\n", "if", "not", "isinstance", "(", "selected_object_predictions", ",", "list", ")", ":", "\n", "            ", "selected_object_predictions", "=", "[", "selected_object_predictions", "]", "\n", "\n", "", "return", "selected_object_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.batched_nms": [[16, 41], ["sahi.utils.import_utils.check_requirements", "predictions[].squeeze", "predictions[].squeeze", "torch.zeros_like", "torch.unique", "keep_indices[].tolist", "combine.nms", "torch.where", "torch.where", "scores[].sort"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.nms"], ["@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "batched_nms", "(", "predictions", ":", "torch", ".", "tensor", ",", "match_metric", ":", "str", "=", "\"IOU\"", ",", "match_threshold", ":", "float", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    Apply non-maximum suppression to avoid detecting too many\n    overlapping bounding boxes for a given object.\n    Args:\n        predictions: (tensor) The location preds for the image\n            along with the class predscores, Shape: [num_boxes,5].\n        match_metric: (str) IOU or IOS\n        match_threshold: (float) The overlap thresh for\n            match metric.\n    Returns:\n        A list of filtered indexes, Shape: [ ,]\n    \"\"\"", "\n", "scores", "=", "predictions", "[", ":", ",", "4", "]", ".", "squeeze", "(", ")", "\n", "category_ids", "=", "predictions", "[", ":", ",", "5", "]", ".", "squeeze", "(", ")", "\n", "keep_mask", "=", "torch", ".", "zeros_like", "(", "category_ids", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "for", "category_id", "in", "torch", ".", "unique", "(", "category_ids", ")", ":", "\n", "        ", "curr_indices", "=", "torch", ".", "where", "(", "category_ids", "==", "category_id", ")", "[", "0", "]", "\n", "curr_keep_indices", "=", "nms", "(", "predictions", "[", "curr_indices", "]", ",", "match_metric", ",", "match_threshold", ")", "\n", "keep_mask", "[", "curr_indices", "[", "curr_keep_indices", "]", "]", "=", "True", "\n", "", "keep_indices", "=", "torch", ".", "where", "(", "keep_mask", ")", "[", "0", "]", "\n", "# sort selected indices by their scores", "\n", "keep_indices", "=", "keep_indices", "[", "scores", "[", "keep_indices", "]", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "]", ".", "tolist", "(", ")", "\n", "return", "keep_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.nms": [[43, 148], ["sahi.utils.import_utils.check_requirements", "scores.argsort", "len", "keep.append", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.max", "torch.max", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.index_select", "idx.tolist", "len", "torch.min", "ValueError"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "nms", "(", "\n", "predictions", ":", "torch", ".", "tensor", ",", "\n", "match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Apply non-maximum suppression to avoid detecting too many\n    overlapping bounding boxes for a given object.\n    Args:\n        predictions: (tensor) The location preds for the image\n            along with the class predscores, Shape: [num_boxes,5].\n        match_metric: (str) IOU or IOS\n        match_threshold: (float) The overlap thresh for\n            match metric.\n    Returns:\n        A list of filtered indexes, Shape: [ ,]\n    \"\"\"", "\n", "# we extract coordinates for every", "\n", "# prediction box present in P", "\n", "x1", "=", "predictions", "[", ":", ",", "0", "]", "\n", "y1", "=", "predictions", "[", ":", ",", "1", "]", "\n", "x2", "=", "predictions", "[", ":", ",", "2", "]", "\n", "y2", "=", "predictions", "[", ":", ",", "3", "]", "\n", "\n", "# we extract the confidence scores as well", "\n", "scores", "=", "predictions", "[", ":", ",", "4", "]", "\n", "\n", "# calculate area of every block in P", "\n", "areas", "=", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "\n", "\n", "# sort the prediction boxes in P", "\n", "# according to their confidence scores", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "\n", "\n", "# initialise an empty list for", "\n", "# filtered prediction boxes", "\n", "keep", "=", "[", "]", "\n", "\n", "while", "len", "(", "order", ")", ">", "0", ":", "\n", "# extract the index of the", "\n", "# prediction with highest score", "\n", "# we call this prediction S", "\n", "        ", "idx", "=", "order", "[", "-", "1", "]", "\n", "\n", "# push S in filtered predictions list", "\n", "keep", ".", "append", "(", "idx", ".", "tolist", "(", ")", ")", "\n", "\n", "# remove S from P", "\n", "order", "=", "order", "[", ":", "-", "1", "]", "\n", "\n", "# sanity check", "\n", "if", "len", "(", "order", ")", "==", "0", ":", "\n", "            ", "break", "\n", "\n", "# select coordinates of BBoxes according to", "\n", "# the indices in order", "\n", "", "xx1", "=", "torch", ".", "index_select", "(", "x1", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "xx2", "=", "torch", ".", "index_select", "(", "x2", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "yy1", "=", "torch", ".", "index_select", "(", "y1", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "yy2", "=", "torch", ".", "index_select", "(", "y2", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "\n", "# find the coordinates of the intersection boxes", "\n", "xx1", "=", "torch", ".", "max", "(", "xx1", ",", "x1", "[", "idx", "]", ")", "\n", "yy1", "=", "torch", ".", "max", "(", "yy1", ",", "y1", "[", "idx", "]", ")", "\n", "xx2", "=", "torch", ".", "min", "(", "xx2", ",", "x2", "[", "idx", "]", ")", "\n", "yy2", "=", "torch", ".", "min", "(", "yy2", ",", "y2", "[", "idx", "]", ")", "\n", "\n", "# find height and width of the intersection boxes", "\n", "w", "=", "xx2", "-", "xx1", "\n", "h", "=", "yy2", "-", "yy1", "\n", "\n", "# take max with 0.0 to avoid negative w and h", "\n", "# due to non-overlapping boxes", "\n", "w", "=", "torch", ".", "clamp", "(", "w", ",", "min", "=", "0.0", ")", "\n", "h", "=", "torch", ".", "clamp", "(", "h", ",", "min", "=", "0.0", ")", "\n", "\n", "# find the intersection area", "\n", "inter", "=", "w", "*", "h", "\n", "\n", "# find the areas of BBoxes according the indices in order", "\n", "rem_areas", "=", "torch", ".", "index_select", "(", "areas", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "\n", "if", "match_metric", "==", "\"IOU\"", ":", "\n", "# find the union of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "union", "=", "(", "rem_areas", "-", "inter", ")", "+", "areas", "[", "idx", "]", "\n", "# find the IoU of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "union", "\n", "\n", "", "elif", "match_metric", "==", "\"IOS\"", ":", "\n", "# find the smaller area of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "smaller", "=", "torch", ".", "min", "(", "rem_areas", ",", "areas", "[", "idx", "]", ")", "\n", "# find the IoU of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "smaller", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "# keep the boxes with IoU less than thresh_iou", "\n", "", "mask", "=", "match_metric_value", "<", "match_threshold", "\n", "order", "=", "order", "[", "mask", "]", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.batched_greedy_nmm": [[150, 180], ["sahi.utils.import_utils.check_requirements", "object_predictions_as_tensor[].squeeze", "torch.unique", "combine.greedy_nmm", "curr_indices.tolist", "greedy_nmm.items", "torch.where"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.greedy_nmm", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "batched_greedy_nmm", "(", "\n", "object_predictions_as_tensor", ":", "torch", ".", "tensor", ",", "\n", "match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Apply greedy version of non-maximum merging per category to avoid detecting\n    too many overlapping bounding boxes for a given object.\n    Args:\n        object_predictions_as_tensor: (tensor) The location preds for the image\n            along with the class predscores, Shape: [num_boxes,5].\n        match_metric: (str) IOU or IOS\n        match_threshold: (float) The overlap thresh for\n            match metric.\n    Returns:\n        keep_to_merge_list: (Dict[int:List[int]]) mapping from prediction indices\n        to keep to a list of prediction indices to be merged.\n    \"\"\"", "\n", "category_ids", "=", "object_predictions_as_tensor", "[", ":", ",", "5", "]", ".", "squeeze", "(", ")", "\n", "keep_to_merge_list", "=", "{", "}", "\n", "for", "category_id", "in", "torch", ".", "unique", "(", "category_ids", ")", ":", "\n", "        ", "curr_indices", "=", "torch", ".", "where", "(", "category_ids", "==", "category_id", ")", "[", "0", "]", "\n", "curr_keep_to_merge_list", "=", "greedy_nmm", "(", "object_predictions_as_tensor", "[", "curr_indices", "]", ",", "match_metric", ",", "match_threshold", ")", "\n", "curr_indices_list", "=", "curr_indices", ".", "tolist", "(", ")", "\n", "for", "curr_keep", ",", "curr_merge_list", "in", "curr_keep_to_merge_list", ".", "items", "(", ")", ":", "\n", "            ", "keep", "=", "curr_indices_list", "[", "curr_keep", "]", "\n", "merge_list", "=", "[", "curr_indices_list", "[", "curr_merge_ind", "]", "for", "curr_merge_ind", "in", "curr_merge_list", "]", "\n", "keep_to_merge_list", "[", "keep", "]", "=", "merge_list", "\n", "", "", "return", "keep_to_merge_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.greedy_nmm": [[182, 303], ["sahi.utils.import_utils.check_requirements", "scores.argsort", "len", "keep.append", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.max", "torch.max", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.index_select", "order[].flip", "order[].flip.tolist", "idx.tolist", "len", "keep_to_merge_list[].append", "torch.min", "ValueError", "scores[].argsort", "idx.tolist", "idx.tolist"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "greedy_nmm", "(", "\n", "object_predictions_as_tensor", ":", "torch", ".", "tensor", ",", "\n", "match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Apply greedy version of non-maximum merging to avoid detecting too many\n    overlapping bounding boxes for a given object.\n    Args:\n        object_predictions_as_tensor: (tensor) The location preds for the image\n            along with the class predscores, Shape: [num_boxes,5].\n        object_predictions_as_list: ObjectPredictionList Object prediction objects\n            to be merged.\n        match_metric: (str) IOU or IOS\n        match_threshold: (float) The overlap thresh for\n            match metric.\n    Returns:\n        keep_to_merge_list: (Dict[int:List[int]]) mapping from prediction indices\n        to keep to a list of prediction indices to be merged.\n    \"\"\"", "\n", "keep_to_merge_list", "=", "{", "}", "\n", "\n", "# we extract coordinates for every", "\n", "# prediction box present in P", "\n", "x1", "=", "object_predictions_as_tensor", "[", ":", ",", "0", "]", "\n", "y1", "=", "object_predictions_as_tensor", "[", ":", ",", "1", "]", "\n", "x2", "=", "object_predictions_as_tensor", "[", ":", ",", "2", "]", "\n", "y2", "=", "object_predictions_as_tensor", "[", ":", ",", "3", "]", "\n", "\n", "# we extract the confidence scores as well", "\n", "scores", "=", "object_predictions_as_tensor", "[", ":", ",", "4", "]", "\n", "\n", "# calculate area of every block in P", "\n", "areas", "=", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "\n", "\n", "# sort the prediction boxes in P", "\n", "# according to their confidence scores", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "\n", "\n", "# initialise an empty list for", "\n", "# filtered prediction boxes", "\n", "keep", "=", "[", "]", "\n", "\n", "while", "len", "(", "order", ")", ">", "0", ":", "\n", "# extract the index of the", "\n", "# prediction with highest score", "\n", "# we call this prediction S", "\n", "        ", "idx", "=", "order", "[", "-", "1", "]", "\n", "\n", "# push S in filtered predictions list", "\n", "keep", ".", "append", "(", "idx", ".", "tolist", "(", ")", ")", "\n", "\n", "# remove S from P", "\n", "order", "=", "order", "[", ":", "-", "1", "]", "\n", "\n", "# sanity check", "\n", "if", "len", "(", "order", ")", "==", "0", ":", "\n", "            ", "break", "\n", "\n", "# select coordinates of BBoxes according to", "\n", "# the indices in order", "\n", "", "xx1", "=", "torch", ".", "index_select", "(", "x1", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "xx2", "=", "torch", ".", "index_select", "(", "x2", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "yy1", "=", "torch", ".", "index_select", "(", "y1", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "yy2", "=", "torch", ".", "index_select", "(", "y2", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "\n", "# find the coordinates of the intersection boxes", "\n", "xx1", "=", "torch", ".", "max", "(", "xx1", ",", "x1", "[", "idx", "]", ")", "\n", "yy1", "=", "torch", ".", "max", "(", "yy1", ",", "y1", "[", "idx", "]", ")", "\n", "xx2", "=", "torch", ".", "min", "(", "xx2", ",", "x2", "[", "idx", "]", ")", "\n", "yy2", "=", "torch", ".", "min", "(", "yy2", ",", "y2", "[", "idx", "]", ")", "\n", "\n", "# find height and width of the intersection boxes", "\n", "w", "=", "xx2", "-", "xx1", "\n", "h", "=", "yy2", "-", "yy1", "\n", "\n", "# take max with 0.0 to avoid negative w and h", "\n", "# due to non-overlapping boxes", "\n", "w", "=", "torch", ".", "clamp", "(", "w", ",", "min", "=", "0.0", ")", "\n", "h", "=", "torch", ".", "clamp", "(", "h", ",", "min", "=", "0.0", ")", "\n", "\n", "# find the intersection area", "\n", "inter", "=", "w", "*", "h", "\n", "\n", "# find the areas of BBoxes according the indices in order", "\n", "rem_areas", "=", "torch", ".", "index_select", "(", "areas", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "\n", "if", "match_metric", "==", "\"IOU\"", ":", "\n", "# find the union of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "union", "=", "(", "rem_areas", "-", "inter", ")", "+", "areas", "[", "idx", "]", "\n", "# find the IoU of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "union", "\n", "\n", "", "elif", "match_metric", "==", "\"IOS\"", ":", "\n", "# find the smaller area of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "smaller", "=", "torch", ".", "min", "(", "rem_areas", ",", "areas", "[", "idx", "]", ")", "\n", "# find the IoS of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "smaller", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "# keep the boxes with IoU/IoS less than thresh_iou", "\n", "", "mask", "=", "match_metric_value", "<", "match_threshold", "\n", "matched_box_indices", "=", "order", "[", "(", "mask", "==", "False", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "]", ".", "flip", "(", "dims", "=", "(", "0", ",", ")", ")", "\n", "unmatched_indices", "=", "order", "[", "(", "mask", "==", "True", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "]", "\n", "\n", "# update box pool", "\n", "order", "=", "unmatched_indices", "[", "scores", "[", "unmatched_indices", "]", ".", "argsort", "(", ")", "]", "\n", "\n", "# create keep_ind to merge_ind_list mapping", "\n", "keep_to_merge_list", "[", "idx", ".", "tolist", "(", ")", "]", "=", "[", "]", "\n", "\n", "for", "matched_box_ind", "in", "matched_box_indices", ".", "tolist", "(", ")", ":", "\n", "            ", "keep_to_merge_list", "[", "idx", ".", "tolist", "(", ")", "]", ".", "append", "(", "matched_box_ind", ")", "\n", "\n", "", "", "return", "keep_to_merge_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.batched_nmm": [[305, 335], ["sahi.utils.import_utils.check_requirements", "object_predictions_as_tensor[].squeeze", "torch.unique", "combine.nmm", "curr_indices.tolist", "nmm.items", "torch.where"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.nmm", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "batched_nmm", "(", "\n", "object_predictions_as_tensor", ":", "torch", ".", "tensor", ",", "\n", "match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Apply non-maximum merging per category to avoid detecting too many\n    overlapping bounding boxes for a given object.\n    Args:\n        object_predictions_as_tensor: (tensor) The location preds for the image\n            along with the class predscores, Shape: [num_boxes,5].\n        match_metric: (str) IOU or IOS\n        match_threshold: (float) The overlap thresh for\n            match metric.\n    Returns:\n        keep_to_merge_list: (Dict[int:List[int]]) mapping from prediction indices\n        to keep to a list of prediction indices to be merged.\n    \"\"\"", "\n", "category_ids", "=", "object_predictions_as_tensor", "[", ":", ",", "5", "]", ".", "squeeze", "(", ")", "\n", "keep_to_merge_list", "=", "{", "}", "\n", "for", "category_id", "in", "torch", ".", "unique", "(", "category_ids", ")", ":", "\n", "        ", "curr_indices", "=", "torch", ".", "where", "(", "category_ids", "==", "category_id", ")", "[", "0", "]", "\n", "curr_keep_to_merge_list", "=", "nmm", "(", "object_predictions_as_tensor", "[", "curr_indices", "]", ",", "match_metric", ",", "match_threshold", ")", "\n", "curr_indices_list", "=", "curr_indices", ".", "tolist", "(", ")", "\n", "for", "curr_keep", ",", "curr_merge_list", "in", "curr_keep_to_merge_list", ".", "items", "(", ")", ":", "\n", "            ", "keep", "=", "curr_indices_list", "[", "curr_keep", "]", "\n", "merge_list", "=", "[", "curr_indices_list", "[", "curr_merge_ind", "]", "for", "curr_merge_ind", "in", "curr_merge_list", "]", "\n", "keep_to_merge_list", "[", "keep", "]", "=", "merge_list", "\n", "", "", "return", "keep_to_merge_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.combine.nmm": [[337, 455], ["sahi.utils.import_utils.check_requirements", "scores.argsort", "range", "len", "pred_ind.tolist.tolist", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.max", "torch.max", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.index_select", "other_pred_inds[].flip", "other_pred_inds[].flip.tolist", "other_pred_inds[].flip.tolist", "torch.min", "ValueError", "keep_to_merge_list[].append", "keep_to_merge_list[].append"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.import_utils.check_requirements", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "nmm", "(", "\n", "object_predictions_as_tensor", ":", "torch", ".", "tensor", ",", "\n", "match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Apply non-maximum merging to avoid detecting too many\n    overlapping bounding boxes for a given object.\n    Args:\n        object_predictions_as_tensor: (tensor) The location preds for the image\n            along with the class predscores, Shape: [num_boxes,5].\n        object_predictions_as_list: ObjectPredictionList Object prediction objects\n            to be merged.\n        match_metric: (str) IOU or IOS\n        match_threshold: (float) The overlap thresh for\n            match metric.\n    Returns:\n        keep_to_merge_list: (Dict[int:List[int]]) mapping from prediction indices\n        to keep to a list of prediction indices to be merged.\n    \"\"\"", "\n", "keep_to_merge_list", "=", "{", "}", "\n", "merge_to_keep", "=", "{", "}", "\n", "\n", "# we extract coordinates for every", "\n", "# prediction box present in P", "\n", "x1", "=", "object_predictions_as_tensor", "[", ":", ",", "0", "]", "\n", "y1", "=", "object_predictions_as_tensor", "[", ":", ",", "1", "]", "\n", "x2", "=", "object_predictions_as_tensor", "[", ":", ",", "2", "]", "\n", "y2", "=", "object_predictions_as_tensor", "[", ":", ",", "3", "]", "\n", "\n", "# we extract the confidence scores as well", "\n", "scores", "=", "object_predictions_as_tensor", "[", ":", ",", "4", "]", "\n", "\n", "# calculate area of every block in P", "\n", "areas", "=", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "\n", "\n", "# sort the prediction boxes in P", "\n", "# according to their confidence scores", "\n", "order", "=", "scores", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "\n", "for", "ind", "in", "range", "(", "len", "(", "object_predictions_as_tensor", ")", ")", ":", "\n", "# extract the index of the", "\n", "# prediction with highest score", "\n", "# we call this prediction S", "\n", "        ", "pred_ind", "=", "order", "[", "ind", "]", "\n", "pred_ind", "=", "pred_ind", ".", "tolist", "(", ")", "\n", "\n", "# remove selected pred", "\n", "other_pred_inds", "=", "order", "[", "order", "!=", "pred_ind", "]", "\n", "\n", "# select coordinates of BBoxes according to", "\n", "# the indices in order", "\n", "xx1", "=", "torch", ".", "index_select", "(", "x1", ",", "dim", "=", "0", ",", "index", "=", "other_pred_inds", ")", "\n", "xx2", "=", "torch", ".", "index_select", "(", "x2", ",", "dim", "=", "0", ",", "index", "=", "other_pred_inds", ")", "\n", "yy1", "=", "torch", ".", "index_select", "(", "y1", ",", "dim", "=", "0", ",", "index", "=", "other_pred_inds", ")", "\n", "yy2", "=", "torch", ".", "index_select", "(", "y2", ",", "dim", "=", "0", ",", "index", "=", "other_pred_inds", ")", "\n", "\n", "# find the coordinates of the intersection boxes", "\n", "xx1", "=", "torch", ".", "max", "(", "xx1", ",", "x1", "[", "pred_ind", "]", ")", "\n", "yy1", "=", "torch", ".", "max", "(", "yy1", ",", "y1", "[", "pred_ind", "]", ")", "\n", "xx2", "=", "torch", ".", "min", "(", "xx2", ",", "x2", "[", "pred_ind", "]", ")", "\n", "yy2", "=", "torch", ".", "min", "(", "yy2", ",", "y2", "[", "pred_ind", "]", ")", "\n", "\n", "# find height and width of the intersection boxes", "\n", "w", "=", "xx2", "-", "xx1", "\n", "h", "=", "yy2", "-", "yy1", "\n", "\n", "# take max with 0.0 to avoid negative w and h", "\n", "# due to non-overlapping boxes", "\n", "w", "=", "torch", ".", "clamp", "(", "w", ",", "min", "=", "0.0", ")", "\n", "h", "=", "torch", ".", "clamp", "(", "h", ",", "min", "=", "0.0", ")", "\n", "\n", "# find the intersection area", "\n", "inter", "=", "w", "*", "h", "\n", "\n", "# find the areas of BBoxes according the indices in order", "\n", "rem_areas", "=", "torch", ".", "index_select", "(", "areas", ",", "dim", "=", "0", ",", "index", "=", "other_pred_inds", ")", "\n", "\n", "if", "match_metric", "==", "\"IOU\"", ":", "\n", "# find the union of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "union", "=", "(", "rem_areas", "-", "inter", ")", "+", "areas", "[", "pred_ind", "]", "\n", "# find the IoU of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "union", "\n", "\n", "", "elif", "match_metric", "==", "\"IOS\"", ":", "\n", "# find the smaller area of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "smaller", "=", "torch", ".", "min", "(", "rem_areas", ",", "areas", "[", "pred_ind", "]", ")", "\n", "# find the IoS of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "smaller", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "# keep the boxes with IoU/IoS less than thresh_iou", "\n", "", "mask", "=", "match_metric_value", "<", "match_threshold", "\n", "matched_box_indices", "=", "other_pred_inds", "[", "(", "mask", "==", "False", ")", ".", "nonzero", "(", ")", ".", "flatten", "(", ")", "]", ".", "flip", "(", "dims", "=", "(", "0", ",", ")", ")", "\n", "\n", "# create keep_ind to merge_ind_list mapping", "\n", "if", "pred_ind", "not", "in", "merge_to_keep", ":", "\n", "            ", "keep_to_merge_list", "[", "pred_ind", "]", "=", "[", "]", "\n", "\n", "for", "matched_box_ind", "in", "matched_box_indices", ".", "tolist", "(", ")", ":", "\n", "                ", "if", "matched_box_ind", "not", "in", "merge_to_keep", ":", "\n", "                    ", "keep_to_merge_list", "[", "pred_ind", "]", ".", "append", "(", "matched_box_ind", ")", "\n", "merge_to_keep", "[", "matched_box_ind", "]", "=", "pred_ind", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "keep", "=", "merge_to_keep", "[", "pred_ind", "]", "\n", "for", "matched_box_ind", "in", "matched_box_indices", ".", "tolist", "(", ")", ":", "\n", "                ", "if", "matched_box_ind", "not", "in", "keep_to_merge_list", "and", "matched_box_ind", "not", "in", "merge_to_keep", ":", "\n", "                    ", "keep_to_merge_list", "[", "keep", "]", ".", "append", "(", "matched_box_ind", ")", "\n", "merge_to_keep", "[", "matched_box_ind", "]", "=", "keep", "\n", "\n", "", "", "", "", "return", "keep_to_merge_list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.__init__": [[12, 15], ["collections.abc.Sequence.__init__"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "list", ")", ":", "\n", "        ", "self", ".", "list", "=", "list", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.__getitem__": [[16, 26], ["isinstance", "torch.is_tensor", "isinstance", "i.tolist.tolist.tolist", "utils.ObjectPredictionList", "isinstance", "map", "utils.ObjectPredictionList", "NotImplementedError", "list", "type"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "i", ")", "or", "isinstance", "(", "i", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "i", "=", "i", ".", "tolist", "(", ")", "\n", "", "if", "isinstance", "(", "i", ",", "int", ")", ":", "\n", "            ", "return", "ObjectPredictionList", "(", "[", "self", ".", "list", "[", "i", "]", "]", ")", "\n", "", "elif", "isinstance", "(", "i", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "accessed_mapping", "=", "map", "(", "self", ".", "list", ".", "__getitem__", ",", "i", ")", "\n", "return", "ObjectPredictionList", "(", "list", "(", "accessed_mapping", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"{type(i)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.__setitem__": [[27, 43], ["isinstance", "torch.is_tensor", "isinstance", "i.tolist.tolist.tolist", "isinstance", "isinstance", "NotImplementedError", "len", "len", "ValueError", "enumerate", "enumerate", "type"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "", "def", "__setitem__", "(", "self", ",", "i", ",", "elem", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "i", ")", "or", "isinstance", "(", "i", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "i", "=", "i", ".", "tolist", "(", ")", "\n", "", "if", "isinstance", "(", "i", ",", "int", ")", ":", "\n", "            ", "self", ".", "list", "[", "i", "]", "=", "elem", "\n", "", "elif", "isinstance", "(", "i", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "if", "len", "(", "i", ")", "!=", "len", "(", "elem", ")", ":", "\n", "                ", "raise", "ValueError", "(", ")", "\n", "", "if", "isinstance", "(", "elem", ",", "ObjectPredictionList", ")", ":", "\n", "                ", "for", "ind", ",", "el", "in", "enumerate", "(", "elem", ".", "list", ")", ":", "\n", "                    ", "self", ".", "list", "[", "i", "[", "ind", "]", "]", "=", "el", "\n", "", "", "else", ":", "\n", "                ", "for", "ind", ",", "el", "in", "enumerate", "(", "elem", ")", ":", "\n", "                    ", "self", ".", "list", "[", "i", "[", "ind", "]", "]", "=", "el", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"{type(i)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.__str__": [[47, 49], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.extend": [[50, 52], ["utils.ObjectPredictionList.list.extend"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.extend"], ["", "def", "extend", "(", "self", ",", "object_prediction_list", ")", ":", "\n", "        ", "self", ".", "list", ".", "extend", "(", "object_prediction_list", ".", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.totensor": [[53, 55], ["utils.object_prediction_list_to_torch"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.object_prediction_list_to_torch"], ["", "def", "totensor", "(", "self", ")", ":", "\n", "        ", "return", "object_prediction_list_to_torch", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tonumpy": [[56, 58], ["utils.object_prediction_list_to_numpy"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.object_prediction_list_to_numpy"], ["", "def", "tonumpy", "(", "self", ")", ":", "\n", "        ", "return", "object_prediction_list_to_numpy", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist": [[59, 64], ["len"], "methods", ["None"], ["", "def", "tolist", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "list", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "list", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "list", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.object_prediction_list_to_torch": [[66, 78], ["len", "torch.zeros", "enumerate", "torch.tensor", "object_prediction.tolist().bbox.to_voc_bbox", "object_prediction.tolist", "object_prediction.tolist", "object_prediction.tolist"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "", "", "def", "object_prediction_list_to_torch", "(", "object_prediction_list", ":", "ObjectPredictionList", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"\n    Returns:\n        torch.tensor of size N x [x1, y1, x2, y2, score, category_id]\n    \"\"\"", "\n", "num_predictions", "=", "len", "(", "object_prediction_list", ")", "\n", "torch_predictions", "=", "torch", ".", "zeros", "(", "[", "num_predictions", ",", "6", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "ind", ",", "object_prediction", "in", "enumerate", "(", "object_prediction_list", ")", ":", "\n", "        ", "torch_predictions", "[", "ind", ",", ":", "4", "]", "=", "torch", ".", "tensor", "(", "object_prediction", ".", "tolist", "(", ")", ".", "bbox", ".", "to_voc_bbox", "(", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "torch_predictions", "[", "ind", ",", "4", "]", "=", "object_prediction", ".", "tolist", "(", ")", ".", "score", ".", "value", "\n", "torch_predictions", "[", "ind", ",", "5", "]", "=", "object_prediction", ".", "tolist", "(", ")", ".", "category", ".", "id", "\n", "", "return", "torch_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.object_prediction_list_to_numpy": [[80, 92], ["len", "numpy.zeros", "enumerate", "numpy.array", "object_prediction.tolist().bbox.to_voc_bbox", "object_prediction.tolist", "object_prediction.tolist", "object_prediction.tolist"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "object_prediction_list_to_numpy", "(", "object_prediction_list", ":", "ObjectPredictionList", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Returns:\n        np.ndarray of size N x [x1, y1, x2, y2, score, category_id]\n    \"\"\"", "\n", "num_predictions", "=", "len", "(", "object_prediction_list", ")", "\n", "numpy_predictions", "=", "np", ".", "zeros", "(", "[", "num_predictions", ",", "6", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "ind", ",", "object_prediction", "in", "enumerate", "(", "object_prediction_list", ")", ":", "\n", "        ", "numpy_predictions", "[", "ind", ",", ":", "4", "]", "=", "np", ".", "array", "(", "object_prediction", ".", "tolist", "(", ")", ".", "bbox", ".", "to_voc_bbox", "(", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "numpy_predictions", "[", "ind", ",", "4", "]", "=", "object_prediction", ".", "tolist", "(", ")", ".", "score", ".", "value", "\n", "numpy_predictions", "[", "ind", ",", "5", "]", "=", "object_prediction", ".", "tolist", "(", ")", ".", "category", ".", "id", "\n", "", "return", "numpy_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_box_union": [[94, 105], ["numpy.array", "numpy.array", "numpy.minimum", "numpy.maximum", "list", "numpy.concatenate"], "function", ["None"], ["", "def", "calculate_box_union", "(", "box1", ":", "Union", "[", "List", "[", "int", "]", ",", "np", ".", "ndarray", "]", ",", "box2", ":", "Union", "[", "List", "[", "int", "]", ",", "np", ".", "ndarray", "]", ")", "->", "List", "[", "int", "]", ":", "\n", "    ", "\"\"\"\n    Args:\n        box1 (List[int]): [x1, y1, x2, y2]\n        box2 (List[int]): [x1, y1, x2, y2]\n    \"\"\"", "\n", "box1", "=", "np", ".", "array", "(", "box1", ")", "\n", "box2", "=", "np", ".", "array", "(", "box2", ")", "\n", "left_top", "=", "np", ".", "minimum", "(", "box1", "[", ":", "2", "]", ",", "box2", "[", ":", "2", "]", ")", "\n", "right_bottom", "=", "np", ".", "maximum", "(", "box1", "[", "2", ":", "]", ",", "box2", "[", "2", ":", "]", ")", "\n", "return", "list", "(", "np", ".", "concatenate", "(", "(", "left_top", ",", "right_bottom", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area": [[107, 113], ["None"], "function", ["None"], ["", "def", "calculate_area", "(", "box", ":", "Union", "[", "List", "[", "int", "]", ",", "np", ".", "ndarray", "]", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Args:\n        box (List[int]): [x1, y1, x2, y2]\n    \"\"\"", "\n", "return", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_intersection_area": [[115, 125], ["numpy.maximum", "numpy.minimum"], "function", ["None"], ["", "def", "calculate_intersection_area", "(", "box1", ":", "np", ".", "ndarray", ",", "box2", ":", "np", ".", "ndarray", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Args:\n        box1 (np.ndarray): np.array([x1, y1, x2, y2])\n        box2 (np.ndarray): np.array([x1, y1, x2, y2])\n    \"\"\"", "\n", "left_top", "=", "np", ".", "maximum", "(", "box1", "[", ":", "2", "]", ",", "box2", "[", ":", "2", "]", ")", "\n", "right_bottom", "=", "np", ".", "minimum", "(", "box1", "[", "2", ":", "]", ",", "box2", "[", "2", ":", "]", ")", "\n", "width_height", "=", "(", "right_bottom", "-", "left_top", ")", ".", "clip", "(", "min", "=", "0", ")", "\n", "return", "width_height", "[", "0", "]", "*", "width_height", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_bbox_iou": [[127, 135], ["numpy.array", "numpy.array", "utils.calculate_area", "utils.calculate_area", "utils.calculate_intersection_area", "pred1.bbox.to_voc_bbox", "pred2.bbox.to_voc_bbox"], "function", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_intersection_area", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["", "def", "calculate_bbox_iou", "(", "pred1", ":", "ObjectPrediction", ",", "pred2", ":", "ObjectPrediction", ")", "->", "float", ":", "\n", "    ", "\"\"\"Returns the ratio of intersection area to the union\"\"\"", "\n", "box1", "=", "np", ".", "array", "(", "pred1", ".", "bbox", ".", "to_voc_bbox", "(", ")", ")", "\n", "box2", "=", "np", ".", "array", "(", "pred2", ".", "bbox", ".", "to_voc_bbox", "(", ")", ")", "\n", "area1", "=", "calculate_area", "(", "box1", ")", "\n", "area2", "=", "calculate_area", "(", "box2", ")", "\n", "intersect", "=", "calculate_intersection_area", "(", "box1", ",", "box2", ")", "\n", "return", "intersect", "/", "(", "area1", "+", "area2", "-", "intersect", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_bbox_ios": [[137, 146], ["numpy.array", "numpy.array", "utils.calculate_area", "utils.calculate_area", "utils.calculate_intersection_area", "numpy.minimum", "pred1.bbox.to_voc_bbox", "pred2.bbox.to_voc_bbox"], "function", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_intersection_area", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["", "def", "calculate_bbox_ios", "(", "pred1", ":", "ObjectPrediction", ",", "pred2", ":", "ObjectPrediction", ")", "->", "float", ":", "\n", "    ", "\"\"\"Returns the ratio of intersection area to the smaller box's area\"\"\"", "\n", "box1", "=", "np", ".", "array", "(", "pred1", ".", "bbox", ".", "to_voc_bbox", "(", ")", ")", "\n", "box2", "=", "np", ".", "array", "(", "pred2", ".", "bbox", ".", "to_voc_bbox", "(", ")", ")", "\n", "area1", "=", "calculate_area", "(", "box1", ")", "\n", "area2", "=", "calculate_area", "(", "box2", ")", "\n", "intersect", "=", "calculate_intersection_area", "(", "box1", ",", "box2", ")", "\n", "smaller_area", "=", "np", ".", "minimum", "(", "area1", ",", "area2", ")", "\n", "return", "intersect", "/", "smaller_area", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.has_match": [[148, 158], ["utils.calculate_bbox_iou", "ValueError", "utils.calculate_bbox_ios"], "function", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.calculate_bbox_iou", "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.calculate_bbox_ios"], ["", "def", "has_match", "(", "\n", "pred1", ":", "ObjectPrediction", ",", "pred2", ":", "ObjectPrediction", ",", "match_type", ":", "str", "=", "\"IOU\"", ",", "match_threshold", ":", "float", "=", "0.5", "\n", ")", "->", "bool", ":", "\n", "    ", "if", "match_type", "==", "\"IOU\"", ":", "\n", "        ", "threshold_condition", "=", "calculate_bbox_iou", "(", "pred1", ",", "pred2", ")", ">", "match_threshold", "\n", "", "elif", "match_type", "==", "\"IOS\"", ":", "\n", "        ", "threshold_condition", "=", "calculate_bbox_ios", "(", "pred1", ",", "pred2", ")", ">", "match_threshold", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "", "return", "threshold_condition", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_mask": [[160, 168], ["numpy.logical_or", "sahi.annotation.Mask"], "function", ["None"], ["", "def", "get_merged_mask", "(", "pred1", ":", "ObjectPrediction", ",", "pred2", ":", "ObjectPrediction", ")", "->", "Mask", ":", "\n", "    ", "mask1", "=", "pred1", ".", "mask", "\n", "mask2", "=", "pred2", ".", "mask", "\n", "union_mask", "=", "np", ".", "logical_or", "(", "mask1", ".", "bool_mask", ",", "mask2", ".", "bool_mask", ")", "\n", "return", "Mask", "(", "\n", "bool_mask", "=", "union_mask", ",", "\n", "full_shape", "=", "mask1", ".", "full_shape", ",", "\n", "shift_amount", "=", "mask1", ".", "shift_amount", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_score": [[171, 177], ["max"], "function", ["None"], ["", "def", "get_merged_score", "(", "\n", "pred1", ":", "ObjectPrediction", ",", "\n", "pred2", ":", "ObjectPrediction", ",", "\n", ")", "->", "float", ":", "\n", "    ", "scores", ":", "List", "[", "float", "]", "=", "[", "pred", ".", "score", ".", "value", "for", "pred", "in", "(", "pred1", ",", "pred2", ")", "]", "\n", "return", "max", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_bbox": [[179, 184], ["pred1.bbox.to_voc_bbox", "pred2.bbox.to_voc_bbox", "sahi.annotation.BoundingBox", "utils.calculate_box_union"], "function", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_box_union"], ["", "def", "get_merged_bbox", "(", "pred1", ":", "ObjectPrediction", ",", "pred2", ":", "ObjectPrediction", ")", "->", "BoundingBox", ":", "\n", "    ", "box1", ":", "List", "[", "int", "]", "=", "pred1", ".", "bbox", ".", "to_voc_bbox", "(", ")", "\n", "box2", ":", "List", "[", "int", "]", "=", "pred2", ".", "bbox", ".", "to_voc_bbox", "(", ")", "\n", "bbox", "=", "BoundingBox", "(", "box", "=", "calculate_box_union", "(", "box1", ",", "box2", ")", ")", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_category": [[186, 191], ["None"], "function", ["None"], ["", "def", "get_merged_category", "(", "pred1", ":", "ObjectPrediction", ",", "pred2", ":", "ObjectPrediction", ")", "->", "Category", ":", "\n", "    ", "if", "pred1", ".", "score", ".", "value", ">", "pred2", ".", "score", ".", "value", ":", "\n", "        ", "return", "pred1", ".", "category", "\n", "", "else", ":", "\n", "        ", "return", "pred2", ".", "category", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.merge_object_prediction_pair": [[193, 216], ["utils.get_merged_bbox", "utils.get_merged_score", "utils.get_merged_category", "sahi.prediction.ObjectPrediction", "utils.get_merged_mask", "merged_bbox.to_voc_bbox"], "function", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_bbox", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_score", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_category", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.get_merged_mask", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["", "", "def", "merge_object_prediction_pair", "(", "\n", "pred1", ":", "ObjectPrediction", ",", "\n", "pred2", ":", "ObjectPrediction", ",", "\n", ")", "->", "ObjectPrediction", ":", "\n", "    ", "shift_amount", "=", "pred1", ".", "bbox", ".", "shift_amount", "\n", "merged_bbox", ":", "BoundingBox", "=", "get_merged_bbox", "(", "pred1", ",", "pred2", ")", "\n", "merged_score", ":", "float", "=", "get_merged_score", "(", "pred1", ",", "pred2", ")", "\n", "merged_category", ":", "Category", "=", "get_merged_category", "(", "pred1", ",", "pred2", ")", "\n", "if", "pred1", ".", "mask", "and", "pred2", ".", "mask", ":", "\n", "        ", "merged_mask", ":", "Mask", "=", "get_merged_mask", "(", "pred1", ",", "pred2", ")", "\n", "bool_mask", "=", "merged_mask", ".", "bool_mask", "\n", "full_shape", "=", "merged_mask", ".", "full_shape", "\n", "", "else", ":", "\n", "        ", "bool_mask", "=", "None", "\n", "full_shape", "=", "None", "\n", "", "return", "ObjectPrediction", "(", "\n", "bbox", "=", "merged_bbox", ".", "to_voc_bbox", "(", ")", ",", "\n", "score", "=", "merged_score", ",", "\n", "category_id", "=", "merged_category", ".", "id", ",", "\n", "category_name", "=", "merged_category", ".", "name", ",", "\n", "bool_mask", "=", "bool_mask", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__init__": [[17, 31], ["ValueError"], "methods", ["None"], ["def", "batched_nms", "(", "predictions", ":", "torch", ".", "tensor", ",", "match_metric", ":", "str", "=", "\"IOU\"", ",", "match_threshold", ":", "float", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    Apply non-maximum suppression to avoid detecting too many\n    overlapping bounding boxes for a given object.\n    Args:\n        predictions: (tensor) The location preds for the image\n            along with the class predscores, Shape: [num_boxes,5].\n        match_metric: (str) IOU or IOS\n        match_threshold: (float) The overlap thresh for\n            match metric.\n    Returns:\n        A list of filtered indexes, Shape: [ ,]\n    \"\"\"", "\n", "scores", "=", "predictions", "[", ":", ",", "4", "]", ".", "squeeze", "(", ")", "\n", "category_ids", "=", "predictions", "[", ":", ",", "5", "]", ".", "squeeze", "(", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions._has_match": [[32, 36], ["combine.PostprocessPredictions.calculate_match", "combine.PostprocessPredictions.has_same_category_id"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.has_same_category_id"], ["keep_mask", "=", "torch", ".", "zeros_like", "(", "category_ids", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "for", "category_id", "in", "torch", ".", "unique", "(", "category_ids", ")", ":", "\n", "        ", "curr_indices", "=", "torch", ".", "where", "(", "category_ids", "==", "category_id", ")", "[", "0", "]", "\n", "curr_keep_indices", "=", "nms", "(", "predictions", "[", "curr_indices", "]", ",", "match_metric", ",", "match_threshold", ")", "\n", "keep_mask", "[", "curr_indices", "[", "curr_keep_indices", "]", "]", "=", "True", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.get_score_func": [[37, 41], ["None"], "methods", ["None"], ["", "keep_indices", "=", "torch", ".", "where", "(", "keep_mask", ")", "[", "0", "]", "\n", "# sort selected indices by their scores", "\n", "keep_indices", "=", "keep_indices", "[", "scores", "[", "keep_indices", "]", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "]", ".", "tolist", "(", ")", "\n", "return", "keep_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.has_same_category_id": [[42, 45], ["None"], "methods", ["None"], ["\n", "", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "nms", "(", "\n", "predictions", ":", "torch", ".", "tensor", ",", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.calculate_bbox_iou": [[46, 55], ["numpy.array", "numpy.array", "sahi.postprocess.utils.calculate_area", "sahi.postprocess.utils.calculate_area", "sahi.postprocess.utils.calculate_intersection_area", "pred1.bbox.to_voc_bbox", "pred2.bbox.to_voc_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_intersection_area", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.calculate_bbox_ios": [[56, 66], ["numpy.array", "numpy.array", "sahi.postprocess.utils.calculate_area", "sahi.postprocess.utils.calculate_area", "sahi.postprocess.utils.calculate_intersection_area", "numpy.minimum", "pred1.bbox.to_voc_bbox", "pred2.bbox.to_voc_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_area", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_intersection_area", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["\n", "# we extract coordinates for every", "\n", "# prediction box present in P", "\n", "x1", "=", "predictions", "[", ":", ",", "0", "]", "\n", "y1", "=", "predictions", "[", ":", ",", "1", "]", "\n", "x2", "=", "predictions", "[", ":", ",", "2", "]", "\n", "y2", "=", "predictions", "[", ":", ",", "3", "]", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions.__call__": [[67, 69], ["NotImplementedError"], "methods", ["None"], ["\n", "# we extract the confidence scores as well", "\n", "scores", "=", "predictions", "[", ":", ",", "4", "]", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.NMSPostprocess.__call__": [[72, 95], ["copy.deepcopy", "len", "source_object_predictions.sort", "selected_object_predictions.append", "combine.NMSPostprocess._has_match", "new_source_object_predictions.append"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions._has_match"], ["areas", "=", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "\n", "\n", "# sort the prediction boxes in P", "\n", "# according to their confidence scores", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "\n", "\n", "# initialise an empty list for", "\n", "# filtered prediction boxes", "\n", "keep", "=", "[", "]", "\n", "\n", "while", "len", "(", "order", ")", ">", "0", ":", "\n", "# extract the index of the", "\n", "# prediction with highest score", "\n", "# we call this prediction S", "\n", "        ", "idx", "=", "order", "[", "-", "1", "]", "\n", "\n", "# push S in filtered predictions list", "\n", "keep", ".", "append", "(", "idx", ".", "tolist", "(", ")", ")", "\n", "\n", "# remove S from P", "\n", "order", "=", "order", "[", ":", "-", "1", "]", "\n", "\n", "# sanity check", "\n", "if", "len", "(", "order", ")", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess.__call__": [[98, 123], ["copy.deepcopy", "len", "source_object_predictions.sort", "enumerate", "selected_object_predictions.append", "combine.UnionMergePostprocess._has_match", "combine.UnionMergePostprocess._merge_object_prediction_pair", "new_source_object_predictions.append"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.ObjectAnnotation.deepcopy", "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.PostprocessPredictions._has_match", "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._merge_object_prediction_pair"], ["# select coordinates of BBoxes according to", "\n", "# the indices in order", "\n", "", "xx1", "=", "torch", ".", "index_select", "(", "x1", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "xx2", "=", "torch", ".", "index_select", "(", "x2", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "yy1", "=", "torch", ".", "index_select", "(", "y1", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "yy2", "=", "torch", ".", "index_select", "(", "y2", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "\n", "# find the coordinates of the intersection boxes", "\n", "xx1", "=", "torch", ".", "max", "(", "xx1", ",", "x1", "[", "idx", "]", ")", "\n", "yy1", "=", "torch", ".", "max", "(", "yy1", ",", "y1", "[", "idx", "]", ")", "\n", "xx2", "=", "torch", ".", "min", "(", "xx2", ",", "x2", "[", "idx", "]", ")", "\n", "yy2", "=", "torch", ".", "min", "(", "yy2", ",", "y2", "[", "idx", "]", ")", "\n", "\n", "# find height and width of the intersection boxes", "\n", "w", "=", "xx2", "-", "xx1", "\n", "h", "=", "yy2", "-", "yy1", "\n", "\n", "# take max with 0.0 to avoid negative w and h", "\n", "# due to non-overlapping boxes", "\n", "w", "=", "torch", ".", "clamp", "(", "w", ",", "min", "=", "0.0", ")", "\n", "h", "=", "torch", ".", "clamp", "(", "h", ",", "min", "=", "0.0", ")", "\n", "\n", "# find the intersection area", "\n", "inter", "=", "w", "*", "h", "\n", "\n", "# find the areas of BBoxes according the indices in order", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._merge_object_prediction_pair": [[124, 148], ["combine.UnionMergePostprocess._get_merged_bbox", "combine.UnionMergePostprocess._get_merged_score", "combine.UnionMergePostprocess._get_merged_category", "sahi.prediction.ObjectPrediction", "combine.UnionMergePostprocess._get_merged_mask", "merged_bbox.to_voc_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_bbox", "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_score", "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_category", "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_mask", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["rem_areas", "=", "torch", ".", "index_select", "(", "areas", ",", "dim", "=", "0", ",", "index", "=", "order", ")", "\n", "\n", "if", "match_metric", "==", "\"IOU\"", ":", "\n", "# find the union of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "union", "=", "(", "rem_areas", "-", "inter", ")", "+", "areas", "[", "idx", "]", "\n", "# find the IoU of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "union", "\n", "\n", "", "elif", "match_metric", "==", "\"IOS\"", ":", "\n", "# find the smaller area of every prediction T in P", "\n", "# with the prediction S", "\n", "# Note that areas[idx] represents area of S", "\n", "            ", "smaller", "=", "torch", ".", "min", "(", "rem_areas", ",", "areas", "[", "idx", "]", ")", "\n", "# find the IoU of every prediction in P with S", "\n", "match_metric_value", "=", "inter", "/", "smaller", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n", "# keep the boxes with IoU less than thresh_iou", "\n", "", "mask", "=", "match_metric_value", "<", "match_threshold", "\n", "order", "=", "order", "[", "mask", "]", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_category": [[150, 156], ["None"], "methods", ["None"], ["", "@", "check_requirements", "(", "[", "\"torch\"", "]", ")", "\n", "def", "batched_greedy_nmm", "(", "\n", "object_predictions_as_tensor", ":", "torch", ".", "tensor", ",", "\n", "match_metric", ":", "str", "=", "\"IOU\"", ",", "\n", "match_threshold", ":", "float", "=", "0.5", ",", "\n", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_bbox": [[157, 163], ["pred1.bbox.to_voc_bbox", "pred2.bbox.to_voc_bbox", "sahi.annotation.BoundingBox", "sahi.postprocess.utils.calculate_box_union"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.calculate_box_union"], []], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_score": [[164, 171], ["max"], "methods", ["None"], ["\n", "category_ids", "=", "object_predictions_as_tensor", "[", ":", ",", "5", "]", ".", "squeeze", "(", ")", "\n", "keep_to_merge_list", "=", "{", "}", "\n", "for", "category_id", "in", "torch", ".", "unique", "(", "category_ids", ")", ":", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.legacy.combine.UnionMergePostprocess._get_merged_mask": [[172, 181], ["numpy.logical_or", "sahi.annotation.Mask"], "methods", ["None"], ["        ", "curr_indices", "=", "torch", ".", "where", "(", "category_ids", "==", "category_id", ")", "[", "0", "]", "\n", "curr_keep_to_merge_list", "=", "greedy_nmm", "(", "object_predictions_as_tensor", "[", "curr_indices", "]", ",", "match_metric", ",", "match_threshold", ")", "\n", "curr_indices_list", "=", "curr_indices", ".", "tolist", "(", ")", "\n", "for", "curr_keep", ",", "curr_merge_list", "in", "curr_keep_to_merge_list", ".", "items", "(", ")", ":", "\n", "            ", "keep", "=", "curr_indices_list", "[", "curr_keep", "]", "\n", "merge_list", "=", "[", "curr_indices_list", "[", "curr_merge_ind", "]", "for", "curr_merge_ind", "in", "curr_merge_list", "]", "\n", "keep_to_merge_list", "[", "keep", "]", "=", "merge_list", "\n", "", "", "return", "keep_to_merge_list", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_prediction_score": [[18, 25], ["PredictionScore", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "numpy.array", "type", "PredictionScore.is_greater_than_threshold", "PredictionScore.is_greater_than_threshold"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionScore.is_greater_than_threshold", "home.repos.pwc.inspect_result.obss_sahi.sahi.prediction.PredictionScore.is_greater_than_threshold"], ["    ", "def", "test_prediction_score", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "prediction", "import", "PredictionScore", "\n", "\n", "prediction_score", "=", "PredictionScore", "(", "np", ".", "array", "(", "0.6", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "prediction_score", ".", "value", ")", ",", "float", ")", "\n", "self", ".", "assertEqual", "(", "prediction_score", ".", "is_greater_than_threshold", "(", "0.5", ")", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "prediction_score", ".", "is_greater_than_threshold", "(", "0.7", ")", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_object_prediction": [[26, 28], ["None"], "methods", ["None"], ["", "def", "test_object_prediction", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "prediction", "import", "ObjectPrediction", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_get_prediction_mmdet": [[29, 74], ["download_mmdet_yolox_tiny_model", "MmdetDetectionModel", "MmdetDetectionModel.load_model", "sahi.utils.cv.read_image", "get_prediction", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_yolox_tiny_model", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction"], ["", "def", "test_get_prediction_mmdet", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "MmdetDetectionModel", "\n", "from", "sahi", ".", "predict", "import", "get_prediction", "\n", "from", "sahi", ".", "utils", ".", "mmdet", "import", "MmdetTestConstants", ",", "download_mmdet_yolox_tiny_model", "\n", "\n", "# init model", "\n", "download_mmdet_yolox_tiny_model", "(", ")", "\n", "\n", "mmdet_detection_model", "=", "MmdetDetectionModel", "(", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_MODEL_PATH", ",", "\n", "config_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "mmdet_detection_model", ".", "load_model", "(", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# get full sized prediction", "\n", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image", ",", "detection_model", "=", "mmdet_detection_model", ",", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "full_shape", "=", "None", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "2", ")", "\n", "num_person", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"person\"", ":", "\n", "                ", "num_person", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_person", ",", "0", ")", "\n", "num_truck", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"truck\"", ":", "\n", "                ", "num_truck", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_truck", ",", "0", ")", "\n", "num_car", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"car\"", ":", "\n", "                ", "num_car", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_car", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_get_prediction_yolov5": [[75, 120], ["download_yolov5n_model", "Yolov5DetectionModel", "Yolov5DetectionModel.load_model", "sahi.utils.cv.read_image", "get_prediction", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction"], ["", "def", "test_get_prediction_yolov5", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "Yolov5DetectionModel", "\n", "from", "sahi", ".", "predict", "import", "get_prediction", "\n", "from", "sahi", ".", "utils", ".", "yolov5", "import", "Yolov5TestConstants", ",", "download_yolov5n_model", "\n", "\n", "# init model", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "yolov5_detection_model", "=", "Yolov5DetectionModel", "(", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "yolov5_detection_model", ".", "load_model", "(", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# get full sized prediction", "\n", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image", ",", "detection_model", "=", "yolov5_detection_model", ",", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "full_shape", "=", "None", ",", "postprocess", "=", "None", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "2", ")", "\n", "num_person", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"person\"", ":", "\n", "                ", "num_person", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_person", ",", "0", ")", "\n", "num_truck", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"truck\"", ":", "\n", "                ", "num_truck", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_truck", ",", "0", ")", "\n", "num_car", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"car\"", ":", "\n", "                ", "num_car", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_car", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_get_prediction_automodel_yolov5": [[121, 167], ["download_yolov5n_model", "AutoDetectionModel.from_pretrained", "AutoDetectionModel.from_pretrained.load_model", "sahi.utils.cv.read_image", "get_prediction", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model", "home.repos.pwc.inspect_result.obss_sahi.sahi.auto_model.AutoDetectionModel.from_pretrained", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction"], ["", "def", "test_get_prediction_automodel_yolov5", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "auto_model", "import", "AutoDetectionModel", "\n", "from", "sahi", ".", "predict", "import", "get_prediction", "\n", "from", "sahi", ".", "utils", ".", "yolov5", "import", "Yolov5TestConstants", ",", "download_yolov5n_model", "\n", "\n", "# init model", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "yolov5_detection_model", "=", "AutoDetectionModel", ".", "from_pretrained", "(", "\n", "model_type", "=", "\"yolov5\"", ",", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "yolov5_detection_model", ".", "load_model", "(", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# get full sized prediction", "\n", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image", ",", "detection_model", "=", "yolov5_detection_model", ",", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "full_shape", "=", "None", ",", "postprocess", "=", "None", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "2", ")", "\n", "num_person", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"person\"", ":", "\n", "                ", "num_person", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_person", ",", "0", ")", "\n", "num_truck", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"truck\"", ":", "\n", "                ", "num_truck", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_truck", ",", "0", ")", "\n", "num_car", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"car\"", ":", "\n", "                ", "num_car", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_car", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_get_sliced_prediction_mmdet": [[168, 232], ["download_mmdet_yolox_tiny_model", "MmdetDetectionModel", "MmdetDetectionModel.load_model", "get_sliced_prediction", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_yolox_tiny_model", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction"], ["", "def", "test_get_sliced_prediction_mmdet", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "MmdetDetectionModel", "\n", "from", "sahi", ".", "predict", "import", "get_sliced_prediction", "\n", "from", "sahi", ".", "utils", ".", "mmdet", "import", "MmdetTestConstants", ",", "download_mmdet_yolox_tiny_model", "\n", "\n", "# init model", "\n", "download_mmdet_yolox_tiny_model", "(", ")", "\n", "\n", "mmdet_detection_model", "=", "MmdetDetectionModel", "(", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_MODEL_PATH", ",", "\n", "config_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "mmdet_detection_model", ".", "load_model", "(", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "\n", "slice_height", "=", "512", "\n", "slice_width", "=", "512", "\n", "overlap_height_ratio", "=", "0.1", "\n", "overlap_width_ratio", "=", "0.2", "\n", "postprocess_type", "=", "\"GREEDYNMM\"", "\n", "match_metric", "=", "\"IOS\"", "\n", "match_threshold", "=", "0.5", "\n", "class_agnostic", "=", "True", "\n", "\n", "# get sliced prediction", "\n", "prediction_result", "=", "get_sliced_prediction", "(", "\n", "image", "=", "image_path", ",", "\n", "detection_model", "=", "mmdet_detection_model", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "perform_standard_pred", "=", "False", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "14", ")", "\n", "num_person", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"person\"", ":", "\n", "                ", "num_person", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_person", ",", "0", ")", "\n", "num_truck", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"truck\"", ":", "\n", "                ", "num_truck", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_truck", ",", "0", ")", "\n", "num_car", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"car\"", ":", "\n", "                ", "num_car", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_car", ",", "14", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_get_sliced_prediction_yolov5": [[233, 296], ["download_yolov5n_model", "Yolov5DetectionModel", "Yolov5DetectionModel.load_model", "get_sliced_prediction", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "test_predict.TestPredict.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction"], ["", "def", "test_get_sliced_prediction_yolov5", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "Yolov5DetectionModel", "\n", "from", "sahi", ".", "predict", "import", "get_sliced_prediction", "\n", "from", "sahi", ".", "utils", ".", "yolov5", "import", "Yolov5TestConstants", ",", "download_yolov5n_model", "\n", "\n", "# init model", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "yolov5_detection_model", "=", "Yolov5DetectionModel", "(", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "yolov5_detection_model", ".", "load_model", "(", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "\n", "slice_height", "=", "512", "\n", "slice_width", "=", "512", "\n", "overlap_height_ratio", "=", "0.1", "\n", "overlap_width_ratio", "=", "0.2", "\n", "postprocess_type", "=", "\"GREEDYNMM\"", "\n", "match_metric", "=", "\"IOS\"", "\n", "match_threshold", "=", "0.5", "\n", "class_agnostic", "=", "True", "\n", "\n", "# get sliced prediction", "\n", "prediction_result", "=", "get_sliced_prediction", "(", "\n", "image", "=", "image_path", ",", "\n", "detection_model", "=", "yolov5_detection_model", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "perform_standard_pred", "=", "False", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "10", ")", "\n", "num_person", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"person\"", ":", "\n", "                ", "num_person", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_person", ",", "0", ")", "\n", "num_truck", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"truck\"", ":", "\n", "                ", "num_truck", "+=", "2", "\n", "", "", "self", ".", "assertEqual", "(", "num_truck", ",", "0", ")", "\n", "num_car", "=", "0", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "if", "object_prediction", ".", "category", ".", "name", "==", "\"car\"", ":", "\n", "                ", "num_car", "+=", "1", "\n", "", "", "self", ".", "assertEqual", "(", "num_car", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_coco_json_prediction": [[297, 383], ["download_mmdet_yolox_tiny_model", "os.path.isdir", "predict", "download_yolov5n_model", "os.path.isdir", "predict", "shutil.rmtree", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_yolox_tiny_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.predict", "home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.predict"], ["", "def", "test_coco_json_prediction", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "predict", "import", "predict", "\n", "from", "sahi", ".", "utils", ".", "mmdet", "import", "MmdetTestConstants", ",", "download_mmdet_yolox_tiny_model", "\n", "from", "sahi", ".", "utils", ".", "yolov5", "import", "Yolov5TestConstants", ",", "download_yolov5n_model", "\n", "\n", "# init model", "\n", "download_mmdet_yolox_tiny_model", "(", ")", "\n", "\n", "postprocess_type", "=", "\"GREEDYNMM\"", "\n", "match_metric", "=", "\"IOS\"", "\n", "match_threshold", "=", "0.5", "\n", "class_agnostic", "=", "True", "\n", "\n", "# prepare paths", "\n", "dataset_json_path", "=", "\"tests/data/coco_utils/terrain_all_coco.json\"", "\n", "source", "=", "\"tests/data/coco_utils/\"", "\n", "project_dir", "=", "\"tests/data/predict_result\"", "\n", "\n", "# get sliced prediction", "\n", "if", "os", ".", "path", ".", "isdir", "(", "project_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "project_dir", ",", "ignore_errors", "=", "True", ")", "\n", "", "predict", "(", "\n", "model_type", "=", "\"mmdet\"", ",", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_MODEL_PATH", ",", "\n", "model_config_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_CONFIG_PATH", ",", "\n", "model_confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "model_device", "=", "MODEL_DEVICE", ",", "\n", "model_category_mapping", "=", "None", ",", "\n", "model_category_remapping", "=", "None", ",", "\n", "source", "=", "source", ",", "\n", "no_sliced_prediction", "=", "False", ",", "\n", "no_standard_prediction", "=", "True", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "overlap_height_ratio", "=", "0.2", ",", "\n", "overlap_width_ratio", "=", "0.2", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", "novisual", "=", "True", ",", "\n", "export_pickle", "=", "False", ",", "\n", "export_crop", "=", "False", ",", "\n", "dataset_json_path", "=", "dataset_json_path", ",", "\n", "project", "=", "project_dir", ",", "\n", "name", "=", "\"exp\"", ",", "\n", "verbose", "=", "1", ",", "\n", ")", "\n", "\n", "# init model", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "# prepare paths", "\n", "dataset_json_path", "=", "\"tests/data/coco_utils/terrain_all_coco.json\"", "\n", "source", "=", "\"tests/data/coco_utils/\"", "\n", "project_dir", "=", "\"tests/data/predict_result\"", "\n", "\n", "# get sliced prediction", "\n", "if", "os", ".", "path", ".", "isdir", "(", "project_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "project_dir", ",", "ignore_errors", "=", "True", ")", "\n", "", "predict", "(", "\n", "model_type", "=", "\"yolov5\"", ",", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "model_config_path", "=", "None", ",", "\n", "model_confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "model_device", "=", "MODEL_DEVICE", ",", "\n", "model_category_mapping", "=", "None", ",", "\n", "model_category_remapping", "=", "None", ",", "\n", "source", "=", "source", ",", "\n", "no_sliced_prediction", "=", "False", ",", "\n", "no_standard_prediction", "=", "True", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "overlap_height_ratio", "=", "0.2", ",", "\n", "overlap_width_ratio", "=", "0.2", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", "novisual", "=", "True", ",", "\n", "export_pickle", "=", "False", ",", "\n", "export_crop", "=", "False", ",", "\n", "dataset_json_path", "=", "dataset_json_path", ",", "\n", "project", "=", "project_dir", ",", "\n", "name", "=", "\"exp\"", ",", "\n", "verbose", "=", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_predict.TestPredict.test_video_prediction": [[385, 509], ["download_yolov5n_model", "os.path.isdir", "predict", "os.path.isdir", "predict", "os.path.isdir", "predict", "path.exists", "download_from_url", "shutil.rmtree", "shutil.rmtree", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.predict", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.predict", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.predict", "home.repos.pwc.inspect_result.obss_sahi.utils.file.download_from_url"], ["", "def", "test_video_prediction", "(", "self", ")", ":", "\n", "        ", "from", "os", "import", "path", "\n", "\n", "from", "sahi", ".", "predict", "import", "predict", "\n", "from", "sahi", ".", "utils", ".", "file", "import", "download_from_url", "\n", "from", "sahi", ".", "utils", ".", "yolov5", "import", "Yolov5TestConstants", ",", "download_yolov5n_model", "\n", "\n", "# download video file", "\n", "source_url", "=", "\"https://github.com/obss/sahi/releases/download/0.9.2/test.mp4\"", "\n", "destination_path", "=", "\"tests/data/test.mp4\"", "\n", "if", "not", "path", ".", "exists", "(", "destination_path", ")", ":", "\n", "            ", "download_from_url", "(", "source_url", ",", "destination_path", ")", "\n", "\n", "# init model", "\n", "", "download_yolov5n_model", "(", ")", "\n", "\n", "postprocess_type", "=", "\"GREEDYNMM\"", "\n", "match_metric", "=", "\"IOS\"", "\n", "match_threshold", "=", "0.5", "\n", "image_size", "=", "320", "\n", "class_agnostic", "=", "True", "\n", "\n", "# prepare paths", "\n", "source", "=", "destination_path", "\n", "project_dir", "=", "\"tests/data/predict_result\"", "\n", "\n", "# get sliced inference from video input without exporting visual", "\n", "if", "os", ".", "path", ".", "isdir", "(", "project_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "project_dir", ",", "ignore_errors", "=", "True", ")", "\n", "", "predict", "(", "\n", "model_type", "=", "\"yolov5\"", ",", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "model_config_path", "=", "None", ",", "\n", "model_confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "model_device", "=", "MODEL_DEVICE", ",", "\n", "model_category_mapping", "=", "None", ",", "\n", "model_category_remapping", "=", "None", ",", "\n", "source", "=", "source", ",", "\n", "no_sliced_prediction", "=", "False", ",", "\n", "no_standard_prediction", "=", "True", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "image_size", "=", "image_size", ",", "\n", "overlap_height_ratio", "=", "0.2", ",", "\n", "overlap_width_ratio", "=", "0.2", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", "novisual", "=", "True", ",", "\n", "export_pickle", "=", "False", ",", "\n", "export_crop", "=", "False", ",", "\n", "dataset_json_path", "=", "None", ",", "\n", "project", "=", "project_dir", ",", "\n", "name", "=", "\"exp\"", ",", "\n", "verbose", "=", "1", ",", "\n", ")", "\n", "\n", "postprocess_type", "=", "\"GREEDYNMM\"", "\n", "match_metric", "=", "\"IOS\"", "\n", "match_threshold", "=", "0.5", "\n", "image_size", "=", "320", "\n", "class_agnostic", "=", "True", "\n", "\n", "# get standard inference from video input without exporting visual", "\n", "if", "os", ".", "path", ".", "isdir", "(", "project_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "project_dir", ",", "ignore_errors", "=", "True", ")", "\n", "", "predict", "(", "\n", "model_type", "=", "\"yolov5\"", ",", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "model_config_path", "=", "None", ",", "\n", "model_confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "model_device", "=", "MODEL_DEVICE", ",", "\n", "model_category_mapping", "=", "None", ",", "\n", "model_category_remapping", "=", "None", ",", "\n", "source", "=", "source", ",", "\n", "no_sliced_prediction", "=", "True", ",", "\n", "no_standard_prediction", "=", "False", ",", "\n", "image_size", "=", "image_size", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", "novisual", "=", "True", ",", "\n", "export_pickle", "=", "False", ",", "\n", "export_crop", "=", "False", ",", "\n", "dataset_json_path", "=", "None", ",", "\n", "project", "=", "project_dir", ",", "\n", "name", "=", "\"exp\"", ",", "\n", "verbose", "=", "1", ",", "\n", ")", "\n", "\n", "# get standard inference from video input and export visual", "\n", "postprocess_type", "=", "\"GREEDYNMM\"", "\n", "match_metric", "=", "\"IOS\"", "\n", "match_threshold", "=", "0.5", "\n", "image_size", "=", "320", "\n", "class_agnostic", "=", "True", "\n", "\n", "# get full sized prediction", "\n", "if", "os", ".", "path", ".", "isdir", "(", "project_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "project_dir", ",", "ignore_errors", "=", "True", ")", "\n", "", "predict", "(", "\n", "model_type", "=", "\"yolov5\"", ",", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "model_config_path", "=", "None", ",", "\n", "model_confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "model_device", "=", "MODEL_DEVICE", ",", "\n", "model_category_mapping", "=", "None", ",", "\n", "model_category_remapping", "=", "None", ",", "\n", "source", "=", "source", ",", "\n", "no_sliced_prediction", "=", "True", ",", "\n", "no_standard_prediction", "=", "False", ",", "\n", "image_size", "=", "image_size", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", "export_pickle", "=", "False", ",", "\n", "export_crop", "=", "False", ",", "\n", "dataset_json_path", "=", "None", ",", "\n", "project", "=", "project_dir", ",", "\n", "name", "=", "\"exp\"", ",", "\n", "verbose", "=", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_shapelyutils.TestShapelyUtils.test_get_shapely_box": [[10, 17], ["sahi.utils.shapely.get_shapely_box", "test_shapelyutils.TestShapelyUtils.assertListEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertTupleEqual", "sahi.utils.shapely.get_shapely_box.exterior.coords.xy[].tolist"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_box", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["    ", "def", "test_get_shapely_box", "(", "self", ")", ":", "\n", "        ", "x", ",", "y", ",", "width", ",", "height", "=", "1", ",", "1", ",", "256", ",", "256", "\n", "shapely_box", "=", "get_shapely_box", "(", "x", ",", "y", ",", "width", ",", "height", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "shapely_box", ".", "exterior", ".", "coords", ".", "xy", "[", "0", "]", ".", "tolist", "(", ")", ",", "[", "257.0", ",", "257.0", ",", "1.0", ",", "1.0", ",", "257.0", "]", ")", "\n", "self", ".", "assertEqual", "(", "shapely_box", ".", "area", ",", "65536", ")", "\n", "self", ".", "assertTupleEqual", "(", "shapely_box", ".", "bounds", ",", "(", "1", ",", "1", ",", "257", ",", "257", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_shapelyutils.TestShapelyUtils.test_get_shapely_multipolygon": [[18, 28], ["sahi.utils.shapely.get_shapely_multipolygon", "test_shapelyutils.TestShapelyUtils.assertListEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertTupleEqual", "sahi.utils.shapely.get_shapely_multipolygon.geoms[].exterior.coords.xy[].tolist"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_multipolygon", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "test_get_shapely_multipolygon", "(", "self", ")", ":", "\n", "        ", "coco_segmentation", "=", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", "\n", "shapely_multipolygon", "=", "get_shapely_multipolygon", "(", "coco_segmentation", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "shapely_multipolygon", ".", "geoms", "[", "0", "]", ".", "exterior", ".", "coords", ".", "xy", "[", "0", "]", ".", "tolist", "(", ")", ",", "\n", "[", "1.0", ",", "325", ",", "250", ",", "5", ",", "1", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "shapely_multipolygon", ".", "area", ",", "41177.5", ")", "\n", "self", ".", "assertTupleEqual", "(", "shapely_multipolygon", ".", "bounds", ",", "(", "1", ",", "1", ",", "325", ",", "200", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_shapelyutils.TestShapelyUtils.test_shapely_annotation": [[29, 118], ["sahi.utils.shapely.get_shapely_multipolygon", "sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_coco_segmentation", "test_shapelyutils.TestShapelyUtils.assertEqual", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_opencv_contours", "test_shapelyutils.TestShapelyUtils.assertEqual", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_coco_bbox", "test_shapelyutils.TestShapelyUtils.assertEqual", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_voc_bbox", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "sahi.utils.shapely.get_shapely_box", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_coco_segmentation", "test_shapelyutils.TestShapelyUtils.assertEqual", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_opencv_contours", "test_shapelyutils.TestShapelyUtils.assertEqual", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_coco_bbox", "test_shapelyutils.TestShapelyUtils.assertEqual", "sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox.to_voc_bbox", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "int", "sahi.utils.shapely.MultiPolygon", "sahi.utils.shapely.MultiPolygon"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_multipolygon", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_opencv_contours", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_box", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_opencv_contours", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["", "def", "test_shapely_annotation", "(", "self", ")", ":", "\n", "# init shapely_annotation from coco segmentation", "\n", "        ", "segmentation", "=", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", "\n", "shapely_multipolygon", "=", "get_shapely_multipolygon", "(", "segmentation", ")", "\n", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_segmentation", "(", "segmentation", ")", "\n", "\n", "# test conversion methods", "\n", "coco_segmentation", "=", "shapely_annotation", ".", "to_coco_segmentation", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco_segmentation", ",", "\n", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", ",", "\n", ")", "\n", "opencv_contours", "=", "shapely_annotation", ".", "to_opencv_contours", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "opencv_contours", ",", "\n", "[", "\n", "[", "\n", "[", "[", "1", ",", "1", "]", "]", ",", "\n", "[", "[", "325", ",", "125", "]", "]", ",", "\n", "[", "[", "250", ",", "200", "]", "]", ",", "\n", "[", "[", "5", ",", "200", "]", "]", ",", "\n", "[", "[", "1", ",", "1", "]", "]", ",", "\n", "]", "\n", "]", ",", "\n", ")", "\n", "coco_bbox", "=", "shapely_annotation", ".", "to_coco_bbox", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco_bbox", ",", "\n", "[", "1", ",", "1", ",", "324", ",", "199", "]", ",", "\n", ")", "\n", "voc_bbox", "=", "shapely_annotation", ".", "to_voc_bbox", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "voc_bbox", ",", "\n", "[", "1", ",", "1", ",", "325", ",", "200", "]", ",", "\n", ")", "\n", "\n", "# test properties", "\n", "self", ".", "assertEqual", "(", "\n", "shapely_annotation", ".", "area", ",", "\n", "int", "(", "shapely_multipolygon", ".", "area", ")", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "shapely_annotation", ".", "multipolygon", ",", "\n", "shapely_multipolygon", ",", "\n", ")", "\n", "\n", "# init shapely_annotation from coco bbox", "\n", "coco_bbox", "=", "[", "1", ",", "1", ",", "100", ",", "100", "]", "\n", "shapely_polygon", "=", "get_shapely_box", "(", "x", "=", "coco_bbox", "[", "0", "]", ",", "y", "=", "coco_bbox", "[", "1", "]", ",", "width", "=", "coco_bbox", "[", "2", "]", ",", "height", "=", "coco_bbox", "[", "3", "]", ")", "\n", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_bbox", "(", "coco_bbox", ")", "\n", "\n", "# test conversion methods", "\n", "coco_segmentation", "=", "shapely_annotation", ".", "to_coco_segmentation", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco_segmentation", ",", "\n", "[", "[", "101", ",", "1", ",", "101", ",", "101", ",", "1", ",", "101", ",", "1", ",", "1", "]", "]", ",", "\n", ")", "\n", "opencv_contours", "=", "shapely_annotation", ".", "to_opencv_contours", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "opencv_contours", ",", "\n", "[", "\n", "[", "\n", "[", "[", "101", ",", "1", "]", "]", ",", "\n", "[", "[", "101", ",", "101", "]", "]", ",", "\n", "[", "[", "1", ",", "101", "]", "]", ",", "\n", "[", "[", "1", ",", "1", "]", "]", ",", "\n", "[", "[", "101", ",", "1", "]", "]", ",", "\n", "]", "\n", "]", ",", "\n", ")", "\n", "coco_bbox", "=", "shapely_annotation", ".", "to_coco_bbox", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco_bbox", ",", "\n", "[", "1", ",", "1", ",", "100", ",", "100", "]", ",", "\n", ")", "\n", "voc_bbox", "=", "shapely_annotation", ".", "to_voc_bbox", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "voc_bbox", ",", "\n", "[", "1", ",", "1", ",", "101", ",", "101", "]", ",", "\n", ")", "\n", "\n", "# test properties", "\n", "self", ".", "assertEqual", "(", "\n", "shapely_annotation", ".", "area", ",", "\n", "MultiPolygon", "(", "[", "shapely_polygon", "]", ")", ".", "area", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "shapely_annotation", ".", "multipolygon", ",", "\n", "MultiPolygon", "(", "[", "shapely_polygon", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_shapelyutils.TestShapelyUtils.test_get_intersection": [[120, 156], ["sahi.utils.shapely.get_shapely_box", "sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation.get_intersection", "range", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "ShapelyAnnotation.from_coco_segmentation.get_intersection.to_list", "len", "range", "ShapelyAnnotation.from_coco_segmentation.get_intersection.to_coco_segmentation", "ShapelyAnnotation.from_coco_segmentation.get_intersection.to_coco_bbox", "ShapelyAnnotation.from_coco_segmentation.get_intersection.to_voc_bbox", "test_shapelyutils.TestShapelyUtils.assertEqual", "int", "int"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_box", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.get_intersection", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_list", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["", "def", "test_get_intersection", "(", "self", ")", ":", "\n", "        ", "x", ",", "y", ",", "width", ",", "height", "=", "1", ",", "1", ",", "256", ",", "256", "\n", "shapely_box", "=", "get_shapely_box", "(", "x", ",", "y", ",", "width", ",", "height", ")", "\n", "\n", "coco_segmentation", "=", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", "\n", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_segmentation", "(", "coco_segmentation", ")", "\n", "\n", "intersection_shapely_annotation", "=", "shapely_annotation", ".", "get_intersection", "(", "shapely_box", ")", "\n", "\n", "test_list", "=", "intersection_shapely_annotation", ".", "to_list", "(", ")", "[", "0", "]", "\n", "true_list", "=", "[", "(", "0", ",", "0", ")", ",", "(", "4", ",", "199", ")", ",", "(", "249", ",", "199", ")", ",", "(", "256", ",", "192", ")", ",", "(", "256", ",", "97", ")", ",", "(", "0", ",", "0", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "test_list", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "int", "(", "test_list", "[", "i", "]", "[", "j", "]", ")", ",", "int", "(", "true_list", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "\n", "", "", "self", ".", "assertEqual", "(", "\n", "intersection_shapely_annotation", ".", "to_coco_segmentation", "(", ")", ",", "\n", "[", "\n", "[", "\n", "0", ",", "\n", "0", ",", "\n", "4", ",", "\n", "199", ",", "\n", "249", ",", "\n", "199", ",", "\n", "256", ",", "\n", "192", ",", "\n", "256", ",", "\n", "97", ",", "\n", "]", "\n", "]", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "intersection_shapely_annotation", ".", "to_coco_bbox", "(", ")", ",", "[", "0", ",", "0", ",", "256", ",", "199", "]", ")", "\n", "\n", "self", ".", "assertEqual", "(", "intersection_shapely_annotation", ".", "to_voc_bbox", "(", ")", ",", "[", "0", ",", "0", ",", "256", ",", "199", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_shapelyutils.TestShapelyUtils.test_get_empty_intersection": [[157, 169], ["sahi.utils.shapely.get_shapely_box", "sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation.get_intersection", "test_shapelyutils.TestShapelyUtils.assertEqual", "test_shapelyutils.TestShapelyUtils.assertEqual", "ShapelyAnnotation.from_coco_segmentation.get_intersection.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.get_shapely_box", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.get_intersection", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "test_get_empty_intersection", "(", "self", ")", ":", "\n", "        ", "x", ",", "y", ",", "width", ",", "height", "=", "300", ",", "300", ",", "256", ",", "256", "\n", "shapely_box", "=", "get_shapely_box", "(", "x", ",", "y", ",", "width", ",", "height", ")", "\n", "\n", "coco_segmentation", "=", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", "\n", "shapely_annotation", "=", "ShapelyAnnotation", ".", "from_coco_segmentation", "(", "coco_segmentation", ")", "\n", "\n", "intersection_shapely_annotation", "=", "shapely_annotation", ".", "get_intersection", "(", "shapely_box", ")", "\n", "\n", "self", ".", "assertEqual", "(", "intersection_shapely_annotation", ".", "area", ",", "0", ")", "\n", "\n", "self", ".", "assertEqual", "(", "intersection_shapely_annotation", ".", "to_coco_bbox", "(", ")", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_annotation.TestAnnotation.test_bounding_box": [[8, 24], ["BoundingBox", "BoundingBox.get_expanded_box", "BoundingBox", "BoundingBox.get_shifted_box", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "BoundingBox.get_expanded_box.to_coco_bbox", "BoundingBox.get_expanded_box.to_voc_bbox", "BoundingBox.get_shifted_box.to_voc_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_expanded_box", "home.repos.pwc.inspect_result.obss_sahi.sahi.annotation.BoundingBox.get_shifted_box", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_voc_bbox"], ["    ", "def", "test_bounding_box", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "annotation", "import", "BoundingBox", "\n", "\n", "bbox_minmax", "=", "[", "30", ",", "30", ",", "100", ",", "150", "]", "\n", "shift_amount", "=", "[", "50", ",", "40", "]", "\n", "\n", "bbox", "=", "BoundingBox", "(", "bbox_minmax", ",", "shift_amount", "=", "[", "0", ",", "0", "]", ")", "\n", "expanded_bbox", "=", "bbox", ".", "get_expanded_box", "(", "ratio", "=", "0.1", ")", "\n", "\n", "bbox", "=", "BoundingBox", "(", "bbox_minmax", ",", "shift_amount", "=", "shift_amount", ")", "\n", "shifted_bbox", "=", "bbox", ".", "get_shifted_box", "(", ")", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "expanded_bbox", ".", "to_coco_bbox", "(", ")", ",", "[", "18", ",", "23", ",", "94", ",", "134", "]", ")", "\n", "self", ".", "assertEqual", "(", "expanded_bbox", ".", "to_voc_bbox", "(", ")", ",", "[", "18", ",", "23", ",", "112", ",", "157", "]", ")", "\n", "self", ".", "assertEqual", "(", "shifted_bbox", ".", "to_voc_bbox", "(", ")", ",", "[", "80", ",", "70", ",", "150", ",", "190", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_annotation.TestAnnotation.test_category": [[25, 33], ["Category", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual"], "methods", ["None"], ["", "def", "test_category", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "annotation", "import", "Category", "\n", "\n", "category_id", "=", "1", "\n", "category_name", "=", "\"car\"", "\n", "category", "=", "Category", "(", "id", "=", "category_id", ",", "name", "=", "category_name", ")", "\n", "self", ".", "assertEqual", "(", "category", ".", "id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "category", ".", "name", ",", "category_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_annotation.TestAnnotation.test_mask": [[34, 46], ["Mask.from_coco_segmentation", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation"], ["", "def", "test_mask", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "annotation", "import", "Mask", "\n", "\n", "coco_segmentation", "=", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", "\n", "full_shape_height", ",", "full_shape_width", "=", "500", ",", "600", "\n", "full_shape", "=", "[", "full_shape_height", ",", "full_shape_width", "]", "\n", "\n", "mask", "=", "Mask", ".", "from_coco_segmentation", "(", "segmentation", "=", "coco_segmentation", ",", "full_shape", "=", "full_shape", ")", "\n", "\n", "self", ".", "assertEqual", "(", "mask", ".", "full_shape_height", ",", "full_shape_height", ")", "\n", "self", ".", "assertEqual", "(", "mask", ".", "full_shape_width", ",", "full_shape_width", ")", "\n", "self", ".", "assertEqual", "(", "mask", ".", "bool_mask", "[", "11", ",", "2", "]", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_annotation.TestAnnotation.test_object_annotation": [[47, 102], ["ObjectAnnotation", "ObjectAnnotation.from_coco_annotation_dict", "ObjectAnnotation.from_coco_bbox", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual", "test_annotation.TestAnnotation.assertEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoPrediction.from_coco_annotation_dict", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox"], ["", "def", "test_object_annotation", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "annotation", "import", "ObjectAnnotation", "\n", "\n", "bbox", "=", "[", "100", ",", "200", ",", "150", ",", "230", "]", "\n", "coco_bbox", "=", "[", "bbox", "[", "0", "]", ",", "bbox", "[", "1", "]", ",", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ",", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", "]", "\n", "category_id", "=", "2", "\n", "category_name", "=", "\"car\"", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", "\n", "image_height", "=", "1080", "\n", "image_width", "=", "1920", "\n", "full_shape", "=", "[", "image_height", ",", "image_width", "]", "\n", "\n", "object_annotation1", "=", "ObjectAnnotation", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", ")", "\n", "\n", "object_annotation2", "=", "ObjectAnnotation", ".", "from_coco_annotation_dict", "(", "\n", "annotation_dict", "=", "{", "\"bbox\"", ":", "coco_bbox", ",", "\"category_id\"", ":", "category_id", ",", "\"segmentation\"", ":", "[", "]", "}", ",", "\n", "category_name", "=", "category_name", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", ")", "\n", "\n", "object_annotation3", "=", "ObjectAnnotation", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "coco_bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "full_shape", "=", "full_shape", ",", "\n", "shift_amount", "=", "shift_amount", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "object_annotation1", ".", "bbox", ".", "minx", ",", "bbox", "[", "0", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation1", ".", "bbox", ".", "miny", ",", "bbox", "[", "1", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation1", ".", "bbox", ".", "maxx", ",", "bbox", "[", "2", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation1", ".", "bbox", ".", "maxy", ",", "bbox", "[", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation1", ".", "category", ".", "id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation1", ".", "category", ".", "name", ",", "category_name", ")", "\n", "\n", "self", ".", "assertEqual", "(", "object_annotation2", ".", "bbox", ".", "minx", ",", "bbox", "[", "0", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation2", ".", "bbox", ".", "miny", ",", "bbox", "[", "1", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation2", ".", "bbox", ".", "maxx", ",", "bbox", "[", "2", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation2", ".", "bbox", ".", "maxy", ",", "bbox", "[", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation2", ".", "category", ".", "id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation2", ".", "category", ".", "name", ",", "category_name", ")", "\n", "\n", "self", ".", "assertEqual", "(", "object_annotation3", ".", "bbox", ".", "minx", ",", "bbox", "[", "0", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation3", ".", "bbox", ".", "miny", ",", "bbox", "[", "1", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation3", ".", "bbox", ".", "maxx", ",", "bbox", "[", "2", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation3", ".", "bbox", ".", "maxy", ",", "bbox", "[", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation3", ".", "category", ".", "id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "object_annotation3", ".", "category", ".", "name", ",", "category_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_mmdetectionmodel.TestMmdetDetectionModel.test_load_model": [[17, 32], ["sahi.utils.mmdet.download_mmdet_cascade_mask_rcnn_model", "MmdetDetectionModel", "test_mmdetectionmodel.TestMmdetDetectionModel.assertNotEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_cascade_mask_rcnn_model"], ["    ", "def", "test_load_model", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "MmdetDetectionModel", "\n", "\n", "download_mmdet_cascade_mask_rcnn_model", "(", ")", "\n", "\n", "mmdet_detection_model", "=", "MmdetDetectionModel", "(", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_MODEL_PATH", ",", "\n", "config_path", "=", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "assertNotEqual", "(", "mmdet_detection_model", ".", "model", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_mmdetectionmodel.TestMmdetDetectionModel.test_perform_inference_with_mask_output": [[33, 70], ["sahi.utils.mmdet.download_mmdet_cascade_mask_rcnn_model", "MmdetDetectionModel", "sahi.utils.cv.read_image", "MmdetDetectionModel.perform_inference", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "box[].astype().tolist", "len", "len", "len", "box[].astype"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_cascade_mask_rcnn_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "test_perform_inference_with_mask_output", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "MmdetDetectionModel", "\n", "\n", "# init model", "\n", "download_mmdet_cascade_mask_rcnn_model", "(", ")", "\n", "\n", "mmdet_detection_model", "=", "MmdetDetectionModel", "(", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_MODEL_PATH", ",", "\n", "config_path", "=", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "mmdet_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "original_predictions", "=", "mmdet_detection_model", ".", "original_predictions", "\n", "\n", "boxes", "=", "original_predictions", "[", "0", "]", "[", "0", "]", "\n", "masks", "=", "original_predictions", "[", "0", "]", "[", "1", "]", "\n", "\n", "# ensure all prediction scores are greater then 0.5", "\n", "for", "box", "in", "boxes", "[", "0", "]", ":", "\n", "            ", "if", "len", "(", "box", ")", "==", "5", ":", "\n", "                ", "if", "box", "[", "4", "]", ">", "0.5", ":", "\n", "                    ", "break", "\n", "\n", "# compare", "\n", "", "", "", "self", ".", "assertEqual", "(", "box", "[", ":", "4", "]", ".", "astype", "(", "\"int\"", ")", ".", "tolist", "(", ")", ",", "[", "377", ",", "273", ",", "410", ",", "314", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "boxes", ")", ",", "80", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "masks", ")", ",", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_mmdetectionmodel.TestMmdetDetectionModel.test_perform_inference_without_mask_output": [[71, 107], ["sahi.utils.mmdet.download_mmdet_yolox_tiny_model", "MmdetDetectionModel", "sahi.utils.cv.read_image", "MmdetDetectionModel.perform_inference", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "print", "box[].astype().tolist", "len", "len", "len", "box[].astype"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_yolox_tiny_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "test_perform_inference_without_mask_output", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "MmdetDetectionModel", "\n", "\n", "# init model", "\n", "download_mmdet_yolox_tiny_model", "(", ")", "\n", "\n", "mmdet_detection_model", "=", "MmdetDetectionModel", "(", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_MODEL_PATH", ",", "\n", "config_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "mmdet_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "original_predictions", "=", "mmdet_detection_model", ".", "original_predictions", "\n", "\n", "boxes", "=", "original_predictions", "[", "0", "]", "\n", "\n", "# find box of first car detection with conf greater than 0.5", "\n", "for", "box", "in", "boxes", "[", "2", "]", ":", "\n", "            ", "print", "(", "len", "(", "box", ")", ")", "\n", "if", "len", "(", "box", ")", "==", "5", ":", "\n", "                ", "if", "box", "[", "4", "]", ">", "0.5", ":", "\n", "                    ", "break", "\n", "\n", "# compare", "\n", "", "", "", "self", ".", "assertEqual", "(", "box", "[", ":", "4", "]", ".", "astype", "(", "\"int\"", ")", ".", "tolist", "(", ")", ",", "[", "320", ",", "323", ",", "380", ",", "365", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "boxes", ")", ",", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_mmdetectionmodel.TestMmdetDetectionModel.test_convert_original_predictions_with_mask_output": [[108, 151], ["sahi.utils.mmdet.download_mmdet_cascade_mask_rcnn_model", "MmdetDetectionModel", "sahi.utils.cv.read_image", "MmdetDetectionModel.perform_inference", "MmdetDetectionModel.convert_original_predictions", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "len", "object_prediction_list[].bbox.to_coco_bbox", "object_prediction_list[].bbox.to_coco_bbox", "test_mmdetectionmodel.TestMmdetDetectionModel.assertGreaterEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_cascade_mask_rcnn_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "test_convert_original_predictions_with_mask_output", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "MmdetDetectionModel", "\n", "\n", "# init model", "\n", "download_mmdet_cascade_mask_rcnn_model", "(", ")", "\n", "\n", "mmdet_detection_model", "=", "MmdetDetectionModel", "(", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_MODEL_PATH", ",", "\n", "config_path", "=", "MmdetTestConstants", ".", "MMDET_CASCADEMASKRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "mmdet_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "\n", "# convert predictions to ObjectPrediction list", "\n", "mmdet_detection_model", ".", "convert_original_predictions", "(", ")", "\n", "object_prediction_list", "=", "mmdet_detection_model", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "\n", "object_prediction_list", "[", "0", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", "[", "448", ",", "308", ",", "41", ",", "36", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "2", "]", ".", "category", ".", "id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "2", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "\n", "object_prediction_list", "[", "2", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", "[", "381", ",", "280", ",", "33", ",", "30", "]", ",", "\n", ")", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "self", ".", "assertGreaterEqual", "(", "object_prediction", ".", "score", ".", "value", ",", "CONFIDENCE_THRESHOLD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_mmdetectionmodel.TestMmdetDetectionModel.test_convert_original_predictions_without_mask_output": [[152, 195], ["sahi.utils.mmdet.download_mmdet_yolox_tiny_model", "MmdetDetectionModel", "sahi.utils.cv.read_image", "MmdetDetectionModel.perform_inference", "MmdetDetectionModel.convert_original_predictions", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "test_mmdetectionmodel.TestMmdetDetectionModel.assertEqual", "len", "object_prediction_list[].bbox.to_coco_bbox", "object_prediction_list[].bbox.to_coco_bbox", "test_mmdetectionmodel.TestMmdetDetectionModel.assertGreaterEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.mmdet.download_mmdet_yolox_tiny_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "", "def", "test_convert_original_predictions_without_mask_output", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "MmdetDetectionModel", "\n", "\n", "# init model", "\n", "download_mmdet_yolox_tiny_model", "(", ")", "\n", "\n", "mmdet_detection_model", "=", "MmdetDetectionModel", "(", "\n", "model_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_MODEL_PATH", ",", "\n", "config_path", "=", "MmdetTestConstants", ".", "MMDET_YOLOX_TINY_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "mmdet_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "\n", "# convert predictions to ObjectPrediction list", "\n", "mmdet_detection_model", ".", "convert_original_predictions", "(", ")", "\n", "object_prediction_list", "=", "mmdet_detection_model", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "\n", "object_prediction_list", "[", "0", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", "[", "320", ",", "323", ",", "60", ",", "42", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "1", "]", ".", "category", ".", "id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "1", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "\n", "object_prediction_list", "[", "1", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "\n", "[", "448", ",", "310", ",", "44", ",", "31", "]", ",", "\n", ")", "\n", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "self", ".", "assertGreaterEqual", "(", "object_prediction", ".", "score", ".", "value", ",", "CONFIDENCE_THRESHOLD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_load_model": [[16, 29], ["TorchVisionDetectionModel", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "isinstance"], "methods", ["None"], ["    ", "def", "test_load_model", "(", "self", ")", ":", "\n", "        ", "from", "torchvision", ".", "models", ".", "detection", ".", "faster_rcnn", "import", "RoIHeads", "\n", "\n", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "config_path", "=", "TorchVisionTestConstants", ".", "FASTERRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "isinstance", "(", "torchvision_detection_model", ".", "model", ".", "roi_heads", ",", "RoIHeads", ")", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_load_model_without_config_path": [[30, 42], ["TorchVisionDetectionModel", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "isinstance"], "methods", ["None"], ["", "def", "test_load_model_without_config_path", "(", "self", ")", ":", "\n", "        ", "from", "torchvision", ".", "models", ".", "detection", ".", "faster_rcnn", "import", "RoIHeads", "\n", "\n", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "isinstance", "(", "torchvision_detection_model", ".", "model", ".", "roi_heads", ",", "RoIHeads", ")", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_set_model": [[43, 62], ["torchvision.models.detection.ssd300_vgg16", "TorchVisionDetectionModel", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "isinstance"], "methods", ["None"], ["", "def", "test_set_model", "(", "self", ")", ":", "\n", "        ", "import", "torchvision", "\n", "from", "torchvision", ".", "models", ".", "detection", ".", "ssd", "import", "SSDHead", "\n", "\n", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "\n", "NUM_CLASSES", "=", "15", "\n", "PRETRAINED", "=", "False", "\n", "\n", "model", "=", "torchvision", ".", "models", ".", "detection", ".", "ssd300_vgg16", "(", "num_classes", "=", "NUM_CLASSES", ",", "pretrained", "=", "PRETRAINED", ")", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "model", "=", "model", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "isinstance", "(", "torchvision_detection_model", ".", "model", ".", "head", ",", "SSDHead", ")", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_perform_inference_without_mask_output": [[63, 111], ["TorchVisionDetectionModel", "sahi.utils.cv.read_image", "TorchVisionDetectionModel.perform_inference", "list", "list", "list", "range", "range", "range", "[].cpu().detach().numpy", "[].cpu().detach().numpy", "[].cpu().detach().numpy", "len", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "range", "len", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "len", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "len", "len", "test_torchvision.TestTorchVisionDetectionModel.assertTrue", "[].cpu().detach", "[].cpu().detach", "[].cpu().detach", "len", "[].cpu", "[].cpu", "[].cpu"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference"], ["", "def", "test_perform_inference_without_mask_output", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "\n", "# init model", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "config_path", "=", "TorchVisionTestConstants", ".", "SSD300_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "torchvision_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "original_predictions", "=", "torchvision_detection_model", ".", "original_predictions", "\n", "\n", "from", "sahi", ".", "utils", ".", "torchvision", "import", "COCO_CLASSES", "\n", "\n", "boxes", "=", "list", "(", "original_predictions", "[", "0", "]", "[", "\"boxes\"", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "scores", "=", "list", "(", "original_predictions", "[", "0", "]", "[", "\"scores\"", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "category_ids", "=", "list", "(", "original_predictions", "[", "0", "]", "[", "\"labels\"", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# get image height and width", "\n", "image_height", ",", "image_width", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# ensure all box coords are valid", "\n", "for", "box_ind", "in", "range", "(", "len", "(", "boxes", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "len", "(", "boxes", "[", "box_ind", "]", ")", ",", "4", ")", "\n", "self", ".", "assertTrue", "(", "boxes", "[", "box_ind", "]", "[", "0", "]", "<=", "image_width", ")", "\n", "self", ".", "assertTrue", "(", "boxes", "[", "box_ind", "]", "[", "1", "]", "<=", "image_height", ")", "\n", "self", ".", "assertTrue", "(", "boxes", "[", "box_ind", "]", "[", "2", "]", "<=", "image_width", ")", "\n", "self", ".", "assertTrue", "(", "boxes", "[", "box_ind", "]", "[", "3", "]", "<=", "image_height", ")", "\n", "for", "coord_ind", "in", "range", "(", "len", "(", "boxes", "[", "box_ind", "]", ")", ")", ":", "\n", "                ", "self", ".", "assertTrue", "(", "boxes", "[", "box_ind", "]", "[", "coord_ind", "]", ">=", "0", ")", "\n", "\n", "# ensure all category ids are valid", "\n", "", "", "for", "category_id_ind", "in", "range", "(", "len", "(", "category_ids", ")", ")", ":", "\n", "            ", "self", ".", "assertTrue", "(", "category_ids", "[", "category_id_ind", "]", "<", "len", "(", "COCO_CLASSES", ")", ")", "\n", "self", ".", "assertTrue", "(", "category_ids", "[", "category_id_ind", "]", ">=", "0", ")", "\n", "\n", "# ensure all scores are valid", "\n", "", "for", "score_ind", "in", "range", "(", "len", "(", "scores", ")", ")", ":", "\n", "            ", "self", ".", "assertTrue", "(", "scores", "[", "score_ind", "]", "<=", "1", ")", "\n", "self", ".", "assertTrue", "(", "scores", "[", "score_ind", "]", ">=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_convert_original_predictions_without_mask_output": [[112, 140], ["TorchVisionDetectionModel", "sahi.utils.cv.read_image", "TorchVisionDetectionModel.perform_inference", "TorchVisionDetectionModel.convert_original_predictions", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "len", "object_prediction_list[].bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "", "def", "test_convert_original_predictions_without_mask_output", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "config_path", "=", "TorchVisionTestConstants", ".", "FASTERRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "torchvision_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "\n", "# convert predictions to ObjectPrediction list", "\n", "torchvision_detection_model", ".", "convert_original_predictions", "(", ")", "\n", "object_prediction_list", "=", "torchvision_detection_model", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "id", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "[", "315", ",", "309", ",", "65", ",", "57", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_convert_original_predictions_with_mask_output": [[141, 169], ["TorchVisionDetectionModel", "sahi.utils.cv.read_image", "TorchVisionDetectionModel.perform_inference", "TorchVisionDetectionModel.convert_original_predictions", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "len", "object_prediction_list[].bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "test_convert_original_predictions_with_mask_output", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "config_path", "=", "TorchVisionTestConstants", ".", "FASTERRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "torchvision_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "\n", "# convert predictions to ObjectPrediction list", "\n", "torchvision_detection_model", ".", "convert_original_predictions", "(", ")", "\n", "object_prediction_list", "=", "torchvision_detection_model", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "id", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "[", "315", ",", "309", ",", "65", ",", "57", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_get_prediction_torchvision": [[170, 204], ["TorchVisionDetectionModel", "TorchVisionDetectionModel.load_model", "sahi.utils.cv.read_image", "get_prediction", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "len", "object_prediction_list[].bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_prediction", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "test_get_prediction_torchvision", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "from", "sahi", ".", "predict", "import", "get_prediction", "\n", "\n", "# init model", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "config_path", "=", "TorchVisionTestConstants", ".", "FASTERRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "torchvision_detection_model", ".", "load_model", "(", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# get full sized prediction", "\n", "prediction_result", "=", "get_prediction", "(", "\n", "image", "=", "image", ",", "\n", "detection_model", "=", "torchvision_detection_model", ",", "\n", "shift_amount", "=", "[", "0", ",", "0", "]", ",", "\n", "full_shape", "=", "None", ",", "\n", "postprocess", "=", "None", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "id", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "[", "315", ",", "309", ",", "65", ",", "57", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_torchvision.TestTorchVisionDetectionModel.test_get_sliced_prediction_torchvision": [[205, 253], ["TorchVisionDetectionModel", "TorchVisionDetectionModel.load_model", "get_sliced_prediction", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "test_torchvision.TestTorchVisionDetectionModel.assertEqual", "len", "object_prediction_list[].bbox.to_coco_bbox"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.load_model", "home.repos.pwc.inspect_result.obss_sahi.scripts.predict.get_sliced_prediction", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "def", "test_get_sliced_prediction_torchvision", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "TorchVisionDetectionModel", "\n", "from", "sahi", ".", "predict", "import", "get_sliced_prediction", "\n", "\n", "# init model", "\n", "torchvision_detection_model", "=", "TorchVisionDetectionModel", "(", "\n", "config_path", "=", "TorchVisionTestConstants", ".", "FASTERRCNN_CONFIG_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "False", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "torchvision_detection_model", ".", "load_model", "(", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "\n", "slice_height", "=", "512", "\n", "slice_width", "=", "512", "\n", "overlap_height_ratio", "=", "0.1", "\n", "overlap_width_ratio", "=", "0.2", "\n", "postprocess_type", "=", "\"GREEDYNMM\"", "\n", "match_metric", "=", "\"IOS\"", "\n", "match_threshold", "=", "0.5", "\n", "class_agnostic", "=", "True", "\n", "\n", "# get sliced prediction", "\n", "prediction_result", "=", "get_sliced_prediction", "(", "\n", "image", "=", "image_path", ",", "\n", "detection_model", "=", "torchvision_detection_model", ",", "\n", "slice_height", "=", "slice_height", ",", "\n", "slice_width", "=", "slice_width", ",", "\n", "overlap_height_ratio", "=", "overlap_height_ratio", ",", "\n", "overlap_width_ratio", "=", "overlap_width_ratio", ",", "\n", "perform_standard_pred", "=", "False", ",", "\n", "postprocess_type", "=", "postprocess_type", ",", "\n", "postprocess_match_threshold", "=", "match_threshold", ",", "\n", "postprocess_match_metric", "=", "match_metric", ",", "\n", "postprocess_class_agnostic", "=", "class_agnostic", ",", "\n", ")", "\n", "object_prediction_list", "=", "prediction_result", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "id", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", ",", "[", "765", ",", "259", ",", "29", ",", "25", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_fileutils.TestFileUtils.test_list_files": [[8, 14], ["list_files", "test_fileutils.TestFileUtils.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.list_files"], ["    ", "def", "test_list_files", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "file", "import", "list_files", "\n", "\n", "directory", "=", "\"tests/data/coco_utils/\"", "\n", "filepath_list", "=", "list_files", "(", "directory", ",", "contains", "=", "[", "\"json\"", "]", ",", "verbose", "=", "False", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "filepath_list", ")", ",", "11", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_fileutils.TestFileUtils.test_list_files_recursively": [[15, 24], ["list_files_recursively", "test_fileutils.TestFileUtils.assertEqual", "test_fileutils.TestFileUtils.assertEqual", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.list_files_recursively"], ["", "def", "test_list_files_recursively", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "file", "import", "list_files_recursively", "\n", "\n", "directory", "=", "\"tests/data/coco_utils/\"", "\n", "relative_filepath_list", ",", "abs_filepath_list", "=", "list_files_recursively", "(", "\n", "directory", ",", "contains", "=", "[", "\"coco.json\"", "]", ",", "verbose", "=", "False", "\n", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "relative_filepath_list", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "abs_filepath_list", ")", ",", "7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_motutils.TestMotUtils.test_mot_vid": [[10, 48], ["os.path.isdir", "MotVideo", "MotFrame", "MotAnnotation", "MotFrame.add_annotation", "MotVideo.add_frame", "MotFrame", "MotAnnotation", "MotFrame.add_annotation", "MotAnnotation", "MotFrame.add_annotation", "MotVideo.add_frame", "MotVideo.export", "MotVideo", "MotFrame", "MotAnnotation", "MotFrame.add_annotation", "MotVideo.add_frame", "MotFrame", "MotAnnotation", "MotFrame.add_annotation", "MotAnnotation", "MotFrame.add_annotation", "MotVideo.add_frame", "MotVideo.export", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.add_frame", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.add_frame", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.export", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.add_frame", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.add_frame", "home.repos.pwc.inspect_result.obss_sahi.utils.mot.MotVideo.export"], ["    ", "def", "test_mot_vid", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "mot", "import", "MotAnnotation", ",", "MotFrame", ",", "MotVideo", "\n", "\n", "export_dir", "=", "\"tests/data/mot/\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "export_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "export_dir", ",", "ignore_errors", "=", "True", ")", "\n", "\n", "", "mot_video", "=", "MotVideo", "(", "name", "=", "\"video.mp4\"", ")", "\n", "# frame 0", "\n", "mot_frame", "=", "MotFrame", "(", ")", "\n", "mot_detection", "=", "MotAnnotation", "(", "bbox", "=", "[", "10", ",", "10", ",", "100", ",", "100", "]", ")", "\n", "mot_frame", ".", "add_annotation", "(", "mot_detection", ")", "\n", "mot_video", ".", "add_frame", "(", "mot_frame", ")", "\n", "# frame 1", "\n", "mot_frame", "=", "MotFrame", "(", ")", "\n", "mot_detection", "=", "MotAnnotation", "(", "bbox", "=", "[", "12", ",", "12", ",", "98", ",", "98", "]", ")", "\n", "mot_frame", ".", "add_annotation", "(", "mot_detection", ")", "\n", "mot_detection", "=", "MotAnnotation", "(", "bbox", "=", "[", "95", ",", "95", ",", "98", ",", "98", "]", ")", "\n", "mot_frame", ".", "add_annotation", "(", "mot_detection", ")", "\n", "mot_video", ".", "add_frame", "(", "mot_frame", ")", "\n", "# export", "\n", "mot_video", ".", "export", "(", "export_dir", "=", "export_dir", ",", "type", "=", "\"gt\"", ",", "exist_ok", "=", "True", ")", "\n", "\n", "mot_video", "=", "MotVideo", "(", "name", "=", "\"video.mp4\"", ")", "\n", "# frame 0", "\n", "mot_frame", "=", "MotFrame", "(", ")", "\n", "mot_detection", "=", "MotAnnotation", "(", "bbox", "=", "[", "10", ",", "10", ",", "100", ",", "100", "]", ")", "\n", "mot_frame", ".", "add_annotation", "(", "mot_detection", ")", "\n", "mot_video", ".", "add_frame", "(", "mot_frame", ")", "\n", "# frame 1", "\n", "mot_frame", "=", "MotFrame", "(", ")", "\n", "mot_detection", "=", "MotAnnotation", "(", "bbox", "=", "[", "12", ",", "12", ",", "98", ",", "98", "]", ")", "\n", "mot_frame", ".", "add_annotation", "(", "mot_detection", ")", "\n", "mot_detection", "=", "MotAnnotation", "(", "bbox", "=", "[", "95", ",", "95", ",", "98", ",", "98", "]", ")", "\n", "mot_frame", ".", "add_annotation", "(", "mot_detection", ")", "\n", "mot_video", ".", "add_frame", "(", "mot_frame", ")", "\n", "# export", "\n", "mot_video", ".", "export", "(", "export_dir", "=", "export_dir", ",", "type", "=", "\"det\"", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco_categories": [[13, 54], ["CocoCategory", "CocoCategory", "CocoCategory.from_coco_category", "CocoCategory.from_coco_category", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.from_coco_category", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoCategory.from_coco_category"], ["    ", "def", "test_coco_categories", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "CocoCategory", "\n", "\n", "category_id", "=", "0", "\n", "category_name", "=", "\"human\"", "\n", "supercategory", "=", "\"human\"", "\n", "coco_category1", "=", "CocoCategory", "(", "id", "=", "category_id", ",", "name", "=", "category_name", ",", "supercategory", "=", "supercategory", ")", "\n", "coco_category2", "=", "CocoCategory", "(", "id", "=", "category_id", ",", "name", "=", "category_name", ")", "\n", "coco_category3", "=", "CocoCategory", ".", "from_coco_category", "(", "\n", "{", "\n", "\"id\"", ":", "category_id", ",", "\n", "\"name\"", ":", "category_name", ",", "\n", "\"supercategory\"", ":", "supercategory", ",", "\n", "}", "\n", ")", "\n", "coco_category4", "=", "CocoCategory", ".", "from_coco_category", "(", "\n", "{", "\n", "\"id\"", ":", "category_id", ",", "\n", "\"name\"", ":", "category_name", ",", "\n", "}", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "id", ",", "coco_category2", ".", "id", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "id", ",", "coco_category3", ".", "id", ")", "\n", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "name", ",", "category_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "name", ",", "coco_category2", ".", "name", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "name", ",", "coco_category3", ".", "name", ")", "\n", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "supercategory", ",", "supercategory", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "supercategory", ",", "coco_category2", ".", "supercategory", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "supercategory", ",", "coco_category3", ".", "supercategory", ")", "\n", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "json", "[", "\"id\"", "]", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "json", "[", "\"name\"", "]", ",", "category_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_category1", ".", "json", "[", "\"supercategory\"", "]", ",", "supercategory", ")", "\n", "\n", "self", ".", "assertEqual", "(", "coco_category4", ".", "id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "coco_category4", ".", "name", ",", "category_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_category4", ".", "supercategory", ",", "category_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco_annotation": [[55, 86], ["CocoAnnotation.from_coco_segmentation", "test_cocoutils.TestCocoUtils.assertAlmostEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "CocoAnnotation.from_coco_bbox", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox"], ["", "def", "test_coco_annotation", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "CocoAnnotation", "\n", "\n", "coco_segmentation", "=", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", "\n", "category_id", "=", "3", "\n", "category_name", "=", "\"car\"", "\n", "coco_annotation", "=", "CocoAnnotation", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "coco_segmentation", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", ")", "\n", "\n", "self", ".", "assertAlmostEqual", "(", "coco_annotation", ".", "area", ",", "41177", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "bbox", ",", "[", "1", ",", "1", ",", "324", ",", "199", "]", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "category_id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "category_name", ",", "category_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "segmentation", ",", "coco_segmentation", ")", "\n", "\n", "coco_bbox", "=", "[", "1", ",", "1", ",", "100", ",", "100", "]", "\n", "category_id", "=", "3", "\n", "coco_annotation", "=", "CocoAnnotation", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "coco_bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "area", ",", "10000", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "bbox", ",", "coco_bbox", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "category_id", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "category_name", ",", "category_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_annotation", ".", "segmentation", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_cocovid_annotation": [[87, 111], ["CocoVidAnnotation", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual"], "methods", ["None"], ["", "def", "test_cocovid_annotation", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "CocoVidAnnotation", "\n", "\n", "bbox", "=", "[", "1", ",", "1", ",", "324", ",", "199", "]", "\n", "category_id", "=", "3", "\n", "category_name", "=", "\"car\"", "\n", "image_id", "=", "13", "\n", "instance_id", "=", "22", "\n", "iscrowd", "=", "0", "\n", "cocovid_annotation", "=", "CocoVidAnnotation", "(", "\n", "bbox", "=", "bbox", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", "image_id", "=", "image_id", ",", "\n", "instance_id", "=", "instance_id", ",", "\n", "iscrowd", "=", "iscrowd", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "cocovid_annotation", ".", "json", "[", "\"bbox\"", "]", ",", "bbox", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_annotation", ".", "json", "[", "\"category_id\"", "]", ",", "category_id", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_annotation", ".", "json", "[", "\"category_name\"", "]", ",", "category_name", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_annotation", ".", "json", "[", "\"image_id\"", "]", ",", "image_id", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_annotation", ".", "json", "[", "\"instance_id\"", "]", ",", "instance_id", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_annotation", ".", "json", "[", "\"iscrowd\"", "]", ",", "iscrowd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco_image": [[112, 182], ["CocoImage", "CocoAnnotation.from_coco_segmentation", "CocoImage.add_annotation", "CocoAnnotation.from_coco_bbox", "CocoImage.add_annotation", "CocoPrediction.from_coco_segmentation", "CocoImage.add_prediction", "CocoPrediction.from_coco_bbox", "CocoImage.add_prediction", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_segmentation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.add_prediction", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.from_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoImage.add_prediction"], ["", "def", "test_coco_image", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "CocoAnnotation", ",", "CocoImage", ",", "CocoPrediction", "\n", "\n", "# init coco image", "\n", "file_name", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "height", "=", "580", "\n", "width", "=", "1068", "\n", "coco_image", "=", "CocoImage", "(", "file_name", ",", "height", ",", "width", ")", "\n", "\n", "# create and add first annotation", "\n", "coco_segmentation", "=", "[", "[", "1", ",", "1", ",", "325", ",", "125", ",", "250", ",", "200", ",", "5", ",", "200", "]", "]", "\n", "category_id", "=", "3", "\n", "category_name", "=", "\"car\"", "\n", "coco_annotation_1", "=", "CocoAnnotation", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "coco_segmentation", ",", "\n", "category_id", "=", "category_id", ",", "\n", "category_name", "=", "category_name", ",", "\n", ")", "\n", "coco_image", ".", "add_annotation", "(", "coco_annotation_1", ")", "\n", "\n", "# create and add second annotation", "\n", "coco_bbox", "=", "[", "1", ",", "1", ",", "100", ",", "100", "]", "\n", "category_id", "=", "2", "\n", "category_name", "=", "\"bus\"", "\n", "coco_annotation_2", "=", "CocoAnnotation", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "coco_bbox", ",", "category_id", "=", "category_id", ",", "category_name", "=", "category_name", "\n", ")", "\n", "coco_image", ".", "add_annotation", "(", "coco_annotation_2", ")", "\n", "\n", "# create and add first prediction", "\n", "prediction_coco_segmentation", "=", "[", "[", "4", ",", "3", ",", "315", ",", "124", ",", "265", ",", "198", ",", "5", ",", "198", "]", "]", "\n", "score", "=", "0.983425", "\n", "category_id", "=", "3", "\n", "category_name", "=", "\"car\"", "\n", "coco_prediction_1", "=", "CocoPrediction", ".", "from_coco_segmentation", "(", "\n", "segmentation", "=", "prediction_coco_segmentation", ",", "category_id", "=", "category_id", ",", "category_name", "=", "category_name", ",", "score", "=", "score", "\n", ")", "\n", "coco_image", ".", "add_prediction", "(", "coco_prediction_1", ")", "\n", "\n", "# create and add second prediction", "\n", "prediction_coco_bbox", "=", "[", "2", ",", "5", ",", "103", ",", "98", "]", "\n", "score", "=", "0.683465", "\n", "category_id", "=", "2", "\n", "category_name", "=", "\"bus\"", "\n", "coco_prediction_2", "=", "CocoPrediction", ".", "from_coco_bbox", "(", "\n", "bbox", "=", "prediction_coco_bbox", ",", "category_id", "=", "category_id", ",", "category_name", "=", "category_name", ",", "score", "=", "score", "\n", ")", "\n", "coco_image", ".", "add_prediction", "(", "coco_prediction_2", ")", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "file_name", ",", "file_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "height", ",", "height", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "width", ",", "width", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_image", ".", "annotations", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "annotations", "[", "0", "]", ".", "category_id", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "annotations", "[", "0", "]", ".", "category_name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "annotations", "[", "0", "]", ".", "segmentation", ",", "coco_segmentation", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "annotations", "[", "1", "]", ".", "category_id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "annotations", "[", "1", "]", ".", "category_name", ",", "\"bus\"", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "annotations", "[", "1", "]", ".", "bbox", ",", "coco_bbox", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_image", ".", "predictions", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "0", "]", ".", "category_id", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "0", "]", ".", "category_name", ",", "\"car\"", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "0", "]", ".", "segmentation", ",", "prediction_coco_segmentation", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "0", "]", ".", "score", ",", "0.983425", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "1", "]", ".", "category_id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "1", "]", ".", "category_name", ",", "\"bus\"", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "1", "]", ".", "bbox", ",", "prediction_coco_bbox", ")", "\n", "self", ".", "assertEqual", "(", "coco_image", ".", "predictions", "[", "1", "]", ".", "score", ",", "0.683465", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_cocovid_image": [[183, 243], ["CocoVidImage", "CocoVidAnnotation", "CocoVidImage.add_annotation", "CocoVidAnnotation", "CocoVidImage.add_annotation", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation"], ["", "def", "test_cocovid_image", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "CocoVidAnnotation", ",", "CocoVidImage", "\n", "\n", "# init coco image", "\n", "file_name", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "height", "=", "580", "\n", "width", "=", "1068", "\n", "cocovid_image", "=", "CocoVidImage", "(", "file_name", ",", "height", ",", "width", ")", "\n", "\n", "# create and add first annotation", "\n", "bbox1", "=", "[", "1", ",", "1", ",", "324", ",", "199", "]", "\n", "category_id1", "=", "3", "\n", "category_name1", "=", "\"car\"", "\n", "image_id1", "=", "13", "\n", "instance_id1", "=", "22", "\n", "iscrowd1", "=", "0", "\n", "cocovid_annotation_1", "=", "CocoVidAnnotation", "(", "\n", "bbox", "=", "bbox1", ",", "\n", "category_id", "=", "category_id1", ",", "\n", "category_name", "=", "category_name1", ",", "\n", "image_id", "=", "image_id1", ",", "\n", "instance_id", "=", "instance_id1", ",", "\n", "iscrowd", "=", "iscrowd1", ",", "\n", ")", "\n", "cocovid_image", ".", "add_annotation", "(", "cocovid_annotation_1", ")", "\n", "\n", "# create and add second annotation", "\n", "bbox2", "=", "[", "1", ",", "1", ",", "50", ",", "150", "]", "\n", "category_id2", "=", "2", "\n", "category_name2", "=", "\"human\"", "\n", "image_id2", "=", "14", "\n", "instance_id2", "=", "23", "\n", "iscrowd2", "=", "0", "\n", "cocovid_annotation_2", "=", "CocoVidAnnotation", "(", "\n", "bbox", "=", "bbox2", ",", "\n", "category_id", "=", "category_id2", ",", "\n", "category_name", "=", "category_name2", ",", "\n", "image_id", "=", "image_id2", ",", "\n", "instance_id", "=", "instance_id2", ",", "\n", "iscrowd", "=", "iscrowd2", ",", "\n", ")", "\n", "cocovid_image", ".", "add_annotation", "(", "cocovid_annotation_2", ")", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "file_name", ",", "file_name", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "json", "[", "\"file_name\"", "]", ",", "file_name", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "height", ",", "height", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "json", "[", "\"height\"", "]", ",", "height", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "width", ",", "width", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "json", "[", "\"width\"", "]", ",", "width", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "cocovid_image", ".", "annotations", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "0", "]", ".", "category_id", ",", "category_id1", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "0", "]", ".", "category_name", ",", "category_name1", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "0", "]", ".", "image_id", ",", "image_id1", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "0", "]", ".", "bbox", ",", "bbox1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "1", "]", ".", "category_id", ",", "category_id2", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "1", "]", ".", "category_name", ",", "category_name2", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "1", "]", ".", "instance_id", ",", "instance_id2", ")", "\n", "self", ".", "assertEqual", "(", "cocovid_image", ".", "annotations", "[", "1", "]", ".", "bbox", ",", "bbox2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco_video": [[244, 295], ["CocoVidImage", "CocoVidAnnotation", "CocoVidImage.add_annotation", "CocoVideo", "CocoVideo.add_cocovidimage", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVideo.add_cocovidimage"], ["", "def", "test_coco_video", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "CocoVidAnnotation", ",", "CocoVideo", ",", "CocoVidImage", "\n", "\n", "# init coco image", "\n", "file_name", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "height1", "=", "519", "\n", "width1", "=", "1067", "\n", "cocovid_image", "=", "CocoVidImage", "(", "file_name", ",", "height1", ",", "width1", ")", "\n", "\n", "# create and add first annotation", "\n", "bbox1", "=", "[", "1", ",", "1", ",", "324", ",", "199", "]", "\n", "category_id1", "=", "3", "\n", "category_name1", "=", "\"car\"", "\n", "image_id1", "=", "13", "\n", "instance_id1", "=", "22", "\n", "iscrowd1", "=", "0", "\n", "cocovid_annotation_1", "=", "CocoVidAnnotation", "(", "\n", "bbox", "=", "bbox1", ",", "\n", "category_id", "=", "category_id1", ",", "\n", "category_name", "=", "category_name1", ",", "\n", "image_id", "=", "image_id1", ",", "\n", "instance_id", "=", "instance_id1", ",", "\n", "iscrowd", "=", "iscrowd1", ",", "\n", ")", "\n", "cocovid_image", ".", "add_annotation", "(", "cocovid_annotation_1", ")", "\n", "\n", "# init coco video", "\n", "name", "=", "\"small-vehicles\"", "\n", "height2", "=", "580", "\n", "width2", "=", "1068", "\n", "coco_video", "=", "CocoVideo", "(", "name", "=", "name", ",", "height", "=", "height2", ",", "width", "=", "width2", ")", "\n", "\n", "# add first image", "\n", "coco_video", ".", "add_cocovidimage", "(", "cocovid_image", ")", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "name", ",", "name", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "json", "[", "\"name\"", "]", ",", "name", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "height", ",", "height2", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "json", "[", "\"height\"", "]", ",", "height2", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "width", ",", "width2", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "json", "[", "\"width\"", "]", ",", "width2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_video", ".", "images", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "file_name", ",", "file_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "json", "[", "\"file_name\"", "]", ",", "file_name", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "height", ",", "height1", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "json", "[", "\"height\"", "]", ",", "height1", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "width", ",", "width1", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "json", "[", "\"width\"", "]", ",", "width1", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "annotations", "[", "0", "]", ".", "bbox", ",", "bbox1", ")", "\n", "self", ".", "assertEqual", "(", "coco_video", ".", "images", "[", "0", "]", ".", "annotations", "[", "0", "]", ".", "json", "[", "\"bbox\"", "]", ",", "bbox1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco": [[296, 338], ["sahi.utils.file.load_json", "Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path"], ["", "def", "test_coco", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "\n", "category_mapping", "=", "{", "1", ":", "\"human\"", ",", "2", ":", "\"car\"", "}", "\n", "# init coco", "\n", "coco_path", "=", "\"tests/data/coco_utils/terrain_all_coco.json\"", "\n", "coco_dict", "=", "load_json", "(", "coco_path", ")", "\n", "coco1", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_dict", ")", "\n", "coco2", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path", ")", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco1", ".", "images", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco2", ".", "images", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "coco1", ".", "images", "[", "2", "]", ".", "annotations", "[", "1", "]", ".", "category_name", ",", "\"human\"", ")", "\n", "self", ".", "assertEqual", "(", "coco2", ".", "images", "[", "2", "]", ".", "annotations", "[", "1", "]", ".", "category_name", ",", "\"human\"", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "images", "[", "1", "]", ".", "annotations", "[", "1", "]", ".", "segmentation", ",", "\n", "[", "[", "501", ",", "451", ",", "622", ",", "451", ",", "622", ",", "543", ",", "501", ",", "543", "]", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco2", ".", "images", "[", "1", "]", ".", "annotations", "[", "1", "]", ".", "segmentation", ",", "\n", "[", "[", "501", ",", "451", ",", "622", ",", "451", ",", "622", ",", "543", ",", "501", ",", "543", "]", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "category_mapping", ",", "\n", "category_mapping", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco2", ".", "category_mapping", ",", "\n", "category_mapping", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "stats", ",", "\n", "coco2", ".", "stats", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "stats", "[", "\"num_images\"", "]", ",", "\n", "len", "(", "coco1", ".", "images", ")", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "coco1", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_split_coco_as_train_val": [[340, 365], ["Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path.split_coco_as_train_val", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.split_coco_as_train_val"], ["", "def", "test_split_coco_as_train_val", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "\n", "coco_dict_path", "=", "\"tests/data/coco_utils/combined_coco.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_dict_path", ",", "image_dir", "=", "image_dir", ")", "\n", "result", "=", "coco", ".", "split_coco_as_train_val", "(", "train_split_rate", "=", "0.5", ",", "numpy_seed", "=", "0", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "result", "[", "\"train_coco\"", "]", ".", "json", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "result", "[", "\"train_coco\"", "]", ".", "json", "[", "\"annotations\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "result", "[", "\"train_coco\"", "]", ".", "json", "[", "\"images\"", "]", "[", "0", "]", "[", "\"height\"", "]", ",", "682", ")", "\n", "self", ".", "assertEqual", "(", "result", "[", "\"train_coco\"", "]", ".", "image_dir", ",", "image_dir", ")", "\n", "self", ".", "assertEqual", "(", "result", "[", "\"train_coco\"", "]", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "result", "[", "\"train_coco\"", "]", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "result", "[", "\"train_coco\"", "]", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "result", "[", "\"train_coco\"", "]", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "result", "[", "\"val_coco\"", "]", ".", "json", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "result", "[", "\"val_coco\"", "]", ".", "json", "[", "\"annotations\"", "]", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "result", "[", "\"val_coco\"", "]", ".", "json", "[", "\"images\"", "]", "[", "0", "]", "[", "\"height\"", "]", ",", "1365", ")", "\n", "self", ".", "assertEqual", "(", "result", "[", "\"val_coco\"", "]", ".", "image_dir", ",", "image_dir", ")", "\n", "self", ".", "assertEqual", "(", "result", "[", "\"val_coco\"", "]", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "result", "[", "\"val_coco\"", "]", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "result", "[", "\"val_coco\"", "]", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "result", "[", "\"val_coco\"", "]", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco2yolo": [[367, 377], ["os.path.isdir", "Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path.export_as_yolov5", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.export_as_yolov5"], ["", "def", "test_coco2yolo", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "\n", "coco_dict_path", "=", "\"tests/data/coco_utils/combined_coco.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "output_dir", "=", "\"tests/data/coco2yolo/\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_dict_path", ",", "image_dir", "=", "image_dir", ")", "\n", "coco", ".", "export_as_yolov5", "(", "output_dir", "=", "output_dir", ",", "train_split_rate", "=", "0.5", ",", "numpy_seed", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_update_categories": [[378, 407], ["sahi.utils.file.load_json", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "sahi.utils.coco.update_categories", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories"], ["", "def", "test_update_categories", "(", "self", ")", ":", "\n", "        ", "coco_path", "=", "\"tests/data/coco_utils/terrain2_coco.json\"", "\n", "source_coco_dict", "=", "load_json", "(", "coco_path", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "source_coco_dict", "[", "\"annotations\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "source_coco_dict", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "source_coco_dict", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "\n", "source_coco_dict", "[", "\"categories\"", "]", ",", "\n", "[", "{", "\"id\"", ":", "1", ",", "\"name\"", ":", "\"car\"", ",", "\"supercategory\"", ":", "\"car\"", "}", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "source_coco_dict", "[", "\"annotations\"", "]", "[", "1", "]", "[", "\"category_id\"", "]", ",", "1", ")", "\n", "\n", "# update categories", "\n", "desired_name2id", "=", "{", "\"human\"", ":", "1", ",", "\"car\"", ":", "2", ",", "\"big_vehicle\"", ":", "3", "}", "\n", "target_coco_dict", "=", "update_categories", "(", "desired_name2id", "=", "desired_name2id", ",", "coco_dict", "=", "source_coco_dict", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "target_coco_dict", "[", "\"annotations\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "target_coco_dict", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "target_coco_dict", "[", "\"categories\"", "]", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "\n", "target_coco_dict", "[", "\"categories\"", "]", ",", "\n", "[", "\n", "{", "\"id\"", ":", "1", ",", "\"name\"", ":", "\"human\"", ",", "\"supercategory\"", ":", "\"human\"", "}", ",", "\n", "{", "\"id\"", ":", "2", ",", "\"name\"", ":", "\"car\"", ",", "\"supercategory\"", ":", "\"car\"", "}", ",", "\n", "{", "\"id\"", ":", "3", ",", "\"name\"", ":", "\"big_vehicle\"", ",", "\"supercategory\"", ":", "\"big_vehicle\"", "}", ",", "\n", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "target_coco_dict", "[", "\"annotations\"", "]", "[", "1", "]", "[", "\"category_id\"", "]", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco_update_categories": [[408, 446], ["Coco.from_coco_dict_or_path", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "Coco.from_coco_dict_or_path.update_categories", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.update_categories"], ["", "def", "test_coco_update_categories", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "\n", "coco_path", "=", "\"tests/data/coco_utils/terrain2_coco.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path", ",", "image_dir", "=", "image_dir", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco", ".", "json", "[", "\"annotations\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco", ".", "json", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco", ".", "json", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco", ".", "json", "[", "\"categories\"", "]", ",", "\n", "[", "{", "\"id\"", ":", "1", ",", "\"name\"", ":", "\"car\"", ",", "\"supercategory\"", ":", "\"car\"", "}", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "json", "[", "\"annotations\"", "]", "[", "1", "]", "[", "\"category_id\"", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "image_dir", ",", "image_dir", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "coco", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "stats", "[", "\"num_annotations\"", "]", ",", "len", "(", "coco", ".", "json", "[", "\"annotations\"", "]", ")", ")", "\n", "\n", "# update categories", "\n", "desired_name2id", "=", "{", "\"human\"", ":", "1", ",", "\"car\"", ":", "2", ",", "\"big_vehicle\"", ":", "3", "}", "\n", "coco", ".", "update_categories", "(", "desired_name2id", "=", "desired_name2id", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco", ".", "json", "[", "\"annotations\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco", ".", "json", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco", ".", "json", "[", "\"categories\"", "]", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco", ".", "json", "[", "\"categories\"", "]", ",", "\n", "[", "\n", "{", "\"id\"", ":", "1", ",", "\"name\"", ":", "\"human\"", ",", "\"supercategory\"", ":", "\"human\"", "}", ",", "\n", "{", "\"id\"", ":", "2", ",", "\"name\"", ":", "\"car\"", ",", "\"supercategory\"", ":", "\"car\"", "}", ",", "\n", "{", "\"id\"", ":", "3", ",", "\"name\"", ":", "\"big_vehicle\"", ",", "\"supercategory\"", ":", "\"big_vehicle\"", "}", ",", "\n", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "json", "[", "\"annotations\"", "]", "[", "1", "]", "[", "\"category_id\"", "]", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "image_dir", ",", "image_dir", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "coco", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "coco", ".", "stats", "[", "\"num_annotations\"", "]", ",", "len", "(", "coco", ".", "json", "[", "\"annotations\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_get_imageid2annotationlist_mapping": [[447, 462], ["sahi.utils.file.load_json", "get_imageid2annotationlist_mapping", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.test_get_imageid2annotationlist_mapping.check_image_id"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.get_imageid2annotationlist_mapping"], ["", "def", "test_get_imageid2annotationlist_mapping", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "get_imageid2annotationlist_mapping", "\n", "\n", "coco_path", "=", "\"tests/data/coco_utils/combined_coco.json\"", "\n", "coco_dict", "=", "load_json", "(", "coco_path", ")", "\n", "imageid2annotationlist_mapping", "=", "get_imageid2annotationlist_mapping", "(", "coco_dict", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "imageid2annotationlist_mapping", ")", ",", "2", ")", "\n", "\n", "def", "check_image_id", "(", "image_id", ")", ":", "\n", "\n", "            ", "image_ids", "=", "[", "annotationlist", "[", "\"image_id\"", "]", "for", "annotationlist", "in", "imageid2annotationlist_mapping", "[", "image_id", "]", "]", "\n", "self", ".", "assertEqual", "(", "image_ids", ",", "[", "image_id", "]", "*", "len", "(", "image_ids", ")", ")", "\n", "\n", "", "check_image_id", "(", "image_id", "=", "1", ")", "\n", "check_image_id", "(", "image_id", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_merge": [[463, 495], ["sahi.utils.file.load_json", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "sahi.utils.file.load_json", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "sahi.utils.coco.merge", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "sahi.utils.coco.merge", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge"], ["", "def", "test_merge", "(", "self", ")", ":", "\n", "# load coco files to be combined", "\n", "        ", "coco_path1", "=", "\"tests/data/coco_utils/terrain1_coco.json\"", "\n", "coco_path2", "=", "\"tests/data/coco_utils/terrain2_coco.json\"", "\n", "coco_dict1", "=", "load_json", "(", "coco_path1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict1", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict1", "[", "\"annotations\"", "]", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict1", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "\n", "coco_dict2", "=", "load_json", "(", "coco_path2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict2", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict2", "[", "\"annotations\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict2", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "\n", "# merge without desired_name2id", "\n", "merged_coco_dict", "=", "merge", "(", "coco_dict1", ",", "coco_dict2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"images\"", "]", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"annotations\"", "]", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "\n", "# merge with desired_name2id", "\n", "desired_name2id", "=", "{", "\"human\"", ":", "1", ",", "\"car\"", ":", "2", ",", "\"big_vehicle\"", ":", "3", "}", "\n", "merged_coco_dict", "=", "merge", "(", "coco_dict1", ",", "coco_dict2", ",", "desired_name2id", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"images\"", "]", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"annotations\"", "]", ")", ",", "12", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"categories\"", "]", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "6", "]", "[", "\"category_id\"", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "6", "]", "[", "\"image_id\"", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "6", "]", "[", "\"id\"", "]", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "7", "]", "[", "\"category_id\"", "]", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "7", "]", "[", "\"image_id\"", "]", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "7", "]", "[", "\"id\"", "]", ",", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_merge_from_list": [[496, 542], ["sahi.utils.file.load_json", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "sahi.utils.file.load_json", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "sahi.utils.file.load_json", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "merge_from_list", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.file.load_json", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge_from_list"], ["", "def", "test_merge_from_list", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "merge_from_list", "\n", "\n", "# load coco files to be combined", "\n", "coco_path1", "=", "\"tests/data/coco_utils/terrain1_coco.json\"", "\n", "coco_path2", "=", "\"tests/data/coco_utils/terrain2_coco.json\"", "\n", "coco_path3", "=", "\"tests/data/coco_utils/terrain3_coco.json\"", "\n", "coco_dict1", "=", "load_json", "(", "coco_path1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict1", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict1", "[", "\"annotations\"", "]", ")", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict1", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "\n", "coco_dict2", "=", "load_json", "(", "coco_path2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict2", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict2", "[", "\"annotations\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict2", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "\n", "coco_dict3", "=", "load_json", "(", "coco_path3", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict3", "[", "\"images\"", "]", ")", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict3", "[", "\"annotations\"", "]", ")", ",", "10", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict3", "[", "\"categories\"", "]", ")", ",", "1", ")", "\n", "\n", "# merge without desired_name2id", "\n", "merged_coco_dict", "=", "merge_from_list", "(", "[", "coco_dict1", ",", "coco_dict2", ",", "coco_dict3", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"images\"", "]", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"annotations\"", "]", ")", ",", "22", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "merged_coco_dict", "[", "\"categories\"", "]", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "\n", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "12", "]", "[", "\"bbox\"", "]", ",", "\n", "coco_dict3", "[", "\"annotations\"", "]", "[", "0", "]", "[", "\"bbox\"", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "12", "]", "[", "\"id\"", "]", ",", "\n", "15", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "12", "]", "[", "\"image_id\"", "]", ",", "\n", "5", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "9", "]", "[", "\"category_id\"", "]", ",", "\n", "1", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "merged_coco_dict", "[", "\"annotations\"", "]", "[", "9", "]", "[", "\"image_id\"", "]", ",", "\n", "3", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_coco_merge": [[544, 588], ["Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path.merge", "Coco.from_coco_dict_or_path.merge", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.merge"], ["", "def", "test_coco_merge", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "\n", "# load coco files to be combined", "\n", "coco_path1", "=", "\"tests/data/coco_utils/terrain1_coco.json\"", "\n", "coco_path2", "=", "\"tests/data/coco_utils/terrain2_coco.json\"", "\n", "coco_path3", "=", "\"tests/data/coco_utils/terrain3_coco.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "coco1", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path1", ",", "image_dir", "=", "image_dir", ")", "\n", "coco2", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path2", ",", "image_dir", "=", "image_dir", ")", "\n", "coco3", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path3", ",", "image_dir", "=", "image_dir", ")", "\n", "coco1", ".", "merge", "(", "coco2", ")", "\n", "coco1", ".", "merge", "(", "coco3", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco1", ".", "json", "[", "\"images\"", "]", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco1", ".", "json", "[", "\"annotations\"", "]", ")", ",", "22", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco1", ".", "json", "[", "\"categories\"", "]", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco1", ".", "images", ")", ",", "3", ")", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "json", "[", "\"annotations\"", "]", "[", "12", "]", "[", "\"id\"", "]", ",", "\n", "13", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "json", "[", "\"annotations\"", "]", "[", "12", "]", "[", "\"image_id\"", "]", ",", "\n", "3", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "json", "[", "\"annotations\"", "]", "[", "9", "]", "[", "\"category_id\"", "]", ",", "\n", "1", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "json", "[", "\"annotations\"", "]", "[", "9", "]", "[", "\"image_id\"", "]", ",", "\n", "2", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco1", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco2", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "coco2", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "coco2", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "coco2", ".", "stats", "[", "\"num_annotations\"", "]", ",", "len", "(", "coco2", ".", "json", "[", "\"annotations\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_get_subsampled_coco": [[589, 642], ["Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path.get_subsampled_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "Coco.from_coco_dict_or_path.get_subsampled_coco", "test_cocoutils.TestCocoUtils.assertEqual", "Coco.from_coco_dict_or_path.get_subsampled_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len", "len", "len", "int", "int"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_subsampled_coco", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_subsampled_coco", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_subsampled_coco"], ["", "def", "test_get_subsampled_coco", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "from", "sahi", ".", "utils", ".", "file", "import", "load_json", "\n", "\n", "coco_path", "=", "\"tests/data/coco_utils/visdrone2019-det-train-first50image.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "SUBSAMPLE_RATIO", "=", "5", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path", ",", "image_dir", "=", "image_dir", ")", "\n", "subsampled_coco", "=", "coco", ".", "get_subsampled_coco", "(", "subsample_ratio", "=", "SUBSAMPLE_RATIO", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "50", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "subsampled_coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "10", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "images", "[", "5", "]", ".", "annotations", ")", ",", "\n", "len", "(", "subsampled_coco", ".", "images", "[", "1", "]", ".", "annotations", ")", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "images", "[", "5", "]", ".", "annotations", ")", ",", "\n", "len", "(", "subsampled_coco", ".", "images", "[", "1", "]", ".", "annotations", ")", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "subsampled_coco", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "subsampled_coco", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "subsampled_coco", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "subsampled_coco", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "subsampled_coco", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n", "\n", "vehicle_subsampled_coco", "=", "coco", ".", "get_subsampled_coco", "(", "subsample_ratio", "=", "SUBSAMPLE_RATIO", ",", "category_id", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "\n", "vehicle_subsampled_coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", ",", "\n", "int", "(", "coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", "/", "SUBSAMPLE_RATIO", ")", "+", "1", ",", "\n", ")", "\n", "\n", "negative_subsampled_coco", "=", "coco", ".", "get_subsampled_coco", "(", "subsample_ratio", "=", "SUBSAMPLE_RATIO", ",", "category_id", "=", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "\n", "negative_subsampled_coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", ",", "\n", "coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "negative_subsampled_coco", ".", "stats", "[", "\"num_negative_images\"", "]", ",", "\n", "int", "(", "coco", ".", "stats", "[", "\"num_negative_images\"", "]", "/", "SUBSAMPLE_RATIO", ")", "+", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_get_upsampled_coco": [[644, 701], ["Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path.get_upsampled_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "Coco.from_coco_dict_or_path.get_upsampled_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertNotEqual", "Coco.from_coco_dict_or_path.get_upsampled_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_upsampled_coco", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_upsampled_coco", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_upsampled_coco"], ["", "def", "test_get_upsampled_coco", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "from", "sahi", ".", "utils", ".", "file", "import", "load_json", "\n", "\n", "coco_path", "=", "\"tests/data/coco_utils/visdrone2019-det-train-first50image.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path", ",", "image_dir", "=", "image_dir", ")", "\n", "UPSAMPLE_RATIO", "=", "5", "\n", "upsampled_coco", "=", "coco", ".", "get_upsampled_coco", "(", "upsample_ratio", "=", "UPSAMPLE_RATIO", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "50", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "upsampled_coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "250", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "images", "[", "5", "]", ".", "annotations", ")", ",", "\n", "len", "(", "upsampled_coco", ".", "images", "[", "5", "+", "len", "(", "coco", ".", "images", ")", "]", ".", "annotations", ")", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "upsampled_coco", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "upsampled_coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", ",", "\n", "coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", "*", "UPSAMPLE_RATIO", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "upsampled_coco", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "upsampled_coco", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "upsampled_coco", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "upsampled_coco", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n", "\n", "vehicle_upsampled_coco", "=", "coco", ".", "get_upsampled_coco", "(", "upsample_ratio", "=", "UPSAMPLE_RATIO", ",", "category_id", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "\n", "vehicle_upsampled_coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", ",", "\n", "coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", "*", "UPSAMPLE_RATIO", ",", "\n", ")", "\n", "self", ".", "assertNotEqual", "(", "\n", "vehicle_upsampled_coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"human\"", "]", ",", "\n", "coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"human\"", "]", "*", "UPSAMPLE_RATIO", ",", "\n", ")", "\n", "\n", "negative_upsampled_coco", "=", "coco", ".", "get_upsampled_coco", "(", "upsample_ratio", "=", "UPSAMPLE_RATIO", ",", "category_id", "=", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "\n", "negative_upsampled_coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", ",", "\n", "coco", ".", "stats", "[", "\"num_images_per_category\"", "]", "[", "\"vehicle\"", "]", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "negative_upsampled_coco", ".", "stats", "[", "\"num_negative_images\"", "]", ",", "\n", "coco", ".", "stats", "[", "\"num_negative_images\"", "]", "*", "UPSAMPLE_RATIO", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_get_area_filtered_coco": [[703, 812], ["Coco.from_coco_dict_or_path", "Coco.from_coco_dict_or_path.get_area_filtered_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertGreater", "test_cocoutils.TestCocoUtils.assertLess", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "Coco.from_coco_dict_or_path.get_area_filtered_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertGreater", "test_cocoutils.TestCocoUtils.assertLess", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "Coco.from_coco_dict_or_path.get_area_filtered_coco", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertGreater", "test_cocoutils.TestCocoUtils.assertLess", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "len", "len", "len", "len", "len", "len", "min", "max", "len", "len", "len", "len", "min", "max", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_area_filtered_coco", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_area_filtered_coco", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_area_filtered_coco"], ["", "def", "test_get_area_filtered_coco", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", "\n", "\n", "coco_path", "=", "\"tests/data/coco_utils/visdrone2019-det-train-first50image.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "min_area", "=", "50", "\n", "max_area", "=", "10000", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path", ",", "image_dir", "=", "image_dir", ")", "\n", "area_filtered_coco", "=", "coco", ".", "get_area_filtered_coco", "(", "min", "=", "min_area", ",", "max", "=", "max_area", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "50", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "area_filtered_coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "17", ",", "\n", ")", "\n", "self", ".", "assertGreater", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"min_annotation_area\"", "]", ",", "\n", "min_area", ",", "\n", ")", "\n", "self", ".", "assertLess", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"max_annotation_area\"", "]", ",", "\n", "max_area", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "area_filtered_coco", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "area_filtered_coco", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "area_filtered_coco", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "area_filtered_coco", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n", "\n", "intervals_per_category", "=", "{", "\n", "\"human\"", ":", "{", "\"min\"", ":", "20", ",", "\"max\"", ":", "10000", "}", ",", "\n", "\"vehicle\"", ":", "{", "\"min\"", ":", "50", ",", "\"max\"", ":", "15000", "}", ",", "\n", "}", "\n", "area_filtered_coco", "=", "coco", ".", "get_area_filtered_coco", "(", "intervals_per_category", "=", "intervals_per_category", ")", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "50", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "area_filtered_coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "24", ",", "\n", ")", "\n", "self", ".", "assertGreater", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"min_annotation_area\"", "]", ",", "\n", "min", "(", "\n", "intervals_per_category", "[", "\"human\"", "]", "[", "\"min\"", "]", ",", "\n", "intervals_per_category", "[", "\"vehicle\"", "]", "[", "\"min\"", "]", ",", "\n", ")", ",", "\n", ")", "\n", "self", ".", "assertLess", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"max_annotation_area\"", "]", ",", "\n", "max", "(", "\n", "intervals_per_category", "[", "\"human\"", "]", "[", "\"max\"", "]", ",", "\n", "intervals_per_category", "[", "\"vehicle\"", "]", "[", "\"max\"", "]", ",", "\n", ")", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "area_filtered_coco", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "area_filtered_coco", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "area_filtered_coco", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "area_filtered_coco", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n", "\n", "intervals_per_category", "=", "{", "\n", "\"human\"", ":", "{", "\"min\"", ":", "20", ",", "\"max\"", ":", "10000", "}", ",", "\n", "\"vehicle\"", ":", "{", "\"min\"", ":", "50", ",", "\"max\"", ":", "15000", "}", ",", "\n", "}", "\n", "area_filtered_coco", "=", "coco", ".", "get_area_filtered_coco", "(", "intervals_per_category", "=", "intervals_per_category", ")", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "50", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "len", "(", "area_filtered_coco", ".", "json", "[", "\"images\"", "]", ")", ",", "\n", "24", ",", "\n", ")", "\n", "self", ".", "assertGreater", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"min_annotation_area\"", "]", ",", "\n", "min", "(", "\n", "intervals_per_category", "[", "\"human\"", "]", "[", "\"min\"", "]", ",", "\n", "intervals_per_category", "[", "\"vehicle\"", "]", "[", "\"min\"", "]", ",", "\n", ")", ",", "\n", ")", "\n", "self", ".", "assertLess", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"max_annotation_area\"", "]", ",", "\n", "max", "(", "\n", "intervals_per_category", "[", "\"human\"", "]", "[", "\"max\"", "]", ",", "\n", "intervals_per_category", "[", "\"vehicle\"", "]", "[", "\"max\"", "]", ",", "\n", ")", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "\n", "area_filtered_coco", ".", "image_dir", ",", "\n", "image_dir", ",", "\n", ")", "\n", "self", ".", "assertEqual", "(", "area_filtered_coco", ".", "stats", "[", "\"num_images\"", "]", ",", "len", "(", "area_filtered_coco", ".", "images", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "area_filtered_coco", ".", "stats", "[", "\"num_annotations\"", "]", ",", "\n", "len", "(", "area_filtered_coco", ".", "json", "[", "\"annotations\"", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_export_coco_as_yolov5": [[814, 824], ["os.path.isdir", "Coco.from_coco_dict_or_path", "export_coco_as_yolov5", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.export_coco_as_yolov5"], ["", "def", "test_export_coco_as_yolov5", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", ",", "export_coco_as_yolov5", "\n", "\n", "coco_dict_path", "=", "\"tests/data/coco_utils/combined_coco.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "output_dir", "=", "\"tests/data/export_coco_as_yolov5/\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_dict_path", ",", "image_dir", "=", "image_dir", ")", "\n", "export_coco_as_yolov5", "(", "output_dir", "=", "output_dir", ",", "train_coco", "=", "coco", ",", "val_coco", "=", "coco", ",", "numpy_seed", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_cocovid": [[825, 827], ["None"], "methods", ["None"], ["", "def", "test_cocovid", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "CocoVid", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_cocoutils.TestCocoUtils.test_bbox_clipping": [[830, 877], ["Coco", "Coco.add_category", "CocoImage", "CocoImage", "CocoAnnotation", "CocoAnnotation", "CocoAnnotation", "CocoAnnotation", "CocoAnnotation", "CocoAnnotation", "CocoAnnotation", "CocoImage.add_annotation", "CocoImage.add_annotation", "CocoImage.add_annotation", "CocoImage.add_annotation", "CocoImage.add_annotation", "CocoImage.add_annotation", "CocoImage.add_annotation", "Coco.add_image", "Coco.add_image", "Coco.get_coco_with_clipped_bboxes", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertEqual", "test_cocoutils.TestCocoUtils.assertIsNotNone", "test_cocoutils.TestCocoUtils.assertEqual", "CocoCategory", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVid.add_category", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.CocoVidImage.add_annotation", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.add_image", "home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.get_coco_with_clipped_bboxes"], ["", "def", "test_bbox_clipping", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "utils", ".", "coco", "import", "Coco", ",", "CocoAnnotation", ",", "CocoCategory", ",", "CocoImage", "\n", "\n", "coco", "=", "Coco", "(", ")", "\n", "coco", ".", "add_category", "(", "CocoCategory", "(", "id", "=", "0", ",", "name", "=", "\"box\"", ",", "supercategory", "=", "\"box\"", ")", ")", "\n", "cocoimg", "=", "CocoImage", "(", "file_name", "=", "\"bboxes.jpg\"", ",", "height", "=", "100", ",", "width", "=", "100", ")", "\n", "cocoimg2", "=", "CocoImage", "(", "file_name", "=", "\"sample_photo.png\"", ",", "height", "=", "1080", ",", "width", "=", "1920", ")", "# negative img", "\n", "cocoann", "=", "CocoAnnotation", "(", "\n", "bbox", "=", "[", "60", ",", "20", ",", "10", ",", "70", "]", ",", "category_id", "=", "0", ",", "category_name", "=", "\"box\"", ",", "image_id", "=", "1", "\n", ")", "# bbox totally inside img", "\n", "cocoann2", "=", "CocoAnnotation", "(", "\n", "bbox", "=", "[", "120", ",", "110", ",", "60", ",", "30", "]", ",", "category_id", "=", "0", ",", "category_name", "=", "\"box\"", ",", "image_id", "=", "1", "\n", ")", "# bbox totally outside img", "\n", "cocoann3", "=", "CocoAnnotation", "(", "bbox", "=", "[", "-", "50", ",", "-", "20", ",", "80", ",", "80", "]", ",", "category_id", "=", "0", ",", "category_name", "=", "\"box\"", ",", "image_id", "=", "1", ")", "# x<0   y<0", "\n", "cocoann4", "=", "CocoAnnotation", "(", "\n", "bbox", "=", "[", "50", ",", "-", "50", ",", "60", ",", "60", "]", ",", "category_id", "=", "0", ",", "category_name", "=", "\"box\"", ",", "image_id", "=", "1", "\n", ")", "#  y<0   x+w > imwidth", "\n", "cocoann5", "=", "CocoAnnotation", "(", "\n", "bbox", "=", "[", "-", "50", ",", "50", ",", "70", ",", "70", "]", ",", "category_id", "=", "0", ",", "category_name", "=", "\"box\"", ",", "image_id", "=", "1", "\n", ")", "#  x<0   y+h > imheight", "\n", "cocoann6", "=", "CocoAnnotation", "(", "\n", "bbox", "=", "[", "80", ",", "80", ",", "50", ",", "50", "]", ",", "category_id", "=", "0", ",", "category_name", "=", "\"box\"", ",", "image_id", "=", "1", "\n", ")", "# x+w > imwidth y+h > imheight", "\n", "cocoann7", "=", "CocoAnnotation", "(", "\n", "bbox", "=", "[", "-", "70", ",", "-", "70", ",", "200", ",", "200", "]", ",", "category_id", "=", "0", ",", "category_name", "=", "\"box\"", ",", "image_id", "=", "1", "\n", ")", "# bbox totally enclosing img", "\n", "\n", "cocoimg", ".", "add_annotation", "(", "cocoann", ")", "\n", "cocoimg", ".", "add_annotation", "(", "cocoann2", ")", "\n", "cocoimg", ".", "add_annotation", "(", "cocoann3", ")", "\n", "cocoimg", ".", "add_annotation", "(", "cocoann4", ")", "\n", "cocoimg", ".", "add_annotation", "(", "cocoann5", ")", "\n", "cocoimg", ".", "add_annotation", "(", "cocoann6", ")", "\n", "cocoimg", ".", "add_annotation", "(", "cocoann7", ")", "\n", "coco", ".", "add_image", "(", "cocoimg", ")", "\n", "coco", ".", "add_image", "(", "cocoimg2", ")", "\n", "\n", "coco_with_clipped_bboxes", "=", "coco", ".", "get_coco_with_clipped_bboxes", "(", ")", "\n", "\n", "self", ".", "assertEqual", "(", "coco_with_clipped_bboxes", ".", "images", "[", "0", "]", ".", "annotations", "[", "0", "]", ".", "bbox", ",", "[", "60", ",", "20", ",", "10", ",", "70", "]", ")", "\n", "self", ".", "assertEqual", "(", "coco_with_clipped_bboxes", ".", "images", "[", "0", "]", ".", "annotations", "[", "1", "]", ".", "bbox", ",", "[", "0", ",", "0", ",", "30", ",", "60", "]", ")", "\n", "self", ".", "assertEqual", "(", "coco_with_clipped_bboxes", ".", "images", "[", "0", "]", ".", "annotations", "[", "2", "]", ".", "bbox", ",", "[", "50", ",", "0", ",", "50", ",", "10", "]", ")", "\n", "self", ".", "assertEqual", "(", "coco_with_clipped_bboxes", ".", "images", "[", "0", "]", ".", "annotations", "[", "3", "]", ".", "bbox", ",", "[", "0", ",", "50", ",", "20", ",", "50", "]", ")", "\n", "self", ".", "assertEqual", "(", "coco_with_clipped_bboxes", ".", "images", "[", "0", "]", ".", "annotations", "[", "4", "]", ".", "bbox", ",", "[", "80", ",", "80", ",", "20", ",", "20", "]", ")", "\n", "self", ".", "assertEqual", "(", "coco_with_clipped_bboxes", ".", "images", "[", "0", "]", ".", "annotations", "[", "5", "]", ".", "bbox", ",", "[", "0", ",", "0", ",", "100", ",", "100", "]", ")", "\n", "self", ".", "assertIsNotNone", "(", "coco_with_clipped_bboxes", ".", "images", "[", "1", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_with_clipped_bboxes", ".", "images", "[", "1", "]", ".", "annotations", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_yolov5model.TestYolov5DetectionModel.test_load_model": [[17, 31], ["sahi.utils.yolov5.download_yolov5n_model", "Yolov5DetectionModel", "test_yolov5model.TestYolov5DetectionModel.assertNotEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model"], ["    ", "def", "test_load_model", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "Yolov5DetectionModel", "\n", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "yolov5_detection_model", "=", "Yolov5DetectionModel", "(", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "assertNotEqual", "(", "yolov5_detection_model", ".", "model", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_yolov5model.TestYolov5DetectionModel.test_set_model": [[32, 50], ["sahi.utils.yolov5.download_yolov5n_model", "yolov5.load", "Yolov5DetectionModel", "test_yolov5model.TestYolov5DetectionModel.assertNotEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model"], ["", "def", "test_set_model", "(", "self", ")", ":", "\n", "        ", "import", "yolov5", "\n", "\n", "from", "sahi", ".", "model", "import", "Yolov5DetectionModel", "\n", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "yolo_model", "=", "yolov5", ".", "load", "(", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ")", "\n", "\n", "yolov5_detection_model", "=", "Yolov5DetectionModel", "(", "\n", "model", "=", "yolo_model", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "assertNotEqual", "(", "yolov5_detection_model", ".", "model", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_yolov5model.TestYolov5DetectionModel.test_perform_inference": [[51, 91], ["sahi.utils.yolov5.download_yolov5n_model", "Yolov5DetectionModel", "sahi.utils.cv.read_image", "Yolov5DetectionModel.perform_inference", "list", "enumerate", "test_yolov5model.TestYolov5DetectionModel.assertEqual", "map", "len", "test_yolov5model.TestYolov5DetectionModel.assertGreaterEqual", "box[].item", "box[].tolist", "box[].item", "box[].item"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.postprocess.utils.ObjectPredictionList.tolist"], ["", "def", "test_perform_inference", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "Yolov5DetectionModel", "\n", "\n", "# init model", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "yolov5_detection_model", "=", "Yolov5DetectionModel", "(", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "yolov5_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "original_predictions", "=", "yolov5_detection_model", ".", "original_predictions", "\n", "\n", "boxes", "=", "original_predictions", ".", "xyxy", "\n", "\n", "# find box of first car detection with conf greater than 0.5", "\n", "for", "box", "in", "boxes", "[", "0", "]", ":", "\n", "            ", "if", "box", "[", "5", "]", ".", "item", "(", ")", "==", "2", ":", "# if category car", "\n", "                ", "if", "box", "[", "4", "]", ".", "item", "(", ")", ">", "0.5", ":", "\n", "                    ", "break", "\n", "\n", "# compare", "\n", "", "", "", "desired_bbox", "=", "[", "321", ",", "329", ",", "378", ",", "368", "]", "\n", "predicted_bbox", "=", "list", "(", "map", "(", "int", ",", "box", "[", ":", "4", "]", ".", "tolist", "(", ")", ")", ")", "\n", "margin", "=", "2", "\n", "for", "ind", ",", "point", "in", "enumerate", "(", "predicted_bbox", ")", ":", "\n", "            ", "assert", "point", "<", "desired_bbox", "[", "ind", "]", "+", "margin", "and", "point", ">", "desired_bbox", "[", "ind", "]", "-", "margin", "\n", "", "self", ".", "assertEqual", "(", "len", "(", "original_predictions", ".", "names", ")", ",", "80", ")", "\n", "for", "box", "in", "boxes", "[", "0", "]", ":", "\n", "            ", "self", ".", "assertGreaterEqual", "(", "box", "[", "4", "]", ".", "item", "(", ")", ",", "CONFIDENCE_THRESHOLD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_yolov5model.TestYolov5DetectionModel.test_convert_original_predictions": [[92, 136], ["sahi.utils.yolov5.download_yolov5n_model", "Yolov5DetectionModel", "sahi.utils.cv.read_image", "Yolov5DetectionModel.perform_inference", "Yolov5DetectionModel.convert_original_predictions", "test_yolov5model.TestYolov5DetectionModel.assertEqual", "test_yolov5model.TestYolov5DetectionModel.assertEqual", "test_yolov5model.TestYolov5DetectionModel.assertEqual", "object_prediction_list[].bbox.to_coco_bbox", "enumerate", "test_yolov5model.TestYolov5DetectionModel.assertEqual", "test_yolov5model.TestYolov5DetectionModel.assertEqual", "object_prediction_list[].bbox.to_coco_bbox", "enumerate", "len", "test_yolov5model.TestYolov5DetectionModel.assertGreaterEqual"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.yolov5.download_yolov5n_model", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.TorchVisionDetectionModel.perform_inference", "home.repos.pwc.inspect_result.obss_sahi.sahi.model.DetectionModel.convert_original_predictions", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox", "home.repos.pwc.inspect_result.obss_sahi.utils.shapely.ShapelyAnnotation.to_coco_bbox"], ["", "", "def", "test_convert_original_predictions", "(", "self", ")", ":", "\n", "        ", "from", "sahi", ".", "model", "import", "Yolov5DetectionModel", "\n", "\n", "# init model", "\n", "download_yolov5n_model", "(", ")", "\n", "\n", "yolov5_detection_model", "=", "Yolov5DetectionModel", "(", "\n", "model_path", "=", "Yolov5TestConstants", ".", "YOLOV5N_MODEL_PATH", ",", "\n", "confidence_threshold", "=", "CONFIDENCE_THRESHOLD", ",", "\n", "device", "=", "MODEL_DEVICE", ",", "\n", "category_remapping", "=", "None", ",", "\n", "load_at_init", "=", "True", ",", "\n", "image_size", "=", "IMAGE_SIZE", ",", "\n", ")", "\n", "\n", "# prepare image", "\n", "image_path", "=", "\"tests/data/small-vehicles1.jpeg\"", "\n", "image", "=", "read_image", "(", "image_path", ")", "\n", "\n", "# perform inference", "\n", "yolov5_detection_model", ".", "perform_inference", "(", "image", ")", "\n", "\n", "# convert predictions to ObjectPrediction list", "\n", "yolov5_detection_model", ".", "convert_original_predictions", "(", ")", "\n", "object_prediction_list", "=", "yolov5_detection_model", ".", "object_prediction_list", "\n", "\n", "# compare", "\n", "self", ".", "assertEqual", "(", "len", "(", "object_prediction_list", ")", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "0", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "desired_bbox", "=", "[", "321", ",", "329", ",", "57", ",", "39", "]", "\n", "predicted_bbox", "=", "object_prediction_list", "[", "0", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", "\n", "margin", "=", "2", "\n", "for", "ind", ",", "point", "in", "enumerate", "(", "predicted_bbox", ")", ":", "\n", "            ", "assert", "point", "<", "desired_bbox", "[", "ind", "]", "+", "margin", "and", "point", ">", "desired_bbox", "[", "ind", "]", "-", "margin", "\n", "", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "2", "]", ".", "category", ".", "id", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "object_prediction_list", "[", "2", "]", ".", "category", ".", "name", ",", "\"car\"", ")", "\n", "desired_bbox", "=", "[", "381", ",", "275", ",", "42", ",", "28", "]", "\n", "predicted_bbox", "=", "object_prediction_list", "[", "2", "]", ".", "bbox", ".", "to_coco_bbox", "(", ")", "\n", "for", "ind", ",", "point", "in", "enumerate", "(", "predicted_bbox", ")", ":", "\n", "            ", "assert", "point", "<", "desired_bbox", "[", "ind", "]", "+", "margin", "and", "point", ">", "desired_bbox", "[", "ind", "]", "-", "margin", "\n", "\n", "", "for", "object_prediction", "in", "object_prediction_list", ":", "\n", "            ", "self", ".", "assertGreaterEqual", "(", "object_prediction", ".", "score", ".", "value", ",", "CONFIDENCE_THRESHOLD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_slicing.TestSlicing.test_slice_image": [[15, 92], ["sahi.utils.coco.Coco.from_coco_dict_or_path", "sahi.slicing.slice_image", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "sahi.utils.cv.read_image", "sahi.slicing.slice_image", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "PIL.Image.open", "sahi.slicing.slice_image", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.utils.coco.Coco.from_coco_dict_or_path", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_image", "home.repos.pwc.inspect_result.obss_sahi.utils.cv.read_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_image", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_image"], ["    ", "def", "test_slice_image", "(", "self", ")", ":", "\n", "# read coco file", "\n", "        ", "coco_path", "=", "\"tests/data/coco_utils/terrain1_coco.json\"", "\n", "coco", "=", "Coco", ".", "from_coco_dict_or_path", "(", "coco_path", ")", "\n", "\n", "output_file_name", "=", "None", "\n", "output_dir", "=", "None", "\n", "image_path", "=", "\"tests/data/coco_utils/\"", "+", "coco", ".", "images", "[", "0", "]", ".", "file_name", "\n", "slice_image_result", "=", "slice_image", "(", "\n", "image", "=", "image_path", ",", "\n", "coco_annotation_list", "=", "coco", ".", "images", "[", "0", "]", ".", "annotations", ",", "\n", "output_file_name", "=", "output_file_name", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "overlap_height_ratio", "=", "0.1", ",", "\n", "overlap_width_ratio", "=", "0.4", ",", "\n", "min_area_ratio", "=", "0.1", ",", "\n", "out_ext", "=", "\".png\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "slice_image_result", ".", "images", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slice_image_result", ".", "coco_images", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "slice_image_result", ".", "coco_images", "[", "0", "]", ".", "annotations", ",", "[", "]", ")", "\n", "self", ".", "assertEqual", "(", "slice_image_result", ".", "coco_images", "[", "15", "]", ".", "annotations", "[", "1", "]", ".", "area", ",", "7296", ")", "\n", "self", ".", "assertEqual", "(", "\n", "slice_image_result", ".", "coco_images", "[", "15", "]", ".", "annotations", "[", "1", "]", ".", "bbox", ",", "\n", "[", "17", ",", "186", ",", "48", ",", "152", "]", ",", "\n", ")", "\n", "\n", "image_cv", "=", "read_image", "(", "image_path", ")", "\n", "slice_image_result", "=", "slice_image", "(", "\n", "image", "=", "image_cv", ",", "\n", "coco_annotation_list", "=", "coco", ".", "images", "[", "0", "]", ".", "annotations", ",", "\n", "output_file_name", "=", "output_file_name", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "overlap_height_ratio", "=", "0.1", ",", "\n", "overlap_width_ratio", "=", "0.4", ",", "\n", "min_area_ratio", "=", "0.1", ",", "\n", "out_ext", "=", "\".png\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "slice_image_result", ".", "images", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slice_image_result", ".", "coco_images", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "slice_image_result", ".", "coco_images", "[", "0", "]", ".", "annotations", ",", "[", "]", ")", "\n", "self", ".", "assertEqual", "(", "slice_image_result", ".", "coco_images", "[", "15", "]", ".", "annotations", "[", "1", "]", ".", "area", ",", "7296", ")", "\n", "self", ".", "assertEqual", "(", "\n", "slice_image_result", ".", "coco_images", "[", "15", "]", ".", "annotations", "[", "1", "]", ".", "bbox", ",", "\n", "[", "17", ",", "186", ",", "48", ",", "152", "]", ",", "\n", ")", "\n", "\n", "image_pil", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "slice_image_result", "=", "slice_image", "(", "\n", "image", "=", "image_pil", ",", "\n", "coco_annotation_list", "=", "coco", ".", "images", "[", "0", "]", ".", "annotations", ",", "\n", "output_file_name", "=", "output_file_name", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "overlap_height_ratio", "=", "0.1", ",", "\n", "overlap_width_ratio", "=", "0.4", ",", "\n", "min_area_ratio", "=", "0.1", ",", "\n", "out_ext", "=", "\".png\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "slice_image_result", ".", "images", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slice_image_result", ".", "coco_images", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "slice_image_result", ".", "coco_images", "[", "0", "]", ".", "annotations", ",", "[", "]", ")", "\n", "self", ".", "assertEqual", "(", "slice_image_result", ".", "coco_images", "[", "15", "]", ".", "annotations", "[", "1", "]", ".", "area", ",", "7296", ")", "\n", "self", ".", "assertEqual", "(", "\n", "slice_image_result", ".", "coco_images", "[", "15", "]", ".", "annotations", "[", "1", "]", ".", "bbox", ",", "\n", "[", "17", ",", "186", ",", "48", ",", "152", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.obss_sahi.tests.test_slicing.TestSlicing.test_slice_coco": [[94, 166], ["sahi.slicing.slice_coco", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "shutil.rmtree", "sahi.slicing.slice_coco", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "test_slicing.TestSlicing.assertEqual", "shutil.rmtree", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_coco", "home.repos.pwc.inspect_result.obss_sahi.sahi.slicing.slice_coco"], ["", "def", "test_slice_coco", "(", "self", ")", ":", "\n", "        ", "import", "shutil", "\n", "\n", "coco_annotation_file_path", "=", "\"tests/data/coco_utils/terrain1_coco.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "output_coco_annotation_file_name", "=", "\"test_out\"", "\n", "output_dir", "=", "\"tests/data/coco_utils/test_out/\"", "\n", "ignore_negative_samples", "=", "True", "\n", "coco_dict", ",", "_", "=", "slice_coco", "(", "\n", "coco_annotation_file_path", "=", "coco_annotation_file_path", ",", "\n", "image_dir", "=", "image_dir", ",", "\n", "output_coco_annotation_file_name", "=", "output_coco_annotation_file_name", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "ignore_negative_samples", "=", "ignore_negative_samples", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "overlap_height_ratio", "=", "0.1", ",", "\n", "overlap_width_ratio", "=", "0.4", ",", "\n", "min_area_ratio", "=", "0.1", ",", "\n", "out_ext", "=", "\".png\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict", "[", "\"images\"", "]", ")", ",", "5", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"images\"", "]", "[", "1", "]", "[", "\"height\"", "]", ",", "512", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"images\"", "]", "[", "1", "]", "[", "\"width\"", "]", ",", "512", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict", "[", "\"annotations\"", "]", ")", ",", "14", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"id\"", "]", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"image_id\"", "]", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"category_id\"", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"area\"", "]", ",", "12483", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"bbox\"", "]", ",", "\n", "[", "340", ",", "204", ",", "73", ",", "171", "]", ",", "\n", ")", "\n", "\n", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "\n", "coco_annotation_file_path", "=", "\"tests/data/coco_utils/terrain1_coco.json\"", "\n", "image_dir", "=", "\"tests/data/coco_utils/\"", "\n", "output_coco_annotation_file_name", "=", "\"test_out\"", "\n", "output_dir", "=", "\"tests/data/coco_utils/test_out/\"", "\n", "ignore_negative_samples", "=", "False", "\n", "coco_dict", ",", "_", "=", "slice_coco", "(", "\n", "coco_annotation_file_path", "=", "coco_annotation_file_path", ",", "\n", "image_dir", "=", "image_dir", ",", "\n", "output_coco_annotation_file_name", "=", "output_coco_annotation_file_name", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "ignore_negative_samples", "=", "ignore_negative_samples", ",", "\n", "slice_height", "=", "512", ",", "\n", "slice_width", "=", "512", ",", "\n", "overlap_height_ratio", "=", "0.1", ",", "\n", "overlap_width_ratio", "=", "0.4", ",", "\n", "min_area_ratio", "=", "0.1", ",", "\n", "out_ext", "=", "\".png\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict", "[", "\"images\"", "]", ")", ",", "18", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"images\"", "]", "[", "1", "]", "[", "\"height\"", "]", ",", "512", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"images\"", "]", "[", "1", "]", "[", "\"width\"", "]", ",", "512", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "coco_dict", "[", "\"annotations\"", "]", ")", ",", "14", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"id\"", "]", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"image_id\"", "]", ",", "14", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"category_id\"", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"area\"", "]", ",", "12483", ")", "\n", "self", ".", "assertEqual", "(", "\n", "coco_dict", "[", "\"annotations\"", "]", "[", "2", "]", "[", "\"bbox\"", "]", ",", "\n", "[", "340", ",", "204", ",", "73", ",", "171", "]", ",", "\n", ")", "\n", "\n", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "\n"]]}