{"home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.__init__": [[9, 22], ["tensorflow.keras.layers.Layer.__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "ValueError"], "methods", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.BahdanauAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", "=", "8", ")", ":", "\n", "        ", "super", "(", "MultiHeadSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "if", "embed_dim", "%", "num_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"", "\n", ")", "\n", "", "self", ".", "projection_dim", "=", "embed_dim", "//", "num_heads", "\n", "self", ".", "query_dense", "=", "layers", ".", "Dense", "(", "embed_dim", ")", "\n", "self", ".", "key_dense", "=", "layers", ".", "Dense", "(", "embed_dim", ")", "\n", "self", ".", "value_dense", "=", "layers", ".", "Dense", "(", "embed_dim", ")", "\n", "self", ".", "combine_heads", "=", "layers", ".", "Dense", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.attention": [[23, 30], ["tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.math.sqrt", "tensorflow.shape"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "query", ",", "key", ",", "value", ")", ":", "\n", "        ", "score", "=", "tf", ".", "matmul", "(", "query", ",", "key", ",", "transpose_b", "=", "True", ")", "\n", "dim_key", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "key", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "scaled_score", "=", "score", "/", "tf", ".", "math", ".", "sqrt", "(", "dim_key", ")", "\n", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scaled_score", ",", "axis", "=", "-", "1", ")", "\n", "output", "=", "tf", ".", "matmul", "(", "weights", ",", "value", ")", "\n", "return", "output", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.separate_heads": [[31, 34], ["tensorflow.reshape", "tensorflow.transpose"], "methods", ["None"], ["", "def", "separate_heads", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_heads", ",", "self", ".", "projection_dim", ")", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.call": [[35, 61], ["models.MultiHeadSelfAttention.query_dense", "models.MultiHeadSelfAttention.key_dense", "models.MultiHeadSelfAttention.value_dense", "models.MultiHeadSelfAttention.separate_heads", "models.MultiHeadSelfAttention.separate_heads", "models.MultiHeadSelfAttention.separate_heads", "models.MultiHeadSelfAttention.attention", "tensorflow.transpose", "tensorflow.reshape", "models.MultiHeadSelfAttention.combine_heads", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.separate_heads", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.separate_heads", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.separate_heads", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.MultiHeadSelfAttention.attention"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "# x.shape = [batch_size, seq_len, embedding_dim]", "\n", "        ", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "query", "=", "self", ".", "query_dense", "(", "inputs", ")", "# (batch_size, seq_len, embed_dim)", "\n", "key", "=", "self", ".", "key_dense", "(", "inputs", ")", "# (batch_size, seq_len, embed_dim)", "\n", "value", "=", "self", ".", "value_dense", "(", "inputs", ")", "# (batch_size, seq_len, embed_dim)", "\n", "query", "=", "self", ".", "separate_heads", "(", "\n", "query", ",", "batch_size", "\n", ")", "# (batch_size, num_heads, seq_len, projection_dim)", "\n", "key", "=", "self", ".", "separate_heads", "(", "\n", "key", ",", "batch_size", "\n", ")", "# (batch_size, num_heads, seq_len, projection_dim)", "\n", "value", "=", "self", ".", "separate_heads", "(", "\n", "value", ",", "batch_size", "\n", ")", "# (batch_size, num_heads, seq_len, projection_dim)", "\n", "attention", ",", "weights", "=", "self", ".", "attention", "(", "query", ",", "key", ",", "value", ")", "\n", "attention", "=", "tf", ".", "transpose", "(", "\n", "attention", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", "\n", ")", "# (batch_size, seq_len, num_heads, projection_dim)", "\n", "concat_attention", "=", "tf", ".", "reshape", "(", "\n", "attention", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "embed_dim", ")", "\n", ")", "# (batch_size, seq_len, embed_dim)", "\n", "output", "=", "self", ".", "combine_heads", "(", "\n", "concat_attention", "\n", ")", "# (batch_size, seq_len, embed_dim)", "\n", "return", "output", "\n", "", "", "class", "TransformerBlock", "(", "layers", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.TransformerBlock.__init__": [[62, 72], ["tensorflow.keras.layers.Layer.__init__", "models.MultiHeadSelfAttention", "tensorflow.keras.Sequential", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.BahdanauAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "ff_dim", ",", "rate", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "TransformerBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "att", "=", "MultiHeadSelfAttention", "(", "embed_dim", ",", "num_heads", ")", "\n", "self", ".", "ffn", "=", "keras", ".", "Sequential", "(", "\n", "[", "layers", ".", "Dense", "(", "ff_dim", ",", "activation", "=", "\"relu\"", ")", ",", "layers", ".", "Dense", "(", "embed_dim", ")", ",", "]", "\n", ")", "\n", "self", ".", "layernorm1", "=", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-6", ")", "\n", "self", ".", "layernorm2", "=", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-6", ")", "\n", "self", ".", "dropout1", "=", "layers", ".", "Dropout", "(", "rate", ")", "\n", "self", ".", "dropout2", "=", "layers", ".", "Dropout", "(", "rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.TransformerBlock.call": [[73, 80], ["models.TransformerBlock.att", "models.TransformerBlock.dropout1", "models.TransformerBlock.layernorm1", "models.TransformerBlock.ffn", "models.TransformerBlock.dropout2", "models.TransformerBlock.layernorm2"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", ")", ":", "\n", "        ", "attn_output", "=", "self", ".", "att", "(", "inputs", ")", "\n", "attn_output", "=", "self", ".", "dropout1", "(", "attn_output", ",", "training", "=", "training", ")", "\n", "out1", "=", "self", ".", "layernorm1", "(", "inputs", "+", "attn_output", ")", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "out1", ")", "\n", "ffn_output", "=", "self", ".", "dropout2", "(", "ffn_output", ",", "training", "=", "training", ")", "\n", "return", "self", ".", "layernorm2", "(", "out1", "+", "ffn_output", ")", "\n", "", "", "class", "BahdanauAttention", "(", "tf", ".", "keras", ".", "layers", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.BahdanauAttention.__init__": [[81, 86], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.BahdanauAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "units", ")", ":", "\n", "        ", "super", "(", "BahdanauAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "units", ")", "\n", "self", ".", "W2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "units", ")", "\n", "self", ".", "V", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.BahdanauAttention.get_config": [[87, 95], ["super().get_config().copy", "super().get_config().copy.update", "super().get_config"], "methods", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.BahdanauAttention.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", ".", "copy", "(", ")", "\n", "config", ".", "update", "(", "{", "\n", "'W1'", ":", "self", ".", "W1", ",", "\n", "'W2'", ":", "self", ".", "W2", ",", "\n", "'V'", ":", "self", ".", "V", "\n", "}", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.BahdanauAttention.call": [[96, 117], ["tensorflow.expand_dims", "models.BahdanauAttention.V", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.nn.tanh", "models.BahdanauAttention.W1", "models.BahdanauAttention.W2"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "values", ",", "query", ")", ":", "\n", "# query hidden state shape == (batch_size, hidden size)", "\n", "# query_with_time_axis shape == (batch_size, 1, hidden size)", "\n", "# values shape == (batch_size, max_len, hidden size)", "\n", "# we are doing this to broadcast addition along the time axis to calculate the score", "\n", "        ", "query_with_time_axis", "=", "tf", ".", "expand_dims", "(", "query", ",", "1", ")", "\n", "\n", "# score shape == (batch_size, max_length, 1)", "\n", "# we get 1 at the last axis because we are applying score to self.V", "\n", "# the shape of the tensor before applying self.V is (batch_size, max_length, units)", "\n", "score", "=", "self", ".", "V", "(", "tf", ".", "nn", ".", "tanh", "(", "\n", "self", ".", "W1", "(", "query_with_time_axis", ")", "+", "self", ".", "W2", "(", "values", ")", ")", ")", "\n", "\n", "# attention_weights shape == (batch_size, max_length, 1)", "\n", "attention_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "score", ",", "axis", "=", "1", ")", "\n", "\n", "# context_vector shape after sum == (batch_size, hidden_size)", "\n", "context_vector", "=", "attention_weights", "*", "values", "\n", "context_vector", "=", "tf", ".", "reduce_sum", "(", "context_vector", ",", "axis", "=", "1", ")", "\n", "\n", "return", "context_vector", ",", "attention_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.flatten_layers": [[118, 124], ["isinstance", "models.flatten_layers"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.flatten_layers"], ["", "", "def", "flatten_layers", "(", "root_layer", ")", ":", "\n", "    ", "if", "isinstance", "(", "root_layer", ",", "tf", ".", "keras", ".", "layers", ".", "Layer", ")", ":", "\n", "        ", "yield", "root_layer", "\n", "", "for", "layer", "in", "root_layer", ".", "_layers", ":", "\n", "        ", "for", "sub_layer", "in", "flatten_layers", "(", "layer", ")", ":", "\n", "            ", "yield", "sub_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.freeze_all_bert_layers": [[125, 137], ["None"], "function", ["None"], ["", "", "", "def", "freeze_all_bert_layers", "(", "l_bert", ")", ":", "\n", "    ", "\"\"\"\n    Freezes all but LayerNorm and adapter layers - see arXiv:1902.00751.\n    \"\"\"", "\n", "l_bert", ".", "trainable", "=", "False", "\n", "l_bert", ".", "encoders_layer", ".", "trainable", "=", "False", "\n", "\n", "for", "layer", "in", "l_bert", ".", "submodules", ":", "\n", "        ", "if", "layer", ".", "name", "in", "[", "\"LayerNorm\"", ",", "\"adapter-down\"", ",", "\"adapter-up\"", "]", ":", "\n", "            ", "layer", ".", "trainable", "=", "True", "\n", "", "else", ":", "\n", "            ", "layer", ".", "trainable", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.freeze_bert_layers": [[138, 150], ["models.flatten_layers"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.flatten_layers"], ["", "", "", "def", "freeze_bert_layers", "(", "l_bert", ")", ":", "\n", "    ", "\"\"\"\n    Freezes all but LayerNorm and adapter layers - see arXiv:1902.00751.\n    \"\"\"", "\n", "for", "layer", "in", "flatten_layers", "(", "l_bert", ")", ":", "\n", "        ", "if", "layer", ".", "name", "in", "[", "\"LayerNorm\"", ",", "\"adapter-down\"", ",", "\"adapter-up\"", "]", ":", "\n", "            ", "layer", ".", "trainable", "=", "True", "\n", "# elif len(layer._layers) == 0:", "\n", "#     layer.trainable = False", "\n", "", "else", ":", "\n", "            ", "layer", ".", "trainable", "=", "False", "\n", "", "l_bert", ".", "embeddings_layer", ".", "trainable", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_gru_with_attention": [[151, 171], ["tensorflow.keras.layers.GRU", "models.BahdanauAttention", "tf.keras.layers.GRU.", "BahdanauAttention.", "tensorflow.keras.layers.GRU", "tf.keras.layers.GRU."], "function", ["None"], ["", "", "def", "encode_gru_with_attention", "(", "config", ",", "input", ")", ":", "\n", "    ", "if", "config", "[", "\"text_use_attention\"", "]", ":", "\n", "        ", "gru_forward", "=", "tf", ".", "keras", ".", "layers", ".", "GRU", "(", "config", "[", "\"rnn_layer_size\"", "]", ",", "return_sequences", "=", "True", ",", "return_state", "=", "True", ",", "\n", "activation", "=", "'relu'", ")", "\n", "\n", "attention_layer", "=", "BahdanauAttention", "(", "config", "[", "\"text_attention_size\"", "]", ")", "\n", "\n", "# apply forward GRU, attention", "\n", "forward_seq", ",", "forward_hidden_state", "=", "gru_forward", "(", "input", ")", "\n", "forward_attention_result", ",", "forward_attention_weights", "=", "attention_layer", "(", "forward_seq", ",", "forward_hidden_state", ")", "\n", "\n", "# concatenate attention results", "\n", "text_encoding", "=", "forward_attention_result", "\n", "", "else", ":", "\n", "        ", "gru_forward", "=", "tf", ".", "keras", ".", "layers", ".", "GRU", "(", "config", "[", "\"rnn_layer_size\"", "]", ",", "activation", "=", "'relu'", ")", "\n", "\n", "# apply forward GRU, attention", "\n", "text_encoding", "=", "gru_forward", "(", "input", ")", "\n", "\n", "", "return", "text_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_lstm_with_attention": [[172, 192], ["tensorflow.keras.layers.LSTM", "models.BahdanauAttention", "tf.keras.layers.LSTM.", "BahdanauAttention.", "tensorflow.keras.layers.LSTM", "tf.keras.layers.LSTM."], "function", ["None"], ["", "def", "encode_lstm_with_attention", "(", "config", ",", "input", ")", ":", "\n", "    ", "if", "config", "[", "\"text_use_attention\"", "]", ":", "\n", "        ", "lstm_forward", "=", "tf", ".", "keras", ".", "layers", ".", "LSTM", "(", "config", "[", "\"rnn_layer_size\"", "]", ",", "return_sequences", "=", "True", ",", "return_state", "=", "True", ",", "\n", "activation", "=", "'tanh'", ")", "\n", "\n", "attention_layer", "=", "BahdanauAttention", "(", "config", "[", "\"text_attention_size\"", "]", ")", "\n", "\n", "# apply forward GRU, attention", "\n", "forward_seq", ",", "forward_hidden_state", ",", "forward_cell_state", "=", "lstm_forward", "(", "input", ")", "\n", "forward_attention_result", ",", "forward_attention_weights", "=", "attention_layer", "(", "forward_seq", ",", "forward_hidden_state", ")", "\n", "\n", "# concatenate attention results", "\n", "text_encoding", "=", "forward_attention_result", "\n", "", "else", ":", "\n", "        ", "lstm_forward", "=", "tf", ".", "keras", ".", "layers", ".", "LSTM", "(", "config", "[", "\"rnn_layer_size\"", "]", ")", "\n", "\n", "# apply forward GRU, attention", "\n", "text_encoding", "=", "lstm_forward", "(", "input", ")", "\n", "\n", "", "return", "text_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_bigru_with_attention": [[193, 224], ["tensorflow.keras.layers.GRU", "tensorflow.keras.layers.GRU", "models.BahdanauAttention", "tf.keras.layers.GRU.", "BahdanauAttention.", "tf.keras.layers.GRU.", "BahdanauAttention.", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.GRU", "tensorflow.keras.layers.GRU", "tf.keras.layers.GRU.", "tf.keras.layers.GRU.", "tensorflow.keras.layers.concatenate"], "function", ["None"], ["", "def", "encode_bigru_with_attention", "(", "config", ",", "input", ")", ":", "\n", "    ", "if", "config", "[", "\"text_use_attention\"", "]", ":", "\n", "        ", "gru_forward", "=", "tf", ".", "keras", ".", "layers", ".", "GRU", "(", "config", "[", "\"rnn_layer_size\"", "]", ",", "return_sequences", "=", "True", ",", "return_state", "=", "True", ",", "\n", "activation", "=", "'tanh'", ")", "\n", "gru_backward", "=", "tf", ".", "keras", ".", "layers", ".", "GRU", "(", "config", "[", "\"rnn_layer_size\"", "]", ",", "go_backwards", "=", "True", ",", "return_sequences", "=", "True", ",", "\n", "return_state", "=", "True", ",", "activation", "=", "'tanh'", ")", "\n", "\n", "attention_layer", "=", "BahdanauAttention", "(", "config", "[", "\"text_attention_size\"", "]", ")", "\n", "\n", "# apply forward GRU, attention", "\n", "forward_seq", ",", "forward_hidden_state", "=", "gru_forward", "(", "input", ")", "\n", "forward_attention_result", ",", "forward_attention_weights", "=", "attention_layer", "(", "forward_seq", ",", "forward_hidden_state", ")", "\n", "\n", "# apply backward GRU, attention", "\n", "backward_seq", ",", "backward_hidden_state", "=", "gru_backward", "(", "input", ")", "\n", "backward_attention_result", ",", "backward_attention_weights", "=", "attention_layer", "(", "backward_seq", ",", "backward_hidden_state", ")", "\n", "\n", "# concatenate attention results", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "concatenate", "(", "[", "backward_attention_result", ",", "forward_attention_result", "]", ")", "\n", "", "else", ":", "\n", "        ", "gru_forward", "=", "tf", ".", "keras", ".", "layers", ".", "GRU", "(", "config", "[", "\"rnn_layer_size\"", "]", ",", "activation", "=", "'tanh'", ")", "\n", "gru_backward", "=", "tf", ".", "keras", ".", "layers", ".", "GRU", "(", "config", "[", "\"rnn_layer_size\"", "]", ",", "go_backwards", "=", "True", ",", "activation", "=", "'tanh'", ")", "\n", "\n", "# apply forward GRU, attention", "\n", "forward_hidden_state", "=", "gru_forward", "(", "input", ")", "\n", "\n", "backward_hidden_state", "=", "gru_backward", "(", "input", ")", "\n", "\n", "# concatenate attention results", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "concatenate", "(", "[", "backward_hidden_state", ",", "forward_hidden_state", "]", ")", "\n", "", "return", "text_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_text_with_bert": [[225, 246], ["bert", "models.encode_gru_with_attention", "models.encode_lstm_with_attention", "models.encode_bigru_with_attention", "tensorflow.keras.layers.Convolution1D", "tensorflow.keras.layers.Convolution1D", "tensorflow.keras.layers.Convolution1D", "tensorflow.keras.layers.AvgPool1D", "tensorflow.keras.layers.Flatten"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_gru_with_attention", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_lstm_with_attention", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_bigru_with_attention"], ["", "def", "encode_text_with_bert", "(", "config", ",", "input_layer", ",", "bert", ")", ":", "\n", "    ", "bert_output", "=", "bert", "(", "input_layer", ")", "\n", "\n", "if", "config", "[", "\"rnn_type\"", "]", "==", "'gru'", ":", "\n", "        ", "text_encoding", "=", "encode_gru_with_attention", "(", "config", ",", "bert_output", ")", "\n", "", "elif", "config", "[", "\"rnn_type\"", "]", "==", "'lstm'", ":", "\n", "        ", "text_encoding", "=", "encode_lstm_with_attention", "(", "config", ",", "bert_output", ")", "\n", "", "elif", "config", "[", "\"rnn_type\"", "]", "==", "'bi-gru'", ":", "\n", "        ", "text_encoding", "=", "encode_bigru_with_attention", "(", "config", ",", "bert_output", ")", "\n", "", "else", ":", "\n", "        ", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Convolution1D", "(", "filters", "=", "100", ",", "kernel_size", "=", "5", ",", "padding", "=", "'same'", ",", "activation", "=", "'tanh'", ")", "(", "\n", "bert_output", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Convolution1D", "(", "filters", "=", "80", ",", "kernel_size", "=", "5", ",", "padding", "=", "'same'", ",", "activation", "=", "'tanh'", ")", "(", "\n", "text_encoding", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Convolution1D", "(", "filters", "=", "50", ",", "kernel_size", "=", "5", ",", "padding", "=", "'same'", ",", "activation", "=", "'tanh'", ")", "(", "\n", "text_encoding", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "AvgPool1D", "(", ")", "(", "text_encoding", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "(", "text_encoding", ")", "\n", "\n", "\n", "", "return", "text_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_text_with_hateword_list": [[247, 257], ["tensorflow.keras.layers.Dense", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation"], "function", ["None"], ["", "def", "encode_text_with_hateword_list", "(", "config", ",", "input_layer", ")", ":", "\n", "    ", "hate_words_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1493", ",", "name", "=", "\"hatewords_norm_layer_1\"", ")", "(", "input_layer", ")", "\n", "hate_words_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "hate_words_encoding", ")", "\n", "hate_words_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "\"relu\"", ")", "(", "hate_words_encoding", ")", "\n", "\n", "hate_words_encoding2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "512", ",", "name", "=", "\"hatewords_norm_layer_2\"", ")", "(", "hate_words_encoding", ")", "\n", "hate_words_encoding2", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "hate_words_encoding2", ")", "\n", "hate_words_encoding2", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "\"relu\"", ")", "(", "hate_words_encoding2", ")", "\n", "\n", "return", "hate_words_encoding2", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_text_with_char_embeddings": [[259, 281], ["tensorflow.keras.layers.Embedding", "tf.keras.layers.Embedding.", "models.encode_gru_with_attention", "models.encode_lstm_with_attention", "models.encode_bigru_with_attention", "tensorflow.keras.layers.Convolution1D", "tensorflow.keras.layers.Convolution1D", "tensorflow.keras.layers.Convolution1D", "tensorflow.keras.layers.AvgPool1D", "tensorflow.keras.layers.Flatten"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_gru_with_attention", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_lstm_with_attention", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_bigru_with_attention"], ["", "def", "encode_text_with_char_embeddings", "(", "config", ",", "input_layer", ")", ":", "\n", "    ", "char_embedding_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "input_dim", "=", "config", "[", "\"char_size\"", "]", ",", "trainable", "=", "True", ",", "output_dim", "=", "50", ",", "embeddings_initializer", "=", "'uniform'", ",", "name", "=", "\"char_embs\"", ")", "\n", "\n", "char_emb_out", "=", "char_embedding_layer", "(", "input_layer", ")", "\n", "\n", "if", "config", "[", "\"text_encoder\"", "]", "==", "'gru'", ":", "\n", "        ", "text_encoding", "=", "encode_gru_with_attention", "(", "config", ",", "char_emb_out", ")", "\n", "", "elif", "config", "[", "\"text_encoder\"", "]", "==", "'lstm'", ":", "\n", "        ", "text_encoding", "=", "encode_lstm_with_attention", "(", "config", ",", "char_emb_out", ")", "\n", "", "elif", "config", "[", "\"text_encoder\"", "]", "==", "'bi-gru'", ":", "\n", "        ", "text_encoding", "=", "encode_bigru_with_attention", "(", "config", ",", "char_emb_out", ")", "\n", "", "else", ":", "\n", "        ", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Convolution1D", "(", "filters", "=", "40", ",", "kernel_size", "=", "5", ",", "padding", "=", "'same'", ",", "activation", "=", "'relu'", ")", "(", "\n", "char_emb_out", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Convolution1D", "(", "filters", "=", "20", ",", "kernel_size", "=", "5", ",", "padding", "=", "'same'", ",", "activation", "=", "'relu'", ")", "(", "\n", "text_encoding", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Convolution1D", "(", "filters", "=", "10", ",", "kernel_size", "=", "5", ",", "padding", "=", "'same'", ",", "activation", "=", "'relu'", ")", "(", "\n", "text_encoding", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "AvgPool1D", "(", ")", "(", "text_encoding", ")", "\n", "text_encoding", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "(", "text_encoding", ")", "\n", "\n", "", "return", "text_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.get_fusion_layer_sizes": [[282, 288], ["layer_sizes.append"], "function", ["None"], ["", "def", "get_fusion_layer_sizes", "(", "individual_layer_size", ",", "num_modalitiies", ")", ":", "\n", "    ", "layer_sizes", "=", "[", "]", "\n", "first_layer_size", "=", "individual_layer_size", "*", "num_modalitiies", "\n", "layer_sizes", ".", "append", "(", "first_layer_size", ")", "\n", "\n", "return", "layer_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_inputs": [[289, 338], ["tensorflow.keras.layers.Input", "inputs.append", "models.encode_text_with_bert", "modality_outputs.append", "tensorflow.keras.layers.Input", "inputs.append", "models.encode_text_with_hateword_list", "modality_outputs.append", "tensorflow.keras.layers.Input", "inputs.append", "models.encode_text_with_char_embeddings", "modality_outputs.append", "tensorflow.io.gfile.GFile", "bert.loader.StockBertConfig.from_json_string", "bert.loader.map_stock_config_to_params", "bert.BertModelLayer.from_params", "reader.read"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_text_with_bert", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_text_with_hateword_list", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_text_with_char_embeddings"], ["", "def", "encode_inputs", "(", "config", ",", "bert_config_file", ",", "bert_check_point_file", ",", "adapter_size", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a classification model.\"\"\"", "\n", "\n", "inputs", "=", "[", "]", "\n", "modality_outputs", "=", "[", "]", "\n", "image_models", "=", "[", "]", "\n", "\n", "has_bert_modality", "=", "False", "\n", "if", "\"bert\"", "in", "config", "[", "\"text_models\"", "]", ":", "\n", "        ", "has_bert_modality", "=", "True", "\n", "\n", "", "if", "has_bert_modality", ":", "\n", "        ", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "bert_config_file", ",", "\"r\"", ")", "as", "reader", ":", "\n", "            ", "bc", "=", "StockBertConfig", ".", "from_json_string", "(", "reader", ".", "read", "(", ")", ")", "\n", "bert_params", "=", "map_stock_config_to_params", "(", "bc", ")", "\n", "bert_params", ".", "adapter_size", "=", "adapter_size", "\n", "bert", "=", "BertModelLayer", ".", "from_params", "(", "bert_params", ",", "name", "=", "\"bert\"", ")", "\n", "", "", "else", ":", "\n", "        ", "bert", "=", "None", "\n", "\n", "", "if", "\"bert\"", "in", "config", "[", "\"text_models\"", "]", ":", "\n", "        ", "tweet_text_bert_input", "=", "tf", ".", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "config", "[", "'tweet_text_seq_len'", "]", ",", ")", ",", "dtype", "=", "'int32'", ",", "\n", "name", "=", "\"text_bert\"", ")", "\n", "inputs", ".", "append", "(", "tweet_text_bert_input", ")", "\n", "\n", "# encode with BERT", "\n", "tweet_text_encoding", "=", "encode_text_with_bert", "(", "config", ",", "tweet_text_bert_input", ",", "bert", ")", "\n", "modality_outputs", ".", "append", "(", "tweet_text_encoding", ")", "\n", "\n", "", "if", "\"hate_words\"", "in", "config", "[", "\"text_models\"", "]", ":", "\n", "        ", "tweet_text_hate_words_input", "=", "tf", ".", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "1493", ",", ")", ",", "dtype", "=", "'int32'", ",", "\n", "name", "=", "\"text_hate_words\"", ")", "\n", "inputs", ".", "append", "(", "tweet_text_hate_words_input", ")", "\n", "\n", "# encode hatewords", "\n", "tweet_text_hate_words_encoding", "=", "encode_text_with_hateword_list", "(", "config", ",", "tweet_text_hate_words_input", ")", "\n", "modality_outputs", ".", "append", "(", "tweet_text_hate_words_encoding", ")", "\n", "\n", "", "if", "\"char_emb\"", "in", "config", "[", "\"text_models\"", "]", ":", "\n", "        ", "tweet_text_char_input", "=", "tf", ".", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "config", "[", "'tweet_text_char_len'", "]", ",", ")", ",", "dtype", "=", "'int32'", ",", "\n", "name", "=", "\"text_char_emb\"", ")", "\n", "inputs", ".", "append", "(", "tweet_text_char_input", ")", "\n", "\n", "# encode with char embeddings", "\n", "tweet_text_char_encoding", "=", "encode_text_with_char_embeddings", "(", "config", ",", "tweet_text_char_input", ")", "\n", "modality_outputs", ".", "append", "(", "tweet_text_char_encoding", ")", "\n", "\n", "\n", "", "return", "inputs", ",", "modality_outputs", ",", "has_bert_modality", ",", "bert", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.get_model": [[339, 409], ["models.encode_inputs", "outputs.append", "tensorflow.keras.Model", "tf.keras.Model.compile", "tf.keras.Model.summary", "len", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.Dense", "bert.loader.load_stock_weights", "tensorflow.keras.optimizers.SGD", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "numpy.power", "models.freeze_bert_layers", "models.freeze_all_bert_layers", "tensorflow.keras.optimizers.RMSProp", "tensorflow.keras.losses.SparseCategoricalCrossentropy", "int", "tensorflow.keras.optimizers.Adagrad", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.metrics.SparseCategoricalAccuracy", "numpy.log2", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.encode_inputs", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.freeze_bert_layers", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.freeze_all_bert_layers"], ["", "def", "get_model", "(", "config", ",", "bert_config_file", ",", "bert_check_point_file", ",", "adapter_size", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a classification model.\"\"\"", "\n", "inputs", ",", "modality_outputs", ",", "has_bert_modality", ",", "bert", "=", "encode_inputs", "(", "config", ",", "bert_config_file", ",", "bert_check_point_file", ",", "adapter_size", ")", "\n", "outputs", "=", "[", "]", "\n", "\n", "if", "len", "(", "modality_outputs", ")", ">", "1", ":", "\n", "        ", "concat_embedding", "=", "tf", ".", "keras", ".", "layers", ".", "concatenate", "(", "modality_outputs", ")", "\n", "", "else", ":", "\n", "        ", "concat_embedding", "=", "modality_outputs", "[", "0", "]", "\n", "\n", "", "fusion_layer_output", "=", "concat_embedding", "\n", "\n", "# fusion_layer_size = len(modality_outputs) * config['feature_normalization_layer_size']", "\n", "fusion_layer_size", "=", "fusion_layer_output", ".", "shape", "[", "1", "]", "\n", "counter", "=", "1", "\n", "while", "fusion_layer_size", ">", "config", "[", "'min_feature_normalization_layer_size'", "]", ":", "\n", "\n", "        ", "fusion_layer_output", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "fusion_layer_size", ",", "name", "=", "\"fusion_layer_\"", "+", "str", "(", "counter", ")", ")", "(", "fusion_layer_output", ")", "\n", "batch_norm_layer_output", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "name", "=", "\"batch_norm_layer_\"", "+", "str", "(", "counter", ")", ")", "(", "fusion_layer_output", ")", "\n", "activation_layer_output", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "\"relu\"", ",", "name", "=", "\"relu_layer_\"", "+", "str", "(", "counter", ")", ")", "(", "batch_norm_layer_output", ")", "\n", "\n", "if", "counter", "==", "1", ":", "\n", "            ", "adapted_layer_size", "=", "np", ".", "power", "(", "2", ",", "int", "(", "np", ".", "log2", "(", "fusion_layer_size", ")", ")", ")", "\n", "if", "adapted_layer_size", "==", "fusion_layer_size", ":", "\n", "                ", "fusion_layer_size", "/=", "2", "\n", "", "else", ":", "\n", "                ", "fusion_layer_size", "=", "adapted_layer_size", "\n", "\n", "", "", "else", ":", "\n", "# decrease by half", "\n", "            ", "fusion_layer_size", "/=", "2", "\n", "\n", "", "counter", "+=", "1", "\n", "\n", "fusion_layer_output", "=", "activation_layer_output", "\n", "\n", "", "last_layer_output", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "units", "=", "2", ",", "activation", "=", "\"softmax\"", ",", "name", "=", "'output_label'", ")", "(", "fusion_layer_output", ")", "\n", "outputs", ".", "append", "(", "last_layer_output", ")", "\n", "\n", "model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "outputs", ")", "\n", "\n", "\n", "# load the pre-trained model weights, if BERT is used as a modality", "\n", "if", "has_bert_modality", ":", "\n", "        ", "load_stock_weights", "(", "bert", ",", "bert_check_point_file", ")", "\n", "\n", "# freeze weights if adapter-BERT is used", "\n", "if", "adapter_size", "is", "not", "None", ":", "\n", "            ", "freeze_bert_layers", "(", "bert", ")", "\n", "", "else", ":", "\n", "            ", "freeze_all_bert_layers", "(", "bert", ")", "\n", "\n", "", "", "if", "config", "[", "\"optimizer\"", "]", "==", "\"sgd\"", ":", "\n", "        ", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "SGD", "(", "lr", "=", "0.01", ",", "decay", "=", "1e-6", ",", "momentum", "=", "0.9", ")", "\n", "", "elif", "config", "[", "\"optimizer\"", "]", "==", "\"rmsprop\"", ":", "\n", "        ", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "RMSProp", "(", ")", "\n", "", "elif", "config", "[", "\"optimizer\"", "]", "==", "\"adagrad\"", ":", "\n", "        ", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adagrad", "(", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "0.0001", ")", "\n", "# Enable Mixed Precision for faster computation, less memory", "\n", "# optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(optimizer)", "\n", "\n", "", "model", ".", "compile", "(", "optimizer", "=", "optimizer", ",", "\n", "loss", "=", "tf", ".", "keras", ".", "losses", ".", "SparseCategoricalCrossentropy", "(", ")", ",", "\n", "metrics", "=", "[", "tf", ".", "keras", ".", "metrics", ".", "SparseCategoricalAccuracy", "(", "name", "=", "\"acc\"", ")", "]", ")", "\n", "\n", "model", ".", "summary", "(", ")", "\n", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.main.prepare_predictions": [[20, 61], ["list", "range", "numpy.array", "sklearn.metrics.average_precision_score", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.recall_score", "sklearn.metrics.precision_score", "sklearn.metrics.accuracy_score", "len", "int", "np.array.append", "prediction_output.append", "str", "str", "str", "predicted_probs.tolist", "json.dumps"], "function", ["None"], ["def", "prepare_predictions", "(", "ids", ",", "predictions", ",", "labels", ")", ":", "\n", "    ", "prediction_output", "=", "[", "]", "\n", "binary_predictions", "=", "list", "(", ")", "\n", "\n", "total_expected", "=", "{", "0", ":", "0", ",", "1", ":", "0", "}", "\n", "true_positives", "=", "{", "0", ":", "0", ",", "1", ":", "0", "}", "\n", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ")", ":", "\n", "        ", "predicted_probs", "=", "predictions", "[", "i", "]", "\n", "predicted_class", "=", "1", "if", "predicted_probs", "[", "1", "]", ">=", "0.51", "else", "0", "\n", "expected", "=", "int", "(", "labels", "[", "i", "]", ")", "\n", "\n", "binary_predictions", ".", "append", "(", "predicted_class", ")", "\n", "\n", "if", "expected", "==", "predicted_class", ":", "\n", "            ", "true_positives", "[", "expected", "]", "+=", "1", "\n", "", "total_expected", "[", "expected", "]", "+=", "1", "\n", "\n", "\n", "l", "=", "{", "\"id\"", ":", "str", "(", "ids", "[", "i", "]", ")", ",", "\"prediction\"", ":", "str", "(", "predicted_class", ")", ",", "\"label\"", ":", "str", "(", "labels", "[", "i", "]", ")", ",", "\"probs\"", ":", "predicted_probs", ".", "tolist", "(", ")", "}", "\n", "prediction_output", ".", "append", "(", "json", ".", "dumps", "(", "l", ")", ")", "\n", "\n", "", "recall_hate", "=", "(", "true_positives", "[", "1", "]", "/", "total_expected", "[", "1", "]", ")", "if", "total_expected", "[", "1", "]", ">", "0", "else", "0", "\n", "recall_not_hate", "=", "(", "true_positives", "[", "0", "]", "/", "total_expected", "[", "0", "]", ")", "if", "total_expected", "[", "0", "]", ">", "0", "else", "0", "\n", "\n", "binary_predictions", "=", "np", ".", "array", "(", "binary_predictions", ")", "\n", "average_precision", "=", "average_precision_score", "(", "binary_predictions", ",", "labels", ")", "\n", "f1", "=", "f1_score", "(", "binary_predictions", ",", "labels", ",", "average", "=", "'binary'", ")", "\n", "f1_weighted", "=", "f1_score", "(", "binary_predictions", ",", "labels", ",", "average", "=", "'weighted'", ")", "\n", "macro_f1", "=", "f1_score", "(", "binary_predictions", ",", "labels", ",", "average", "=", "'macro'", ")", "\n", "recall", "=", "recall_score", "(", "binary_predictions", ",", "labels", ",", "average", "=", "'binary'", ")", "\n", "precision", "=", "precision_score", "(", "binary_predictions", ",", "labels", ",", "average", "=", "'binary'", ")", "\n", "accuracy", "=", "accuracy_score", "(", "binary_predictions", ",", "labels", ")", "\n", "\n", "score_output", "=", "{", "\"accuracy\"", ":", "accuracy", ",", "\"average_precision\"", ":", "average_precision", ",", "\"f1\"", ":", "f1", ",", "\"weighted_f1\"", ":", "f1_weighted", ",", "\"macro_f1\"", ":", "macro_f1", ",", "\"recall\"", ":", "recall", ",", "\"precision\"", ":", "precision", ",", "\n", "\"HatefulOffensive\"", ":", "{", "\"recall\"", ":", "recall_hate", ",", "\"support\"", ":", "total_expected", "[", "1", "]", "}", ",", "\n", "\"NOT\"", ":", "{", "\"recall\"", ":", "recall_not_hate", ",", "\"support\"", ":", "total_expected", "[", "0", "]", "}", "\n", "}", "\n", "\n", "return", "prediction_output", ",", "score_output", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.main.train": [[62, 159], ["tensorflow.config.experimental.list_physical_devices", "range", "file_utils.read_file_to_list", "print", "bert.tokenization.bert_tokenization.FullTokenizer", "data_loader.load_dataset", "print", "print", "print", "datetime.datetime.now", "file_utils.create_folder", "file_utils.create_folder", "tensorflow.keras.callbacks.ModelCheckpoint", "tensorflow.keras.callbacks.EarlyStopping", "tensorflow.keras.callbacks.TensorBoard", "print", "models.get_model", "models.get_model.fit", "models.get_model.predict", "main.prepare_predictions", "print", "file_utils.save_string_to_file", "file_utils.save_list_to_file", "file_utils.save_string_to_file", "len", "matplotlib.style.use", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.close", "len", "tensorflow.config.experimental.set_memory_growth", "print", "print", "len", "datetime.now.strftime().replace", "json.dumps", "json.dumps", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "os.path.join", "str", "str", "str", "datetime.now.strftime", "tensorflow.test.is_gpu_available"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.read_file_to_list", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.load_dataset", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.create_folder", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.create_folder", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.models.get_model", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.main.prepare_predictions", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.save_string_to_file", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.save_list_to_file", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.save_string_to_file"], ["", "def", "train", "(", "config", ")", ":", "\n", "    ", "physical_devices", "=", "tf", ".", "config", ".", "experimental", ".", "list_physical_devices", "(", "'GPU'", ")", "\n", "os", ".", "environ", "[", "'TF_CPP_MIN_LOG_LEVEL'", "]", "=", "'3'", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "physical_devices", ")", ")", ":", "\n", "        ", "tf", ".", "config", ".", "experimental", ".", "set_memory_growth", "(", "physical_devices", "[", "i", "]", ",", "True", ")", "\n", "\n", "# hate word list", "\n", "", "hate_words", "=", "file_utils", ".", "read_file_to_list", "(", "config", "[", "'base_dir'", "]", "+", "'resources/hate_words.txt'", ")", "\n", "\n", "# BERT related configurations", "\n", "print", "(", "'Using BERT: {}'", ".", "format", "(", "config", "[", "'bert_model_dir'", "]", ")", ")", "\n", "bert_ckpt_dir", "=", "config", "[", "'base_dir'", "]", "+", "config", "[", "'bert_model_dir'", "]", "+", "\"/\"", "\n", "bert_check_point_file", "=", "bert_ckpt_dir", "+", "\"bert_model.ckpt\"", "\n", "bert_config_file", "=", "bert_ckpt_dir", "+", "\"bert_config.json\"", "\n", "bert_tokenizer", "=", "bert", ".", "tokenization", ".", "bert_tokenization", ".", "FullTokenizer", "(", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "bert_ckpt_dir", ",", "\"vocab.txt\"", ")", ")", "\n", "\n", "X_train", ",", "y_train", ",", "y_train_ids", ",", "X_valid", ",", "y_valid", ",", "y_valid_ids", ",", "X_test", ",", "y_test", ",", "y_test_ids", "=", "data_loader", ".", "load_dataset", "(", "config", ",", "bert_tokenizer", ",", "hate_words", ")", "\n", "\n", "print", "(", "\"Training input file shapes\"", ")", "\n", "for", "k", "in", "X_train", ":", "\n", "        ", "print", "(", "'\\t'", "+", "k", "+", "\" shape: \"", "+", "str", "(", "X_train", "[", "k", "]", ".", "shape", ")", ")", "\n", "\n", "", "print", "(", "\"Validation input file shapes\"", ")", "\n", "for", "k", "in", "X_valid", ":", "\n", "        ", "print", "(", "'\\t'", "+", "k", "+", "\" shape: \"", "+", "str", "(", "X_valid", "[", "k", "]", ".", "shape", ")", ")", "\n", "\n", "", "print", "(", "\"Test data size\"", ",", "len", "(", "y_test_ids", ")", ")", "\n", "\n", "# folders to save the trained models and results", "\n", "\n", "results_dir_path", "=", "config", "[", "'base_dir'", "]", "+", "'results'", "\n", "now", "=", "datetime", ".", "now", "(", ")", "\n", "model_dir_path", "=", "config", "[", "'base_dir'", "]", "+", "'results/'", "+", "now", ".", "strftime", "(", "\"%d-%m-%Y %H:%M:%S\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "\n", "file_utils", ".", "create_folder", "(", "results_dir_path", ")", "\n", "file_utils", ".", "create_folder", "(", "model_dir_path", ")", "\n", "\n", "\n", "model_check_point_callback", "=", "tf", ".", "keras", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "model_dir_path", "+", "'/best_model-epoch-{epoch:03d}-acc-{acc:03f}-val_acc-{val_acc:03f}.h5'", ",", "\n", "save_best_only", "=", "True", ",", "\n", "monitor", "=", "config", "[", "'monitor'", "]", ")", "\n", "\n", "early_stopping_callback", "=", "tf", ".", "keras", ".", "callbacks", ".", "EarlyStopping", "(", "patience", "=", "config", "[", "\"epoch_patience\"", "]", ",", "\n", "restore_best_weights", "=", "True", ",", "\n", "monitor", "=", "config", "[", "'monitor'", "]", ")", "\n", "\n", "tensorboard_callback", "=", "tf", ".", "keras", ".", "callbacks", ".", "TensorBoard", "(", "log_dir", "=", "model_dir_path", "+", "\"/logs\"", ")", "\n", "\n", "callbacks", "=", "[", "early_stopping_callback", "]", "\n", "\n", "print", "(", "'Using GPUs: '", "+", "str", "(", "tf", ".", "test", ".", "is_gpu_available", "(", ")", ")", ")", "\n", "\n", "# create the model", "\n", "model", "=", "models", ".", "get_model", "(", "config", ",", "bert_config_file", ",", "bert_check_point_file", ",", "adapter_size", "=", "None", ")", "\n", "\n", "\n", "history", "=", "model", ".", "fit", "(", "X_train", ",", "y_train", ",", "validation_data", "=", "(", "X_valid", ",", "y_valid", ")", ",", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", ",", "\n", "shuffle", "=", "True", ",", "\n", "epochs", "=", "config", "[", "'epochs'", "]", ",", "\n", "callbacks", "=", "callbacks", ")", "\n", "\n", "predictions", "=", "model", ".", "predict", "(", "X_test", ",", "batch_size", "=", "config", "[", "'batch_size'", "]", ")", "\n", "\n", "test_predictions", ",", "test_score_output", "=", "prepare_predictions", "(", "y_test_ids", ",", "predictions", ",", "y_test", "[", "'output_label'", "]", ")", "\n", "\n", "print", "(", "'Test macro-f1: '", ",", "test_score_output", "[", "'macro_f1'", "]", ")", "\n", "\n", "# save the model", "\n", "# model.save(model_dir_path + \"/model.h5\")", "\n", "\n", "\n", "# save prediction score, predictions", "\n", "file_utils", ".", "save_string_to_file", "(", "json", ".", "dumps", "(", "test_score_output", ")", ",", "\n", "model_dir_path", "+", "'/test_prediction_score.json'", ")", "\n", "file_utils", ".", "save_list_to_file", "(", "test_predictions", ",", "model_dir_path", "+", "'/test_predictions.jsonl'", ")", "\n", "\n", "# save the training config", "\n", "file_utils", ".", "save_string_to_file", "(", "json", ".", "dumps", "(", "config", ")", ",", "\n", "model_dir_path", "+", "'/training_config.json'", ")", "\n", "\n", "\n", "N", "=", "len", "(", "history", ".", "epoch", ")", "\n", "plt", ".", "style", ".", "use", "(", "\"ggplot\"", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "1", ",", "N", "+", "1", ")", ",", "history", ".", "history", "[", "'loss'", "]", ",", "label", "=", "'loss'", ")", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "1", ",", "N", "+", "1", ")", ",", "history", ".", "history", "[", "'val_loss'", "]", ",", "label", "=", "'val_loss'", ")", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "1", ",", "N", "+", "1", ")", ",", "history", ".", "history", "[", "'acc'", "]", ",", "label", "=", "'acc'", ")", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "1", ",", "N", "+", "1", ")", ",", "history", ".", "history", "[", "'val_acc'", "]", ",", "label", "=", "'val_acc'", ")", "\n", "plt", ".", "title", "(", "\"Validation, Test Loss and Accuracy on HASOC \"", "+", "config", "[", "\"dataset_year\"", "]", "+", "\" Dataset, \"", "+", "config", "[", "'optimizer'", "]", ")", "\n", "plt", ".", "xlabel", "(", "\"Epoch #\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Loss/Accuracy\"", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"lower left\"", ")", "\n", "plt", ".", "savefig", "(", "model_dir_path", "+", "\"/history.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.replace_digits_emojis": [[13, 20], ["s.strip.lower().strip", "emoji.demojize", "re.sub", "re.sub", "s.strip.strip", "s.strip.lower"], "function", ["None"], ["def", "replace_digits_emojis", "(", "s", ")", ":", "\n", "    ", "s", "=", "s", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "s", "=", "emoji", ".", "demojize", "(", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "r'\\d+'", ",", "''", ",", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "s", ")", "\n", "s", "=", "s", ".", "strip", "(", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.remove_urls_mentions": [[21, 25], ["re.sub", "text.replace().strip.replace().strip", "text.replace().strip.replace"], "function", ["None"], ["", "def", "remove_urls_mentions", "(", "text", ")", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "r\"(?:\\@|https?\\://)\\S+\"", ",", "\"\"", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"RT\"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.replace_space": [[26, 31], ["text.strip.replace().strip", "re.sub", "text.strip.strip", "text.strip.replace"], "function", ["None"], ["", "def", "replace_space", "(", "text", ")", ":", "\n", "    ", "text", "=", "text", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\\s+\"", ",", "' '", ",", "text", ")", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.merge_outputs": [[32, 51], ["data_loader.replace_space", "l.replace.replace", "data_loader.replace_digits_emojis"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.replace_space", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.replace_digits_emojis"], ["", "def", "merge_outputs", "(", "processed_text", ")", ":", "\n", "    ", "text", "=", "\"\"", "\n", "for", "l", "in", "processed_text", ":", "\n", "        ", "if", "\"</\"", "in", "l", ":", "\n", "            ", "l", "=", "l", ".", "replace", "(", "\"</\"", ",", "\"<\"", ")", "\n", "\n", "", "if", "l", "in", "[", "'<percent>'", ",", "'<url>'", ",", "'<'", ",", "'<number>'", ",", "'</allcaps>'", ",", "\n", "'<money>'", ",", "'<phone>'", ",", "'<allcaps>'", ",", "'<repeated>'", ",", "'<hashtag>'", ",", "\n", "'<date>'", ",", "'<time>'", ",", "'<censored>'", ",", "'</hashtag>'", ",", "'<email>'", "]", ":", "\n", "            ", "continue", "\n", "", "elif", "l", "in", "[", "'<emphasis>'", ",", "'<user>'", ",", "'<surprise>'", ",", "'<laugh>'", ",", "'<sad>'", ",", "'<annoyed>'", ",", "'<happy>'", "]", ":", "\n", "            ", "if", "l", "==", "'<user>'", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "text", "+=", "\" \"", "+", "l", "\n", "", "", "else", ":", "\n", "            ", "text", "+=", "\" \"", "+", "replace_digits_emojis", "(", "l", ")", "\n", "", "", "normalized", "=", "replace_space", "(", "text", ")", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.normalize_text": [[52, 57], ["text_preprocessor.pre_process_doc", "data_loader.merge_outputs"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.merge_outputs"], ["", "def", "normalize_text", "(", "input_text", ":", "str", ",", "text_preprocessor", ")", ":", "\n", "    ", "processed_text", "=", "text_preprocessor", ".", "pre_process_doc", "(", "input_text", ")", "\n", "normalized_text", "=", "merge_outputs", "(", "processed_text", ")", "\n", "\n", "return", "normalized_text", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.sample_validation_set": [[58, 129], ["int", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "sampled_indexes[].append", "y_valid_ids.append", "y_train_ids.append", "float", "validation_data.append", "training_data.append", "validation_data.append", "training_data.append", "len"], "function", ["None"], ["", "def", "sample_validation_set", "(", "X", ",", "y", ",", "ids", ")", ":", "\n", "    ", "validation_sample_size", "=", "int", "(", "(", "float", "(", "len", "(", "ids", ")", ")", "*", "0.1", ")", "/", "2", ")", "\n", "\n", "X_train", "=", "{", "}", "\n", "y_train", "=", "{", "}", "\n", "y_train_ids", "=", "[", "]", "\n", "X_valid", "=", "{", "}", "\n", "y_valid", "=", "{", "}", "\n", "y_valid_ids", "=", "[", "]", "\n", "\n", "sampled_indexes", "=", "{", "0", ":", "[", "]", ",", "1", ":", "[", "]", "}", "\n", "index_counter", "=", "0", "\n", "for", "label", "in", "y", "[", "'output_label'", "]", ":", "\n", "        ", "if", "len", "(", "sampled_indexes", "[", "label", "]", ")", "<", "validation_sample_size", ":", "\n", "            ", "sampled_indexes", "[", "label", "]", ".", "append", "(", "index_counter", ")", "\n", "", "index_counter", "+=", "1", "\n", "\n", "\n", "", "for", "k", "in", "X", ":", "\n", "        ", "data", "=", "X", "[", "k", "]", "\n", "\n", "training_data", "=", "[", "]", "\n", "validation_data", "=", "[", "]", "\n", "index_counter", "=", "0", "\n", "for", "d", "in", "data", ":", "\n", "            ", "label", "=", "y", "[", "'output_label'", "]", "[", "index_counter", "]", "\n", "\n", "# add to validation split", "\n", "if", "index_counter", "in", "sampled_indexes", "[", "label", "]", ":", "\n", "                ", "validation_data", ".", "append", "(", "d", ")", "\n", "", "else", ":", "\n", "                ", "training_data", ".", "append", "(", "d", ")", "\n", "\n", "", "index_counter", "+=", "1", "\n", "\n", "", "X_train", "[", "k", "]", "=", "np", ".", "array", "(", "training_data", ")", "\n", "X_valid", "[", "k", "]", "=", "np", ".", "array", "(", "validation_data", ")", "\n", "\n", "", "for", "k", "in", "y", ":", "\n", "        ", "data", "=", "y", "[", "k", "]", "\n", "\n", "training_data", "=", "[", "]", "\n", "validation_data", "=", "[", "]", "\n", "index_counter", "=", "0", "\n", "for", "d", "in", "data", ":", "\n", "            ", "label", "=", "y", "[", "'output_label'", "]", "[", "index_counter", "]", "\n", "\n", "# add to validation split", "\n", "if", "index_counter", "in", "sampled_indexes", "[", "label", "]", ":", "\n", "                ", "validation_data", ".", "append", "(", "d", ")", "\n", "", "else", ":", "\n", "                ", "training_data", ".", "append", "(", "d", ")", "\n", "\n", "", "index_counter", "+=", "1", "\n", "\n", "", "y_train", "[", "k", "]", "=", "np", ".", "array", "(", "training_data", ")", "\n", "y_valid", "[", "k", "]", "=", "np", ".", "array", "(", "validation_data", ")", "\n", "\n", "", "index_counter", "=", "0", "\n", "for", "id", "in", "ids", ":", "\n", "        ", "label", "=", "y", "[", "'output_label'", "]", "[", "index_counter", "]", "\n", "\n", "# add to validation split", "\n", "if", "index_counter", "in", "sampled_indexes", "[", "label", "]", ":", "\n", "            ", "y_valid_ids", ".", "append", "(", "id", ")", "\n", "", "else", ":", "\n", "            ", "y_train_ids", ".", "append", "(", "id", ")", "\n", "\n", "", "index_counter", "+=", "1", "\n", "\n", "", "return", "X_train", ",", "y_train", ",", "y_train_ids", ",", "X_valid", ",", "y_valid", ",", "y_valid_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.apply_oversampling": [[130, 170], ["random.sample", "oversampled_ids.extend", "oversampled_text_docs.extend", "oversampled_labels.extend", "label_to_ids[].append", "ids.index", "oversampled_ids.append", "oversampled_labels.append", "oversampled_text_docs.append"], "function", ["None"], ["", "def", "apply_oversampling", "(", "ids", ",", "labels", ",", "text_docs", ")", ":", "\n", "\n", "    ", "count", "=", "{", "'HOF'", ":", "0", ",", "'NOT'", ":", "0", "}", "\n", "label_to_ids", "=", "{", "'HOF'", ":", "[", "]", ",", "'NOT'", ":", "[", "]", "}", "\n", "\n", "c", "=", "0", "\n", "for", "l", "in", "labels", ":", "\n", "        ", "count", "[", "l", "]", "+=", "1", "\n", "\n", "id", "=", "ids", "[", "c", "]", "\n", "label_to_ids", "[", "l", "]", ".", "append", "(", "id", ")", "\n", "c", "+=", "1", "\n", "\n", "", "oversampled_ids", ",", "oversampled_labels", ",", "oversampled_text_docs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "if", "count", "[", "'HOF'", "]", ">", "count", "[", "'NOT'", "]", ":", "\n", "        ", "max_label", "=", "'HOF'", "\n", "min_label", "=", "'NOT'", "\n", "", "else", ":", "\n", "        ", "max_label", "=", "'NOT'", "\n", "min_label", "=", "'HOF'", "\n", "\n", "\n", "", "label_diff", "=", "count", "[", "max_label", "]", "-", "count", "[", "min_label", "]", "\n", "\n", "random_ids", "=", "random", ".", "sample", "(", "label_to_ids", "[", "min_label", "]", ",", "label_diff", ")", "\n", "\n", "for", "r", "in", "random_ids", ":", "\n", "        ", "id_index", "=", "ids", ".", "index", "(", "r", ")", "\n", "\n", "oversampled_ids", ".", "append", "(", "ids", "[", "id_index", "]", ")", "\n", "oversampled_labels", ".", "append", "(", "labels", "[", "id_index", "]", ")", "\n", "oversampled_text_docs", ".", "append", "(", "text_docs", "[", "id_index", "]", ")", "\n", "\n", "# add the existing data", "\n", "", "oversampled_ids", ".", "extend", "(", "ids", ")", "\n", "oversampled_text_docs", ".", "extend", "(", "text_docs", ")", "\n", "oversampled_labels", ".", "extend", "(", "labels", ")", "\n", "\n", "return", "oversampled_ids", ",", "oversampled_labels", ",", "oversampled_text_docs", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.tokenize": [[171, 182], ["text.split", "filtered_tokens.append"], "function", ["None"], ["", "def", "tokenize", "(", "text", ")", ":", "\n", "    ", "tags", "=", "[", "'<emphasis>'", ",", "'<user>'", ",", "'<surprise>'", ",", "'<percent>'", ",", "'<url>'", ",", "'<'", ",", "'<number>'", ",", "'</allcaps>'", ",", "'<money>'", ",", "\n", "'<phone>'", ",", "'<allcaps>'", ",", "'<repeated>'", ",", "'<laugh>'", ",", "'<hashtag>'", ",", "'<elongated>'", ",", "'<sad>'", ",", "'<annoyed>'", ",", "\n", "'<date>'", ",", "'<time>'", ",", "'<censored>'", ",", "'<happy>'", ",", "'</hashtag>'", ",", "'<email>'", "]", "\n", "tokens", "=", "text", ".", "split", "(", "' '", ")", "\n", "filtered_tokens", "=", "[", "]", "\n", "\n", "for", "t", "in", "tokens", ":", "\n", "        ", "if", "t", "not", "in", "tags", ":", "\n", "            ", "filtered_tokens", ".", "append", "(", "t", ")", "\n", "", "", "return", "filtered_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.pad_text": [[183, 187], ["numpy.array", "min", "len", "len"], "function", ["None"], ["", "def", "pad_text", "(", "max_seq_len", ",", "token_ids", ")", ":", "\n", "    ", "token_ids", "=", "token_ids", "[", ":", "min", "(", "len", "(", "token_ids", ")", ",", "max_seq_len", "-", "2", ")", "]", "\n", "token_ids", "=", "token_ids", "+", "[", "0", "]", "*", "(", "max_seq_len", "-", "len", "(", "token_ids", ")", ")", "\n", "return", "np", ".", "array", "(", "token_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.embed_text_with_hate_words": [[188, 203], ["list", "numpy.array", "text.split", "numpy.zeros", "list.append", "len", "hate_words.index"], "function", ["None"], ["", "def", "embed_text_with_hate_words", "(", "config", ",", "data", ":", "list", ",", "hate_words", ":", "list", ")", ":", "\n", "    ", "x", "=", "list", "(", ")", "\n", "for", "text", "in", "data", ":", "\n", "\n", "# tokenize", "\n", "        ", "tokens", "=", "text", ".", "split", "(", "' '", ")", "\n", "multihot_encoding_array", "=", "np", ".", "zeros", "(", "len", "(", "hate_words", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "for", "t", "in", "tokens", ":", "\n", "            ", "if", "t", "in", "hate_words", ":", "\n", "                ", "index", "=", "hate_words", ".", "index", "(", "t", ")", "\n", "multihot_encoding_array", "[", "index", "]", "=", "1", "\n", "\n", "", "", "x", ".", "append", "(", "multihot_encoding_array", ")", "\n", "", "return", "np", ".", "array", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.embed_text_with_bert": [[204, 219], ["list", "numpy.array", "bert_tokenizer.tokenize", "bert_tokenizer.convert_tokens_to_ids", "data_loader.pad_text", "list.append"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.tokenize", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.pad_text"], ["", "def", "embed_text_with_bert", "(", "config", ":", "dict", ",", "data", ":", "list", ",", "bert_tokenizer", ":", "FullTokenizer", ")", ":", "\n", "    ", "x", "=", "list", "(", ")", "\n", "\n", "for", "text", "in", "data", ":", "\n", "\n", "# tokenize", "\n", "        ", "tokens", "=", "bert_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens", "+", "[", "\"[SEP]\"", "]", "\n", "# convert tokens into IDs by embedding the text with BERT", "\n", "token_ids", "=", "bert_tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "# pad zeros to the token ids, if necessary", "\n", "max_seq_len", "=", "config", "[", "'tweet_text_seq_len'", "]", "\n", "token_ids", "=", "pad_text", "(", "max_seq_len", ",", "token_ids", ")", "\n", "x", ".", "append", "(", "token_ids", ")", "\n", "", "return", "np", ".", "array", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.embed_text_with_characters": [[220, 235], ["tensorflow.keras.preprocessing.text.Tokenizer", "enumerate", "tensorflow.keras.preprocessing.text.Tokenizer.texts_to_sequences", "tensorflow.keras.preprocessing.sequence.pad_sequences", "len"], "function", ["None"], ["", "def", "embed_text_with_characters", "(", "config", ":", "dict", ",", "data", ":", "list", ")", ":", "\n", "    ", "char_tokenizer", "=", "Tokenizer", "(", "lower", "=", "True", ",", "char_level", "=", "True", ",", "oov_token", "=", "\"UNKNOWN\"", ")", "\n", "\n", "alphabet", "=", "\" abcdefghijklmnopqrstuvwxyz\"", "\n", "char_dict", "=", "{", "\"PADDING\"", ":", "0", ",", "\"UNKNOWN\"", ":", "1", "}", "\n", "for", "i", ",", "char", "in", "enumerate", "(", "alphabet", ")", ":", "\n", "        ", "char_dict", "[", "char", "]", "=", "len", "(", "char_dict", ")", "\n", "\n", "", "char_tokenizer", ".", "word_index", "=", "char_dict", "\n", "\n", "x", "=", "char_tokenizer", ".", "texts_to_sequences", "(", "data", ")", "\n", "\n", "x_padded", "=", "pad_sequences", "(", "x", ",", "padding", "=", "'post'", ",", "maxlen", "=", "config", "[", "'tweet_text_char_len'", "]", ")", "\n", "\n", "return", "x_padded", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.normalize_text_docs": [[236, 242], ["data_loader.normalize_text", "normalized_text_docs.append"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.normalize_text"], ["", "def", "normalize_text_docs", "(", "text_docs", ":", "list", ",", "text_preprocessor", ")", ":", "\n", "    ", "normalized_text_docs", "=", "[", "]", "\n", "for", "text", "in", "text_docs", ":", "\n", "        ", "normalized_text", "=", "normalize_text", "(", "text", ",", "text_preprocessor", ")", "\n", "normalized_text_docs", ".", "append", "(", "normalized_text", ")", "\n", "", "return", "normalized_text_docs", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.encode_labels": [[243, 250], ["list", "numpy.array", "list.append"], "function", ["None"], ["", "def", "encode_labels", "(", "data", ":", "list", ")", ":", "\n", "    ", "y", "=", "list", "(", ")", "\n", "label_to_index", "=", "{", "\"HOF\"", ":", "1", ",", "\"NOT\"", ":", "0", "}", "\n", "\n", "for", "label", "in", "data", ":", "\n", "        ", "y", ".", "append", "(", "label_to_index", "[", "label", "]", ")", "\n", "", "return", "np", ".", "array", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.load_split": [[251, 273], ["df[].tolist", "df[].tolist", "df[].tolist", "data_loader.encode_labels", "data_loader.apply_oversampling", "data_loader.normalize_text_docs", "data_loader.embed_text_with_bert", "data_loader.embed_text_with_hate_words", "data_loader.embed_text_with_characters"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.encode_labels", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.apply_oversampling", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.normalize_text_docs", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.embed_text_with_bert", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.embed_text_with_hate_words", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.embed_text_with_characters"], ["", "def", "load_split", "(", "config", ",", "df", ",", "bert_tokenizer", ",", "hate_words", ",", "text_preprocessor", ",", "oversample", ":", "bool", ")", ":", "\n", "    ", "X", ",", "y", "=", "{", "}", ",", "{", "}", "\n", "\n", "ids", "=", "df", "[", "\"id\"", "]", ".", "tolist", "(", ")", "\n", "labels", "=", "df", "[", "\"label\"", "]", ".", "tolist", "(", ")", "\n", "text_docs", "=", "df", "[", "\"text\"", "]", ".", "tolist", "(", ")", "\n", "\n", "if", "oversample", ":", "\n", "        ", "ids", ",", "labels", ",", "text_docs", "=", "apply_oversampling", "(", "ids", ",", "labels", ",", "text_docs", ")", "\n", "\n", "", "if", "config", "[", "'normalize_text'", "]", ":", "\n", "        ", "text_docs", "=", "normalize_text_docs", "(", "text_docs", ",", "text_preprocessor", ")", "\n", "\n", "", "if", "\"bert\"", "in", "config", "[", "\"text_models\"", "]", ":", "\n", "        ", "X", "[", "\"text_bert\"", "]", "=", "embed_text_with_bert", "(", "config", ",", "text_docs", ",", "bert_tokenizer", ")", "\n", "", "if", "\"hate_words\"", "in", "config", "[", "\"text_models\"", "]", ":", "\n", "        ", "X", "[", "\"text_hate_words\"", "]", "=", "embed_text_with_hate_words", "(", "config", ",", "text_docs", ",", "hate_words", ")", "\n", "", "if", "\"char_emb\"", "in", "config", "[", "\"text_models\"", "]", ":", "\n", "        ", "X", "[", "\"text_char_emb\"", "]", "=", "embed_text_with_characters", "(", "config", ",", "text_docs", ")", "\n", "\n", "", "y", "[", "'output_label'", "]", "=", "encode_labels", "(", "labels", ")", "\n", "return", "X", ",", "y", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.load_dataset": [[276, 317], ["pandas.read_csv", "pandas.read_csv", "ekphrasis.classes.preprocessor.TextPreProcessor", "data_loader.load_split", "data_loader.load_split", "data_loader.sample_validation_set", "ekphrasis.classes.tokenizer.SocialTokenizer"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.load_split", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.load_split", "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.data_loader.sample_validation_set"], ["", "def", "load_dataset", "(", "config", ",", "bert_tokenizer", ",", "hate_words", ")", ":", "\n", "    ", "train_df", "=", "pd", ".", "read_csv", "(", "config", "[", "'base_dir'", "]", "+", "'resources/hasoc_data/'", "+", "config", "[", "'dataset_year'", "]", "+", "'/train.tsv'", ",", "sep", "=", "'\\t'", ",", "header", "=", "0", ")", "\n", "test_df", "=", "pd", ".", "read_csv", "(", "config", "[", "'base_dir'", "]", "+", "'resources/hasoc_data/'", "+", "config", "[", "'dataset_year'", "]", "+", "'/test.tsv'", ",", "sep", "=", "'\\t'", ",", "header", "=", "0", ")", "\n", "\n", "# load the Ekphrasis preprocessor", "\n", "text_preprocessor", "=", "TextPreProcessor", "(", "\n", "# terms that will be normalized", "\n", "normalize", "=", "[", "'url'", ",", "'email'", ",", "'percent'", ",", "'money'", ",", "'phone'", ",", "'user'", ",", "\n", "'time'", ",", "'url'", ",", "'date'", ",", "'number'", "]", ",", "\n", "# terms that will be annotated", "\n", "annotate", "=", "{", "\"hashtag\"", ",", "\"allcaps\"", ",", "\"elongated\"", ",", "\"repeated\"", ",", "\n", "'emphasis'", ",", "'censored'", "}", ",", "\n", "fix_html", "=", "True", ",", "# fix HTML tokens", "\n", "\n", "# corpus from which the word statistics are going to be used", "\n", "# for word segmentation", "\n", "segmenter", "=", "\"twitter\"", ",", "\n", "\n", "# corpus from which the word statistics are going to be used", "\n", "# for spell correction", "\n", "corrector", "=", "\"twitter\"", ",", "\n", "\n", "unpack_hashtags", "=", "True", ",", "# perform word segmentation on hashtags", "\n", "unpack_contractions", "=", "True", ",", "# Unpack contractions (can't -> can not)", "\n", "spell_correct_elong", "=", "False", ",", "# spell correction for elongated words", "\n", "\n", "# select a tokenizer. You can use SocialTokenizer, or pass your own", "\n", "# the tokenizer, should take as input a string and return a list of tokens", "\n", "tokenizer", "=", "SocialTokenizer", "(", "lowercase", "=", "True", ")", ".", "tokenize", ",", "\n", "\n", "# list of dictionaries, for replacing tokens extracted from the text,", "\n", "# with other expressions. You can pass more than one dictionaries.", "\n", "dicts", "=", "[", "emoticons", "]", "\n", ")", "\n", "\n", "X_train", ",", "y_train", ",", "y_train_ids", "=", "load_split", "(", "config", ",", "train_df", ",", "bert_tokenizer", ",", "hate_words", ",", "text_preprocessor", ",", "oversample", "=", "config", "[", "'oversample'", "]", ")", "\n", "X_test", ",", "y_test", ",", "y_test_ids", "=", "load_split", "(", "config", ",", "test_df", ",", "bert_tokenizer", ",", "hate_words", ",", "text_preprocessor", ",", "oversample", "=", "False", ")", "\n", "\n", "X_train", ",", "y_train", ",", "y_train_ids", ",", "X_valid", ",", "y_valid", ",", "y_valid_ids", "=", "sample_validation_set", "(", "X_train", ",", "y_train", ",", "y_train_ids", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "y_train_ids", ",", "X_valid", ",", "y_valid", ",", "y_valid_ids", ",", "X_test", ",", "y_test", ",", "y_test_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.save_list_to_file": [[4, 8], ["open", "open.write", "open.close", "str"], "function", ["None"], ["def", "save_list_to_file", "(", "input_list", ":", "list", ",", "file_path", ")", ":", "\n", "    ", "file", "=", "open", "(", "file_path", ",", "'w'", ")", "\n", "file", ".", "write", "(", "\"\\n\"", ".", "join", "(", "str", "(", "item", ")", "for", "item", "in", "input_list", ")", ")", "\n", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.save_string_to_file": [[9, 13], ["open", "open.write", "open.close"], "function", ["None"], ["", "def", "save_string_to_file", "(", "text", ",", "file_path", ")", ":", "\n", "    ", "file", "=", "open", "(", "file_path", ",", "'w'", ")", "\n", "file", ".", "write", "(", "text", ")", "\n", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.read_file_to_set": [[14, 21], ["set", "os.path.isfile", "open", "file.readlines", "set.add", "l.strip"], "function", ["None"], ["", "def", "read_file_to_set", "(", "file_path", ")", ":", "\n", "    ", "content", "=", "set", "(", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "file", ":", "\n", "            ", "for", "l", "in", "file", ".", "readlines", "(", ")", ":", "\n", "                ", "content", ".", "add", "(", "l", ".", "strip", "(", ")", ")", "\n", "", "", "", "return", "content", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.read_file_to_list": [[22, 29], ["list", "os.path.isfile", "open", "file.readlines", "list.append", "l.strip().replace", "l.strip"], "function", ["None"], ["", "def", "read_file_to_list", "(", "file_path", ")", ":", "\n", "    ", "content", "=", "list", "(", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "file", ":", "\n", "            ", "for", "l", "in", "file", ".", "readlines", "(", ")", ":", "\n", "                ", "content", ".", "append", "(", "l", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "", "", "", "return", "content", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.read_json_file": [[30, 34], ["open", "json.load"], "function", ["None"], ["", "def", "read_json_file", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ")", "as", "json_file", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "json_file", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.path_exists": [[36, 38], ["os.path.exists"], "function", ["None"], ["", "", "def", "path_exists", "(", "dir_path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "exists", "(", "dir_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.create_folder": [[39, 43], ["file_utils.path_exists", "os.mkdir"], "function", ["home.repos.pwc.inspect_result.sherzod-hakimov_hasoc-2021---hate-speech-detection.None.file_utils.path_exists"], ["", "def", "create_folder", "(", "dir_path", ")", ":", "\n", "    ", "if", "not", "path_exists", "(", "dir_path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "dir_path", ")", "\n", "", "pass", "\n", "", ""]]}