{"home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.__init__": [[5, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "windows", ",", "buffer_size", "=", "5000", ")", ":", "\n", "        ", "self", ".", "buffer", "=", "[", "]", "\n", "self", ".", "location", "=", "0", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "window", "=", "windows", "\n", "self", ".", "total_additions", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.add": [[12, 23], ["len", "rehearsal.ReservoirSampler.buffer.append", "random.randint", "min"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "total_additions", "+=", "1", "\n", "\n", "M", "=", "len", "(", "self", ".", "buffer", ")", "\n", "if", "M", "<", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "buffer", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "i", "=", "random", ".", "randint", "(", "0", ",", "min", "(", "self", ".", "total_additions", ",", "self", ".", "window", ")", ")", "\n", "if", "i", "<", "self", ".", "buffer_size", ":", "\n", "                ", "self", ".", "buffer", "[", "i", "]", "=", "data", "\n", "", "", "self", ".", "location", "=", "(", "self", ".", "location", "+", "1", ")", "%", "self", ".", "buffer_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample": [[24, 26], ["random.sample"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "random", ".", "sample", "(", "self", ".", "buffer", ",", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample_trajectory": [[27, 30], ["random.randint", "len"], "methods", ["None"], ["", "def", "sample_trajectory", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "initial_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "buffer", ")", "-", "batch_size", ")", "\n", "return", "self", ".", "buffer", "[", "initial_index", ":", "initial_index", "+", "batch_size", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.__init__": [[16, 75], ["vars", "print", "datetime.datetime.now().strftime", "str", "os.path.join", "os.path.exists", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logger.addHandler", "logging.handlers.logging.StreamHandler", "logging.handlers.logging.StreamHandler.setLevel", "logging.handlers.logging.StreamHandler.setFormatter", "logger.addHandler", "logger.setLevel", "experiment.experiment.store_json", "subprocess.check_output().decode", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output().decode", "os.path.exists", "os.makedirs", "logging.Formatter", "logging.Formatter", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output().decode", "datetime.datetime.now", "os.makedirs", "str", "os.makedirs", "str", "subprocess.check_output", "subprocess.check_output", "os.path.exists", "str", "subprocess.check_output", "str"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.store_json"], ["def", "__init__", "(", "self", ",", "name", ",", "args", ",", "output_dir", "=", "\"../\"", ",", "commit_changes", "=", "False", ")", ":", "\n", "        ", "import", "sys", "\n", "self", ".", "command_args", "=", "\"python \"", "+", "\" \"", ".", "join", "(", "sys", ".", "argv", ")", "\n", "if", "commit_changes", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "git_hash", "=", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'HEAD'", "]", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'add'", ",", "'-u'", "]", ")", "\n", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'add'", ",", "'-A'", "]", ")", "\n", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'commit'", ",", "'-m'", ",", "'running experiment '", "+", "name", "]", ")", "\n", "self", ".", "git_hash", "=", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'HEAD'", "]", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "except", ":", "\n", "                ", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'init'", "]", ")", "\n", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'add'", ",", "'-A'", "]", ")", "\n", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'commit'", ",", "'-m'", ",", "'running experiment '", "+", "name", "]", ")", "\n", "self", ".", "git_hash", "=", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'HEAD'", "]", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "# self.git_hash = \"Not a Git Repo\"", "\n", "# logger.info(\"Git hash for current experiment : %s\", self.git_hash)", "\n", "", "", "if", "not", "args", "is", "None", ":", "\n", "            ", "self", ".", "name", "=", "name", "\n", "self", ".", "params", "=", "vars", "(", "args", ")", "\n", "print", "(", "self", ".", "params", ")", "\n", "self", ".", "results", "=", "{", "}", "\n", "\n", "root_folder", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%d%B%Y\"", ")", "\n", "\n", "output_dir", "=", "str", "(", "output_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "root_folder", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/\"", "+", "root_folder", ")", "\n", "", "except", ":", "\n", "                    ", "assert", "(", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/\"", "+", "root_folder", ")", ")", "\n", "\n", "", "", "self", ".", "root_folder", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "root_folder", ")", "\n", "self", ".", "full_path", "=", "self", ".", "root_folder", "+", "\"/\"", "+", "self", ".", "name", "\n", "\n", "ver", "=", "0", "\n", "\n", "while", "os", ".", "path", ".", "exists", "(", "self", ".", "full_path", "+", "\"_\"", "+", "str", "(", "ver", ")", ")", ":", "\n", "                ", "ver", "+=", "1", "\n", "", "try", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "full_path", "+", "\"_\"", "+", "str", "(", "ver", ")", ")", "\n", "", "except", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "full_path", "+", "\"_\"", "+", "str", "(", "ver", ")", "+", "\"_race_condition\"", ")", "\n", "", "self", ".", "path", "=", "self", ".", "full_path", "+", "\"_\"", "+", "str", "(", "ver", ")", "+", "\"/\"", "\n", "# logger.info(\"Experiment result directory\", self.path)", "\n", "self", ".", "results", "[", "\"Temp Results\"", "]", "=", "[", "[", "1", ",", "2", ",", "3", ",", "4", "]", ",", "[", "5", ",", "6", ",", "2", ",", "6", "]", "]", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "self", ".", "path", "+", "\"log.txt\"", ")", "\n", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fh", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "'%(name)-12s: %(levelname)-8s %(message)s'", ")", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "ch", "=", "logging", ".", "handlers", ".", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "ch", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "'%(name)-12s: %(levelname)-8s %(message)s'", ")", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "self", ".", "store_json", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.is_jsonable": [[76, 82], ["json.dumps"], "methods", ["None"], ["", "", "def", "is_jsonable", "(", "self", ",", "x", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "json", ".", "dumps", "(", "x", ")", "\n", "return", "True", "\n", "", "except", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.add_result": [[83, 87], ["experiment.experiment.is_jsonable", "experiment.experiment.is_jsonable"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.is_jsonable", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.is_jsonable"], ["", "", "def", "add_result", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "        ", "assert", "(", "self", ".", "is_jsonable", "(", "key", ")", ")", "\n", "assert", "(", "self", ".", "is_jsonable", "(", "value", ")", ")", "\n", "self", ".", "results", "[", "key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.store_json": [[88, 92], ["open", "json.dump", "outfile.write"], "methods", ["None"], ["", "def", "store_json", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "path", "+", "\"metadata.json\"", ",", "'w'", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "__dict__", ",", "outfile", ",", "indent", "=", "4", ",", "separators", "=", "(", "','", ",", "': '", ")", ",", "sort_keys", "=", "True", ")", "\n", "outfile", ".", "write", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.get_json": [[93, 95], ["json.dumps"], "methods", ["None"], ["", "", "def", "get_json", "(", "self", ")", ":", "\n", "        ", "return", "json", ".", "dumps", "(", "self", ".", "__dict__", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.find_index": [[6, 10], ["enumerate"], "function", ["None"], ["def", "find_index", "(", "y_traj", ",", "y_rand", ")", ":", "\n", "    ", "for", "idx", ",", "label", "in", "enumerate", "(", "y_rand", "[", "0", "]", ")", ":", "\n", "        ", "if", "label", "==", "y_traj", "[", "0", "]", ":", "\n", "            ", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_balanced_data": [[11, 18], ["enumerate", "list", "min", "sorted", "cactus_partition.values", "len", "random.sample"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample"], ["", "", "", "def", "sample_balanced_data", "(", "cactus_partition", ")", ":", "\n", "    ", "for", "idx", ",", "cluster", "in", "enumerate", "(", "list", "(", "cactus_partition", ".", "values", "(", ")", ")", ")", ":", "\n", "# Sample fixed elements after clustering --> balanced dataset", "\n", "        ", "random_samples_number", "=", "min", "(", "20", ",", "len", "(", "cluster", ")", ")", "\n", "cluster", "=", "sorted", "(", "random", ".", "sample", "(", "cluster", ",", "random_samples_number", ")", ")", "\n", "cactus_partition", "[", "idx", "]", "=", "cluster", "\n", "", "return", "cactus_partition", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_random_data": [[19, 28], ["enumerate", "list", "random.randint", "sorted", "cactus_partition.values", "min", "random.sample", "len"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample"], ["", "def", "sample_random_data", "(", "cactus_partition", ")", ":", "\n", "    ", "for", "idx", ",", "cluster", "in", "enumerate", "(", "list", "(", "cactus_partition", ".", "values", "(", ")", ")", ")", ":", "\n", "# Sample random data from mini-Imagenet after clustering", "\n", "        ", "min_len", "=", "10", "\n", "max_len", "=", "30", "\n", "random_samples_number", "=", "random", ".", "randint", "(", "min_len", ",", "min", "(", "max_len", ",", "len", "(", "cluster", ")", ")", ")", "\n", "cluster", "=", "sorted", "(", "random", ".", "sample", "(", "cluster", ",", "random_samples_number", ")", ")", "\n", "cactus_partition", "[", "idx", "]", "=", "cluster", "\n", "", "return", "cactus_partition", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_unbalanced_data": [[29, 41], ["numpy.asarray", "cactus_partition.values", "enumerate", "np.asarray.min", "np.asarray.max", "int", "new_lens.append", "sorted", "len", "random.sample", "cactus_partition.values", "len"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample"], ["", "def", "sample_unbalanced_data", "(", "cactus_partition", ")", ":", "\n", "    ", "lens", "=", "np", ".", "asarray", "(", "[", "len", "(", "el", ")", "for", "el", "in", "cactus_partition", ".", "values", "(", ")", "]", ")", "\n", "min", ",", "max", "=", "lens", ".", "min", "(", ")", ",", "lens", ".", "max", "(", ")", "\n", "new_min", ",", "new_max", "=", "10", ",", "30", "\n", "new_lens", "=", "[", "]", "\n", "for", "cluster", "in", "cactus_partition", ".", "values", "(", ")", ":", "\n", "        ", "new_cluster_len", "=", "int", "(", "(", "(", "(", "new_max", "-", "new_min", ")", "*", "(", "len", "(", "cluster", ")", "-", "min", ")", ")", "/", "(", "max", "-", "min", ")", ")", "+", "new_min", ")", "\n", "new_lens", ".", "append", "(", "new_cluster_len", ")", "\n", "\n", "", "for", "idx", ",", "cluster_len", "in", "enumerate", "(", "new_lens", ")", ":", "\n", "        ", "cactus_partition", "[", "idx", "]", "=", "sorted", "(", "random", ".", "sample", "(", "cactus_partition", "[", "idx", "]", ",", "cluster_len", ")", ")", "\n", "", "return", "cactus_partition", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_reducted_dataset": [[42, 56], ["numpy.array_split", "numpy.concatenate", "enumerate", "numpy.concatenate", "numpy.random.choice", "np.concatenate.append", "numpy.asarray", "new_cls.append", "numpy.stack", "numpy.split"], "function", ["None"], ["", "def", "sample_reducted_dataset", "(", "data", ",", "labels", ",", "num_classes", ")", ":", "\n", "# Sample fixed random data from mini-Imagenet before clustering", "\n", "    ", "sample_elements", "=", "20", "\n", "data", "=", "np", ".", "array_split", "(", "data", ",", "num_classes", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "np", ".", "asarray", "(", "np", ".", "split", "(", "labels", ",", "num_classes", ")", ")", "[", ":", ",", ":", "sample_elements", "]", ")", "\n", "new_classes", "=", "[", "]", "\n", "for", "i", ",", "cls", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "indices", "=", "np", ".", "random", ".", "choice", "(", "cls", ".", "shape", "[", "0", "]", ",", "sample_elements", ",", "replace", "=", "False", ")", "\n", "new_cls", "=", "[", "]", "\n", "for", "idx", "in", "indices", ":", "\n", "            ", "new_cls", ".", "append", "(", "cls", "[", "idx", "]", ")", "\n", "", "new_classes", ".", "append", "(", "np", ".", "stack", "(", "(", "new_cls", ")", ")", ")", "\n", "", "new_classes", "=", "np", ".", "concatenate", "(", "new_classes", ")", "\n", "return", "new_classes", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.compute_weigth_vector": [[57, 83], ["cactus_partition.items", "max", "dict.fromkeys", "enumerate", "numpy.asarray().astype", "cactus_partition.keys", "range", "sorted", "len", "len", "len", "len", "cactus_partition.items", "len", "np.asarray().astype.append", "numpy.asarray", "np.asarray().astype.min", "np.asarray().astype.max", "np.asarray().astype.min", "len", "np.asarray().astype.append", "np.asarray().astype.append", "len", "len"], "function", ["None"], ["", "def", "compute_weigth_vector", "(", "cactus_partition", ")", ":", "\n", "    ", "min_len", "=", "1000", "\n", "max_len", "=", "0", "\n", "for", "el", "in", "cactus_partition", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "el", "[", "1", "]", ")", ">=", "max_len", ":", "\n", "            ", "max_len", "=", "len", "(", "el", "[", "1", "]", ")", "\n", "", "if", "len", "(", "el", "[", "1", "]", ")", "<", "min_len", ":", "\n", "            ", "min_len", "=", "len", "(", "el", "[", "1", "]", ")", "\n", "\n", "", "", "max_key", "=", "max", "(", "cactus_partition", ".", "keys", "(", ")", ")", "\n", "empty", "=", "dict", ".", "fromkeys", "(", "range", "(", "max_key", "+", "1", ")", ",", "[", "]", ")", "\n", "cactus_partition", "=", "{", "**", "empty", ",", "**", "cactus_partition", "}", "\n", "\n", "balance_vector", "=", "[", "]", "\n", "for", "idx", ",", "el", "in", "enumerate", "(", "sorted", "(", "cactus_partition", ".", "items", "(", ")", ")", ")", ":", "\n", "        ", "if", "len", "(", "el", "[", "1", "]", ")", "!=", "min_len", ":", "\n", "            ", "balance_vector", ".", "append", "(", "(", "max_len", "-", "min_len", ")", "/", "(", "len", "(", "el", "[", "1", "]", ")", "-", "min_len", ")", ")", "\n", "", "elif", "len", "(", "el", "[", "1", "]", ")", "==", "0", ":", "\n", "            ", "balance_vector", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "balance_vector", ".", "append", "(", "(", "max_len", "-", "min_len", ")", "/", "(", "(", "len", "(", "el", "[", "1", "]", ")", "+", "1", ")", "-", "min_len", ")", ")", "\n", "\n", "", "", "balance_vector", "=", "np", ".", "asarray", "(", "balance_vector", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "balance_vector", "=", "(", "balance_vector", "-", "balance_vector", ".", "min", "(", ")", ")", "/", "(", "balance_vector", ".", "max", "(", ")", "-", "balance_vector", ".", "min", "(", ")", ")", "\n", "\n", "return", "balance_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.set_seed": [[85, 91], ["random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.remove_classes": [[93, 108], ["numpy.array", "numpy.zeros_like", "numpy.nonzero", "numpy.array"], "function", ["None"], ["", "def", "remove_classes", "(", "trainset", ",", "to_keep", ")", ":", "\n", "# trainset.data = trainset.data[order]", "\n", "    ", "trainset", ".", "targets", "=", "np", ".", "array", "(", "trainset", ".", "targets", ")", "\n", "# trainset.targets = trainset.targets[order]", "\n", "\n", "indices", "=", "np", ".", "zeros_like", "(", "trainset", ".", "targets", ")", "\n", "for", "a", "in", "to_keep", ":", "\n", "        ", "indices", "=", "indices", "+", "(", "trainset", ".", "targets", "==", "a", ")", ".", "astype", "(", "int", ")", "\n", "", "indices", "=", "np", ".", "nonzero", "(", "indices", ")", "\n", "trainset", ".", "data", "=", "[", "trainset", ".", "data", "[", "i", "]", "for", "i", "in", "indices", "[", "0", "]", "]", "\n", "# trainset.data = trainset.data[indices]", "\n", "trainset", ".", "targets", "=", "np", ".", "array", "(", "trainset", ".", "targets", ")", "\n", "trainset", ".", "targets", "=", "trainset", ".", "targets", "[", "indices", "]", "\n", "\n", "return", "trainset", "\n", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_train.train": [[6, 23], ["maml.train", "numpy.random.choice", "sampler.get_complete_iterator", "maml.sample_training_data", "torch.cuda.is_available", "maml", "d_traj_iterators.append", "sampler.sample_task", "x_spt.cuda", "y_spt.cuda", "x_qry.cuda", "y_qry.cuda"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.ImagenetSampler.get_complete_iterator", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.sample_training_data", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.ImagenetSampler.sample_task"], ["def", "train", "(", "args", ",", "traj_classes", ",", "sampler", ",", "maml", ")", ":", "\n", "    ", "maml", ".", "train", "(", ")", "\n", "t1", "=", "np", ".", "random", ".", "choice", "(", "traj_classes", ",", "args", ".", "tasks", ",", "replace", "=", "False", ")", "\n", "\n", "d_traj_iterators", "=", "[", "]", "\n", "for", "t", "in", "t1", ":", "\n", "        ", "d_traj_iterators", ".", "append", "(", "sampler", ".", "sample_task", "(", "[", "t", "]", ")", ")", "\n", "\n", "", "d_rand_iterator", "=", "sampler", ".", "get_complete_iterator", "(", ")", "\n", "\n", "x_spt", ",", "y_spt", ",", "x_qry", ",", "y_qry", "=", "maml", ".", "sample_training_data", "(", "d_traj_iterators", ",", "d_rand_iterator", ",", "\n", "reset", "=", "not", "args", ".", "no_reset", ",", "rehearsal", "=", "args", ".", "rehearsal", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "x_spt", ",", "y_spt", ",", "x_qry", ",", "y_qry", "=", "x_spt", ".", "cuda", "(", ")", ",", "y_spt", ".", "cuda", "(", ")", ",", "x_qry", ".", "cuda", "(", ")", ",", "y_qry", ".", "cuda", "(", ")", "\n", "\n", "", "accs", ",", "loss", "=", "maml", "(", "x_spt", ",", "y_spt", ",", "x_qry", ",", "y_qry", ")", "\n", "return", "maml", ",", "accs", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_train.train_iid": [[25, 40], ["maml.train", "img.to.to", "y.to.to", "maml", "maml.argmax", "opt.zero_grad", "torch.nn.functional.cross_entropy", "F.cross_entropy.backward", "opt.step", "len", "torch.eq().sum().item", "len", "torch.eq().sum", "torch.eq"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train"], ["", "def", "train_iid", "(", "opt", ",", "maml", ",", "iterator", ",", "device", ")", ":", "\n", "    ", "maml", ".", "train", "(", ")", "\n", "correct", "=", "0", "\n", "for", "img", ",", "y", "in", "iterator", ":", "\n", "        ", "img", "=", "img", ".", "to", "(", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "device", ")", "\n", "pred", "=", "maml", "(", "img", ",", "vars", "=", "None", ",", "outer_att", "=", "True", ")", "\n", "pred_q", "=", "(", "pred", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "correct", "+=", "torch", ".", "eq", "(", "pred_q", ",", "y", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "img", ")", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "pred", ",", "y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "", "accs", "=", "correct", "/", "len", "(", "iterator", ")", "\n", "return", "maml", ",", "accs", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_train.test": [[42, 56], ["maml.eval", "torch.no_grad", "img.to.to", "target.to.to", "torch.nn.functional.softmax().argmax", "maml.net", "maml", "torch.eq().sum().item", "len", "torch.nn.functional.softmax", "torch.eq().sum", "torch.eq"], "function", ["None"], ["", "def", "test", "(", "maml", ",", "iid", ",", "iterator", ",", "device", ")", ":", "\n", "    ", "maml", ".", "eval", "(", ")", "\n", "correct", "=", "0", "\n", "for", "img", ",", "target", "in", "iterator", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img", "=", "img", ".", "to", "(", "device", ")", "\n", "target", "=", "target", ".", "to", "(", "device", ")", "\n", "if", "not", "iid", ":", "\n", "                ", "logits_q", "=", "maml", ".", "net", "(", "img", ",", "vars", "=", "None", ",", "outer_att", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "logits_q", "=", "maml", "(", "img", ",", "vars", "=", "None", ",", "outer_att", "=", "True", ")", "\n", "", "pred_q", "=", "F", ".", "softmax", "(", "logits_q", ",", "dim", "=", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "correct", "+=", "torch", ".", "eq", "(", "pred_q", ",", "target", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "img", ")", "\n", "", "", "return", "correct", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.model_loader": [[10, 34], ["model.modelfactory.get_model", "torch.load.to", "model.Learner", "model.Learner", "torch.load", "torch.load", "zip", "torch.load.reset_vars", "torch.Parameter", "torch.Parameter", "learner.Learner.named_parameters", "torch.load.named_parameters", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.load.vars._parameters.keys"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.modelfactory.get_model", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.reset_vars"], ["def", "model_loader", "(", "args", ",", "classes", ",", "device", ")", ":", "\n", "    ", "config", "=", "get_model", "(", "args", ",", "classes", ")", "\n", "if", "args", ".", "scratch", ":", "\n", "        ", "maml", "=", "learner", ".", "Learner", "(", "config", ",", "args", ")", "\n", "", "else", ":", "\n", "        ", "maml_old", "=", "learner", ".", "Learner", "(", "config", ",", "args", ")", "\n", "maml", "=", "torch", ".", "load", "(", "args", ".", "model", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "if", "maml", ".", "config", "[", "-", "1", "]", "[", "'config'", "]", "[", "'out-channels'", "]", "!=", "classes", ":", "\n", "            ", "maml", ".", "config", "[", "-", "1", "]", "[", "'config'", "]", "[", "'out-channels'", "]", "=", "classes", "\n", "key_last_vars", "=", "[", "*", "maml", ".", "vars", ".", "_parameters", ".", "keys", "(", ")", "]", "[", "-", "2", ":", "]", "\n", "maml", ".", "vars", ".", "_parameters", "[", "key_last_vars", "[", "0", "]", "]", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "ones", "(", "classes", ",", "maml", ".", "vars", ".", "_parameters", "[", "key_last_vars", "[", "0", "]", "]", ".", "shape", "[", "1", "]", ")", ")", "\n", "maml", ".", "vars", ".", "_parameters", "[", "key_last_vars", "[", "1", "]", "]", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "classes", ")", ")", "\n", "\n", "", "for", "(", "n1", ",", "old_model", ")", ",", "(", "n2", ",", "loaded_model", ")", "in", "zip", "(", "maml_old", ".", "named_parameters", "(", ")", ",", "maml", ".", "named_parameters", "(", ")", ")", ":", "\n", "            ", "loaded_model", ".", "adaptation", "=", "old_model", ".", "adaptation", "\n", "loaded_model", ".", "meta", "=", "old_model", ".", "meta", "\n", "\n", "", "maml", ".", "reset_vars", "(", ")", "\n", "\n", "", "maml", "=", "maml", ".", "to", "(", "device", ")", "\n", "\n", "return", "maml", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train": [[36, 65], ["maml.train", "utils.rehearsal.ReservoirSampler", "torch.optim.Adam", "torch.optim.Adam", "range", "maml.get_adaptation_parameters", "utils.rehearsal.ReservoirSampler.add", "maml", "torch.optim.Adam.zero_grad", "torch.nn.functional.cross_entropy", "F.cross_entropy.backward", "torch.optim.Adam.step", "utils.rehearsal.ReservoirSampler.sample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "img.to.to", "y.to.to", "len", "x_coreset.append", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.get_adaptation_parameters", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.add", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample"], ["", "def", "train", "(", "args", ",", "maml", ",", "iterator_sorted", ",", "aggregation", ",", "device", ",", "lr", ")", ":", "\n", "    ", "maml", ".", "train", "(", ")", "\n", "res_sampler", "=", "ReservoirSampler", "(", "args", ".", "windows", ",", "args", ".", "buffer_size", ")", "\n", "opt", "=", "torch", ".", "optim", ".", "Adam", "(", "maml", ".", "get_adaptation_parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "for", "_", "in", "range", "(", "0", ",", "args", ".", "epoch", ")", ":", "\n", "        ", "for", "img", ",", "y", "in", "iterator_sorted", ":", "\n", "# Rehearsal", "\n", "            ", "res_sampler", ".", "add", "(", "(", "img", ",", "y", ")", ")", "\n", "if", "args", ".", "rehearsal", "and", "len", "(", "res_sampler", ".", "buffer", ")", ">=", "10", ":", "\n", "                ", "coreset", "=", "res_sampler", ".", "sample", "(", "5", ")", "\n", "x_coreset", ",", "y_coreset", "=", "[", "]", ",", "[", "]", "\n", "for", "example", "in", "coreset", ":", "\n", "                    ", "x_coreset", ".", "append", "(", "example", "[", "0", "]", ")", "\n", "y_coreset", ".", "append", "(", "example", "[", "1", "]", ")", "\n", "", "img_coreset", "=", "torch", ".", "cat", "(", "x_coreset", ")", "\n", "y_coreset", "=", "torch", ".", "cat", "(", "y_coreset", ")", "\n", "\n", "img", "=", "torch", ".", "cat", "(", "[", "img", ",", "img_coreset", "]", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "y_coreset", "]", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "                ", "img", "=", "img", ".", "to", "(", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "device", ")", "\n", "\n", "", "pred", "=", "maml", "(", "img", ",", "outer_att", "=", "aggregation", ")", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "pred", ",", "y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "", "", "return", "maml", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test": [[67, 83], ["maml.eval", "logger.info", "len", "str", "torch.no_grad", "torch.no_grad", "img.to.to", "target.to.to", "maml", "maml.argmax", "torch.eq().sum().item", "torch.eq().sum().item", "len", "torch.eq().sum", "torch.eq().sum", "torch.eq", "torch.eq"], "function", ["None"], ["", "def", "test", "(", "logger", ",", "maml", ",", "iterator", ",", "aggregation", ",", "device", ")", ":", "\n", "    ", "maml", ".", "eval", "(", ")", "\n", "correct", "=", "0", "\n", "for", "img", ",", "target", "in", "iterator", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img", "=", "img", ".", "to", "(", "device", ")", "\n", "target", "=", "target", ".", "to", "(", "device", ")", "\n", "logits_q", "=", "maml", "(", "img", ",", "vars", "=", "None", ",", "outer_att", "=", "aggregation", ")", "\n", "\n", "pred_q", "=", "(", "logits_q", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "\n", "correct", "+=", "torch", ".", "eq", "(", "pred_q", ",", "target", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "img", ")", "\n", "\n", "", "", "current_acc", "=", "correct", "/", "len", "(", "iterator", ")", "\n", "logger", ".", "info", "(", "str", "(", "current_acc", ")", ")", "\n", "return", "current_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.lr_search": [[85, 106], ["range", "float", "logger.info", "lr_all.append", "str", "meta_test.model_loader", "meta_test.train", "logger.info", "meta_test.test", "print", "print", "scipy.stats.mode"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.model_loader", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test"], ["", "def", "lr_search", "(", "args", ",", "classes", ",", "iterator_sorted", ",", "iterator", ",", "logger", ",", "aggregation", ",", "device", ")", ":", "\n", "    ", "lr_list", "=", "[", "0.03", ",", "0.01", ",", "0.003", ",", "0.001", ",", "0.0003", ",", "0.0001", ",", "0.00003", ",", "0.00001", ",", "0.000003", ",", "0.000001", ",", "0.0000003", ",", "0.0000001", "]", "\n", "lr_all", "=", "[", "]", "\n", "max_lr", "=", "0", "\n", "for", "lr_search", "in", "range", "(", "0", ",", "5", ")", ":", "\n", "        ", "max_acc", "=", "-", "10", "\n", "for", "lr", "in", "lr_list", ":", "\n", "            ", "maml", "=", "model_loader", "(", "args", ",", "classes", ",", "device", ")", "\n", "args", ".", "epoch", "=", "1", "\n", "maml", "=", "train", "(", "args", ",", "maml", ",", "iterator_sorted", ",", "aggregation", ",", "device", ",", "lr", ")", "\n", "logger", ".", "info", "(", "\"Result after one epoch for LR = %f\"", ",", "lr", ")", "\n", "current_acc", "=", "test", "(", "logger", ",", "maml", ",", "iterator", ",", "aggregation", ",", "device", ")", "\n", "if", "current_acc", ">", "max_acc", ":", "\n", "                ", "max_acc", "=", "current_acc", "\n", "max_lr", "=", "lr", "\n", "print", "(", "\"max lr \"", ",", "max_lr", ")", "\n", "print", "(", "\"mac acc \"", ",", "max_acc", ")", "\n", "", "", "lr_all", ".", "append", "(", "max_lr", ")", "\n", "", "best_lr", "=", "float", "(", "stats", ".", "mode", "(", "lr_all", ")", "[", "0", "]", "[", "0", "]", ")", "\n", "logger", ".", "info", "(", "\"BEST LR %s= \"", ",", "str", "(", "best_lr", ")", ")", "\n", "return", "best_lr", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cifar.Cifar.__init__": [[11, 44], ["numpy.concatenate", "numpy.load.transpose().astype", "numpy.pad", "numpy.repeat", "list", "list", "range", "print", "numpy.load", "numpy.load", "numpy.arange", "int", "len", "pathlib.Path.joinpath", "pathlib.Path.joinpath", "numpy.load.transpose", "range", "range", "numpy.unique", "len", "cifar.Cifar.data2.append", "cifar.Cifar.targets2.append", "cifar.Cifar.data2.append", "cifar.Cifar.targets2.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "        ", "if", "all", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "pathlib", ".", "Path", ".", "joinpath", "(", "DATASET_PATH", ",", "\"train.npy\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "pathlib", ".", "Path", ".", "joinpath", "(", "DATASET_PATH", ",", "\"test.npy\"", ")", ")", "\n", "\n", "", "classes", "=", "data", ".", "shape", "[", "0", "]", "\n", "sample_elements", "=", "20", "\n", "data", "=", "np", ".", "concatenate", "(", "data", "[", ":", ",", ":", "sample_elements", "]", ")", "\n", "data", "=", "data", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "data", "=", "np", ".", "pad", "(", "data", ",", "(", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "26", ",", "26", ")", ",", "(", "26", ",", "26", ")", ")", ")", "\n", "labels", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "classes", ")", ",", "sample_elements", ")", "\n", "\n", "self", ".", "data", "=", "list", "(", "data", ")", "\n", "self", ".", "targets", "=", "list", "(", "labels", ")", "\n", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "for", "a", "in", "range", "(", "int", "(", "len", "(", "self", ".", "targets", ")", "/", "20", ")", ")", ":", "\n", "            ", "start", "=", "a", "*", "20", "\n", "if", "train", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", ",", "start", "+", "15", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", "+", "15", ",", "start", "+", "20", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "\n", "", "", "", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cifar.Cifar.__len__": [[45, 47], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cifar.Cifar.__getitem__": [[48, 58], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset": [[8, 20], ["datasets.Omniglot", "datasets.MiniImagenet", "datasets.Cifar", "datasets.Cub", "print"], "function", ["None"], ["def", "get_dataset", "(", "args", ",", "data", ",", "labels", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "dataset", "==", "\"omniglot\"", ":", "\n", "        ", "return", "om", ".", "Omniglot", "(", "data", ",", "labels", ",", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"imagenet\"", ":", "\n", "        ", "return", "mi", ".", "MiniImagenet", "(", "data", ",", "labels", ",", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"cifar\"", ":", "\n", "        ", "return", "cf", ".", "Cifar", "(", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"cub\"", ":", "\n", "        ", "return", "cub", ".", "Cub", "(", "data", ",", "labels", ",", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Unsupported Dataset\"", ")", "\n", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.cactus": [[22, 28], ["datasets.task_generator.TaskGenerator", "datasets.task_generator.TaskGenerator.get_partitions_kmeans", "datasets.task_generator.TaskGenerator.make_unsupervised_dataset"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.get_partitions_kmeans", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.make_unsupervised_dataset"], ["", "", "def", "cactus", "(", "args", ",", "X", ",", "Z", ",", "Y", ",", "train", ")", ":", "\n", "    ", "num_samples_per_class", "=", "args", ".", "num_train_samples_per_class", "+", "args", ".", "num_val_samples_per_class", "\n", "task_generator", "=", "TaskGenerator", "(", "num_samples_per_class", "=", "num_samples_per_class", ",", "args", "=", "args", ")", "\n", "partition", "=", "task_generator", ".", "get_partitions_kmeans", "(", "encodings", "=", "Z", ",", "train", "=", "train", ")", "\n", "data", ",", "labels", ",", "true_labels", "=", "task_generator", ".", "make_unsupervised_dataset", "(", "data", "=", "X", ",", "partition", "=", "partition", ",", "true_labels", "=", "Y", ")", "\n", "return", "data", ",", "labels", ",", "true_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset_unbalanced": [[30, 43], ["datasets.OmniglotUnbalanced", "datasets.OmniglotAugmentation", "datasets.MiniImagenetUnbalanced", "datasets.CubUnsupervised", "print"], "function", ["None"], ["", "def", "get_dataset_unbalanced", "(", "args", ",", "data", ",", "partition", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "dataset", "==", "\"omniglot\"", ":", "\n", "        ", "if", "not", "args", ".", "aug", ":", "\n", "            ", "return", "om", ".", "OmniglotUnbalanced", "(", "data", ",", "partition", ",", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "else", ":", "\n", "            ", "return", "om", ".", "OmniglotAugmentation", "(", "data", ",", "partition", ",", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "", "elif", "args", ".", "dataset", "==", "\"imagenet\"", ":", "\n", "        ", "return", "mi", ".", "MiniImagenetUnbalanced", "(", "data", ",", "partition", ",", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"cub\"", ":", "\n", "        ", "return", "cub", ".", "CubUnsupervised", "(", "data", ",", "partition", ",", "train", "=", "train", ",", "all", "=", "all", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Unsupported Dataset\"", ")", "\n", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.cactus_unbalanced": [[45, 50], ["datasets.task_generator.TaskGenerator", "datasets.task_generator.TaskGenerator.get_partitions_kmeans"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.get_partitions_kmeans"], ["", "", "def", "cactus_unbalanced", "(", "args", ",", "Z", ",", "train", ")", ":", "\n", "    ", "num_samples_per_class", "=", "args", ".", "lb", "\n", "task_generator", "=", "TaskGenerator", "(", "num_samples_per_class", "=", "num_samples_per_class", ",", "args", "=", "args", ")", "\n", "partition", "=", "task_generator", ".", "get_partitions_kmeans", "(", "encodings", "=", "Z", ",", "train", "=", "train", ")", "\n", "return", "partition", "\n", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SamplerFactory.__init__": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SamplerFactory.get_sampler": [[13, 19], ["task_sampler.OmniglotSampler", "task_sampler.ImagenetSampler"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_sampler", "(", "dataset", ",", "tasks", ",", "trainset", ",", "testset", "=", "None", ")", ":", "\n", "        ", "if", "\"omni\"", "in", "dataset", ":", "\n", "            ", "return", "OmniglotSampler", "(", "tasks", ",", "trainset", ",", "testset", ")", "\n", "", "elif", "\"imagenet\"", ":", "\n", "            ", "return", "ImagenetSampler", "(", "tasks", ",", "trainset", ",", "testset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.OmniglotSampler.__init__": [[23, 27], ["task_sampler.SampleOmni", "task_sampler.OmniglotSampler.task_sampler.add_complete_iterator", "list", "range", "int", "len"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_complete_iterator"], ["    ", "def", "__init__", "(", "self", ",", "tasks", ",", "trainset", ",", "testset", ")", ":", "\n", "        ", "self", ".", "tasks", "=", "tasks", "\n", "self", ".", "task_sampler", "=", "SampleOmni", "(", "trainset", ",", "testset", ")", "\n", "self", ".", "task_sampler", ".", "add_complete_iterator", "(", "list", "(", "range", "(", "0", ",", "int", "(", "len", "(", "self", ".", "tasks", ")", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.OmniglotSampler.get_complete_iterator": [[28, 30], ["None"], "methods", ["None"], ["", "def", "get_complete_iterator", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "task_sampler", ".", "complete_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.OmniglotSampler.sample_task": [[31, 33], ["task_sampler.OmniglotSampler.task_sampler.get"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get"], ["", "def", "sample_task", "(", "self", ",", "t", ",", "train", "=", "True", ")", ":", "\n", "        ", "return", "self", ".", "task_sampler", ".", "get", "(", "t", ",", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.ImagenetSampler.__init__": [[37, 41], ["task_sampler.SampleImagenet", "task_sampler.ImagenetSampler.task_sampler.add_complete_iterator", "list", "range", "int", "len"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_complete_iterator"], ["    ", "def", "__init__", "(", "self", ",", "tasks", ",", "trainset", ",", "testset", ")", ":", "\n", "        ", "self", ".", "tasks", "=", "tasks", "\n", "self", ".", "task_sampler", "=", "SampleImagenet", "(", "trainset", ",", "testset", ")", "\n", "self", ".", "task_sampler", ".", "add_complete_iterator", "(", "list", "(", "range", "(", "0", ",", "int", "(", "len", "(", "self", ".", "tasks", ")", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.ImagenetSampler.get_complete_iterator": [[42, 44], ["None"], "methods", ["None"], ["", "def", "get_complete_iterator", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "task_sampler", ".", "complete_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.ImagenetSampler.sample_task": [[45, 47], ["task_sampler.ImagenetSampler.task_sampler.get"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get"], ["", "def", "sample_task", "(", "self", ",", "t", ",", "train", "=", "True", ")", ":", "\n", "        ", "return", "self", ".", "task_sampler", ".", "get", "(", "t", ",", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.ImagenetSampler.sample_tasks": [[48, 55], ["task_sampler.ImagenetSampler.task_sampler.get_task_trainset", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get_task_trainset"], ["", "def", "sample_tasks", "(", "self", ",", "t", ",", "train", "=", "False", ")", ":", "\n", "# assert(false)", "\n", "        ", "dataset", "=", "self", ".", "task_sampler", ".", "get_task_trainset", "(", "t", ",", "train", ")", "\n", "train_iterator", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "return", "train_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleOmni.__init__": [[59, 65], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "trainset", ",", "testset", ")", ":", "\n", "        ", "self", ".", "task_iterators", "=", "[", "]", "\n", "self", ".", "trainset", "=", "trainset", "\n", "self", ".", "testset", "=", "testset", "\n", "self", ".", "iterators", "=", "{", "}", "\n", "self", ".", "test_iterators", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleOmni.add_complete_iterator": [[66, 81], ["task_sampler.SampleOmni.get_task_trainset", "torch.utils.data.DataLoader", "logger.info", "torch.utils.data.DataLoader", "len"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get_task_trainset"], ["", "def", "add_complete_iterator", "(", "self", ",", "tasks", ")", ":", "\n", "        ", "dataset", "=", "self", ".", "get_task_trainset", "(", "tasks", ",", "True", ")", "\n", "\n", "# dataset = self.get_task_testset(tasks)", "\n", "train_iterator", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "10", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "self", ".", "complete_iterator", "=", "train_iterator", "\n", "logger", ".", "info", "(", "\"Len of complete iterator = %d\"", ",", "len", "(", "self", ".", "complete_iterator", ")", "*", "256", ")", "\n", "\n", "train_iterator2", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "\n", "self", ".", "another_complete_iterator", "=", "train_iterator2", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleOmni.add_task_iterator": [[82, 90], ["task_sampler.SampleOmni.get_task_trainset", "torch.utils.data.DataLoader", "print"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get_task_trainset"], ["", "def", "add_task_iterator", "(", "self", ",", "task", ",", "train", ")", ":", "\n", "        ", "dataset", "=", "self", ".", "get_task_trainset", "(", "[", "task", "]", ",", "train", ")", "\n", "train_iterator", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "self", ".", "iterators", "[", "task", "]", "=", "train_iterator", "\n", "print", "(", "\"Task %d has been added to the list\"", "%", "task", ")", "\n", "return", "train_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleOmni.get": [[91, 104], ["task_sampler.SampleOmni.add_task_iterator", "task_sampler.SampleOmni.add_task_iterator"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_task_iterator", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_task_iterator"], ["", "def", "get", "(", "self", ",", "tasks", ",", "train", ")", ":", "\n", "        ", "if", "train", ":", "\n", "            ", "for", "task", "in", "tasks", ":", "\n", "                ", "if", "task", "in", "self", ".", "iterators", ":", "\n", "                    ", "return", "self", ".", "iterators", "[", "task", "]", "\n", "", "else", ":", "\n", "                    ", "return", "self", ".", "add_task_iterator", "(", "task", ",", "True", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "task", "in", "tasks", ":", "\n", "                ", "if", "tasks", "in", "self", ".", "test_iterators", ":", "\n", "                    ", "return", "self", ".", "test_iterators", "[", "task", "]", "\n", "", "else", ":", "\n", "                    ", "return", "self", ".", "add_task_iterator", "(", "task", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleOmni.get_task_trainset": [[105, 126], ["numpy.asarray", "numpy.zeros_like", "numpy.nonzero", "copy.deepcopy", "copy.deepcopy"], "methods", ["None"], ["", "", "", "", "def", "get_task_trainset", "(", "self", ",", "tasks", ",", "train", ")", ":", "\n", "\n", "        ", "if", "train", ":", "\n", "            ", "set", "=", "copy", ".", "deepcopy", "(", "self", ".", "trainset", ")", "\n", "", "else", ":", "\n", "            ", "set", "=", "copy", ".", "deepcopy", "(", "self", ".", "testset", ")", "\n", "# class labels -> set.targets", "\n", "", "class_labels", "=", "np", ".", "asarray", "(", "set", ".", "targets", ")", "\n", "\n", "indices", "=", "np", ".", "zeros_like", "(", "class_labels", ")", "\n", "for", "a", "in", "tasks", ":", "\n", "            ", "indices", "=", "indices", "+", "(", "class_labels", "==", "a", ")", ".", "astype", "(", "int", ")", "\n", "", "indices", "=", "np", ".", "nonzero", "(", "indices", ")", "\n", "\n", "set", ".", "data", "=", "[", "set", ".", "data", "[", "i", "]", "for", "i", "in", "indices", "[", "0", "]", "]", "\n", "set", ".", "targets", "=", "[", "set", ".", "targets", "[", "i", "]", "for", "i", "in", "indices", "[", "0", "]", "]", "\n", "\n", "set", ".", "data2", "=", "[", "]", "\n", "set", ".", "targets2", "=", "[", "]", "\n", "\n", "return", "set", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleOmni.filter_upto": [[127, 133], ["copy.deepcopy"], "methods", ["None"], ["", "def", "filter_upto", "(", "self", ",", "task", ")", ":", "\n", "\n", "        ", "trainset", "=", "copy", ".", "deepcopy", "(", "self", ".", "trainset", ")", "\n", "trainset", ".", "data", "=", "trainset", ".", "data", "[", "trainset", ".", "data", "[", "'target'", "]", "<=", "task", "]", "\n", "\n", "return", "trainset", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.__init__": [[137, 143], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "trainset", ",", "testset", ")", ":", "\n", "        ", "self", ".", "task_iterators", "=", "[", "]", "\n", "self", ".", "trainset", "=", "trainset", "\n", "self", ".", "testset", "=", "testset", "\n", "self", ".", "iterators", "=", "{", "}", "\n", "self", ".", "test_iterators", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_complete_iterator": [[144, 158], ["task_sampler.SampleImagenet.get_task_trainset", "torch.utils.data.DataLoader", "logger.info", "torch.utils.data.DataLoader", "len"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get_task_trainset"], ["", "def", "add_complete_iterator", "(", "self", ",", "tasks", ")", ":", "\n", "        ", "dataset", "=", "self", ".", "get_task_trainset", "(", "tasks", ",", "True", ")", "\n", "# dataset = self.get_task_testset(tasks)", "\n", "train_iterator", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "10", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "self", ".", "complete_iterator", "=", "train_iterator", "\n", "logger", ".", "info", "(", "\"Len of complete iterator = %d\"", ",", "len", "(", "self", ".", "complete_iterator", ")", "*", "256", ")", "\n", "\n", "train_iterator2", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "\n", "self", ".", "another_complete_iterator", "=", "train_iterator2", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_task_iterator": [[159, 168], ["task_sampler.SampleImagenet.get_task_trainset", "torch.utils.data.DataLoader", "print"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get_task_trainset"], ["", "def", "add_task_iterator", "(", "self", ",", "task", ",", "train", ")", ":", "\n", "\n", "        ", "dataset", "=", "self", ".", "get_task_trainset", "(", "[", "task", "]", ",", "train", ")", "\n", "train_iterator", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "0", ")", "\n", "self", ".", "iterators", "[", "task", "]", "=", "train_iterator", "\n", "print", "(", "\"Task %d has been added to the list\"", "%", "task", ")", "\n", "return", "train_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get": [[169, 182], ["task_sampler.SampleImagenet.add_task_iterator", "task_sampler.SampleImagenet.add_task_iterator"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_task_iterator", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.add_task_iterator"], ["", "def", "get", "(", "self", ",", "tasks", ",", "train", ")", ":", "\n", "        ", "if", "train", ":", "\n", "            ", "for", "task", "in", "tasks", ":", "\n", "                ", "if", "task", "in", "self", ".", "iterators", ":", "\n", "                    ", "return", "self", ".", "iterators", "[", "task", "]", "\n", "", "else", ":", "\n", "                    ", "return", "self", ".", "add_task_iterator", "(", "task", ",", "True", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "task", "in", "tasks", ":", "\n", "                ", "if", "tasks", "in", "self", ".", "test_iterators", ":", "\n", "                    ", "return", "self", ".", "test_iterators", "[", "task", "]", "\n", "", "else", ":", "\n", "                    ", "return", "self", ".", "add_task_iterator", "(", "task", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.get_task_trainset": [[183, 204], ["numpy.asarray", "numpy.zeros_like", "numpy.nonzero", "copy.deepcopy", "copy.deepcopy"], "methods", ["None"], ["", "", "", "", "def", "get_task_trainset", "(", "self", ",", "tasks", ",", "train", ")", ":", "\n", "\n", "        ", "if", "train", ":", "\n", "            ", "set", "=", "copy", ".", "deepcopy", "(", "self", ".", "trainset", ")", "\n", "", "else", ":", "\n", "            ", "set", "=", "copy", ".", "deepcopy", "(", "self", ".", "testset", ")", "\n", "# class labels -> set.targets", "\n", "", "class_labels", "=", "np", ".", "asarray", "(", "set", ".", "targets", ")", "\n", "\n", "indices", "=", "np", ".", "zeros_like", "(", "class_labels", ")", "\n", "for", "a", "in", "tasks", ":", "\n", "            ", "indices", "=", "indices", "+", "(", "class_labels", "==", "a", ")", ".", "astype", "(", "int", ")", "\n", "", "indices", "=", "np", ".", "nonzero", "(", "indices", ")", "\n", "\n", "set", ".", "data", "=", "[", "set", ".", "data", "[", "i", "]", "for", "i", "in", "indices", "[", "0", "]", "]", "\n", "set", ".", "targets", "=", "[", "set", ".", "targets", "[", "i", "]", "for", "i", "in", "indices", "[", "0", "]", "]", "\n", "\n", "set", ".", "data2", "=", "[", "]", "\n", "set", ".", "targets2", "=", "[", "]", "\n", "\n", "return", "set", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SampleImagenet.filter_upto": [[205, 211], ["copy.deepcopy"], "methods", ["None"], ["", "def", "filter_upto", "(", "self", ",", "task", ")", ":", "\n", "\n", "        ", "trainset", "=", "copy", ".", "deepcopy", "(", "self", ".", "trainset", ")", "\n", "trainset", ".", "data", "=", "trainset", ".", "data", "[", "trainset", ".", "data", "[", "'target'", "]", "<=", "task", "]", "\n", "\n", "return", "trainset", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cub.Cub.__init__": [[15, 47], ["numpy.asarray().astype", "numpy.argsort", "numpy.asarray", "numpy.asarray", "list", "list", "range", "print", "torch.transpose().astype", "numpy.asarray.append", "numpy.asarray.append", "int", "len", "numpy.asarray", "range", "range", "numpy.unique", "torch.transpose", "len", "cub.Cub.data2.append", "cub.Cub.targets2.append", "cub.Cub.data2.append", "cub.Cub.targets2.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "labels", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "        ", "data", "=", "data", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "labels", "=", "np", ".", "asarray", "(", "labels", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "labels", ")", "\n", "sorted_data", "=", "[", "]", "\n", "sorted_true_labels", "=", "[", "]", "\n", "for", "index", "in", "sorted_indices", ":", "\n", "            ", "sorted_data", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "sorted_true_labels", ".", "append", "(", "labels", "[", "index", "]", ")", "\n", "", "sorted_data", "=", "np", ".", "asarray", "(", "sorted_data", ")", "\n", "sorted_true_labels", "=", "np", ".", "asarray", "(", "sorted_true_labels", ")", "\n", "\n", "self", ".", "data", "=", "list", "(", "sorted_data", ")", "\n", "self", ".", "targets", "=", "list", "(", "sorted_true_labels", ")", "\n", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "\n", "for", "a", "in", "range", "(", "int", "(", "len", "(", "self", ".", "targets", ")", "/", "20", ")", ")", ":", "\n", "            ", "start", "=", "a", "*", "20", "\n", "if", "train", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", ",", "start", "+", "15", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", "+", "15", ",", "start", "+", "20", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "", "", "", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cub.Cub.__len__": [[48, 50], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cub.Cub.__getitem__": [[51, 61], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cub.CubUnsupervised.__init__": [[64, 95], ["collections.OrderedDict", "collections.defaultdict", "collections.OrderedDict.items", "collections.defaultdict.items", "print", "sorted", "key.astype.astype.astype", "int", "cub.CubUnsupervised.data.extend", "cub.CubUnsupervised.targets.extend", "len", "collections.OrderedDict.items", "new_partition[].append", "itertools.repeat", "cub.CubUnsupervised.data2.extend", "cub.CubUnsupervised.targets2.extend", "cub.CubUnsupervised.data2.extend", "cub.CubUnsupervised.targets2.extend", "numpy.unique", "len", "len", "itertools.repeat", "itertools.repeat", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "partition", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "        ", "crop", "=", "84", "\n", "start", "=", "data", ".", "shape", "[", "2", "]", "//", "2", "-", "crop", "//", "2", "\n", "data", "=", "data", "[", ":", ",", ":", ",", "start", ":", "start", "+", "crop", ",", "start", ":", "start", "+", "crop", "]", "\n", "\n", "partition", "=", "OrderedDict", "(", "sorted", "(", "partition", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "new_partition", "=", "defaultdict", "(", "list", ")", "\n", "for", "key", ",", "values", "in", "partition", ".", "items", "(", ")", ":", "\n", "            ", "for", "index", "in", "values", ":", "\n", "                ", "new_partition", "[", "key", "]", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "\n", "", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "for", "key", ",", "values", "in", "new_partition", ".", "items", "(", ")", ":", "\n", "            ", "key", "=", "key", ".", "astype", "(", "np", ".", "int64", ")", "\n", "train_partition", "=", "int", "(", "0.75", "*", "len", "(", "values", ")", ")", "\n", "self", ".", "data", ".", "extend", "(", "values", ")", "\n", "self", ".", "targets", ".", "extend", "(", "repeat", "(", "key", ",", "len", "(", "values", ")", ")", ")", "\n", "if", "train", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", ":", "train_partition", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "train_partition", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", "train_partition", ":", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "(", "len", "(", "values", ")", "-", "train_partition", ")", ")", ")", "\n", "\n", "", "", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cub.CubUnsupervised.__len__": [[96, 98], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.cub.CubUnsupervised.__getitem__": [[99, 109], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.miniimagenet.MiniImagenet.__init__": [[8, 44], ["numpy.asarray().astype", "numpy.argsort", "numpy.asarray", "numpy.asarray", "list", "list", "range", "print", "data.transpose().astype", "numpy.asarray.append", "numpy.asarray.append", "int", "len", "numpy.asarray", "range", "range", "numpy.unique", "data.transpose", "len", "miniimagenet.MiniImagenet.data2.append", "miniimagenet.MiniImagenet.targets2.append", "miniimagenet.MiniImagenet.data2.append", "miniimagenet.MiniImagenet.targets2.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "labels", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "\n", "        ", "data", "=", "data", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "labels", "=", "np", ".", "asarray", "(", "labels", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "labels", ")", "\n", "sorted_data", "=", "[", "]", "\n", "sorted_true_labels", "=", "[", "]", "\n", "for", "index", "in", "sorted_indices", ":", "\n", "            ", "sorted_data", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "sorted_true_labels", ".", "append", "(", "labels", "[", "index", "]", ")", "\n", "", "sorted_data", "=", "np", ".", "asarray", "(", "sorted_data", ")", "\n", "sorted_true_labels", "=", "np", ".", "asarray", "(", "sorted_true_labels", ")", "\n", "\n", "self", ".", "data", "=", "list", "(", "sorted_data", ")", "\n", "self", ".", "targets", "=", "list", "(", "sorted_true_labels", ")", "\n", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "\n", "for", "a", "in", "range", "(", "int", "(", "len", "(", "self", ".", "targets", ")", "/", "20", ")", ")", ":", "\n", "            ", "start", "=", "a", "*", "20", "\n", "if", "train", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", ",", "start", "+", "15", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", "+", "15", ",", "start", "+", "20", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "", "", "", "if", "all", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.miniimagenet.MiniImagenet.__len__": [[45, 47], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.miniimagenet.MiniImagenet.__getitem__": [[48, 58], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.miniimagenet.MiniImagenetUnbalanced.__init__": [[61, 94], ["collections.OrderedDict", "collections.defaultdict", "collections.OrderedDict.items", "collections.defaultdict.items", "print", "data.transpose().astype", "sorted", "key.astype.astype.astype", "int", "miniimagenet.MiniImagenetUnbalanced.data.extend", "miniimagenet.MiniImagenetUnbalanced.targets.extend", "len", "collections.OrderedDict.items", "new_partition[].append", "itertools.repeat", "miniimagenet.MiniImagenetUnbalanced.data2.extend", "miniimagenet.MiniImagenetUnbalanced.targets2.extend", "miniimagenet.MiniImagenetUnbalanced.data2.extend", "miniimagenet.MiniImagenetUnbalanced.targets2.extend", "numpy.unique", "data.transpose", "len", "len", "itertools.repeat", "itertools.repeat", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "partition", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "\n", "        ", "data", "=", "data", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "\n", "partition", "=", "OrderedDict", "(", "sorted", "(", "partition", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "new_partition", "=", "defaultdict", "(", "list", ")", "\n", "for", "key", ",", "values", "in", "partition", ".", "items", "(", ")", ":", "\n", "            ", "for", "index", "in", "values", ":", "\n", "                ", "new_partition", "[", "key", "]", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "\n", "", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "for", "key", ",", "values", "in", "new_partition", ".", "items", "(", ")", ":", "\n", "            ", "key", "=", "key", ".", "astype", "(", "np", ".", "int64", ")", "\n", "train_partition", "=", "int", "(", "0.75", "*", "len", "(", "values", ")", ")", "\n", "self", ".", "data", ".", "extend", "(", "values", ")", "\n", "self", ".", "targets", ".", "extend", "(", "repeat", "(", "key", ",", "len", "(", "values", ")", ")", ")", "\n", "if", "train", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", ":", "train_partition", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "train_partition", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", "train_partition", ":", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "(", "len", "(", "values", ")", "-", "train_partition", ")", ")", ")", "\n", "\n", "", "", "if", "all", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.miniimagenet.MiniImagenetUnbalanced.__len__": [[95, 97], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.miniimagenet.MiniImagenetUnbalanced.__getitem__": [[98, 108], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.Omniglot.__init__": [[10, 43], ["numpy.asarray", "numpy.argsort", "numpy.asarray", "numpy.asarray", "list", "list", "range", "print", "torch.transpose().astype", "numpy.asarray.append", "numpy.asarray.append", "int", "len", "range", "range", "numpy.unique", "torch.transpose", "len", "omniglot.Omniglot.data2.append", "omniglot.Omniglot.targets2.append", "omniglot.Omniglot.data2.append", "omniglot.Omniglot.targets2.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "labels", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "\n", "        ", "data", "=", "data", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "labels", "=", "np", ".", "asarray", "(", "labels", ")", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "labels", ")", "\n", "sorted_data", "=", "[", "]", "\n", "sorted_labels", "=", "[", "]", "\n", "for", "index", "in", "sorted_indices", ":", "\n", "            ", "sorted_data", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "sorted_labels", ".", "append", "(", "labels", "[", "index", "]", ")", "\n", "", "sorted_data", "=", "np", ".", "asarray", "(", "sorted_data", ")", "\n", "sorted_labels", "=", "np", ".", "asarray", "(", "sorted_labels", ")", "\n", "\n", "self", ".", "data", "=", "list", "(", "sorted_data", ")", "\n", "self", ".", "targets", "=", "list", "(", "sorted_labels", ")", "\n", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "for", "a", "in", "range", "(", "int", "(", "len", "(", "self", ".", "targets", ")", "/", "20", ")", ")", ":", "\n", "            ", "start", "=", "a", "*", "20", "\n", "if", "train", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", ",", "start", "+", "15", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "b", "in", "range", "(", "start", "+", "15", ",", "start", "+", "20", ")", ":", "\n", "                    ", "self", ".", "data2", ".", "append", "(", "self", ".", "data", "[", "b", "]", ")", "\n", "self", ".", "targets2", ".", "append", "(", "self", ".", "targets", "[", "b", "]", ")", "\n", "\n", "", "", "", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.Omniglot.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.Omniglot.__getitem__": [[47, 57], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.OmniglotUnbalanced.__init__": [[60, 95], ["collections.OrderedDict", "collections.defaultdict", "collections.OrderedDict.items", "collections.defaultdict.items", "print", "len", "sorted", "key.astype.astype.astype", "int", "omniglot.OmniglotUnbalanced.data.extend", "omniglot.OmniglotUnbalanced.targets.extend", "len", "torch.transpose().astype", "collections.OrderedDict.items", "new_partition[].append", "itertools.repeat", "omniglot.OmniglotUnbalanced.data2.extend", "omniglot.OmniglotUnbalanced.targets2.extend", "omniglot.OmniglotUnbalanced.data2.extend", "omniglot.OmniglotUnbalanced.targets2.extend", "numpy.unique", "len", "len", "itertools.repeat", "itertools.repeat", "torch.transpose", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "partition", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "data", ".", "shape", ")", "==", "2", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "\n", "", "partition", "=", "OrderedDict", "(", "sorted", "(", "partition", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "new_partition", "=", "defaultdict", "(", "list", ")", "\n", "for", "key", ",", "values", "in", "partition", ".", "items", "(", ")", ":", "\n", "            ", "for", "index", "in", "values", ":", "\n", "                ", "new_partition", "[", "key", "]", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "\n", "", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "for", "key", ",", "values", "in", "new_partition", ".", "items", "(", ")", ":", "\n", "            ", "key", "=", "key", ".", "astype", "(", "np", ".", "int64", ")", "\n", "train_partition", "=", "int", "(", "0.75", "*", "len", "(", "values", ")", ")", "\n", "self", ".", "data", ".", "extend", "(", "values", ")", "\n", "self", ".", "targets", ".", "extend", "(", "repeat", "(", "key", ",", "len", "(", "values", ")", ")", ")", "\n", "if", "train", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", ":", "train_partition", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "train_partition", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", "train_partition", ":", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "(", "len", "(", "values", ")", "-", "train_partition", ")", ")", ")", "\n", "\n", "", "", "if", "all", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.OmniglotUnbalanced.__len__": [[96, 98], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.OmniglotUnbalanced.__getitem__": [[99, 109], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.OmniglotAugmentation.__init__": [[112, 159], ["datasets.augmentation.CustomAugmentation.from_id", "collections.OrderedDict", "collections.defaultdict", "collections.OrderedDict.items", "collections.defaultdict.items", "print", "len", "sorted", "key.astype.astype.astype", "int", "omniglot.OmniglotAugmentation.data.extend", "omniglot.OmniglotAugmentation.targets.extend", "len", "torch.transpose().astype", "collections.OrderedDict.items", "len", "numpy.random.choice", "range", "itertools.repeat", "omniglot.OmniglotAugmentation.data2.extend", "omniglot.OmniglotAugmentation.targets2.extend", "omniglot.OmniglotAugmentation.data2.extend", "omniglot.OmniglotAugmentation.targets2.extend", "numpy.unique", "new_partition[].append", "new_partition[].append", "len", "numpy.random.choice", "new_partition[].append", "len", "len", "itertools.repeat", "itertools.repeat", "torch.transpose", "datasets.augmentation.CustomAugmentation.from_id.", "len"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.from_id"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "partition", ",", "train", "=", "True", ",", "all", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "data", ".", "shape", ")", "==", "2", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "", "augmentation", "=", "CustomAugmentation", ".", "from_id", "(", "0", ")", "\n", "partition", "=", "OrderedDict", "(", "sorted", "(", "partition", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "new_partition", "=", "defaultdict", "(", "list", ")", "\n", "# add augmentation here", "\n", "for", "key", ",", "values", "in", "partition", ".", "items", "(", ")", ":", "\n", "# if cluster > 20 select 20 random sample", "\n", "            ", "if", "len", "(", "values", ")", ">", "20", ":", "\n", "                ", "keep", "=", "np", ".", "random", ".", "choice", "(", "values", ",", "20", ",", "replace", "=", "False", ")", "\n", "for", "index", "in", "keep", ":", "\n", "                    ", "new_partition", "[", "key", "]", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "# otherwise, copy the original elements and add", "\n", "# the augmented version up to 20 samples", "\n", "", "", "else", ":", "\n", "                ", "for", "index", "in", "values", ":", "\n", "                    ", "new_partition", "[", "key", "]", ".", "append", "(", "data", "[", "index", "]", ")", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "values", ")", ",", "20", ",", "1", ")", ":", "\n", "                    ", "keep", "=", "np", ".", "random", ".", "choice", "(", "values", ",", "1", ",", "replace", "=", "False", ")", "\n", "new_partition", "[", "key", "]", ".", "append", "(", "augmentation", "(", "data", "[", "keep", "[", "0", "]", "]", ")", ")", "\n", "\n", "", "", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "data2", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "self", ".", "targets2", "=", "[", "]", "\n", "for", "key", ",", "values", "in", "new_partition", ".", "items", "(", ")", ":", "\n", "            ", "key", "=", "key", ".", "astype", "(", "np", ".", "int64", ")", "\n", "train_partition", "=", "int", "(", "0.75", "*", "len", "(", "values", ")", ")", "\n", "self", ".", "data", ".", "extend", "(", "values", ")", "\n", "self", ".", "targets", ".", "extend", "(", "repeat", "(", "key", ",", "len", "(", "values", ")", ")", ")", "\n", "if", "train", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", ":", "train_partition", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "train_partition", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "data2", ".", "extend", "(", "values", "[", "train_partition", ":", "]", ")", "\n", "self", ".", "targets2", ".", "extend", "(", "repeat", "(", "key", ",", "(", "len", "(", "values", ")", "-", "train_partition", ")", ")", ")", "\n", "\n", "", "", "if", "all", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "self", ".", "targets", "=", "self", ".", "targets2", "\n", "self", ".", "data", "=", "self", ".", "data2", "\n", "\n", "", "print", "(", "\"Total classes = \"", ",", "len", "(", "np", ".", "unique", "(", "self", ".", "targets", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.OmniglotAugmentation.__len__": [[160, 162], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.omniglot.OmniglotAugmentation.__getitem__": [[163, 173], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target character class.\n        \"\"\"", "\n", "image", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "return", "image", ",", "target", "", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.__init__": [[12, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_samples_per_class", ",", "args", ")", ":", "\n", "        ", "self", ".", "num_samples_per_class", "=", "num_samples_per_class", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.make_unsupervised_dataset": [[16, 43], ["enumerate", "numpy.argwhere().flatten", "numpy.delete", "numpy.delete", "numpy.asarray", "numpy.argsort", "numpy.sort", "numpy.asarray", "numpy.asarray", "len", "list", "numpy.asarray.append", "numpy.asarray.append", "partition.values", "len", "sorted", "numpy.argwhere", "random.sample", "list", "partition.keys", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample"], ["", "def", "make_unsupervised_dataset", "(", "self", ",", "data", ",", "partition", ",", "true_labels", ")", ":", "\n", "        ", "\"\"\"\n        Make unsupervised dataset associating the predicted labels to the corresponding images, sampling the fixed\n        number of elements per class and ordering data per labels\n        \"\"\"", "\n", "new_labels", "=", "[", "-", "1", "]", "*", "len", "(", "data", ")", "\n", "for", "idx", ",", "cluster", "in", "enumerate", "(", "list", "(", "partition", ".", "values", "(", ")", ")", ")", ":", "\n", "            ", "if", "len", "(", "cluster", ")", ">", "self", ".", "num_samples_per_class", ":", "\n", "                ", "cluster", "=", "sorted", "(", "random", ".", "sample", "(", "cluster", ",", "self", ".", "num_samples_per_class", ")", ")", "\n", "", "for", "img", "in", "cluster", ":", "\n", "                ", "new_labels", "[", "img", "]", "=", "list", "(", "partition", ".", "keys", "(", ")", ")", "[", "idx", "]", "\n", "\n", "", "", "empty_indices", "=", "np", ".", "argwhere", "(", "np", ".", "asarray", "(", "new_labels", ")", "==", "-", "1", ")", ".", "flatten", "(", ")", "\n", "new_data", "=", "np", ".", "delete", "(", "data", ",", "empty_indices", ",", "axis", "=", "0", ")", "\n", "new_true_labels", "=", "np", ".", "delete", "(", "true_labels", ",", "empty_indices", ",", "axis", "=", "0", ")", "\n", "new_labels", "=", "np", ".", "asarray", "(", "new_labels", ")", "\n", "new_labels", "=", "new_labels", "[", "new_labels", "!=", "-", "1", "]", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "new_labels", ")", "\n", "sorted_labels", "=", "np", ".", "sort", "(", "new_labels", ")", "\n", "sorted_data", "=", "[", "]", "\n", "sorted_true_labels", "=", "[", "]", "\n", "for", "index", "in", "sorted_indices", ":", "\n", "            ", "sorted_data", ".", "append", "(", "new_data", "[", "index", "]", ")", "\n", "sorted_true_labels", ".", "append", "(", "new_true_labels", "[", "index", "]", ")", "\n", "", "sorted_data", "=", "np", ".", "asarray", "(", "sorted_data", ")", "\n", "sorted_true_labels", "=", "np", ".", "asarray", "(", "sorted_true_labels", ")", "\n", "return", "sorted_data", ",", "sorted_labels", ",", "sorted_true_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.get_partitions_kmeans": [[44, 83], ["print", "tqdm.tqdm.tqdm", "task_generator.TaskGenerator.get_partition_from_labels", "tqdm.tqdm.tqdm", "range", "len", "len", "len", "len", "kmeans_list.append", "numpy.random.uniform", "encodings_list.append", "sklearn.cluster.KMeans().fit", "numpy.unique", "numpy.sum", "numpy.multiply", "tqdm.tqdm.tqdm.write", "tqdm.tqdm.tqdm.write", "sklearn.cluster.KMeans"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.get_partition_from_labels"], ["", "def", "get_partitions_kmeans", "(", "self", ",", "encodings", ",", "train", ")", ":", "\n", "        ", "encodings_list", "=", "[", "encodings", "]", "\n", "if", "train", ":", "\n", "            ", "if", "self", ".", "args", ".", "scaled_encodings", ":", "\n", "                ", "n_clusters_list", "=", "[", "self", ".", "args", ".", "num_clusters", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "args", ".", "num_partitions", "-", "1", ")", ":", "\n", "                    ", "weight_vector", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.0", ",", "high", "=", "1.0", ",", "size", "=", "encodings", ".", "shape", "[", "1", "]", ")", "\n", "encodings_list", ".", "append", "(", "np", ".", "multiply", "(", "encodings", ",", "weight_vector", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "n_clusters_list", "=", "[", "self", ".", "args", ".", "num_clusters", "]", "*", "self", ".", "args", ".", "num_partitions", "\n", "", "", "else", ":", "\n", "            ", "n_clusters_list", "=", "[", "self", ".", "args", ".", "num_clusters", "]", "\n", "", "assert", "len", "(", "encodings_list", ")", "*", "len", "(", "n_clusters_list", ")", "==", "self", ".", "args", ".", "num_partitions", "\n", "if", "self", ".", "args", ".", "num_partitions", "!=", "1", ":", "\n", "            ", "n_init", "=", "1", "# so it doesn't take forever", "\n", "", "else", ":", "\n", "            ", "n_init", "=", "10", "\n", "", "init", "=", "'k-means++'", "\n", "\n", "print", "(", "'Number of encodings: {}, number of n_clusters: {}, number of inits: '", ".", "format", "(", "len", "(", "encodings_list", ")", ",", "len", "(", "n_clusters_list", ")", ")", ",", "n_init", ")", "\n", "\n", "kmeans_list", "=", "[", "]", "\n", "for", "n_clusters", "in", "tqdm", "(", "n_clusters_list", ",", "desc", "=", "'get_partitions_kmeans_n_clusters'", ")", ":", "\n", "            ", "for", "encodings", "in", "tqdm", "(", "encodings_list", ",", "desc", "=", "'get_partitions_kmeans_encodings'", ")", ":", "\n", "                ", "while", "True", ":", "\n", "                    ", "kmeans", "=", "KMeans", "(", "n_clusters", "=", "n_clusters", ",", "init", "=", "init", ",", "precompute_distances", "=", "True", ",", "random_state", "=", "128", ",", "n_jobs", "=", "40", ",", "\n", "n_init", "=", "n_init", ",", "max_iter", "=", "3000", ")", ".", "fit", "(", "encodings", ")", "\n", "uniques", ",", "counts", "=", "np", ".", "unique", "(", "kmeans", ".", "labels_", ",", "return_counts", "=", "True", ")", "\n", "num_big_enough_clusters", "=", "np", ".", "sum", "(", "counts", ">", "self", ".", "num_samples_per_class", ")", "\n", "if", "num_big_enough_clusters", ">", "0.30", "*", "n_clusters", ":", "#0.75", "\n", "                        ", "break", "\n", "", "else", ":", "\n", "                        ", "tqdm", ".", "write", "(", "\"Too few classes ({}) with greater than {} examples.\"", ".", "format", "(", "num_big_enough_clusters", ",", "\n", "self", ".", "num_samples_per_class", ")", ")", "\n", "tqdm", ".", "write", "(", "'Frequency: {}'", ".", "format", "(", "counts", ")", ")", "\n", "", "", "kmeans_list", ".", "append", "(", "kmeans", ")", "\n", "\n", "", "", "partition", "=", "self", ".", "get_partition_from_labels", "(", "kmeans_list", "[", "-", "1", "]", ".", "labels_", ")", "\n", "return", "partition", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.get_partition_from_labels": [[84, 96], ["collections.defaultdict", "enumerate", "partition[].append", "task_generator.TaskGenerator.clean_partition"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.clean_partition"], ["", "def", "get_partition_from_labels", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n        Constructs the partition of the set of indices in labels, grouping indices according to their label.\n        :param labels: np.array of labels, whose i-th element is the label for the i-th datapoint\n        :return: a dictionary mapping class label to a list of indices that have that label\n        \"\"\"", "\n", "partition", "=", "defaultdict", "(", "list", ")", "\n", "for", "ind", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "partition", "[", "label", "]", ".", "append", "(", "ind", ")", "\n", "", "if", "not", "self", ".", "args", ".", "aug", ":", "\n", "            ", "self", ".", "clean_partition", "(", "partition", ")", "\n", "", "return", "partition", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_generator.TaskGenerator.clean_partition": [[97, 105], ["list", "partition.keys", "len"], "methods", ["None"], ["", "def", "clean_partition", "(", "self", ",", "partition", ")", ":", "\n", "        ", "\"\"\"\n        Removes subsets that are too small from a partition.\n        \"\"\"", "\n", "for", "cls", "in", "list", "(", "partition", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "len", "(", "partition", "[", "cls", "]", ")", "<", "self", ".", "num_samples_per_class", ":", "\n", "                ", "del", "(", "partition", "[", "cls", "]", ")", "\n", "", "", "return", "partition", "", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.gen_bar_updater": [[9, 19], ["torch.utils.model_zoo.tqdm", "torch.utils.model_zoo.tqdm.update"], "function", ["None"], ["            ", "return", "idx", "\n", "\n", "", "", "", "def", "sample_balanced_data", "(", "cactus_partition", ")", ":", "\n", "    ", "for", "idx", ",", "cluster", "in", "enumerate", "(", "list", "(", "cactus_partition", ".", "values", "(", ")", ")", ")", ":", "\n", "# Sample fixed elements after clustering --> balanced dataset", "\n", "        ", "random_samples_number", "=", "min", "(", "20", ",", "len", "(", "cluster", ")", ")", "\n", "cluster", "=", "sorted", "(", "random", ".", "sample", "(", "cluster", ",", "random_samples_number", ")", ")", "\n", "cactus_partition", "[", "idx", "]", "=", "cluster", "\n", "", "return", "cactus_partition", "\n", "\n", "", "def", "sample_random_data", "(", "cactus_partition", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.check_integrity": [[21, 35], ["hashlib.md5", "hashlib.md5.hexdigest", "os.path.isfile", "os.path.isfile", "open", "iter", "hashlib.md5.update", "f.read"], "function", ["None"], ["# Sample random data from mini-Imagenet after clustering", "\n", "        ", "min_len", "=", "10", "\n", "max_len", "=", "30", "\n", "random_samples_number", "=", "random", ".", "randint", "(", "min_len", ",", "min", "(", "max_len", ",", "len", "(", "cluster", ")", ")", ")", "\n", "cluster", "=", "sorted", "(", "random", ".", "sample", "(", "cluster", ",", "random_samples_number", ")", ")", "\n", "cactus_partition", "[", "idx", "]", "=", "cluster", "\n", "", "return", "cactus_partition", "\n", "\n", "", "def", "sample_unbalanced_data", "(", "cactus_partition", ")", ":", "\n", "    ", "lens", "=", "np", ".", "asarray", "(", "[", "len", "(", "el", ")", "for", "el", "in", "cactus_partition", ".", "values", "(", ")", "]", ")", "\n", "min", ",", "max", "=", "lens", ".", "min", "(", ")", ",", "lens", ".", "max", "(", ")", "\n", "new_min", ",", "new_max", "=", "10", ",", "30", "\n", "new_lens", "=", "[", "]", "\n", "for", "cluster", "in", "cactus_partition", ".", "values", "(", ")", ":", "\n", "        ", "new_cluster_len", "=", "int", "(", "(", "(", "(", "new_max", "-", "new_min", ")", "*", "(", "len", "(", "cluster", ")", "-", "min", ")", ")", "/", "(", "max", "-", "min", ")", ")", "+", "new_min", ")", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.makedir_exist_ok": [[37, 48], ["os.makedirs", "os.makedirs"], "function", ["None"], ["\n", "", "for", "idx", ",", "cluster_len", "in", "enumerate", "(", "new_lens", ")", ":", "\n", "        ", "cactus_partition", "[", "idx", "]", "=", "sorted", "(", "random", ".", "sample", "(", "cactus_partition", "[", "idx", "]", ",", "cluster_len", ")", ")", "\n", "", "return", "cactus_partition", "\n", "\n", "", "def", "sample_reducted_dataset", "(", "data", ",", "labels", ",", "num_classes", ")", ":", "\n", "# Sample fixed random data from mini-Imagenet before clustering", "\n", "    ", "sample_elements", "=", "20", "\n", "data", "=", "np", ".", "array_split", "(", "data", ",", "num_classes", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "np", ".", "asarray", "(", "np", ".", "split", "(", "labels", ",", "num_classes", ")", ")", "[", ":", ",", ":", "sample_elements", "]", ")", "\n", "new_classes", "=", "[", "]", "\n", "for", "i", ",", "cls", "in", "enumerate", "(", "data", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.download_url": [[50, 85], ["os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "utils.makedir_exist_ok", "os.path.basename", "os.path.basename", "os.path.isfile", "os.path.isfile", "utils.check_integrity", "print", "print", "urllib.request.urlretrieve", "utils.gen_bar_updater", "url.replace.replace", "print", "urllib.request.urlretrieve", "utils.gen_bar_updater"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.makedir_exist_ok", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.check_integrity", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.gen_bar_updater", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.gen_bar_updater"], ["new_cls", "=", "[", "]", "\n", "for", "idx", "in", "indices", ":", "\n", "            ", "new_cls", ".", "append", "(", "cls", "[", "idx", "]", ")", "\n", "", "new_classes", ".", "append", "(", "np", ".", "stack", "(", "(", "new_cls", ")", ")", ")", "\n", "", "new_classes", "=", "np", ".", "concatenate", "(", "new_classes", ")", "\n", "return", "new_classes", ",", "labels", "\n", "\n", "", "def", "compute_weigth_vector", "(", "cactus_partition", ")", ":", "\n", "    ", "min_len", "=", "1000", "\n", "max_len", "=", "0", "\n", "for", "el", "in", "cactus_partition", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "el", "[", "1", "]", ")", ">=", "max_len", ":", "\n", "            ", "max_len", "=", "len", "(", "el", "[", "1", "]", ")", "\n", "", "if", "len", "(", "el", "[", "1", "]", ")", "<", "min_len", ":", "\n", "            ", "min_len", "=", "len", "(", "el", "[", "1", "]", ")", "\n", "\n", "", "", "max_key", "=", "max", "(", "cactus_partition", ".", "keys", "(", ")", ")", "\n", "empty", "=", "dict", ".", "fromkeys", "(", "range", "(", "max_key", "+", "1", ")", ",", "[", "]", ")", "\n", "cactus_partition", "=", "{", "**", "empty", ",", "**", "cactus_partition", "}", "\n", "\n", "balance_vector", "=", "[", "]", "\n", "for", "idx", ",", "el", "in", "enumerate", "(", "sorted", "(", "cactus_partition", ".", "items", "(", ")", ")", ")", ":", "\n", "        ", "if", "len", "(", "el", "[", "1", "]", ")", "!=", "min_len", ":", "\n", "            ", "balance_vector", ".", "append", "(", "(", "max_len", "-", "min_len", ")", "/", "(", "len", "(", "el", "[", "1", "]", ")", "-", "min_len", ")", ")", "\n", "", "elif", "len", "(", "el", "[", "1", "]", ")", "==", "0", ":", "\n", "            ", "balance_vector", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "balance_vector", ".", "append", "(", "(", "max_len", "-", "min_len", ")", "/", "(", "(", "len", "(", "el", "[", "1", "]", ")", "+", "1", ")", "-", "min_len", ")", ")", "\n", "\n", "", "", "balance_vector", "=", "np", ".", "asarray", "(", "balance_vector", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "balance_vector", "=", "(", "balance_vector", "-", "balance_vector", ".", "min", "(", ")", ")", "/", "(", "balance_vector", ".", "max", "(", ")", "-", "balance_vector", ".", "min", "(", ")", ")", "\n", "\n", "return", "balance_vector", "\n", "\n", "\n", "", "def", "set_seed", "(", "seed", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.list_dir": [[88, 107], ["os.path.expanduser", "os.path.expanduser", "list", "filter", "os.listdir", "os.listdir", "os.path.join", "os.path.join", "os.path.isdir", "os.path.isdir", "os.path.join", "os.path.join"], "function", ["None"], ["torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "\n", "", "def", "remove_classes", "(", "trainset", ",", "to_keep", ")", ":", "\n", "# trainset.data = trainset.data[order]", "\n", "    ", "trainset", ".", "targets", "=", "np", ".", "array", "(", "trainset", ".", "targets", ")", "\n", "# trainset.targets = trainset.targets[order]", "\n", "\n", "indices", "=", "np", ".", "zeros_like", "(", "trainset", ".", "targets", ")", "\n", "for", "a", "in", "to_keep", ":", "\n", "        ", "indices", "=", "indices", "+", "(", "trainset", ".", "targets", "==", "a", ")", ".", "astype", "(", "int", ")", "\n", "", "indices", "=", "np", ".", "nonzero", "(", "indices", ")", "\n", "trainset", ".", "data", "=", "[", "trainset", ".", "data", "[", "i", "]", "for", "i", "in", "indices", "[", "0", "]", "]", "\n", "# trainset.data = trainset.data[indices]", "\n", "trainset", ".", "targets", "=", "np", ".", "array", "(", "trainset", ".", "targets", ")", "\n", "trainset", ".", "targets", "=", "trainset", ".", "targets", "[", "indices", "]", "\n", "\n", "return", "trainset", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.list_files": [[109, 130], ["os.path.expanduser", "os.path.expanduser", "list", "filter", "os.listdir", "os.listdir", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "p.endswith", "os.path.join", "os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.get_embeddings": [[132, 196], ["print", "numpy.load", "utils.get_embeddings.get_XYZ"], "function", ["None"], []], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.__init__": [[10, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vflip", ":", "bool", ",", "hflip", ":", "bool", ",", "affine", ":", "bool", ",", "\n", "adjust_brightness", ":", "bool", ",", "adjust_contrast", ":", "bool", ",", "\n", "adjust_saturation", ":", "bool", ",", "adjust_hue", ":", "bool", ",", "crop", ":", "bool", ")", ":", "\n", "\n", "        ", "self", ".", "vflip", "=", "vflip", "\n", "self", ".", "hflip", "=", "hflip", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "adjust_brightness", "=", "adjust_brightness", "\n", "self", ".", "adjust_contrast", "=", "adjust_contrast", "\n", "self", ".", "adjust_saturation", "=", "adjust_saturation", "\n", "self", ".", "adjust_hue", "=", "adjust_hue", "\n", "self", ".", "crop", "=", "crop", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.from_id": [[23, 30], ["list", "print", "augmentation.CustomAugmentation", "itertools.product", "range", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "from_id", "(", "id_augm", ")", ":", "\n", "        ", "hyperspace", "=", "[", "[", "True", ",", "False", "]", "for", "_", "in", "range", "(", "8", ")", "]", "\n", "hyperspace", "=", "list", "(", "itertools", ".", "product", "(", "*", "hyperspace", ")", ")", "\n", "print", "(", "\"Total combinations: {}\"", ".", "format", "(", "len", "(", "hyperspace", ")", ")", ")", "\n", "h", "=", "hyperspace", "[", "id_augm", "]", "\n", "return", "CustomAugmentation", "(", "*", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.get_affine_params": [[31, 43], ["random.randint", "random.uniform", "random.uniform", "numpy.round", "numpy.round", "random.uniform", "random.uniform"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_affine_params", "(", "w", ",", "h", ")", ":", "\n", "        ", "affine_angle_rot", "=", "random", ".", "randint", "(", "-", "5", ",", "5", ")", "\n", "max_dx", "=", "0.05", "*", "w", "\n", "max_dy", "=", "0.05", "*", "h", "\n", "affine_translate", "=", "(", "np", ".", "round", "(", "random", ".", "uniform", "(", "-", "max_dx", ",", "max_dx", ")", ")", ",", "\n", "np", ".", "round", "(", "random", ".", "uniform", "(", "-", "max_dy", ",", "max_dy", ")", ")", ")", "\n", "affine_scale", "=", "random", ".", "uniform", "(", "1.0", ",", "1.05", ")", "\n", "affine_shear", "=", "random", ".", "uniform", "(", "-", "1.0", ",", "1.0", ")", "\n", "\n", "return", "affine_angle_rot", ",", "affine_translate", ",", "affine_scale", ",", "affine_shear", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.get_color_jitter_params": [[44, 52], ["random.uniform", "random.uniform", "random.uniform", "random.uniform"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_color_jitter_params", "(", "w", ",", "h", ")", ":", "\n", "        ", "brightness_factor", "=", "random", ".", "uniform", "(", "0.8", ",", "1.2", ")", "\n", "contrast_factor", "=", "random", ".", "uniform", "(", "0.8", ",", "1.2", ")", "\n", "saturation_factor", "=", "random", ".", "uniform", "(", "0.8", ",", "1.2", ")", "\n", "hue_factor", "=", "random", ".", "uniform", "(", "-", "0.02", ",", "0.02", ")", "\n", "return", "brightness_factor", ",", "contrast_factor", ",", "saturation_factor", ",", "hue_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.get_crop_params": [[53, 62], ["random.choice", "random.randint", "random.randint", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_crop_params", "(", "w", ",", "h", ")", ":", "\n", "        ", "crop_size", "=", "random", ".", "choice", "(", "[", "0.75", ",", "0.8", ",", "0.85", ",", "0.9", "]", ")", "\n", "th", ",", "tw", "=", "(", "int", "(", "crop_size", "*", "h", ")", ",", "int", "(", "crop_size", "*", "w", ")", ")", "\n", "if", "w", "==", "tw", "and", "h", "==", "th", ":", "\n", "            ", "return", "0", ",", "0", ",", "h", ",", "w", "\n", "", "i", "=", "random", ".", "randint", "(", "0", ",", "h", "-", "th", ")", "\n", "j", "=", "random", ".", "randint", "(", "0", ",", "w", "-", "tw", ")", "\n", "return", "i", ",", "j", ",", "th", ",", "tw", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.__call__": [[63, 114], ["augmentation.CustomAugmentation.get_affine_params", "augmentation.CustomAugmentation.get_color_jitter_params", "augmentation.CustomAugmentation.get_crop_params", "augmentation.CustomAugmentation.__call__.apply_bool"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.get_affine_params", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.get_color_jitter_params", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.augmentation.CustomAugmentation.get_crop_params"], ["", "def", "__call__", "(", "self", ",", "image", ")", ":", "\n", "\n", "        ", "w", ",", "h", "=", "image", ".", "shape", "[", "1", "]", ",", "image", ".", "shape", "[", "2", "]", "\n", "\n", "affine_angle_rot", ",", "affine_translate", ",", "affine_scale", ",", "affine_shear", "=", "self", ".", "get_affine_params", "(", "w", ",", "h", ")", "\n", "\n", "brightness_factor", ",", "contrast_factor", ",", "saturation_factor", ",", "hue_factor", "=", "self", ".", "get_color_jitter_params", "(", "w", ",", "h", ")", "\n", "\n", "i", ",", "j", ",", "th", ",", "tw", "=", "self", ".", "get_crop_params", "(", "w", ",", "h", ")", "\n", "\n", "def", "apply_bool", "(", "val", ")", ":", "\n", "            ", "return", "val", "and", "random", ".", "choice", "(", "[", "True", ",", "False", "]", ")", "\n", "\n", "", "apply_crop", "=", "apply_bool", "(", "self", ".", "crop", ")", "\n", "apply_vflip", "=", "apply_bool", "(", "self", ".", "vflip", ")", "\n", "apply_hflip", "=", "apply_bool", "(", "self", ".", "hflip", ")", "\n", "apply_adjust_brightness", "=", "apply_bool", "(", "self", ".", "adjust_brightness", ")", "\n", "apply_adjust_contrast", "=", "apply_bool", "(", "self", ".", "adjust_contrast", ")", "\n", "apply_adjust_saturation", "=", "apply_bool", "(", "self", ".", "adjust_saturation", ")", "\n", "apply_adjust_hue", "=", "apply_bool", "(", "self", ".", "adjust_hue", ")", "\n", "apply_affine", "=", "apply_bool", "(", "self", ".", "affine", ")", "\n", "\n", "# image = deepcopy(image_original)", "\n", "image", "=", "F", ".", "to_pil_image", "(", "torch", ".", "from_numpy", "(", "image", ")", ")", "\n", "\n", "\n", "if", "apply_crop", ":", "\n", "            ", "image", "=", "F", ".", "crop", "(", "image", ",", "i", ",", "j", ",", "th", ",", "tw", ")", "\n", "image", "=", "F", ".", "resize", "(", "image", ",", "(", "w", ",", "h", ")", ")", "\n", "", "if", "apply_vflip", ":", "\n", "            ", "image", "=", "F", ".", "vflip", "(", "image", ")", "\n", "", "if", "apply_hflip", ":", "\n", "            ", "image", "=", "F", ".", "hflip", "(", "image", ")", "\n", "", "if", "apply_adjust_brightness", ":", "\n", "            ", "image", "=", "F", ".", "adjust_brightness", "(", "image", ",", "brightness_factor", ")", "\n", "", "if", "apply_adjust_contrast", ":", "\n", "            ", "image", "=", "F", ".", "adjust_contrast", "(", "image", ",", "contrast_factor", ")", "\n", "", "if", "apply_adjust_saturation", ":", "\n", "            ", "image", "=", "F", ".", "adjust_saturation", "(", "image", ",", "saturation_factor", ")", "\n", "", "if", "apply_adjust_hue", ":", "\n", "            ", "image", "=", "F", ".", "adjust_hue", "(", "image", ",", "hue_factor", ")", "\n", "", "if", "apply_affine", ":", "\n", "            ", "image", "=", "F", ".", "affine", "(", "image", ",", "affine_angle_rot", ",", "\n", "affine_translate", ",", "\n", "affine_scale", ",", "affine_shear", ")", "\n", "\n", "", "image", "=", "F", ".", "to_tensor", "(", "image", ")", ".", "numpy", "(", ")", "#.transpose((1, 2, 0))", "\n", "\n", "return", "image", "", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.__init__": [[19, 41], ["torch.nn.Module.__init__", "utils.rehearsal.ReservoirSampler", "model.Learner", "torch.optim.Adam", "torch.from_numpy().cuda", "meta_learner.MetaLearnerClassification.net.parameters", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.__init__", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters"], ["def", "__init__", "(", "self", ",", "args", ",", "config", ",", "balance_vector", ")", ":", "\n", "\n", "        ", "super", "(", "MetaLearnerClassification", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "update_lr", "=", "args", ".", "update_lr", "\n", "self", ".", "meta_lr", "=", "args", ".", "meta_lr", "\n", "self", ".", "dataset", "=", "args", ".", "dataset", "\n", "self", ".", "step_count", "=", "0", "\n", "if", "args", ".", "attention", "or", "args", ".", "mean", ":", "\n", "            ", "self", ".", "aggregation", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "aggregation", "=", "False", "\n", "", "if", "balance_vector", "is", "not", "None", ":", "\n", "            ", "self", ".", "balance_param", "=", "torch", ".", "from_numpy", "(", "balance_vector", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "balance_param", "=", "None", "\n", "", "self", ".", "rehearsal", "=", "args", ".", "rehearsal", "\n", "\n", "self", ".", "res_sampler", "=", "ReservoirSampler", "(", "args", ".", "windows", ",", "args", ".", "buffer_size", ")", "\n", "self", ".", "buffer_size", "=", "args", ".", "buffer_size", "\n", "self", ".", "net", "=", "Learner", ".", "Learner", "(", "config", ",", "args", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "meta_lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.reset_classifer": [[42, 46], ["torch.nn.init.kaiming_normal_", "meta_learner.MetaLearnerClassification.net.parameters", "meta_learner.MetaLearnerClassification.net.parameters", "weight[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters"], ["", "def", "reset_classifer", "(", "self", ",", "class_to_reset", ")", ":", "\n", "        ", "bias", "=", "self", ".", "net", ".", "parameters", "(", ")", "[", "-", "1", "]", "\n", "weight", "=", "self", ".", "net", ".", "parameters", "(", ")", "[", "-", "2", "]", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "weight", "[", "class_to_reset", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.clip_grad_params": [[47, 56], ["params.parameters"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters"], ["", "def", "clip_grad_params", "(", "self", ",", "params", ",", "norm", "=", "500", ")", ":", "\n", "\n", "        ", "for", "p", "in", "params", ".", "parameters", "(", ")", ":", "\n", "            ", "g", "=", "p", ".", "grad", "\n", "# print(g)", "\n", "g", "=", "(", "g", "*", "(", "g", "<", "norm", ")", ".", "float", "(", ")", ")", "+", "(", "(", "g", ">", "norm", ")", ".", "float", "(", ")", ")", "*", "norm", "\n", "g", "=", "(", "g", "*", "(", "g", ">", "-", "norm", ")", ".", "float", "(", ")", ")", "-", "(", "(", "g", "<", "-", "norm", ")", ".", "float", "(", ")", ")", "*", "norm", "\n", "# print(g)", "\n", "p", ".", "grad", "=", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.inner_update": [[57, 83], ["meta_learner.MetaLearnerClassification.net", "torch.autograd.grad", "torch.nn.functional.cross_entropy", "meta_learner.MetaLearnerClassification.net.parameters", "meta_learner.MetaLearnerClassification.net.get_adaptation_parameters", "torch.nn.functional.cross_entropy", "new_weights.append", "new_weights.append"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.get_adaptation_parameters"], ["", "", "def", "inner_update", "(", "self", ",", "x", ",", "fast_weights", ",", "y", ",", "outer_att", ")", ":", "\n", "        ", "adaptation_weight_counter", "=", "0", "\n", "logits", "=", "self", ".", "net", "(", "x", ",", "fast_weights", ",", "outer_att", "=", "outer_att", ")", "\n", "if", "self", ".", "balance_param", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "balance_param", "[", "y", "]", "*", "F", ".", "cross_entropy", "(", "logits", ",", "y", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "y", ")", "\n", "", "if", "fast_weights", "is", "None", ":", "\n", "            ", "fast_weights", "=", "self", ".", "net", ".", "parameters", "(", ")", "\n", "\n", "# Computes and returns the sum of gradients of outputs w.r.t. the inputs", "\n", "", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "net", ".", "get_adaptation_parameters", "(", "fast_weights", ")", ",", "create_graph", "=", "True", ")", "\n", "\n", "new_weights", "=", "[", "]", "\n", "for", "p", "in", "fast_weights", ":", "\n", "            ", "if", "p", ".", "adaptation", ":", "\n", "                ", "g", "=", "grad", "[", "adaptation_weight_counter", "]", "\n", "temp_weight", "=", "p", "-", "self", ".", "update_lr", "*", "g", "\n", "temp_weight", ".", "adaptation", "=", "p", ".", "adaptation", "\n", "temp_weight", ".", "meta", "=", "p", ".", "meta", "\n", "new_weights", ".", "append", "(", "temp_weight", ")", "\n", "adaptation_weight_counter", "+=", "1", "\n", "", "else", ":", "\n", "                ", "new_weights", ".", "append", "(", "p", ")", "\n", "\n", "", "", "return", "new_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.meta_loss": [[84, 89], ["meta_learner.MetaLearnerClassification.net", "torch.nn.functional.cross_entropy"], "methods", ["None"], ["", "def", "meta_loss", "(", "self", ",", "x", ",", "fast_weights", ",", "y", ",", "outer_att", ")", ":", "\n", "\n", "        ", "logits", "=", "self", ".", "net", "(", "x", ",", "fast_weights", ",", "outer_att", "=", "outer_att", ")", "\n", "loss_q", "=", "F", ".", "cross_entropy", "(", "logits", ",", "y", ")", "\n", "return", "loss_q", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.eval_accuracy": [[90, 94], ["torch.nn.functional.softmax().argmax", "torch.eq().sum().item", "torch.nn.functional.softmax", "torch.eq().sum", "torch.eq"], "methods", ["None"], ["", "def", "eval_accuracy", "(", "self", ",", "logits", ",", "y", ")", ":", "\n", "        ", "pred_q", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "correct", "=", "torch", ".", "eq", "(", "pred_q", ",", "y", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "correct", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.forward": [[95, 184], ["meta_learner.MetaLearnerClassification.inner_update", "meta_learner.MetaLearnerClassification.optimizer.zero_grad", "meta_loss.backward", "meta_learner.MetaLearnerClassification.clip_grad_params", "meta_learner.MetaLearnerClassification.optimizer.step", "torch.cat", "torch.cat", "len", "torch.no_grad", "meta_learner.MetaLearnerClassification.meta_loss", "meta_learner.MetaLearnerClassification.eval_accuracy", "meta_learner.MetaLearnerClassification.meta_loss", "meta_learner.MetaLearnerClassification.eval_accuracy", "meta_learner.MetaLearnerClassification.inner_update", "meta_learner.MetaLearnerClassification.meta_loss", "range", "numpy.array", "len", "meta_learner.MetaLearnerClassification.res_sampler.add", "utils.utils.find_index", "meta_learner.MetaLearnerClassification.res_sampler.sample", "torch.cat", "torch.cat", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "range", "range", "meta_learner.MetaLearnerClassification.net.parameters", "torch.cat.squeeze", "meta_learner.MetaLearnerClassification.inner_update", "meta_learner.MetaLearnerClassification.meta_loss", "torch.cat().unsqueeze.squeeze().unsqueeze", "torch.cat().unsqueeze.squeeze().unsqueeze", "range", "len", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.nn.functional.softmax().argmax", "torch.eq().sum().item", "len", "torch.cat", "torch.cat", "torch.cat().unsqueeze.squeeze", "torch.cat().unsqueeze.squeeze", "torch.nn.functional.softmax", "torch.eq().sum", "torch.eq"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.inner_update", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.clip_grad_params", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.meta_loss", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.eval_accuracy", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.meta_loss", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.eval_accuracy", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.inner_update", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.meta_loss", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.add", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.find_index", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.rehearsal.ReservoirSampler.sample", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.inner_update", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.meta_loss"], ["", "def", "forward", "(", "self", ",", "x_traj", ",", "y_traj", ",", "x_rand", ",", "y_rand", ")", ":", "\n", "        ", "\"\"\"\n        :param x_traj:   Input data of sampled trajectory\n        :param y_traj:   Ground truth of the sampled trajectory\n        :param x_rand:   Input data of the random batch of data\n        :param y_rand:   Ground truth of the random 1batch of data\n        :return:\n        \"\"\"", "\n", "\n", "if", "self", ".", "rehearsal", ":", "\n", "            ", "x_traj", "=", "torch", ".", "cat", "(", "(", "x_traj", ",", "x_rand", ".", "squeeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "y_traj", "=", "torch", ".", "cat", "(", "(", "y_traj", ",", "y_rand", ".", "squeeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "\n", "[", "self", ".", "res_sampler", ".", "add", "(", "(", "x_traj", "[", "idx", "]", ",", "y_traj", "[", "idx", "]", ")", ")", "for", "idx", "in", "range", "(", "len", "(", "x_traj", ")", ")", "]", "\n", "if", "self", ".", "rehearsal", "and", "len", "(", "self", ".", "res_sampler", ".", "buffer", ")", ">=", "30", ":", "\n", "                ", "index", "=", "find_index", "(", "y_traj", ",", "y_rand", ")", "\n", "x_rand", "=", "x_rand", "[", ":", ",", "index", ":", "]", "\n", "y_rand", "=", "y_rand", "[", ":", ",", "index", ":", "]", "\n", "coreset", "=", "self", ".", "res_sampler", ".", "sample", "(", "10", ")", "\n", "x_coreset", ",", "y_coreset", "=", "[", "]", ",", "[", "]", "\n", "for", "example", "in", "coreset", ":", "\n", "                    ", "x_coreset", ".", "append", "(", "example", "[", "0", "]", ")", "\n", "y_coreset", ".", "append", "(", "example", "[", "1", "]", ")", "\n", "", "x_coreset", "=", "torch", ".", "cat", "(", "x_coreset", ")", "\n", "y_coreset", "=", "torch", ".", "cat", "(", "y_coreset", ")", "\n", "x_rand", "=", "torch", ".", "cat", "(", "(", "x_coreset", ",", "x_rand", "[", "0", "]", ")", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "y_rand", "=", "torch", ".", "cat", "(", "(", "y_coreset", ",", "y_rand", "[", "0", "]", ")", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "", "if", "self", ".", "aggregation", ":", "\n", "            ", "self", ".", "update_step", "=", "1", "\n", "dim", "=", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "update_step", "=", "len", "(", "x_traj", ")", "\n", "dim", "=", "1", "\n", "\n", "", "meta_losses", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "update_step", "+", "dim", ")", "]", "# losses_q[i] is the loss on step i", "\n", "accuracy_meta_set", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "update_step", "+", "dim", ")", "]", "\n", "\n", "# Doing a single inner update to get updated weights", "\n", "fast_weights", "=", "self", ".", "inner_update", "(", "x_traj", "[", "0", "]", ",", "None", ",", "y_traj", "[", "0", "]", ",", "False", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Meta loss before any inner updates", "\n", "            ", "meta_loss", ",", "last_layer_logits", "=", "self", ".", "meta_loss", "(", "x_rand", "[", "0", "]", ",", "self", ".", "net", ".", "parameters", "(", ")", ",", "y_rand", "[", "0", "]", ",", "self", ".", "aggregation", ")", "\n", "meta_losses", "[", "0", "]", "+=", "meta_loss", "\n", "\n", "classification_accuracy", "=", "self", ".", "eval_accuracy", "(", "last_layer_logits", ",", "y_rand", "[", "0", "]", ")", "\n", "accuracy_meta_set", "[", "0", "]", "=", "accuracy_meta_set", "[", "0", "]", "+", "classification_accuracy", "\n", "\n", "# Meta loss after a single inner update", "\n", "meta_loss", ",", "last_layer_logits", "=", "self", ".", "meta_loss", "(", "x_rand", "[", "0", "]", ",", "fast_weights", ",", "y_rand", "[", "0", "]", ",", "self", ".", "aggregation", ")", "\n", "meta_losses", "[", "1", "]", "+=", "meta_loss", "\n", "\n", "classification_accuracy", "=", "self", ".", "eval_accuracy", "(", "last_layer_logits", ",", "y_rand", "[", "0", "]", ")", "\n", "accuracy_meta_set", "[", "1", "]", "=", "accuracy_meta_set", "[", "1", "]", "+", "classification_accuracy", "\n", "\n", "", "if", "self", ".", "aggregation", ":", "\n", "            ", "fast_weights", "=", "self", ".", "inner_update", "(", "x_traj", ".", "squeeze", "(", "1", ")", ",", "fast_weights", ",", "y_traj", "[", "0", "]", ",", "False", ")", "\n", "\n", "# Computing meta-loss with respect to latest weights", "\n", "meta_loss", ",", "logits", "=", "self", ".", "meta_loss", "(", "x_rand", "[", "0", "]", ",", "fast_weights", ",", "y_rand", "[", "0", "]", ",", "self", ".", "aggregation", ")", "\n", "meta_losses", "[", "-", "1", "]", "+=", "meta_loss", "\n", "", "else", ":", "\n", "            ", "for", "k", "in", "range", "(", "1", ",", "self", ".", "update_step", ")", ":", "\n", "# Doing inner updates using fast weights", "\n", "                ", "fast_weights", "=", "self", ".", "inner_update", "(", "x_traj", "[", "k", "]", ",", "fast_weights", ",", "y_traj", "[", "k", "]", ",", "False", ")", "\n", "\n", "# Computing meta-loss with respect to latest weights", "\n", "meta_loss", ",", "logits", "=", "self", ".", "meta_loss", "(", "x_rand", "[", "0", "]", ",", "fast_weights", ",", "y_rand", "[", "0", "]", ",", "self", ".", "aggregation", ")", "\n", "meta_losses", "[", "k", "+", "1", "]", "+=", "meta_loss", "\n", "\n", "# Computing accuracy on the meta and traj set for understanding the learning", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "pred_q", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "classification_accuracy", "=", "torch", ".", "eq", "(", "pred_q", ",", "y_rand", "[", "0", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "# convert to numpy", "\n", "accuracy_meta_set", "[", "k", "+", "1", "]", "=", "accuracy_meta_set", "[", "k", "+", "1", "]", "+", "classification_accuracy", "\n", "\n", "# Taking the meta gradient step", "\n", "", "", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "meta_loss", "=", "meta_losses", "[", "-", "1", "]", "\n", "\n", "meta_loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "clip_grad_params", "(", "self", ".", "net", ",", "norm", "=", "5", ")", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "accuracies", "=", "np", ".", "array", "(", "accuracy_meta_set", ")", "/", "len", "(", "x_rand", "[", "0", "]", ")", "\n", "return", "accuracies", ",", "meta_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.sample_training_data": [[185, 232], ["torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat.append", "torch.cat.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "data[].item", "torch.cat", "torch.cat", "meta_learner.MetaLearnerClassification.reset_classifer", "int", "x_traj.append", "y_traj.append", "torch.cat().unsqueeze.append", "torch.cat().unsqueeze.append", "len"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.meta_learner.MetaLearnerClassification.reset_classifer"], ["", "def", "sample_training_data", "(", "self", ",", "traj_iterators", ",", "rand_iterator", ",", "reset", "=", "True", ",", "rehearsal", "=", "False", ")", ":", "\n", "# Sample data for inner and meta updates", "\n", "        ", "x_traj", ",", "y_traj", ",", "x_rand", ",", "y_rand", ",", "x_rand_temp", ",", "y_rand_temp", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "counter", "=", "0", "\n", "x_rand_temp", "=", "[", "]", "\n", "y_rand_temp", "=", "[", "]", "\n", "\n", "for", "it1", "in", "traj_iterators", ":", "\n", "            ", "for", "img", ",", "data", "in", "it1", ":", "\n", "                ", "class_to_reset", "=", "data", "[", "0", "]", ".", "item", "(", ")", "\n", "if", "reset", ":", "\n", "# Resetting weights corresponding to classes in the inner updates; this prevents", "\n", "# the learner from memorizing the data (which would kill the gradients due to inner updates)", "\n", "                    ", "self", ".", "reset_classifer", "(", "class_to_reset", ")", "\n", "\n", "", "counter", "+=", "1", "\n", "\n", "if", "counter", "<=", "int", "(", "len", "(", "it1", ")", "*", "2", "/", "3", ")", ":", "\n", "                    ", "x_traj", ".", "append", "(", "img", ")", "\n", "y_traj", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "                    ", "x_rand_temp", ".", "append", "(", "img", ")", "\n", "y_rand_temp", ".", "append", "(", "data", ")", "\n", "\n", "# Sampling the random batch of data", "\n", "", "", "", "counter", "=", "0", "\n", "for", "img", ",", "data", "in", "rand_iterator", ":", "\n", "            ", "if", "counter", "==", "1", ":", "\n", "                ", "break", "\n", "", "x_rand", ".", "append", "(", "img", ")", "\n", "y_rand", ".", "append", "(", "data", ")", "\n", "counter", "+=", "1", "\n", "\n", "", "y_rand_temp", "=", "torch", ".", "cat", "(", "y_rand_temp", ")", ".", "unsqueeze", "(", "0", ")", "\n", "x_rand_temp", "=", "torch", ".", "cat", "(", "x_rand_temp", ")", ".", "unsqueeze", "(", "0", ")", "\n", "x_traj", ",", "y_traj", ",", "x_rand", ",", "y_rand", "=", "torch", ".", "stack", "(", "x_traj", ")", ",", "torch", ".", "stack", "(", "y_traj", ")", ",", "torch", ".", "stack", "(", "x_rand", ")", ",", "torch", ".", "stack", "(", "\n", "y_rand", ")", "\n", "\n", "if", "not", "rehearsal", ":", "\n", "            ", "x_rand", "=", "torch", ".", "cat", "(", "[", "x_rand", ",", "x_rand_temp", "]", ",", "1", ")", "\n", "y_rand", "=", "torch", ".", "cat", "(", "[", "y_rand", ",", "y_rand_temp", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_rand", "=", "x_rand_temp", "\n", "y_rand", "=", "y_rand_temp", "\n", "\n", "", "return", "x_traj", ",", "y_traj", ",", "x_rand", ",", "y_rand", "", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.modelfactory.get_model": [[2, 66], ["config_net.insert", "config_net.insert", "config_net.insert", "config_net.insert", "config_net.insert", "print", "config_net.insert"], "function", ["None"], ["def", "get_model", "(", "args", ",", "classes", ")", ":", "\n", "    ", "channels", "=", "256", "\n", "if", "args", ".", "dataset", "==", "\"omniglot\"", ":", "\n", "        ", "in_ch", "=", "1", "\n", "last_conv_layer_kernel", "=", "1", "\n", "n", "=", "1", "\n", "", "elif", "args", ".", "dataset", "==", "\"imagenet\"", "or", "args", ".", "dataset", "==", "\"cub\"", "or", "args", ".", "dataset", "==", "\"cifar\"", ":", "\n", "        ", "in_ch", "=", "3", "\n", "last_conv_layer_kernel", "=", "3", "\n", "n", "=", "9", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Unsupported model; either implement the model in model/ModelFactory or choose a different model\"", ")", "\n", "assert", "(", "False", ")", "\n", "\n", "", "config_net", "=", "[", "\n", "{", "\"name\"", ":", "'conv2d'", ",", "\"adaptation\"", ":", "False", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "channels", ",", "\"in-channels\"", ":", "in_ch", ",", "\"kernal\"", ":", "3", ",", "\"stride\"", ":", "2", ",", "\"padding\"", ":", "0", "}", "}", ",", "\n", "{", "\"name\"", ":", "'relu'", "}", ",", "\n", "\n", "{", "\"name\"", ":", "'conv2d'", ",", "\"adaptation\"", ":", "False", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "channels", ",", "\"in-channels\"", ":", "channels", ",", "\"kernal\"", ":", "3", ",", "\"stride\"", ":", "1", ",", "\n", "\"padding\"", ":", "0", "}", "}", ",", "\n", "{", "\"name\"", ":", "'relu'", "}", ",", "\n", "\n", "{", "\"name\"", ":", "'conv2d'", ",", "\"adaptation\"", ":", "False", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "channels", ",", "\"in-channels\"", ":", "channels", ",", "\"kernal\"", ":", "3", ",", "\"stride\"", ":", "2", ",", "\n", "\"padding\"", ":", "0", "}", "}", ",", "\n", "{", "\"name\"", ":", "'relu'", "}", ",", "\n", "#", "\n", "{", "\"name\"", ":", "'conv2d'", ",", "\"adaptation\"", ":", "False", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "channels", ",", "\"in-channels\"", ":", "channels", ",", "\"kernal\"", ":", "3", ",", "\"stride\"", ":", "1", ",", "\n", "\"padding\"", ":", "0", "}", "}", ",", "\n", "{", "\"name\"", ":", "'relu'", "}", ",", "\n", "\n", "{", "\"name\"", ":", "'conv2d'", ",", "\"adaptation\"", ":", "False", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "channels", ",", "\"in-channels\"", ":", "channels", ",", "\"kernal\"", ":", "3", ",", "\"stride\"", ":", "2", ",", "\n", "\"padding\"", ":", "0", "}", "}", ",", "\n", "{", "\"name\"", ":", "'relu'", "}", ",", "\n", "\n", "{", "\"name\"", ":", "'conv2d'", ",", "\"adaptation\"", ":", "False", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "channels", ",", "\"in-channels\"", ":", "channels", ",", "\"kernal\"", ":", "last_conv_layer_kernel", ",", "\"stride\"", ":", "2", ",", "\n", "\"padding\"", ":", "0", "}", "}", ",", "\n", "{", "\"name\"", ":", "'relu'", "}", ",", "\n", "\n", "{", "\"name\"", ":", "'flatten'", "}", ",", "\n", "\n", "{", "\"name\"", ":", "'linear'", ",", "\"adaptation\"", ":", "True", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "1024", ",", "\"in-channels\"", ":", "n", "*", "channels", "}", "}", ",", "\n", "{", "\"name\"", ":", "'linear'", ",", "\"adaptation\"", ":", "True", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "classes", ",", "\"in-channels\"", ":", "1024", "}", "}", "\n", "]", "\n", "\n", "if", "args", ".", "attention", ":", "\n", "        ", "config_net", ".", "insert", "(", "13", ",", "{", "\"name\"", ":", "'linear'", ",", "\"adaptation\"", ":", "True", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "n", "*", "channels", ",", "\"in-channels\"", ":", "n", "*", "channels", "}", "}", ")", "\n", "config_net", ".", "insert", "(", "14", ",", "{", "\"name\"", ":", "'tanh'", "}", ",", ")", "\n", "config_net", ".", "insert", "(", "15", ",", "{", "\"name\"", ":", "'linear'", ",", "\"adaptation\"", ":", "True", ",", "\"meta\"", ":", "True", ",", "\n", "\"config\"", ":", "{", "\"out-channels\"", ":", "1", ",", "\"in-channels\"", ":", "n", "*", "channels", "}", "}", ")", "\n", "config_net", ".", "insert", "(", "16", ",", "{", "\"name\"", ":", "'softmax'", "}", ")", "\n", "config_net", ".", "insert", "(", "17", ",", "{", "\"name\"", ":", "'sum'", "}", ")", "\n", "", "elif", "args", ".", "mean", ":", "\n", "        ", "config_net", ".", "insert", "(", "13", ",", "{", "\"name\"", ":", "'mean'", "}", ")", "\n", "\n", "", "return", "config_net", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.conv2d": [[5, 12], ["torch.nn.Parameter", "torch.nn.init.kaiming_normal_", "torch.nn.Parameter", "torch.ones", "torch.zeros"], "function", ["None"], ["def", "conv2d", "(", "param", ",", "adaptation", ",", "meta", ")", ":", "\n", "    ", "w", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "param", "[", "'out-channels'", "]", ",", "param", "[", "'in-channels'", "]", ",", "param", "[", "'kernal'", "]", ",", "param", "[", "'kernal'", "]", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "w", ")", "\n", "b", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "param", "[", "'out-channels'", "]", ")", ")", "\n", "w", ".", "meta", ",", "b", ".", "meta", "=", "meta", ",", "meta", "\n", "w", ".", "adaptation", ",", "b", ".", "adaptation", "=", "adaptation", ",", "adaptation", "\n", "return", "w", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.linear": [[14, 21], ["torch.nn.Parameter", "torch.nn.init.kaiming_normal_", "torch.nn.Parameter", "torch.ones", "torch.zeros"], "function", ["None"], ["", "def", "linear", "(", "out_dim", ",", "in_dim", ",", "adaptation", ",", "meta", ")", ":", "\n", "    ", "w", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "out_dim", ",", "in_dim", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "w", ")", "\n", "b", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "out_dim", ")", ")", "\n", "w", ".", "meta", ",", "b", ".", "meta", "=", "meta", ",", "meta", "\n", "w", ".", "adaptation", ",", "b", ".", "adaptation", "=", "adaptation", ",", "adaptation", "\n", "return", "w", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.batch_norm": [[23, 29], ["torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.zeros", "torch.ones"], "function", ["None"], ["", "def", "batch_norm", "(", "param", ")", ":", "\n", "    ", "w", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "param", "[", "'in-channels'", "]", ")", ")", "\n", "# must set requires_grad=False", "\n", "running_mean", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "param", "[", "'in-channels'", "]", ")", ",", "requires_grad", "=", "False", ")", "\n", "running_var", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "param", "[", "'in-channels'", "]", ")", ",", "requires_grad", "=", "False", ")", "\n", "return", "w", ",", "running_mean", ",", "running_var", "\n", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.__init__": [[12, 20], ["torch.nn.Module.__init__", "learner.Learner.parse_config", "torch.nn.ParameterList", "torch.nn.ParameterList"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.__init__", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parse_config"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "args", ")", ":", "\n", "        ", "super", "(", "Learner", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "attention", "=", "args", ".", "attention", "\n", "# this dict contains all tensors needed to be optimized", "\n", "self", ".", "vars", ",", "self", ".", "vars_bn", "=", "self", ".", "parse_config", "(", "self", ".", "config", ",", "nn", ".", "ParameterList", "(", ")", ",", "nn", ".", "ParameterList", "(", ")", ")", "\n", "self", ".", "attention_coeff", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.reset_vars": [[21, 35], ["len", "enumerate", "len", "logger.info", "torch.nn.init.kaiming_normal_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "reset_vars", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all adaptation parameters to random values. Bias terms are set to zero and other terms to default values of kaiming_normal_\n        :return:\n        \"\"\"", "\n", "num_vars", "=", "len", "(", "self", ".", "vars", ")", "\n", "last_w", ",", "last_b", "=", "num_vars", "-", "2", ",", "num_vars", "-", "1", "\n", "for", "idx", ",", "var", "in", "enumerate", "(", "self", ".", "vars", ")", ":", "\n", "            ", "if", "idx", "==", "last_w", "or", "idx", "==", "last_b", ":", "\n", "                ", "if", "len", "(", "var", ".", "shape", ")", ">", "1", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Resetting weight\"", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "var", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parse_config": [[36, 66], ["enumerate", "model.layers.conv2d", "vars_list.append", "vars_list.append", "model.layers.linear", "vars_list.append", "vars_list.append", "model.layers.batch_norm", "vars_list.append", "var_bn_list.append", "var_bn_list.append", "print"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.conv2d", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.linear", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.batch_norm"], ["", "", "", "", "def", "parse_config", "(", "self", ",", "config", ",", "vars_list", ",", "var_bn_list", ")", ":", "\n", "\n", "        ", "for", "i", ",", "info_dict", "in", "enumerate", "(", "config", ")", ":", "\n", "\n", "            ", "if", "info_dict", "[", "\"name\"", "]", "==", "'conv2d'", ":", "\n", "                ", "w", ",", "b", "=", "layers", ".", "conv2d", "(", "info_dict", "[", "\"config\"", "]", ",", "info_dict", "[", "\"adaptation\"", "]", ",", "info_dict", "[", "\"meta\"", "]", ")", "\n", "vars_list", ".", "append", "(", "w", ")", "\n", "vars_list", ".", "append", "(", "b", ")", "\n", "\n", "", "elif", "info_dict", "[", "\"name\"", "]", "==", "'linear'", ":", "\n", "                ", "param_config", "=", "info_dict", "[", "\"config\"", "]", "\n", "w", ",", "b", "=", "layers", ".", "linear", "(", "param_config", "[", "\"out-channels\"", "]", ",", "param_config", "[", "\"in-channels\"", "]", ",", "info_dict", "[", "\"adaptation\"", "]", ",", "\n", "info_dict", "[", "\"meta\"", "]", ")", "\n", "vars_list", ".", "append", "(", "w", ")", "\n", "vars_list", ".", "append", "(", "b", ")", "\n", "\n", "", "elif", "info_dict", "[", "'name'", "]", "==", "'bn'", ":", "\n", "                ", "param_config", "=", "info_dict", "[", "\"config\"", "]", "\n", "w", ",", "running_mean", ",", "running_var", "=", "layers", ".", "batch_norm", "(", "param_config", "[", "\"in-channels\"", "]", ")", "\n", "vars_list", ".", "append", "(", "w", ")", "\n", "var_bn_list", ".", "append", "(", "running_mean", ")", "\n", "var_bn_list", ".", "append", "(", "running_var", ")", "\n", "\n", "", "elif", "info_dict", "[", "\"name\"", "]", "in", "[", "'tanh'", ",", "'relu'", ",", "'upsample'", ",", "'avg_pool2d'", ",", "'max_pool2d'", ",", "\n", "'flatten'", ",", "'leakyrelu'", ",", "'sigmoid'", ",", "'sum'", ",", "'softmax'", ",", "'mean'", "]", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "print", "(", "info_dict", "[", "\"name\"", "]", ")", "\n", "raise", "NotImplementedError", "\n", "", "", "return", "vars_list", ",", "var_bn_list", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.forward": [[67, 136], ["enumerate", "len", "torch.nn.functional.conv2d", "torch.nn.functional.linear", "torch.nn.functional.batch_norm.view", "torch.nn.functional.batch_norm.size", "torch.nn.functional.relu", "torch.nn.functional.tanh", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "features_vector.unsqueeze.unsqueeze.view", "torch.nn.functional.batch_norm.unsqueeze", "torch.nn.functional.batch_norm.size", "features_vector.unsqueeze.unsqueeze.unsqueeze", "torch.sum", "torch.sum", "len", "torch.nn.functional.batch_norm.unsqueeze", "torch.mean", "len", "torch.nn.functional.batch_norm.unsqueeze", "torch.nn.functional.batch_norm"], "methods", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.conv2d", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.linear", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.layers.batch_norm"], ["", "def", "forward", "(", "self", ",", "x", ",", "vars", "=", "None", ",", "config", "=", "None", ",", "outer_att", "=", "False", ")", ":", "\n", "        ", "if", "vars", "is", "None", ":", "\n", "            ", "vars", "=", "self", ".", "vars", "\n", "\n", "", "if", "config", "is", "None", ":", "\n", "            ", "config", "=", "self", ".", "config", "\n", "\n", "", "idx", "=", "0", "\n", "bn_idx", "=", "0", "\n", "features_vector", "=", "None", "\n", "for", "layer_counter", ",", "info_dict", "in", "enumerate", "(", "config", ")", ":", "\n", "            ", "name", "=", "info_dict", "[", "\"name\"", "]", "\n", "\n", "if", "name", "==", "'conv2d'", ":", "\n", "                ", "w", ",", "b", "=", "vars", "[", "idx", "]", ",", "vars", "[", "idx", "+", "1", "]", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "w", ",", "b", ",", "stride", "=", "info_dict", "[", "'config'", "]", "[", "'stride'", "]", ",", "padding", "=", "info_dict", "[", "'config'", "]", "[", "'padding'", "]", ")", "\n", "\n", "if", "self", ".", "attention", "and", "idx", "==", "10", ":", "\n", "                    ", "features_vector", "=", "x", "\n", "\n", "", "idx", "+=", "2", "\n", "\n", "", "elif", "name", "==", "'linear'", ":", "\n", "                ", "w", ",", "b", "=", "vars", "[", "idx", "]", ",", "vars", "[", "idx", "+", "1", "]", "\n", "x", "=", "F", ".", "linear", "(", "x", ",", "w", ",", "b", ")", "\n", "idx", "+=", "2", "\n", "\n", "", "elif", "name", "==", "'flatten'", ":", "\n", "                ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "", "elif", "name", "==", "'relu'", ":", "\n", "                ", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "\n", "", "elif", "name", "==", "'tanh'", ":", "\n", "                ", "x", "=", "F", ".", "tanh", "(", "x", ")", "\n", "\n", "", "elif", "name", "==", "'softmax'", ":", "\n", "                ", "if", "outer_att", ":", "\n", "                    ", "x", "=", "F", ".", "softmax", "(", "x", ".", "unsqueeze", "(", "1", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "x", "=", "F", ".", "softmax", "(", "x", ",", "dim", "=", "0", ")", "\n", "", "self", ".", "attention_coeff", "=", "x", "\n", "\n", "", "elif", "name", "==", "'sum'", ":", "\n", "                ", "features_vector", "=", "features_vector", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "if", "outer_att", ":", "\n", "                    ", "features_vector", "=", "features_vector", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "torch", ".", "sum", "(", "features_vector", "*", "x", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "x", "=", "torch", ".", "sum", "(", "features_vector", "*", "x", ",", "dim", "=", "0", ")", "\n", "", "if", "len", "(", "x", ".", "shape", ")", "==", "1", ":", "\n", "                    ", "x", "=", "x", ".", "unsqueeze", "(", "0", ")", "\n", "", "", "elif", "name", "==", "'mean'", ":", "\n", "                ", "if", "not", "outer_att", ":", "\n", "                    ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ")", "\n", "", "if", "len", "(", "x", ".", "shape", ")", "==", "1", ":", "\n", "                    ", "x", "=", "x", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "", "elif", "name", "==", "'bn'", ":", "\n", "                ", "w", ",", "b", "=", "vars", "[", "idx", "]", ",", "vars", "[", "idx", "+", "1", "]", "\n", "running_mean", ",", "running_var", "=", "self", ".", "vars_bn", "[", "bn_idx", "]", ",", "self", ".", "vars_bn", "[", "bn_idx", "+", "1", "]", "\n", "x", "=", "F", ".", "batch_norm", "(", "x", ",", "running_mean", ",", "running_var", ",", "weight", "=", "w", ",", "bias", "=", "b", ",", "training", "=", "True", ")", "\n", "idx", "+=", "2", "\n", "bn_idx", "+=", "2", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "assert", "idx", "==", "len", "(", "vars", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.get_adaptation_parameters": [[137, 144], ["list", "filter", "list"], "methods", ["None"], ["", "def", "get_adaptation_parameters", "(", "self", ",", "vars", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :return: adaptation parameters i.e. parameters changed in the inner loop\n        \"\"\"", "\n", "if", "vars", "is", "None", ":", "\n", "            ", "vars", "=", "self", ".", "vars", "\n", "", "return", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "adaptation", ",", "list", "(", "vars", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.get_forward_meta_parameters": [[145, 150], ["list", "filter", "list"], "methods", ["None"], ["", "def", "get_forward_meta_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: adaptation parameters i.e. parameters changed in the inner loop\n        \"\"\"", "\n", "return", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "meta", ",", "list", "(", "self", ".", "vars", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters": [[151, 157], ["None"], "methods", ["None"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        override this function since initial parameters will return with a generator.\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "vars", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.fusion.dataset_handler": [[21, 55], ["datasets.utils.get_embeddings", "datasets.datasetfactory.cactus_unbalanced", "datasets.datasetfactory.get_dataset_unbalanced", "datasets.datasetfactory.get_dataset_unbalanced", "numpy.unique", "int", "numpy.split", "list", "numpy.stack", "datasets.SamplerFactory.get_sampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "utils.sample_random_data", "utils.compute_weigth_vector", "numpy.argwhere().flatten", "utils.sample_unbalanced_data", "utils.sample_balanced_data", "numpy.argwhere"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.get_embeddings", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.cactus_unbalanced", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset_unbalanced", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset_unbalanced", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SamplerFactory.get_sampler", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_random_data", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.compute_weigth_vector", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_unbalanced_data", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_balanced_data"], ["def", "dataset_handler", "(", "args", ")", ":", "\n", "    ", "X_train", ",", "Y_train", ",", "Z_train", ",", "X_val", ",", "Y_val", ",", "Z_val", "=", "get_embeddings", "(", "args", ".", "dataset", ",", "args", ".", "num_encoding_dims", ",", "args", ".", "test_set", ",", "args", ".", "encoder", ")", "\n", "\n", "cactus_partition", "=", "cactus_unbalanced", "(", "args", ",", "Z_train", ",", "train", "=", "True", ")", "\n", "\n", "if", "(", "args", ".", "dataset", "==", "\"imagenet\"", "or", "args", ".", "dataset", "==", "\"cub\"", ")", "and", "args", ".", "sampling", "==", "\"random\"", ":", "\n", "        ", "cactus_partition", "=", "utils", ".", "sample_random_data", "(", "cactus_partition", ")", "\n", "", "elif", "(", "args", ".", "dataset", "==", "\"imagenet\"", "or", "args", ".", "dataset", "==", "\"cub\"", ")", "and", "args", ".", "sampling", "==", "\"proportional\"", ":", "\n", "        ", "cactus_partition", "=", "utils", ".", "sample_unbalanced_data", "(", "cactus_partition", ")", "\n", "", "elif", "(", "args", ".", "dataset", "==", "\"imagenet\"", "or", "args", ".", "dataset", "==", "\"cub\"", ")", "and", "args", ".", "sampling", "==", "\"balanced\"", ":", "\n", "        ", "cactus_partition", "=", "utils", ".", "sample_balanced_data", "(", "cactus_partition", ")", "\n", "\n", "# Computing balancing vector", "\n", "", "if", "args", ".", "balancing", ":", "\n", "        ", "balance_vector", "=", "utils", ".", "compute_weigth_vector", "(", "cactus_partition", ")", "\n", "", "else", ":", "\n", "        ", "balance_vector", "=", "None", "\n", "\n", "", "dataset", "=", "get_dataset_unbalanced", "(", "args", ",", "X_train", ",", "cactus_partition", ",", "train", "=", "True", ")", "\n", "dataset_test", "=", "get_dataset_unbalanced", "(", "args", ",", "X_train", ",", "cactus_partition", ",", "train", "=", "False", ")", "\n", "\n", "classes", "=", "np", ".", "unique", "(", "dataset", ".", "targets", ")", "\n", "total_classes_num", "=", "int", "(", "classes", ".", "shape", "[", "0", "]", "/", "2", ")", "\n", "_", ",", "traj_classes", "=", "np", ".", "split", "(", "classes", ",", "np", ".", "argwhere", "(", "classes", "==", "classes", "[", "total_classes_num", "]", ")", ".", "flatten", "(", ")", ")", "\n", "classes", "=", "list", "(", "classes", ")", "\n", "traj_classes", "=", "np", ".", "stack", "(", "classes", ")", "\n", "\n", "sampler", "=", "ts", ".", "SamplerFactory", ".", "get_sampler", "(", "args", ".", "dataset", ",", "classes", ",", "dataset", ",", "dataset_test", ")", "\n", "# Iterators used for evaluation", "\n", "iterator_train", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "5", ",", "shuffle", "=", "args", ".", "iid", ",", "num_workers", "=", "0", ")", "\n", "iterator_test", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_test", ",", "batch_size", "=", "5", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ")", "\n", "\n", "return", "traj_classes", ",", "sampler", ",", "iterator_train", ",", "iterator_test", ",", "balance_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.fusion.main": [[57, 113], ["utils.set_seed", "utils.experiment.experiment", "tensorboardX.SummaryWriter", "logging.getLogger", "torch.cuda.is_available", "model.modelfactory.get_model", "fusion.dataset_handler", "torch.optim.Adam", "range", "tensorboardX.SummaryWriter.close", "torch.device", "torch.device", "torch.load().to", "Learner().to.parameters", "model.meta_learner.MetaLearnerClassification().to", "model.learner.Learner().to", "meta.meta_train.train_iid", "meta.meta_train.train", "torch.save", "torch.save", "torch.save", "meta.meta_train.test", "tensorboardX.SummaryWriter.add_scalar", "logging.getLogger.info", "meta.meta_train.test", "tensorboardX.SummaryWriter.add_scalar", "logging.getLogger.info", "logging.getLogger.info", "torch.load", "str", "str", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "str", "model.meta_learner.MetaLearnerClassification", "model.learner.Learner", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.set_seed", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.modelfactory.get_model", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.oml.dataset_handler", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_train.train_iid", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "utils", ".", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "my_experiment", "=", "experiment", "(", "args", ".", "name", ",", "args", ",", "LOG_DIR", ",", "commit_changes", "=", "args", ".", "commit", ")", "\n", "writer", "=", "SummaryWriter", "(", "my_experiment", ".", "path", "+", "\"tensorboard\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'experiment'", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "config", "=", "get_model", "(", "args", ",", "args", ".", "num_clusters", ")", "\n", "\n", "traj_classes", ",", "sampler", ",", "iterator_train", ",", "iterator_test", ",", "balance_vector", "=", "dataset_handler", "(", "args", ")", "\n", "\n", "if", "not", "args", ".", "reload", ":", "\n", "        ", "if", "not", "args", ".", "iid", ":", "\n", "            ", "maml", "=", "MetaLearnerClassification", "(", "args", ",", "config", ",", "balance_vector", "=", "balance_vector", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "maml", "=", "Learner", "(", "config", ",", "args", ")", ".", "to", "(", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "maml", "=", "torch", ".", "load", "(", "args", ".", "ckpt_path", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "opt", "=", "torch", ".", "optim", ".", "Adam", "(", "maml", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "update_lr", ")", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "steps", ")", ":", "\n", "        ", "if", "args", ".", "iid", ":", "\n", "            ", "maml", ",", "accs", ",", "_", "=", "train_iid", "(", "opt", ",", "maml", ",", "iterator_train", ",", "device", ")", "\n", "", "else", ":", "\n", "            ", "maml", ",", "accs", ",", "_", "=", "train", "(", "args", ",", "traj_classes", ",", "sampler", ",", "maml", ")", "\n", "\n", "", "if", "args", ".", "iid", "and", "step", "==", "(", "args", ".", "steps", "-", "1", ")", ":", "\n", "                ", "torch", ".", "save", "(", "maml", ",", "my_experiment", ".", "path", "+", "\"learner.model\"", ")", "\n", "\n", "", "if", "step", "%", "300", "==", "299", ":", "\n", "            ", "torch", ".", "save", "(", "maml", ".", "net", ",", "my_experiment", ".", "path", "+", "\"learner.model\"", ")", "\n", "torch", ".", "save", "(", "maml", ",", "my_experiment", ".", "path", "+", "\"meta-learner.model\"", ")", "\n", "\n", "correct", "=", "test", "(", "maml", ",", "args", ".", "iid", ",", "iterator_test", ",", "device", ")", "\n", "writer", ".", "add_scalar", "(", "'/metatrain/test/classifier/accuracy'", ",", "correct", "/", "len", "(", "iterator_test", ")", ",", "step", ")", "\n", "logger", ".", "info", "(", "\"Test Accuracy = %s\"", ",", "str", "(", "correct", "/", "len", "(", "iterator_test", ")", ")", ")", "\n", "\n", "correct_train_it", "=", "test", "(", "maml", ",", "args", ".", "iid", ",", "iterator_train", ",", "device", ")", "\n", "writer", ".", "add_scalar", "(", "'/metatrain/train_iterator/classifier/accuracy'", ",", "correct_train_it", "/", "len", "(", "iterator_train", ")", ",", "step", ")", "\n", "logger", ".", "info", "(", "\"Train Iterator Accuracy = %s\"", ",", "str", "(", "correct_train_it", "/", "len", "(", "iterator_train", ")", ")", ")", "\n", "\n", "# Evaluation during training for sanity checks", "\n", "", "if", "step", "%", "40", "==", "39", ":", "\n", "            ", "if", "not", "args", ".", "iid", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'/metatrain/train/accuracy'", ",", "accs", "[", "-", "1", "]", ",", "step", ")", "\n", "", "else", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'/metatrain/train/accuracy'", ",", "accs", ",", "step", ")", "\n", "", "logger", ".", "info", "(", "'step: %d \\t training acc %s'", ",", "step", ",", "str", "(", "accs", ")", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.tester.dataset_handler": [[18, 52], ["datasets.utils.get_embeddings", "numpy.random.choice", "utils.utils.remove_classes", "torch.utils.data.DataLoader", "utils.utils.remove_classes", "torch.utils.data.DataLoader", "datasets.datasetfactory.get_dataset", "numpy.random.choice", "utils.utils.remove_classes", "torch.utils.data.DataLoader", "utils.utils.remove_classes", "torch.utils.data.DataLoader", "numpy.min", "numpy.max", "utils.utils.sample_reducted_dataset", "numpy.insert", "numpy.repeat", "list", "datasets.datasetfactory.get_dataset", "datasets.datasetfactory.get_dataset", "numpy.max", "list", "datasets.datasetfactory.get_dataset", "datasets.datasetfactory.get_dataset", "new_X_test.extend", "new_Y_test.extend", "numpy.stack", "numpy.stack", "numpy.arange", "numpy.max", "range", "range", "len", "numpy.where", "numpy.unique", "numpy.stack"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.get_embeddings", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.remove_classes", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.remove_classes", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.remove_classes", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.remove_classes", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_reducted_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset"], ["def", "dataset_handler", "(", "args", ",", "tot_class", ")", ":", "\n", "    ", "if", "args", ".", "dataset", "==", "\"omniglot\"", "or", "args", ".", "dataset", "==", "\"imagenet\"", "or", "args", ".", "dataset", "==", "\"cub\"", ":", "\n", "        ", "X_train", ",", "Y_train", ",", "Z_train", ",", "X_test", ",", "Y_test", ",", "Z_test", "=", "get_embeddings", "(", "args", ".", "dataset", ",", "args", ".", "num_encoding_dims", ",", "args", ".", "test_set", ",", "args", ".", "encoder", ")", "\n", "Y_test", "=", "Y_test", "-", "np", ".", "min", "(", "Y_test", ")", "\n", "classes", "=", "np", ".", "max", "(", "Y_test", ")", "+", "1", "\n", "\n", "if", "args", ".", "dataset", "==", "\"imagenet\"", ":", "\n", "            ", "X_test", ",", "Y_test", "=", "sample_reducted_dataset", "(", "X_test", ",", "Y_test", ",", "classes", ")", "\n", "\n", "", "if", "args", ".", "dataset", "==", "\"cub\"", ":", "\n", "            ", "indices_of_change", "=", "np", ".", "insert", "(", "np", ".", "where", "(", "Y_test", "[", ":", "-", "1", "]", "!=", "Y_test", "[", "1", ":", "]", ")", "[", "0", "]", "+", "1", ",", "0", ",", "0", ")", "\n", "new_X_test", ",", "new_Y_test", "=", "[", "]", ",", "[", "]", "\n", "for", "index", "in", "indices_of_change", ":", "\n", "                ", "new_X_test", ".", "extend", "(", "X_test", "[", "index", ":", "index", "+", "20", "]", ")", "#sample 20 examples per class", "\n", "new_Y_test", ".", "extend", "(", "Y_test", "[", "index", ":", "index", "+", "20", "]", ")", "\n", "", "X_test", ",", "Y_test", "=", "np", ".", "stack", "(", "new_X_test", ")", ",", "np", ".", "stack", "(", "new_Y_test", ")", "\n", "Y_test", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "len", "(", "np", ".", "unique", "(", "np", ".", "stack", "(", "new_Y_test", ")", ")", ")", ")", ",", "20", ")", "\n", "classes", "=", "np", ".", "max", "(", "Y_test", ")", "+", "1", "\n", "\n", "", "keep", "=", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "classes", ")", ")", ",", "tot_class", ",", "replace", "=", "False", ")", "\n", "dataset", "=", "remove_classes", "(", "get_dataset", "(", "args", ",", "X_test", ",", "Y_test", ",", "train", "=", "True", ")", ",", "keep", ")", "\n", "iterator_sorted", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "args", ".", "iid", ",", "num_workers", "=", "0", ")", "\n", "dataset", "=", "remove_classes", "(", "get_dataset", "(", "args", ",", "X_test", ",", "Y_test", ",", "train", "=", "False", ")", ",", "keep", ")", "\n", "iterator", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "32", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "get_dataset", "(", "args", ",", "None", ",", "None", ",", "True", ",", "all", "=", "False", ")", "\n", "classes", "=", "np", ".", "max", "(", "dataset", ".", "targets", ")", "+", "1", "\n", "keep", "=", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "classes", ")", ")", ",", "tot_class", ",", "replace", "=", "False", ")", "\n", "dataset", "=", "remove_classes", "(", "get_dataset", "(", "args", ",", "None", ",", "None", ",", "train", "=", "True", ",", "all", "=", "False", ")", ",", "keep", ")", "\n", "iterator_sorted", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "args", ".", "iid", ",", "num_workers", "=", "0", ")", "\n", "dataset", "=", "remove_classes", "(", "get_dataset", "(", "args", ",", "None", ",", "None", ",", "train", "=", "False", ",", "all", "=", "False", ")", ",", "keep", ")", "\n", "iterator", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "32", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ")", "\n", "", "return", "iterator", ",", "iterator_sorted", ",", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.tester.main": [[54, 116], ["torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "random.seed", "utils.experiment.experiment", "tensorboardX.SummaryWriter", "logging.getLogger", "logging.getLogger.setLevel", "tensorboardX.SummaryWriter.close", "torch.cuda.is_available", "tester.dataset_handler", "meta.meta_test.lr_search", "range", "torch.device", "torch.device", "meta.meta_test.model_loader", "meta.meta_test.train", "meta.meta_test.test", "logging.getLogger.info", "tensorboardX.SummaryWriter.add_scalar", "final_results_all.append", "print", "logging.getLogger.info", "utils.experiment.experiment.store_json", "print", "numpy.array", "logging.getLogger.info", "print", "str", "str", "str", "str", "str", "numpy.mean", "numpy.std"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.oml.dataset_handler", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.lr_search", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.model_loader", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.experiment.experiment.store_json"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "my_experiment", "=", "experiment", "(", "args", ".", "name", ",", "args", ",", "LOG_DIR", ",", "args", ".", "commit", ")", "\n", "writer", "=", "SummaryWriter", "(", "my_experiment", ".", "path", "+", "\"tensorboard\"", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'experiment'", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "# Decrease learning rate at these epochs", "\n", "if", "args", ".", "dataset", "==", "\"omniglot\"", ":", "\n", "        ", "schedule", "=", "[", "10", ",", "50", ",", "75", ",", "100", ",", "150", ",", "200", "]", "\n", "", "elif", "args", ".", "dataset", "==", "\"imagenet\"", "or", "args", ".", "dataset", "==", "\"cifar\"", ":", "\n", "        ", "schedule", "=", "[", "2", ",", "4", ",", "6", ",", "8", ",", "10", "]", "\n", "", "elif", "args", ".", "dataset", "==", "\"cub\"", ":", "\n", "        ", "schedule", "=", "[", "2", ",", "10", ",", "20", ",", "30", ",", "40", "]", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Unsupported dataset\"", ")", "\n", "assert", "(", "False", ")", "\n", "\n", "", "if", "args", ".", "attention", "or", "args", ".", "mean", ":", "\n", "        ", "aggregation", "=", "True", "\n", "", "else", ":", "\n", "        ", "aggregation", "=", "False", "\n", "\n", "", "final_results_all", "=", "[", "]", "\n", "\n", "for", "tot_class", "in", "schedule", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "iterator", ",", "iterator_sorted", ",", "classes", "=", "dataset_handler", "(", "args", ",", "tot_class", ")", "\n", "# Learning rate search", "\n", "best_lr", "=", "lr_search", "(", "args", ",", "classes", ",", "iterator_sorted", ",", "iterator", ",", "logger", ",", "aggregation", ",", "device", ")", "\n", "\n", "for", "aoo", "in", "range", "(", "0", ",", "args", ".", "runs", ")", ":", "\n", "            ", "maml", "=", "model_loader", "(", "args", ",", "classes", ",", "device", ")", "\n", "# Meta-test training phase", "\n", "maml", "=", "train", "(", "args", ",", "maml", ",", "iterator_sorted", ",", "aggregation", ",", "device", ",", "best_lr", ")", "\n", "# Meta-test test phase", "\n", "current_acc", "=", "test", "(", "logger", ",", "maml", ",", "iterator", ",", "aggregation", ",", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Final Max Result = %s\"", ",", "str", "(", "current_acc", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'/finetune/best_'", "+", "str", "(", "aoo", ")", ",", "current_acc", ",", "tot_class", ")", "\n", "final_results_all", ".", "append", "(", "(", "tot_class", ",", "current_acc", ")", ")", "\n", "print", "(", "\"A=  \"", ",", "current_acc", ")", "\n", "logger", ".", "info", "(", "\"Final results = %s\"", ",", "str", "(", "current_acc", ")", ")", "\n", "\n", "my_experiment", ".", "results", "[", "\"Final Results\"", "]", "=", "final_results_all", "\n", "my_experiment", ".", "store_json", "(", ")", "\n", "print", "(", "\"FINAL RESULTS = \"", ",", "final_results_all", ")", "\n", "\n", "# mean and std of the results", "\n", "accs_current_cls", "=", "np", ".", "array", "(", "[", "res", "[", "1", "]", "for", "res", "in", "final_results_all", "if", "res", "[", "0", "]", "==", "tot_class", "]", ")", "\n", "logger", ".", "info", "(", "\"Task %d, mean: %s, std: %s\"", ",", "tot_class", ",", "str", "(", "np", ".", "mean", "(", "accs_current_cls", ")", ")", ",", "\n", "str", "(", "np", ".", "std", "(", "accs_current_cls", ")", ")", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.baseline.dataset_handler": [[21, 42], ["datasets.utils.get_embeddings", "datasets.datasetfactory.cactus", "datasets.datasetfactory.get_dataset", "datasets.datasetfactory.get_dataset", "numpy.unique", "int", "numpy.split", "list", "numpy.stack", "datasets.SamplerFactory.get_sampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "numpy.argwhere().flatten", "numpy.argwhere"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.get_embeddings", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.cactus", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SamplerFactory.get_sampler"], ["def", "dataset_handler", "(", "args", ")", ":", "\n", "    ", "X_train", ",", "Y_train", ",", "Z_train", ",", "X_val", ",", "Y_val", ",", "Z_val", "=", "get_embeddings", "(", "args", ".", "dataset", ",", "args", ".", "num_encoding_dims", ",", "args", ".", "test_set", ",", "args", ".", "encoder", ")", "\n", "\n", "cactus_data", ",", "cactus_labels", ",", "true_labels", "=", "cactus", "(", "args", ",", "X_train", ",", "Z_train", ",", "Y_train", ",", "train", "=", "True", ")", "\n", "\n", "dataset", "=", "get_dataset", "(", "args", ",", "cactus_data", ",", "cactus_labels", ",", "train", "=", "True", ")", "\n", "dataset_test", "=", "get_dataset", "(", "args", ",", "cactus_data", ",", "cactus_labels", ",", "train", "=", "False", ")", "\n", "\n", "classes", "=", "np", ".", "unique", "(", "dataset", ".", "targets", ")", "\n", "total_classes_num", "=", "int", "(", "classes", ".", "shape", "[", "0", "]", "/", "2", ")", "\n", "_", ",", "traj_classes", "=", "np", ".", "split", "(", "classes", ",", "np", ".", "argwhere", "(", "classes", "==", "classes", "[", "total_classes_num", "]", ")", ".", "flatten", "(", ")", ")", "\n", "classes", "=", "list", "(", "classes", ")", "\n", "traj_classes", "=", "np", ".", "stack", "(", "classes", ")", "\n", "\n", "sampler", "=", "ts", ".", "SamplerFactory", ".", "get_sampler", "(", "args", ".", "dataset", ",", "classes", ",", "dataset", ",", "dataset_test", ")", "\n", "# Iterators used for evaluation", "\n", "iterator_train", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "5", ",", "shuffle", "=", "args", ".", "iid", ",", "num_workers", "=", "0", ")", "\n", "iterator_test", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_test", ",", "batch_size", "=", "5", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ")", "\n", "\n", "return", "traj_classes", ",", "sampler", ",", "iterator_train", ",", "iterator_test", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.baseline.main": [[44, 100], ["utils.set_seed", "utils.experiment.experiment", "tensorboardX.SummaryWriter", "logging.getLogger", "torch.cuda.is_available", "model.modelfactory.get_model", "baseline.dataset_handler", "torch.optim.Adam", "range", "tensorboardX.SummaryWriter.close", "torch.device", "torch.device", "torch.load().to", "Learner().to.parameters", "model.meta_learner.MetaLearnerClassification().to", "model.learner.Learner().to", "meta.meta_train.train_iid", "meta.meta_train.train", "torch.save", "torch.save", "torch.save", "meta.meta_train.test", "tensorboardX.SummaryWriter.add_scalar", "logging.getLogger.info", "meta.meta_train.test", "tensorboardX.SummaryWriter.add_scalar", "logging.getLogger.info", "logging.getLogger.info", "torch.load", "str", "str", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "str", "model.meta_learner.MetaLearnerClassification", "model.learner.Learner", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.set_seed", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.modelfactory.get_model", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.oml.dataset_handler", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_train.train_iid", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "utils", ".", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "my_experiment", "=", "experiment", "(", "args", ".", "name", ",", "args", ",", "LOG_DIR", ",", "commit_changes", "=", "args", ".", "commit", ")", "\n", "writer", "=", "SummaryWriter", "(", "my_experiment", ".", "path", "+", "\"tensorboard\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'experiment'", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "config", "=", "get_model", "(", "args", ",", "args", ".", "num_clusters", ")", "\n", "\n", "traj_classes", ",", "sampler", ",", "iterator_train", ",", "iterator_test", "=", "dataset_handler", "(", "args", ")", "\n", "\n", "if", "not", "args", ".", "reload", ":", "\n", "        ", "if", "not", "args", ".", "iid", ":", "\n", "            ", "maml", "=", "MetaLearnerClassification", "(", "args", ",", "config", ",", "balance_vector", "=", "None", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "maml", "=", "Learner", "(", "config", ",", "args", ")", ".", "to", "(", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "maml", "=", "torch", ".", "load", "(", "args", ".", "ckpt_path", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "opt", "=", "torch", ".", "optim", ".", "Adam", "(", "maml", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "update_lr", ")", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "steps", ")", ":", "\n", "        ", "if", "args", ".", "iid", ":", "\n", "            ", "maml", ",", "accs", ",", "_", "=", "train_iid", "(", "opt", ",", "maml", ",", "iterator_train", ",", "device", ")", "\n", "", "else", ":", "\n", "            ", "maml", ",", "accs", ",", "_", "=", "train", "(", "args", ",", "traj_classes", ",", "sampler", ",", "maml", ")", "\n", "\n", "", "if", "args", ".", "iid", "and", "step", "==", "(", "args", ".", "steps", "-", "1", ")", ":", "\n", "                ", "torch", ".", "save", "(", "maml", ",", "my_experiment", ".", "path", "+", "\"learner.model\"", ")", "\n", "\n", "", "if", "step", "%", "300", "==", "299", ":", "\n", "            ", "torch", ".", "save", "(", "maml", ".", "net", ",", "my_experiment", ".", "path", "+", "\"learner.model\"", ")", "\n", "torch", ".", "save", "(", "maml", ",", "my_experiment", ".", "path", "+", "\"meta-learner.model\"", ")", "\n", "\n", "correct", "=", "test", "(", "maml", ",", "args", ".", "iid", ",", "iterator_test", ",", "device", ")", "\n", "writer", ".", "add_scalar", "(", "'/metatrain/test/classifier/accuracy'", ",", "correct", "/", "len", "(", "iterator_test", ")", ",", "step", ")", "\n", "logger", ".", "info", "(", "\"Test Accuracy = %s\"", ",", "str", "(", "correct", "/", "len", "(", "iterator_test", ")", ")", ")", "\n", "\n", "correct_train_it", "=", "test", "(", "maml", ",", "args", ".", "iid", ",", "iterator_train", ",", "device", ")", "\n", "writer", ".", "add_scalar", "(", "'/metatrain/train_iterator/classifier/accuracy'", ",", "correct_train_it", "/", "len", "(", "iterator_train", ")", ",", "step", ")", "\n", "logger", ".", "info", "(", "\"Train Iterator Accuracy = %s\"", ",", "str", "(", "correct_train_it", "/", "len", "(", "iterator_train", ")", ")", ")", "\n", "\n", "# Evaluation during training for sanity checks", "\n", "", "if", "step", "%", "40", "==", "39", ":", "\n", "            ", "if", "not", "args", ".", "iid", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'/metatrain/train/accuracy'", ",", "accs", "[", "-", "1", "]", ",", "step", ")", "\n", "", "else", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'/metatrain/train/accuracy'", ",", "accs", ",", "step", ")", "\n", "", "logger", ".", "info", "(", "'step: %d \\t training acc %s'", ",", "step", ",", "str", "(", "accs", ")", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.oml.dataset_handler": [[21, 55], ["numpy.unique", "int", "numpy.split", "list", "numpy.stack", "datasets.SamplerFactory.get_sampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "datasets.datasetfactory.get_dataset", "datasets.datasetfactory.get_dataset", "datasets.utils.get_embeddings", "numpy.repeat", "datasets.datasetfactory.get_dataset", "datasets.datasetfactory.get_dataset", "numpy.argwhere().flatten", "utils.sample_reducted_dataset", "numpy.arange", "numpy.insert", "numpy.stack", "numpy.argwhere", "new_X_train.extend", "numpy.where"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.task_sampler.SamplerFactory.get_sampler", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.utils.get_embeddings", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.datasets.datasetfactory.get_dataset", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.sample_reducted_dataset"], ["def", "dataset_handler", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "dataset", "==", "\"cifar\"", ":", "\n", "        ", "dataset", "=", "get_dataset", "(", "args", ",", "None", ",", "None", ",", "train", "=", "True", ",", "all", "=", "True", ")", "\n", "dataset_test", "=", "get_dataset", "(", "args", ",", "None", ",", "None", ",", "train", "=", "False", ",", "all", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "X_train", ",", "Y_train", ",", "Z_train", ",", "X_val", ",", "Y_val", ",", "Z_val", "=", "get_embeddings", "(", "args", ".", "dataset", ",", "args", ".", "num_encoding_dims", ",", "args", ".", "test_set", ",", "args", ".", "encoder", ")", "\n", "\n", "if", "args", ".", "dataset", "==", "\"imagenet\"", ":", "\n", "            ", "X_train", ",", "Y_train", "=", "utils", ".", "sample_reducted_dataset", "(", "X_train", ",", "Y_train", ",", "args", ".", "num_classes", ")", "\n", "\n", "", "elif", "args", ".", "dataset", "==", "\"cub\"", ":", "\n", "            ", "indices_of_change", "=", "np", ".", "insert", "(", "np", ".", "where", "(", "Y_train", "[", ":", "-", "1", "]", "!=", "Y_train", "[", "1", ":", "]", ")", "[", "0", "]", "+", "1", ",", "0", ",", "0", ")", "\n", "new_X_train", "=", "[", "]", "\n", "for", "index", "in", "indices_of_change", ":", "\n", "                ", "new_X_train", ".", "extend", "(", "X_train", "[", "index", ":", "index", "+", "20", "]", ")", "# sample 20 examples per class", "\n", "", "X_train", "=", "np", ".", "stack", "(", "new_X_train", ")", "\n", "", "Y_train", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "100", ")", ",", "20", ")", "\n", "\n", "dataset", "=", "get_dataset", "(", "args", ",", "X_train", ",", "Y_train", ",", "train", "=", "True", ")", "\n", "dataset_test", "=", "get_dataset", "(", "args", ",", "X_train", ",", "Y_train", ",", "train", "=", "False", ")", "\n", "\n", "", "classes", "=", "np", ".", "unique", "(", "dataset", ".", "targets", ")", "\n", "total_classes_num", "=", "int", "(", "classes", ".", "shape", "[", "0", "]", "/", "2", ")", "\n", "_", ",", "traj_classes", "=", "np", ".", "split", "(", "classes", ",", "np", ".", "argwhere", "(", "classes", "==", "classes", "[", "total_classes_num", "]", ")", ".", "flatten", "(", ")", ")", "\n", "classes", "=", "list", "(", "classes", ")", "\n", "traj_classes", "=", "np", ".", "stack", "(", "classes", ")", "\n", "\n", "sampler", "=", "ts", ".", "SamplerFactory", ".", "get_sampler", "(", "args", ".", "dataset", ",", "classes", ",", "dataset", ",", "dataset_test", ")", "\n", "# Iterators used for evaluation", "\n", "iterator_train", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "5", ",", "shuffle", "=", "args", ".", "iid", ",", "num_workers", "=", "4", ")", "\n", "iterator_test", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_test", ",", "batch_size", "=", "5", ",", "shuffle", "=", "False", ",", "num_workers", "=", "4", ")", "\n", "\n", "return", "traj_classes", ",", "sampler", ",", "iterator_train", ",", "iterator_test", "\n", "\n"]], "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.oml.main": [[57, 112], ["utils.set_seed", "utils.experiment.experiment", "tensorboardX.SummaryWriter", "logging.getLogger", "torch.cuda.is_available", "model.modelfactory.get_model", "oml.dataset_handler", "torch.optim.Adam", "range", "tensorboardX.SummaryWriter.close", "torch.device", "torch.device", "torch.load().to", "Learner().to.parameters", "model.meta_learner.MetaLearnerClassification().to", "model.learner.Learner().to", "meta.meta_train.train_iid", "meta.meta_train.train", "torch.save", "torch.save", "torch.save", "meta.meta_train.test", "tensorboardX.SummaryWriter.add_scalar", "logging.getLogger.info", "meta.meta_train.test", "tensorboardX.SummaryWriter.add_scalar", "logging.getLogger.info", "logging.getLogger.info", "torch.load", "str", "str", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "str", "model.meta_learner.MetaLearnerClassification", "model.learner.Learner", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.alessiabertugli_FUSION.utils.utils.set_seed", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.modelfactory.get_model", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.trainers.oml.dataset_handler", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.model.learner.Learner.parameters", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_train.train_iid", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.train", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test", "home.repos.pwc.inspect_result.alessiabertugli_FUSION.meta.meta_test.test"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "utils", ".", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "my_experiment", "=", "experiment", "(", "args", ".", "name", ",", "args", ",", "LOG_DIR", ",", "commit_changes", "=", "args", ".", "commit", ")", "\n", "writer", "=", "SummaryWriter", "(", "my_experiment", ".", "path", "+", "\"tensorboard\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'experiment'", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "config", "=", "get_model", "(", "args", ",", "args", ".", "num_classes", ")", "\n", "\n", "if", "not", "args", ".", "reload", ":", "\n", "        ", "if", "not", "args", ".", "iid", ":", "\n", "            ", "maml", "=", "MetaLearnerClassification", "(", "args", ",", "config", ",", "balance_vector", "=", "None", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "maml", "=", "Learner", "(", "config", ",", "args", ")", ".", "to", "(", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "maml", "=", "torch", ".", "load", "(", "args", ".", "ckpt_path", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "traj_classes", ",", "sampler", ",", "iterator_train", ",", "iterator_test", "=", "dataset_handler", "(", "args", ")", "\n", "opt", "=", "torch", ".", "optim", ".", "Adam", "(", "maml", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "update_lr", ")", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "steps", ")", ":", "\n", "        ", "if", "args", ".", "iid", ":", "\n", "            ", "maml", ",", "accs", ",", "_", "=", "train_iid", "(", "opt", ",", "maml", ",", "iterator_train", ",", "device", ")", "\n", "", "else", ":", "\n", "            ", "maml", ",", "accs", ",", "_", "=", "train", "(", "args", ",", "traj_classes", ",", "sampler", ",", "maml", ")", "\n", "\n", "", "if", "args", ".", "iid", "and", "step", "==", "(", "args", ".", "steps", "-", "1", ")", ":", "\n", "                ", "torch", ".", "save", "(", "maml", ",", "my_experiment", ".", "path", "+", "\"learner.model\"", ")", "\n", "\n", "", "if", "step", "%", "300", "==", "299", ":", "\n", "            ", "torch", ".", "save", "(", "maml", ".", "net", ",", "my_experiment", ".", "path", "+", "\"learner.model\"", ")", "\n", "torch", ".", "save", "(", "maml", ",", "my_experiment", ".", "path", "+", "\"meta-learner.model\"", ")", "\n", "\n", "correct", "=", "test", "(", "maml", ",", "args", ".", "iid", ",", "iterator_test", ",", "device", ")", "\n", "writer", ".", "add_scalar", "(", "'/metatrain/test/classifier/accuracy'", ",", "correct", "/", "len", "(", "iterator_test", ")", ",", "step", ")", "\n", "logger", ".", "info", "(", "\"Test Accuracy = %s\"", ",", "str", "(", "correct", "/", "len", "(", "iterator_test", ")", ")", ")", "\n", "\n", "correct_train_it", "=", "test", "(", "maml", ",", "args", ".", "iid", ",", "iterator_train", ",", "device", ")", "\n", "writer", ".", "add_scalar", "(", "'/metatrain/train_iterator/classifier/accuracy'", ",", "correct_train_it", "/", "len", "(", "iterator_train", ")", ",", "step", ")", "\n", "logger", ".", "info", "(", "\"Train Iterator Accuracy = %s\"", ",", "str", "(", "correct_train_it", "/", "len", "(", "iterator_train", ")", ")", ")", "\n", "\n", "# Evaluation during training for sanity checks", "\n", "", "if", "step", "%", "40", "==", "39", ":", "\n", "            ", "if", "not", "args", ".", "iid", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'/metatrain/train/accuracy'", ",", "accs", "[", "-", "1", "]", ",", "step", ")", "\n", "", "else", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'/metatrain/train/accuracy'", ",", "accs", ",", "step", ")", "\n", "", "logger", ".", "info", "(", "'step: %d \\t training acc %s'", ",", "step", ",", "str", "(", "accs", ")", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]]}