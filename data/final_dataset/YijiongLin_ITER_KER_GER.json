{"home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_vec_env": [[22, 60], ["baselines.logger.get_dir", "baselines.common.set_global_seeds", "MPI.COMM_WORLD.Get_rank", "baselines.common.vec_env.subproc_vec_env.SubprocVecEnv", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "cmd_util.make_env", "cmd_util.make_vec_env.make_thunk"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_env"], ["def", "make_vec_env", "(", "env_id", ",", "env_type", ",", "num_env", ",", "seed", ",", "\n", "wrapper_kwargs", "=", "None", ",", "\n", "env_kwargs", "=", "None", ",", "\n", "start_index", "=", "0", ",", "\n", "reward_scale", "=", "1.0", ",", "\n", "flatten_dict_observations", "=", "True", ",", "\n", "gamestate", "=", "None", ",", "\n", "initializer", "=", "None", ",", "\n", "force_dummy", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.\n    \"\"\"", "\n", "wrapper_kwargs", "=", "wrapper_kwargs", "or", "{", "}", "\n", "env_kwargs", "=", "env_kwargs", "or", "{", "}", "\n", "mpi_rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "if", "MPI", "else", "0", "\n", "seed", "=", "seed", "+", "10000", "*", "mpi_rank", "if", "seed", "is", "not", "None", "else", "None", "\n", "logger_dir", "=", "logger", ".", "get_dir", "(", ")", "\n", "def", "make_thunk", "(", "rank", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "return", "lambda", ":", "make_env", "(", "\n", "env_id", "=", "env_id", ",", "\n", "env_type", "=", "env_type", ",", "\n", "mpi_rank", "=", "mpi_rank", ",", "\n", "subrank", "=", "rank", ",", "\n", "seed", "=", "seed", ",", "\n", "reward_scale", "=", "reward_scale", ",", "\n", "gamestate", "=", "gamestate", ",", "\n", "flatten_dict_observations", "=", "flatten_dict_observations", ",", "\n", "wrapper_kwargs", "=", "wrapper_kwargs", ",", "\n", "env_kwargs", "=", "env_kwargs", ",", "\n", "logger_dir", "=", "logger_dir", ",", "\n", "initializer", "=", "initializer", "\n", ")", "\n", "\n", "", "set_global_seeds", "(", "seed", ")", "\n", "if", "not", "force_dummy", "and", "num_env", ">", "1", ":", "\n", "        ", "return", "SubprocVecEnv", "(", "[", "make_thunk", "(", "i", "+", "start_index", ",", "initializer", "=", "initializer", ")", "for", "i", "in", "range", "(", "num_env", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "DummyVecEnv", "(", "[", "make_thunk", "(", "i", "+", "start_index", ",", "initializer", "=", "None", ")", "for", "i", "in", "range", "(", "num_env", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_env": [[62, 107], ["retro_wrappers.wrap_deepmind_retro.seed", "baselines.bench.Monitor", "isinstance", "initializer", "re.sub", "re.sub", "importlib.import_module", "baselines.common.atari_wrappers.make_atari", "isinstance", "retro_wrappers.wrap_deepmind_retro.observation_space.spaces.keys", "gym.wrappers.FlattenDictWrapper", "baselines.common.atari_wrappers.wrap_deepmind", "baselines.common.wrappers.ClipActionsWrapper", "baselines.common.retro_wrappers.RewardScaler", "baselines.common.retro_wrappers.make_retro", "gym.make", "os.path.join", "baselines.common.retro_wrappers.wrap_deepmind_retro", "list", "str", "str"], "function", ["None"], ["", "", "def", "make_env", "(", "env_id", ",", "env_type", ",", "mpi_rank", "=", "0", ",", "subrank", "=", "0", ",", "seed", "=", "None", ",", "reward_scale", "=", "1.0", ",", "gamestate", "=", "None", ",", "flatten_dict_observations", "=", "True", ",", "wrapper_kwargs", "=", "None", ",", "env_kwargs", "=", "None", ",", "logger_dir", "=", "None", ",", "initializer", "=", "None", ")", ":", "\n", "    ", "if", "initializer", "is", "not", "None", ":", "\n", "        ", "initializer", "(", "mpi_rank", "=", "mpi_rank", ",", "subrank", "=", "subrank", ")", "\n", "\n", "", "wrapper_kwargs", "=", "wrapper_kwargs", "or", "{", "}", "\n", "env_kwargs", "=", "env_kwargs", "or", "{", "}", "\n", "if", "':'", "in", "env_id", ":", "\n", "        ", "import", "re", "\n", "import", "importlib", "\n", "module_name", "=", "re", ".", "sub", "(", "':.*'", ",", "''", ",", "env_id", ")", "\n", "env_id", "=", "re", ".", "sub", "(", "'.*:'", ",", "''", ",", "env_id", ")", "\n", "importlib", ".", "import_module", "(", "module_name", ")", "\n", "", "if", "env_type", "==", "'atari'", ":", "\n", "        ", "env", "=", "make_atari", "(", "env_id", ")", "\n", "", "elif", "env_type", "==", "'retro'", ":", "\n", "        ", "import", "retro", "\n", "gamestate", "=", "gamestate", "or", "retro", ".", "State", ".", "DEFAULT", "\n", "env", "=", "retro_wrappers", ".", "make_retro", "(", "game", "=", "env_id", ",", "max_episode_steps", "=", "10000", ",", "use_restricted_actions", "=", "retro", ".", "Actions", ".", "DISCRETE", ",", "state", "=", "gamestate", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "gym", ".", "make", "(", "env_id", ",", "**", "env_kwargs", ")", "\n", "\n", "", "if", "flatten_dict_observations", "and", "isinstance", "(", "env", ".", "observation_space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "        ", "keys", "=", "env", ".", "observation_space", ".", "spaces", ".", "keys", "(", ")", "\n", "env", "=", "gym", ".", "wrappers", ".", "FlattenDictWrapper", "(", "env", ",", "dict_keys", "=", "list", "(", "keys", ")", ")", "\n", "\n", "", "env", ".", "seed", "(", "seed", "+", "subrank", "if", "seed", "is", "not", "None", "else", "None", ")", "\n", "env", "=", "Monitor", "(", "env", ",", "\n", "logger_dir", "and", "os", ".", "path", ".", "join", "(", "logger_dir", ",", "str", "(", "mpi_rank", ")", "+", "'.'", "+", "str", "(", "subrank", ")", ")", ",", "\n", "allow_early_resets", "=", "True", ")", "\n", "\n", "\n", "if", "env_type", "==", "'atari'", ":", "\n", "        ", "env", "=", "wrap_deepmind", "(", "env", ",", "**", "wrapper_kwargs", ")", "\n", "", "elif", "env_type", "==", "'retro'", ":", "\n", "        ", "if", "'frame_stack'", "not", "in", "wrapper_kwargs", ":", "\n", "            ", "wrapper_kwargs", "[", "'frame_stack'", "]", "=", "1", "\n", "", "env", "=", "retro_wrappers", ".", "wrap_deepmind_retro", "(", "env", ",", "**", "wrapper_kwargs", ")", "\n", "\n", "", "if", "isinstance", "(", "env", ".", "action_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "        ", "env", "=", "ClipActionsWrapper", "(", "env", ")", "\n", "\n", "", "if", "reward_scale", "!=", "1", ":", "\n", "        ", "env", "=", "retro_wrappers", ".", "RewardScaler", "(", "env", ",", "reward_scale", ")", "\n", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_mujoco_env": [[109, 124], ["MPI.COMM_WORLD.Get_rank", "baselines.common.set_global_seeds", "gym.make", "baselines.bench.Monitor", "RewardScaler.seed", "os.path.join", "RewardScaler", "baselines.logger.get_dir", "baselines.logger.get_dir", "str"], "function", ["None"], ["", "def", "make_mujoco_env", "(", "env_id", ",", "seed", ",", "reward_scale", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored gym.Env for MuJoCo.\n    \"\"\"", "\n", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "myseed", "=", "seed", "+", "1000", "*", "rank", "if", "seed", "is", "not", "None", "else", "None", "\n", "set_global_seeds", "(", "myseed", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "logger_path", "=", "None", "if", "logger", ".", "get_dir", "(", ")", "is", "None", "else", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "str", "(", "rank", ")", ")", "\n", "env", "=", "Monitor", "(", "env", ",", "logger_path", ",", "allow_early_resets", "=", "True", ")", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "if", "reward_scale", "!=", "1.0", ":", "\n", "        ", "from", "baselines", ".", "common", ".", "retro_wrappers", "import", "RewardScaler", "\n", "env", "=", "RewardScaler", "(", "env", ",", "reward_scale", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_robotics_env": [[125, 137], ["baselines.common.set_global_seeds", "gym.make", "gym.wrappers.FlattenDictWrapper", "baselines.bench.Monitor", "baselines.bench.Monitor.seed", "baselines.logger.get_dir", "os.path.join", "baselines.logger.get_dir", "str"], "function", ["None"], ["", "def", "make_robotics_env", "(", "env_id", ",", "seed", ",", "rank", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored gym.Env for MuJoCo.\n    \"\"\"", "\n", "set_global_seeds", "(", "seed", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "env", "=", "FlattenDictWrapper", "(", "env", ",", "[", "'observation'", ",", "'desired_goal'", "]", ")", "\n", "env", "=", "Monitor", "(", "\n", "env", ",", "logger", ".", "get_dir", "(", ")", "and", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "str", "(", "rank", ")", ")", ",", "\n", "info_keywords", "=", "(", "'is_success'", ",", ")", ")", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.arg_parser": [[138, 144], ["argparse.ArgumentParser"], "function", ["None"], ["", "def", "arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an empty argparse.ArgumentParser.\n    \"\"\"", "\n", "import", "argparse", "\n", "return", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.atari_arg_parser": [[145, 151], ["print", "cmd_util.common_arg_parser"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.common_arg_parser"], ["", "def", "atari_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an argparse.ArgumentParser for run_atari.py.\n    \"\"\"", "\n", "print", "(", "'Obsolete - use common_arg_parser instead'", ")", "\n", "return", "common_arg_parser", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.mujoco_arg_parser": [[152, 155], ["print", "cmd_util.common_arg_parser"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.common_arg_parser"], ["", "def", "mujoco_arg_parser", "(", ")", ":", "\n", "    ", "print", "(", "'Obsolete - use common_arg_parser instead'", ")", "\n", "return", "common_arg_parser", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.common_arg_parser": [[156, 177], ["cmd_util.arg_parser", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.arg_parser"], ["", "def", "common_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an argparse.ArgumentParser for run_mujoco.py.\n    \"\"\"", "\n", "parser", "=", "arg_parser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--env'", ",", "help", "=", "'environment ID'", ",", "type", "=", "str", ",", "default", "=", "'Reacher-v2'", ")", "\n", "parser", ".", "add_argument", "(", "'--env_type'", ",", "help", "=", "'type of environment, used when the environment type cannot be automatically determined'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'RNG seed'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--alg'", ",", "help", "=", "'Algorithm'", ",", "type", "=", "str", ",", "default", "=", "'ppo2'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_timesteps'", ",", "type", "=", "float", ",", "default", "=", "1e6", ")", ",", "\n", "parser", ".", "add_argument", "(", "'--network'", ",", "help", "=", "'network type (mlp, cnn, lstm, cnn_lstm, conv_only)'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--gamestate'", ",", "help", "=", "'game state to load (so far only used in retro games)'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--num_env'", ",", "help", "=", "'Number of environment copies being run in parallel. When not specified, set to number of cpus for Atari, and to 1 for Mujoco'", ",", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--reward_scale'", ",", "help", "=", "'Reward scale factor. Default: 1.0'", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "help", "=", "'Path to save trained model to'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--save_video_interval'", ",", "help", "=", "'Save video every x steps (0 = disabled)'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--save_video_length'", ",", "help", "=", "'Length of recorded video. Default: 200'", ",", "default", "=", "200", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--log_path'", ",", "help", "=", "'Directory to save learning curve data.'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--play'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_rsym'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.robotics_arg_parser": [[178, 187], ["cmd_util.arg_parser", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "int"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.arg_parser"], ["", "def", "robotics_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an argparse.ArgumentParser for run_mujoco.py.\n    \"\"\"", "\n", "parser", "=", "arg_parser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--env'", ",", "help", "=", "'environment ID'", ",", "type", "=", "str", ",", "default", "=", "'FetchReach-v0'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'RNG seed'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--num-timesteps'", ",", "type", "=", "int", ",", "default", "=", "int", "(", "1e6", ")", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.parse_unknown_args": [[189, 209], ["arg.startswith", "arg.split", "arg.split"], "function", ["None"], ["", "def", "parse_unknown_args", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Parse arguments not consumed by arg parser into a dictionary\n    \"\"\"", "\n", "retval", "=", "{", "}", "\n", "preceded_by_key", "=", "False", "\n", "for", "arg", "in", "args", ":", "\n", "        ", "if", "arg", ".", "startswith", "(", "'--'", ")", ":", "\n", "            ", "if", "'='", "in", "arg", ":", "\n", "                ", "key", "=", "arg", ".", "split", "(", "'='", ")", "[", "0", "]", "[", "2", ":", "]", "\n", "value", "=", "arg", ".", "split", "(", "'='", ")", "[", "1", "]", "\n", "retval", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "                ", "key", "=", "arg", "[", "2", ":", "]", "\n", "preceded_by_key", "=", "True", "\n", "", "", "elif", "preceded_by_key", ":", "\n", "            ", "retval", "[", "key", "]", "=", "arg", "\n", "preceded_by_key", "=", "False", "\n", "\n", "", "", "return", "retval", "\n", "", ""]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.train": [[54, 87], ["run.get_env_type", "print", "int", "run.get_learn_function", "run.get_learn_function_defaults", "get_learn_function_defaults.update", "run.build_env", "print", "get_learn_function.", "baselines.common.vec_env.vec_video_recorder.VecVideoRecorder", "os.join", "get_learn_function_defaults.get", "run.get_default_network", "baselines.logger.get_dir"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_env_type", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_learn_function", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_learn_function_defaults", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.build_env", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_default_network"], ["def", "train", "(", "args", ",", "extra_args", ")", ":", "\n", "    ", "env_type", ",", "env_id", "=", "get_env_type", "(", "args", ")", "\n", "print", "(", "'env_type: {}'", ".", "format", "(", "env_type", ")", ")", "\n", "\n", "total_timesteps", "=", "int", "(", "args", ".", "num_timesteps", ")", "\n", "seed", "=", "args", ".", "seed", "\n", "\n", "learn", "=", "get_learn_function", "(", "args", ".", "alg", ")", "\n", "alg_kwargs", "=", "get_learn_function_defaults", "(", "args", ".", "alg", ",", "env_type", ")", "\n", "alg_kwargs", ".", "update", "(", "extra_args", ")", "\n", "\n", "env", "=", "build_env", "(", "args", ")", "\n", "if", "args", ".", "save_video_interval", "!=", "0", ":", "\n", "        ", "env", "=", "VecVideoRecorder", "(", "env", ",", "osp", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "\"videos\"", ")", ",", "record_video_trigger", "=", "lambda", "x", ":", "x", "%", "args", ".", "save_video_interval", "==", "0", ",", "video_length", "=", "args", ".", "save_video_length", ")", "\n", "\n", "", "if", "args", ".", "network", ":", "\n", "        ", "alg_kwargs", "[", "'network'", "]", "=", "args", ".", "network", "\n", "", "else", ":", "\n", "        ", "if", "alg_kwargs", ".", "get", "(", "'network'", ")", "is", "None", ":", "\n", "            ", "alg_kwargs", "[", "'network'", "]", "=", "get_default_network", "(", "env_type", ")", "\n", "\n", "", "", "print", "(", "'Training {} on {}:{} with arguments \\n{}'", ".", "format", "(", "args", ".", "alg", ",", "env_type", ",", "env_id", ",", "alg_kwargs", ")", ")", "\n", "\n", "model", "=", "learn", "(", "\n", "env", "=", "env", ",", "\n", "seed", "=", "seed", ",", "\n", "total_timesteps", "=", "total_timesteps", ",", "\n", "save_path", "=", "args", ".", "save_path", ",", "\n", "n_rsym", "=", "args", ".", "n_rsym", ",", "\n", "**", "alg_kwargs", "\n", ")", "\n", "\n", "return", "model", ",", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.build_env": [[89, 122], ["multiprocessing.cpu_count", "run.get_env_type", "tensorflow.ConfigProto", "baselines.common.tf_util.get_session", "baselines.common.cmd_util.make_vec_env", "baselines.common.cmd_util.make_env", "baselines.common.vec_env.VecNormalize", "baselines.common.cmd_util.make_env", "baselines.common.cmd_util.make_vec_env", "baselines.common.vec_env.VecFrameStack"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_env_type", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_vec_env", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_env", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_env", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.make_vec_env"], ["", "def", "build_env", "(", "args", ")", ":", "\n", "    ", "ncpu", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "if", "sys", ".", "platform", "==", "'darwin'", ":", "ncpu", "//=", "2", "\n", "nenv", "=", "args", ".", "num_env", "or", "ncpu", "\n", "alg", "=", "args", ".", "alg", "\n", "seed", "=", "args", ".", "seed", "\n", "\n", "env_type", ",", "env_id", "=", "get_env_type", "(", "args", ")", "\n", "\n", "if", "env_type", "in", "{", "'atari'", ",", "'retro'", "}", ":", "\n", "        ", "if", "alg", "==", "'deepq'", ":", "\n", "            ", "env", "=", "make_env", "(", "env_id", ",", "env_type", ",", "seed", "=", "seed", ",", "wrapper_kwargs", "=", "{", "'frame_stack'", ":", "True", "}", ")", "\n", "", "elif", "alg", "==", "'trpo_mpi'", ":", "\n", "            ", "env", "=", "make_env", "(", "env_id", ",", "env_type", ",", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "            ", "frame_stack_size", "=", "4", "\n", "env", "=", "make_vec_env", "(", "env_id", ",", "env_type", ",", "nenv", ",", "seed", ",", "gamestate", "=", "args", ".", "gamestate", ",", "reward_scale", "=", "args", ".", "reward_scale", ")", "\n", "env", "=", "VecFrameStack", "(", "env", ",", "frame_stack_size", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "intra_op_parallelism_threads", "=", "1", ",", "\n", "inter_op_parallelism_threads", "=", "1", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "get_session", "(", "config", "=", "config", ")", "\n", "\n", "flatten_dict_observations", "=", "alg", "not", "in", "{", "'her'", "}", "\n", "env", "=", "make_vec_env", "(", "env_id", ",", "env_type", ",", "args", ".", "num_env", "or", "1", ",", "seed", ",", "reward_scale", "=", "args", ".", "reward_scale", ",", "flatten_dict_observations", "=", "flatten_dict_observations", ")", "\n", "\n", "if", "env_type", "==", "'mujoco'", ":", "\n", "            ", "env", "=", "VecNormalize", "(", "env", ",", "use_tf", "=", "True", ")", "\n", "\n", "", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_env_type": [[124, 149], ["gym.envs.registry.all", "_game_envs[].add", "_game_envs.keys", "_game_envs.items", "[].split", "re.sub", "_game_envs.keys", "env._entry_point.split"], "function", ["None"], ["", "def", "get_env_type", "(", "args", ")", ":", "\n", "    ", "env_id", "=", "args", ".", "env", "\n", "\n", "if", "args", ".", "env_type", "is", "not", "None", ":", "\n", "        ", "return", "args", ".", "env_type", ",", "env_id", "\n", "\n", "# Re-parse the gym registry, since we could have new envs since last time.", "\n", "", "for", "env", "in", "gym", ".", "envs", ".", "registry", ".", "all", "(", ")", ":", "\n", "        ", "env_type", "=", "env", ".", "_entry_point", ".", "split", "(", "':'", ")", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "\n", "_game_envs", "[", "env_type", "]", ".", "add", "(", "env", ".", "id", ")", "# This is a set so add is idempotent", "\n", "\n", "", "if", "env_id", "in", "_game_envs", ".", "keys", "(", ")", ":", "\n", "        ", "env_type", "=", "env_id", "\n", "env_id", "=", "[", "g", "for", "g", "in", "_game_envs", "[", "env_type", "]", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "env_type", "=", "None", "\n", "for", "g", ",", "e", "in", "_game_envs", ".", "items", "(", ")", ":", "\n", "            ", "if", "env_id", "in", "e", ":", "\n", "                ", "env_type", "=", "g", "\n", "break", "\n", "", "", "if", "':'", "in", "env_id", ":", "\n", "            ", "env_type", "=", "re", ".", "sub", "(", "r':.*'", ",", "''", ",", "env_id", ")", "\n", "", "assert", "env_type", "is", "not", "None", ",", "'env_id {} is not recognized in env types'", ".", "format", "(", "env_id", ",", "_game_envs", ".", "keys", "(", ")", ")", "\n", "\n", "", "return", "env_type", ",", "env_id", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_default_network": [[151, 156], ["None"], "function", ["None"], ["", "def", "get_default_network", "(", "env_type", ")", ":", "\n", "    ", "if", "env_type", "in", "{", "'atari'", ",", "'retro'", "}", ":", "\n", "        ", "return", "'cnn'", "\n", "", "else", ":", "\n", "        ", "return", "'mlp'", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_alg_module": [[157, 167], ["importlib.import_module", "importlib.import_module"], "function", ["None"], ["", "", "def", "get_alg_module", "(", "alg", ",", "submodule", "=", "None", ")", ":", "\n", "    ", "submodule", "=", "submodule", "or", "alg", "\n", "try", ":", "\n", "# first try to import the alg module from baselines", "\n", "        ", "alg_module", "=", "import_module", "(", "'.'", ".", "join", "(", "[", "'baselines'", ",", "alg", ",", "submodule", "]", ")", ")", "\n", "", "except", "ImportError", ":", "\n", "# then from rl_algs", "\n", "        ", "alg_module", "=", "import_module", "(", "'.'", ".", "join", "(", "[", "'rl_'", "+", "'algs'", ",", "alg", ",", "submodule", "]", ")", ")", "\n", "\n", "", "return", "alg_module", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_learn_function": [[169, 171], ["run.get_alg_module"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_alg_module"], ["", "def", "get_learn_function", "(", "alg", ")", ":", "\n", "    ", "return", "get_alg_module", "(", "alg", ")", ".", "learn", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_learn_function_defaults": [[173, 180], ["run.get_alg_module", "getattr"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.get_alg_module"], ["", "def", "get_learn_function_defaults", "(", "alg", ",", "env_type", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "alg_defaults", "=", "get_alg_module", "(", "alg", ",", "'defaults'", ")", "\n", "kwargs", "=", "getattr", "(", "alg_defaults", ",", "env_type", ")", "(", ")", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "        ", "kwargs", "=", "{", "}", "\n", "", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.parse_cmdline_kwargs": [[183, 196], ["isinstance", "run.parse_cmdline_kwargs.parse"], "function", ["None"], ["", "def", "parse_cmdline_kwargs", "(", "args", ")", ":", "\n", "    ", "'''\n    convert a list of '='-spaced command-line arguments to a dictionary, evaluating python objects when possible\n    '''", "\n", "def", "parse", "(", "v", ")", ":", "\n", "\n", "        ", "assert", "isinstance", "(", "v", ",", "str", ")", "\n", "try", ":", "\n", "            ", "return", "eval", "(", "v", ")", "\n", "", "except", "(", "NameError", ",", "SyntaxError", ")", ":", "\n", "            ", "return", "v", "\n", "\n", "", "", "return", "{", "k", ":", "parse", "(", "v", ")", "for", "k", ",", "v", "in", "parse_unknown_args", "(", "args", ")", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.configure_logger": [[198, 203], ["baselines.logger.configure", "baselines.logger.configure"], "function", ["None"], ["", "def", "configure_logger", "(", "log_path", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "log_path", "is", "not", "None", ":", "\n", "        ", "logger", ".", "configure", "(", "log_path", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "configure", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.main": [[205, 263], ["baselines.common.cmd_util.common_arg_parser", "baselines.common.cmd_util.common_arg_parser.parse_known_args", "run.parse_cmdline_kwargs", "run.train", "env.close", "datetime.datetime.now().strftime", "os.path.join", "os.path.join", "datetime.datetime.now().strftime", "os.path.join", "os.path.join", "run.configure_logger", "MPI.COMM_WORLD.Get_rank", "run.configure_logger", "os.expanduser", "model.save", "baselines.logger.log", "env.reset", "numpy.zeros", "MPI.COMM_WORLD.Get_rank", "hasattr", "env.step", "env.render", "datetime.datetime.now", "datetime.datetime.now", "model.step", "model.step", "isinstance", "isinstance", "done.any", "print", "env.reset"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.cmd_util.common_arg_parser", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.parse_cmdline_kwargs", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.train", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.configure_logger", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.None.run.configure_logger", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.save", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.step", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.step", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.step"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "# configure logger, disable logging in child MPI processes (with rank > 0)", "\n", "    ", "arg_parser", "=", "common_arg_parser", "(", ")", "\n", "args", ",", "unknown_args", "=", "arg_parser", ".", "parse_known_args", "(", "args", ")", "\n", "extra_args", "=", "parse_cmdline_kwargs", "(", "unknown_args", ")", "\n", "if", "args", ".", "log_path", "is", "not", "None", ":", "\n", "# =========modifiy the log path with time=============", "\n", "        ", "time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%y_%a_%b_%d_%H:%M:%S:%f'", ")", "\n", "args", ".", "log_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_path", ",", "time", ")", "\n", "# =====================================================", "\n", "", "if", "args", ".", "save_path", "is", "not", "None", ":", "\n", "# =========modifiy the save path with time=============", "\n", "        ", "time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%y_%a_%b_%d_%H:%M:%S:%f'", ")", "\n", "args", ".", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "time", ")", "\n", "# =====================================================", "\n", "\n", "\n", "", "if", "MPI", "is", "None", "or", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "==", "0", ":", "\n", "        ", "rank", "=", "0", "\n", "configure_logger", "(", "args", ".", "log_path", ")", "\n", "", "else", ":", "\n", "        ", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "configure_logger", "(", "args", ".", "log_path", ",", "format_strs", "=", "[", "]", ")", "\n", "", "model", ",", "env", "=", "train", "(", "args", ",", "extra_args", ")", "\n", "if", "args", ".", "save_path", "is", "not", "None", "and", "rank", "==", "0", ":", "\n", "        ", "save_path", "=", "osp", ".", "expanduser", "(", "args", ".", "save_path", ")", "\n", "\n", "# =========modifiy the save path with time=============", "\n", "# save_path_custom = os.path.join(save_path,time)", "\n", "# =====================================================", "\n", "model", ".", "save", "(", "save_path", ")", "\n", "\n", "", "if", "args", ".", "play", ":", "\n", "        ", "logger", ".", "log", "(", "\"Running trained model\"", ")", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "\n", "state", "=", "model", ".", "initial_state", "if", "hasattr", "(", "model", ",", "'initial_state'", ")", "else", "None", "\n", "dones", "=", "np", ".", "zeros", "(", "(", "1", ",", ")", ")", "\n", "\n", "episode_rew", "=", "0", "\n", "while", "True", ":", "\n", "            ", "if", "state", "is", "not", "None", ":", "\n", "                ", "actions", ",", "_", ",", "state", ",", "_", "=", "model", ".", "step", "(", "obs", ",", "S", "=", "state", ",", "M", "=", "dones", ")", "\n", "", "else", ":", "\n", "                ", "actions", ",", "_", ",", "_", ",", "_", "=", "model", ".", "step", "(", "obs", ")", "\n", "\n", "", "obs", ",", "rew", ",", "done", ",", "_", "=", "env", ".", "step", "(", "actions", ")", "\n", "episode_rew", "+=", "rew", "[", "0", "]", "if", "isinstance", "(", "env", ",", "VecEnv", ")", "else", "rew", "\n", "env", ".", "render", "(", ")", "\n", "done", "=", "done", ".", "any", "(", ")", "if", "isinstance", "(", "done", ",", "np", ".", "ndarray", ")", "else", "done", "\n", "if", "done", ":", "\n", "                ", "print", "(", "'episode_rew={}'", ".", "format", "(", "episode_rew", ")", ")", "\n", "episode_rew", "=", "0", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "\n", "", "", "", "env", ".", "close", "(", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.plot": [[13, 102], ["click.command", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "os.listdir", "os.path.join", "matplotlib.figure", "plt.figure.add_subplot", "numpy.arange", "numpy.arange", "fig.add_subplot.set_xticks", "fig.add_subplot.set_xticks", "fig.add_subplot.grid", "fig.add_subplot.grid", "fig.add_subplot.grid", "os.listdir", "range", "plot_exp_rsym.filter_special_character", "plot_exp_rsym.filter_special_character", "matplotlib.legend", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.suptitle", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "matplotlib.savefig", "matplotlib.show", "len", "os.path.join", "os.listdir", "print", "numpy.mean", "os.path.join", "pandas.read_csv", "all_sub_exps.append", "plot_exp_rsym.np_move_avg", "numpy.std", "numpy.std", "colours.pop", "matplotlib.plot", "matplotlib.fill_between", "matplotlib.plot", "matplotlib.fill_between", "str", "int", "sorted_folder_list.append", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "str", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.filter_special_character", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.filter_special_character", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.np_move_avg", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.plot", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.plot"], ["@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "option", "(", "'--result'", ",", "type", "=", "str", ",", "default", "=", "'test/success_rate'", ",", "help", "=", "'epoch,stats_g/mean,stats_g/std,stats_o/mean,stats_o/std,test/episode,test/mean_Q,test/success_rate,train/episode,train/success_rate'", ")", "\n", "@", "click", ".", "option", "(", "'--log_folder'", ",", "type", "=", "str", ",", "default", "=", "'/home/bourne/log_data/her/'", ",", "help", "=", "'the log_path you use in baselines.run commamd'", ")", "\n", "@", "click", ".", "option", "(", "'--precentile'", ",", "type", "=", "list", ",", "default", "=", "[", "25", ",", "50", ",", "75", "]", ",", "help", "=", "'the precent you want to use to compare'", ")", "\n", "@", "click", ".", "option", "(", "'--n_epoch'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'how many epoch you want to see from 0~n_epoch'", ")", "\n", "@", "click", ".", "option", "(", "'--title'", ",", "type", "=", "str", ",", "default", "=", "'FetchExperiments'", ",", "help", "=", "'tile of the table you plotting'", ")", "\n", "@", "click", ".", "option", "(", "'--random_color'", ",", "type", "=", "str", ",", "default", "=", "False", ",", "help", "=", "' \\'--random_color=True\\' for use random color,  \\'--random_color=False\\' for setup color'", ")", "\n", "@", "click", ".", "option", "(", "'--n_win'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "' \\'--n_win=n\\' using n width window to smooth the data'", ")", "\n", "\n", "def", "plot", "(", "result", ",", "log_folder", ",", "precentile", ",", "n_epoch", ",", "title", ",", "random_color", ",", "n_win", ")", ":", "\n", "\n", "    ", "colours", "=", "[", "'g'", ",", "'black'", ",", "'r'", ",", "'b'", ",", "'gold'", ",", "'c'", ",", "'m'", "]", "\n", "\n", "for", "exp_type_folder", "in", "os", ".", "listdir", "(", "log_folder", ")", ":", "\n", "        ", "exp_type_name", "=", "exp_type_folder", "\n", "exp_type_folder", "=", "os", ".", "path", ".", "join", "(", "log_folder", ",", "exp_type_folder", ")", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "32", ",", "18", ")", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "1", ",", "1", ",", "1", ")", "\n", "\n", "# Major ticks every 20, minor ticks every 5", "\n", "major_ticks", "=", "np", ".", "arange", "(", "0", ",", "n_epoch", ",", "20", ")", "\n", "minor_ticks", "=", "np", ".", "arange", "(", "0", ",", "n_epoch", ",", "5", ")", "\n", "ax", ".", "set_xticks", "(", "major_ticks", ")", "\n", "ax", ".", "set_xticks", "(", "minor_ticks", ",", "minor", "=", "True", ")", "\n", "# And a corresponding grid", "\n", "ax", ".", "grid", "(", "which", "=", "'both'", ")", "\n", "# Or if you want different settings for the grids:", "\n", "ax", ".", "grid", "(", "which", "=", "'minor'", ",", "alpha", "=", "0.2", ")", "\n", "ax", ".", "grid", "(", "which", "=", "'major'", ",", "alpha", "=", "0.5", ")", "\n", "\n", "# Sorting the files in the list: 0,1,2,3..., for plotting the label legends in right orders.", "\n", "sorting_folder_list", "=", "os", ".", "listdir", "(", "exp_type_folder", ")", "\n", "sorted_folder_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sorting_folder_list", ")", ")", ":", "\n", "            ", "for", "sorting_folder", "in", "sorting_folder_list", ":", "\n", "                ", "if", "i", "==", "int", "(", "sorting_folder", "[", "-", "4", ":", "-", "3", "]", ")", ":", "\n", "                    ", "sorted_folder_list", ".", "append", "(", "sorting_folder", ")", "\n", "\n", "", "", "", "for", "sub_exp_type_folder", "in", "sorted_folder_list", ":", "\n", "            ", "sub_exp_tpye_name", "=", "sub_exp_type_folder", "\n", "sub_exp_type_folder", "=", "os", ".", "path", ".", "join", "(", "exp_type_folder", ",", "sub_exp_type_folder", ")", "\n", "num_of_this_type_exps", "=", "0", "\n", "all_sub_exps", "=", "[", "]", "\n", "for", "sub_exp_folder", "in", "os", ".", "listdir", "(", "sub_exp_type_folder", ")", ":", "# fetchpickandplace_2exp", "\n", "                ", "sub_exp_folder", "=", "os", ".", "path", ".", "join", "(", "sub_exp_type_folder", ",", "sub_exp_folder", ")", "\n", "csv", "=", "pd", ".", "read_csv", "(", "sub_exp_folder", "+", "'/progress.csv'", ",", "skipinitialspace", "=", "True", ")", "\n", "exp", "=", "csv", "[", "result", "]", ".", "_values", "\n", "exp", "=", "exp", "[", "0", ":", "n_epoch", "]", "# useful for align, bc some experiments didn't finish all epochs", "\n", "all_sub_exps", ".", "append", "(", "exp", ")", "\n", "num_of_this_type_exps", "+=", "1", "\n", "", "print", "(", "'Exp_Name: '", "+", "sub_exp_tpye_name", "+", "'\\nTotal_sub_experiments={}'", ".", "format", "(", "num_of_this_type_exps", ")", ")", "\n", "\n", "value_mean", "=", "np", ".", "mean", "(", "all_sub_exps", ",", "axis", "=", "0", ")", "\n", "if", "n_win", "!=", "0", ":", "\n", "                ", "smoothed_value_mean", "=", "np_move_avg", "(", "value_mean", ",", "n_win", ")", "\n", "", "value_up", "=", "value_mean", "+", "np", ".", "std", "(", "all_sub_exps", ",", "axis", "=", "0", ")", "\n", "value_down", "=", "value_mean", "-", "np", ".", "std", "(", "all_sub_exps", ",", "axis", "=", "0", ")", "\n", "# value_down, value_media, value_up = np.percentile(all_sub_exps, precentile, axis=0)", "\n", "if", "random_color", ":", "\n", "\n", "                ", "colour", "=", "(", "uniform", "(", "0", ",", "1", ")", ",", "uniform", "(", "0", ",", "1", ")", ",", "uniform", "(", "0", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "colour", "=", "colours", ".", "pop", "(", ")", "\n", "\n", "", "if", "n_win", "==", "0", ":", "\n", "# do not smooth data", "\n", "                ", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "value_mean", ")", ")", ",", "value_mean", ",", "color", "=", "colour", ",", "label", "=", "sub_exp_tpye_name", ",", "linewidth", "=", "4", ")", "\n", "plt", ".", "fill_between", "(", "np", ".", "arange", "(", "len", "(", "value_mean", ")", ")", ",", "value_up", ",", "value_down", ",", "color", "=", "colour", ",", "alpha", "=", "0.2", ")", "\n", "", "else", ":", "\n", "# smooth data", "\n", "                ", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "smoothed_value_mean", ")", ")", ",", "smoothed_value_mean", ",", "color", "=", "colour", ",", "label", "=", "sub_exp_tpye_name", ",", "linewidth", "=", "4", ")", "\n", "plt", ".", "fill_between", "(", "np", ".", "arange", "(", "len", "(", "value_mean", ")", ")", ",", "value_up", ",", "value_down", ",", "color", "=", "colour", ",", "alpha", "=", "0.2", ")", "\n", "\n", "", "", "font1", "=", "{", "\n", "'weight'", ":", "'normal'", ",", "\n", "'size'", ":", "20", ",", "\n", "}", "\n", "\n", "y_matrix", "=", "filter_special_character", "(", "result", ")", "\n", "filtered_exp_type_name", "=", "filter_special_character", "(", "exp_type_name", ")", "\n", "\n", "plt", ".", "legend", "(", "prop", "=", "font1", ",", "loc", "=", "4", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "30", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "30", ")", "\n", "plt", ".", "suptitle", "(", "(", "(", "filtered_exp_type_name", "+", "' smooth_'", "+", "str", "(", "n_win", ")", ")", ")", ",", "fontsize", "=", "30", ")", "\n", "ax", ".", "set_xlabel", "(", "'Epoch'", ",", "fontsize", "=", "30", ")", "\n", "ax", ".", "set_ylabel", "(", "y_matrix", ",", "fontsize", "=", "30", ")", "\n", "plt", ".", "savefig", "(", "filtered_exp_type_name", "+", "' '", "+", "y_matrix", "+", "' smooth_'", "+", "str", "(", "n_win", ")", "+", "'.png'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.np_move_avg": [[103, 114], ["numpy.convolve", "range", "numpy.mean", "numpy.ones", "len", "averaged_data.append", "len"], "function", ["None"], ["", "", "def", "np_move_avg", "(", "input_data", ",", "n_width", ",", "mode", "=", "\"same\"", ")", ":", "\n", "    ", "smoothed_data", "=", "np", ".", "convolve", "(", "input_data", ",", "np", ".", "ones", "(", "(", "n_width", ",", ")", ")", "/", "n_width", ",", "mode", "=", "mode", ")", "\n", "# the last n data will smooth wrongly, so here just to substitude the last n data with original data.", "\n", "start_index", "=", "len", "(", "input_data", ")", "-", "n_width", "-", "1", "\n", "for", "n", "in", "range", "(", "n_width", ")", ":", "\n", "        ", "averaged_data", "=", "[", "]", "\n", "substituded_index", "=", "(", "len", "(", "input_data", ")", "-", "n", "-", "1", ")", "\n", "for", "data", "in", "input_data", "[", "start_index", ":", "substituded_index", "]", ":", "\n", "            ", "averaged_data", ".", "append", "(", "data", ")", "\n", "", "smoothed_data", "[", "substituded_index", "]", "=", "np", ".", "mean", "(", "averaged_data", ")", "\n", "", "return", "smoothed_data", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.result_plot_method.plot_exp_rsym.filter_special_character": [[115, 119], ["eval", "eval", "repr().replace", "repr().replace", "repr", "repr"], "function", ["None"], ["", "def", "filter_special_character", "(", "str_name", ")", ":", "\n", "    ", "str_name", "=", "eval", "(", "(", "repr", "(", "str_name", ")", ".", "replace", "(", "'/'", ",", "' '", ")", ")", ")", "\n", "str_name", "=", "eval", "(", "(", "repr", "(", "str_name", ")", ".", "replace", "(", "'_'", ",", "' '", ")", ")", ")", "\n", "return", "str_name", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.visualized_plot_ker_traj.plot_ker_traj.sorting_dir": [[9, 17], ["os.listdir", "range", "len", "int", "sorted_folder_list.append"], "function", ["None"], ["def", "sorting_dir", "(", "load_data_folder", ")", ":", "\n", "    ", "sorting_folder_list", "=", "os", ".", "listdir", "(", "load_data_folder", ")", "\n", "sorted_folder_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sorting_folder_list", ")", "+", "1", ")", ":", "\n", "        ", "for", "sorting_folder", "in", "sorting_folder_list", ":", "\n", "            ", "if", "i", "==", "int", "(", "sorting_folder", "[", "-", "5", ":", "-", "4", "]", ")", ":", "\n", "                ", "sorted_folder_list", ".", "append", "(", "sorting_folder", ")", "\n", "", "", "", "return", "sorted_folder_list", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.visualized_plot_ker_traj.plot_ker_traj.get_cube": [[22, 30], ["numpy.meshgrid", "numpy.cos", "numpy.sin", "numpy.sin", "numpy.sin", "numpy.cos", "numpy.sqrt", "numpy.arange"], "function", ["None"], ["def", "get_cube", "(", "cube_x", ",", "cube_y", ",", "cube_z", ")", ":", "\n", "    ", "phi", "=", "np", ".", "arange", "(", "1", ",", "10", ",", "2", ")", "*", "np", ".", "pi", "/", "4", "\n", "Phi", ",", "Theta", "=", "np", ".", "meshgrid", "(", "phi", ",", "phi", ")", "\n", "\n", "cube_x", "=", "np", ".", "cos", "(", "Phi", ")", "*", "np", ".", "sin", "(", "Theta", ")", "\n", "cube_y", "=", "np", ".", "sin", "(", "Phi", ")", "*", "np", ".", "sin", "(", "Theta", ")", "\n", "cube_z", "=", "np", ".", "cos", "(", "Theta", ")", "/", "np", ".", "sqrt", "(", "2", ")", "\n", "return", "cube_x", ",", "cube_y", ",", "cube_z", "\n", "", "x_length", "=", "0.5", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.__init__": [[12, 47], ["collections.deque", "collections.deque", "rollout.RolloutWorker.reset_all_rollouts", "rollout.RolloutWorker.clear_history", "baselines.her.mirror_learning_method.mirror_learning", "key.replace", "dims.keys", "key.startswith"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.clear_history"], ["    ", "@", "store_args", "\n", "def", "__init__", "(", "self", ",", "env_name", ",", "venv", ",", "policy", ",", "dims", ",", "logger", ",", "T", ",", "rollout_batch_size", "=", "1", ",", "\n", "exploit", "=", "False", ",", "use_target_net", "=", "False", ",", "compute_Q", "=", "False", ",", "noise_eps", "=", "0", ",", "\n", "random_eps", "=", "0", ",", "history_len", "=", "100", ",", "render", "=", "False", ",", "monitor", "=", "False", ",", "n_rsym", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Rollout worker generates experience by interacting with one or many environments.\n\n        Args:\n            make_env (function): a factory function that creates a new instance of the environment\n                when called\n            policy (object): the policy that is used to act\n            dims (dict of ints): the dimensions for observations (o), goals (g), and actions (u)\n            logger (object): the logger that is used by the rollout worker\n            rollout_batch_size (int): the number of parallel rollouts that should be used\n            exploit (boolean): whether or not to exploit, i.e. to act optimally according to the\n                current policy without any exploration\n            use_target_net (boolean): whether or not to use the target net for rollouts\n            compute_Q (boolean): whether or not to compute the Q values alongside the actions\n            noise_eps (float): scale of the additive Gaussian noise\n            random_eps (float): probability of selecting a completely random action\n            history_len (int): length of history for statistics smoothing\n            render (boolean): whether or not to render the rollouts\n        \"\"\"", "\n", "\n", "assert", "self", ".", "T", ">", "0", "\n", "\n", "self", ".", "info_keys", "=", "[", "key", ".", "replace", "(", "'info_'", ",", "''", ")", "for", "key", "in", "dims", ".", "keys", "(", ")", "if", "key", ".", "startswith", "(", "'info_'", ")", "]", "\n", "\n", "self", ".", "success_history", "=", "deque", "(", "maxlen", "=", "history_len", ")", "\n", "self", ".", "Q_history", "=", "deque", "(", "maxlen", "=", "history_len", ")", "\n", "\n", "self", ".", "n_episodes", "=", "0", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "self", ".", "clear_history", "(", ")", "\n", "self", ".", "n_rsym", "=", "n_rsym", "\n", "self", ".", "mirror", "=", "mirror_learning", "(", "env_name", ",", "n_rsym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.reset_all_rollouts": [[48, 53], ["rollout.RolloutWorker.venv.reset"], "methods", ["None"], ["", "def", "reset_all_rollouts", "(", "self", ")", ":", "\n", "        ", "self", ".", "obs_dict", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "initial_o", "=", "self", ".", "obs_dict", "[", "'observation'", "]", "\n", "self", ".", "initial_ag", "=", "self", ".", "obs_dict", "[", "'achieved_goal'", "]", "\n", "self", ".", "g", "=", "self", ".", "obs_dict", "[", "'desired_goal'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts": [[54, 59], ["rollout.RolloutWorker.generate_rollouts_ker", "rollout.RolloutWorker.generate_rollouts_vanilla"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts_ker", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts_vanilla"], ["", "def", "generate_rollouts", "(", "self", ",", "terminate_ker", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "n_rsym", "and", "terminate_ker", "==", "False", ":", "\n", "            ", "return", "self", ".", "generate_rollouts_ker", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "generate_rollouts_vanilla", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts_vanilla": [[60, 146], ["rollout.RolloutWorker.reset_all_rollouts", "numpy.empty", "numpy.empty", "range", "obs.append", "achieved_goals.append", "dict", "zip", "numpy.mean", "rollout.RolloutWorker.success_history.append", "baselines.her.util.convert_episode_to_batch_major", "numpy.empty", "rollout.RolloutWorker.policy.get_actions", "numpy.empty", "numpy.empty", "numpy.zeros", "rollout.RolloutWorker.venv.step", "numpy.array", "any", "enumerate", "numpy.isnan().any", "dones.append", "obs.append", "achieved_goals.append", "successes.append", "acts.append", "goals.append", "numpy.empty.copy", "numpy.empty.copy", "numpy.array", "rollout.RolloutWorker.Q_history.append", "Qs.append", "u.reshape.reshape.reshape", "enumerate", "rollout.RolloutWorker.logger.warn", "rollout.RolloutWorker.reset_all_rollouts", "rollout.RolloutWorker.generate_rollouts", "numpy.empty.copy", "numpy.empty.copy", "numpy.array.copy", "u.reshape.reshape.copy", "rollout.RolloutWorker.g.copy", "numpy.mean", "i.get", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.get_actions", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.step", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts"], ["", "", "def", "generate_rollouts_vanilla", "(", "self", ")", ":", "\n", "        ", "\"\"\"Performs `rollout_batch_size` rollouts in parallel for time horizon `T` with the current\n        policy acting on it accordingly.\n        \"\"\"", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "# compute observations", "\n", "o", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'o'", "]", ")", ",", "np", ".", "float32", ")", "# observations", "\n", "ag", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'g'", "]", ")", ",", "np", ".", "float32", ")", "# achieved goals", "\n", "o", "[", ":", "]", "=", "self", ".", "initial_o", "\n", "ag", "[", ":", "]", "=", "self", ".", "initial_ag", "\n", "\n", "# generate episodes", "\n", "obs", ",", "achieved_goals", ",", "acts", ",", "goals", ",", "successes", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "dones", "=", "[", "]", "\n", "info_values", "=", "[", "np", ".", "empty", "(", "(", "self", ".", "T", "-", "1", ",", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'info_'", "+", "key", "]", ")", ",", "np", ".", "float32", ")", "for", "key", "in", "self", ".", "info_keys", "]", "\n", "Qs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "T", ")", ":", "\n", "            ", "policy_output", "=", "self", ".", "policy", ".", "get_actions", "(", "\n", "o", ",", "ag", ",", "self", ".", "g", ",", "\n", "compute_Q", "=", "self", ".", "compute_Q", ",", "\n", "noise_eps", "=", "self", ".", "noise_eps", "if", "not", "self", ".", "exploit", "else", "0.", ",", "\n", "random_eps", "=", "self", ".", "random_eps", "if", "not", "self", ".", "exploit", "else", "0.", ",", "\n", "use_target_net", "=", "self", ".", "use_target_net", ")", "\n", "\n", "if", "self", ".", "compute_Q", ":", "\n", "                ", "u", ",", "Q", "=", "policy_output", "\n", "Qs", ".", "append", "(", "Q", ")", "\n", "", "else", ":", "\n", "                ", "u", "=", "policy_output", "\n", "\n", "", "if", "u", ".", "ndim", "==", "1", ":", "\n", "# The non-batched case should still have a reasonable shape.", "\n", "                ", "u", "=", "u", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "", "o_new", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'o'", "]", ")", ")", "\n", "ag_new", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'g'", "]", ")", ")", "\n", "success", "=", "np", ".", "zeros", "(", "self", ".", "rollout_batch_size", ")", "\n", "# compute new states and observations", "\n", "obs_dict_new", ",", "_", ",", "done", ",", "info", "=", "self", ".", "venv", ".", "step", "(", "u", ")", "\n", "o_new", "=", "obs_dict_new", "[", "'observation'", "]", "\n", "ag_new", "=", "obs_dict_new", "[", "'achieved_goal'", "]", "\n", "success", "=", "np", ".", "array", "(", "[", "i", ".", "get", "(", "'is_success'", ",", "0.0", ")", "for", "i", "in", "info", "]", ")", "\n", "\n", "if", "any", "(", "done", ")", ":", "\n", "# here we assume all environments are done is ~same number of steps, so we terminate rollouts whenever any of the envs returns done", "\n", "# trick with using vecenvs is not to add the obs from the environments that are \"done\", because those are already observations", "\n", "# after a reset", "\n", "                ", "break", "\n", "\n", "", "for", "i", ",", "info_dict", "in", "enumerate", "(", "info", ")", ":", "\n", "                ", "for", "idx", ",", "key", "in", "enumerate", "(", "self", ".", "info_keys", ")", ":", "\n", "                    ", "info_values", "[", "idx", "]", "[", "t", ",", "i", "]", "=", "info", "[", "i", "]", "[", "key", "]", "\n", "\n", "", "", "if", "np", ".", "isnan", "(", "o_new", ")", ".", "any", "(", ")", ":", "\n", "                ", "self", ".", "logger", ".", "warn", "(", "'NaN caught during rollout generation. Trying again...'", ")", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "return", "self", ".", "generate_rollouts", "(", ")", "\n", "\n", "", "dones", ".", "append", "(", "done", ")", "\n", "obs", ".", "append", "(", "o", ".", "copy", "(", ")", ")", "\n", "achieved_goals", ".", "append", "(", "ag", ".", "copy", "(", ")", ")", "\n", "successes", ".", "append", "(", "success", ".", "copy", "(", ")", ")", "\n", "acts", ".", "append", "(", "u", ".", "copy", "(", ")", ")", "\n", "goals", ".", "append", "(", "self", ".", "g", ".", "copy", "(", ")", ")", "\n", "o", "[", "...", "]", "=", "o_new", "\n", "ag", "[", "...", "]", "=", "ag_new", "\n", "", "obs", ".", "append", "(", "o", ".", "copy", "(", ")", ")", "\n", "achieved_goals", ".", "append", "(", "ag", ".", "copy", "(", ")", ")", "\n", "\n", "episode", "=", "dict", "(", "o", "=", "obs", ",", "\n", "u", "=", "acts", ",", "\n", "g", "=", "goals", ",", "\n", "ag", "=", "achieved_goals", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "self", ".", "info_keys", ",", "info_values", ")", ":", "\n", "            ", "episode", "[", "'info_{}'", ".", "format", "(", "key", ")", "]", "=", "value", "\n", "\n", "# stats", "\n", "", "successful", "=", "np", ".", "array", "(", "successes", ")", "[", "-", "1", ",", ":", "]", "\n", "assert", "successful", ".", "shape", "==", "(", "self", ".", "rollout_batch_size", ",", ")", "\n", "success_rate", "=", "np", ".", "mean", "(", "successful", ")", "\n", "self", ".", "success_history", ".", "append", "(", "success_rate", ")", "\n", "if", "self", ".", "compute_Q", ":", "\n", "            ", "self", ".", "Q_history", ".", "append", "(", "np", ".", "mean", "(", "Qs", ")", ")", "\n", "", "self", ".", "n_episodes", "+=", "self", ".", "rollout_batch_size", "\n", "\n", "return", "convert_episode_to_batch_major", "(", "episode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts_ker": [[147, 258], ["rollout.RolloutWorker.reset_all_rollouts", "numpy.empty", "numpy.empty", "range", "obs.append", "achieved_goals.append", "rollout.RolloutWorker.mirror.mirror_process", "numpy.mean", "rollout.RolloutWorker.success_history.append", "numpy.empty", "rollout.RolloutWorker.policy.get_actions", "numpy.empty", "numpy.empty", "numpy.zeros", "rollout.RolloutWorker.venv.step", "numpy.array", "any", "enumerate", "numpy.isnan().any", "dones.append", "obs.append", "achieved_goals.append", "successes.append", "acts.append", "goals.append", "numpy.empty.copy", "numpy.empty.copy", "dict", "zip", "episodes.append", "numpy.array", "rollout.RolloutWorker.Q_history.append", "baselines.her.util.convert_episode_to_batch_major", "episodes_batch.append", "Qs.append", "u.reshape.reshape.reshape", "enumerate", "rollout.RolloutWorker.logger.warn", "rollout.RolloutWorker.reset_all_rollouts", "rollout.RolloutWorker.generate_rollouts", "numpy.empty.copy", "numpy.empty.copy", "numpy.array.copy", "u.reshape.reshape.copy", "rollout.RolloutWorker.g.copy", "numpy.mean", "i.get", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.mirror_process", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.get_actions", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.step", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts"], ["", "def", "generate_rollouts_ker", "(", "self", ")", ":", "\n", "        ", "\"\"\"Performs `rollout_batch_size` rollouts in parallel for time horizon `T` with the current\n        policy acting on it accordingly.\n        \"\"\"", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "\n", "episodes", "=", "[", "]", "\n", "episodes_batch", "=", "[", "]", "\n", "\n", "# compute observations", "\n", "o", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'o'", "]", ")", ",", "np", ".", "float32", ")", "# observations", "\n", "ag", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'g'", "]", ")", ",", "np", ".", "float32", ")", "# achieved goals", "\n", "o", "[", ":", "]", "=", "self", ".", "initial_o", "\n", "ag", "[", ":", "]", "=", "self", ".", "initial_ag", "\n", "\n", "# generate episodes", "\n", "obs", ",", "achieved_goals", ",", "acts", ",", "goals", ",", "successes", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "dones", "=", "[", "]", "\n", "info_values", "=", "[", "np", ".", "empty", "(", "(", "self", ".", "T", "-", "1", ",", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'info_'", "+", "key", "]", ")", ",", "np", ".", "float32", ")", "for", "key", "in", "self", ".", "info_keys", "]", "\n", "Qs", "=", "[", "]", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "T", ")", ":", "\n", "            ", "policy_output", "=", "self", ".", "policy", ".", "get_actions", "(", "\n", "o", ",", "ag", ",", "self", ".", "g", ",", "\n", "compute_Q", "=", "self", ".", "compute_Q", ",", "\n", "noise_eps", "=", "self", ".", "noise_eps", "if", "not", "self", ".", "exploit", "else", "0.", ",", "\n", "random_eps", "=", "self", ".", "random_eps", "if", "not", "self", ".", "exploit", "else", "0.", ",", "\n", "use_target_net", "=", "self", ".", "use_target_net", ")", "\n", "\n", "if", "self", ".", "compute_Q", ":", "\n", "                ", "u", ",", "Q", "=", "policy_output", "\n", "Qs", ".", "append", "(", "Q", ")", "\n", "", "else", ":", "\n", "                ", "u", "=", "policy_output", "\n", "\n", "", "if", "u", ".", "ndim", "==", "1", ":", "\n", "# The non-batched case should still have a reasonable shape.", "\n", "                ", "u", "=", "u", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "", "o_new", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'o'", "]", ")", ")", "\n", "ag_new", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'g'", "]", ")", ")", "\n", "success", "=", "np", ".", "zeros", "(", "self", ".", "rollout_batch_size", ")", "\n", "# compute new states and observations, do not return the reward, and get it from her_sampler.py", "\n", "obs_dict_new", ",", "_", ",", "done", ",", "info", "=", "self", ".", "venv", ".", "step", "(", "u", ")", "\n", "o_new", "=", "obs_dict_new", "[", "'observation'", "]", "\n", "ag_new", "=", "obs_dict_new", "[", "'achieved_goal'", "]", "\n", "success", "=", "np", ".", "array", "(", "[", "i", ".", "get", "(", "'is_success'", ",", "0.0", ")", "for", "i", "in", "info", "]", ")", "\n", "\n", "# no need", "\n", "if", "any", "(", "done", ")", ":", "\n", "# here we assume all environments are done is ~same number of steps, so we terminate rollouts whenever any of the envs returns done", "\n", "# trick with using vecenvs is not to add the obs from the environments that are \"done\", because those are already observations", "\n", "# after a reset", "\n", "                ", "break", "\n", "# no need", "\n", "", "for", "i", ",", "info_dict", "in", "enumerate", "(", "info", ")", ":", "\n", "                ", "for", "idx", ",", "key", "in", "enumerate", "(", "self", ".", "info_keys", ")", ":", "\n", "                    ", "info_values", "[", "idx", "]", "[", "t", ",", "i", "]", "=", "info", "[", "i", "]", "[", "key", "]", "\n", "# no need", "\n", "", "", "if", "np", ".", "isnan", "(", "o_new", ")", ".", "any", "(", ")", ":", "\n", "                ", "self", ".", "logger", ".", "warn", "(", "'NaN caught during rollout generation. Trying again...'", ")", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "return", "self", ".", "generate_rollouts", "(", ")", "\n", "\n", "", "dones", ".", "append", "(", "done", ")", "\n", "obs", ".", "append", "(", "o", ".", "copy", "(", ")", ")", "\n", "achieved_goals", ".", "append", "(", "ag", ".", "copy", "(", ")", ")", "\n", "successes", ".", "append", "(", "success", ".", "copy", "(", ")", ")", "\n", "acts", ".", "append", "(", "u", ".", "copy", "(", ")", ")", "\n", "goals", ".", "append", "(", "self", ".", "g", ".", "copy", "(", ")", ")", "\n", "\n", "o", "[", "...", "]", "=", "o_new", "\n", "ag", "[", "...", "]", "=", "ag_new", "\n", "\n", "", "obs", ".", "append", "(", "o", ".", "copy", "(", ")", ")", "\n", "achieved_goals", ".", "append", "(", "ag", ".", "copy", "(", ")", ")", "\n", "\n", "# ----------------Mirror Augmentation--------------------------- ", "\n", "original_ka_episodes", "=", "self", ".", "mirror", ".", "mirror_process", "(", "obs", ",", "acts", ",", "goals", ",", "achieved_goals", ")", "\n", "# ----------------end---------------------------", "\n", "\n", "# ----------------pack up as transition--------------------------- ", "\n", "for", "(", "obs", ",", "acts", ",", "goals", ",", "achieved_goals", ")", "in", "original_ka_episodes", ":", "\n", "            ", "episode", "=", "dict", "(", "o", "=", "obs", ",", "\n", "u", "=", "acts", ",", "\n", "g", "=", "goals", ",", "\n", "ag", "=", "achieved_goals", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "self", ".", "info_keys", ",", "info_values", ")", ":", "\n", "                ", "episode", "[", "'info_{}'", ".", "format", "(", "key", ")", "]", "=", "value", "\n", "", "episodes", ".", "append", "(", "episode", ")", "\n", "# ----------------end---------------------------", "\n", "\n", "# stats", "\n", "", "successful", "=", "np", ".", "array", "(", "successes", ")", "[", "-", "1", ",", ":", "]", "\n", "assert", "successful", ".", "shape", "==", "(", "self", ".", "rollout_batch_size", ",", ")", "\n", "success_rate", "=", "np", ".", "mean", "(", "successful", ")", "\n", "self", ".", "success_history", ".", "append", "(", "success_rate", ")", "\n", "if", "self", ".", "compute_Q", ":", "\n", "            ", "self", ".", "Q_history", ".", "append", "(", "np", ".", "mean", "(", "Qs", ")", ")", "\n", "\n", "", "mul_factor", "=", "1", "\n", "self", ".", "n_episodes", "+=", "(", "mul_factor", "*", "self", ".", "rollout_batch_size", ")", "\n", "\n", "# ----------------format processing---------------------------", "\n", "# return dict: ['o', 'u', 'g', 'ag', 'info_is_success']", "\n", "for", "episode", "in", "episodes", ":", "\n", "            ", "episode_batch", "=", "convert_episode_to_batch_major", "(", "episode", ")", "\n", "episodes_batch", ".", "append", "(", "episode_batch", ")", "\n", "# ----------------end---------------------------", "\n", "\n", "", "return", "episodes_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.mirror_learning_type": [[259, 261], ["None"], "methods", ["None"], ["", "def", "mirror_learning_type", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.clear_history": [[263, 268], ["rollout.RolloutWorker.success_history.clear", "rollout.RolloutWorker.Q_history.clear"], "methods", ["None"], ["", "def", "clear_history", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears all histories that are used for statistics\n        \"\"\"", "\n", "self", ".", "success_history", ".", "clear", "(", ")", "\n", "self", ".", "Q_history", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.current_success_rate": [[269, 271], ["numpy.mean"], "methods", ["None"], ["", "def", "current_success_rate", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "success_history", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.current_mean_Q": [[272, 274], ["numpy.mean"], "methods", ["None"], ["", "def", "current_mean_Q", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "Q_history", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.save_policy": [[275, 280], ["open", "pickle.dump"], "methods", ["None"], ["", "def", "save_policy", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Pickles the current policy for later inspection.\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "policy", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.logs": [[281, 294], ["numpy.mean", "prefix.endswith", "numpy.mean"], "methods", ["None"], ["", "", "def", "logs", "(", "self", ",", "prefix", "=", "'worker'", ")", ":", "\n", "        ", "\"\"\"Generates a dictionary that contains all collected statistics.\n        \"\"\"", "\n", "logs", "=", "[", "]", "\n", "logs", "+=", "[", "(", "'success_rate'", ",", "np", ".", "mean", "(", "self", ".", "success_history", ")", ")", "]", "\n", "if", "self", ".", "compute_Q", ":", "\n", "            ", "logs", "+=", "[", "(", "'mean_Q'", ",", "np", ".", "mean", "(", "self", ".", "Q_history", ")", ")", "]", "\n", "", "logs", "+=", "[", "(", "'episode'", ",", "self", ".", "n_episodes", ")", "]", "\n", "\n", "if", "prefix", "!=", "''", "and", "not", "prefix", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "return", "[", "(", "prefix", "+", "'/'", "+", "key", ",", "val", ")", "for", "key", ",", "val", "in", "logs", "]", "\n", "", "else", ":", "\n", "            ", "return", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.__init__": [[7, 31], ["threading.Lock", "numpy.empty", "buffer_shapes.items"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "buffer_shapes", ",", "size_in_transitions", ",", "T", ",", "sample_transitions", ")", ":", "\n", "        ", "\"\"\"Creates a replay buffer.\n\n        Args:\n            buffer_shapes (dict of ints): the shape for all buffers that are used in the replay\n                buffer\n            size_in_transitions (int): the size of the buffer, measured in transitions\n            T (int): the time horizon for episodes\n            sample_transitions (function): a function that samples from the replay buffer\n        \"\"\"", "\n", "self", ".", "buffer_shapes", "=", "buffer_shapes", "\n", "self", ".", "size", "=", "size_in_transitions", "//", "T", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "sample_transitions", "=", "sample_transitions", "\n", "\n", "# self.buffers is {key: array(size_in_episodes x T or T+1 x dim_key)}", "\n", "self", ".", "buffers", "=", "{", "key", ":", "np", ".", "empty", "(", "[", "self", ".", "size", ",", "*", "shape", "]", ")", "\n", "for", "key", ",", "shape", "in", "buffer_shapes", ".", "items", "(", ")", "}", "\n", "\n", "# memory management", "\n", "self", ".", "current_size", "=", "0", "\n", "self", ".", "n_transitions_stored", "=", "0", "\n", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.full": [[32, 36], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "full", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "==", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.sample": [[37, 56], ["replay_buffer.ReplayBuffer.sample_transitions", "replay_buffer.ReplayBuffer.buffers.keys", "list", "replay_buffer.ReplayBuffer.buffers.keys"], "methods", ["None"], ["", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Returns a dict {key: array(batch_size x shapes[key])}\n        \"\"\"", "\n", "buffers", "=", "{", "}", "\n", "\n", "with", "self", ".", "lock", ":", "\n", "            ", "assert", "self", ".", "current_size", ">", "0", "\n", "for", "key", "in", "self", ".", "buffers", ".", "keys", "(", ")", ":", "\n", "                ", "buffers", "[", "key", "]", "=", "self", ".", "buffers", "[", "key", "]", "[", ":", "self", ".", "current_size", "]", "\n", "\n", "", "", "buffers", "[", "'o_2'", "]", "=", "buffers", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "buffers", "[", "'ag_2'", "]", "=", "buffers", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "buffers", ",", "batch_size", ")", "\n", "\n", "for", "key", "in", "(", "[", "'r'", ",", "'o_2'", ",", "'ag_2'", "]", "+", "list", "(", "self", ".", "buffers", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "assert", "key", "in", "transitions", ",", "\"key %s missing from transitions\"", "%", "key", "\n", "\n", "", "return", "transitions", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.store_episode": [[57, 72], ["numpy.all", "len", "replay_buffer.ReplayBuffer._get_storage_idx", "replay_buffer.ReplayBuffer.buffers.keys", "episode_batch.keys", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer._get_storage_idx"], ["", "def", "store_episode", "(", "self", ",", "episode_batch", ")", ":", "\n", "        ", "\"\"\"episode_batch: array(batch_size x (T or T+1) x dim_key)\n        \"\"\"", "\n", "batch_sizes", "=", "[", "len", "(", "episode_batch", "[", "key", "]", ")", "for", "key", "in", "episode_batch", ".", "keys", "(", ")", "]", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "batch_sizes", ")", "==", "batch_sizes", "[", "0", "]", ")", "\n", "batch_size", "=", "batch_sizes", "[", "0", "]", "\n", "\n", "with", "self", ".", "lock", ":", "\n", "            ", "idxs", "=", "self", ".", "_get_storage_idx", "(", "batch_size", ")", "\n", "\n", "# load inputs into buffers", "\n", "for", "key", "in", "self", ".", "buffers", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "buffers", "[", "key", "]", "[", "idxs", "]", "=", "episode_batch", "[", "key", "]", "\n", "\n", "", "self", ".", "n_transitions_stored", "+=", "batch_size", "*", "self", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.get_current_episode_size": [[73, 76], ["None"], "methods", ["None"], ["", "", "def", "get_current_episode_size", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.get_current_size": [[77, 80], ["None"], "methods", ["None"], ["", "", "def", "get_current_size", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "*", "self", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.get_transitions_stored": [[81, 84], ["None"], "methods", ["None"], ["", "", "def", "get_transitions_stored", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "n_transitions_stored", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.clear_buffer": [[85, 91], ["numpy.empty", "replay_buffer.ReplayBuffer.buffer_shapes.items"], "methods", ["None"], ["", "", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "self", ".", "current_size", "=", "0", "\n", "self", ".", "n_transitions_stored", "=", "0", "\n", "self", ".", "buffers", "=", "{", "key", ":", "np", ".", "empty", "(", "[", "self", ".", "size", ",", "*", "shape", "]", ")", "\n", "for", "key", ",", "shape", "in", "self", ".", "buffer_shapes", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer._get_storage_idx": [[92, 112], ["min", "numpy.arange", "numpy.arange", "numpy.random.randint", "numpy.concatenate", "numpy.random.randint"], "methods", ["None"], ["", "", "def", "_get_storage_idx", "(", "self", ",", "inc", "=", "None", ")", ":", "\n", "        ", "inc", "=", "inc", "or", "1", "# size increment", "\n", "assert", "inc", "<=", "self", ".", "size", ",", "\"Batch committed to replay is too large!\"", "\n", "# go consecutively until you hit the end, and then go randomly.", "\n", "if", "self", ".", "current_size", "+", "inc", "<=", "self", ".", "size", ":", "\n", "            ", "idx", "=", "np", ".", "arange", "(", "self", ".", "current_size", ",", "self", ".", "current_size", "+", "inc", ")", "\n", "", "elif", "self", ".", "current_size", "<", "self", ".", "size", ":", "\n", "            ", "overflow", "=", "inc", "-", "(", "self", ".", "size", "-", "self", ".", "current_size", ")", "\n", "idx_a", "=", "np", ".", "arange", "(", "self", ".", "current_size", ",", "self", ".", "size", ")", "\n", "idx_b", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "current_size", ",", "overflow", ")", "\n", "idx", "=", "np", ".", "concatenate", "(", "[", "idx_a", ",", "idx_b", "]", ")", "\n", "", "else", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "size", ",", "inc", ")", "\n", "\n", "# update replay size", "\n", "", "self", ".", "current_size", "=", "min", "(", "self", ".", "size", ",", "self", ".", "current_size", "+", "inc", ")", "\n", "\n", "if", "inc", "==", "1", ":", "\n", "            ", "idx", "=", "idx", "[", "0", "]", "\n", "", "return", "idx", "\n", "", "", ""]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.__init__": [[23, 108], ["baselines.her.util.import_function", "ddpg.dims_to_shapes", "collections.OrderedDict", "sorted", "baselines.her.replay_buffer.ReplayBuffer", "baselines.her.replay_buffer.ReplayBuffer", "ddpg.DDPG.input_dims.keys", "key.startswith", "tensorflow.variable_scope", "tensorflow.contrib.staging.StagingArea", "ddpg.DDPG.staging_tf.put", "ddpg.DDPG._create_network", "tensorflow.placeholder", "dims_to_shapes.items", "list", "ddpg.DDPG.stage_shapes.values", "ddpg.DDPG.stage_shapes.values", "ddpg.DDPG.stage_shapes.keys"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.dims_to_shapes", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._create_network"], ["    ", "@", "store_args", "\n", "def", "__init__", "(", "self", ",", "input_dims", ",", "buffer_size", ",", "hidden", ",", "layers", ",", "network_class", ",", "polyak", ",", "batch_size", ",", "\n", "Q_lr", ",", "pi_lr", ",", "norm_eps", ",", "norm_clip", ",", "max_u", ",", "action_l2", ",", "clip_obs", ",", "scope", ",", "T", ",", "\n", "rollout_batch_size", ",", "subtract_goals", ",", "relative_goals", ",", "clip_pos_returns", ",", "clip_return", ",", "\n", "bc_loss", ",", "q_filter", ",", "num_demo", ",", "demo_batch_size", ",", "prm_loss_weight", ",", "aux_loss_weight", ",", "\n", "sample_transitions", ",", "gamma", ",", "reuse", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Implementation of DDPG that is used in combination with Hindsight Experience Replay (HER).\n            Added functionality to use demonstrations for training to Overcome exploration problem.\n\n        Args:\n            input_dims (dict of ints): dimensions for the observation (o), the goal (g), and the\n                actions (u)\n            buffer_size (int): number of transitions that are stored in the replay buffer\n            hidden (int): number of units in the hidden layers\n            layers (int): number of hidden layers\n            network_class (str): the network class that should be used (e.g. 'baselines.her.ActorCritic')\n            polyak (float): coefficient for Polyak-averaging of the target network\n            batch_size (int): batch size for training\n            Q_lr (float): learning rate for the Q (critic) network\n            pi_lr (float): learning rate for the pi (actor) network\n            norm_eps (float): a small value used in the normalizer to avoid numerical instabilities\n            norm_clip (float): normalized inputs are clipped to be in [-norm_clip, norm_clip]\n            max_u (float): maximum action magnitude, i.e. actions are in [-max_u, max_u]\n            action_l2 (float): coefficient for L2 penalty on the actions\n            clip_obs (float): clip observations before normalization to be in [-clip_obs, clip_obs]\n            scope (str): the scope used for the TensorFlow graph\n            T (int): the time horizon for rollouts\n            rollout_batch_size (int): number of parallel rollouts per DDPG agent\n            subtract_goals (function): function that subtracts goals from each other\n            relative_goals (boolean): whether or not relative goals should be fed into the network\n            clip_pos_returns (boolean): whether or not positive returns should be clipped\n            clip_return (float): clip returns to be in [-clip_return, clip_return]\n            sample_transitions (function) function that samples from the replay buffer\n            gamma (float): gamma used for Q learning updates\n            reuse (boolean): whether or not the networks should be reused\n            bc_loss: whether or not the behavior cloning loss should be used as an auxilliary loss\n            q_filter: whether or not a filter on the q value update should be used when training with demonstartions\n            num_demo: Number of episodes in to be used in the demonstration buffer\n            demo_batch_size: number of samples to be used from the demonstrations buffer, per mpi thread\n            prm_loss_weight: Weight corresponding to the primary loss\n            aux_loss_weight: Weight corresponding to the auxilliary loss also called the cloning loss\n        \"\"\"", "\n", "if", "self", ".", "clip_return", "is", "None", ":", "\n", "            ", "self", ".", "clip_return", "=", "np", ".", "inf", "\n", "\n", "", "self", ".", "create_actor_critic", "=", "import_function", "(", "self", ".", "network_class", ")", "\n", "\n", "input_shapes", "=", "dims_to_shapes", "(", "self", ".", "input_dims", ")", "\n", "self", ".", "dimo", "=", "self", ".", "input_dims", "[", "'o'", "]", "\n", "self", ".", "dimg", "=", "self", ".", "input_dims", "[", "'g'", "]", "\n", "self", ".", "dimu", "=", "self", ".", "input_dims", "[", "'u'", "]", "\n", "\n", "# Prepare staging area for feeding data to the model.", "\n", "stage_shapes", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "sorted", "(", "self", ".", "input_dims", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "'info_'", ")", ":", "\n", "                ", "continue", "\n", "", "stage_shapes", "[", "key", "]", "=", "(", "None", ",", "*", "input_shapes", "[", "key", "]", ")", "\n", "", "for", "key", "in", "[", "'o'", ",", "'g'", "]", ":", "\n", "            ", "stage_shapes", "[", "key", "+", "'_2'", "]", "=", "stage_shapes", "[", "key", "]", "\n", "", "stage_shapes", "[", "'r'", "]", "=", "(", "None", ",", ")", "\n", "self", ".", "stage_shapes", "=", "stage_shapes", "\n", "\n", "# Create network.", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "self", ".", "staging_tf", "=", "StagingArea", "(", "\n", "dtypes", "=", "[", "tf", ".", "float32", "for", "_", "in", "self", ".", "stage_shapes", ".", "keys", "(", ")", "]", ",", "\n", "shapes", "=", "list", "(", "self", ".", "stage_shapes", ".", "values", "(", ")", ")", ")", "\n", "self", ".", "buffer_ph_tf", "=", "[", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "shape", ")", "for", "shape", "in", "self", ".", "stage_shapes", ".", "values", "(", ")", "]", "\n", "self", ".", "stage_op", "=", "self", ".", "staging_tf", ".", "put", "(", "self", ".", "buffer_ph_tf", ")", "\n", "\n", "self", ".", "_create_network", "(", "reuse", "=", "reuse", ")", "\n", "\n", "# Configure the replay buffer.", "\n", "", "buffer_shapes", "=", "{", "key", ":", "(", "self", ".", "T", "-", "1", "if", "key", "!=", "'o'", "else", "self", ".", "T", ",", "*", "input_shapes", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "input_shapes", ".", "items", "(", ")", "}", "\n", "buffer_shapes", "[", "'g'", "]", "=", "(", "buffer_shapes", "[", "'g'", "]", "[", "0", "]", ",", "self", ".", "dimg", ")", "\n", "buffer_shapes", "[", "'ag'", "]", "=", "(", "self", ".", "T", ",", "self", ".", "dimg", ")", "\n", "\n", "buffer_size", "=", "(", "self", ".", "buffer_size", "//", "self", ".", "rollout_batch_size", ")", "*", "self", ".", "rollout_batch_size", "\n", "self", ".", "buffer", "=", "ReplayBuffer", "(", "buffer_shapes", ",", "buffer_size", ",", "self", ".", "T", ",", "self", ".", "sample_transitions", ")", "\n", "\n", "global", "DEMO_BUFFER", "\n", "DEMO_BUFFER", "=", "ReplayBuffer", "(", "buffer_shapes", ",", "buffer_size", ",", "self", ".", "T", ",", "self", ".", "sample_transitions", ")", "#initialize the demo buffer; in the same way as the primary data buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._random_action": [[109, 111], ["numpy.random.uniform"], "methods", ["None"], ["", "def", "_random_action", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "self", ".", "max_u", ",", "high", "=", "self", ".", "max_u", ",", "size", "=", "(", "n", ",", "self", ".", "dimu", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._preprocess_og": [[112, 122], ["numpy.clip", "numpy.clip", "g.reshape.reshape.reshape", "ag.reshape.reshape.reshape", "ddpg.DDPG.subtract_goals", "g.reshape.reshape.reshape"], "methods", ["None"], ["", "def", "_preprocess_og", "(", "self", ",", "o", ",", "ag", ",", "g", ")", ":", "\n", "        ", "if", "self", ".", "relative_goals", ":", "\n", "            ", "g_shape", "=", "g", ".", "shape", "\n", "g", "=", "g", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", "\n", "ag", "=", "ag", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", "\n", "g", "=", "self", ".", "subtract_goals", "(", "g", ",", "ag", ")", "\n", "g", "=", "g", ".", "reshape", "(", "*", "g_shape", ")", "\n", "", "o", "=", "np", ".", "clip", "(", "o", ",", "-", "self", ".", "clip_obs", ",", "self", ".", "clip_obs", ")", "\n", "g", "=", "np", ".", "clip", "(", "g", ",", "-", "self", ".", "clip_obs", ",", "self", ".", "clip_obs", ")", "\n", "return", "o", ",", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.step": [[123, 126], ["ddpg.DDPG.get_actions"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.get_actions"], ["", "def", "step", "(", "self", ",", "obs", ")", ":", "\n", "        ", "actions", "=", "self", ".", "get_actions", "(", "obs", "[", "'observation'", "]", ",", "obs", "[", "'achieved_goal'", "]", ",", "obs", "[", "'desired_goal'", "]", ")", "\n", "return", "actions", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.get_actions": [[128, 159], ["ddpg.DDPG._preprocess_og", "ddpg.DDPG.sess.run", "numpy.clip", "u.copy.copy.copy", "o.reshape", "g.reshape", "numpy.zeros", "numpy.random.randn", "numpy.random.binomial().reshape", "len", "ddpg.DDPG._random_action", "numpy.random.binomial"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._random_action"], ["", "def", "get_actions", "(", "self", ",", "o", ",", "ag", ",", "g", ",", "noise_eps", "=", "0.", ",", "random_eps", "=", "0.", ",", "use_target_net", "=", "False", ",", "\n", "compute_Q", "=", "False", ")", ":", "\n", "        ", "o", ",", "g", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "policy", "=", "self", ".", "target", "if", "use_target_net", "else", "self", ".", "main", "\n", "# values to compute", "\n", "vals", "=", "[", "policy", ".", "pi_tf", "]", "\n", "if", "compute_Q", ":", "\n", "            ", "vals", "+=", "[", "policy", ".", "Q_pi_tf", "]", "\n", "# feed", "\n", "", "feed", "=", "{", "\n", "policy", ".", "o_tf", ":", "o", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimo", ")", ",", "\n", "policy", ".", "g_tf", ":", "g", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", ",", "\n", "policy", ".", "u_tf", ":", "np", ".", "zeros", "(", "(", "o", ".", "size", "//", "self", ".", "dimo", ",", "self", ".", "dimu", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "}", "\n", "\n", "ret", "=", "self", ".", "sess", ".", "run", "(", "vals", ",", "feed_dict", "=", "feed", ")", "\n", "# action postprocessing", "\n", "u", "=", "ret", "[", "0", "]", "\n", "noise", "=", "noise_eps", "*", "self", ".", "max_u", "*", "np", ".", "random", ".", "randn", "(", "*", "u", ".", "shape", ")", "# gaussian noise", "\n", "u", "+=", "noise", "\n", "u", "=", "np", ".", "clip", "(", "u", ",", "-", "self", ".", "max_u", ",", "self", ".", "max_u", ")", "\n", "u", "+=", "np", ".", "random", ".", "binomial", "(", "1", ",", "random_eps", ",", "u", ".", "shape", "[", "0", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "*", "(", "self", ".", "_random_action", "(", "u", ".", "shape", "[", "0", "]", ")", "-", "u", ")", "# eps-greedy", "\n", "if", "u", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "u", "=", "u", "[", "0", "]", "\n", "", "u", "=", "u", ".", "copy", "(", ")", "\n", "ret", "[", "0", "]", "=", "u", "\n", "\n", "if", "len", "(", "ret", ")", "==", "1", ":", "\n", "            ", "return", "ret", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.init_demo_buffer": [[160, 216], ["numpy.load", "range", "baselines.logger.info", "key.replace", "numpy.empty", "range", "obs.append", "achieved_goals.append", "dict", "zip", "baselines.her.util.convert_episode_to_batch_major", "DEMO_BUFFER.store_episode", "baselines.logger.debug", "baselines.her.util.convert_episode_to_batch_major.clear", "DEMO_BUFFER.get_current_size", "ddpg.DDPG.input_dims.keys", "key.startswith", "obs.append", "acts.append", "goals.append", "achieved_goals.append", "enumerate", "DEMO_BUFFER.get_current_size", "baselines.her.util.transitions_in_episode_batch", "ddpg.DDPG.sample_transitions", "ddpg.DDPG._preprocess_og", "ddpg.DDPG.o_stats.update", "ddpg.DDPG.g_stats.update", "ddpg.DDPG.o_stats.recompute_stats", "ddpg.DDPG.g_stats.recompute_stats", "[].get", "[].get", "[].get", "[].get", "[].get"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.store_episode", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.get_current_size", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.get_current_size", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._preprocess_og"], ["", "", "def", "init_demo_buffer", "(", "self", ",", "demoDataFile", ",", "update_stats", "=", "True", ")", ":", "#function that initializes the demo buffer", "\n", "\n", "        ", "demoData", "=", "np", ".", "load", "(", "demoDataFile", ")", "#load the demonstration data from data file", "\n", "info_keys", "=", "[", "key", ".", "replace", "(", "'info_'", ",", "''", ")", "for", "key", "in", "self", ".", "input_dims", ".", "keys", "(", ")", "if", "key", ".", "startswith", "(", "'info_'", ")", "]", "\n", "info_values", "=", "[", "np", ".", "empty", "(", "(", "self", ".", "T", "-", "1", ",", "1", ",", "self", ".", "input_dims", "[", "'info_'", "+", "key", "]", ")", ",", "np", ".", "float32", ")", "for", "key", "in", "info_keys", "]", "\n", "\n", "demo_data_obs", "=", "demoData", "[", "'obs'", "]", "\n", "demo_data_acs", "=", "demoData", "[", "'acs'", "]", "\n", "demo_data_info", "=", "demoData", "[", "'info'", "]", "\n", "\n", "for", "epsd", "in", "range", "(", "self", ".", "num_demo", ")", ":", "# we initialize the whole demo buffer at the start of the training", "\n", "            ", "obs", ",", "acts", ",", "goals", ",", "achieved_goals", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "i", "=", "0", "\n", "for", "transition", "in", "range", "(", "self", ".", "T", "-", "1", ")", ":", "\n", "                ", "obs", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'observation'", ")", "]", ")", "\n", "acts", ".", "append", "(", "[", "demo_data_acs", "[", "epsd", "]", "[", "transition", "]", "]", ")", "\n", "goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'desired_goal'", ")", "]", ")", "\n", "achieved_goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'achieved_goal'", ")", "]", ")", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "info_keys", ")", ":", "\n", "                    ", "info_values", "[", "idx", "]", "[", "transition", ",", "i", "]", "=", "demo_data_info", "[", "epsd", "]", "[", "transition", "]", "[", "key", "]", "\n", "\n", "\n", "", "", "obs", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "self", ".", "T", "-", "1", "]", ".", "get", "(", "'observation'", ")", "]", ")", "\n", "achieved_goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "self", ".", "T", "-", "1", "]", ".", "get", "(", "'achieved_goal'", ")", "]", ")", "\n", "\n", "episode", "=", "dict", "(", "o", "=", "obs", ",", "\n", "u", "=", "acts", ",", "\n", "g", "=", "goals", ",", "\n", "ag", "=", "achieved_goals", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "info_keys", ",", "info_values", ")", ":", "\n", "                ", "episode", "[", "'info_{}'", ".", "format", "(", "key", ")", "]", "=", "value", "\n", "\n", "", "episode", "=", "convert_episode_to_batch_major", "(", "episode", ")", "\n", "global", "DEMO_BUFFER", "\n", "DEMO_BUFFER", ".", "store_episode", "(", "episode", ")", "# create the observation dict and append them into the demonstration buffer", "\n", "logger", ".", "debug", "(", "\"Demo buffer size currently \"", ",", "DEMO_BUFFER", ".", "get_current_size", "(", ")", ")", "#print out the demonstration buffer size", "\n", "\n", "if", "update_stats", ":", "\n", "# add transitions to normalizer to normalize the demo data as well", "\n", "                ", "episode", "[", "'o_2'", "]", "=", "episode", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "episode", "[", "'ag_2'", "]", "=", "episode", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "num_normalizing_transitions", "=", "transitions_in_episode_batch", "(", "episode", ")", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "episode", ",", "num_normalizing_transitions", ")", "\n", "\n", "o", ",", "g", ",", "ag", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", ",", "transitions", "[", "'ag'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "# No need to preprocess the o_2 and g_2 since this is only used for stats", "\n", "\n", "self", ".", "o_stats", ".", "update", "(", "transitions", "[", "'o'", "]", ")", "\n", "self", ".", "g_stats", ".", "update", "(", "transitions", "[", "'g'", "]", ")", "\n", "\n", "self", ".", "o_stats", ".", "recompute_stats", "(", ")", "\n", "self", ".", "g_stats", ".", "recompute_stats", "(", ")", "\n", "", "episode", ".", "clear", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Demo buffer size: \"", ",", "DEMO_BUFFER", ".", "get_current_size", "(", ")", ")", "#print out the demonstration buffer size", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.store_episode": [[217, 243], ["ddpg.DDPG.buffer.store_episode", "ddpg.DDPG.buffer.clear_buffer", "baselines.her.util.transitions_in_episode_batch", "ddpg.DDPG.sample_transitions", "ddpg.DDPG._preprocess_og", "ddpg.DDPG.o_stats.update", "ddpg.DDPG.g_stats.update", "ddpg.DDPG.o_stats.recompute_stats", "ddpg.DDPG.g_stats.recompute_stats"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.store_episode", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.clear_buffer", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._preprocess_og"], ["", "def", "store_episode", "(", "self", ",", "episode_batch", ",", "update_stats", "=", "True", ",", "if_clear_buffer_first", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        episode_batch: array of batch_size x (T or T+1) x dim_key\n                       'o' is of size T+1, others are of size T\n        \"\"\"", "\n", "if", "if_clear_buffer_first", ":", "\n", "            ", "self", ".", "buffer", ".", "clear_buffer", "(", ")", "\n", "", "self", ".", "buffer", ".", "store_episode", "(", "episode_batch", ")", "\n", "\n", "\n", "if", "update_stats", ":", "\n", "# add transitions to normalizer", "\n", "            ", "episode_batch", "[", "'o_2'", "]", "=", "episode_batch", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "episode_batch", "[", "'ag_2'", "]", "=", "episode_batch", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "num_normalizing_transitions", "=", "transitions_in_episode_batch", "(", "episode_batch", ")", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "episode_batch", ",", "num_normalizing_transitions", ")", "\n", "\n", "o", ",", "g", ",", "ag", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", ",", "transitions", "[", "'ag'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "# No need to preprocess the o_2 and g_2 since this is only used for stats", "\n", "\n", "self", ".", "o_stats", ".", "update", "(", "transitions", "[", "'o'", "]", ")", "\n", "self", ".", "g_stats", ".", "update", "(", "transitions", "[", "'g'", "]", ")", "\n", "\n", "self", ".", "o_stats", ".", "recompute_stats", "(", ")", "\n", "self", ".", "g_stats", ".", "recompute_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.get_current_buffer_size": [[244, 246], ["ddpg.DDPG.buffer.get_current_size"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.get_current_size"], ["", "", "def", "get_current_buffer_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "buffer", ".", "get_current_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._sync_optimizers": [[247, 250], ["ddpg.DDPG.Q_adam.sync", "ddpg.DDPG.pi_adam.sync"], "methods", ["None"], ["", "def", "_sync_optimizers", "(", "self", ")", ":", "\n", "        ", "self", ".", "Q_adam", ".", "sync", "(", ")", "\n", "self", ".", "pi_adam", ".", "sync", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._grads": [[251, 260], ["ddpg.DDPG.sess.run"], "methods", ["None"], ["", "def", "_grads", "(", "self", ")", ":", "\n", "# Avoid feed_dict here for performance!", "\n", "        ", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "=", "self", ".", "sess", ".", "run", "(", "[", "\n", "self", ".", "Q_loss_tf", ",", "\n", "self", ".", "main", ".", "Q_pi_tf", ",", "\n", "self", ".", "Q_grad_tf", ",", "\n", "self", ".", "pi_grad_tf", "\n", "]", ")", "\n", "return", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._update": [[261, 264], ["ddpg.DDPG.Q_adam.update", "ddpg.DDPG.pi_adam.update"], "methods", ["None"], ["", "def", "_update", "(", "self", ",", "Q_grad", ",", "pi_grad", ")", ":", "\n", "        ", "self", ".", "Q_adam", ".", "update", "(", "Q_grad", ",", "self", ".", "Q_lr", ")", "\n", "self", ".", "pi_adam", ".", "update", "(", "pi_grad", ",", "self", ".", "pi_lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.sample_batch": [[265, 285], ["ddpg.DDPG._preprocess_og", "ddpg.DDPG._preprocess_og", "ddpg.DDPG.buffer.sample", "DEMO_BUFFER.sample", "DEMO_BUFFER.sample.items", "ddpg.DDPG.buffer.sample", "transitions[].tolist", "numpy.array", "ddpg.DDPG.stage_shapes.keys", "transitions[].tolist.append", "v.tolist"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.replay_buffer.ReplayBuffer.sample"], ["", "def", "sample_batch", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "bc_loss", ":", "#use demonstration buffer to sample as well if bc_loss flag is set TRUE", "\n", "            ", "transitions", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", "-", "self", ".", "demo_batch_size", ")", "\n", "global", "DEMO_BUFFER", "\n", "transitions_demo", "=", "DEMO_BUFFER", ".", "sample", "(", "self", ".", "demo_batch_size", ")", "#sample from the demo buffer", "\n", "for", "k", ",", "values", "in", "transitions_demo", ".", "items", "(", ")", ":", "\n", "                ", "rolloutV", "=", "transitions", "[", "k", "]", ".", "tolist", "(", ")", "\n", "for", "v", "in", "values", ":", "\n", "                    ", "rolloutV", ".", "append", "(", "v", ".", "tolist", "(", ")", ")", "\n", "", "transitions", "[", "k", "]", "=", "np", ".", "array", "(", "rolloutV", ")", "\n", "", "", "else", ":", "\n", "            ", "transitions", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", ")", "#otherwise only sample from primary buffer", "\n", "\n", "", "o", ",", "o_2", ",", "g", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'o_2'", "]", ",", "transitions", "[", "'g'", "]", "\n", "ag", ",", "ag_2", "=", "transitions", "[", "'ag'", "]", ",", "transitions", "[", "'ag_2'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "transitions", "[", "'o_2'", "]", ",", "transitions", "[", "'g_2'", "]", "=", "self", ".", "_preprocess_og", "(", "o_2", ",", "ag_2", ",", "g", ")", "\n", "\n", "transitions_batch", "=", "[", "transitions", "[", "key", "]", "for", "key", "in", "self", ".", "stage_shapes", ".", "keys", "(", ")", "]", "\n", "return", "transitions_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.stage_batch": [[286, 291], ["ddpg.DDPG.sess.run", "ddpg.DDPG.sample_batch", "len", "len", "dict", "zip"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.sample_batch"], ["", "def", "stage_batch", "(", "self", ",", "batch", "=", "None", ")", ":", "\n", "        ", "if", "batch", "is", "None", ":", "\n", "            ", "batch", "=", "self", ".", "sample_batch", "(", ")", "\n", "", "assert", "len", "(", "self", ".", "buffer_ph_tf", ")", "==", "len", "(", "batch", ")", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "stage_op", ",", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "buffer_ph_tf", ",", "batch", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.train": [[292, 298], ["ddpg.DDPG._grads", "ddpg.DDPG._update", "ddpg.DDPG.stage_batch"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._grads", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._update", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.stage_batch"], ["", "def", "train", "(", "self", ",", "stage", "=", "True", ")", ":", "\n", "        ", "if", "stage", ":", "\n", "            ", "self", ".", "stage_batch", "(", ")", "\n", "", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "=", "self", ".", "_grads", "(", ")", "\n", "self", ".", "_update", "(", "Q_grad", ",", "pi_grad", ")", "\n", "return", "critic_loss", ",", "actor_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._init_target_net": [[299, 301], ["ddpg.DDPG.sess.run"], "methods", ["None"], ["", "def", "_init_target_net", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "init_target_net_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.update_target_net": [[302, 304], ["ddpg.DDPG.sess.run"], "methods", ["None"], ["", "def", "update_target_net", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_net_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.clear_buffer": [[305, 307], ["ddpg.DDPG.buffer.clear_buffer"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.clear_buffer"], ["", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "self", ".", "buffer", ".", "clear_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars": [[308, 312], ["tensorflow.get_collection", "len"], "methods", ["None"], ["", "def", "_vars", "(", "self", ",", "scope", ")", ":", "\n", "        ", "res", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "self", ".", "scope", "+", "'/'", "+", "scope", ")", "\n", "assert", "len", "(", "res", ")", ">", "0", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._global_vars": [[313, 316], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "_global_vars", "(", "self", ",", "scope", ")", ":", "\n", "        ", "res", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "scope", "+", "'/'", "+", "scope", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._create_network": [[317, 407], ["baselines.logger.info", "baselines.common.tf_util.get_session", "ddpg.DDPG.staging_tf.get", "collections.OrderedDict", "tensorflow.reshape", "numpy.concatenate", "tensorflow.clip_by_value", "tensorflow.reduce_mean", "tensorflow.gradients", "tensorflow.gradients", "zip", "zip", "baselines.her.util.flatten_grads", "baselines.her.util.flatten_grads", "baselines.common.mpi_adam.MpiAdam", "baselines.common.mpi_adam.MpiAdam", "list", "list", "tensorflow.variables_initializer().run", "ddpg.DDPG._sync_optimizers", "ddpg.DDPG._init_target_net", "tensorflow.variable_scope", "baselines.her.normalizer.Normalizer", "tensorflow.variable_scope", "baselines.her.normalizer.Normalizer", "tensorflow.variable_scope", "ddpg.DDPG.create_actor_critic", "vs.reuse_variables", "tensorflow.variable_scope", "collections.OrderedDict.copy", "ddpg.DDPG.create_actor_critic", "vs.reuse_variables", "len", "len", "tensorflow.square", "tensorflow.reshape", "tensorflow.reduce_sum", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "len", "len", "len", "len", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._global_vars", "ddpg.DDPG._global_vars", "map", "map", "vs.reuse_variables", "vs.reuse_variables", "numpy.zeros", "numpy.ones", "vs.reuse_variables", "vs.reuse_variables", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "tensorflow.boolean_mask", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "zip", "zip", "tensorflow.variables_initializer", "enumerate", "tensorflow.stop_gradient", "tensorflow.square", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "v[].assign", "v[].assign", "ddpg.DDPG._global_vars", "ddpg.DDPG.stage_shapes.keys", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.square", "tensorflow.square", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._sync_optimizers", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._init_target_net", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._global_vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._global_vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._global_vars"], ["", "def", "_create_network", "(", "self", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating a DDPG agent with action space %d x %s...\"", "%", "(", "self", ".", "dimu", ",", "self", ".", "max_u", ")", ")", "\n", "self", ".", "sess", "=", "tf_util", ".", "get_session", "(", ")", "\n", "\n", "# running averages", "\n", "with", "tf", ".", "variable_scope", "(", "'o_stats'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "self", ".", "o_stats", "=", "Normalizer", "(", "self", ".", "dimo", ",", "self", ".", "norm_eps", ",", "self", ".", "norm_clip", ",", "sess", "=", "self", ".", "sess", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'g_stats'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "self", ".", "g_stats", "=", "Normalizer", "(", "self", ".", "dimg", ",", "self", ".", "norm_eps", ",", "self", ".", "norm_clip", ",", "sess", "=", "self", ".", "sess", ")", "\n", "\n", "# mini-batch sampling.", "\n", "", "batch", "=", "self", ".", "staging_tf", ".", "get", "(", ")", "\n", "batch_tf", "=", "OrderedDict", "(", "[", "(", "key", ",", "batch", "[", "i", "]", ")", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "self", ".", "stage_shapes", ".", "keys", "(", ")", ")", "]", ")", "\n", "batch_tf", "[", "'r'", "]", "=", "tf", ".", "reshape", "(", "batch_tf", "[", "'r'", "]", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "\n", "#choose only the demo buffer samples", "\n", "mask", "=", "np", ".", "concatenate", "(", "(", "np", ".", "zeros", "(", "self", ".", "batch_size", "-", "self", ".", "demo_batch_size", ")", ",", "np", ".", "ones", "(", "self", ".", "demo_batch_size", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "# networks", "\n", "with", "tf", ".", "variable_scope", "(", "'main'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "self", ".", "main", "=", "self", ".", "create_actor_critic", "(", "batch_tf", ",", "net_type", "=", "'main'", ",", "**", "self", ".", "__dict__", ")", "\n", "vs", ".", "reuse_variables", "(", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'target'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "target_batch_tf", "=", "batch_tf", ".", "copy", "(", ")", "\n", "target_batch_tf", "[", "'o'", "]", "=", "batch_tf", "[", "'o_2'", "]", "\n", "target_batch_tf", "[", "'g'", "]", "=", "batch_tf", "[", "'g_2'", "]", "\n", "self", ".", "target", "=", "self", ".", "create_actor_critic", "(", "\n", "target_batch_tf", ",", "net_type", "=", "'target'", ",", "**", "self", ".", "__dict__", ")", "\n", "vs", ".", "reuse_variables", "(", ")", "\n", "", "assert", "len", "(", "self", ".", "_vars", "(", "\"main\"", ")", ")", "==", "len", "(", "self", ".", "_vars", "(", "\"target\"", ")", ")", "\n", "\n", "# loss functions", "\n", "target_Q_pi_tf", "=", "self", ".", "target", ".", "Q_pi_tf", "\n", "clip_range", "=", "(", "-", "self", ".", "clip_return", ",", "0.", "if", "self", ".", "clip_pos_returns", "else", "np", ".", "inf", ")", "\n", "target_tf", "=", "tf", ".", "clip_by_value", "(", "batch_tf", "[", "'r'", "]", "+", "self", ".", "gamma", "*", "target_Q_pi_tf", ",", "*", "clip_range", ")", "\n", "self", ".", "Q_loss_tf", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "stop_gradient", "(", "target_tf", ")", "-", "self", ".", "main", ".", "Q_tf", ")", ")", "\n", "\n", "if", "self", ".", "bc_loss", "==", "1", "and", "self", ".", "q_filter", "==", "1", ":", "# train with demonstrations and use bc_loss and q_filter both", "\n", "            ", "maskMain", "=", "tf", ".", "reshape", "(", "tf", ".", "boolean_mask", "(", "self", ".", "main", ".", "Q_tf", ">", "self", ".", "main", ".", "Q_pi_tf", ",", "mask", ")", ",", "[", "-", "1", "]", ")", "#where is the demonstrator action better than actor action according to the critic? choose those samples only", "\n", "#define the cloning loss on the actor's actions only on the samples which adhere to the above masks", "\n", "self", ".", "cloning_loss_tf", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "tf", ".", "boolean_mask", "(", "tf", ".", "boolean_mask", "(", "(", "self", ".", "main", ".", "pi_tf", ")", ",", "mask", ")", ",", "maskMain", ",", "axis", "=", "0", ")", "-", "tf", ".", "boolean_mask", "(", "tf", ".", "boolean_mask", "(", "(", "batch_tf", "[", "'u'", "]", ")", ",", "mask", ")", ",", "maskMain", ",", "axis", "=", "0", ")", ")", ")", "\n", "self", ".", "pi_loss_tf", "=", "-", "self", ".", "prm_loss_weight", "*", "tf", ".", "reduce_mean", "(", "self", ".", "main", ".", "Q_pi_tf", ")", "#primary loss scaled by it's respective weight prm_loss_weight", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "prm_loss_weight", "*", "self", ".", "action_l2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "main", ".", "pi_tf", "/", "self", ".", "max_u", ")", ")", "#L2 loss on action values scaled by the same weight prm_loss_weight", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "aux_loss_weight", "*", "self", ".", "cloning_loss_tf", "#adding the cloning loss to the actor loss as an auxilliary loss scaled by its weight aux_loss_weight", "\n", "\n", "", "elif", "self", ".", "bc_loss", "==", "1", "and", "self", ".", "q_filter", "==", "0", ":", "# train with demonstrations without q_filter", "\n", "            ", "self", ".", "cloning_loss_tf", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "tf", ".", "boolean_mask", "(", "(", "self", ".", "main", ".", "pi_tf", ")", ",", "mask", ")", "-", "tf", ".", "boolean_mask", "(", "(", "batch_tf", "[", "'u'", "]", ")", ",", "mask", ")", ")", ")", "\n", "self", ".", "pi_loss_tf", "=", "-", "self", ".", "prm_loss_weight", "*", "tf", ".", "reduce_mean", "(", "self", ".", "main", ".", "Q_pi_tf", ")", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "prm_loss_weight", "*", "self", ".", "action_l2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "main", ".", "pi_tf", "/", "self", ".", "max_u", ")", ")", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "aux_loss_weight", "*", "self", ".", "cloning_loss_tf", "\n", "\n", "", "else", ":", "#If  not training with demonstrations", "\n", "            ", "self", ".", "pi_loss_tf", "=", "-", "tf", ".", "reduce_mean", "(", "self", ".", "main", ".", "Q_pi_tf", ")", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "action_l2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "main", ".", "pi_tf", "/", "self", ".", "max_u", ")", ")", "\n", "\n", "", "Q_grads_tf", "=", "tf", ".", "gradients", "(", "self", ".", "Q_loss_tf", ",", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "\n", "pi_grads_tf", "=", "tf", ".", "gradients", "(", "self", ".", "pi_loss_tf", ",", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "\n", "assert", "len", "(", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "==", "len", "(", "Q_grads_tf", ")", "\n", "assert", "len", "(", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "==", "len", "(", "pi_grads_tf", ")", "\n", "self", ".", "Q_grads_vars_tf", "=", "zip", "(", "Q_grads_tf", ",", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "\n", "self", ".", "pi_grads_vars_tf", "=", "zip", "(", "pi_grads_tf", ",", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "\n", "self", ".", "Q_grad_tf", "=", "flatten_grads", "(", "grads", "=", "Q_grads_tf", ",", "var_list", "=", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "\n", "self", ".", "pi_grad_tf", "=", "flatten_grads", "(", "grads", "=", "pi_grads_tf", ",", "var_list", "=", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "\n", "\n", "# optimizers", "\n", "self", ".", "Q_adam", "=", "MpiAdam", "(", "self", ".", "_vars", "(", "'main/Q'", ")", ",", "scale_grad_by_procs", "=", "False", ")", "\n", "self", ".", "pi_adam", "=", "MpiAdam", "(", "self", ".", "_vars", "(", "'main/pi'", ")", ",", "scale_grad_by_procs", "=", "False", ")", "\n", "\n", "# polyak averaging", "\n", "self", ".", "main_vars", "=", "self", ".", "_vars", "(", "'main/Q'", ")", "+", "self", ".", "_vars", "(", "'main/pi'", ")", "\n", "self", ".", "target_vars", "=", "self", ".", "_vars", "(", "'target/Q'", ")", "+", "self", ".", "_vars", "(", "'target/pi'", ")", "\n", "self", ".", "stats_vars", "=", "self", ".", "_global_vars", "(", "'o_stats'", ")", "+", "self", ".", "_global_vars", "(", "'g_stats'", ")", "\n", "self", ".", "init_target_net_op", "=", "list", "(", "\n", "map", "(", "lambda", "v", ":", "v", "[", "0", "]", ".", "assign", "(", "v", "[", "1", "]", ")", ",", "zip", "(", "self", ".", "target_vars", ",", "self", ".", "main_vars", ")", ")", ")", "\n", "self", ".", "update_target_net_op", "=", "list", "(", "\n", "map", "(", "lambda", "v", ":", "v", "[", "0", "]", ".", "assign", "(", "self", ".", "polyak", "*", "v", "[", "0", "]", "+", "(", "1.", "-", "self", ".", "polyak", ")", "*", "v", "[", "1", "]", ")", ",", "zip", "(", "self", ".", "target_vars", ",", "self", ".", "main_vars", ")", ")", ")", "\n", "\n", "# initialize all variables", "\n", "tf", ".", "variables_initializer", "(", "self", ".", "_global_vars", "(", "''", ")", ")", ".", "run", "(", ")", "\n", "self", ".", "_sync_optimizers", "(", ")", "\n", "self", ".", "_init_target_net", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.logs": [[408, 419], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "prefix.endswith", "ddpg.DDPG.sess.run", "ddpg.DDPG.sess.run", "ddpg.DDPG.sess.run", "ddpg.DDPG.sess.run"], "methods", ["None"], ["", "def", "logs", "(", "self", ",", "prefix", "=", "''", ")", ":", "\n", "        ", "logs", "=", "[", "]", "\n", "logs", "+=", "[", "(", "'stats_o/mean'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "o_stats", ".", "mean", "]", ")", ")", ")", "]", "\n", "logs", "+=", "[", "(", "'stats_o/std'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "o_stats", ".", "std", "]", ")", ")", ")", "]", "\n", "logs", "+=", "[", "(", "'stats_g/mean'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "g_stats", ".", "mean", "]", ")", ")", ")", "]", "\n", "logs", "+=", "[", "(", "'stats_g/std'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "g_stats", ".", "std", "]", ")", ")", ")", "]", "\n", "\n", "if", "prefix", "!=", "''", "and", "not", "prefix", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "return", "[", "(", "prefix", "+", "'/'", "+", "key", ",", "val", ")", "for", "key", ",", "val", "in", "logs", "]", "\n", "", "else", ":", "\n", "            ", "return", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.__getstate__": [[420, 431], ["ddpg.DDPG.sess.run", "ddpg.DDPG.__dict__.items", "all", "ddpg.DDPG._global_vars"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._global_vars"], ["", "", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Our policies can be loaded from pkl, but after unpickling you cannot continue training.\n        \"\"\"", "\n", "excluded_subnames", "=", "[", "'_tf'", ",", "'_op'", ",", "'_vars'", ",", "'_adam'", ",", "'buffer'", ",", "'sess'", ",", "'_stats'", ",", "\n", "'main'", ",", "'target'", ",", "'lock'", ",", "'env'", ",", "'sample_transitions'", ",", "\n", "'stage_shapes'", ",", "'create_actor_critic'", "]", "\n", "\n", "state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "self", ".", "__dict__", ".", "items", "(", ")", "if", "all", "(", "[", "not", "subname", "in", "k", "for", "subname", "in", "excluded_subnames", "]", ")", "}", "\n", "state", "[", "'buffer_size'", "]", "=", "self", ".", "buffer_size", "\n", "state", "[", "'tf'", "]", "=", "self", ".", "sess", ".", "run", "(", "[", "x", "for", "x", "in", "self", ".", "_global_vars", "(", "''", ")", "if", "'buffer'", "not", "in", "x", ".", "name", "]", ")", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.__setstate__": [[432, 447], ["ddpg.DDPG.__init__", "state.items", "ddpg.DDPG.sess.run", "len", "len", "tensorflow.assign", "ddpg.DDPG._global_vars", "zip"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.__init__", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG._global_vars"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "'sample_transitions'", "not", "in", "state", ":", "\n", "# We don't need this for playing the policy.", "\n", "            ", "state", "[", "'sample_transitions'", "]", "=", "None", "\n", "\n", "", "self", ".", "__init__", "(", "**", "state", ")", "\n", "# set up stats (they are overwritten in __init__)", "\n", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "[", "-", "6", ":", "]", "==", "'_stats'", ":", "\n", "                ", "self", ".", "__dict__", "[", "k", "]", "=", "v", "\n", "# load TF variables", "\n", "", "", "vars", "=", "[", "x", "for", "x", "in", "self", ".", "_global_vars", "(", "''", ")", "if", "'buffer'", "not", "in", "x", ".", "name", "]", "\n", "assert", "(", "len", "(", "vars", ")", "==", "len", "(", "state", "[", "\"tf\"", "]", ")", ")", "\n", "node", "=", "[", "tf", ".", "assign", "(", "var", ",", "val", ")", "for", "var", ",", "val", "in", "zip", "(", "vars", ",", "state", "[", "\"tf\"", "]", ")", "]", "\n", "self", ".", "sess", ".", "run", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.save": [[448, 450], ["baselines.common.tf_util.save_variables"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "tf_util", ".", "save_variables", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.dims_to_shapes": [[16, 18], ["tuple", "tuple", "input_dims.items"], "function", ["None"], ["def", "dims_to_shapes", "(", "input_dims", ")", ":", "\n", "    ", "return", "{", "key", ":", "tuple", "(", "[", "val", "]", ")", "if", "val", ">", "0", "else", "tuple", "(", ")", "for", "key", ",", "val", "in", "input_dims", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.mpi_average": [[21, 27], ["isinstance", "any", "baselines.common.mpi_moments.mpi_moments", "numpy.array"], "function", ["None"], ["def", "mpi_average", "(", "value", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "        ", "value", "=", "[", "value", "]", "\n", "", "if", "not", "any", "(", "value", ")", ":", "\n", "        ", "value", "=", "[", "0.", "]", "\n", "", "return", "mpi_moments", "(", "np", ".", "array", "(", "value", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.train": [[29, 124], ["mpi4py.MPI.COMM_WORLD.Get_rank", "baselines.logger.info", "range", "writer.close", "os.path.join", "os.path.join", "os.path.join", "policy.init_demo_buffer", "rollout_worker.clear_history", "range", "policy.save", "evaluator.clear_history", "range", "baselines.logger.record_tabular", "evaluator.logs", "rollout_worker.logs", "policy.logs", "her.mpi_average", "writer.add_scalar", "numpy.random.uniform", "np.random.uniform.copy", "mpi4py.MPI.COMM_WORLD.Bcast", "rollout_worker.generate_rollouts", "range", "policy.update_target_net", "evaluator.generate_rollouts", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.dump_tabular", "evaluator.current_success_rate", "policy.store_episode", "policy.train", "her.mpi_average", "val.copy", "her.mpi_average", "her.mpi_average", "int", "int", "policy.store_episode"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.init_demo_buffer", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.clear_history", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.save", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.clear_history", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.logs", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.logs", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.logs", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.mpi_average", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.update_target_net", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.generate_rollouts", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.rollout.RolloutWorker.current_success_rate", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.store_episode", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.train", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.mpi_average", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.mpi_average", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.mpi_average", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.store_episode"], ["", "def", "train", "(", "*", ",", "policy", ",", "rollout_worker", ",", "evaluator", ",", "\n", "n_epochs", ",", "n_test_rollouts", ",", "n_cycles", ",", "n_batches", ",", "policy_save_interval", ",", "\n", "save_path", ",", "demo_file", ",", "env_name", ",", "n_rsym", ",", "**", "kwargs", ")", ":", "\n", "    ", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "\n", "if", "save_path", ":", "\n", "        ", "latest_policy_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'policy_latest.pkl'", ")", "\n", "best_policy_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'policy_best.pkl'", ")", "\n", "periodic_policy_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'policy_{}.pkl'", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Training...\"", ")", "\n", "best_success_rate", "=", "-", "1", "\n", "\n", "if", "policy", ".", "bc_loss", "==", "1", ":", "policy", ".", "init_demo_buffer", "(", "demo_file", ")", "#initialize demo buffer if training with demonstrations", "\n", "\n", "# num_timesteps = n_epochs * n_cycles * rollout_length * number of rollout workers", "\n", "\n", "# prepare the param for training on KER", "\n", "n_rsym_number", "=", "n_rsym", "\n", "first_time_enter", "=", "True", "\n", "test_suc_rate", "=", "0", "\n", "single_suc_rate_threshold", "=", "SINGLE_SUC_RATE_THRESHOLD", "\n", "terminate_ker_now", "=", "False", "\n", "if_clear_buffer", "=", "False", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "# train", "\n", "\n", "#Terminate KER during training or not ", "\n", "        ", "if", "(", "single_suc_rate_threshold", "is", "not", "None", ")", "and", "(", "n_rsym_number", "!=", "0", ")", ":", "\n", "# int(xxx*10) to get rid of the float, and just enter once to terminate KER.", "\n", "            ", "if", "(", "int", "(", "test_suc_rate", "*", "10", ")", "==", "int", "(", "single_suc_rate_threshold", "*", "10", ")", ")", "and", "first_time_enter", ":", "\n", "                ", "first_time_enter", "=", "False", "\n", "if_clear_buffer", "=", "IF_CLEAR_BUFFER", "\n", "terminate_ker_now", "=", "True", "\n", "\n", "", "", "rollout_worker", ".", "clear_history", "(", ")", "\n", "for", "_", "in", "range", "(", "n_cycles", ")", ":", "\n", "# generate episodes", "\n", "            ", "episodes", "=", "rollout_worker", ".", "generate_rollouts", "(", "terminate_ker", "=", "terminate_ker_now", ")", "\n", "\n", "# with KER", "\n", "if", "(", "n_rsym_number", "!=", "0", ")", "and", "terminate_ker_now", "==", "False", ":", "\n", "                ", "for", "episode", "in", "episodes", ":", "\n", "                    ", "policy", ".", "store_episode", "(", "episode", ")", "\n", "# without KER", "\n", "", "", "else", ":", "\n", "                ", "policy", ".", "store_episode", "(", "episodes", ",", "if_clear_buffer_first", "=", "if_clear_buffer", ")", "\n", "# HER/DDPG do not need clear buffer", "\n", "if_clear_buffer", "=", "False", "\n", "\n", "", "for", "_", "in", "range", "(", "n_batches", ")", ":", "\n", "                ", "policy", ".", "train", "(", ")", "\n", "", "policy", ".", "update_target_net", "(", ")", "\n", "", "policy", ".", "save", "(", "save_path", ")", "\n", "\n", "# test", "\n", "evaluator", ".", "clear_history", "(", ")", "\n", "for", "_", "in", "range", "(", "n_test_rollouts", ")", ":", "\n", "            ", "evaluator", ".", "generate_rollouts", "(", ")", "\n", "\n", "# record logs", "\n", "", "logger", ".", "record_tabular", "(", "'epoch'", ",", "epoch", ")", "\n", "for", "key", ",", "val", "in", "evaluator", ".", "logs", "(", "'test'", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "key", ",", "mpi_average", "(", "val", ")", ")", "\n", "if", "key", "==", "\"test/success_rate\"", ":", "\n", "                ", "test_suc_rate", "=", "val", ".", "copy", "(", ")", "\n", "", "", "for", "key", ",", "val", "in", "rollout_worker", ".", "logs", "(", "'train'", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "key", ",", "mpi_average", "(", "val", ")", ")", "\n", "", "for", "key", ",", "val", "in", "policy", ".", "logs", "(", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "key", ",", "mpi_average", "(", "val", ")", ")", "\n", "\n", "", "if", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "dump_tabular", "(", ")", "\n", "\n", "# save the policy if it's better than the previous ones", "\n", "", "success_rate", "=", "mpi_average", "(", "evaluator", ".", "current_success_rate", "(", ")", ")", "\n", "writer", ".", "add_scalar", "(", "env_name", "+", "'_success_rate'", ",", "success_rate", ",", "epoch", ")", "\n", "# if rank == 0 and success_rate >= best_success_rate and save_path:", "\n", "#     best_success_rate = success_rate", "\n", "#     logger.info('New best success rate: {}. Saving policy to {} ...'.format(best_success_rate, best_policy_path))", "\n", "#     evaluator.save_policy(best_policy_path)", "\n", "#     evaluator.save_policy(latest_policy_path)", "\n", "# if rank == 0 and policy_save_interval > 0 and epoch % policy_save_interval == 0 and save_path:", "\n", "#     policy_path = periodic_policy_path.format(epoch)", "\n", "#     logger.info('Saving periodic policy to {} ...'.format(policy_path))", "\n", "#     evaluator.save_policy(policy_path)", "\n", "\n", "# make sure that different threads have different seeds", "\n", "local_uniform", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "(", "1", ",", ")", ")", "\n", "root_uniform", "=", "local_uniform", ".", "copy", "(", ")", "\n", "MPI", ".", "COMM_WORLD", ".", "Bcast", "(", "root_uniform", ",", "root", "=", "0", ")", "\n", "if", "rank", "!=", "0", ":", "\n", "            ", "assert", "local_uniform", "[", "0", "]", "!=", "root_uniform", "[", "0", "]", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "return", "policy", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.learn": [[126, 218], ["baselines.common.set_global_seeds", "config.prepare_params.update", "baselines.prepare_params", "config.prepare_params.update", "baselines.log_params", "baselines.configure_dims", "baselines.configure_ddpg", "baselines.her.rollout.RolloutWorker", "baselines.her.rollout.RolloutWorker", "her.train", "mpi4py.MPI.COMM_WORLD.Get_rank", "mpi4py.MPI.COMM_WORLD.Get_size", "config.prepare_params.update", "open", "json.dump", "baselines.logger.warn", "baselines.logger.warn", "baselines.logger.warn", "baselines.logger.warn", "baselines.logger.warn", "baselines.common.tf_util.load_variables", "os.path.join", "baselines.logger.get_dir"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.train"], ["", "def", "learn", "(", "*", ",", "network", ",", "env", ",", "total_timesteps", ",", "\n", "seed", "=", "None", ",", "\n", "eval_env", "=", "None", ",", "\n", "replay_strategy", "=", "'future'", ",", "\n", "policy_save_interval", "=", "5", ",", "\n", "clip_return", "=", "True", ",", "\n", "demo_file", "=", "None", ",", "\n", "override_params", "=", "None", ",", "\n", "load_path", "=", "None", ",", "\n", "save_path", "=", "None", ",", "\n", "n_rsym", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "\n", "    ", "override_params", "=", "override_params", "or", "{", "}", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "        ", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "num_cpu", "=", "MPI", ".", "COMM_WORLD", ".", "Get_size", "(", ")", "\n", "\n", "# Seed everything.", "\n", "", "rank_seed", "=", "seed", "+", "1000000", "*", "rank", "if", "seed", "is", "not", "None", "else", "None", "\n", "set_global_seeds", "(", "rank_seed", ")", "\n", "\n", "# Prepare params.", "\n", "params", "=", "config", ".", "DEFAULT_PARAMS", "\n", "env_name", "=", "env", ".", "spec", ".", "id", "\n", "params", "[", "'env_name'", "]", "=", "env_name", "\n", "params", "[", "'replay_strategy'", "]", "=", "replay_strategy", "\n", "if", "env_name", "in", "config", ".", "DEFAULT_ENV_PARAMS", ":", "\n", "        ", "params", ".", "update", "(", "config", ".", "DEFAULT_ENV_PARAMS", "[", "env_name", "]", ")", "# merge env-specific parameters in", "\n", "", "params", ".", "update", "(", "**", "override_params", ")", "# makes it possible to override any parameter", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "'params.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "         ", "json", ".", "dump", "(", "params", ",", "f", ")", "\n", "", "params", "=", "config", ".", "prepare_params", "(", "params", ")", "\n", "params", "[", "'rollout_batch_size'", "]", "=", "env", ".", "num_envs", "\n", "\n", "if", "demo_file", "is", "not", "None", ":", "\n", "        ", "params", "[", "'bc_loss'", "]", "=", "1", "\n", "", "params", ".", "update", "(", "kwargs", ")", "\n", "\n", "config", ".", "log_params", "(", "params", ",", "logger", "=", "logger", ")", "\n", "\n", "if", "num_cpu", "==", "1", ":", "\n", "        ", "logger", ".", "warn", "(", ")", "\n", "logger", ".", "warn", "(", "'*** Warning ***'", ")", "\n", "logger", ".", "warn", "(", "\n", "'You are running HER with just a single MPI worker. This will work, but the '", "+", "\n", "'experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) '", "+", "\n", "'were obtained with --num_cpu 19. This makes a significant difference and if you '", "+", "\n", "'are looking to reproduce those results, be aware of this. Please also refer to '", "+", "\n", "'https://github.com/openai/baselines/issues/314 for further details.'", ")", "\n", "logger", ".", "warn", "(", "'****************'", ")", "\n", "logger", ".", "warn", "(", ")", "\n", "\n", "", "dims", "=", "config", ".", "configure_dims", "(", "params", ")", "\n", "policy", "=", "config", ".", "configure_ddpg", "(", "dims", "=", "dims", ",", "params", "=", "params", ",", "clip_return", "=", "clip_return", ")", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "tf_util", ".", "load_variables", "(", "load_path", ")", "\n", "\n", "", "rollout_params", "=", "{", "\n", "'exploit'", ":", "False", ",", "\n", "'use_target_net'", ":", "False", ",", "\n", "'use_demo_states'", ":", "True", ",", "\n", "'compute_Q'", ":", "False", ",", "\n", "'T'", ":", "params", "[", "'T'", "]", ",", "\n", "}", "\n", "\n", "eval_params", "=", "{", "\n", "'exploit'", ":", "True", ",", "\n", "'use_target_net'", ":", "params", "[", "'test_with_polyak'", "]", ",", "\n", "'use_demo_states'", ":", "False", ",", "\n", "'compute_Q'", ":", "True", ",", "\n", "'T'", ":", "params", "[", "'T'", "]", ",", "\n", "}", "\n", "\n", "for", "name", "in", "[", "'T'", ",", "'rollout_batch_size'", ",", "'gamma'", ",", "'noise_eps'", ",", "'random_eps'", "]", ":", "\n", "        ", "rollout_params", "[", "name", "]", "=", "params", "[", "name", "]", "\n", "eval_params", "[", "name", "]", "=", "params", "[", "name", "]", "\n", "\n", "", "eval_env", "=", "eval_env", "or", "env", "\n", "\n", "rollout_worker", "=", "RolloutWorker", "(", "env_name", ",", "env", ",", "policy", ",", "dims", ",", "logger", ",", "monitor", "=", "True", ",", "n_rsym", "=", "n_rsym", ",", "**", "rollout_params", ")", "\n", "evaluator", "=", "RolloutWorker", "(", "env_name", ",", "eval_env", ",", "policy", ",", "dims", ",", "logger", ",", "**", "eval_params", ")", "\n", "\n", "n_cycles", "=", "params", "[", "'n_cycles'", "]", "\n", "n_epochs", "=", "total_timesteps", "//", "n_cycles", "//", "rollout_worker", ".", "T", "//", "rollout_worker", ".", "rollout_batch_size", "\n", "\n", "return", "train", "(", "\n", "save_path", "=", "save_path", ",", "policy", "=", "policy", ",", "rollout_worker", "=", "rollout_worker", ",", "\n", "evaluator", "=", "evaluator", ",", "n_epochs", "=", "n_epochs", ",", "n_test_rollouts", "=", "params", "[", "'n_test_rollouts'", "]", ",", "\n", "n_cycles", "=", "params", "[", "'n_cycles'", "]", ",", "n_batches", "=", "params", "[", "'n_batches'", "]", ",", "\n", "policy_save_interval", "=", "policy_save_interval", ",", "demo_file", "=", "demo_file", ",", "env_name", "=", "env_name", ",", "n_rsym", "=", "n_rsym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.main": [[220, 230], ["click.command", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "her.learn", "int", "click.Choice"], "function", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.her.learn"], ["", "@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "option", "(", "'--env'", ",", "type", "=", "str", ",", "default", "=", "'FetchReach-v1'", ",", "help", "=", "'the name of the OpenAI Gym environment that you want to train on'", ")", "\n", "@", "click", ".", "option", "(", "'--total_timesteps'", ",", "type", "=", "int", ",", "default", "=", "int", "(", "5e5", ")", ",", "help", "=", "'the number of timesteps to run'", ")", "\n", "@", "click", ".", "option", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'the random seed used to seed both the environment and the training code'", ")", "\n", "@", "click", ".", "option", "(", "'--policy_save_interval'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'the interval with which policy pickles are saved. If set to 0, only the best and latest policy will be pickled.'", ")", "\n", "@", "click", ".", "option", "(", "'--replay_strategy'", ",", "type", "=", "click", ".", "Choice", "(", "[", "'future'", ",", "'none'", "]", ")", ",", "default", "=", "'future'", ",", "help", "=", "'the HER replay strategy to be used. \"future\" uses HER, \"none\" disables HER.'", ")", "\n", "@", "click", ".", "option", "(", "'--clip_return'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'whether or not returns should be clipped'", ")", "\n", "@", "click", ".", "option", "(", "'--demo_file'", ",", "type", "=", "str", ",", "default", "=", "'PATH/TO/DEMO/DATA/FILE.npz'", ",", "help", "=", "'demo data file path'", ")", "\n", "def", "main", "(", "**", "kwargs", ")", ":", "\n", "    ", "learn", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.__init__": [[21, 33], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "env_type", ",", "n_rsym", ")", ":", "\n", "        ", "self", ".", "env_type", "=", "env_type", "\n", "self", ".", "n_rsym", "=", "n_rsym", "\n", "self", ".", "sym_plane", "=", "None", "\n", "if", "(", "self", ".", "env_type", "==", "'FetchPickAndPlace-v1'", ")", "or", "(", "self", ".", "env_type", "==", "'FetchPush-v1'", ")", "or", "(", "self", ".", "env_type", "==", "'FetchReach-v1'", ")", ":", "\n", "            ", "self", ".", "max_z_theta", "=", "MAX_Z_THETA_PICK_PUSH", "\n", "self", ".", "robot_base_x", "=", "0.695", "\n", "self", ".", "robot_base_y", "=", "0.75", "\n", "", "elif", "self", ".", "env_type", "==", "'FetchSlide-v1'", ":", "\n", "            ", "self", ".", "max_z_theta", "=", "MAX_Z_THETA_SLIDE", "\n", "self", ".", "robot_base_x", "=", "0.34", "\n", "self", ".", "robot_base_y", "=", "0.75", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.y_mirror": [[34, 36], ["mirror_learning_method.mirror_learning.sym_plane_compute"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.sym_plane_compute"], ["", "", "def", "y_mirror", "(", "self", ",", "param", ")", ":", "\n", "        ", "return", "self", ".", "sym_plane_compute", "(", "param", ",", "'y_axis'", ",", "'y_mirror'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.x_mirror": [[37, 39], ["mirror_learning_method.mirror_learning.sym_plane_compute"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.sym_plane_compute"], ["", "def", "x_mirror", "(", ")", ":", "\n", "        ", "self", ".", "sym_plane_compute", "(", "param", ",", "'x_axis'", ",", "'y_mirror'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.kaleidoscope_robot": [[41, 120], ["numpy.array", "gym.envs.robotics.rotations.euler2mat", "numpy.array", "gym.envs.robotics.rotations.euler2mat", "len", "param.copy", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.orientation_mat_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "mirror_learning_method.mirror_learning.orientation_mat_symmetric_with_rot_plane"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.orientation_mat_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.orientation_mat_symmetric_with_rot_plane"], ["", "def", "kaleidoscope_robot", "(", "self", ",", "param", ",", "z_theta", ",", "sym_axis", "=", "'y_axis'", ",", "sym_method", "=", "'y_mirror'", ")", ":", "\n", "\n", "        ", "if", "sym_axis", "==", "'y_axis'", ":", "\n", "# in linear variable, plus i; in angular variable, minus i", "\n", "            ", "i", "=", "0", "\n", "", "elif", "sym_axis", "==", "'x_axis'", ":", "\n", "            ", "i", "=", "-", "1", "\n", "\n", "", "if", "sym_method", "==", "'y_mirror'", ":", "\n", "            ", "self", ".", "sym_plane", "=", "SYM_PLANE_Y", "\n", "", "elif", "sym_method", "==", "'x_mirror'", ":", "\n", "            ", "self", ".", "sym_plane", "=", "SYM_PLANE_X", "\n", "\n", "# compute the rotation transformation & its inverse.", "\n", "", "theta", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "z_theta", "]", ")", "\n", "rot_z_theta", "=", "r_tool", ".", "euler2mat", "(", "theta", ")", "\n", "\n", "inv_theta", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "-", "z_theta", "]", ")", "\n", "inv_rot_z_theta", "=", "r_tool", ".", "euler2mat", "(", "inv_theta", ")", "\n", "# Determine the input is which element", "\n", "param_len", "=", "len", "(", "param", "[", "0", "]", ")", "\n", "#goal & achieved goal  ", "\n", "if", "param_len", "==", "3", ":", "\n", "            ", "v_l_a", "=", "param", "[", "0", "]", "[", "0", ":", "3", "]", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "True", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "0", ":", "3", "]", "=", "s_v_l_a", "\n", "\n", "", "elif", "param_len", "==", "4", ":", "#action", "\n", "            ", "v_l_a", "=", "param", "[", "0", "]", "[", "0", ":", "3", "]", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "False", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "0", ":", "3", "]", "=", "s_v_l_a", "\n", "\n", "", "elif", "param_len", "==", "10", ":", "# observation without object", "\n", "# grip pos", "\n", "            ", "v_l_a", "=", "param", "[", "0", "]", "[", "0", ":", "3", "]", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "True", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "0", ":", "3", "]", "=", "s_v_l_a", "\n", "# grip vel", "\n", "v_l_a", "=", "param", "[", "0", "]", "[", "3", ":", "6", "]", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "False", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "3", ":", "6", "]", "=", "s_v_l_a", "\n", "\n", "", "elif", "param_len", "==", "25", ":", "# observation with object", "\n", "# sym_grip_pos", "\n", "            ", "v_l_a", "=", "param", "[", "0", "]", "[", "0", ":", "3", "]", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "True", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "0", ":", "3", "]", "=", "s_v_l_a", "\n", "\n", "# sym_obj_pos", "\n", "v_l_a", "=", "param", "[", "0", "]", "[", "3", ":", "6", "]", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "True", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "3", ":", "6", "]", "=", "s_v_l_a", "\n", "\n", "# sym_obj_rel_pos", "\n", "param", "[", "0", "]", "[", "6", "]", "=", "param", "[", "0", "]", "[", "3", "]", "-", "param", "[", "0", "]", "[", "0", "]", "\n", "param", "[", "0", "]", "[", "7", "]", "=", "param", "[", "0", "]", "[", "4", "]", "-", "param", "[", "0", "]", "[", "1", "]", "\n", "param", "[", "0", "]", "[", "8", "]", "=", "param", "[", "0", "]", "[", "5", "]", "-", "param", "[", "0", "]", "[", "2", "]", "\n", "\n", "# sym_obj_rot_euler", "\n", "theta_a", "=", "param", "[", "0", "]", "[", "11", ":", "14", "]", "\n", "param", "[", "0", "]", "[", "11", ":", "14", "]", "=", "self", ".", "orientation_mat_symmetric_with_rot_plane", "(", "theta_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "\n", "# get the obj real velp ", "\n", "v_l_a", "=", "param", "[", "0", "]", "[", "14", ":", "17", "]", "+", "param", "[", "0", "]", "[", "20", ":", "23", "]", "\n", "# get the sym obj real velp", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "False", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "14", ":", "17", "]", "=", "s_v_l_a", "\n", "# get the sym grip real velp", "\n", "v_l_a", "=", "param", "[", "0", "]", "[", "20", ":", "23", "]", "\n", "s_v_l_a", "=", "self", ".", "linear_vector_symmetric_with_rot_plane", "(", "False", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "param", "[", "0", "]", "[", "20", ":", "23", "]", "=", "s_v_l_a", "\n", "# get the sym obj relative velp ", "\n", "param", "[", "0", "]", "[", "14", ":", "17", "]", "-=", "param", "[", "0", "]", "[", "20", ":", "23", "]", "\n", "\n", "# sym_obj_velr", "\n", "theta_a", "=", "param", "[", "0", "]", "[", "17", ":", "20", "]", "\n", "param", "[", "0", "]", "[", "17", ":", "20", "]", "=", "self", ".", "orientation_mat_symmetric_with_rot_plane", "(", "theta_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", "\n", "\n", "", "return", "param", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.linear_vector_symmetric_with_rot_plane": [[122, 134], ["numpy.dot", "numpy.dot", "numpy.dot.copy"], "methods", ["None"], ["", "def", "linear_vector_symmetric_with_rot_plane", "(", "self", ",", "if_pos", ",", "v_l_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", ":", "\n", "# Point 'a' position = v_l_a", "\n", "        ", "if", "if_pos", "==", "True", ":", "\n", "            ", "v_l_a", "[", "0", "]", "-=", "self", ".", "robot_base_x", "\n", "v_l_a", "[", "1", "]", "-=", "self", ".", "robot_base_y", "\n", "", "v_l_a_hat", "=", "np", ".", "dot", "(", "inv_rot_z_theta", ",", "v_l_a", ")", "\n", "v_l_a_hat", "[", "1", "+", "i", "]", "=", "-", "v_l_a_hat", "[", "1", "+", "i", "]", "\n", "s_v_l_a", "=", "np", ".", "dot", "(", "rot_z_theta", ",", "v_l_a_hat", ")", "\n", "if", "if_pos", "==", "True", ":", "\n", "            ", "s_v_l_a", "[", "0", "]", "+=", "self", ".", "robot_base_x", "\n", "s_v_l_a", "[", "1", "]", "+=", "self", ".", "robot_base_y", "\n", "", "return", "s_v_l_a", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.orientation_mat_symmetric_with_rot_plane": [[136, 157], ["gym.envs.robotics.rotations.euler2mat", "numpy.matmul", "gym.envs.robotics.rotations.mat2euler", "gym.envs.robotics.rotations.euler2mat", "numpy.matmul", "gym.envs.robotics.rotations.mat2euler", "gym.envs.robotics.rotations.mat2euler.copy"], "methods", ["None"], ["", "def", "orientation_mat_symmetric_with_rot_plane", "(", "self", ",", "theta_a", ",", "rot_z_theta", ",", "inv_rot_z_theta", ",", "i", ")", ":", "\n", "# Point 'a' orientation euler angle = theta_a", "\n", "# euler to rot matrix for transform", "\n", "        ", "v_r_a", "=", "r_tool", ".", "euler2mat", "(", "theta_a", ")", "\n", "# transform to the O cordinate from S cordinate", "\n", "v_r_a_hat", "=", "np", ".", "matmul", "(", "v_r_a", ",", "inv_rot_z_theta", ")", "\n", "\n", "# Rot matrix to euler for sym", "\n", "v_r_a_hat", "=", "r_tool", ".", "mat2euler", "(", "v_r_a_hat", ")", "\n", "\n", "# Sym on transformed S's xoz plane (y axis)", "\n", "v_r_a_hat", "[", "0", "-", "i", "]", "=", "-", "v_r_a_hat", "[", "0", "-", "i", "]", "\n", "v_r_a_hat", "[", "2", "]", "=", "-", "v_r_a_hat", "[", "2", "]", "\n", "\n", "# euler to rot matrix for transform ", "\n", "v_r_a_hat", "=", "r_tool", ".", "euler2mat", "(", "v_r_a_hat", ")", "\n", "s_v_r_a", "=", "np", ".", "matmul", "(", "v_r_a_hat", ",", "rot_z_theta", ")", "\n", "\n", "# Rot matrix to euler for return", "\n", "s_v_r_a", "=", "r_tool", ".", "mat2euler", "(", "s_v_r_a", ")", "\n", "return", "s_v_r_a", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.kaleidoscope_obj": [[158, 160], ["None"], "methods", ["None"], ["", "def", "kaleidoscope_obj", "(", ")", ":", "\n", "        ", "pass", "\n", "", "def", "mirage", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.mirage": [[160, 162], ["None"], "methods", ["None"], ["", "def", "mirage", "(", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.sym_plane_compute": [[164, 218], ["len", "param.copy"], "methods", ["None"], ["", "def", "sym_plane_compute", "(", "self", ",", "param", ",", "sym_axis", ",", "sym_method", ")", ":", "\n", "# This function is for the vanilla mirror. (x&y mirror)", "\n", "        ", "if", "sym_axis", "==", "'y_axis'", ":", "\n", "# in linear variable, plus i; in angular variable, minus i", "\n", "            ", "i", "=", "0", "\n", "", "elif", "sym_axis", "==", "'x_axis'", ":", "\n", "            ", "i", "=", "-", "1", "\n", "\n", "\n", "", "if", "sym_method", "==", "'y_mirror'", ":", "\n", "            ", "self", ".", "sym_plane", "=", "SYM_PLANE_Y", "\n", "", "elif", "sym_method", "==", "'x_mirror'", ":", "\n", "            ", "self", ".", "sym_plane", "=", "SYM_PLANE_X", "\n", "# elif sym_method == 'kaleidoscope_robot':", "\n", "#     SYM_PLANE = SYM_PLANE_Y", "\n", "\n", "\n", "", "param_len", "=", "len", "(", "param", "[", "0", "]", ")", "\n", "if", "param_len", "==", "3", ":", "#goal & achieved goal", "\n", "            ", "param", "[", "0", "]", "[", "1", "+", "i", "]", "=", "self", ".", "sym_plane", "-", "param", "[", "0", "]", "[", "1", "+", "i", "]", "\n", "\n", "", "elif", "param_len", "==", "4", ":", "#action", "\n", "            ", "param", "[", "0", "]", "[", "1", "+", "i", "]", "=", "-", "param", "[", "0", "]", "[", "1", "+", "i", "]", "\n", "\n", "", "elif", "param_len", "==", "10", ":", "# observation without object", "\n", "            ", "param", "[", "0", "]", "[", "1", "+", "i", "]", "=", "self", ".", "sym_plane", "-", "param", "[", "0", "]", "[", "1", "+", "i", "]", "\n", "# vel do not need SYM_PLANE", "\n", "param", "[", "0", "]", "[", "4", "+", "i", "]", "=", "-", "param", "[", "0", "]", "[", "4", "+", "i", "]", "\n", "\n", "", "elif", "param_len", "==", "25", ":", "# observation with object", "\n", "\n", "# sym_grip_pos", "\n", "            ", "param", "[", "0", "]", "[", "1", "+", "i", "]", "=", "self", ".", "sym_plane", "-", "param", "[", "0", "]", "[", "1", "+", "i", "]", "\n", "# sym_obj_pos", "\n", "param", "[", "0", "]", "[", "4", "+", "i", "]", "=", "self", ".", "sym_plane", "-", "param", "[", "0", "]", "[", "4", "+", "i", "]", "\n", "\n", "# sym_obj_rel_pos", "\n", "param", "[", "0", "]", "[", "6", "]", "=", "param", "[", "0", "]", "[", "3", "]", "-", "param", "[", "0", "]", "[", "0", "]", "\n", "param", "[", "0", "]", "[", "7", "]", "=", "param", "[", "0", "]", "[", "4", "]", "-", "param", "[", "0", "]", "[", "1", "]", "\n", "param", "[", "0", "]", "[", "8", "]", "=", "param", "[", "0", "]", "[", "5", "]", "-", "param", "[", "0", "]", "[", "2", "]", "\n", "\n", "# sym_obj_rot_euler", "\n", "param", "[", "0", "]", "[", "11", "-", "i", "]", "=", "-", "param", "[", "0", "]", "[", "11", "-", "i", "]", "\n", "param", "[", "0", "]", "[", "13", "]", "=", "-", "param", "[", "0", "]", "[", "13", "]", "\n", "\n", "# get the sym_obj_rel_velp & sym_grip_velp", "\n", "# no need to transform back to original pose, it can be directly compute the relative pose.", "\n", "param", "[", "0", "]", "[", "15", "+", "i", "]", "=", "-", "param", "[", "0", "]", "[", "15", "+", "i", "]", "\n", "param", "[", "0", "]", "[", "21", "+", "i", "]", "=", "-", "param", "[", "0", "]", "[", "21", "+", "i", "]", "\n", "\n", "# sym_obj_velr", "\n", "param", "[", "0", "]", "[", "17", "-", "i", "]", "=", "-", "param", "[", "0", "]", "[", "17", "-", "i", "]", "\n", "param", "[", "0", "]", "[", "19", "]", "=", "-", "param", "[", "0", "]", "[", "19", "]", "\n", "", "return", "param", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.mirror_process": [[220, 311], ["ka_episodes_set.append", "range", "numpy.random.uniform", "z_theta_set.append", "z_theta_set.copy", "z_theta_set.copy.append", "numpy.save", "ymirror_episode_set.append", "ka_episodes_set.append", "numpy.save", "ipdb.set_trace", "numpy.save", "ipdb.set_trace", "ka_episodes_tem.append", "ka_episodes_set.append", "mirror_learning_method.mirror_learning.y_mirror", "y_goals.append", "mirror_learning_method.mirror_learning.y_mirror", "y_obs.append", "mirror_learning_method.mirror_learning.y_mirror", "y_acts.append", "mirror_learning_method.mirror_learning.y_mirror", "y_achieved_goals.append", "str", "mirror_learning_method.mirror_learning.kaleidoscope_robot", "s_goals.append", "mirror_learning_method.mirror_learning.kaleidoscope_robot", "s_obs.append", "mirror_learning_method.mirror_learning.kaleidoscope_robot", "s_acts.append", "mirror_learning_method.mirror_learning.kaleidoscope_robot", "s_achieved_goals.append", "goal.copy", "mirror_learning_method.mirror_learning.copy", "ob.copy", "mirror_learning_method.mirror_learning.copy", "act.copy", "mirror_learning_method.mirror_learning.copy", "achieved_goal.copy", "mirror_learning_method.mirror_learning.copy", "goal.copy", "mirror_learning_method.mirror_learning.copy", "ob.copy", "mirror_learning_method.mirror_learning.copy", "act.copy", "mirror_learning_method.mirror_learning.copy", "achieved_goal.copy", "mirror_learning_method.mirror_learning.copy", "str", "str"], "methods", ["home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.save", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.save", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.ddpg.DDPG.save", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.y_mirror", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.y_mirror", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.y_mirror", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.y_mirror", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.kaleidoscope_robot", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.kaleidoscope_robot", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.kaleidoscope_robot", "home.repos.pwc.inspect_result.YijiongLin_ITER_KER_GER.her.mirror_learning_method.mirror_learning.kaleidoscope_robot"], ["", "def", "mirror_process", "(", "self", ",", "obs", ",", "acts", ",", "goals", ",", "achieved_goals", ")", ":", "\n", "\n", "\n", "# ---------------------------recursive symmetry------------------------------------------------", "\n", "        ", "ka_episodes_set", "=", "[", "]", "\n", "ka_episodes_set", ".", "append", "(", "[", "obs", ",", "acts", ",", "goals", ",", "achieved_goals", "]", ")", "\n", "z_theta_set", "=", "[", "]", "\n", "\n", "# If self.n_rsym == None, means use vanillar her, or in test mode.", "\n", "if", "self", ".", "n_rsym", "==", "None", "or", "self", ".", "n_rsym", "==", "0", ":", "\n", "            ", "if", "BOOL_OUTPUT_ONE_EPISODE_TRAJ", ":", "\n", "                ", "np", ".", "save", "(", "(", "'/home/bourne/data_plot/all_n_rsym_trajs/sym_'", "+", "str", "(", "self", ".", "n_rsym", ")", "+", "'.npy'", ")", ",", "ka_episodes_set", ")", "\n", "set_trace", "(", ")", "\n", "", "return", "ka_episodes_set", "\n", "\n", "\n", "# not finished yet", "\n", "# self.compute_sym_number(goals[0][0])", "\n", "\n", "# One symmetry will be done in the y mirror, so here n_rsym need to minus 1 ", "\n", "", "for", "_", "in", "range", "(", "self", ".", "n_rsym", "-", "1", ")", ":", "\n", "            ", "z_theta", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "self", ".", "max_z_theta", ")", "\n", "z_theta_set", ".", "append", "(", "z_theta", ")", "\n", "\n", "", "if", "BOOL_OUTPUT_ONE_EPISODE_TRAJ", ":", "\n", "#output the symmetric thetas for one step ", "\n", "            ", "output_theta_set", "=", "z_theta_set", ".", "copy", "(", ")", "\n", "output_theta_set", ".", "append", "(", "0", ")", "\n", "save_dir", "=", "'/home/bourne/data_plot/all_n_rsym_thetas/thetas_n_rsym_'", "+", "str", "(", "self", ".", "n_rsym", ")", "+", "'.npy'", "\n", "np", ".", "save", "(", "save_dir", ",", "output_theta_set", ")", "\n", "\n", "", "for", "z_theta", "in", "z_theta_set", ":", "\n", "            ", "ka_episodes_tem", "=", "[", "]", "\n", "for", "[", "o_obs", ",", "o_acts", ",", "o_goals", ",", "o_achieved_goals", "]", "in", "ka_episodes_set", ":", "\n", "                ", "s_goals", "=", "[", "]", "\n", "s_obs", "=", "[", "]", "\n", "s_acts", "=", "[", "]", "\n", "s_achieved_goals", "=", "[", "]", "\n", "for", "goal", "in", "o_goals", ":", "\n", "                    ", "s_goal", "=", "self", ".", "kaleidoscope_robot", "(", "goal", ".", "copy", "(", ")", ",", "z_theta", ")", "\n", "s_goals", ".", "append", "(", "s_goal", ".", "copy", "(", ")", ")", "\n", "\n", "", "for", "ob", "in", "o_obs", ":", "\n", "                    ", "s_ob", "=", "self", ".", "kaleidoscope_robot", "(", "ob", ".", "copy", "(", ")", ",", "z_theta", ")", "\n", "s_obs", ".", "append", "(", "s_ob", ".", "copy", "(", ")", ")", "\n", "\n", "", "for", "act", "in", "o_acts", ":", "\n", "                    ", "s_act", "=", "self", ".", "kaleidoscope_robot", "(", "act", ".", "copy", "(", ")", ",", "z_theta", ")", "\n", "s_acts", ".", "append", "(", "s_act", ".", "copy", "(", ")", ")", "\n", "\n", "", "for", "achieved_goal", "in", "o_achieved_goals", ":", "\n", "                    ", "s_achieved_goal", "=", "self", ".", "kaleidoscope_robot", "(", "achieved_goal", ".", "copy", "(", ")", ",", "z_theta", ")", "\n", "s_achieved_goals", ".", "append", "(", "s_achieved_goal", ".", "copy", "(", ")", ")", "\n", "\n", "", "ka_episodes_tem", ".", "append", "(", "[", "s_obs", ",", "s_acts", ",", "s_goals", ",", "s_achieved_goals", "]", ")", "\n", "", "for", "ka_episode", "in", "ka_episodes_tem", ":", "\n", "                ", "ka_episodes_set", ".", "append", "(", "ka_episode", ")", "\n", "# ---------------------------end", "\n", "\n", "#--------------- All datas are symmetrized with y axis.", "\n", "", "", "ymirror_episode_set", "=", "[", "]", "\n", "for", "[", "o_obs", ",", "o_acts", ",", "o_goals", ",", "o_achieved_goals", "]", "in", "ka_episodes_set", ":", "\n", "            ", "y_goals", "=", "[", "]", "\n", "y_obs", "=", "[", "]", "\n", "y_acts", "=", "[", "]", "\n", "y_achieved_goals", "=", "[", "]", "\n", "for", "goal", "in", "o_goals", ":", "\n", "                ", "y_goal", "=", "self", ".", "y_mirror", "(", "goal", ".", "copy", "(", ")", ")", "\n", "y_goals", ".", "append", "(", "y_goal", ".", "copy", "(", ")", ")", "\n", "\n", "", "for", "ob", "in", "o_obs", ":", "\n", "                ", "y_ob", "=", "self", ".", "y_mirror", "(", "ob", ".", "copy", "(", ")", ")", "\n", "y_obs", ".", "append", "(", "y_ob", ".", "copy", "(", ")", ")", "\n", "\n", "", "for", "act", "in", "o_acts", ":", "\n", "                ", "y_act", "=", "self", ".", "y_mirror", "(", "act", ".", "copy", "(", ")", ")", "\n", "y_acts", ".", "append", "(", "y_act", ".", "copy", "(", ")", ")", "\n", "\n", "", "for", "achieved_goal", "in", "o_achieved_goals", ":", "\n", "                ", "y_achieved_goal", "=", "self", ".", "y_mirror", "(", "achieved_goal", ".", "copy", "(", ")", ")", "\n", "y_achieved_goals", ".", "append", "(", "y_achieved_goal", ".", "copy", "(", ")", ")", "\n", "", "ymirror_episode_set", ".", "append", "(", "[", "y_obs", ",", "y_acts", ",", "y_goals", ",", "y_achieved_goals", "]", ")", "\n", "", "for", "ymirror_episode", "in", "ymirror_episode_set", ":", "\n", "            ", "ka_episodes_set", ".", "append", "(", "ymirror_episode", ")", "\n", "\n", "# output the trajs for one step", "\n", "", "if", "BOOL_OUTPUT_ONE_EPISODE_TRAJ", ":", "\n", "            ", "np", ".", "save", "(", "(", "'/home/bourne/data_plot/all_n_rsym_trajs/trajs_n_rsym_'", "+", "str", "(", "self", ".", "n_rsym", ")", "+", "'.npy'", ")", ",", "ka_episodes_set", ")", "\n", "set_trace", "(", ")", "\n", "\n", "", "return", "ka_episodes_set", "\n", "#--------------- end.", "\n"]]}