{"home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.__init__": [[22, 130], ["os.path.join", "set", "logging.info", "questeval_metric.QuestEval._load_all_models", "logging.warning", "logging.warning", "os.listdir", "datasets.load_metric", "torch.cuda.is_available", "spacy.load", "LinearizeWebnlgInput", "logging.warning", "download", "spacy.load"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._load_all_models"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "task", ":", "str", "=", "\"text2text\"", ",", "\n", "language", ":", "str", "=", "\"en\"", ",", "\n", "answer_types", ":", "Tuple", "=", "(", "'NER'", ",", "'NOUN'", ")", ",", "\n", "list_scores", ":", "Tuple", "=", "(", "'answerability'", ",", "'bertscore'", ",", "'f1'", ")", ",", "\n", "src_preproc_pipe", "=", "None", ",", "\n", "do_weighter", ":", "bool", "=", "False", ",", "\n", "do_consistency", ":", "bool", "=", "False", ",", "\n", "qg_batch_size", ":", "int", "=", "36", ",", "\n", "clf_batch_size", ":", "int", "=", "48", ",", "\n", "limit_sent", ":", "int", "=", "5", ",", "\n", "reduction_multi_refs", ":", "Callable", "=", "max", ",", "\n", "no_cuda", ":", "bool", "=", "False", ",", "\n", "use_cache", ":", "bool", "=", "True", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Main class for the QuestEval metric\n\n        Args:\n            task (:str):\n                the task to evaluate with QuestEval\n\n        Return:\n            :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n        \"\"\"", "\n", "\"\"\"\n        format for the json logs:\n            hash(txt) #json file name\n                {\n                'type': type\n                'text': text or pointer if image\n                'self': {answer_type_1: {'answers': [answers],\n                                         {'model_QG_1': {'questions': [questions],\n                                                         'model_Weighter_1': [weights]\n                                                        }\n                                         }\n                        }\n                'asked': {question_1: {model_QA_1:  'answer': answer,\n                                                    'answerability': score\n                                                    'ground_truth': {answer_1: {'f1': score,\n                                                                              'bertscore: score}\n                                    }\n                        }\n                }\n        \"\"\"", "\n", "self", ".", "AVAILABLE_LANGUAGES", "=", "(", "\"en\"", ",", ")", "# todo: \"multi\"", "\n", "self", ".", "AVAILABLE_TASKS", "=", "(", "\"text2text\"", ",", "\"summarization\"", ",", "\"text_simplification\"", ",", "\"data2text\"", ")", "\n", "\n", "if", "task", "not", "in", "self", ".", "AVAILABLE_TASKS", ":", "\n", "            ", "logging", ".", "warning", "(", "f\"Task {task} is not known. Setting the default text2text task. \"", ")", "\n", "task", "=", "\"text2text\"", "\n", "\n", "", "if", "language", "not", "in", "self", ".", "AVAILABLE_LANGUAGES", ":", "\n", "            ", "raise", "(", "\n", "f\"Language {language} is not implemented. The list of available languages are: {self.AVAILABLE_LANGUAGES}.\"", "\n", ")", "\n", "\n", "", "if", "task", "==", "'summarization'", "and", "do_weighter", "is", "False", ":", "\n", "            ", "logging", ".", "warning", "(", "\n", "\"Task is summarization but the weighter is deactivate. Set do_weighter=True to activate it when loading QuestEval.\"", "\n", ")", "\n", "\n", "", "self", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "DIR", ",", "'logs'", ")", "\n", "self", ".", "hash_files", "=", "set", "(", "os", ".", "listdir", "(", "self", ".", "log_dir", ")", ")", "\n", "self", ".", "use_cache", "=", "use_cache", "\n", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "language", "=", "language", "\n", "\n", "self", ".", "answer_types", "=", "answer_types", "\n", "self", ".", "src_preproc_pipe", "=", "src_preproc_pipe", "\n", "self", ".", "limit_sent", "=", "limit_sent", "\n", "self", ".", "sep", "=", "\"</s>\"", "\n", "self", ".", "qg_prefix", "=", "None", "\n", "self", ".", "qg_batch_size", "=", "qg_batch_size", "\n", "self", ".", "clf_batch_size", "=", "clf_batch_size", "\n", "self", ".", "device", "=", "'cuda'", "if", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "no_cuda", ")", "else", "'cpu'", "\n", "\n", "self", ".", "reduction_multi_refs", "=", "reduction_multi_refs", "\n", "self", ".", "do_consistency", "=", "do_consistency", "\n", "self", ".", "do_weighter", "=", "do_weighter", "\n", "self", ".", "list_scores", "=", "list_scores", "\n", "if", "'bertscore'", "in", "self", ".", "list_scores", ":", "\n", "            ", "self", ".", "metric_BERTScore", "=", "load_metric", "(", "\"bertscore\"", ")", "\n", "\n", "", "if", "language", "==", "'en'", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "spacy_pipeline", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "", "except", "OSError", ":", "\n", "                ", "logging", ".", "warning", "(", "\"Downloading language model for the spaCy model.\"", ")", "\n", "from", "spacy", ".", "cli", "import", "download", "\n", "download", "(", "'en_core_web_sm'", ")", "\n", "self", ".", "spacy_pipeline", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "\n", "", "", "if", "self", ".", "src_preproc_pipe", "is", "None", ":", "\n", "            ", "if", "task", "==", "'data2text'", ":", "\n", "                ", "\"\"\"\n                structured tables should be linearized for our QA/QG format this way:\n                'name [ The Eagle ] , eatType [ coffee shop ] , food [ French ] , priceRange [ \u00a3 2 0 - 2 5 ] , customer rating [ 3 out of 5 ] , area [ city centre ] , familyFriendly [ yes ] , near [ Burger King ]'\n                we handle by default the preprocessing of the table for webnlg given the GEM format (https://gem-benchmark.com/)\n                if your tables are in an other format, please pass a custom function for src_preproc_pipe\n                \"\"\"", "\n", "from", "questeval", ".", "utils", "import", "LinearizeWebnlgInput", "\n", "self", ".", "src_preproc_pipe", "=", "LinearizeWebnlgInput", "(", "spacy_pipeline", "=", "self", ".", "spacy_pipeline", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"Loading the models, it can take time to download at first time.\"", ")", "\n", "self", ".", "models", "=", "self", ".", "_load_all_models", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._load_all_models": [[131, 166], ["models.keys", "dict", "models[].keys", "questeval_metric.QuestEval.get_model", "questeval_metric.QuestEval.get_model", "models.get", "dict", "type"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.get_model", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.get_model"], ["", "def", "_load_all_models", "(", "self", ")", "->", "Dict", ":", "\n", "# Textual hypothesis", "\n", "        ", "models", "=", "{", "\"hyp\"", ":", "{", "}", "}", "\n", "if", "self", ".", "language", "==", "'en'", ":", "\n", "            ", "models", "[", "'hyp'", "]", "[", "'QA'", "]", "=", "f'{HF_ORGANIZATION}/t5-qa_squad2neg-en'", "\n", "models", "[", "'hyp'", "]", "[", "'QG'", "]", "=", "f'{HF_ORGANIZATION}/t5-qg_squad1-en'", "\n", "", "else", ":", "\n", "            ", "raise", "(", "\"Multilingual evaluation not handled yet.\"", ")", "\n", "\n", "# (if) multimodal sources", "\n", "", "if", "self", ".", "task", "==", "\"data2text\"", ":", "\n", "            ", "models", "[", "'src'", "]", "=", "dict", "(", ")", "\n", "models", "[", "'src'", "]", "[", "'QA'", "]", "=", "f'{HF_ORGANIZATION}/t5-qa_webnlg_synth-en'", "\n", "models", "[", "'src'", "]", "[", "'QG'", "]", "=", "f'{HF_ORGANIZATION}/t5-qg_webnlg_synth-en'", "\n", "\n", "# Loading all the different models", "\n", "", "for", "modality", "in", "models", ".", "keys", "(", ")", ":", "\n", "            ", "for", "task", "in", "models", "[", "modality", "]", ".", "keys", "(", ")", ":", "\n", "                ", "if", "not", "type", "(", "models", "[", "modality", "]", "[", "task", "]", ")", "==", "str", ":", "\n", "                    ", "continue", "\n", "", "models", "[", "modality", "]", "[", "task", "]", "=", "self", ".", "get_model", "(", "model_name", "=", "models", "[", "modality", "]", "[", "task", "]", ")", "\n", "\n", "# Loading the weighter", "\n", "", "", "models", "[", "'Weighter'", "]", "=", "None", "\n", "if", "self", ".", "do_weighter", ":", "\n", "            ", "models", "[", "'Weighter'", "]", "=", "self", ".", "get_model", "(", "model_name", "=", "f'{HF_ORGANIZATION}/t5-weighter_cnndm-en'", ")", "\n", "\n", "# Linking already loaded models for the other keys", "\n", "", "for", "k", "in", "[", "\"src\"", ",", "\"ref\"", "]", ":", "\n", "            ", "if", "models", ".", "get", "(", "k", ")", "==", "None", ":", "\n", "                ", "models", "[", "k", "]", "=", "dict", "(", ")", "\n", "models", "[", "k", "]", "[", "'QA'", "]", "=", "models", "[", "'hyp'", "]", "[", "'QA'", "]", "\n", "models", "[", "k", "]", "[", "'QG'", "]", "=", "models", "[", "'hyp'", "]", "[", "'QG'", "]", "\n", "\n", "", "", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.corpus_questeval": [[167, 209], ["range", "all", "all", "len", "logging.info", "questeval_metric.QuestEval._batch_questeval", "numpy.average", "len", "len", "len", "len", "len", "isinstance", "isinstance", "set", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._batch_questeval"], ["", "def", "corpus_questeval", "(", "\n", "self", ",", "\n", "hypothesis", ":", "List", "[", "str", "]", ",", "\n", "sources", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "list_references", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "batch_size", ":", "int", "=", "512", "\n", ")", "->", "Dict", ":", "\n", "\n", "        ", "assert", "hypothesis", "is", "not", "None", "\n", "\n", "having_sources", "=", "(", "\n", "sources", "is", "not", "None", "\n", "and", "all", "(", "[", "isinstance", "(", "s", ",", "str", ")", "for", "s", "in", "sources", "]", ")", "# Only str allowed", "\n", ")", "\n", "having_references", "=", "(", "\n", "list_references", "is", "not", "None", "\n", "and", "all", "(", "[", "isinstance", "(", "r", ",", "str", ")", "for", "rs", "in", "list_references", "for", "r", "in", "rs", "]", ")", "# Only str allowed", "\n", "and", "len", "(", "set", "(", "[", "len", "(", "rs", ")", "for", "rs", "in", "list_references", "]", ")", ")", "==", "1", "# Same number of refs per ex", "\n", ")", "\n", "\n", "assert", "having_sources", "or", "having_references", ",", "\"You need to provide at least correct sources or correct references.\"", "\n", "if", "having_references", ":", "\n", "            ", "assert", "len", "(", "list_references", ")", "==", "len", "(", "hypothesis", ")", "\n", "", "if", "having_sources", ":", "\n", "            ", "assert", "len", "(", "sources", ")", "==", "len", "(", "hypothesis", ")", "\n", "\n", "", "scores", "=", "[", "]", "\n", "for", "ex_idx", "in", "range", "(", "0", ",", "len", "(", "hypothesis", ")", ",", "batch_size", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Total examples: {len(hypothesis)}. Proceeding the examples {ex_idx}\"", ")", "\n", "batch_sources", ",", "batch_list_references", "=", "None", ",", "None", "\n", "if", "having_sources", ":", "\n", "                ", "batch_sources", "=", "sources", "[", "ex_idx", ":", "ex_idx", "+", "batch_size", "]", "\n", "", "if", "having_references", ":", "\n", "                ", "batch_list_references", "=", "list_references", "[", "ex_idx", ":", "ex_idx", "+", "batch_size", "]", "\n", "", "scores", "+=", "self", ".", "_batch_questeval", "(", "\n", "hypothesis", "=", "hypothesis", "[", "ex_idx", ":", "ex_idx", "+", "batch_size", "]", ",", "\n", "sources", "=", "batch_sources", ",", "\n", "list_references", "=", "batch_list_references", ",", "\n", ")", "\n", "\n", "", "result", "=", "{", "'corpus_score'", ":", "np", ".", "average", "(", "scores", ")", ",", "'ex_level_scores'", ":", "scores", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._batch_questeval": [[210, 278], ["dict", "questeval_metric.QuestEval._texts2logs", "questeval_metric.QuestEval._compute_answer_similarity_scores", "zip", "questeval_metric.QuestEval._serialize_logs", "questeval_metric.QuestEval._texts2logs", "max", "max", "max", "list_compared_logs.append", "range", "questeval_metric.QuestEval._serialize_logs", "scores.append", "questeval_metric.QuestEval._compute_question_answering", "questeval_metric.QuestEval._compute_question_answering", "questeval_metric.QuestEval._compute_answer_similarity_scores", "questeval_metric.QuestEval._serialize_logs", "questeval_metric.QuestEval._serialize_logs", "len", "min", "max", "questeval_metric.QuestEval._texts2logs", "max", "max", "max", "list_compared_logs.append", "range", "questeval_metric.QuestEval._calculate_score_from_logs", "questeval_metric.QuestEval._compute_question_answering", "questeval_metric.QuestEval._compute_question_answering", "questeval_metric.QuestEval._compute_answer_similarity_scores", "questeval_metric.QuestEval._serialize_logs", "questeval_metric.QuestEval._serialize_logs", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._texts2logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_answer_similarity_scores", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._serialize_logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._texts2logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._serialize_logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_answering", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_answering", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_answer_similarity_scores", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._serialize_logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._serialize_logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._texts2logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._calculate_score_from_logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_answering", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_answering", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_answer_similarity_scores", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._serialize_logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._serialize_logs"], ["", "def", "_batch_questeval", "(", "\n", "self", ",", "\n", "hypothesis", ":", "List", "[", "str", "]", ",", "\n", "sources", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "list_references", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "float", "]", ":", "\n", "\n", "        ", "list_compared_logs", "=", "[", "]", "\n", "d_loaded_logs", "=", "dict", "(", ")", "\n", "\n", "# Hypothesis", "\n", "hyp_logs", ",", "hyp_hashes", ",", "modified_logs", "=", "self", ".", "_texts2logs", "(", "hypothesis", ",", "type_logs", "=", "'hyp'", ",", "d_loaded_logs", "=", "d_loaded_logs", ")", "\n", "if", "modified_logs", ":", "\n", "            ", "self", ".", "_serialize_logs", "(", "hyp_logs", ",", "hyp_hashes", ")", "\n", "\n", "# Source", "\n", "", "if", "sources", "is", "not", "None", ":", "\n", "            ", "src_logs", ",", "src_hashes", ",", "modified_logs", "=", "self", ".", "_texts2logs", "(", "sources", ",", "type_logs", "=", "'src'", ",", "d_loaded_logs", "=", "d_loaded_logs", ")", "\n", "# Asking the questions on the compared text", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_question_answering", "(", "src_logs", ",", "hyp_logs", ",", "'src'", ",", "'hyp'", ")", ",", "modified_logs", ")", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_question_answering", "(", "hyp_logs", ",", "src_logs", ",", "'hyp'", ",", "'src'", ")", ",", "modified_logs", ")", "\n", "# Compute the similarity scores", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_answer_similarity_scores", "(", "src_logs", ",", "type_logs", "=", "'src'", ")", ",", "modified_logs", ")", "\n", "# Serialise logs", "\n", "if", "modified_logs", ":", "\n", "                ", "self", ".", "_serialize_logs", "(", "src_logs", ",", "src_hashes", ")", "\n", "self", ".", "_serialize_logs", "(", "hyp_logs", ",", "hyp_hashes", ")", "\n", "", "list_compared_logs", ".", "append", "(", "src_logs", ")", "\n", "\n", "# Reference", "\n", "", "if", "list_references", "is", "not", "None", ":", "\n", "            ", "len_refs", "=", "[", "len", "(", "refs", ")", "for", "refs", "in", "list_references", "]", "\n", "assert", "min", "(", "len_refs", ")", "==", "max", "(", "len_refs", ")", ",", "\"The number of references used to compute the score among the example should  be consistant.\"", "\n", "for", "i_ref", "in", "range", "(", "len_refs", "[", "0", "]", ")", ":", "\n", "                ", "references", "=", "[", "refs", "[", "i_ref", "]", "for", "refs", "in", "list_references", "]", "\n", "ref_logs", ",", "ref_hashes", ",", "modified_logs", "=", "self", ".", "_texts2logs", "(", "references", ",", "type_logs", "=", "'ref'", ",", "d_loaded_logs", "=", "d_loaded_logs", ")", "\n", "# Asking the questions on the compared text", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_question_answering", "(", "ref_logs", ",", "hyp_logs", ",", "'ref'", ",", "'hyp'", ")", ",", "modified_logs", ")", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_question_answering", "(", "hyp_logs", ",", "ref_logs", ",", "'hyp'", ",", "'ref'", ")", ",", "modified_logs", ")", "\n", "# Compute the similarity scores", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_answer_similarity_scores", "(", "ref_logs", ",", "type_logs", "=", "'ref'", ")", ",", "modified_logs", ")", "\n", "# Serialise logs", "\n", "if", "modified_logs", ":", "\n", "                    ", "self", ".", "_serialize_logs", "(", "ref_logs", ",", "ref_hashes", ")", "\n", "self", ".", "_serialize_logs", "(", "hyp_logs", ",", "hyp_hashes", ")", "\n", "", "list_compared_logs", ".", "append", "(", "ref_logs", ")", "\n", "\n", "# Compute the similarity scores for hyp", "\n", "", "", "modified_logs", "=", "self", ".", "_compute_answer_similarity_scores", "(", "hyp_logs", ",", "type_logs", "=", "'hyp'", ")", "\n", "# Serialise hyp logs", "\n", "if", "modified_logs", ":", "\n", "            ", "self", ".", "_serialize_logs", "(", "hyp_logs", ",", "hyp_hashes", ")", "\n", "\n", "", "list_compared_logs", "=", "[", "\n", "[", "\n", "list_compared_logs", "[", "i", "]", "[", "j", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_compared_logs", ")", ")", "\n", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "list_compared_logs", "[", "0", "]", ")", ")", "\n", "]", "\n", "\n", "# Calculate Score", "\n", "scores", "=", "[", "]", "\n", "for", "hyps_log", ",", "compared_logs", "in", "zip", "(", "hyp_logs", ",", "list_compared_logs", ")", ":", "\n", "            ", "scores", ".", "append", "(", "self", ".", "_calculate_score_from_logs", "(", "hyps_log", ",", "compared_logs", ")", ")", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._texts2logs": [[279, 304], ["questeval_metric.QuestEval._load_logs", "max", "max", "questeval_metric.QuestEval._compute_answer_selection", "questeval_metric.QuestEval._compute_question_generation", "max", "questeval_metric.QuestEval.src_preproc_pipe", "questeval_metric.QuestEval._compute_question_answering", "questeval_metric.QuestEval._compute_weighter"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._load_logs", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_answer_selection", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_generation", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_answering", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_weighter"], ["", "def", "_texts2logs", "(", "\n", "self", ",", "\n", "texts", ":", "List", "[", "str", "]", ",", "\n", "type_logs", ":", "str", ",", "\n", "d_loaded_logs", ":", "Dict", "\n", ")", ":", "\n", "        ", "modified_logs", "=", "False", "\n", "\n", "# Preprocessing", "\n", "if", "type_logs", "==", "'src'", "and", "self", ".", "src_preproc_pipe", "is", "not", "None", ":", "\n", "            ", "texts", "=", "[", "self", ".", "src_preproc_pipe", "(", "source", ")", "for", "source", "in", "texts", "]", "\n", "\n", "", "logs", ",", "logs_hashes", "=", "self", ".", "_load_logs", "(", "texts", ",", "type_logs", ",", "d_loaded_logs", ")", "\n", "# Selecting the answers", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_answer_selection", "(", "logs", ",", "type_logs", ")", ",", "modified_logs", ")", "\n", "#  Generating the questions", "\n", "modified_logs", "=", "max", "(", "self", ".", "_compute_question_generation", "(", "logs", ",", "type_logs", ")", ",", "modified_logs", ")", "\n", "# Asking the questions on itself (Round trip consistency)", "\n", "if", "self", ".", "do_consistency", ":", "\n", "            ", "modified_logs", "=", "(", "self", ".", "_compute_question_answering", "(", "logs", ",", "logs", ",", "type_logs", ",", "type_logs", ")", ",", "modified_logs", ")", "\n", "# Weighter", "\n", "", "if", "type_logs", "==", "'src'", "and", "self", ".", "do_weighter", ":", "\n", "            ", "modified_logs", "=", "max", "(", "self", ".", "_compute_weighter", "(", "logs", ",", "type_logs", "=", "'src'", ")", ",", "modified_logs", ")", "\n", "\n", "", "return", "logs", ",", "logs_hashes", ",", "modified_logs", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._load_logs": [[305, 343], ["questeval.utils.text2hash", "logs.append", "log_hashs.append", "dict", "dict", "os.path.join", "open", "json.load", "all", "isinstance", "isinstance", "isinstance", "isinstance", "questeval_metric.QuestEval.hash_files.remove", "os.remove", "questeval_metric.QuestEval.hash_files.remove", "os.remove"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.text2hash"], ["", "def", "_load_logs", "(", "\n", "self", ",", "\n", "texts", ":", "List", ",", "\n", "type_logs", ":", "str", ",", "\n", "d_loaded_logs", ":", "Dict", "\n", ")", "->", "Tuple", "[", "List", "[", "Dict", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "logs", ",", "log_hashs", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "text", "in", "texts", ":", "\n", "            ", "log_hash", "=", "text2hash", "(", "text", ")", "\n", "if", "log_hash", "not", "in", "d_loaded_logs", ":", "\n", "                ", "log", "=", "{", "'type'", ":", "type_logs", ",", "'text'", ":", "text", ",", "'self'", ":", "dict", "(", ")", ",", "'asked'", ":", "dict", "(", ")", "}", "\n", "if", "not", "(", "self", ".", "use_cache", "and", "log_hash", "in", "self", ".", "hash_files", "and", "text", "!=", "\"\"", ")", ":", "\n", "                    ", "temp", "=", "1", "\n", "", "if", "self", ".", "use_cache", "and", "log_hash", "in", "self", ".", "hash_files", "and", "text", "!=", "\"\"", ":", "\n", "                    ", "cached_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "log_dir", ",", "log_hash", ")", "\n", "try", ":", "\n", "                        ", "with", "open", "(", "cached_path", ",", "'r'", ")", "as", "f_log", ":", "\n", "                            ", "tmp", "=", "json", ".", "load", "(", "f_log", ")", "\n", "assert", "all", "(", "[", "k", "in", "log", "for", "k", "in", "[", "'type'", ",", "'text'", ",", "'self'", ",", "'asked'", "]", "]", ")", "\n", "assert", "isinstance", "(", "log", "[", "'type'", "]", ",", "str", ")", "\n", "assert", "isinstance", "(", "log", "[", "'text'", "]", ",", "str", ")", "\n", "assert", "isinstance", "(", "log", "[", "'self'", "]", ",", "dict", ")", "\n", "assert", "isinstance", "(", "log", "[", "'asked'", "]", ",", "dict", ")", "\n", "log", "=", "tmp", "\n", "", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "                        ", "self", ".", "hash_files", ".", "remove", "(", "log_hash", ")", "\n", "os", ".", "remove", "(", "cached_path", ")", "\n", "", "except", "AssertionError", ":", "\n", "                        ", "self", ".", "hash_files", ".", "remove", "(", "log_hash", ")", "\n", "os", ".", "remove", "(", "cached_path", ")", "\n", "\n", "", "", "d_loaded_logs", "[", "log_hash", "]", "=", "log", "\n", "\n", "", "logs", ".", "append", "(", "d_loaded_logs", "[", "log_hash", "]", ")", "\n", "log_hashs", ".", "append", "(", "log_hash", ")", "\n", "\n", "", "return", "logs", ",", "log_hashs", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._serialize_logs": [[344, 352], ["zip", "open", "json.dump", "os.path.join"], "methods", ["None"], ["", "def", "_serialize_logs", "(", "\n", "self", ",", "\n", "logs", ":", "List", "[", "Dict", "]", ",", "\n", "hashes", ":", "List", "[", "str", "]", "\n", ")", "->", "None", ":", "\n", "        ", "for", "log", ",", "hash", "in", "zip", "(", "logs", ",", "hashes", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "log_dir", ",", "hash", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "                ", "json", ".", "dump", "(", "log", ",", "outfile", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.open_log_from_text": [[353, 361], ["questeval.utils.text2hash", "open", "json.load", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.text2hash"], ["", "", "", "def", "open_log_from_text", "(", "self", ",", "text", ":", "str", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"\n        Function to open a serialised log and analyse it.\n        \"\"\"", "\n", "log_hash", "=", "text2hash", "(", "text", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "log_dir", ",", "log_hash", ")", ",", "'r'", ")", "as", "f_log", ":", "\n", "            ", "log", "=", "json", ".", "load", "(", "f_log", ")", "\n", "", "return", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_answer_selection": [[362, 381], ["questeval_metric.QuestEval._get_answer_types", "enumerate", "len", "len", "questeval_metric.QuestEval._predict_self_answers", "range", "dict", "to_do_exs.append", "to_do_exs_idxs.append", "len"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_self_answers"], ["", "def", "_compute_answer_selection", "(", "\n", "self", ",", "\n", "logs", ":", "List", "[", "Dict", "]", ",", "\n", "type_logs", ":", "str", "\n", ")", "->", "None", ":", "\n", "        ", "for", "answer_type", "in", "self", ".", "_get_answer_types", "(", "type_logs", ")", ":", "\n", "            ", "to_do_exs", ",", "to_do_exs_idxs", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "log", "in", "enumerate", "(", "logs", ")", ":", "\n", "                ", "if", "answer_type", "not", "in", "log", "[", "'self'", "]", "and", "log", "[", "'text'", "]", "!=", "''", ":", "\n", "                    ", "log", "[", "'self'", "]", "[", "answer_type", "]", "=", "dict", "(", ")", "\n", "to_do_exs", ".", "append", "(", "log", "[", "'text'", "]", ")", "\n", "to_do_exs_idxs", ".", "append", "(", "idx", ")", "\n", "\n", "", "", "if", "len", "(", "to_do_exs", ")", "!=", "0", ":", "\n", "                ", "list_answers", "=", "self", ".", "_predict_self_answers", "(", "to_do_exs", ",", "answer_type", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "list_answers", ")", ")", ":", "\n", "                    ", "logs", "[", "to_do_exs_idxs", "[", "i", "]", "]", "[", "'self'", "]", "[", "answer_type", "]", "[", "'answers'", "]", "=", "list_answers", "[", "i", "]", "\n", "\n", "", "", "", "return", "len", "(", "to_do_exs", ")", "!=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_generation": [[382, 410], ["questeval_metric.QuestEval._get_qg_hash", "enumerate", "questeval_metric.QuestEval._get_answer_types", "len", "questeval_metric.QuestEval._predict_questions", "range", "len", "len", "[].append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_questions"], ["", "def", "_compute_question_generation", "(", "\n", "self", ",", "\n", "logs", ":", "List", "[", "Dict", "]", ",", "\n", "type_logs", ":", "str", "\n", ")", "->", "None", ":", "\n", "        ", "name_model_qg", "=", "self", ".", "_get_qg_hash", "(", "type_logs", ")", "\n", "\n", "to_do_exs", ",", "to_do_exs_idxs", ",", "to_do_exs_types", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "log", "in", "enumerate", "(", "logs", ")", ":", "\n", "            ", "if", "log", "[", "'text'", "]", "==", "''", ":", "\n", "                ", "continue", "\n", "", "for", "answer_type", "in", "self", ".", "_get_answer_types", "(", "type_logs", ")", ":", "\n", "                ", "if", "name_model_qg", "not", "in", "log", "[", "'self'", "]", "[", "answer_type", "]", ":", "\n", "                    ", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "=", "{", "'questions'", ":", "[", "]", "}", "\n", "\n", "to_do_exs", "+=", "[", "(", "a", ",", "log", "[", "'text'", "]", ")", "for", "a", "in", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "'answers'", "]", "]", "\n", "to_do_exs_idxs", "+=", "[", "idx", "]", "*", "len", "(", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "'answers'", "]", ")", "\n", "to_do_exs_types", "+=", "[", "answer_type", "]", "*", "len", "(", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "'answers'", "]", ")", "\n", "\n", "", "", "", "if", "len", "(", "to_do_exs", ")", "!=", "0", ":", "\n", "            ", "question_texts", "=", "self", ".", "_predict_questions", "(", "to_do_exs", ",", "type_logs", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "question_texts", ")", ")", ":", "\n", "                ", "idx", "=", "to_do_exs_idxs", "[", "i", "]", "\n", "answer_type", "=", "to_do_exs_types", "[", "i", "]", "\n", "question", "=", "question_texts", "[", "i", "]", "\n", "logs", "[", "idx", "]", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "[", "'questions'", "]", ".", "append", "(", "question", ")", "\n", "\n", "", "", "return", "len", "(", "to_do_exs", ")", "!=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_question_answering": [[411, 465], ["questeval_metric.QuestEval._get_qg_hash", "questeval_metric.QuestEval._get_qa_hash", "enumerate", "len", "len", "zip", "questeval_metric.QuestEval._get_answer_types", "len", "questeval_metric.QuestEval._predict_answers", "range", "len", "zip", "len", "len", "len", "len", "len", "len", "len", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_answers"], ["", "def", "_compute_question_answering", "(", "\n", "self", ",", "\n", "logs_1", ":", "Dict", ",", "\n", "logs_2", ":", "Dict", ",", "\n", "type_logs_1", ":", "str", ",", "\n", "type_logs_2", ":", "str", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        asking questions from logs_2 on text from logs_1\n        \"\"\"", "\n", "assert", "len", "(", "logs_1", ")", "==", "len", "(", "logs_2", ")", "\n", "\n", "name_model_qg", "=", "self", ".", "_get_qg_hash", "(", "type_logs_2", ")", "\n", "name_model_qa", "=", "self", ".", "_get_qa_hash", "(", "type_logs_1", ")", "\n", "\n", "to_do_exs", ",", "to_do_exs_types", ",", "to_do_exs_idxs", ",", "to_do_gold_asws", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "(", "log_1", ",", "log_2", ")", "in", "enumerate", "(", "zip", "(", "logs_1", ",", "logs_2", ")", ")", ":", "\n", "            ", "if", "log_1", "[", "'text'", "]", "==", "''", "or", "log_2", "[", "'text'", "]", "==", "''", ":", "\n", "                ", "continue", "\n", "", "for", "answer_type", "in", "self", ".", "_get_answer_types", "(", "type_logs_2", ")", ":", "\n", "                ", "questions", "=", "log_2", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "[", "'questions'", "]", "\n", "gold_answers", "=", "log_2", "[", "'self'", "]", "[", "answer_type", "]", "[", "'answers'", "]", "\n", "assert", "len", "(", "questions", ")", "==", "len", "(", "gold_answers", ")", "\n", "for", "question", ",", "gold_answer", "in", "zip", "(", "questions", ",", "gold_answers", ")", ":", "\n", "                    ", "if", "question", "not", "in", "log_1", "[", "'asked'", "]", ":", "\n", "                        ", "log_1", "[", "'asked'", "]", "[", "question", "]", "=", "dict", "(", ")", "\n", "\n", "", "if", "name_model_qa", "not", "in", "log_1", "[", "'asked'", "]", "[", "question", "]", ":", "\n", "                        ", "to_do_exs", "+=", "[", "(", "question", ",", "log_1", "[", "'text'", "]", ")", "]", "\n", "to_do_exs_idxs", "+=", "[", "idx", "]", "\n", "to_do_gold_asws", "+=", "[", "gold_answer", "]", "\n", "\n", "# if already in the logs, we need to add the gold_answers if it hasnt been yet", "\n", "", "elif", "gold_answer", "not", "in", "log_1", "[", "'asked'", "]", "[", "question", "]", "[", "name_model_qa", "]", "[", "'ground_truth'", "]", ":", "\n", "                        ", "log_1", "[", "'asked'", "]", "[", "question", "]", "[", "name_model_qa", "]", "[", "'ground_truth'", "]", "[", "gold_answer", "]", "=", "{", "}", "\n", "\n", "", "", "", "", "if", "len", "(", "to_do_exs", ")", "!=", "0", ":", "\n", "            ", "answerability_scores", ",", "qa_texts", "=", "self", ".", "_predict_answers", "(", "to_do_exs", ",", "type_logs_1", ")", "\n", "\n", "assert", "len", "(", "to_do_exs", ")", "==", "len", "(", "qa_texts", ")", "==", "len", "(", "to_do_gold_asws", ")", "==", "len", "(", "answerability_scores", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "to_do_exs", ")", ")", ":", "\n", "\n", "                ", "question", "=", "to_do_exs", "[", "i", "]", "[", "0", "]", "\n", "idx", "=", "to_do_exs_idxs", "[", "i", "]", "\n", "assert", "to_do_exs", "[", "i", "]", "[", "1", "]", "==", "logs_1", "[", "idx", "]", "[", "'text'", "]", "\n", "\n", "if", "name_model_qa", "not", "in", "logs_1", "[", "idx", "]", "[", "'asked'", "]", "[", "question", "]", ":", "\n", "                    ", "logs_1", "[", "idx", "]", "[", "'asked'", "]", "[", "question", "]", "[", "name_model_qa", "]", "=", "{", "'answer'", ":", "qa_texts", "[", "i", "]", ",", "\n", "'answerability'", ":", "answerability_scores", "[", "i", "]", ",", "\n", "'ground_truth'", ":", "dict", "(", ")", "\n", "}", "\n", "", "logs_1", "[", "idx", "]", "[", "'asked'", "]", "[", "question", "]", "[", "name_model_qa", "]", "[", "'ground_truth'", "]", "[", "to_do_gold_asws", "[", "i", "]", "]", "=", "{", "}", "\n", "\n", "", "", "return", "len", "(", "to_do_exs", ")", "!=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_answer_similarity_scores": [[466, 518], ["questeval_metric.QuestEval._get_qa_hash", "enumerate", "len", "range", "len", "len", "len", "questeval.utils.calculate_f1_squad", "questeval.utils.calculate_BERTScore", "NotImplementedError", "questeval_metric.QuestEval._get_qa_hash", "zip"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.calculate_f1_squad", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.calculate_BERTScore", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash"], ["", "def", "_compute_answer_similarity_scores", "(", "\n", "self", ",", "\n", "logs", ":", "Dict", ",", "\n", "type_logs", ":", "str", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        filling the similarity scores\n        \"\"\"", "\n", "\n", "modified_logs", "=", "False", "\n", "name_model_qa", "=", "self", ".", "_get_qa_hash", "(", "type_logs", ")", "\n", "\n", "for", "type_score", "in", "self", ".", "list_scores", ":", "\n", "\n", "# no need for comparison for answerabiliy, it is calculated directly in compute_question_answering", "\n", "            ", "if", "type_score", "==", "'answerability'", ":", "\n", "                ", "continue", "\n", "\n", "", "to_do_exs_idxs", ",", "to_do_questions", ",", "to_do_pred_asws", ",", "to_do_gold_asws", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "log", "in", "enumerate", "(", "logs", ")", ":", "\n", "                ", "if", "log", "[", "'text'", "]", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "for", "question", "in", "log", "[", "'asked'", "]", ":", "\n", "                    ", "d_answer", "=", "log", "[", "'asked'", "]", "[", "question", "]", "[", "self", ".", "_get_qa_hash", "(", "log", "[", "'type'", "]", ")", "]", "\n", "for", "gold_answer", "in", "d_answer", "[", "'ground_truth'", "]", ":", "\n", "                        ", "if", "type_score", "not", "in", "d_answer", "[", "'ground_truth'", "]", "[", "gold_answer", "]", ":", "\n", "                            ", "to_do_exs_idxs", "+=", "[", "idx", "]", "\n", "to_do_questions", "+=", "[", "question", "]", "\n", "to_do_pred_asws", "+=", "[", "d_answer", "[", "'answer'", "]", "]", "\n", "to_do_gold_asws", "+=", "[", "gold_answer", "]", "\n", "\n", "", "", "", "", "if", "len", "(", "to_do_exs_idxs", ")", "!=", "0", ":", "\n", "\n", "                ", "modified_logs", "=", "True", "\n", "\n", "if", "type_score", "==", "'f1'", ":", "\n", "                    ", "sim_scores", "=", "[", "calculate_f1_squad", "(", "pred_asw", ",", "gold_asw", ")", "for", "pred_asw", ",", "gold_asw", "in", "\n", "zip", "(", "to_do_pred_asws", ",", "to_do_gold_asws", ")", "]", "\n", "", "elif", "type_score", "==", "'bertscore'", ":", "\n", "                    ", "sim_scores", "=", "calculate_BERTScore", "(", "to_do_pred_asws", ",", "to_do_gold_asws", ",", "self", ".", "metric_BERTScore", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "f\"{type_score} not implemented\"", ")", "\n", "\n", "", "assert", "len", "(", "to_do_exs_idxs", ")", "==", "len", "(", "sim_scores", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "to_do_exs_idxs", ")", ")", ":", "\n", "                    ", "idx", "=", "to_do_exs_idxs", "[", "i", "]", "\n", "q", "=", "to_do_questions", "[", "i", "]", "\n", "a", "=", "to_do_gold_asws", "[", "i", "]", "\n", "logs", "[", "idx", "]", "[", "'asked'", "]", "[", "q", "]", "[", "name_model_qa", "]", "[", "'ground_truth'", "]", "[", "a", "]", "[", "type_score", "]", "=", "sim_scores", "[", "i", "]", "\n", "\n", "", "", "", "return", "modified_logs", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._compute_weighter": [[519, 557], ["questeval_metric.QuestEval._get_weighter_hash", "questeval_metric.QuestEval._get_qg_hash", "enumerate", "questeval_metric.QuestEval._get_answer_types", "len", "questeval_metric.QuestEval._predict_weighter", "range", "len", "len", "len", "len", "[].append", "len", "len", "len", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_weighter_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_weighter"], ["", "def", "_compute_weighter", "(", "\n", "self", ",", "\n", "logs", ":", "Dict", ",", "\n", "type_logs", ":", "str", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        weighting the probability that a question is asking about important content or not (see https://arxiv.org/abs/2103.12693)\n        \"\"\"", "\n", "\n", "name_model_weighter", "=", "self", ".", "_get_weighter_hash", "(", ")", "\n", "name_model_qg", "=", "self", ".", "_get_qg_hash", "(", "type_logs", ")", "\n", "\n", "to_do_exs", ",", "to_do_exs_types", ",", "to_do_exs_idxs", ",", "to_do_gold_asws", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "log", "in", "enumerate", "(", "logs", ")", ":", "\n", "            ", "if", "log", "[", "'text'", "]", "==", "''", ":", "\n", "                ", "continue", "\n", "", "for", "answer_type", "in", "self", ".", "_get_answer_types", "(", "type_logs", ")", ":", "\n", "                ", "if", "name_model_weighter", "not", "in", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", ":", "\n", "                    ", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "[", "name_model_weighter", "]", "=", "[", "]", "\n", "\n", "questions", "=", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "[", "'questions'", "]", "\n", "answers", "=", "log", "[", "'self'", "]", "[", "answer_type", "]", "[", "'answers'", "]", "\n", "assert", "len", "(", "questions", ")", "==", "len", "(", "answers", ")", "\n", "to_do_exs", "+=", "[", "f\"{asw} {self.sep} {question} {self.sep} {log['text']}\"", "\n", "for", "asw", ",", "question", "in", "zip", "(", "answers", ",", "questions", ")", "]", "\n", "\n", "to_do_exs_idxs", "+=", "[", "idx", "]", "*", "len", "(", "answers", ")", "\n", "to_do_exs_types", "+=", "[", "answer_type", "]", "*", "len", "(", "answers", ")", "\n", "\n", "", "", "", "if", "len", "(", "to_do_exs", ")", "!=", "0", ":", "\n", "            ", "weighter_scores", "=", "self", ".", "_predict_weighter", "(", "to_do_exs", ")", "\n", "assert", "len", "(", "to_do_exs", ")", "==", "len", "(", "weighter_scores", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "to_do_exs", ")", ")", ":", "\n", "                ", "idx", "=", "to_do_exs_idxs", "[", "i", "]", "\n", "answer_type", "=", "to_do_exs_types", "[", "i", "]", "\n", "logs", "[", "idx", "]", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "[", "name_model_weighter", "]", ".", "append", "(", "weighter_scores", "[", "i", "]", ")", "\n", "\n", "", "", "return", "len", "(", "to_do_exs", ")", "!=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types": [[558, 560], ["None"], "methods", ["None"], ["", "def", "_get_answer_types", "(", "self", ",", "type_logs", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "(", "'TABLE'", ",", ")", "if", "type_logs", "==", "'src'", "and", "self", ".", "task", "==", "'data2text'", "else", "self", ".", "answer_types", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_self_answers": [[561, 581], ["questeval.utils.sentencize", "questeval_metric.QuestEval.spacy_pipeline", "questeval.utils.extract_table_answers", "questeval_metric.QuestEval.spacy_pipeline"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.sentencize", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.extract_table_answers"], ["", "def", "_predict_self_answers", "(", "\n", "self", ",", "\n", "texts", ":", "List", ",", "\n", "answer_type", ":", "str", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "if", "self", ".", "limit_sent", "is", "not", "None", ":", "\n", "            ", "list_sentences", "=", "[", "sentencize", "(", "text", ",", "self", ".", "spacy_pipeline", ")", "for", "text", "in", "texts", "]", "\n", "texts", "=", "[", "' '", ".", "join", "(", "sentences", "[", ":", "self", ".", "limit_sent", "]", ")", "for", "sentences", "in", "list_sentences", "]", "\n", "\n", "", "list_answers", "=", "[", "]", "\n", "if", "answer_type", "==", "'NER'", ":", "\n", "            ", "list_answers", "=", "[", "[", "a", ".", "text", "for", "a", "in", "self", ".", "spacy_pipeline", "(", "text", ")", ".", "ents", "]", "for", "text", "in", "texts", "]", "\n", "", "elif", "answer_type", "==", "'NOUN'", ":", "\n", "            ", "list_answers", "=", "[", "[", "a", ".", "text", "for", "a", "in", "self", ".", "spacy_pipeline", "(", "text", ")", ".", "noun_chunks", "]", "for", "text", "in", "texts", "]", "\n", "", "elif", "answer_type", "==", "'SPANER'", ":", "\n", "            ", "pass", "# todo not implemented", "\n", "", "elif", "answer_type", "==", "'TABLE'", ":", "\n", "            ", "list_answers", "=", "[", "extract_table_answers", "(", "text", ")", "for", "text", "in", "texts", "]", "\n", "\n", "", "return", "list_answers", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_questions": [[582, 594], ["model_QG.predict"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.API_T2T.predict"], ["", "def", "_predict_questions", "(", "\n", "self", ",", "\n", "to_do_exs", ":", "List", "[", "tuple", "]", ",", "\n", "type_logs", ":", "str", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "model_QG", "=", "self", ".", "models", "[", "type_logs", "]", "[", "'QG'", "]", "\n", "\n", "str_prefix", "=", "f'{self.qg_prefix} {self.sep} '", "if", "self", ".", "qg_prefix", "is", "not", "None", "else", "''", "\n", "formated_inputs", "=", "[", "f'{str_prefix}{asw} {self.sep} {context}'", "for", "asw", ",", "context", "in", "to_do_exs", "]", "\n", "_", ",", "question_texts", "=", "model_QG", ".", "predict", "(", "formated_inputs", ")", "\n", "\n", "return", "question_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_answers": [[595, 605], ["model_QA.predict"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.API_T2T.predict"], ["", "def", "_predict_answers", "(", "\n", "self", ",", "\n", "to_do_exs", ":", "List", "[", "tuple", "]", ",", "\n", "type_logs", ":", "str", "\n", ")", "->", "Tuple", "[", "List", "[", "float", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "model_QA", "=", "self", ".", "models", "[", "type_logs", "]", "[", "'QA'", "]", "\n", "formated_inputs", "=", "[", "f'{question} {self.sep} {context}'", "for", "question", ",", "context", "in", "to_do_exs", "]", "\n", "qa_scores", ",", "qa_texts", "=", "model_QA", ".", "predict", "(", "formated_inputs", ")", "\n", "\n", "return", "qa_scores", ",", "qa_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._predict_weighter": [[606, 616], ["questeval_metric.QuestEval.models[].predict", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.API_T2T.predict"], ["", "def", "_predict_weighter", "(", "self", ",", "to_do_exs", ":", "List", "[", "str", "]", ")", "->", "List", "[", "float", "]", ":", "\n", "        ", "if", "self", ".", "models", "[", "'Weighter'", "]", "is", "None", ":", "\n", "# Neutral Policy", "\n", "            ", "probs", "=", "[", "1.0", "for", "_", "in", "to_do_exs", "]", "\n", "\n", "", "else", ":", "\n", "            ", "probs", ",", "texts", "=", "self", ".", "models", "[", "'Weighter'", "]", ".", "predict", "(", "to_do_exs", ")", "\n", "assert", "len", "(", "probs", ")", "==", "len", "(", "to_do_exs", ")", "\n", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._calculate_score_from_logs": [[617, 633], ["questeval_metric.QuestEval.reduction_multi_refs", "scores.append", "questeval_metric.QuestEval._base_score", "questeval_metric.QuestEval._base_score", "numpy.average"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._base_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._base_score"], ["", "def", "_calculate_score_from_logs", "(", "\n", "self", ",", "\n", "hyp_log", ":", "List", "[", "Dict", "]", ",", "\n", "compared_logs", ":", "List", "[", "List", "[", "Dict", "]", "]", "\n", ")", "->", "float", ":", "\n", "\n", "        ", "scores", "=", "[", "]", "\n", "for", "compared_log", "in", "compared_logs", ":", "\n", "            ", "if", "compared_log", "[", "'text'", "]", "==", "''", "or", "hyp_log", "[", "'text'", "]", "==", "''", ":", "\n", "                ", "score", "=", "0", "\n", "", "else", ":", "\n", "                ", "hyp_score", "=", "self", ".", "_base_score", "(", "hyp_log", ",", "compared_log", ")", "\n", "compared_score", "=", "self", ".", "_base_score", "(", "compared_log", ",", "hyp_log", ")", "\n", "score", "=", "np", ".", "average", "(", "[", "hyp_score", ",", "compared_score", "]", ")", "\n", "", "scores", ".", "append", "(", "score", ")", "\n", "", "return", "self", ".", "reduction_multi_refs", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._base_score": [[634, 677], ["numpy.average", "numpy.multiply().tolist", "questeval_metric.QuestEval._get_scores", "questeval_metric.QuestEval._get_qg_hash", "questeval_metric.QuestEval._get_weighter_hash", "questeval_metric.QuestEval._get_scores", "list_borned", "max", "len", "regularizer", "regularizer", "numpy.multiply", "min", "questeval_metric.QuestEval._get_answer_types"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_scores", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_weighter_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_scores", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types"], ["", "def", "_base_score", "(", "\n", "self", ",", "\n", "questioned_log", ":", "Dict", ",", "\n", "compared_log", ":", "Dict", "\n", ")", "->", "float", ":", "\n", "        ", "regularizer", "=", "lambda", "list_score", ",", "list_reg", ":", "np", ".", "multiply", "(", "scores", ",", "list_reg", ")", ".", "tolist", "(", ")", "\n", "list_borned", "=", "lambda", "a_list", ":", "[", "max", "(", "min", "(", "1", ",", "x", ")", ",", "0", ")", "for", "x", "in", "a_list", "]", "\n", "\n", "if", "self", ".", "do_consistency", ":", "\n", "            ", "consistencies", "=", "self", ".", "_get_scores", "(", "compared_log", ",", "compared_log", ",", "'f1'", ")", "\n", "\n", "", "if", "self", ".", "do_weighter", "and", "compared_log", "[", "'type'", "]", "==", "'src'", ":", "\n", "            ", "name_model_qg", "=", "self", ".", "_get_qg_hash", "(", "compared_log", "[", "'type'", "]", ")", "\n", "name_model_weighter", "=", "self", ".", "_get_weighter_hash", "(", ")", "\n", "weighter_probs", "=", "[", "\n", "w", "for", "answer_type", "in", "self", ".", "_get_answer_types", "(", "questioned_log", "[", "'type'", "]", ")", "\n", "for", "w", "in", "compared_log", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "[", "name_model_weighter", "]", "\n", "]", "\n", "\n", "", "list_scores", "=", "[", "]", "\n", "for", "type_score", "in", "self", ".", "list_scores", ":", "\n", "            ", "scores", "=", "self", ".", "_get_scores", "(", "questioned_log", ",", "compared_log", ",", "type_score", ")", "\n", "\n", "# if no questions, return a score set to 0; could be improved though ?", "\n", "if", "len", "(", "scores", ")", "==", "0", ":", "\n", "                ", "return", "0", "\n", "\n", "# sometimes the answers scores return a value ~1.000000X which is superior to 1", "\n", "", "scores", "=", "list_borned", "(", "scores", ")", "\n", "\n", "if", "self", ".", "do_consistency", ":", "\n", "                ", "assert", "consistencies", "is", "not", "None", ",", "\"consistencies is None. Please compute the score with ques_consists activate.\"", "\n", "scores", "=", "regularizer", "(", "scores", ",", "consistencies", ")", "\n", "\n", "", "if", "self", ".", "do_weighter", "and", "compared_log", "[", "'type'", "]", "==", "'src'", ":", "\n", "                ", "assert", "weighter_probs", "is", "not", "None", ",", "\"weighter_probs is None. Please compute the weighter probs with do_weighter activate.\"", "\n", "scores", "=", "regularizer", "(", "scores", ",", "weighter_probs", ")", "\n", "\n", "", "list_scores", "+=", "scores", "\n", "\n", "", "final_score", "=", "np", ".", "average", "(", "list_scores", ")", "\n", "assert", "0", "<=", "final_score", "<=", "1", ",", "\"score should be in [0-1] \"", "\n", "return", "final_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_scores": [[678, 707], ["questeval_metric.QuestEval._get_qg_hash", "questeval_metric.QuestEval._get_qa_hash", "questeval_metric.QuestEval._get_answer_types", "len", "len", "questeval_metric.QuestEval._get_answer_types", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_types"], ["", "def", "_get_scores", "(", "\n", "self", ",", "\n", "questioned_log", ":", "List", "[", "Dict", "]", ",", "\n", "compared_log", ":", "List", "[", "Dict", "]", ",", "\n", "type_score", ":", "str", "\n", ")", "->", "List", "[", "float", "]", ":", "\n", "\n", "        ", "name_model_qg", "=", "self", ".", "_get_qg_hash", "(", "compared_log", "[", "'type'", "]", ")", "\n", "asked_questions", "=", "[", "q", "for", "answer_type", "in", "self", ".", "_get_answer_types", "(", "compared_log", "[", "'type'", "]", ")", "\n", "for", "q", "in", "compared_log", "[", "'self'", "]", "[", "answer_type", "]", "[", "name_model_qg", "]", "[", "'questions'", "]", "\n", "]", "\n", "\n", "name_model_qa", "=", "self", ".", "_get_qa_hash", "(", "questioned_log", "[", "'type'", "]", ")", "\n", "if", "type_score", "==", "'answerability'", ":", "\n", "            ", "scores", "=", "[", "questioned_log", "[", "'asked'", "]", "[", "q", "]", "[", "name_model_qa", "]", "[", "'answerability'", "]", "\n", "for", "q", "in", "asked_questions", "]", "\n", "\n", "", "else", ":", "# F1 or BERTScore", "\n", "            ", "asked_answers", "=", "[", "a", "for", "answer_type", "in", "self", ".", "_get_answer_types", "(", "compared_log", "[", "'type'", "]", ")", "\n", "for", "a", "in", "compared_log", "[", "'self'", "]", "[", "answer_type", "]", "[", "'answers'", "]", "]", "\n", "\n", "assert", "len", "(", "asked_answers", ")", "==", "len", "(", "asked_questions", ")", "\n", "\n", "[", "questioned_log", "[", "'asked'", "]", "[", "q", "]", "[", "name_model_qa", "]", "[", "'ground_truth'", "]", "[", "a", "]", "[", "type_score", "]", "\n", "for", "q", ",", "a", "in", "zip", "(", "asked_questions", ",", "asked_answers", ")", "]", "\n", "scores", "=", "[", "questioned_log", "[", "'asked'", "]", "[", "q", "]", "[", "name_model_qa", "]", "[", "'ground_truth'", "]", "[", "a", "]", "[", "type_score", "]", "\n", "for", "q", ",", "a", "in", "zip", "(", "asked_questions", ",", "asked_answers", ")", "]", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.get_model": [[708, 738], ["model_name.lower", "questeval.utils.API_T2T", "NotImplementedError", "model_name.lower", "model_name.lower", "model_name.lower"], "methods", ["None"], ["", "def", "get_model", "(", "self", ",", "model_name", ":", "str", ",", ")", ":", "\n", "        ", "keep_score_idx", "=", "None", "\n", "\n", "if", "'t5'", "in", "model_name", ".", "lower", "(", ")", ":", "\n", "\n", "            ", "if", "\"qa\"", "in", "model_name", ".", "lower", "(", ")", ":", "\n", "# 73 is the index for the token unanswerable in T5 vocabulary", "\n", "                ", "keep_score_idx", "=", "73", "\n", "", "if", "'weighter'", "in", "model_name", ".", "lower", "(", ")", ":", "\n", "# 1176 is the index for the token true in T5 vocabulary", "\n", "                ", "keep_score_idx", "=", "1176", "\n", "", "if", "model_name", "==", "f\"{HF_ORGANIZATION}/t5-qg_squad1-en\"", ":", "\n", "# the default models were trained with this prefix 'sv1' and 'nqa' prefix on the two datasets", "\n", "                ", "self", ".", "qg_prefix", "=", "'sv1'", "\n", "\n", "# batch size", "\n", "", "model_batch_size", "=", "self", ".", "qg_batch_size", "if", "\"qg\"", "in", "model_name", ".", "lower", "(", ")", "else", "self", ".", "clf_batch_size", "\n", "\n", "model", "=", "API_T2T", "(", "\n", "pretrained_model_name_or_path", "=", "model_name", ",", "\n", "keep_score_idx", "=", "keep_score_idx", ",", "\n", "max_source_length", "=", "512", ",", "\n", "model_batch_size", "=", "model_batch_size", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f'Model Name Not Handled: the model name should contain t5 ({model_name}).'", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.set_model": [[739, 755], ["questeval_metric.QuestEval.get_model"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.get_model"], ["", "def", "set_model", "(", "\n", "self", ",", "\n", "key", ":", "str", ",", "\n", "task", ":", "str", ",", "\n", "model_name", ":", "str", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "assert", "key", "in", "[", "None", ",", "'hyp'", ",", "'src'", ",", "'ref'", "]", "\n", "assert", "task", "in", "[", "'weighter'", ",", "'QG'", ",", "'QG'", "]", "\n", "\n", "model", "=", "self", ".", "get_model", "(", "model_name", "=", "model_name", ")", "\n", "\n", "if", "key", "is", "None", ":", "\n", "            ", "self", ".", "models", "[", "task", "]", "=", "model", "\n", "", "else", ":", "\n", "            ", "self", ".", "models", "[", "key", "]", "[", "task", "]", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_answer_hash": [[756, 762], ["None"], "methods", ["None"], ["", "", "def", "_get_answer_hash", "(", "self", ")", "->", "str", ":", "\n", "# TODO: self.spacy_pipeline", "\n", "        ", "msg", "=", "f\"LimitSent={self.limit_sent}\"", "f\"_models={'_'.join(self.answer_types)}\"", "\n", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash": [[763, 768], ["None"], "methods", ["None"], ["", "def", "_get_qg_hash", "(", "self", ",", "type_log", ":", "str", ")", "->", "str", ":", "\n", "        ", "model", "=", "self", ".", "models", "[", "type_log", "]", "[", "'QG'", "]", "\n", "msg", "=", "f'QG_hash={model.pretrained_model_name_or_path}'", "\n", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash": [[769, 774], ["None"], "methods", ["None"], ["", "def", "_get_qa_hash", "(", "self", ",", "type_log", ":", "str", ")", "->", "str", ":", "\n", "        ", "model", "=", "self", ".", "models", "[", "type_log", "]", "[", "'QA'", "]", "\n", "msg", "=", "f'QA_hash={model.pretrained_model_name_or_path}'", "\n", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_weighter_hash": [[775, 783], ["None"], "methods", ["None"], ["", "def", "_get_weighter_hash", "(", "self", ")", "->", "str", ":", "\n", "        ", "msg", "=", "'W_hash='", "\n", "tmp", "=", "'None'", "\n", "if", "self", ".", "do_weighter", ":", "\n", "            ", "model", "=", "self", ".", "models", "[", "'Weighter'", "]", "\n", "tmp", "=", "f'{model.pretrained_model_name_or_path}'", "\n", "", "msg", "+=", "tmp", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.__hash__": [[784, 793], ["questeval_metric.QuestEval._get_weighter_hash", "questeval_metric.QuestEval._get_qa_hash", "questeval_metric.QuestEval._get_qa_hash", "questeval_metric.QuestEval._get_qa_hash", "questeval_metric.QuestEval._get_qg_hash", "questeval_metric.QuestEval._get_qg_hash", "questeval_metric.QuestEval._get_qg_hash"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_weighter_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qa_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval._get_qg_hash"], ["", "def", "__hash__", "(", "self", ")", "->", "str", ":", "\n", "        ", "msg", "=", "f\"QuestEval_version={__version__}\"", "f\"_task={self.task}_lang={self.language}_preproc={self.src_preproc_pipe}\"", "f\"_consist={self.do_consistency}_scores={self.list_scores}\"", "f\"{self._get_weighter_hash()}\"", "f\"_hyp_{self._get_qa_hash('hyp')}_ref_{self._get_qa_hash('ref')}_src_{self._get_qa_hash('src')}\"", "f\"_hyp_{self._get_qg_hash('hyp')}_ref_{self._get_qg_hash('ref')}_src_{self._get_qg_hash('src')}\"", "\n", "\n", "return", "msg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.API_T2T.__init__": [[49, 72], ["transformers.T5Tokenizer.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "utils.API_T2T.model.cuda"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "pretrained_model_name_or_path", ":", "str", ",", "\n", "max_source_length", ":", "int", ",", "\n", "model_batch_size", ":", "int", ",", "\n", "keep_score_idx", ":", "int", ",", "# Note: will work only if beamsize == 1", "\n", "device", ":", "str", "=", "\"cuda\"", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "pretrained_model_name_or_path", "=", "pretrained_model_name_or_path", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", "=", "pretrained_model_name_or_path", "\n", ")", "\n", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", "=", "pretrained_model_name_or_path", "\n", ")", "\n", "\n", "self", ".", "keep_score_idx", "=", "keep_score_idx", "\n", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "            ", "self", ".", "model", ".", "cuda", "(", ")", "\n", "", "self", ".", "max_source_length", "=", "max_source_length", "\n", "self", ".", "model_batch_size", "=", "model_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.API_T2T.predict": [[73, 121], ["range", "len", "utils.API_T2T.tokenizer", "torch.no_grad", "utils.API_T2T.model.generate", "utils.API_T2T.tokenizer.batch_decode", "keep_score_idx_score.squeeze.squeeze.tolist", "len", "keep_score_idx_score.squeeze.squeeze.squeeze", "source_ids.to", "source_mask.to", "[].softmax"], "methods", ["None"], ["", "def", "predict", "(", "\n", "self", ",", "\n", "sources", ":", "List", "[", "str", "]", ",", "\n", ")", ":", "\n", "# sources should be question <s> context", "\n", "\n", "        ", "gen_texts", "=", "[", "]", "\n", "keep_score_idx_scores", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sources", ")", ",", "self", ".", "model_batch_size", ")", ":", "\n", "            ", "inputs", "=", "self", ".", "tokenizer", "(", "\n", "sources", "[", "i", ":", "i", "+", "self", ".", "model_batch_size", "]", ",", "\n", "max_length", "=", "self", ".", "max_source_length", ",", "\n", "padding", "=", "\"max_length\"", ",", "\n", "truncation", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "source_ids", ",", "source_mask", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"attention_mask\"", "]", "\n", "dict_generated_ids", "=", "self", ".", "model", ".", "generate", "(", "\n", "input_ids", "=", "source_ids", ".", "to", "(", "self", ".", "model", ".", "device", ")", ",", "\n", "attention_mask", "=", "source_mask", ".", "to", "(", "self", ".", "model", ".", "device", ")", ",", "\n", "use_cache", "=", "True", ",", "\n", "decoder_start_token_id", "=", "None", ",", "\n", "num_beams", "=", "1", ",", "\n", "num_return_sequences", "=", "1", ",", "\n", "do_sample", "=", "False", ",", "\n", "output_scores", "=", "True", ",", "\n", "return_dict_in_generate", "=", "True", "\n", ")", "\n", "gen_text", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "\n", "dict_generated_ids", "[", "'sequences'", "]", ",", "\n", "skip_special_tokens", "=", "True", ",", "\n", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "\n", "gen_texts", "+=", "gen_text", "\n", "\n", "keep_score_idx_score", "=", "(", "1", "-", "dict_generated_ids", "[", "'scores'", "]", "[", "0", "]", ".", "softmax", "(", "-", "1", ")", "[", ":", ",", "self", ".", "keep_score_idx", "]", ")", "\n", "if", "len", "(", "gen_text", ")", "!=", "1", ":", "\n", "                    ", "keep_score_idx_score", "=", "keep_score_idx_score", ".", "squeeze", "(", ")", "\n", "", "keep_score_idx_scores", "+=", "keep_score_idx_score", ".", "tolist", "(", ")", "\n", "\n", "# Note: self.model.additional_scores_idx keep in memory probs only if beam == 1;", "\n", "#   it is usefull only when T5 is used as a classifier so far.", "\n", "", "", "return", "keep_score_idx_scores", ",", "gen_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.WrongE2EFormat.__init__": [[213, 222], ["Exception.__init__", "err.format"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.WrongWebNlgFormat.__init__"], ["    ", "def", "__init__", "(", "self", ",", "obj", ")", ":", "\n", "        ", "err", "=", "\"\"\"\n            It seems you passed an objected weirdly formatted.\n            For E2E, please give a Meaning Representation as a string, \n            formatted as below:\n                input = 'name[The Eagle], eatType[coffee shop], food[Japanese]'\n            Your object was: {}\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "err", ".", "format", "(", "obj", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.LinearizeWebnlgInput.__init__": [[251, 271], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "spacy_pipeline", ",", "\n", "lowercase", "=", "False", ",", "\n", "format", ":", "str", "=", "'gem'", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Linearize a WebNLG input for QuestEval.\n        Input must be a list of triples, each being a string with two \"|\".\n        Example:\n            [\n                \"(15788)_1993_SB | discoverer | Donal_O'Ceallaigh\",\n                \"(15788)_1993_SB | epoch | 2006-03-06\"\n            ]\n        lowercase=True indicates that you want all strings to be lowercased.\n        \"\"\"", "\n", "\n", "self", ".", "lowercase", "=", "lowercase", "\n", "self", ".", "format", "=", "format", "\n", "self", ".", "spacy_pipeline", "=", "spacy_pipeline", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.LinearizeWebnlgInput.__call__": [[272, 300], ["dict", "list", "enumerate", "ValueError", "isinstance", "utils.WrongWebNlgFormat", "utils.Triple", "dict.setdefault", "table[].append", "dict.items", "list.append", "list", "list.append"], "methods", ["None"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "input", ":", "List", "[", "str", "]", "\n", ")", "->", "str", ":", "\n", "\n", "        ", "if", "self", ".", "format", "!=", "'gem'", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unsupported format for now: {self.format}'", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "input", ",", "list", ")", ":", "\n", "            ", "raise", "WrongWebNlgFormat", "(", "input", ")", "\n", "\n", "", "triples", "=", "[", "Triple", "(", "triple", ",", "\n", "spacy_pipeline", "=", "self", ".", "spacy_pipeline", ",", "\n", "lower", "=", "self", ".", "lowercase", ")", "\n", "for", "triple", "in", "input", "]", "\n", "\n", "table", "=", "dict", "(", ")", "\n", "for", "triple", "in", "triples", ":", "\n", "            ", "table", ".", "setdefault", "(", "triple", ".", "sbj", ",", "list", "(", ")", ")", "\n", "table", "[", "triple", ".", "sbj", "]", ".", "append", "(", "(", "triple", ".", "obj", ",", "triple", ".", "prp", ")", ")", "\n", "\n", "", "ret", "=", "list", "(", ")", "\n", "for", "entidx", ",", "(", "entname", ",", "entlist", ")", "in", "enumerate", "(", "table", ".", "items", "(", ")", ",", "1", ")", ":", "\n", "            ", "ret", ".", "append", "(", "f'entity [ {entname} ]'", ")", "\n", "for", "values", ",", "key", "in", "entlist", ":", "\n", "                ", "ret", ".", "append", "(", "f'{key} [ {values} ]'", ")", "\n", "\n", "", "", "return", "' , '", ".", "join", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.__init__": [[303, 320], ["utils.Triple.safe_split", "utils.Triple.clean_prp", "utils.Triple.strip", "obj.split", "obj.split", "spacy_pipeline", "spacy_pipeline", "utils.Triple.clean_obj", "utils.Triple.clean_obj", "obj.strip", "sbj.strip"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.safe_split", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.clean_prp", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.clean_obj", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.clean_obj"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "raw_text", ":", "str", ",", "\n", "spacy_pipeline", ",", "\n", "lower", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "sbj", ",", "prp", ",", "obj", "=", "self", ".", "safe_split", "(", "raw_text", ")", "\n", "obj", "=", "' '", ".", "join", "(", "[", "t", ".", "text", "for", "t", "in", "spacy_pipeline", "(", "self", ".", "clean_obj", "(", "obj", ".", "strip", "(", ")", ",", "lc", "=", "lower", ")", ")", "]", ")", "\n", "prp", "=", "self", ".", "clean_prp", "(", "prp", ".", "strip", "(", ")", ")", "\n", "sbj", "=", "' '", ".", "join", "(", "[", "t", ".", "text", "for", "t", "in", "spacy_pipeline", "(", "self", ".", "clean_obj", "(", "sbj", ".", "strip", "(", ")", ",", "lc", "=", "lower", ")", ")", "]", ")", "\n", "if", "prp", "==", "'ethnicgroup'", ":", "\n", "            ", "obj", "=", "obj", ".", "split", "(", "'_in_'", ")", "[", "0", "]", "\n", "obj", "=", "obj", ".", "split", "(", "'_of_'", ")", "[", "0", "]", "\n", "\n", "", "self", ".", "sbj", "=", "sbj", "\n", "self", ".", "obj", "=", "obj", "\n", "self", ".", "prp", "=", "prp", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.safe_split": [[321, 336], ["raw_text.strip().split", "isinstance", "TypeError", "TypeError", "raw_text.strip", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "safe_split", "(", "\n", "raw_text", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "raw_text", ",", "str", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'A triple must be a string with two \"|\"'", "\n", "f'but you gave: {raw_text}'", ")", "\n", "\n", "", "split", "=", "raw_text", ".", "strip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "if", "not", "len", "(", "split", ")", "==", "3", ":", "\n", "            ", "raise", "TypeError", "(", "'A triple must be a string with two \"|\"'", "\n", "f'but you gave: {raw_text}'", ")", "\n", "\n", "", "return", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.__repr__": [[337, 339], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f'{self.sbj} | {self.prp} | {self.obj}'", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.clean_obj": [[340, 350], ["unidecode.unidecode", "re.sub", "re.sub", "s.lower.lower.lower"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "clean_obj", "(", "\n", "s", ",", "\n", "lc", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "s", "=", "unidecode", ".", "unidecode", "(", "s", ")", "\n", "if", "lc", ":", "s", "=", "s", ".", "lower", "(", ")", "\n", "s", "=", "re", ".", "sub", "(", "'^\"|\"$'", ",", "\"\"", ",", "s", ")", "# remove useless quotesigns", "\n", "s", "=", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "s", ")", "# turn undescores to spaces", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.Triple.clean_prp": [[351, 364], ["unidecode.unidecode", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "s.lower.lower.strip", "s.lower.lower.lower"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "clean_prp", "(", "\n", "s", ":", "str", ",", "\n", "lc", ":", "bool", "=", "False", "\n", ")", "->", "str", ":", "\n", "        ", "s", "=", "unidecode", ".", "unidecode", "(", "s", ")", "\n", "if", "lc", ":", "s", "=", "s", ".", "lower", "(", ")", "\n", "s", "=", "re", ".", "sub", "(", "'^\"|\"$'", ",", "\"\"", ",", "s", ")", "# remove useless quotesigns", "\n", "s", "=", "re", ".", "sub", "(", "'\\s+'", ",", "'_'", ",", "s", ")", "# turn spaces to underscores", "\n", "s", "=", "re", ".", "sub", "(", "'\\s+\\(in metres\\)'", ",", "'_m'", ",", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "'\\s+\\(in feet\\)'", ",", "'_f'", ",", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "'\\(.*\\)'", ",", "''", ",", "s", ")", "\n", "return", "s", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.WrongWebNlgFormat.__init__": [[367, 380], ["Exception.__init__", "err.format"], "methods", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.WrongWebNlgFormat.__init__"], ["    ", "def", "__init__", "(", "self", ",", "obj", ")", ":", "\n", "        ", "err", "=", "\"\"\"\n            It seems you passed an objected weirdly formatted.\n            For webnlg, please give a list of triplets, where each\n            triplet is a string with two '|'.\n            For instance:\n                input = [\n                    \"(15788)_1993_SB | discoverer | Donal_O'Ceallaigh\",\n                    \"(15788)_1993_SB | epoch | 2006-03-06\"\n                ]\n            Your object was: {}\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "err", ".", "format", "(", "obj", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.text2hash": [[15, 20], ["hashlib.sha512", "hashlib.sha512.hexdigest", "string.encode"], "function", ["None"], ["def", "text2hash", "(", "string", ":", "str", ")", "->", "str", ":", "\n", "    ", "hash_object", "=", "hashlib", ".", "sha512", "(", "string", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "hex_dig", "=", "hash_object", ".", "hexdigest", "(", ")", "\n", "\n", "return", "hex_dig", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.split_on_punct": [[22, 39], ["enumerate", "len", "len", "len"], "function", ["None"], ["", "def", "split_on_punct", "(", "doc", ")", ":", "\n", "    ", "\"\"\"\n    From one spacy doc to a List of (sentence_text, (start, end))\n    \"\"\"", "\n", "start", "=", "0", "\n", "seen_period", "=", "False", "\n", "start_idx", "=", "0", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "doc", ")", ":", "\n", "        ", "if", "seen_period", "and", "not", "token", ".", "is_punct", ":", "\n", "            ", "yield", "doc", "[", "start", ":", "token", ".", "i", "]", ".", "text", ",", "(", "start_idx", ",", "token", ".", "idx", ")", "\n", "start", "=", "token", ".", "i", "\n", "start_idx", "=", "token", ".", "idx", "\n", "seen_period", "=", "False", "\n", "", "elif", "token", ".", "text", "in", "[", "\".\"", ",", "\"!\"", ",", "\"?\"", "]", ":", "\n", "            ", "seen_period", "=", "True", "\n", "", "", "if", "start", "<", "len", "(", "doc", ")", ":", "\n", "        ", "yield", "doc", "[", "start", ":", "len", "(", "doc", ")", "]", ".", "text", ",", "(", "start_idx", ",", "len", "(", "doc", ".", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.sentencize": [[41, 46], ["spacy_pipeline", "utils.split_on_punct"], "function", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.split_on_punct"], ["", "", "def", "sentencize", "(", "\n", "text", ":", "str", ",", "spacy_pipeline", "\n", ")", "->", "List", ":", "\n", "    ", "preprocessed_context", "=", "spacy_pipeline", "(", "text", ")", "\n", "return", "[", "sentence_tuple", "[", "0", "]", "for", "sentence_tuple", "in", "split_on_punct", "(", "preprocessed_context", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.calculate_f1_squad": [[123, 163], ["utils.calculate_f1_squad.get_tokens"], "function", ["None"], ["", "", "def", "calculate_f1_squad", "(", "\n", "a_gold", ":", "str", ",", "\n", "a_pred", ":", "str", "\n", ")", "->", "float", ":", "\n", "    ", "def", "normalize_answer", "(", "s", ")", ":", "\n", "        ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "            ", "regex", "=", "re", ".", "compile", "(", "r'\\b(a|an|the)\\b'", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "            ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "            ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "            ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n", "", "def", "get_tokens", "(", "s", ")", ":", "\n", "        ", "if", "not", "s", ":", "return", "[", "]", "\n", "return", "normalize_answer", "(", "s", ")", ".", "split", "(", ")", "\n", "\n", "", "gold_toks", "=", "get_tokens", "(", "a_gold", ")", "\n", "pred_toks", "=", "get_tokens", "(", "a_pred", ")", "\n", "common", "=", "collections", ".", "Counter", "(", "gold_toks", ")", "&", "collections", ".", "Counter", "(", "pred_toks", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "gold_toks", ")", "==", "0", "or", "len", "(", "pred_toks", ")", "==", "0", ":", "\n", "# If either is no-answer, then F1 is 1 if they agree, 0 otherwise", "\n", "        ", "return", "int", "(", "gold_toks", "==", "pred_toks", ")", "\n", "", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_toks", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_toks", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.calculate_BERTScore": [[165, 185], ["metric_BERTScore.add_batch", "metric_BERTScore.compute", "len"], "function", ["None"], ["", "def", "calculate_BERTScore", "(", "\n", "model_predictions", ":", "List", "[", "str", "]", ",", "\n", "gold_references", ":", "List", "[", "str", "]", ",", "\n", "metric_BERTScore", ",", "\n", "device", ":", "str", ",", "\n", ")", "->", "List", "[", "float", "]", ":", "\n", "\n", "    ", "if", "len", "(", "model_predictions", ")", "==", "0", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "metric_BERTScore", ".", "add_batch", "(", "predictions", "=", "model_predictions", ",", "references", "=", "gold_references", ")", "\n", "final_score", "=", "metric_BERTScore", ".", "compute", "(", "model_type", "=", "'bert-base-multilingual-cased'", ",", "device", "=", "device", ")", "\n", "\n", "\"\"\"\n    # set all unanswerable scores to 0\n    for i, (pred) in enumerate(model_predictions):\n        if pred == \"unanswerable\":\n            final_score['f1'][i] = 0.0\n    \"\"\"", "\n", "return", "[", "f1", "for", "f1", "in", "final_score", "[", "'f1'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.extract_table_answers": [[187, 208], ["text.split", "asws.append", "asw_toks.append"], "function", ["None"], ["", "def", "extract_table_answers", "(", "\n", "text", ":", "str", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "\n", "    ", "asws", "=", "[", "]", "\n", "\n", "asw_toks", "=", "[", "]", "\n", "is_asw", "=", "False", "\n", "for", "tok", "in", "text", ".", "split", "(", ")", ":", "\n", "\n", "        ", "if", "tok", "==", "']'", ":", "\n", "            ", "asws", ".", "append", "(", "' '", ".", "join", "(", "asw_toks", ")", ")", "\n", "is_asw", "=", "False", "\n", "asw_toks", "=", "[", "]", "\n", "\n", "", "if", "is_asw", ":", "\n", "            ", "asw_toks", ".", "append", "(", "tok", ")", "\n", "\n", "", "if", "tok", "==", "'['", ":", "\n", "            ", "is_asw", "=", "True", "\n", "", "", "return", "asws", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.utils.linearize_e2e_input": [[224, 246], ["dict", "ValueError", "isinstance", "utils.WrongE2EFormat", "[].split", "input.split", "dict.items", "s.strip"], "function", ["None"], ["", "", "def", "linearize_e2e_input", "(", "\n", "input", ":", "str", ",", "\n", "format", ":", "str", "=", "'gem'", "\n", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Linearize an E2E input for QuestEval.\n    Input must be a string, in standard E2E format.\n    Example:\n        'name[The Eagle], eatType[coffee shop], food[Japanese]'\n    lowercase=True indicates that you want all tokens to be lowercased.\n    \"\"\"", "\n", "if", "format", "!=", "'gem'", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unsupported format for now: {format}'", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "input", ",", "str", ")", ":", "\n", "        ", "raise", "WrongE2EFormat", "(", "input", ")", "\n", "\n", "", "items", "=", "dict", "(", "[", "s", ".", "strip", "(", ")", "[", ":", "-", "1", "]", ".", "split", "(", "'['", ")", "for", "s", "in", "input", ".", "split", "(", "','", ")", "]", ")", "\n", "\n", "return", "' , '", ".", "join", "(", "[", "\n", "f'{key} [ {value} ]'", "\n", "for", "key", ",", "value", "in", "items", ".", "items", "(", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score": [[2, 8], ["questeval.corpus_questeval", "enumerate", "round", "round", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.questeval.questeval_metric.QuestEval.corpus_questeval"], ["def", "compute_questeval_score", "(", "questeval", ",", "res", ",", "HYPS", ",", "SRCS", ",", "REFSS", ")", ":", "\n", "    ", "d_score", "=", "questeval", ".", "corpus_questeval", "(", "hypothesis", "=", "HYPS", ",", "sources", "=", "SRCS", ",", "list_references", "=", "REFSS", ")", "\n", "assert", "round", "(", "d_score", "[", "'corpus_score'", "]", ",", "4", ")", "-", "1e-4", "<=", "round", "(", "res", "[", "'corpus_score'", "]", ",", "4", ")", "<=", "round", "(", "d_score", "[", "'corpus_score'", "]", ",", "4", ")", "+", "1e-4", "\n", "for", "seg_i", ",", "seg_score", "in", "enumerate", "(", "res", "[", "'ex_level_scores'", "]", ")", ":", "\n", "        ", "assert", "0", "<=", "d_score", "[", "'ex_level_scores'", "]", "[", "seg_i", "]", "<=", "1", "\n", "assert", "round", "(", "seg_score", ",", "4", ")", "-", "1e-4", "<=", "round", "(", "d_score", "[", "'ex_level_scores'", "]", "[", "seg_i", "]", ",", "4", ")", "<=", "round", "(", "seg_score", ",", "4", ")", "+", "1e-4", "", "", "", ""]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.units.test_questeval_metric.test_questeval_exceptions": [[13, 22], ["questeval.questeval_metric.QuestEval", "pytest.raises", "tests.utils.helpers.compute_questeval_score", "pytest.raises", "tests.utils.helpers.compute_questeval_score"], "function", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score"], ["def", "test_questeval_exceptions", "(", ")", ":", "\n", "\n", "    ", "questeval", "=", "QuestEval", "(", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", "as", "loc_error", ":", "\n", "        ", "compute_questeval_score", "(", "questeval", ",", "res", "=", "-", "1", ",", "HYPS", "=", "[", "\"\"", "]", ",", "SRCS", "=", "None", ",", "REFSS", "=", "None", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", "as", "loc_error", ":", "\n", "        ", "compute_questeval_score", "(", "questeval", ",", "res", "=", "-", "1", ",", "HYPS", "=", "None", ",", "SRCS", "=", "[", "\"\"", "]", ",", "REFSS", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.units.test_questeval_metric.test_questeval_metric_text2text": [[23, 42], ["questeval.questeval_metric.QuestEval", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score"], "function", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score"], ["", "", "def", "test_questeval_metric_text2text", "(", ")", ":", "\n", "\n", "    ", "questeval", "=", "QuestEval", "(", ")", "\n", "\n", "# empty strings", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_empty", ",", "HYPS", "=", "HYP_empty", ",", "SRCS", "=", "SRC_empty", ",", "REFSS", "=", "REF_empty", ")", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_empty", ",", "HYPS", "=", "HYP_empty", ",", "SRCS", "=", "None", ",", "REFSS", "=", "REF_empty", ")", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_empty", ",", "HYPS", "=", "HYP_empty", ",", "SRCS", "=", "SRC_empty", ",", "REFSS", "=", "None", ")", "\n", "\n", "# default example - source and reference", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_t2t", "[", "'source_reference'", "]", ",", "HYPS", "=", "HYP_t2t", ",", "SRCS", "=", "SRC_t2t", ",", "REFSS", "=", "REF_t2t", ")", "\n", "# default example - source only", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_t2t", "[", "'source'", "]", ",", "HYPS", "=", "HYP_t2t", ",", "SRCS", "=", "SRC_t2t", ",", "REFSS", "=", "None", ")", "\n", "# default example - reference only", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_t2t", "[", "'reference'", "]", ",", "HYPS", "=", "HYP_t2t", ",", "SRCS", "=", "None", ",", "REFSS", "=", "REF_t2t", ")", "\n", "# default example - check that source and reference can be switched", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_t2t", "[", "'source'", "]", ",", "HYPS", "=", "HYP_t2t", ",", "SRCS", "=", "None", ",", "REFSS", "=", "[", "[", "s", "]", "for", "s", "in", "SRC_t2t", "]", ")", "\n", "# default example - check that source and reference are equally weighted", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_t2t", "[", "'source'", "]", ",", "HYPS", "=", "HYP_t2t", ",", "SRCS", "=", "SRC_t2t", ",", "REFSS", "=", "[", "[", "s", "]", "for", "s", "in", "SRC_t2t", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.units.test_questeval_metric.test_questeval_metric_data2text": [[43, 58], ["questeval.questeval_metric.QuestEval", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "pytest.raises", "tests.utils.helpers.compute_questeval_score"], "function", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score"], ["", "def", "test_questeval_metric_data2text", "(", ")", ":", "\n", "\n", "    ", "questeval", "=", "QuestEval", "(", "task", "=", "\"data2text\"", ")", "\n", "\n", "# Checking the source linearization", "\n", "from", "questeval", ".", "utils", "import", "WrongWebNlgFormat", "\n", "with", "pytest", ".", "raises", "(", "WrongWebNlgFormat", ")", "as", "loc_error", ":", "\n", "        ", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_D2T", "[", "'source_reference'", "]", ",", "HYPS", "=", "HYP_D2T", ",", "SRCS", "=", "SRC_D2T_wrong_format", ",", "REFSS", "=", "REF_D2T", ")", "\n", "\n", "# Data2text example - source and reference", "\n", "", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_D2T", "[", "'source_reference'", "]", ",", "HYPS", "=", "HYP_D2T", ",", "SRCS", "=", "SRC_D2T", ",", "REFSS", "=", "REF_D2T", ")", "\n", "# Data2text example - source", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_D2T", "[", "'source'", "]", ",", "HYPS", "=", "HYP_D2T", ",", "SRCS", "=", "SRC_D2T", ",", "REFSS", "=", "None", ")", "\n", "# Data2text example - reference", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_D2T", "[", "'reference'", "]", ",", "HYPS", "=", "HYP_D2T", ",", "SRCS", "=", "None", ",", "REFSS", "=", "REF_D2T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.units.test_questeval_metric.test_questeval_metric_summarization": [[59, 79], ["questeval.questeval_metric.QuestEval", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score", "tests.utils.helpers.compute_questeval_score"], "function", ["home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score", "home.repos.pwc.inspect_result.ThomasScialom_QuestEval.utils.helpers.compute_questeval_score"], ["", "def", "test_questeval_metric_summarization", "(", ")", ":", "\n", "\n", "    ", "questeval", "=", "QuestEval", "(", "task", "=", "\"summarization\"", ",", "do_weighter", "=", "True", ")", "\n", "\n", "# Summarization - source and reference", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_sum", "[", "'source_reference'", "]", ",", "HYPS", "=", "HYP_sum", ",", "SRCS", "=", "SRC_sum", ",", "REFSS", "=", "REF_sum", ")", "\n", "# Summarization - source", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_sum", "[", "'source'", "]", ",", "HYPS", "=", "HYP_sum", ",", "SRCS", "=", "SRC_sum", ",", "REFSS", "=", "None", ")", "\n", "# Summarization - reference", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_sum", "[", "'reference'", "]", ",", "HYPS", "=", "HYP_sum", ",", "SRCS", "=", "None", ",", "REFSS", "=", "REF_sum", ")", "\n", "\n", "# If we remove the weighter", "\n", "assert", "questeval", ".", "do_weighter", "==", "True", "\n", "questeval", ".", "do_weighter", "=", "False", "\n", "# Summarization - source and reference", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_sum", "[", "'source_reference_without_weighter'", "]", ",", "HYPS", "=", "HYP_sum", ",", "SRCS", "=", "SRC_sum", ",", "REFSS", "=", "REF_sum", ")", "\n", "# Summarization - source", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_sum", "[", "'source_without_weighter'", "]", ",", "HYPS", "=", "HYP_sum", ",", "SRCS", "=", "SRC_sum", ",", "REFSS", "=", "None", ")", "\n", "# Summarization - reference", "\n", "compute_questeval_score", "(", "questeval", "=", "questeval", ",", "res", "=", "RES_sum", "[", "'reference_without_weighter'", "]", ",", "HYPS", "=", "HYP_sum", ",", "SRCS", "=", "None", ",", "REFSS", "=", "REF_sum", ")", "\n", "", ""]]}