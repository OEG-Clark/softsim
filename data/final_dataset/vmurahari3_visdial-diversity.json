{"home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.options.readCommandLine": [[7, 179], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "vars", "os.path.join", "time.strftime", "os.path.join", "argparse.ArgumentParser.parse_args", "argparse.ArgumentParser.error", "time.gmtime", "random.randint", "str"], "function", ["None"], ["def", "readCommandLine", "(", "argv", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train and Test the Visual Dialog model'", ")", "\n", "\n", "#-------------------------------------------------------------------------", "\n", "# Data input settings", "\n", "parser", ".", "add_argument", "(", "'-inputImg'", ",", "default", "=", "'data/visdial/data_img.h5'", ",", "\n", "help", "=", "'HDF5 file with image features'", ")", "\n", "parser", ".", "add_argument", "(", "'-inputQues'", ",", "default", "=", "'data/visdial/chat_processed_data.h5'", ",", "\n", "help", "=", "'HDF5 file with preprocessed questions'", ")", "\n", "parser", ".", "add_argument", "(", "'-inputJson'", ",", "default", "=", "'data/visdial/chat_processed_params.json'", ",", "\n", "help", "=", "'JSON file with info and vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'-inputDenseJson'", ",", "default", "=", "'data/visdial/visdial_1.0_val_dense_annotations.json'", ",", "\n", "help", "=", "'JSON file with dense annotations'", ")", "\n", "parser", ".", "add_argument", "(", "'-cocoDir'", ",", "default", "=", "''", ",", "\n", "help", "=", "'Directory for coco images, optional'", ")", "\n", "parser", ".", "add_argument", "(", "'-cocoInfo'", ",", "default", "=", "''", ",", "\n", "help", "=", "'JSON file with coco split information'", ")", "\n", "\n", "#-------------------------------------------------------------------------", "\n", "# Logging settings", "\n", "parser", ".", "add_argument", "(", "'-verbose'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Level of verbosity (default 1 prints some info)'", ",", "\n", "choices", "=", "[", "1", ",", "2", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-savePath'", ",", "default", "=", "'checkpoints/'", ",", "\n", "help", "=", "'Path to save checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'-saveName'", ",", "default", "=", "''", ",", "\n", "help", "=", "'Name of save directory within savePath'", ")", "\n", "parser", ".", "add_argument", "(", "'-startFrom'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Copy weights from model at this path'", ")", "\n", "parser", ".", "add_argument", "(", "'-qstartFrom'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Copy weights from qbot model at this path'", ")", "\n", "parser", ".", "add_argument", "(", "'-continue'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Continue training from last epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'-enableVisdom'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Flag for enabling visdom logging'", ")", "\n", "parser", ".", "add_argument", "(", "'-visdomEnv'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Name of visdom environment for plotting'", ")", "\n", "parser", ".", "add_argument", "(", "'-visdomServer'", ",", "type", "=", "str", ",", "default", "=", "'127.0.0.1'", ",", "\n", "help", "=", "'Address of visdom server instance'", ")", "\n", "parser", ".", "add_argument", "(", "'-visdomServerPort'", ",", "type", "=", "int", ",", "default", "=", "8893", ",", "\n", "help", "=", "'Port of visdom server instance'", ")", "\n", "\n", "#-------------------------------------------------------------------------", "\n", "# Model params for both a-bot and q-bot", "\n", "parser", ".", "add_argument", "(", "'-randomSeed'", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "'Seed for random number generators'", ")", "\n", "parser", ".", "add_argument", "(", "'-imgEmbedSize'", ",", "default", "=", "300", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of the multimodal embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'-imgFeatureSize'", ",", "default", "=", "4096", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of the image feature'", ")", "\n", "parser", ".", "add_argument", "(", "'-embedSize'", ",", "default", "=", "300", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of input word embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'-rnnHiddenSize'", ",", "default", "=", "512", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of the LSTM state'", ")", "\n", "parser", ".", "add_argument", "(", "'-numLayers'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of layers in LSTM'", ")", "\n", "parser", ".", "add_argument", "(", "'-imgNorm'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Normalize the image feature. 1=yes, 0=no'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-AbotMCTS'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'Running Rollouts for rewards calculation for Abot. 1=yes, 0=no'", ")", "\n", "\n", "# A-Bot encoder + decoder", "\n", "parser", ".", "add_argument", "(", "'-encoder'", ",", "default", "=", "'hre-ques-lateim-hist'", ",", "\n", "help", "=", "'Name of the encoder to use'", ",", "\n", "choices", "=", "[", "'hre-ques-lateim-hist'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-decoder'", ",", "default", "=", "'gen'", ",", "\n", "help", "=", "'Name of the decoder to use (gen)'", ",", "\n", "choices", "=", "[", "'gen'", "]", ")", "\n", "# Q-bot encoder + decoder", "\n", "parser", ".", "add_argument", "(", "'-qencoder'", ",", "default", "=", "'hre-ques-lateim-hist'", ",", "\n", "help", "=", "'Name of the encoder to use'", ",", "\n", "choices", "=", "[", "'hre-ques-lateim-hist'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-qdecoder'", ",", "default", "=", "'gen'", ",", "\n", "help", "=", "'Name of the decoder to use (only gen supported now)'", ",", "\n", "choices", "=", "[", "'gen'", "]", ")", "\n", "\n", "#-------------------------------------------------------------------------", "\n", "# Optimization / training params", "\n", "parser", ".", "add_argument", "(", "'-trainMode'", ",", "default", "=", "'rl-full-QAf'", ",", "\n", "help", "=", "'What should train.py do?'", ",", "\n", "choices", "=", "[", "'sl-abot'", ",", "'sl-qbot'", ",", "'rl-full-QAf'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-numRounds'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of rounds of dialog (max 10)'", ")", "\n", "parser", ".", "add_argument", "(", "'-batchSize'", ",", "default", "=", "20", ",", "type", "=", "int", ",", "\n", "help", "=", "'Batch size (number of threads) '", "\n", "'(Adjust base on GPU memory)'", ")", "\n", "parser", ".", "add_argument", "(", "'-learningRate'", ",", "default", "=", "1e-3", ",", "type", "=", "float", ",", "\n", "help", "=", "'Learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'-minLRate'", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "'Minimum learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "'Dropout'", ")", "\n", "parser", ".", "add_argument", "(", "'-numEpochs'", ",", "default", "=", "85", ",", "type", "=", "int", ",", "help", "=", "'Epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'-lrDecayRate'", ",", "default", "=", "0.9997592083", ",", "type", "=", "float", ",", "\n", "help", "=", "'Decay for learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'-CELossCoeff'", ",", "default", "=", "1", ",", "type", "=", "float", ",", "\n", "help", "=", "'Coefficient for cross entropy loss'", ")", "\n", "parser", ".", "add_argument", "(", "'-RLLossCoeff'", ",", "default", "=", "20000", ",", "type", "=", "float", ",", "\n", "help", "=", "'Coefficient for cross entropy loss'", ")", "\n", "parser", ".", "add_argument", "(", "'-useCosSimilarityLoss'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'whether to use similarity loss'", ")", "\n", "parser", ".", "add_argument", "(", "'-CosSimilarityLossCoeff'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "\n", "help", "=", "'Coefficient for similarity loss'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-useHuberLoss'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'whether to use Huber loss'", ")", "\n", "parser", ".", "add_argument", "(", "'-HuberLossCoeff'", ",", "default", "=", "1", ",", "type", "=", "float", ",", "\n", "help", "=", "'Coefficient for Huber loss'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-featLossCoeff'", ",", "default", "=", "1000", ",", "type", "=", "float", ",", "\n", "help", "=", "'Coefficient for feature regression loss'", ")", "\n", "parser", ".", "add_argument", "(", "'-useCurriculum'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Use curriculum or for RL training (1) or not (0)'", ")", "\n", "parser", ".", "add_argument", "(", "'-freezeQFeatNet'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'Freeze weights of Q-bot feature network'", ")", "\n", "parser", ".", "add_argument", "(", "'-rlAbotReward'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Choose whether RL reward goes to A-Bot'", ")", "\n", "\n", "# annealing params\"", "\n", "parser", ".", "add_argument", "(", "'-annealingEndRound'", ",", "default", "=", "3", ",", "type", "=", "int", ",", "help", "=", "'Round at which annealing ends'", ")", "\n", "parser", ".", "add_argument", "(", "'-annealingReduceEpoch'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'Num epochs at which annealing happens'", ")", "\n", "\n", "# Other training environmnet settings", "\n", "parser", ".", "add_argument", "(", "'-useGPU'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Use GPU or CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'-numWorkers'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of worker threads in dataloader'", ")", "\n", "\n", "#-------------------------------------------------------------------------", "\n", "# Evaluation params", "\n", "parser", ".", "add_argument", "(", "'-beamSize'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Beam width for beam-search sampling'", ")", "\n", "parser", ".", "add_argument", "(", "'-evalModeList'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "\n", "help", "=", "'What task should the evaluator perform?'", ",", "\n", "choices", "=", "[", "'ABotRank'", ",", "'QBotRank'", ",", "'QABotsRank'", ",", "'dialog'", ",", "'human_study'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-evalSplit'", ",", "default", "=", "'val'", ",", "\n", "choices", "=", "[", "'train'", ",", "'val'", ",", "'test'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-evalTitle'", ",", "default", "=", "'eval'", ",", "\n", "help", "=", "'If generating a plot, include this in the title'", ")", "\n", "parser", ".", "add_argument", "(", "'-startEpoch'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'Starting epoch for evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'-endEpoch'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'Last epoch for evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'-useNDCG'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to use NDCG in evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'-discountFactor'", ",", "default", "=", "0.5", ",", "type", "=", "float", ",", "help", "=", "\"discount factor for future rewards\"", ")", "\n", "#-------------------------------------------------------------------------", "\n", "\n", "try", ":", "\n", "        ", "parsed", "=", "vars", "(", "parser", ".", "parse_args", "(", "args", "=", "argv", ")", ")", "\n", "", "except", "IOError", "as", "msg", ":", "\n", "        ", "parser", ".", "error", "(", "str", "(", "msg", ")", ")", "\n", "\n", "", "if", "parsed", "[", "'saveName'", "]", ":", "\n", "# Custom save file path", "\n", "        ", "parsed", "[", "'savePath'", "]", "=", "os", ".", "path", ".", "join", "(", "parsed", "[", "'savePath'", "]", ",", "\n", "parsed", "[", "'saveName'", "]", ")", "\n", "", "else", ":", "\n", "# Standard save path with time stamp", "\n", "        ", "import", "random", "\n", "timeStamp", "=", "strftime", "(", "'%d-%b-%y-%X-%a'", ",", "gmtime", "(", ")", ")", "\n", "parsed", "[", "'savePath'", "]", "=", "os", ".", "path", ".", "join", "(", "parsed", "[", "'savePath'", "]", ",", "timeStamp", ")", "\n", "parsed", "[", "'savePath'", "]", "+=", "'_{:0>6d}'", ".", "format", "(", "random", ".", "randint", "(", "0", ",", "10e6", ")", ")", "\n", "\n", "# check if history is needed", "\n", "", "parsed", "[", "'useHistory'", "]", "=", "True", "if", "'hist'", "in", "parsed", "[", "'encoder'", "]", "else", "False", "\n", "\n", "# check if image is needed", "\n", "if", "'lateim'", "in", "parsed", "[", "'encoder'", "]", ":", "\n", "        ", "parsed", "[", "'useIm'", "]", "=", "'late'", "\n", "", "elif", "'im'", "in", "parsed", "[", "'encoder'", "]", ":", "\n", "        ", "parsed", "[", "'useIm'", "]", "=", "True", "\n", "", "else", ":", "\n", "        ", "parsed", "[", "'useIm'", "]", "=", "False", "\n", "", "return", "parsed", "\n", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.train.batch_iter": [[131, 135], ["six.moves.range", "enumerate"], "function", ["None"], ["", "def", "batch_iter", "(", "dataloader", ")", ":", "\n", "    ", "for", "epochId", "in", "range", "(", "params", "[", "'numEpochs'", "]", ")", ":", "\n", "        ", "for", "idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "yield", "epochId", ",", "idx", ",", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.__init__": [[13, 166], ["six.iteritems", "tuple", "print", "len", "print", "print", "h5py.File", "print", "numpy.loadtxt", "setattr", "open", "json.load", "six.iteritems", "int", "print", "h5py.File", "print", "six.iteritems", "dataloader_human_study.VisDialDatasetHumanStudy.data[].size", "print", "dataloader_human_study.VisDialDatasetHumanStudy.prepareDataset", "setattr", "open", "json.load", "six.iteritems", "numpy.array", "torch.from_numpy", "print", "numpy.array", "print", "sklearn.preprocessing.normalize", "torch.FloatTensor", "six.iteritems", "hasattr", "getattr", "numpy.array", "torch.from_numpy", "open", "json.load", "os.path.join", "int"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.prepareDataset"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "subsets", ")", ":", "\n", "        ", "'''\n            Initialize the dataset with splits given by 'subsets', where\n            subsets is taken from ['train', 'val', 'test']\n\n            Notation:\n                'dtype' is a split taking values from ['train', 'val', 'test']\n                'stype' is a sqeuence type from ['ques', 'ans']\n        '''", "\n", "\n", "# By default, load Q-Bot, A-Bot and dialog options for A-Bot", "\n", "\n", "self", ".", "useQuestion", "=", "True", "\n", "self", ".", "useAnswer", "=", "True", "\n", "self", ".", "useOptions", "=", "True", "\n", "self", ".", "useHistory", "=", "True", "\n", "self", ".", "useIm", "=", "True", "\n", "self", ".", "useNDCG", "=", "params", "[", "\"useNDCG\"", "]", "\n", "\n", "# Absorb parameters", "\n", "for", "key", ",", "value", "in", "iteritems", "(", "params", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "self", ".", "subsets", "=", "tuple", "(", "subsets", ")", "\n", "self", ".", "numRounds", "=", "params", "[", "'numRounds'", "]", "\n", "\n", "print", "(", "'\\nDataloader loading json file: '", "+", "self", ".", "inputJson", ")", "\n", "with", "open", "(", "self", ".", "inputJson", ",", "'r'", ")", "as", "fileId", ":", "\n", "            ", "info", "=", "json", ".", "load", "(", "fileId", ")", "\n", "# Absorb values", "\n", "for", "key", ",", "value", "in", "iteritems", "(", "info", ")", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "", "if", "'val'", "in", "subsets", "and", "self", ".", "useNDCG", ":", "\n", "            ", "with", "open", "(", "self", ".", "inputDenseJson", ",", "'r'", ")", "as", "fileId", ":", "\n", "                ", "dense_annotation", "=", "json", ".", "load", "(", "fileId", ")", "\n", "self", ".", "dense_annotation", "=", "dense_annotation", "\n", "\n", "", "", "wordCount", "=", "len", "(", "self", ".", "word2ind", ")", "\n", "# Add <START> and <END> to vocabulary", "\n", "self", ".", "word2ind", "[", "'<START>'", "]", "=", "wordCount", "+", "1", "\n", "self", ".", "word2ind", "[", "'<END>'", "]", "=", "wordCount", "+", "2", "\n", "self", ".", "startToken", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "self", ".", "endToken", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "# Padding token is at index 0", "\n", "self", ".", "vocabSize", "=", "wordCount", "+", "3", "\n", "print", "(", "'Vocab size with <START>, <END>: %d'", "%", "self", ".", "vocabSize", ")", "\n", "\n", "# Construct the reverse map", "\n", "self", ".", "ind2word", "=", "{", "\n", "int", "(", "ind", ")", ":", "word", "\n", "for", "word", ",", "ind", "in", "iteritems", "(", "self", ".", "word2ind", ")", "\n", "}", "\n", "\n", "# Read questions, answers and options", "\n", "print", "(", "'Dataloader loading h5 file: '", "+", "self", ".", "inputQues", ")", "\n", "quesFile", "=", "h5py", ".", "File", "(", "self", ".", "inputQues", ",", "'r'", ")", "\n", "\n", "if", "self", ".", "useIm", ":", "\n", "# Read images", "\n", "            ", "print", "(", "'Dataloader loading h5 file: '", "+", "self", ".", "inputImg", ")", "\n", "imgFile", "=", "h5py", ".", "File", "(", "self", ".", "inputImg", ",", "'r'", ")", "\n", "\n", "# Number of data points in each split (train/val/test)", "\n", "", "self", ".", "numDataPoints", "=", "{", "}", "\n", "self", ".", "data", "=", "{", "}", "\n", "\n", "# map from load to save labels", "\n", "ioMap", "=", "{", "\n", "'ques_%s'", ":", "'%s_ques'", ",", "\n", "'ques_length_%s'", ":", "'%s_ques_len'", ",", "\n", "'ans_%s'", ":", "'%s_ans'", ",", "\n", "'ans_length_%s'", ":", "'%s_ans_len'", ",", "\n", "'ans_index_%s'", ":", "'%s_ans_ind'", ",", "\n", "'img_pos_%s'", ":", "'%s_img_pos'", ",", "\n", "'opt_%s'", ":", "'%s_opt'", ",", "\n", "'opt_length_%s'", ":", "'%s_opt_len'", ",", "\n", "'opt_list_%s'", ":", "'%s_opt_list'", "\n", "}", "\n", "\n", "# Processing every split in subsets", "\n", "for", "dtype", "in", "subsets", ":", "# dtype is in [train, val, test]", "\n", "            ", "print", "(", "\"\\nProcessing split [%s]...\"", "%", "dtype", ")", "\n", "if", "(", "'ques_%s'", "%", "dtype", ")", "not", "in", "quesFile", ":", "\n", "                ", "self", ".", "useQuestion", "=", "False", "\n", "", "if", "(", "'ans_%s'", "%", "dtype", ")", "not", "in", "quesFile", ":", "\n", "                ", "self", ".", "useAnswer", "=", "False", "\n", "", "if", "(", "'opt_%s'", "%", "dtype", ")", "not", "in", "quesFile", ":", "\n", "                ", "self", ".", "useOptions", "=", "False", "\n", "# read the question, answer, option related information", "\n", "", "for", "loadLabel", ",", "saveLabel", "in", "iteritems", "(", "ioMap", ")", ":", "\n", "                ", "if", "loadLabel", "%", "dtype", "not", "in", "quesFile", ":", "\n", "                    ", "continue", "\n", "", "dataMat", "=", "np", ".", "array", "(", "quesFile", "[", "loadLabel", "%", "dtype", "]", ",", "dtype", "=", "'int64'", ")", "\n", "self", ".", "data", "[", "saveLabel", "%", "dtype", "]", "=", "torch", ".", "from_numpy", "(", "dataMat", ")", "\n", "\n", "# Read image features, if needed", "\n", "", "if", "self", ".", "useIm", ":", "\n", "                ", "print", "(", "'Reading image features...'", ")", "\n", "imgFeats", "=", "np", ".", "array", "(", "imgFile", "[", "'images_'", "+", "dtype", "]", ")", "\n", "\n", "if", "not", "self", ".", "imgNorm", ":", "\n", "                    ", "continue", "\n", "# normalize, if needed", "\n", "", "print", "(", "'Normalizing image features..'", ")", "\n", "imgFeats", "=", "normalize", "(", "imgFeats", ",", "axis", "=", "1", ",", "norm", "=", "'l2'", ")", "\n", "\n", "# save img features", "\n", "self", ".", "data", "[", "'%s_img_fv'", "%", "dtype", "]", "=", "torch", ".", "FloatTensor", "(", "imgFeats", ")", "\n", "# Visdial", "\n", "if", "hasattr", "(", "self", ",", "'unique_img_train'", ")", "and", "params", "[", "'cocoDir'", "]", ":", "\n", "                    ", "coco_dir", "=", "params", "[", "'cocoDir'", "]", "\n", "with", "open", "(", "params", "[", "'cocoInfo'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                        ", "coco_info", "=", "json", ".", "load", "(", "f", ")", "\n", "", "id_to_fname", "=", "{", "\n", "im", "[", "'id'", "]", ":", "im", "[", "'file_path'", "]", "\n", "for", "im", "in", "coco_info", "[", "'images'", "]", "\n", "}", "\n", "cocoids", "=", "getattr", "(", "self", ",", "'unique_img_%s'", "%", "dtype", ")", "\n", "if", "'.jpg'", "not", "in", "cocoids", "[", "0", "]", ":", "\n", "                        ", "img_fnames", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "coco_dir", ",", "id_to_fname", "[", "int", "(", "cocoid", ")", "]", ")", "\n", "for", "cocoid", "in", "cocoids", "\n", "]", "\n", "", "else", ":", "\n", "                        ", "img_fnames", "=", "cocoids", "\n", "", "self", ".", "data", "[", "'%s_img_fnames'", "%", "dtype", "]", "=", "img_fnames", "\n", "\n", "# read the history, if needed", "\n", "", "", "if", "self", ".", "useHistory", ":", "\n", "                ", "captionMap", "=", "{", "\n", "'cap_%s'", ":", "'%s_cap'", ",", "\n", "'cap_length_%s'", ":", "'%s_cap_len'", "\n", "}", "\n", "for", "loadLabel", ",", "saveLabel", "in", "iteritems", "(", "captionMap", ")", ":", "\n", "                    ", "mat", "=", "np", ".", "array", "(", "quesFile", "[", "loadLabel", "%", "dtype", "]", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "data", "[", "saveLabel", "%", "dtype", "]", "=", "torch", ".", "from_numpy", "(", "mat", ")", "\n", "\n", "# Number of data points", "\n", "", "", "self", ".", "numDataPoints", "[", "dtype", "]", "=", "self", ".", "data", "[", "dtype", "+", "'_cap'", "]", ".", "size", "(", "0", ")", "\n", "\n", "# Prepare dataset for training", "\n", "", "for", "dtype", "in", "subsets", ":", "\n", "            ", "print", "(", "\"\\nSequence processing for [%s]...\"", "%", "dtype", ")", "\n", "self", ".", "prepareDataset", "(", "dtype", ")", "\n", "", "print", "(", "\"\"", ")", "\n", "\n", "# Default pytorch loader dtype is set to train", "\n", "# load image indices in the test set on which the human study is done. ", "\n", "if", "'train'", "in", "subsets", ":", "\n", "            ", "self", ".", "_split", "=", "'train'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_split", "=", "subsets", "[", "0", "]", "\n", "", "self", ".", "rand_idx", "=", "np", ".", "loadtxt", "(", "'data/human_study/human_study_indices.csv'", ")", "\n", "self", ".", "NUM_SAMPLES", "=", "self", ".", "rand_idx", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.split": [[171, 175], ["None"], "methods", ["None"], ["", "@", "split", ".", "setter", "\n", "def", "split", "(", "self", ",", "split", ")", ":", "\n", "        ", "assert", "split", "in", "self", ".", "subsets", "# ['train', 'val', 'test']", "\n", "self", ".", "_split", "=", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.prepareDataset": [[180, 198], ["dataloader_human_study.VisDialDatasetHumanStudy.processCaption", "dataloader_human_study.VisDialDatasetHumanStudy.processOptions", "dataloader_human_study.VisDialDatasetHumanStudy.processSequence", "dataloader_human_study.VisDialDatasetHumanStudy.processSequence"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.processCaption", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.processOptions", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence"], ["", "def", "prepareDataset", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "if", "self", ".", "useHistory", ":", "\n", "            ", "self", ".", "processCaption", "(", "dtype", ")", "\n", "\n", "# prefix/postfix with <START> and <END>", "\n", "", "if", "self", ".", "useOptions", ":", "\n", "            ", "self", ".", "processOptions", "(", "dtype", ")", "\n", "# options are 1-indexed, changed to 0-indexed", "\n", "self", ".", "data", "[", "dtype", "+", "'_opt'", "]", "-=", "1", "\n", "\n", "# process answers and questions", "\n", "", "if", "self", ".", "useAnswer", ":", "\n", "            ", "self", ".", "processSequence", "(", "dtype", ",", "stype", "=", "'ans'", ")", "\n", "# 1 indexed to 0 indexed", "\n", "if", "dtype", "!=", "'test'", ":", "\n", "                ", "self", ".", "data", "[", "dtype", "+", "'_ans_ind'", "]", "-=", "1", "\n", "", "", "if", "self", ".", "useQuestion", ":", "\n", "            ", "self", ".", "processSequence", "(", "dtype", ",", "stype", "=", "'ques'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.processSequence": [[199, 234], ["seq.size", "torch.Size", "torch.LongTensor().fill_", "six.moves.range", "six.moves.range", "torch.LongTensor", "print"], "methods", ["None"], ["", "", "def", "processSequence", "(", "self", ",", "dtype", ",", "stype", "=", "'ans'", ")", ":", "\n", "        ", "'''\n        Add <START> and <END> token to answers or questions.\n        Arguments:\n            'dtype'    : Split to use among ['train', 'val', 'test']\n            'sentType' : Sequence type, either 'ques' or 'ans'\n        '''", "\n", "assert", "stype", "in", "[", "'ques'", ",", "'ans'", "]", "\n", "prefix", "=", "dtype", "+", "\"_\"", "+", "stype", "\n", "\n", "seq", "=", "self", ".", "data", "[", "prefix", "]", "\n", "seqLen", "=", "self", ".", "data", "[", "prefix", "+", "'_len'", "]", "\n", "\n", "numConvs", ",", "numRounds", ",", "maxAnsLen", "=", "seq", ".", "size", "(", ")", "\n", "newSize", "=", "torch", ".", "Size", "(", "[", "numConvs", ",", "numRounds", ",", "maxAnsLen", "+", "2", "]", ")", "\n", "sequence", "=", "torch", ".", "LongTensor", "(", "newSize", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "# decodeIn begins with <START>", "\n", "sequence", "[", ":", ",", ":", ",", "0", "]", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "endTokenId", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "\n", "for", "thId", "in", "range", "(", "numConvs", ")", ":", "\n", "            ", "for", "rId", "in", "range", "(", "numRounds", ")", ":", "\n", "                ", "length", "=", "seqLen", "[", "thId", ",", "rId", "]", "\n", "if", "length", "==", "0", ":", "\n", "                    ", "print", "(", "'Warning: Skipping empty %s sequence at (%d, %d)'", "%", "(", "stype", ",", "thId", ",", "rId", ")", ")", "\n", "continue", "\n", "\n", "", "sequence", "[", "thId", ",", "rId", ",", "1", ":", "length", "+", "1", "]", "=", "seq", "[", "thId", ",", "rId", ",", ":", "length", "]", "\n", "sequence", "[", "thId", ",", "rId", ",", "length", "+", "1", "]", "=", "endTokenId", "\n", "\n", "# Sequence length is number of tokens + 1", "\n", "", "", "self", ".", "data", "[", "prefix", "+", "\"_len\"", "]", "=", "seqLen", "+", "1", "\n", "self", ".", "data", "[", "prefix", "]", "=", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.processCaption": [[235, 267], ["seq.size", "torch.Size", "torch.LongTensor().fill_", "six.moves.range", "torch.LongTensor", "print"], "methods", ["None"], ["", "def", "processCaption", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "'''\n        Add <START> and <END> token to caption.\n        Arguments:\n            'dtype'    : Split to use among ['train', 'val', 'test']\n        '''", "\n", "prefix", "=", "dtype", "+", "'_cap'", "\n", "\n", "seq", "=", "self", ".", "data", "[", "prefix", "]", "\n", "seqLen", "=", "self", ".", "data", "[", "prefix", "+", "'_len'", "]", "\n", "\n", "numConvs", ",", "maxCapLen", "=", "seq", ".", "size", "(", ")", "\n", "newSize", "=", "torch", ".", "Size", "(", "[", "numConvs", ",", "maxCapLen", "+", "2", "]", ")", "\n", "sequence", "=", "torch", ".", "LongTensor", "(", "newSize", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "# decodeIn begins with <START>", "\n", "sequence", "[", ":", ",", "0", "]", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "endTokenId", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "\n", "for", "thId", "in", "range", "(", "numConvs", ")", ":", "\n", "            ", "length", "=", "seqLen", "[", "thId", "]", "\n", "if", "length", "==", "0", ":", "\n", "                ", "print", "(", "'Warning: Skipping empty %s sequence at (%d)'", "%", "(", "stype", ",", "\n", "thId", ")", ")", "\n", "continue", "\n", "\n", "", "sequence", "[", "thId", ",", "1", ":", "length", "+", "1", "]", "=", "seq", "[", "thId", ",", ":", "length", "]", "\n", "sequence", "[", "thId", ",", "length", "+", "1", "]", "=", "endTokenId", "\n", "\n", "# Sequence length is number of tokens + 1", "\n", "", "self", ".", "data", "[", "prefix", "+", "\"_len\"", "]", "=", "seqLen", "+", "1", "\n", "self", ".", "data", "[", "prefix", "]", "=", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.processOptions": [[268, 293], ["ans.size", "torch.Size", "torch.LongTensor().fill_", "six.moves.range", "torch.LongTensor", "print"], "methods", ["None"], ["", "def", "processOptions", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "ans", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_list'", "]", "\n", "ansLen", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_len'", "]", "\n", "\n", "ansListLen", ",", "maxAnsLen", "=", "ans", ".", "size", "(", ")", "\n", "\n", "newSize", "=", "torch", ".", "Size", "(", "[", "ansListLen", ",", "maxAnsLen", "+", "2", "]", ")", "\n", "options", "=", "torch", ".", "LongTensor", "(", "newSize", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "# decodeIn begins with <START>", "\n", "options", "[", ":", ",", "0", "]", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "endTokenId", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "\n", "for", "ansId", "in", "range", "(", "ansListLen", ")", ":", "\n", "            ", "length", "=", "ansLen", "[", "ansId", "]", "\n", "if", "length", "==", "0", ":", "\n", "                ", "print", "(", "'Warning: Skipping empty option answer list at (%d)'", "%", "ansId", ")", "\n", "continue", "\n", "\n", "", "options", "[", "ansId", ",", "1", ":", "length", "+", "1", "]", "=", "ans", "[", "ansId", ",", ":", "length", "]", "\n", "options", "[", "ansId", ",", "length", "+", "1", "]", "=", "endTokenId", "\n", "\n", "", "self", ".", "data", "[", "dtype", "+", "'_opt_len'", "]", "=", "ansLen", "+", "1", "\n", "self", ".", "data", "[", "dtype", "+", "'_opt_seq'", "]", "=", "options", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.__len__": [[298, 301], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# Assert that loader_dtype is in subsets ['train', 'val', 'test']", "\n", "        ", "return", "self", ".", "NUM_SAMPLES", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.__getitem__": [[302, 308], ["print", "int", "dataloader_human_study.VisDialDatasetHumanStudy.getIndexItem", "type"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.getIndexItem"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "print", "(", "type", "(", "self", ".", "rand_idx", "[", "idx", "]", ")", ")", "\n", "idx", "=", "int", "(", "self", ".", "rand_idx", "[", "idx", "]", ")", "\n", "item", "=", "self", ".", "getIndexItem", "(", "self", ".", "_split", ",", "idx", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.collate_fn": [[309, 340], ["out.keys", "[].contiguous", "out.keys", "[].contiguous", "out.keys", "[].contiguous", "out.keys", "[].contiguous", "torch.LongTensor", "torch.stack", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "out", "=", "{", "}", "\n", "\n", "mergedBatch", "=", "{", "key", ":", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", "for", "key", "in", "batch", "[", "0", "]", "}", "\n", "for", "key", "in", "mergedBatch", ":", "\n", "            ", "if", "key", "==", "'img_fname'", "or", "key", "==", "'index'", ":", "\n", "                ", "out", "[", "key", "]", "=", "mergedBatch", "[", "key", "]", "\n", "", "elif", "key", "==", "'cap_len'", ":", "\n", "# 'cap_lens' are single integers, need special treatment", "\n", "                ", "out", "[", "key", "]", "=", "torch", ".", "LongTensor", "(", "mergedBatch", "[", "key", "]", ")", "\n", "", "else", ":", "\n", "                ", "out", "[", "key", "]", "=", "torch", ".", "stack", "(", "mergedBatch", "[", "key", "]", ",", "0", ")", "\n", "\n", "# Dynamic shaping of padded batch", "\n", "", "", "if", "'ques'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "quesLen", "=", "out", "[", "'ques_len'", "]", "+", "1", "\n", "out", "[", "'ques'", "]", "=", "out", "[", "'ques'", "]", "[", ":", ",", ":", ",", ":", "torch", ".", "max", "(", "quesLen", ")", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "'ans'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "ansLen", "=", "out", "[", "'ans_len'", "]", "+", "1", "\n", "out", "[", "'ans'", "]", "=", "out", "[", "'ans'", "]", "[", ":", ",", ":", ",", ":", "torch", ".", "max", "(", "ansLen", ")", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "'cap'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "capLen", "=", "out", "[", "'cap_len'", "]", "+", "1", "\n", "out", "[", "'cap'", "]", "=", "out", "[", "'cap'", "]", "[", ":", ",", ":", "torch", ".", "max", "(", "capLen", ")", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "'opt'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "optLen", "=", "out", "[", "'opt_len'", "]", "+", "1", "\n", "out", "[", "'opt'", "]", "=", "out", "[", "'opt'", "]", "[", ":", ",", ":", ",", ":", ",", ":", "torch", ".", "max", "(", "optLen", ")", "+", "2", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader_human_study.VisDialDatasetHumanStudy.getIndexItem": [[345, 404], ["list", "torch.Size", "optInds.view", "dataloader_human_study.VisDialDatasetHumanStudy.data[].index_select", "optLens.view.view.view", "dataloader_human_study.VisDialDatasetHumanStudy.data[].index_select", "dataloader_human_study.VisDialDatasetHumanStudy.view", "torch.LongTensor", "torch.FloatTensor", "torch.LongTensor", "optInds.size"], "methods", ["None"], ["", "def", "getIndexItem", "(", "self", ",", "dtype", ",", "idx", ")", ":", "\n", "        ", "item", "=", "{", "'index'", ":", "idx", "}", "\n", "\n", "# get question", "\n", "if", "self", ".", "useQuestion", ":", "\n", "            ", "ques", "=", "self", ".", "data", "[", "dtype", "+", "'_ques'", "]", "[", "idx", "]", "\n", "quesLen", "=", "self", ".", "data", "[", "dtype", "+", "'_ques_len'", "]", "[", "idx", "]", "\n", "item", "[", "'ques'", "]", "=", "ques", "\n", "item", "[", "'ques_len'", "]", "=", "quesLen", "\n", "\n", "# get answer", "\n", "", "if", "self", ".", "useAnswer", ":", "\n", "            ", "ans", "=", "self", ".", "data", "[", "dtype", "+", "'_ans'", "]", "[", "idx", "]", "\n", "ansLen", "=", "self", ".", "data", "[", "dtype", "+", "'_ans_len'", "]", "[", "idx", "]", "\n", "item", "[", "'ans_len'", "]", "=", "ansLen", "\n", "item", "[", "'ans'", "]", "=", "ans", "\n", "\n", "# get caption", "\n", "", "if", "self", ".", "useHistory", ":", "\n", "            ", "cap", "=", "self", ".", "data", "[", "dtype", "+", "'_cap'", "]", "[", "idx", "]", "\n", "capLen", "=", "self", ".", "data", "[", "dtype", "+", "'_cap_len'", "]", "[", "idx", "]", "\n", "item", "[", "'cap'", "]", "=", "cap", "\n", "item", "[", "'cap_len'", "]", "=", "capLen", "\n", "\n", "", "if", "self", ".", "useOptions", "and", "dtype", "!=", "'test'", ":", "\n", "            ", "optInds", "=", "self", ".", "data", "[", "dtype", "+", "'_opt'", "]", "[", "idx", "]", "\n", "ansId", "=", "self", ".", "data", "[", "dtype", "+", "'_ans_ind'", "]", "[", "idx", "]", "\n", "\n", "optSize", "=", "list", "(", "optInds", ".", "size", "(", ")", ")", "\n", "newSize", "=", "torch", ".", "Size", "(", "optSize", "+", "[", "-", "1", "]", ")", "\n", "\n", "indVector", "=", "optInds", ".", "view", "(", "-", "1", ")", "\n", "optLens", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_len'", "]", ".", "index_select", "(", "0", ",", "indVector", ")", "\n", "optLens", "=", "optLens", ".", "view", "(", "optSize", ")", "\n", "\n", "opts", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_seq'", "]", ".", "index_select", "(", "0", ",", "indVector", ")", "\n", "\n", "item", "[", "'opt'", "]", "=", "opts", ".", "view", "(", "newSize", ")", "\n", "item", "[", "'opt_len'", "]", "=", "optLens", "\n", "item", "[", "'ans_id'", "]", "=", "ansId", "\n", "\n", "# if image needed", "\n", "", "if", "self", ".", "useIm", ":", "\n", "            ", "item", "[", "'img_feat'", "]", "=", "self", ".", "data", "[", "dtype", "+", "'_img_fv'", "]", "[", "idx", "]", "\n", "# item['img_fname'] = self.data[dtype + '_img_fnames'][idx]", "\n", "if", "dtype", "+", "'_img_labels'", "in", "self", ".", "data", ":", "\n", "                ", "item", "[", "'img_label'", "]", "=", "self", ".", "data", "[", "dtype", "+", "'_img_labels'", "]", "[", "idx", "]", "\n", "\n", "# dense annotations if val set", "\n", "", "", "if", "dtype", "==", "'val'", "and", "self", ".", "useNDCG", ":", "\n", "\n", "            ", "round_id", "=", "self", ".", "dense_annotation", "[", "idx", "]", "[", "'round_id'", "]", "\n", "gt_relevance", "=", "self", ".", "dense_annotation", "[", "idx", "]", "[", "'gt_relevance'", "]", "\n", "image_id", "=", "self", ".", "dense_annotation", "[", "idx", "]", "[", "'image_id'", "]", "\n", "item", "[", "\"round_id\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "round_id", "]", ")", "\n", "item", "[", "\"gt_relevance\"", "]", "=", "torch", ".", "FloatTensor", "(", "gt_relevance", ")", "\n", "item", "[", "\"image_id\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "image_id", "]", ")", "\n", "\n", "", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.__init__": [[13, 163], ["six.iteritems", "tuple", "print", "len", "print", "print", "h5py.File", "print", "setattr", "open", "json.load", "six.iteritems", "int", "print", "h5py.File", "print", "six.iteritems", "dataloader.VisDialDataset.data[].size", "print", "dataloader.VisDialDataset.prepareDataset", "setattr", "open", "json.load", "six.iteritems", "numpy.array", "torch.from_numpy", "print", "numpy.array", "print", "sklearn.preprocessing.normalize", "torch.FloatTensor", "six.iteritems", "hasattr", "getattr", "numpy.array", "torch.from_numpy", "open", "json.load", "os.path.join", "int"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.prepareDataset"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "subsets", ")", ":", "\n", "        ", "'''\n            Initialize the dataset with splits given by 'subsets', where\n            subsets is taken from ['train', 'val', 'test']\n\n            Notation:\n                'dtype' is a split taking values from ['train', 'val', 'test']\n                'stype' is a sqeuence type from ['ques', 'ans']\n        '''", "\n", "\n", "# By default, load Q-Bot, A-Bot and dialog options for A-Bot", "\n", "self", ".", "useQuestion", "=", "True", "\n", "self", ".", "useAnswer", "=", "True", "\n", "self", ".", "useOptions", "=", "True", "\n", "self", ".", "useHistory", "=", "True", "\n", "self", ".", "useIm", "=", "True", "\n", "self", ".", "useNDCG", "=", "params", "[", "\"useNDCG\"", "]", "\n", "\n", "# Absorb parameters", "\n", "for", "key", ",", "value", "in", "iteritems", "(", "params", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "self", ".", "subsets", "=", "tuple", "(", "subsets", ")", "\n", "self", ".", "numRounds", "=", "params", "[", "'numRounds'", "]", "\n", "\n", "print", "(", "'\\nDataloader loading json file: '", "+", "self", ".", "inputJson", ")", "\n", "with", "open", "(", "self", ".", "inputJson", ",", "'r'", ")", "as", "fileId", ":", "\n", "            ", "info", "=", "json", ".", "load", "(", "fileId", ")", "\n", "# Absorb values", "\n", "for", "key", ",", "value", "in", "iteritems", "(", "info", ")", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "", "if", "'val'", "in", "subsets", "and", "self", ".", "useNDCG", ":", "\n", "            ", "with", "open", "(", "self", ".", "inputDenseJson", ",", "'r'", ")", "as", "fileId", ":", "\n", "                ", "dense_annotation", "=", "json", ".", "load", "(", "fileId", ")", "\n", "self", ".", "dense_annotation", "=", "dense_annotation", "\n", "\n", "", "", "wordCount", "=", "len", "(", "self", ".", "word2ind", ")", "\n", "# Add <START> and <END> to vocabulary", "\n", "self", ".", "word2ind", "[", "'<START>'", "]", "=", "wordCount", "+", "1", "\n", "self", ".", "word2ind", "[", "'<END>'", "]", "=", "wordCount", "+", "2", "\n", "self", ".", "startToken", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "self", ".", "endToken", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "# Padding token is at index 0", "\n", "self", ".", "vocabSize", "=", "wordCount", "+", "3", "\n", "print", "(", "'Vocab size with <START>, <END>: %d'", "%", "self", ".", "vocabSize", ")", "\n", "\n", "# Construct the reverse map", "\n", "self", ".", "ind2word", "=", "{", "\n", "int", "(", "ind", ")", ":", "word", "\n", "for", "word", ",", "ind", "in", "iteritems", "(", "self", ".", "word2ind", ")", "\n", "}", "\n", "\n", "# Read questions, answers and options", "\n", "print", "(", "'Dataloader loading h5 file: '", "+", "self", ".", "inputQues", ")", "\n", "quesFile", "=", "h5py", ".", "File", "(", "self", ".", "inputQues", ",", "'r'", ")", "\n", "\n", "if", "self", ".", "useIm", ":", "\n", "# Read images", "\n", "            ", "print", "(", "'Dataloader loading h5 file: '", "+", "self", ".", "inputImg", ")", "\n", "imgFile", "=", "h5py", ".", "File", "(", "self", ".", "inputImg", ",", "'r'", ")", "\n", "\n", "# Number of data points in each split (train/val/test)", "\n", "", "self", ".", "numDataPoints", "=", "{", "}", "\n", "self", ".", "data", "=", "{", "}", "\n", "\n", "# map from load to save labels", "\n", "ioMap", "=", "{", "\n", "'ques_%s'", ":", "'%s_ques'", ",", "\n", "'ques_length_%s'", ":", "'%s_ques_len'", ",", "\n", "'ans_%s'", ":", "'%s_ans'", ",", "\n", "'ans_length_%s'", ":", "'%s_ans_len'", ",", "\n", "'ans_index_%s'", ":", "'%s_ans_ind'", ",", "\n", "'img_pos_%s'", ":", "'%s_img_pos'", ",", "\n", "'opt_%s'", ":", "'%s_opt'", ",", "\n", "'opt_length_%s'", ":", "'%s_opt_len'", ",", "\n", "'opt_list_%s'", ":", "'%s_opt_list'", ",", "\n", "'num_rounds_%s'", ":", "'%s_num_rounds'", "\n", "}", "\n", "\n", "# Processing every split in subsets", "\n", "for", "dtype", "in", "subsets", ":", "# dtype is in [train, val, test]", "\n", "            ", "print", "(", "\"\\nProcessing split [%s]...\"", "%", "dtype", ")", "\n", "if", "(", "'ques_%s'", "%", "dtype", ")", "not", "in", "quesFile", ":", "\n", "                ", "self", ".", "useQuestion", "=", "False", "\n", "", "if", "(", "'ans_%s'", "%", "dtype", ")", "not", "in", "quesFile", ":", "\n", "                ", "self", ".", "useAnswer", "=", "False", "\n", "", "if", "(", "'opt_%s'", "%", "dtype", ")", "not", "in", "quesFile", ":", "\n", "                ", "self", ".", "useOptions", "=", "False", "\n", "# read the question, answer, option related information", "\n", "", "for", "loadLabel", ",", "saveLabel", "in", "iteritems", "(", "ioMap", ")", ":", "\n", "                ", "if", "loadLabel", "%", "dtype", "not", "in", "quesFile", ":", "\n", "                    ", "continue", "\n", "", "dataMat", "=", "np", ".", "array", "(", "quesFile", "[", "loadLabel", "%", "dtype", "]", ",", "dtype", "=", "'int64'", ")", "\n", "self", ".", "data", "[", "saveLabel", "%", "dtype", "]", "=", "torch", ".", "from_numpy", "(", "dataMat", ")", "\n", "\n", "# Read image features, if needed", "\n", "", "if", "self", ".", "useIm", ":", "\n", "                ", "print", "(", "'Reading image features...'", ")", "\n", "imgFeats", "=", "np", ".", "array", "(", "imgFile", "[", "'images_'", "+", "dtype", "]", ")", "\n", "\n", "if", "not", "self", ".", "imgNorm", ":", "\n", "                    ", "continue", "\n", "# normalize, if needed", "\n", "", "print", "(", "'Normalizing image features..'", ")", "\n", "imgFeats", "=", "normalize", "(", "imgFeats", ",", "axis", "=", "1", ",", "norm", "=", "'l2'", ")", "\n", "\n", "# save img features", "\n", "self", ".", "data", "[", "'%s_img_fv'", "%", "dtype", "]", "=", "torch", ".", "FloatTensor", "(", "imgFeats", ")", "\n", "# Visdial", "\n", "if", "hasattr", "(", "self", ",", "'unique_img_train'", ")", "and", "params", "[", "'cocoDir'", "]", ":", "\n", "                    ", "coco_dir", "=", "params", "[", "'cocoDir'", "]", "\n", "with", "open", "(", "params", "[", "'cocoInfo'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                        ", "coco_info", "=", "json", ".", "load", "(", "f", ")", "\n", "", "id_to_fname", "=", "{", "\n", "im", "[", "'id'", "]", ":", "im", "[", "'file_path'", "]", "\n", "for", "im", "in", "coco_info", "[", "'images'", "]", "\n", "}", "\n", "cocoids", "=", "getattr", "(", "self", ",", "'unique_img_%s'", "%", "dtype", ")", "\n", "if", "'.jpg'", "not", "in", "cocoids", "[", "0", "]", ":", "\n", "                        ", "img_fnames", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "coco_dir", ",", "id_to_fname", "[", "int", "(", "cocoid", ")", "]", ")", "\n", "for", "cocoid", "in", "cocoids", "\n", "]", "\n", "", "else", ":", "\n", "                        ", "img_fnames", "=", "cocoids", "\n", "", "self", ".", "data", "[", "'%s_img_fnames'", "%", "dtype", "]", "=", "img_fnames", "\n", "\n", "# read the history, if needed", "\n", "", "", "if", "self", ".", "useHistory", ":", "\n", "                ", "captionMap", "=", "{", "\n", "'cap_%s'", ":", "'%s_cap'", ",", "\n", "'cap_length_%s'", ":", "'%s_cap_len'", "\n", "}", "\n", "for", "loadLabel", ",", "saveLabel", "in", "iteritems", "(", "captionMap", ")", ":", "\n", "                    ", "mat", "=", "np", ".", "array", "(", "quesFile", "[", "loadLabel", "%", "dtype", "]", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "data", "[", "saveLabel", "%", "dtype", "]", "=", "torch", ".", "from_numpy", "(", "mat", ")", "\n", "\n", "# Number of data points", "\n", "", "", "self", ".", "numDataPoints", "[", "dtype", "]", "=", "self", ".", "data", "[", "dtype", "+", "'_cap'", "]", ".", "size", "(", "0", ")", "\n", "\n", "# Prepare dataset for training", "\n", "", "for", "dtype", "in", "subsets", ":", "\n", "            ", "print", "(", "\"\\nSequence processing for [%s]...\"", "%", "dtype", ")", "\n", "self", ".", "prepareDataset", "(", "dtype", ")", "\n", "", "print", "(", "\"\"", ")", "\n", "\n", "# Default pytorch loader dtype is set to train", "\n", "if", "'train'", "in", "subsets", ":", "\n", "            ", "self", ".", "_split", "=", "'train'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_split", "=", "subsets", "[", "0", "]", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.split": [[173, 177], ["None"], "methods", ["None"], ["", "@", "split", ".", "setter", "\n", "def", "split", "(", "self", ",", "split", ")", ":", "\n", "        ", "assert", "split", "in", "self", ".", "subsets", "# ['train', 'val', 'test']", "\n", "self", ".", "_split", "=", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.prepareDataset": [[182, 200], ["dataloader.VisDialDataset.processCaption", "dataloader.VisDialDataset.processOptions", "dataloader.VisDialDataset.processSequence", "dataloader.VisDialDataset.processSequence"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.processCaption", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.processOptions", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence"], ["", "def", "prepareDataset", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "if", "self", ".", "useHistory", ":", "\n", "            ", "self", ".", "processCaption", "(", "dtype", ")", "\n", "\n", "# prefix/postfix with <START> and <END>", "\n", "", "if", "self", ".", "useOptions", ":", "\n", "            ", "self", ".", "processOptions", "(", "dtype", ")", "\n", "# options are 1-indexed, changed to 0-indexed", "\n", "self", ".", "data", "[", "dtype", "+", "'_opt'", "]", "-=", "1", "\n", "\n", "# process answers and questions", "\n", "", "if", "self", ".", "useAnswer", ":", "\n", "            ", "self", ".", "processSequence", "(", "dtype", ",", "stype", "=", "'ans'", ")", "\n", "# 1 indexed to 0 indexed", "\n", "if", "dtype", "!=", "'test'", ":", "\n", "                ", "self", ".", "data", "[", "dtype", "+", "'_ans_ind'", "]", "-=", "1", "\n", "", "", "if", "self", ".", "useQuestion", ":", "\n", "            ", "self", ".", "processSequence", "(", "dtype", ",", "stype", "=", "'ques'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.processSequence": [[201, 236], ["seq.size", "torch.Size", "torch.LongTensor().fill_", "six.moves.range", "six.moves.range", "torch.LongTensor", "print"], "methods", ["None"], ["", "", "def", "processSequence", "(", "self", ",", "dtype", ",", "stype", "=", "'ans'", ")", ":", "\n", "        ", "'''\n        Add <START> and <END> token to answers or questions.\n        Arguments:\n            'dtype'    : Split to use among ['train', 'val', 'test']\n            'sentType' : Sequence type, either 'ques' or 'ans'\n        '''", "\n", "assert", "stype", "in", "[", "'ques'", ",", "'ans'", "]", "\n", "prefix", "=", "dtype", "+", "\"_\"", "+", "stype", "\n", "\n", "seq", "=", "self", ".", "data", "[", "prefix", "]", "\n", "seqLen", "=", "self", ".", "data", "[", "prefix", "+", "'_len'", "]", "\n", "\n", "numConvs", ",", "numRounds", ",", "maxAnsLen", "=", "seq", ".", "size", "(", ")", "\n", "newSize", "=", "torch", ".", "Size", "(", "[", "numConvs", ",", "numRounds", ",", "maxAnsLen", "+", "2", "]", ")", "\n", "sequence", "=", "torch", ".", "LongTensor", "(", "newSize", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "# decodeIn begins with <START>", "\n", "sequence", "[", ":", ",", ":", ",", "0", "]", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "endTokenId", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "\n", "for", "thId", "in", "range", "(", "numConvs", ")", ":", "\n", "            ", "for", "rId", "in", "range", "(", "numRounds", ")", ":", "\n", "                ", "length", "=", "seqLen", "[", "thId", ",", "rId", "]", "\n", "if", "length", "==", "0", ":", "\n", "                    ", "print", "(", "'Warning: Skipping empty %s sequence at (%d, %d)'", "%", "(", "stype", ",", "thId", ",", "rId", ")", ")", "\n", "continue", "\n", "\n", "", "sequence", "[", "thId", ",", "rId", ",", "1", ":", "length", "+", "1", "]", "=", "seq", "[", "thId", ",", "rId", ",", ":", "length", "]", "\n", "sequence", "[", "thId", ",", "rId", ",", "length", "+", "1", "]", "=", "endTokenId", "\n", "\n", "# Sequence length is number of tokens + 1", "\n", "", "", "self", ".", "data", "[", "prefix", "+", "\"_len\"", "]", "=", "seqLen", "+", "1", "\n", "self", ".", "data", "[", "prefix", "]", "=", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.processCaption": [[237, 269], ["seq.size", "torch.Size", "torch.LongTensor().fill_", "six.moves.range", "torch.LongTensor", "print"], "methods", ["None"], ["", "def", "processCaption", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "'''\n        Add <START> and <END> token to caption.\n        Arguments:\n            'dtype'    : Split to use among ['train', 'val', 'test']\n        '''", "\n", "prefix", "=", "dtype", "+", "'_cap'", "\n", "\n", "seq", "=", "self", ".", "data", "[", "prefix", "]", "\n", "seqLen", "=", "self", ".", "data", "[", "prefix", "+", "'_len'", "]", "\n", "\n", "numConvs", ",", "maxCapLen", "=", "seq", ".", "size", "(", ")", "\n", "newSize", "=", "torch", ".", "Size", "(", "[", "numConvs", ",", "maxCapLen", "+", "2", "]", ")", "\n", "sequence", "=", "torch", ".", "LongTensor", "(", "newSize", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "# decodeIn begins with <START>", "\n", "sequence", "[", ":", ",", "0", "]", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "endTokenId", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "\n", "for", "thId", "in", "range", "(", "numConvs", ")", ":", "\n", "            ", "length", "=", "seqLen", "[", "thId", "]", "\n", "if", "length", "==", "0", ":", "\n", "                ", "print", "(", "'Warning: Skipping empty %s sequence at (%d)'", "%", "(", "stype", ",", "\n", "thId", ")", ")", "\n", "continue", "\n", "\n", "", "sequence", "[", "thId", ",", "1", ":", "length", "+", "1", "]", "=", "seq", "[", "thId", ",", ":", "length", "]", "\n", "sequence", "[", "thId", ",", "length", "+", "1", "]", "=", "endTokenId", "\n", "\n", "# Sequence length is number of tokens + 1", "\n", "", "self", ".", "data", "[", "prefix", "+", "\"_len\"", "]", "=", "seqLen", "+", "1", "\n", "self", ".", "data", "[", "prefix", "]", "=", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.processOptions": [[270, 295], ["ans.size", "torch.Size", "torch.LongTensor().fill_", "six.moves.range", "torch.LongTensor", "print"], "methods", ["None"], ["", "def", "processOptions", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "ans", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_list'", "]", "\n", "ansLen", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_len'", "]", "\n", "\n", "ansListLen", ",", "maxAnsLen", "=", "ans", ".", "size", "(", ")", "\n", "\n", "newSize", "=", "torch", ".", "Size", "(", "[", "ansListLen", ",", "maxAnsLen", "+", "2", "]", ")", "\n", "options", "=", "torch", ".", "LongTensor", "(", "newSize", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "# decodeIn begins with <START>", "\n", "options", "[", ":", ",", "0", "]", "=", "self", ".", "word2ind", "[", "'<START>'", "]", "\n", "endTokenId", "=", "self", ".", "word2ind", "[", "'<END>'", "]", "\n", "\n", "for", "ansId", "in", "range", "(", "ansListLen", ")", ":", "\n", "            ", "length", "=", "ansLen", "[", "ansId", "]", "\n", "if", "length", "==", "0", ":", "\n", "                ", "print", "(", "'Warning: Skipping empty option answer list at (%d)'", "%", "ansId", ")", "\n", "continue", "\n", "\n", "", "options", "[", "ansId", ",", "1", ":", "length", "+", "1", "]", "=", "ans", "[", "ansId", ",", ":", "length", "]", "\n", "options", "[", "ansId", ",", "length", "+", "1", "]", "=", "endTokenId", "\n", "\n", "", "self", ".", "data", "[", "dtype", "+", "'_opt_len'", "]", "=", "ansLen", "+", "1", "\n", "self", ".", "data", "[", "dtype", "+", "'_opt_seq'", "]", "=", "options", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.__len__": [[300, 303], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# Assert that loader_dtype is in subsets ['train', 'val', 'test']", "\n", "        ", "return", "self", ".", "numDataPoints", "[", "self", ".", "_split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.__getitem__": [[304, 307], ["dataloader.VisDialDataset.getIndexItem"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.getIndexItem"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "item", "=", "self", ".", "getIndexItem", "(", "self", ".", "_split", ",", "idx", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.collate_fn": [[308, 339], ["out.keys", "[].contiguous", "out.keys", "[].contiguous", "out.keys", "[].contiguous", "out.keys", "[].contiguous", "torch.LongTensor", "torch.stack", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "out", "=", "{", "}", "\n", "\n", "mergedBatch", "=", "{", "key", ":", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", "for", "key", "in", "batch", "[", "0", "]", "}", "\n", "for", "key", "in", "mergedBatch", ":", "\n", "            ", "if", "key", "==", "'img_fname'", "or", "key", "==", "'index'", ":", "\n", "                ", "out", "[", "key", "]", "=", "mergedBatch", "[", "key", "]", "\n", "", "elif", "key", "==", "'cap_len'", ":", "\n", "# 'cap_lens' are single integers, need special treatment", "\n", "                ", "out", "[", "key", "]", "=", "torch", ".", "LongTensor", "(", "mergedBatch", "[", "key", "]", ")", "\n", "", "else", ":", "\n", "                ", "out", "[", "key", "]", "=", "torch", ".", "stack", "(", "mergedBatch", "[", "key", "]", ",", "0", ")", "\n", "\n", "# Dynamic shaping of padded batch", "\n", "", "", "if", "'ques'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "quesLen", "=", "out", "[", "'ques_len'", "]", "+", "1", "\n", "out", "[", "'ques'", "]", "=", "out", "[", "'ques'", "]", "[", ":", ",", ":", ",", ":", "torch", ".", "max", "(", "quesLen", ")", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "'ans'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "ansLen", "=", "out", "[", "'ans_len'", "]", "+", "1", "\n", "out", "[", "'ans'", "]", "=", "out", "[", "'ans'", "]", "[", ":", ",", ":", ",", ":", "torch", ".", "max", "(", "ansLen", ")", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "'cap'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "capLen", "=", "out", "[", "'cap_len'", "]", "+", "1", "\n", "out", "[", "'cap'", "]", "=", "out", "[", "'cap'", "]", "[", ":", ",", ":", "torch", ".", "max", "(", "capLen", ")", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "'opt'", "in", "out", ".", "keys", "(", ")", ":", "\n", "            ", "optLen", "=", "out", "[", "'opt_len'", "]", "+", "1", "\n", "out", "[", "'opt'", "]", "=", "out", "[", "'opt'", "]", "[", ":", ",", ":", ",", ":", ",", ":", "torch", ".", "max", "(", "optLen", ")", "+", "2", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.None.dataloader.VisDialDataset.getIndexItem": [[344, 420], ["torch.LongTensor", "list", "torch.Size", "optInds.view", "dataloader.VisDialDataset.data[].index_select", "optLens.view.view.view", "dataloader.VisDialDataset.data[].index_select", "dataloader.VisDialDataset.view", "torch.LongTensor", "torch.FloatTensor", "torch.LongTensor", "optInds.size"], "methods", ["None"], ["", "def", "getIndexItem", "(", "self", ",", "dtype", ",", "idx", ")", ":", "\n", "        ", "item", "=", "{", "'index'", ":", "idx", "}", "\n", "\n", "item", "[", "'num_rounds'", "]", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "data", "[", "dtype", "+", "'_num_rounds'", "]", "[", "idx", "]", "]", ")", "\n", "\n", "# get question", "\n", "if", "self", ".", "useQuestion", ":", "\n", "            ", "ques", "=", "self", ".", "data", "[", "dtype", "+", "'_ques'", "]", "[", "idx", "]", "\n", "quesLen", "=", "self", ".", "data", "[", "dtype", "+", "'_ques_len'", "]", "[", "idx", "]", "\n", "\n", "# hacky! packpadded sequence error for zero length sequences in 0.3. add 1 here if split is test.", "\n", "# zero length seqences have length 1 because of start token", "\n", "if", "dtype", "==", "'test'", ":", "\n", "                ", "quesLen", "[", "quesLen", "==", "1", "]", "=", "2", "\n", "\n", "", "item", "[", "'ques'", "]", "=", "ques", "\n", "item", "[", "'ques_len'", "]", "=", "quesLen", "\n", "\n", "# get answer", "\n", "", "if", "self", ".", "useAnswer", ":", "\n", "            ", "ans", "=", "self", ".", "data", "[", "dtype", "+", "'_ans'", "]", "[", "idx", "]", "\n", "ansLen", "=", "self", ".", "data", "[", "dtype", "+", "'_ans_len'", "]", "[", "idx", "]", "\n", "# hacky! packpadded sequence error for zero length sequences in 0.3. add 1 here if split is test.", "\n", "# zero length seqences have length 1 because of start token", "\n", "\n", "if", "dtype", "==", "'test'", ":", "\n", "                ", "ansLen", "[", "ansLen", "==", "1", "]", "=", "2", "\n", "\n", "", "item", "[", "'ans_len'", "]", "=", "ansLen", "\n", "item", "[", "'ans'", "]", "=", "ans", "\n", "\n", "# get caption", "\n", "", "if", "self", ".", "useHistory", ":", "\n", "            ", "cap", "=", "self", ".", "data", "[", "dtype", "+", "'_cap'", "]", "[", "idx", "]", "\n", "capLen", "=", "self", ".", "data", "[", "dtype", "+", "'_cap_len'", "]", "[", "idx", "]", "\n", "item", "[", "'cap'", "]", "=", "cap", "\n", "item", "[", "'cap_len'", "]", "=", "capLen", "\n", "\n", "", "if", "self", ".", "useOptions", ":", "\n", "            ", "optInds", "=", "self", ".", "data", "[", "dtype", "+", "'_opt'", "]", "[", "idx", "]", "\n", "ansId", "=", "None", "\n", "if", "dtype", "!=", "'test'", ":", "\n", "                ", "ansId", "=", "self", ".", "data", "[", "dtype", "+", "'_ans_ind'", "]", "[", "idx", "]", "\n", "\n", "", "optSize", "=", "list", "(", "optInds", ".", "size", "(", ")", ")", "\n", "newSize", "=", "torch", ".", "Size", "(", "optSize", "+", "[", "-", "1", "]", ")", "\n", "\n", "indVector", "=", "optInds", ".", "view", "(", "-", "1", ")", "\n", "optLens", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_len'", "]", ".", "index_select", "(", "0", ",", "indVector", ")", "\n", "optLens", "=", "optLens", ".", "view", "(", "optSize", ")", "\n", "\n", "opts", "=", "self", ".", "data", "[", "dtype", "+", "'_opt_seq'", "]", ".", "index_select", "(", "0", ",", "indVector", ")", "\n", "\n", "item", "[", "'opt'", "]", "=", "opts", ".", "view", "(", "newSize", ")", "\n", "item", "[", "'opt_len'", "]", "=", "optLens", "\n", "if", "dtype", "!=", "'test'", ":", "\n", "                ", "item", "[", "'ans_id'", "]", "=", "ansId", "\n", "\n", "# if image needed", "\n", "", "", "if", "self", ".", "useIm", ":", "\n", "            ", "item", "[", "'img_feat'", "]", "=", "self", ".", "data", "[", "dtype", "+", "'_img_fv'", "]", "[", "idx", "]", "\n", "# item['img_fname'] = self.data[dtype + '_img_fnames'][idx]", "\n", "if", "dtype", "+", "'_img_labels'", "in", "self", ".", "data", ":", "\n", "                ", "item", "[", "'img_label'", "]", "=", "self", ".", "data", "[", "dtype", "+", "'_img_labels'", "]", "[", "idx", "]", "\n", "\n", "# dense annotations if val set", "\n", "", "", "if", "dtype", "==", "'val'", "and", "self", ".", "useNDCG", ":", "\n", "\n", "            ", "round_id", "=", "self", ".", "dense_annotation", "[", "idx", "]", "[", "'round_id'", "]", "\n", "gt_relevance", "=", "self", ".", "dense_annotation", "[", "idx", "]", "[", "'gt_relevance'", "]", "\n", "image_id", "=", "self", ".", "dense_annotation", "[", "idx", "]", "[", "'image_id'", "]", "\n", "item", "[", "\"round_id\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "round_id", "]", ")", "\n", "item", "[", "\"gt_relevance\"", "]", "=", "torch", ".", "FloatTensor", "(", "gt_relevance", ")", "\n", "item", "[", "\"image_id\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "image_id", "]", ")", "\n", "\n", "", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.initializeWeights": [[14, 45], ["root.modules", "type", "module.weight.data.size", "module.weight.data.size", "math.sqrt", "module.weight.data.copy_", "hasattr", "module.bias.data.fill_", "torch.randn", "torch.randn", "torch.randn", "module.named_parameters", "type", "param.data.fill_", "param.size", "param.size", "math.sqrt", "param.data.copy_", "torch.randn", "torch.randn", "torch.randn"], "function", ["None"], ["def", "initializeWeights", "(", "root", ",", "itype", "=", "'xavier'", ")", ":", "\n", "    ", "assert", "itype", "==", "'xavier'", ",", "'Only Xavier initialization supported'", "\n", "\n", "for", "module", "in", "root", ".", "modules", "(", ")", ":", "\n", "# Initialize weights", "\n", "        ", "name", "=", "type", "(", "module", ")", ".", "__name__", "\n", "# If linear or embedding", "\n", "if", "name", "in", "[", "'Embedding'", ",", "'Linear'", "]", ":", "\n", "            ", "fanIn", "=", "module", ".", "weight", ".", "data", ".", "size", "(", "0", ")", "\n", "fanOut", "=", "module", ".", "weight", ".", "data", ".", "size", "(", "1", ")", "\n", "\n", "factor", "=", "math", ".", "sqrt", "(", "2.0", "/", "(", "fanIn", "+", "fanOut", ")", ")", "\n", "weight", "=", "torch", ".", "randn", "(", "fanIn", ",", "fanOut", ")", "*", "factor", "\n", "module", ".", "weight", ".", "data", ".", "copy_", "(", "weight", ")", "\n", "", "elif", "'LSTM'", "in", "name", ":", "\n", "            ", "for", "name", ",", "param", "in", "module", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'bias'", "in", "name", ":", "\n", "                    ", "param", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "", "else", ":", "\n", "                    ", "fanIn", "=", "param", ".", "size", "(", "0", ")", "\n", "fanOut", "=", "param", ".", "size", "(", "1", ")", "\n", "\n", "factor", "=", "math", ".", "sqrt", "(", "2.0", "/", "(", "fanIn", "+", "fanOut", ")", ")", "\n", "weight", "=", "torch", ".", "randn", "(", "fanIn", ",", "fanOut", ")", "*", "factor", "\n", "param", ".", "data", ".", "copy_", "(", "weight", ")", "\n", "", "", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "# Check for bias and reset", "\n", "", "if", "hasattr", "(", "module", ",", "'bias'", ")", "and", "type", "(", "module", ".", "bias", ")", "!=", "bool", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.saveModel": [[47, 53], ["torch.save", "torch.save", "torch.save", "model.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.save", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.save", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.save"], ["", "", "", "def", "saveModel", "(", "model", ",", "optimizer", ",", "saveFile", ",", "params", ")", ":", "\n", "    ", "torch", ".", "save", "(", "{", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'params'", ":", "params", ",", "\n", "}", ",", "saveFile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.loadModel": [[55, 165], ["Questioner.encoder.parameters", "Questioner.decoder.parameters", "params.copy.copy", "print", "list", "Answerer", "Questioner.cuda", "p.register_hook", "p.register_hook", "Questioner.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "set().union", "Questioner", "set", "set", "print", "print", "str"], "function", ["None"], ["", "def", "loadModel", "(", "params", ",", "agent", "=", "'abot'", ",", "overwrite", "=", "False", ",", "multiGPU", "=", "False", ")", ":", "\n", "    ", "if", "overwrite", "is", "False", ":", "\n", "        ", "params", "=", "params", ".", "copy", "(", ")", "\n", "", "loadedParams", "=", "{", "}", "\n", "# should be everything used in encoderParam, decoderParam below", "\n", "encoderOptions", "=", "[", "\n", "'encoder'", ",", "'vocabSize'", ",", "'embedSize'", ",", "'rnnHiddenSize'", ",", "'numLayers'", ",", "\n", "'useHistory'", ",", "'useIm'", ",", "'imgEmbedSize'", ",", "'imgFeatureSize'", ",", "'numRounds'", ",", "\n", "'dropout'", "\n", "]", "\n", "decoderOptions", "=", "[", "\n", "'decoder'", ",", "'vocabSize'", ",", "'embedSize'", ",", "'rnnHiddenSize'", ",", "'numLayers'", ",", "\n", "'dropout'", "\n", "]", "\n", "modelOptions", "=", "encoderOptions", "+", "decoderOptions", "\n", "\n", "mdict", "=", "None", "\n", "gpuFlag", "=", "params", "[", "'useGPU'", "]", "\n", "continueFlag", "=", "params", "[", "'continue'", "]", "\n", "numEpochs", "=", "params", "[", "'numEpochs'", "]", "\n", "startArg", "=", "'startFrom'", "if", "agent", "==", "'abot'", "else", "'qstartFrom'", "\n", "if", "continueFlag", ":", "\n", "        ", "assert", "params", "[", "startArg", "]", ",", "\"Can't continue training without a \\\n                                    checkpoint\"", "\n", "\n", "# load a model from disk if it is given", "\n", "", "if", "params", "[", "startArg", "]", ":", "\n", "        ", "print", "(", "'Loading model (weights and config) from {}'", ".", "format", "(", "\n", "params", "[", "startArg", "]", ")", ")", "\n", "\n", "if", "gpuFlag", ":", "\n", "            ", "mdict", "=", "torch", ".", "load", "(", "params", "[", "startArg", "]", ")", "\n", "", "else", ":", "\n", "            ", "mdict", "=", "torch", ".", "load", "(", "params", "[", "startArg", "]", ",", "\n", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "\n", "# Model options is a union of standard model options defined", "\n", "# above and parameters loaded from checkpoint", "\n", "", "modelOptions", "=", "list", "(", "set", "(", "modelOptions", ")", ".", "union", "(", "set", "(", "mdict", "[", "'params'", "]", ")", ")", ")", "\n", "for", "opt", "in", "modelOptions", ":", "\n", "            ", "if", "opt", "not", "in", "params", ":", "\n", "# Loading options from a checkpoint which are", "\n", "# necessary for continuing training, but are", "\n", "# not present in original parameter list.", "\n", "                ", "if", "continueFlag", ":", "\n", "                    ", "print", "(", "\"Loaded option '%s' from checkpoint\"", "%", "opt", ")", "\n", "params", "[", "opt", "]", "=", "mdict", "[", "'params'", "]", "[", "opt", "]", "\n", "loadedParams", "[", "opt", "]", "=", "mdict", "[", "'params'", "]", "[", "opt", "]", "\n", "\n", "", "", "elif", "params", "[", "opt", "]", "!=", "mdict", "[", "'params'", "]", "[", "opt", "]", ":", "\n", "# When continuing training from a checkpoint, overwriting", "\n", "# parameters loaded from checkpoint is okay.", "\n", "                ", "if", "continueFlag", ":", "\n", "                    ", "print", "(", "\"Overwriting param '%s'\"", "%", "str", "(", "opt", ")", ")", "\n", "params", "[", "opt", "]", "=", "mdict", "[", "'params'", "]", "[", "opt", "]", "\n", "\n", "", "", "", "params", "[", "'continue'", "]", "=", "continueFlag", "\n", "params", "[", "'numEpochs'", "]", "=", "numEpochs", "\n", "params", "[", "'useGPU'", "]", "=", "gpuFlag", "\n", "\n", "if", "params", "[", "'continue'", "]", ":", "\n", "            ", "assert", "'ckpt_lRate'", "in", "params", ",", "\"Checkpoint does not have\\\n                info for restoring learning rate and optimizer.\"", "\n", "\n", "# assert False, \"STOP right there, criminal scum!\"", "\n", "\n", "# Initialize model class", "\n", "", "", "encoderParam", "=", "{", "k", ":", "params", "[", "k", "]", "for", "k", "in", "encoderOptions", "}", "\n", "decoderParam", "=", "{", "k", ":", "params", "[", "k", "]", "for", "k", "in", "decoderOptions", "}", "\n", "\n", "encoderParam", "[", "'startToken'", "]", "=", "encoderParam", "[", "'vocabSize'", "]", "-", "2", "\n", "encoderParam", "[", "'endToken'", "]", "=", "encoderParam", "[", "'vocabSize'", "]", "-", "1", "\n", "decoderParam", "[", "'startToken'", "]", "=", "decoderParam", "[", "'vocabSize'", "]", "-", "2", "\n", "decoderParam", "[", "'endToken'", "]", "=", "decoderParam", "[", "'vocabSize'", "]", "-", "1", "\n", "\n", "if", "agent", "==", "'abot'", ":", "\n", "        ", "encoderParam", "[", "'type'", "]", "=", "params", "[", "'encoder'", "]", "\n", "decoderParam", "[", "'type'", "]", "=", "params", "[", "'decoder'", "]", "\n", "encoderParam", "[", "'isAnswerer'", "]", "=", "True", "\n", "from", "visdial", ".", "models", ".", "answerer", "import", "Answerer", "\n", "model", "=", "Answerer", "(", "encoderParam", ",", "decoderParam", ",", "multiGPU", "=", "multiGPU", ")", "\n", "\n", "", "elif", "agent", "==", "'qbot'", ":", "\n", "        ", "encoderParam", "[", "'type'", "]", "=", "params", "[", "'qencoder'", "]", "\n", "decoderParam", "[", "'type'", "]", "=", "params", "[", "'qdecoder'", "]", "\n", "encoderParam", "[", "'isAnswerer'", "]", "=", "False", "\n", "encoderParam", "[", "'useIm'", "]", "=", "False", "\n", "from", "visdial", ".", "models", ".", "questioner", "import", "Questioner", "\n", "model", "=", "Questioner", "(", "\n", "encoderParam", ",", "\n", "decoderParam", ",", "\n", "imgFeatureSize", "=", "encoderParam", "[", "'imgFeatureSize'", "]", ",", "multiGPU", "=", "multiGPU", ")", "\n", "\n", "", "if", "params", "[", "'useGPU'", "]", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "for", "p", "in", "model", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "register_hook", "(", "clampGrad", ")", "\n", "", "for", "p", "in", "model", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "register_hook", "(", "clampGrad", ")", "\n", "# NOTE: model.parameters() should be used here, otherwise immediate", "\n", "# child modules in model will not have gradient clamping", "\n", "\n", "# copy parameters if specified", "\n", "", "if", "mdict", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "mdict", "[", "'model'", "]", ")", "\n", "optim_state", "=", "mdict", "[", "'optimizer'", "]", "\n", "", "else", ":", "\n", "        ", "optim_state", "=", "None", "\n", "", "return", "model", ",", "loadedParams", ",", "optim_state", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.clampGrad": [[167, 173], ["grad.data.clamp_"], "function", ["None"], ["", "def", "clampGrad", "(", "grad", ",", "limit", "=", "5.0", ")", ":", "\n", "    ", "'''\n    Gradient clip by value\n    '''", "\n", "grad", ".", "data", ".", "clamp_", "(", "min", "=", "-", "limit", ",", "max", "=", "limit", ")", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.getSortedOrder": [[175, 183], ["torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "isinstance", "sortedLen.cpu().numpy().tolist.cpu().numpy().tolist", "lens.contiguous().view", "sortedLen.cpu().numpy().tolist.cpu().numpy", "lens.contiguous", "sortedLen.cpu().numpy().tolist.cpu"], "function", ["None"], ["", "def", "getSortedOrder", "(", "lens", ")", ":", "\n", "    ", "sortedLen", ",", "fwdOrder", "=", "torch", ".", "sort", "(", "\n", "lens", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "bwdOrder", "=", "torch", ".", "sort", "(", "fwdOrder", ")", "\n", "if", "isinstance", "(", "sortedLen", ",", "Variable", ")", ":", "\n", "        ", "sortedLen", "=", "sortedLen", ".", "data", "\n", "", "sortedLen", "=", "sortedLen", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "return", "sortedLen", ",", "fwdOrder", ",", "bwdOrder", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.dynamicRNN": [[185, 228], ["utilities.getSortedOrder", "seqInput.index_select", "torch.nn.utils.rnn.pack_padded_sequence", "rnnModel.flatten_parameters", "rnnModel", "h_n[].index_select", "h_n.index_select.index_select", "c_n.index_select.index_select", "x.index_select", "hx[].size"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.getSortedOrder"], ["", "def", "dynamicRNN", "(", "rnnModel", ",", "\n", "seqInput", ",", "\n", "seqLens", ",", "\n", "initialState", "=", "None", ",", "\n", "returnStates", "=", "False", ")", ":", "\n", "    ", "'''\n    Inputs:\n        rnnModel     : Any torch.nn RNN model\n        seqInput     : (batchSize, maxSequenceLength, embedSize)\n                        Input sequence tensor (padded) for RNN model\n        seqLens      : batchSize length torch.LongTensor or numpy array\n        initialState : Initial (hidden, cell) states of RNN\n\n    Output:\n        A single tensor of shape (batchSize, rnnHiddenSize) corresponding\n        to the outputs of the RNN model at the last time step of each input\n        sequence. If returnStates is True, also return a tuple of hidden\n        and cell states at every layer of size (num_layers, batchSize,\n        rnnHiddenSize)\n    '''", "\n", "sortedLen", ",", "fwdOrder", ",", "bwdOrder", "=", "getSortedOrder", "(", "seqLens", ")", "\n", "sortedSeqInput", "=", "seqInput", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "fwdOrder", ")", "\n", "packedSeqInput", "=", "pack_padded_sequence", "(", "\n", "sortedSeqInput", ",", "lengths", "=", "sortedLen", ",", "batch_first", "=", "True", ")", "\n", "\n", "if", "initialState", "is", "not", "None", ":", "\n", "        ", "hx", "=", "initialState", "\n", "sortedHx", "=", "[", "x", ".", "index_select", "(", "dim", "=", "1", ",", "index", "=", "fwdOrder", ")", "for", "x", "in", "hx", "]", "\n", "assert", "hx", "[", "0", "]", ".", "size", "(", "0", ")", "==", "rnnModel", ".", "num_layers", "# Matching num_layers", "\n", "", "else", ":", "\n", "        ", "hx", "=", "None", "\n", "\n", "", "rnnModel", ".", "flatten_parameters", "(", ")", "\n", "_", ",", "(", "h_n", ",", "c_n", ")", "=", "rnnModel", "(", "packedSeqInput", ",", "hx", ")", "\n", "\n", "rnn_output", "=", "h_n", "[", "-", "1", "]", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "bwdOrder", ")", "\n", "\n", "if", "returnStates", ":", "\n", "        ", "h_n", "=", "h_n", ".", "index_select", "(", "dim", "=", "1", ",", "index", "=", "bwdOrder", ")", "\n", "c_n", "=", "c_n", ".", "index_select", "(", "dim", "=", "1", ",", "index", "=", "bwdOrder", ")", "\n", "return", "rnn_output", ",", "(", "h_n", ",", "c_n", ")", "\n", "", "else", ":", "\n", "        ", "return", "rnn_output", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.maskedNll": [[229, 265], ["gtSeq.data.new().fill_", "torch.autograd.Variable", "target.data.gt", "isinstance", "isinstance", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable", "seq.size", "gtSeq.data.new", "torch.gather", "torch.gather", "torch.gather", "torch.sum", "torch.sum", "torch.sum", "gtSeq.size", "target.unsqueeze", "torch.autograd.Variable.float"], "function", ["None"], ["", "", "def", "maskedNll", "(", "seq", ",", "gtSeq", ",", "returnScores", "=", "False", ")", ":", "\n", "    ", "'''\n    Compute the NLL loss of ground truth (target) sentence given the\n    model. Assumes that gtSeq has <START> and <END> token surrounding\n    every sequence and gtSeq is left aligned (i.e. right padded)\n\n    S: <START>, E: <END>, W: word token, 0: padding token, P(*): logProb\n\n        gtSeq:\n            [ S     W1    W2  E   0   0]\n        Teacher forced logProbs (seq):\n            [P(W1) P(W2) P(E) -   -   -]\n        Required gtSeq (target):\n            [  W1    W2    E  0   0   0]\n        Mask (non-zero tokens in target):\n            [  1     1     1  0   0   0]\n    '''", "\n", "# Shifting gtSeq 1 token left to remove <START>", "\n", "padColumn", "=", "gtSeq", ".", "data", ".", "new", "(", "gtSeq", ".", "size", "(", "0", ")", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "padColumn", "=", "Variable", "(", "padColumn", ")", "\n", "target", "=", "torch", ".", "cat", "(", "[", "gtSeq", ",", "padColumn", "]", ",", "dim", "=", "1", ")", "[", ":", ",", "1", ":", "]", "\n", "\n", "# Generate a mask of non-padding (non-zero) tokens", "\n", "mask", "=", "target", ".", "data", ".", "gt", "(", "0", ")", "\n", "loss", "=", "0", "\n", "if", "isinstance", "(", "gtSeq", ",", "Variable", ")", ":", "\n", "        ", "mask", "=", "Variable", "(", "mask", ",", "volatile", "=", "gtSeq", ".", "volatile", ")", "\n", "", "assert", "isinstance", "(", "target", ",", "Variable", ")", "\n", "gtLogProbs", "=", "torch", ".", "gather", "(", "seq", ",", "2", ",", "target", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "# Mean sentence probs:", "\n", "# gtLogProbs = gtLogProbs/(mask.float().sum(1).view(-1,1))", "\n", "if", "returnScores", ":", "\n", "        ", "return", "(", "gtLogProbs", "*", "(", "mask", ".", "float", "(", ")", ")", ")", ".", "sum", "(", "1", ")", "\n", "", "maskedLL", "=", "torch", ".", "masked_select", "(", "gtLogProbs", ",", "mask", ")", "\n", "nll_loss", "=", "-", "torch", ".", "sum", "(", "maskedLL", ")", "/", "seq", ".", "size", "(", "0", ")", "\n", "return", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.concatPaddedSequences": [[267, 341], ["torch.cat", "torch.cat", "torch.cat", "seq1.size", "seq2.size", "torch.cat.size", "seq1.size", "range", "torch.cat", "torch.cat", "torch.cat", "concat_list.append", "RuntimeError", "F.pad.unsqueeze", "torch.pad", "print", "torch.pad", "print", "torch.cat", "torch.cat", "torch.cat", "print", "print", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "concatPaddedSequences", "(", "seq1", ",", "seqLens1", ",", "seq2", ",", "seqLens2", ",", "padding", "=", "'right'", ")", ":", "\n", "    ", "'''\n    Concates two input sequences of shape (batchSize, seqLength). The\n    corresponding lengths tensor is of shape (batchSize). Padding sense\n    of input sequences needs to be specified as 'right' or 'left'\n\n    Args:\n        seq1, seqLens1 : First sequence tokens and length\n        seq2, seqLens2 : Second sequence tokens and length\n        padding        : Padding sense of input sequences - either\n                         'right' or 'left'\n    '''", "\n", "\n", "concat_list", "=", "[", "]", "\n", "cat_seq", "=", "torch", ".", "cat", "(", "[", "seq1", ",", "seq2", "]", ",", "dim", "=", "1", ")", "\n", "maxLen1", "=", "seq1", ".", "size", "(", "1", ")", "\n", "maxLen2", "=", "seq2", ".", "size", "(", "1", ")", "\n", "maxCatLen", "=", "cat_seq", ".", "size", "(", "1", ")", "\n", "batchSize", "=", "seq1", ".", "size", "(", "0", ")", "\n", "for", "b_idx", "in", "range", "(", "batchSize", ")", ":", "\n", "        ", "len_1", "=", "seqLens1", "[", "b_idx", "]", ".", "data", "[", "0", "]", "\n", "len_2", "=", "seqLens2", "[", "b_idx", "]", ".", "data", "[", "0", "]", "\n", "\n", "cat_len_", "=", "len_1", "+", "len_2", "\n", "if", "cat_len_", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Both input sequences are empty\"", ")", "\n", "\n", "", "elif", "padding", "==", "'left'", ":", "\n", "            ", "pad_len_1", "=", "maxLen1", "-", "len_1", "\n", "pad_len_2", "=", "maxLen2", "-", "len_2", "\n", "if", "len_1", "==", "0", ":", "\n", "                ", "print", "(", "\"[Warning] Empty input sequence 1 given to \"", "\n", "\"concatPaddedSequences\"", ")", "\n", "cat_", "=", "seq2", "[", "b_idx", "]", "[", "pad_len_2", ":", "]", "\n", "\n", "", "elif", "len_2", "==", "0", ":", "\n", "                ", "print", "(", "\"[Warning] Empty input sequence 2 given to \"", "\n", "\"concatPaddedSequences\"", ")", "\n", "cat_", "=", "seq1", "[", "b_idx", "]", "[", "pad_len_1", ":", "]", "\n", "\n", "", "else", ":", "\n", "                ", "cat_", "=", "torch", ".", "cat", "(", "[", "seq1", "[", "b_idx", "]", "[", "pad_len_1", ":", "]", ",", "\n", "seq2", "[", "b_idx", "]", "[", "pad_len_2", ":", "]", "]", ",", "0", ")", "\n", "", "cat_padded", "=", "F", ".", "pad", "(", "\n", "input", "=", "cat_", ",", "# Left pad", "\n", "pad", "=", "(", "(", "maxCatLen", "-", "cat_len_", ")", ",", "0", ")", ",", "\n", "mode", "=", "\"constant\"", ",", "\n", "value", "=", "0", ")", "\n", "", "elif", "padding", "==", "'right'", ":", "\n", "            ", "if", "len_1", "==", "0", ":", "\n", "                ", "print", "(", "\"[Warning] Empty input sequence 1 given to \"", "\n", "\"concatPaddedSequences\"", ")", "\n", "cat_", "=", "seq2", "[", "b_idx", "]", "[", ":", "len_1", "]", "\n", "\n", "", "elif", "len_2", "==", "0", ":", "\n", "                ", "print", "(", "\"[Warning] Empty input sequence 2 given to \"", "\n", "\"concatPaddedSequences\"", ")", "\n", "cat_", "=", "seq1", "[", "b_idx", "]", "[", ":", "len_1", "]", "\n", "\n", "", "else", ":", "\n", "                ", "cat_", "=", "torch", ".", "cat", "(", "[", "seq1", "[", "b_idx", "]", "[", ":", "len_1", "]", ",", "\n", "seq2", "[", "b_idx", "]", "[", ":", "len_2", "]", "]", ",", "0", ")", "\n", "# cat_ = cat_seq[b_idx].masked_select(cat_seq[b_idx].ne(0))", "\n", "", "cat_padded", "=", "F", ".", "pad", "(", "\n", "input", "=", "cat_", ",", "# Right pad", "\n", "pad", "=", "(", "0", ",", "(", "maxCatLen", "-", "cat_len_", ")", ")", ",", "\n", "mode", "=", "\"constant\"", ",", "\n", "value", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "(", "ValueError", ",", "\"Expected padding to be either 'left' or \\\n                                'right', got '%s' instead.\"", "%", "padding", ")", "\n", "", "concat_list", ".", "append", "(", "cat_padded", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "concat_output", "=", "torch", ".", "cat", "(", "concat_list", ",", "0", ")", "\n", "return", "concat_output", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.cosinePenalty": [[342, 352], ["torch.CosineSimilarity", "nn.CosineSimilarity.", "torch.mean", "torch.mean", "torch.mean"], "function", ["None"], ["", "def", "cosinePenalty", "(", "tensor1", ",", "tensor2", ")", ":", "\n", "    ", "\"\"\"\n    Calculates cosine similarity between two tensors of size batch x dim\n    \n    Returns:\n        tensor1,tensor2 -- torch.Tensor(shape: batch x dim)\n    \"\"\"", "\n", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "1", ",", "eps", "=", "1e-6", ")", "\n", "similarity_scores", "=", "cos", "(", "tensor1", ",", "tensor2", ")", "\n", "return", "torch", ".", "mean", "(", "similarity_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.huberPenalty": [[353, 370], ["torch.abs", "torch.abs", "torch.abs", "torch.sum", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "huberPenalty", "(", "tensor1", ",", "tensor2", ",", "threshold", "=", "0.1", ")", ":", "\n", "    ", "\"\"\"\n    Calculates huber (Smooth-L1 penalty) loss between two tensors of size batch x dim\n    https://en.wikipedia.org/wiki/Huber_loss\n    Returns:\n        tensor1,tensor2 -- torch.Tensor(shape: batch x dim)\n        threshold -- l2 penalty if absolute difference is less than threshold, l1 penalty otherwise\n    \"\"\"", "\n", "assert", "tensor1", ".", "shape", "==", "tensor2", ".", "shape", "\n", "batch", ",", "_", "=", "tensor1", ".", "shape", "\n", "norm_differences", "=", "torch", ".", "abs", "(", "tensor1", "-", "tensor2", ")", "\n", "l2_mask", "=", "norm_differences", "<=", "threshold", "\n", "norm_differences_new", "=", "0.5", "*", "norm_differences", "*", "norm_differences", "*", "(", "l2_mask", "==", "1", ")", ".", "float", "(", ")", "\n", "l1_mask", "=", "norm_differences", ">", "threshold", "\n", "norm_differences_new", "=", "norm_differences_new", "+", "(", "(", "(", "l1_mask", "==", "1", ")", ".", "float", "(", ")", ")", "*", "(", "threshold", "*", "\n", "(", "norm_differences", "-", "(", "0.5", "*", "threshold", ")", ")", ")", ")", "\n", "return", "torch", ".", "sum", "(", "norm_differences_new", ")", "/", "batch", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.__init__": [[7, 27], ["print", "visdom.Visdom"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "env_name", "=", "'main'", ",", "\n", "server", "=", "\"http://127.0.0.1\"", ",", "\n", "port", "=", "8893", ",", "\n", "enable", "=", "True", ")", ":", "\n", "        ", "'''\n            Initialize a visdom server on server:port\n        '''", "\n", "print", "(", "\"Initializing visdom env [%s]\"", "%", "env_name", ")", "\n", "self", ".", "is_enabled", "=", "enable", "\n", "self", ".", "env_name", "=", "env_name", "\n", "if", "self", ".", "is_enabled", ":", "\n", "            ", "self", ".", "viz", "=", "visdom", ".", "Visdom", "(", "\n", "port", "=", "port", ",", "\n", "env", "=", "env_name", ",", "\n", "server", "=", "server", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "viz", "=", "None", "\n", "", "self", ".", "wins", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.linePlot": [[28, 63], ["str", "visualize.VisdomVisualize.wins.keys", "visualize.VisdomVisualize.viz.line", "visualize.VisdomVisualize.viz.line", "numpy.array", "numpy.array", "dict", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "linePlot", "(", "self", ",", "x", ",", "y", ",", "key", ",", "line_name", ",", "xlabel", "=", "\"Iterations\"", ")", ":", "\n", "        ", "'''\n            Add or update a line plot on the visdom server self.viz\n            Argumens:\n                x : Scalar -> X-coordinate on plot\n                y : Scalar -> Value at x\n                key : Name of plot/graph\n                line_name : Name of line within plot/graph\n                xlabel : Label for x-axis (default: # Iterations)\n\n            Plots and lines are created if they don't exist, otherwise\n            they are updated.\n        '''", "\n", "key", "=", "str", "(", "key", ")", "\n", "if", "self", ".", "is_enabled", ":", "\n", "            ", "if", "key", "in", "self", ".", "wins", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "viz", ".", "line", "(", "\n", "X", "=", "np", ".", "array", "(", "[", "x", "]", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "[", "y", "]", ")", ",", "\n", "win", "=", "self", ".", "wins", "[", "key", "]", ",", "\n", "update", "=", "'append'", ",", "\n", "name", "=", "line_name", ",", "\n", "opts", "=", "dict", "(", "showlegend", "=", "True", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "wins", "[", "key", "]", "=", "self", ".", "viz", ".", "line", "(", "\n", "X", "=", "np", ".", "array", "(", "[", "x", "]", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "[", "y", "]", ")", ",", "\n", "win", "=", "key", ",", "\n", "name", "=", "line_name", ",", "\n", "opts", "=", "{", "\n", "'xlabel'", ":", "xlabel", ",", "\n", "'ylabel'", ":", "key", ",", "\n", "'title'", ":", "key", ",", "\n", "'showlegend'", ":", "True", ",", "\n", "# 'legend': [line_name],", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.showText": [[67, 76], ["str", "visualize.VisdomVisualize.viz.text"], "methods", ["None"], ["", "", "", "def", "showText", "(", "self", ",", "text", ",", "key", ")", ":", "\n", "        ", "'''\n        Created a named text window or updates an existing one with\n        the name == key\n        '''", "\n", "key", "=", "str", "(", "key", ")", "\n", "if", "self", ".", "is_enabled", ":", "\n", "            ", "win", "=", "self", ".", "wins", "[", "key", "]", "if", "key", "in", "self", ".", "wins", "else", "None", "\n", "self", ".", "wins", "[", "key", "]", "=", "self", ".", "viz", ".", "text", "(", "text", ",", "win", "=", "win", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.addText": [[77, 83], ["visualize.VisdomVisualize.viz.text"], "methods", ["None"], ["", "", "def", "addText", "(", "self", ",", "text", ")", ":", "\n", "        ", "'''\n        Adds an unnamed text window without keeping track of win id\n        '''", "\n", "if", "self", ".", "is_enabled", ":", "\n", "            ", "self", ".", "viz", ".", "text", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.save": [[84, 87], ["visualize.VisdomVisualize.viz.save"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.visualize.VisdomVisualize.save"], ["", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "is_enabled", ":", "\n", "            ", "self", ".", "viz", ".", "save", "(", "[", "self", ".", "env_name", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG.__init__": [[57, 61], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ndcg_numerator", "=", "0.0", "\n", "self", ".", "_ndcg_denominator", "=", "0.0", "\n", "self", ".", "ndcg_vals", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG.observe": [[62, 109], ["predicted_scores.unsqueeze.unsqueeze.detach", "predicted_scores.unsqueeze.unsqueeze.unsqueeze", "metrics.scores_to_ranks", "predicted_ranks.squeeze.squeeze.squeeze", "predicted_ranks.squeeze.squeeze.size", "torch.sum", "torch.sort", "torch.sort", "range", "sum", "int", "metrics.NDCG._dcg", "metrics.NDCG._dcg", "batch_ndcg.append", "metrics.NDCG.ndcg_vals.append"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.scores_to_ranks", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG._dcg", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG._dcg"], ["", "def", "observe", "(", "self", ",", "\n", "predicted_scores", ":", "torch", ".", "Tensor", ",", "\n", "target_relevance", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Observe model output scores and target ground truth relevance and accumulate NDCG metric.\n\n        Parameters\n        ----------\n        predicted_scores: torch.Tensor\n            A tensor of shape (batch_size, num_options), because dense annotations are\n            available for only one randomly picked round out of ten.\n        target_relevance: torch.Tensor\n            A tensor of shape same as predicted scores, indicating ground truth relevance of\n            each answer option for a particular round.\n        \"\"\"", "\n", "predicted_scores", "=", "predicted_scores", ".", "detach", "(", ")", "\n", "\n", "# shape: (batch_size, 1, num_options)", "\n", "predicted_scores", "=", "predicted_scores", ".", "unsqueeze", "(", "1", ")", "\n", "predicted_ranks", "=", "scores_to_ranks", "(", "predicted_scores", ")", "\n", "\n", "# shape: (batch_size, num_options)", "\n", "predicted_ranks", "=", "predicted_ranks", ".", "squeeze", "(", ")", "\n", "batch_size", ",", "num_options", "=", "predicted_ranks", ".", "size", "(", ")", "\n", "\n", "k", "=", "torch", ".", "sum", "(", "target_relevance", "!=", "0", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# shape: (batch_size, num_options)", "\n", "_", ",", "rankings", "=", "torch", ".", "sort", "(", "predicted_ranks", ",", "dim", "=", "-", "1", ")", "\n", "# Sort relevance in descending order so highest relevance gets top rank.", "\n", "_", ",", "best_rankings", "=", "torch", ".", "sort", "(", "target_relevance", ",", "dim", "=", "-", "1", ",", "descending", "=", "True", ")", "\n", "\n", "# shape: (batch_size, )", "\n", "batch_ndcg", "=", "[", "]", "\n", "for", "batch_index", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "num_relevant", "=", "int", "(", "k", ".", "data", "[", "batch_index", "]", ")", "\n", "dcg", "=", "self", ".", "_dcg", "(", "\n", "rankings", "[", "batch_index", "]", "[", ":", "num_relevant", "]", ",", "target_relevance", "[", "batch_index", "]", "\n", ")", "\n", "best_dcg", "=", "self", ".", "_dcg", "(", "\n", "best_rankings", "[", "batch_index", "]", "[", ":", "num_relevant", "]", ",", "target_relevance", "[", "batch_index", "]", "\n", ")", "\n", "batch_ndcg", ".", "append", "(", "dcg", "/", "best_dcg", ")", "\n", "self", ".", "ndcg_vals", ".", "append", "(", "dcg", ".", "data", "[", "0", "]", "/", "best_dcg", ".", "data", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "_ndcg_denominator", "+=", "batch_size", "\n", "self", ".", "_ndcg_numerator", "+=", "sum", "(", "batch_ndcg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG._dcg": [[110, 116], ["rankings.cuda.cuda.cuda", "relevance[].cpu().float", "numpy.log2", "torch.autograd.Variable", "torch.sum", "torch.from_numpy", "relevance[].cpu", "torch.arange().float().numpy", "torch.arange().float", "torch.arange", "len"], "methods", ["None"], ["", "def", "_dcg", "(", "self", ",", "rankings", ":", "torch", ".", "Tensor", ",", "relevance", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "rankings", "=", "rankings", ".", "cuda", "(", ")", "\n", "sorted_relevance", "=", "relevance", "[", "rankings", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "discounts", "=", "np", ".", "log2", "(", "torch", ".", "arange", "(", "len", "(", "rankings", ")", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "+", "2", ")", "\n", "discounts", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "discounts", ")", ")", "\n", "return", "torch", ".", "sum", "(", "sorted_relevance", "/", "discounts", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG.retrieve": [[117, 129], ["metrics.NDCG.reset", "float", "numpy.std", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset"], ["", "def", "retrieve", "(", "self", ",", "reset", ":", "bool", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "_ndcg_denominator", ">", "0", ":", "\n", "            ", "metrics", "=", "{", "\n", "\"ndcg\"", ":", "float", "(", "self", ".", "_ndcg_numerator", "/", "self", ".", "_ndcg_denominator", ")", ",", "\n", "\"ndcg_std\"", ":", "np", ".", "std", "(", "np", ".", "array", "(", "self", ".", "ndcg_vals", ")", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG.reset": [[130, 134], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ndcg_numerator", "=", "0.0", "\n", "self", ".", "_ndcg_denominator", "=", "0.0", "\n", "self", ".", "ndcg_vals", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.evaluateMetric": [[9, 31], ["ranks.reshape().astype.data.numpy", "ranks.reshape().astype.reshape", "ranks.reshape().astype.reshape", "ranks.reshape().astype.reshape", "ranks.reshape().astype.reshape().astype", "ranks.reshape().astype.mean", "ranks.reshape().astype.reshape().astype", "float", "float", "float", "ranks.reshape().astype.reshape", "ranks.reshape().astype.reshape"], "function", ["None"], ["def", "evaluateMetric", "(", "ranks", ",", "metric", ")", ":", "\n", "    ", "ranks", "=", "ranks", ".", "data", ".", "numpy", "(", ")", "\n", "if", "metric", "==", "'r1'", ":", "\n", "        ", "ranks", "=", "ranks", ".", "reshape", "(", "-", "1", ")", "\n", "return", "100", "*", "(", "ranks", "==", "1", ")", ".", "sum", "(", ")", "/", "float", "(", "ranks", ".", "shape", "[", "0", "]", ")", "\n", "", "if", "metric", "==", "'r5'", ":", "\n", "        ", "ranks", "=", "ranks", ".", "reshape", "(", "-", "1", ")", "\n", "return", "100", "*", "(", "ranks", "<=", "5", ")", ".", "sum", "(", ")", "/", "float", "(", "ranks", ".", "shape", "[", "0", "]", ")", "\n", "", "if", "metric", "==", "'r10'", ":", "\n", "# ranks = ranks.view(-1)", "\n", "        ", "ranks", "=", "ranks", ".", "reshape", "(", "-", "1", ")", "\n", "# return 100*torch.sum(ranks <= 10).data[0]/float(ranks.size(0))", "\n", "return", "100", "*", "(", "ranks", "<=", "10", ")", ".", "sum", "(", ")", "/", "float", "(", "ranks", ".", "shape", "[", "0", "]", ")", "\n", "", "if", "metric", "==", "'mean'", ":", "\n", "# ranks = ranks.view(-1).float()", "\n", "        ", "ranks", "=", "ranks", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "float", ")", "\n", "return", "ranks", ".", "mean", "(", ")", "\n", "", "if", "metric", "==", "'mrr'", ":", "\n", "# ranks = ranks.view(-1).float()", "\n", "        ", "ranks", "=", "ranks", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "float", ")", "\n", "# return torch.reciprocal(ranks).mean().data[0]", "\n", "return", "(", "1", "/", "ranks", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.computeMetrics": [[32, 35], ["metrics.evaluateMetric"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.evaluateMetric"], ["", "", "def", "computeMetrics", "(", "ranks", ")", ":", "\n", "    ", "results", "=", "{", "metric", ":", "evaluateMetric", "(", "ranks", ",", "metric", ")", "for", "metric", "in", "metricList", "}", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.scores_to_ranks": [[36, 55], ["scores.view.size", "scores.view.view", "scores.view.sort", "ranked_idx.clone().fill_", "range", "ranks.view.view", "ranked_idx.size", "range", "ranked_idx.clone"], "function", ["None"], ["", "def", "scores_to_ranks", "(", "scores", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Convert model output scores into ranks.\"\"\"", "\n", "batch_size", ",", "num_rounds", ",", "num_options", "=", "scores", ".", "size", "(", ")", "\n", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "num_options", ")", "\n", "\n", "# sort in descending order - largest score gets highest rank", "\n", "sorted_ranks", ",", "ranked_idx", "=", "scores", ".", "sort", "(", "1", ",", "descending", "=", "True", ")", "\n", "\n", "# i-th position in ranked_idx specifies which score shall take this position", "\n", "# but we want i-th position to have rank of score at that position, do this conversion", "\n", "ranks", "=", "ranked_idx", ".", "clone", "(", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "for", "i", "in", "range", "(", "ranked_idx", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "num_options", ")", ":", "\n", "            ", "ranks", "[", "i", ",", "ranked_idx", "[", "i", "]", "[", "j", "]", ".", "data", "[", "0", "]", "]", "=", "j", "\n", "# convert from 0-99 ranks to 1-100 ranks", "\n", "", "", "ranks", "+=", "1", "\n", "ranks", "=", "ranks", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "num_options", ")", "\n", "return", "ranks", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.answerer.Answerer.__init__": [[11, 51], ["visdial.models.agent.Agent.__init__", "utils.utilities.utilities.initializeWeights", "utils.utilities.utilities.initializeWeights", "answerer.Answerer.reset", "print", "print", "visdial.Encoder", "visdial.Encoder", "Exception", "visdial.Decoder", "visdial.Decoder", "Exception", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.__init__", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.initializeWeights", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.initializeWeights", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset"], ["    ", "def", "__init__", "(", "self", ",", "encoderParam", ",", "decoderParam", ",", "verbose", "=", "1", ",", "multiGPU", "=", "False", ")", ":", "\n", "        ", "'''\n            A-Bot Model\n\n            Uses an encoder network for input sequences (questions, answers and\n            history) and a decoder network for generating a response (answer).\n        '''", "\n", "super", "(", "Answerer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encType", "=", "encoderParam", "[", "'type'", "]", "\n", "self", ".", "decType", "=", "decoderParam", "[", "'type'", "]", "\n", "\n", "# Encoder", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'Encoder: '", "+", "self", ".", "encType", ")", "\n", "print", "(", "'Decoder: '", "+", "self", ".", "decType", ")", "\n", "", "if", "'hre'", "in", "self", ".", "encType", ":", "\n", "            ", "self", ".", "encoder", "=", "hre_enc", ".", "Encoder", "(", "**", "encoderParam", ")", "\n", "if", "multiGPU", ":", "\n", "                ", "self", ".", "encoder", "=", "nn", ".", "DataParallel", "(", "self", ".", "encoder", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown encoder {}'", ".", "format", "(", "self", ".", "encType", ")", ")", "\n", "\n", "# Decoder", "\n", "", "if", "'gen'", "==", "self", ".", "decType", ":", "\n", "            ", "self", ".", "decoder", "=", "gen_dec", ".", "Decoder", "(", "**", "decoderParam", ")", "\n", "if", "multiGPU", ":", "\n", "                ", "self", ".", "decoder", "=", "nn", ".", "DataParallel", "(", "self", ".", "decoder", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unkown decoder {}'", ".", "format", "(", "self", ".", "decType", ")", ")", "\n", "\n", "# Share word embedding parameters between encoder and decoder", "\n", "", "if", "multiGPU", ":", "\n", "            ", "self", ".", "decoder", ".", "module", ".", "wordEmbed", "=", "self", ".", "encoder", ".", "module", ".", "wordEmbed", "\n", "", "else", ":", "\n", "            ", "self", ".", "decoder", ".", "wordEmbed", "=", "self", ".", "encoder", ".", "wordEmbed", "\n", "\n", "# Initialize weights", "\n", "", "utils", ".", "initializeWeights", "(", "self", ".", "encoder", ")", "\n", "utils", ".", "initializeWeights", "(", "self", ".", "decoder", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.answerer.Answerer.reset": [[52, 57], ["answerer.Answerer.encoder.reset"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "'''Delete dialog history.'''", "\n", "self", ".", "caption", "=", "None", "\n", "self", ".", "answers", "=", "[", "]", "\n", "self", ".", "encoder", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.answerer.Answerer.observe": [[58, 72], ["answerer.Answerer.encoder.observe", "answerer.Answerer.answers.append", "len"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe"], ["", "def", "observe", "(", "self", ",", "round", ",", "ans", "=", "None", ",", "caption", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        Update Q-Bot percepts. See self.encoder.observe() in the corresponding\n        encoder class definition (hre).\n        '''", "\n", "if", "caption", "is", "not", "None", ":", "\n", "            ", "assert", "round", "==", "-", "1", ",", "\"Round number should be -1 when observing\"", "\" caption, got %d instead\"", "\n", "self", ".", "caption", "=", "caption", "\n", "", "if", "ans", "is", "not", "None", ":", "\n", "            ", "assert", "round", "==", "len", "(", "self", ".", "answers", ")", ",", "\"Round number does not match number of answers observed\"", "\n", "self", ".", "answers", ".", "append", "(", "ans", ")", "\n", "", "self", ".", "encoder", ".", "observe", "(", "round", ",", "ans", "=", "ans", ",", "caption", "=", "caption", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.answerer.Answerer.forward": [[73, 88], ["answerer.Answerer.encoder", "answerer.Answerer.decoder", "len", "Exception"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "'''\n        Forward pass the last observed answer to compute its log\n        likelihood under the current decoder RNN state.\n        '''", "\n", "encStates", "=", "self", ".", "encoder", "(", ")", "\n", "if", "len", "(", "self", ".", "answers", ")", ">", "0", ":", "\n", "            ", "decIn", "=", "self", ".", "answers", "[", "-", "1", "]", "\n", "", "elif", "self", ".", "caption", "is", "not", "None", ":", "\n", "            ", "decIn", "=", "self", ".", "caption", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Must provide an input sequence'", ")", "\n", "\n", "", "logProbs", "=", "self", ".", "decoder", "(", "encStates", ",", "inputSeq", "=", "decIn", ")", "\n", "return", "logProbs", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.answerer.Answerer.forwardDecode": [[89, 110], ["answerer.Answerer.encoder", "answerer.Answerer.decoder.forwardDecode"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode"], ["", "def", "forwardDecode", "(", "self", ",", "inference", "=", "'sample'", ",", "futureReward", "=", "False", ",", "beamSize", "=", "1", ",", "maxSeqLen", "=", "20", ",", "run_mcts", "=", "False", ")", ":", "\n", "        ", "'''\n        Decode a sequence (answer) using either sampling or greedy inference.\n        An answer is decoded given the current state (dialog history). This\n        can be called at every round after a question is observed.\n\n        Arguments:\n            inference : Inference method for decoding\n                'sample' - Sample each word from its softmax distribution\n                'greedy' - Always choose the word with highest probability\n                           if beam size is 1, otherwise use beam search.\n            beamSize  : Beam search width\n            maxSeqLen : Maximum length of token sequence to generate\n        '''", "\n", "encStates", "=", "self", ".", "encoder", "(", ")", "\n", "answers", ",", "ansLens", "=", "self", ".", "decoder", ".", "forwardDecode", "(", "\n", "encStates", ",", "\n", "maxSeqLen", "=", "maxSeqLen", ",", "\n", "inference", "=", "inference", ",", "futureReward", "=", "futureReward", ",", "\n", "beamSize", "=", "beamSize", ",", "run_mcts", "=", "run_mcts", ")", "\n", "return", "answers", ",", "ansLens", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.answerer.Answerer.evalOptions": [[111, 122], ["answerer.Answerer.encoder", "answerer.Answerer.decoder.evalOptions"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.evalOptions"], ["", "def", "evalOptions", "(", "self", ",", "options", ",", "optionLens", ",", "scoringFunction", ")", ":", "\n", "        ", "'''\n        Given the current state (question and conversation history), evaluate\n        a set of candidate answers to the question.\n\n        Output:\n            Log probabilities of candidate options.\n        '''", "\n", "states", "=", "self", ".", "encoder", "(", ")", "\n", "return", "self", ".", "decoder", ".", "evalOptions", "(", "states", ",", "options", ",", "optionLens", ",", "\n", "scoringFunction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.answerer.Answerer.reinforce": [[123, 126], ["answerer.Answerer.decoder.reinforce"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.reinforce"], ["", "def", "reinforce", "(", "self", ",", "reward", ",", "futureReward", "=", "False", ",", "mcts", "=", "False", ")", ":", "\n", "# Propogate reinforce function call to decoder", "\n", "        ", "return", "self", ".", "decoder", ".", "reinforce", "(", "reward", ",", "futureReward", "=", "futureReward", ",", "mcts", "=", "mcts", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.__init__": [[9, 63], ["visdial.models.agent.Agent.__init__", "encoderParam.copy.copy.copy", "utils.utilities.utilities.initializeWeights", "utils.utilities.utilities.initializeWeights", "questioner.Questioner.reset", "print", "print", "visdial.Encoder", "visdial.Encoder", "Exception", "visdial.Decoder", "visdial.Decoder", "Exception", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.__init__", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.initializeWeights", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.initializeWeights", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset"], ["    ", "def", "__init__", "(", "self", ",", "encoderParam", ",", "decoderParam", ",", "imgFeatureSize", "=", "0", ",", "\n", "verbose", "=", "1", ",", "multiGPU", "=", "False", ")", ":", "\n", "        ", "'''\n            Q-Bot Model\n\n            Uses an encoder network for input sequences (questions, answers and\n            history) and a decoder network for generating a response (question).\n        '''", "\n", "super", "(", "Questioner", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encType", "=", "encoderParam", "[", "'type'", "]", "\n", "self", ".", "decType", "=", "decoderParam", "[", "'type'", "]", "\n", "self", ".", "dropout", "=", "encoderParam", "[", "'dropout'", "]", "\n", "self", ".", "rnnHiddenSize", "=", "encoderParam", "[", "'rnnHiddenSize'", "]", "\n", "self", ".", "imgFeatureSize", "=", "imgFeatureSize", "\n", "encoderParam", "=", "encoderParam", ".", "copy", "(", ")", "\n", "encoderParam", "[", "'isAnswerer'", "]", "=", "False", "\n", "\n", "# Encoder", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'Encoder: '", "+", "self", ".", "encType", ")", "\n", "print", "(", "'Decoder: '", "+", "self", ".", "decType", ")", "\n", "", "if", "'hre'", "in", "self", ".", "encType", ":", "\n", "            ", "self", ".", "encoder", "=", "hre_enc", ".", "Encoder", "(", "**", "encoderParam", ")", "\n", "if", "multiGPU", ":", "\n", "                ", "self", ".", "encoder", "=", "nn", ".", "DataParallel", "(", "self", ".", "encoder", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown encoder {}'", ".", "format", "(", "self", ".", "encType", ")", ")", "\n", "\n", "# Decoder", "\n", "", "if", "'gen'", "==", "self", ".", "decType", ":", "\n", "            ", "self", ".", "decoder", "=", "gen_dec", ".", "Decoder", "(", "**", "decoderParam", ")", "\n", "if", "multiGPU", ":", "\n", "                ", "self", ".", "decoder", "=", "nn", ".", "DataParallel", "(", "self", ".", "decoder", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unkown decoder {}'", ".", "format", "(", "self", ".", "decType", ")", ")", "\n", "\n", "# Share word embedding parameters between encoder and decoder", "\n", "", "if", "multiGPU", ":", "\n", "            ", "self", ".", "decoder", ".", "module", ".", "wordEmbed", "=", "self", ".", "encoder", ".", "module", ".", "wordEmbed", "\n", "", "else", ":", "\n", "            ", "self", ".", "decoder", ".", "wordEmbed", "=", "self", ".", "encoder", ".", "wordEmbed", "\n", "\n", "# Setup feature regressor", "\n", "", "if", "self", ".", "imgFeatureSize", ":", "\n", "            ", "self", ".", "featureNet", "=", "nn", ".", "Linear", "(", "self", ".", "rnnHiddenSize", ",", "\n", "self", ".", "imgFeatureSize", ")", "\n", "if", "multiGPU", ":", "\n", "                ", "self", ".", "featureNet", "=", "nn", ".", "DataParallel", "(", "self", ".", "featureNet", ")", "\n", "", "self", ".", "featureNetInputDropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n", "# Initialize weights", "\n", "", "utils", ".", "initializeWeights", "(", "self", ".", "encoder", ")", "\n", "utils", ".", "initializeWeights", "(", "self", ".", "decoder", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.reset": [[64, 68], ["questioner.Questioner.encoder.reset"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "'''Delete dialog history.'''", "\n", "self", ".", "questions", "=", "[", "]", "\n", "self", ".", "encoder", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.freezeFeatNet": [[69, 74], ["net.parameters"], "methods", ["None"], ["", "def", "freezeFeatNet", "(", "self", ")", ":", "\n", "        ", "nets", "=", "[", "self", ".", "featureNet", "]", "\n", "for", "net", "in", "nets", ":", "\n", "            ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.observe": [[75, 87], ["questioner.Questioner.encoder.observe", "questioner.Questioner.questions.append", "len"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe"], ["", "", "", "def", "observe", "(", "self", ",", "round", ",", "ques", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        Update Q-Bot percepts. See self.encoder.observe() in the corresponding\n        encoder class definition (hre).\n        '''", "\n", "assert", "'image'", "not", "in", "kwargs", ",", "\"Q-Bot does not see image\"", "\n", "if", "ques", "is", "not", "None", ":", "\n", "            ", "assert", "round", "==", "len", "(", "self", ".", "questions", ")", ",", "\"Round number does not match number of questions observed\"", "\n", "self", ".", "questions", ".", "append", "(", "ques", ")", "\n", "\n", "", "self", ".", "encoder", ".", "observe", "(", "round", ",", "ques", "=", "ques", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.forward": [[88, 100], ["questioner.Questioner.encoder", "questioner.Questioner.decoder", "len", "Exception"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "'''\n        Forward pass the last observed question to compute its log\n        likelihood under the current decoder RNN state.\n        '''", "\n", "encStates", "=", "self", ".", "encoder", "(", ")", "\n", "if", "len", "(", "self", ".", "questions", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "'Must provide question if not sampling one.'", ")", "\n", "", "decIn", "=", "self", ".", "questions", "[", "-", "1", "]", "\n", "\n", "logProbs", "=", "self", ".", "decoder", "(", "encStates", ",", "inputSeq", "=", "decIn", ")", "\n", "return", "logProbs", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.forwardDecode": [[101, 124], ["questioner.Questioner.encoder", "questioner.Questioner.decoder.forwardDecode"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode"], ["", "def", "forwardDecode", "(", "self", ",", "inference", "=", "'sample'", ",", "futureReward", "=", "False", ",", "beamSize", "=", "1", ",", "maxSeqLen", "=", "20", ",", "run_mcts", "=", "False", ")", ":", "\n", "        ", "'''\n        Decode a sequence (question) using either sampling or greedy inference.\n        A question is decoded given current state (dialog history). This can\n        be called at round 0 after the caption is observed, and at end of every\n        round (after a response from A-Bot is observed).\n\n        Arguments:\n            inference : Inference method for decoding\n                'sample' - Sample each word from its softmax distribution\n                'greedy' - Always choose the word with highest probability\n                           if beam size is 1, otherwise use beam search.\n            beamSize  : Beam search width\n            maxSeqLen : Maximum length of token sequence to generate\n        '''", "\n", "encStates", "=", "self", ".", "encoder", "(", ")", "\n", "questions", ",", "quesLens", "=", "self", ".", "decoder", ".", "forwardDecode", "(", "\n", "encStates", ",", "\n", "maxSeqLen", "=", "maxSeqLen", ",", "\n", "inference", "=", "inference", ",", "\n", "futureReward", "=", "futureReward", ",", "\n", "beamSize", "=", "beamSize", ",", "run_mcts", "=", "run_mcts", ")", "\n", "return", "questions", ",", "quesLens", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.predictImage": [[125, 135], ["questioner.Questioner.encoder", "questioner.Questioner.featureNet", "questioner.Questioner.featureNetInputDropout"], "methods", ["None"], ["", "def", "predictImage", "(", "self", ")", ":", "\n", "        ", "'''\n        Predict/guess an fc7 vector given the current conversation history. This can\n        be called at round 0 after the caption is observed, and at end of every round\n        (after a response from A-Bot is observed).\n        '''", "\n", "encState", "=", "self", ".", "encoder", "(", ")", "\n", "# h, c from lstm", "\n", "h", ",", "c", "=", "encState", "\n", "return", "self", ".", "featureNet", "(", "self", ".", "featureNetInputDropout", "(", "h", "[", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.reinforce": [[136, 139], ["questioner.Questioner.decoder.reinforce"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.reinforce"], ["", "def", "reinforce", "(", "self", ",", "reward", ",", "futureReward", "=", "False", ",", "mcts", "=", "False", ")", ":", "\n", "# Propogate reinforce function call to decoder", "\n", "        ", "return", "self", ".", "decoder", ".", "reinforce", "(", "reward", ",", "futureReward", "=", "futureReward", ",", "mcts", "=", "mcts", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.agent.Agent.__init__": [[11, 13], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.__init__": [[10, 39], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocabSize", ",", "\n", "embedSize", ",", "\n", "rnnHiddenSize", ",", "\n", "numLayers", ",", "\n", "startToken", ",", "\n", "endToken", ",", "\n", "dropout", "=", "0", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabSize", "=", "vocabSize", "\n", "self", ".", "embedSize", "=", "embedSize", "\n", "self", ".", "rnnHiddenSize", "=", "rnnHiddenSize", "\n", "self", ".", "numLayers", "=", "numLayers", "\n", "self", ".", "startToken", "=", "startToken", "\n", "self", ".", "endToken", "=", "endToken", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "# Modules", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "\n", "self", ".", "embedSize", ",", "\n", "self", ".", "rnnHiddenSize", ",", "\n", "self", ".", "numLayers", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "outNet", "=", "nn", ".", "Linear", "(", "self", ".", "rnnHiddenSize", ",", "self", ".", "vocabSize", ")", "\n", "self", ".", "logSoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "all_log_probs", "=", "[", "]", "\n", "self", ".", "all_mask", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forward": [[40, 73], ["gen.Decoder.wordEmbed", "gen.Decoder.rnn", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout.size", "torch.dropout.view", "gen.Decoder.outNet", "gen.Decoder.logSoftmax", "gen.Decoder.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encStates", ",", "inputSeq", ")", ":", "\n", "        ", "'''\n        Given encoder states, forward pass an input sequence 'inputSeq' to\n        compute its log likelihood under the current decoder RNN state.\n\n        Arguments:\n            encStates: (H, C) Tuple of hidden and cell encoder states\n            inputSeq: Input sequence for computing log probabilities\n            reconstruct_past_ques: Option whether there is a coherrence term\n                                   for predicting question on past round\n\n        Output:\n            A (batchSize, length, vocabSize) sized tensor of log-probabilities\n            obtained from feeding 'inputSeq' to decoder RNN at evert time step\n\n        Note:\n            Maximizing the NLL of an input sequence involves feeding as input\n            tokens from the GT (ground truth) sequence at every time step and\n            maximizing the probability of the next token (\"teacher forcing\").\n            See 'maskedNll' in utils/utilities.py where the log probability of\n            the next time step token is indexed out for computing NLL loss.\n        '''", "\n", "if", "inputSeq", "is", "not", "None", ":", "\n", "            ", "inputSeq", "=", "self", ".", "wordEmbed", "(", "inputSeq", ")", "\n", "outputs", ",", "_", "=", "self", ".", "rnn", "(", "inputSeq", ",", "encStates", ")", "\n", "outputs", "=", "F", ".", "dropout", "(", "outputs", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "outputSize", "=", "outputs", ".", "size", "(", ")", "\n", "flatOutputs", "=", "outputs", ".", "view", "(", "-", "1", ",", "outputSize", "[", "2", "]", ")", "\n", "flatScores", "=", "self", ".", "outNet", "(", "flatOutputs", ")", "\n", "flatLogProbs", "=", "self", ".", "logSoftmax", "(", "flatScores", ")", "\n", "logProbs", "=", "flatLogProbs", ".", "view", "(", "outputSize", "[", "0", "]", ",", "outputSize", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "", "return", "logProbs", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode": [[74, 236], ["encStates[].size", "th.LongTensor", "torch.autograd.Variable.fill_", "torch.autograd.Variable.fill_", "torch.autograd.Variable.fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "th.LongTensor().fill_", "th.LongTensor().fill_", "th.ByteTensor().fill_", "range", "mask[].fill_", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "sample.unsqueeze.unsqueeze.data.new().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gen.Decoder.beamSearchDecoder", "gen.Decoder.wordEmbed", "gen.Decoder.rnn", "gen.Decoder.outNet", "gen.Decoder.logSoftmax", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "gen.Decoder.samples.append", "sample.unsqueeze.unsqueeze.data.eq", "sample.unsqueeze.unsqueeze.data.masked_fill_", "th.LongTensor().fill_.masked_fill_", "gen.Decoder.mcts_samples.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "gen.Decoder.mcts_samples_lens.append", "gen.Decoder.all_log_probs.append", "gen.Decoder.all_mask.append", "th.LongTensor", "th.LongTensor", "th.ByteTensor", "output.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "seq[].unsqueeze", "mask[].unsqueeze", "seq[].unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat().squeeze", "torch.autograd.Variable.unsqueeze().repeat().squeeze", "torch.autograd.Variable.unsqueeze().repeat().squeeze", "sample.unsqueeze.unsqueeze.data.new", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "gen.Decoder.get_mcts_samples", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gen.Decoder.mcts_samples.append", "gen.Decoder.mcts_samples_lens.append", "random.randint", "sample.unsqueeze.unsqueeze.contiguous", "gen.Decoder.saved_log_probs.append", "sample.unsqueeze.unsqueeze.unsqueeze", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "gen.Decoder.saved_log_probs.append", "sample.unsqueeze.unsqueeze.unsqueeze", "sample.unsqueeze.unsqueeze.size", "torch.cat.gather", "torch.cat.gather", "torch.cat.gather", "torch.distributions.Categorical.log_prob", "torch.distributions.Categorical.log_prob", "torch.distributions.Categorical.log_prob", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "ValueError", "seq[].unsqueeze", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "seq[].unsqueeze.repeat", "sample.unsqueeze.unsqueeze.view", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.beamSearchDecoder", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.get_mcts_samples"], ["", "def", "forwardDecode", "(", "self", ",", "\n", "encStates", ",", "\n", "maxSeqLen", "=", "20", ",", "\n", "inference", "=", "'sample'", ",", "\n", "beamSize", "=", "1", ",", "futureReward", "=", "True", ",", "run_mcts", "=", "False", ",", "num_beams_mcts", "=", "10", ")", ":", "\n", "        ", "'''\n        Decode a sequence of tokens given an encoder state, using either\n        sampling or greedy inference.\n\n        Arguments:\n            encStates : (H, C) Tuple of hidden and cell encoder states\n            maxSeqLen : Maximum length of token sequence to generate\n            inference : Inference method for decoding\n                'sample' - Sample each word from its softmax distribution\n                'greedy' - Always choose the word with highest probability\n                           if beam size is 1, otherwise use beam search.\n            beamSize  : Beam search width\n\n        Notes:\n            * This function is not called during SL pre-training\n            * Greedy inference is used for evaluation\n            * Sampling is used in RL fine-tuning\n        '''", "\n", "if", "inference", "==", "'greedy'", "and", "beamSize", ">", "1", ":", "\n", "# Use beam search inference when beam size is > 1", "\n", "            ", "return", "self", ".", "beamSearchDecoder", "(", "encStates", ",", "beamSize", ",", "maxSeqLen", ")", "\n", "\n", "# Determine if cuda tensors are being used", "\n", "", "if", "self", ".", "wordEmbed", ".", "weight", ".", "is_cuda", ":", "\n", "            ", "th", "=", "torch", ".", "cuda", "\n", "", "else", ":", "\n", "            ", "th", "=", "torch", "\n", "\n", "", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "mcts_samples", "=", "[", "]", "\n", "self", ".", "mcts_samples_lens", "=", "[", "]", "\n", "\n", "maxLen", "=", "maxSeqLen", "+", "1", "# Extra <END> token", "\n", "batchSize", "=", "encStates", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "# Placeholder for filling in tokens at evert time step", "\n", "seq", "=", "th", ".", "LongTensor", "(", "batchSize", ",", "maxLen", "+", "1", ")", "\n", "seq", ".", "fill_", "(", "self", ".", "endToken", ")", "\n", "seq", "[", ":", ",", "0", "]", "=", "self", ".", "startToken", "\n", "seq", "=", "Variable", "(", "seq", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# Initial state linked from encStates", "\n", "hid", "=", "encStates", "\n", "\n", "sampleLens", "=", "th", ".", "LongTensor", "(", "batchSize", ")", ".", "fill_", "(", "0", ")", "\n", "# Tensors needed for tracking sampleLens", "\n", "unitColumn", "=", "th", ".", "LongTensor", "(", "batchSize", ")", ".", "fill_", "(", "1", ")", "\n", "mask", "=", "th", ".", "ByteTensor", "(", "seq", ".", "size", "(", ")", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "self", ".", "saved_log_probs", "=", "[", "]", "\n", "\n", "# Generating tokens sequentially", "\n", "for", "t", "in", "range", "(", "maxLen", "-", "1", ")", ":", "\n", "            ", "emb", "=", "self", ".", "wordEmbed", "(", "seq", "[", ":", ",", "t", ":", "t", "+", "1", "]", ")", "\n", "# emb has shape  (batch, 1, embedSize)", "\n", "output", ",", "hid", "=", "self", ".", "rnn", "(", "emb", ",", "hid", ")", "\n", "# output has shape (batch, 1, rnnHiddenSize)", "\n", "scores", "=", "self", ".", "outNet", "(", "output", ".", "squeeze", "(", "1", ")", ")", "\n", "logProb", "=", "self", ".", "logSoftmax", "(", "scores", ")", "\n", "\n", "# Explicitly removing padding token (index 0) and <START> token", "\n", "# (index -2) from logProbs so that they are never sampled.", "\n", "# This is allows us to keep <START> and padding token in", "\n", "# the decoder vocab without any problems in RL sampling.", "\n", "if", "t", ">", "0", ":", "\n", "                ", "logProb", "=", "torch", ".", "cat", "(", "[", "logProb", "[", ":", ",", "1", ":", "-", "2", "]", ",", "logProb", "[", ":", ",", "-", "1", ":", "]", "]", ",", "1", ")", "\n", "", "elif", "t", "==", "0", ":", "\n", "# Additionally, remove <END> token from the first sample", "\n", "# to prevent the sampling of an empty sequence.", "\n", "                ", "logProb", "=", "logProb", "[", ":", ",", "1", ":", "-", "2", "]", "\n", "# This also shifts end token index back by 1", "\n", "", "END_TOKEN_IDX", "=", "self", ".", "endToken", "-", "1", "\n", "\n", "probs", "=", "torch", ".", "exp", "(", "logProb", ")", "\n", "\n", "#MCTS stuff", "\n", "if", "inference", "==", "'sample'", "and", "run_mcts", ":", "\n", "# create samples for the hidden state", "\n", "                ", "startPrefix", "=", "seq", "[", ":", ",", ":", "t", "+", "1", "]", ".", "unsqueeze", "(", "1", ")", "\n", "if", "t", "!=", "maxLen", "-", "1", ":", "\n", "                    ", "mcts_samples", ",", "mcts_seqLens", "=", "self", ".", "get_mcts_samples", "(", "hid", ",", "num_beams_mcts", ",", "maxLen", "-", "1", "-", "t", ",", "seq", "[", ":", ",", "t", "]", ")", "\n", "mcts_samples", "=", "torch", ".", "cat", "(", "[", "startPrefix", ".", "repeat", "(", "1", ",", "num_beams_mcts", ",", "1", ")", ",", "mcts_samples", "]", ",", "dim", "=", "2", ")", "\n", "# updating lengths as well", "\n", "mcts_seqLens", "=", "mcts_seqLens", "+", "t", "+", "1", "\n", "self", ".", "mcts_samples", ".", "append", "(", "mcts_samples", ")", "\n", "self", ".", "mcts_samples_lens", ".", "append", "(", "mcts_seqLens", ")", "\n", "# randomly select one of the MCTS sample to be the value on the next iteration", "\n", "sample_index", "=", "random", ".", "randint", "(", "0", ",", "num_beams_mcts", "-", "1", ")", "\n", "sample", "=", "mcts_samples", "[", ":", ",", "sample_index", ",", "t", "+", "1", "]", "\n", "# log probs", "\n", "# sample has ids wrt to the vocab. It has the following guarantees:", "\n", "# start token/padding token is never sampled sample lens deal with the end token", "\n", "# since we have remove the padding token in logProb ,we need to offset the sample by -1", "\n", "sample", "=", "sample", "-", "1", "\n", "sample", "=", "sample", ".", "contiguous", "(", ")", "\n", "self", ".", "saved_log_probs", ".", "append", "(", "logProb", ".", "gather", "(", "1", ",", "sample", ".", "view", "(", "-", "1", ",", "1", ")", ")", ")", "\n", "sample", "=", "sample", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "", "elif", "inference", "==", "'sample'", "and", "not", "run_mcts", ":", "\n", "                ", "categorical_dist", "=", "Categorical", "(", "probs", ")", "\n", "sample", "=", "categorical_dist", ".", "sample", "(", ")", "\n", "# Saving log probs for a subsequent reinforce call", "\n", "self", ".", "saved_log_probs", ".", "append", "(", "categorical_dist", ".", "log_prob", "(", "sample", ")", ")", "\n", "sample", "=", "sample", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "elif", "inference", "==", "'greedy'", ":", "\n", "                ", "_", ",", "sample", "=", "torch", ".", "max", "(", "probs", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid inference type: '{}'\"", ".", "format", "(", "inference", ")", ")", "\n", "\n", "# Compensating for removed padding token prediction earlier", "\n", "", "sample", "=", "sample", "+", "1", "# Incrementing all token indices by 1", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sample", ")", "\n", "seq", ".", "data", "[", ":", ",", "t", "+", "1", "]", "=", "sample", ".", "data", "\n", "# Marking spots where <END> token is generated", "\n", "mask", "[", ":", ",", "t", "]", "=", "sample", ".", "data", ".", "eq", "(", "END_TOKEN_IDX", ")", "\n", "\n", "# Compensating for shift in <END> token index", "\n", "sample", ".", "data", ".", "masked_fill_", "(", "mask", "[", ":", ",", "t", "]", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "endToken", ")", "\n", "\n", "", "mask", "[", ":", ",", "maxLen", "-", "1", "]", ".", "fill_", "(", "1", ")", "\n", "\n", "# Computing lengths of generated sequences", "\n", "for", "t", "in", "range", "(", "maxLen", ")", ":", "\n", "# Zero out the spots where end token is reached", "\n", "            ", "unitColumn", ".", "masked_fill_", "(", "mask", "[", ":", ",", "t", "]", ",", "0", ")", "\n", "# Update mask", "\n", "mask", "[", ":", ",", "t", "]", "=", "unitColumn", "\n", "# Add +1 length to all un-ended sequences", "\n", "sampleLens", "=", "sampleLens", "+", "unitColumn", "\n", "\n", "# Keep mask for later use in RL reward masking", "\n", "", "self", ".", "mask", "=", "Variable", "(", "mask", ",", "requires_grad", "=", "False", ")", "\n", "if", "inference", "==", "'sample'", "and", "run_mcts", ":", "\n", "# we now have sequence lengths of all the samples. We cant generate MCTS samples for the", "\n", "# the last token. For that case, we will just duplicate the sample.", "\n", "            ", "self", ".", "mcts_samples", ".", "append", "(", "seq", "[", ":", ",", ":", "maxLen", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_beams_mcts", ",", "1", ")", ")", "\n", "mcts_seqLens", "=", "Variable", "(", "sampleLens", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "num_beams_mcts", ")", ".", "squeeze", "(", "0", ")", ")", "\n", "self", ".", "mcts_samples_lens", ".", "append", "(", "mcts_seqLens", ")", "\n", "\n", "# Adding <START> to generated answer lengths for consistency", "\n", "", "sampleLens", "=", "sampleLens", "+", "1", "\n", "sampleLens", "=", "Variable", "(", "sampleLens", ",", "requires_grad", "=", "False", ")", "\n", "\n", "startColumn", "=", "sample", ".", "data", ".", "new", "(", "sample", ".", "size", "(", ")", ")", ".", "fill_", "(", "self", ".", "startToken", ")", "\n", "startColumn", "=", "Variable", "(", "startColumn", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# Note that we do not add startColumn to self.samples itself", "\n", "# as reinforce is called on self.samples (which needs to be", "\n", "# the output of a stochastic function)", "\n", "gen_samples", "=", "[", "startColumn", "]", "+", "self", ".", "samples", "\n", "if", "futureReward", ":", "\n", "            ", "self", ".", "all_log_probs", ".", "append", "(", "self", ".", "saved_log_probs", ")", "\n", "self", ".", "all_mask", ".", "append", "(", "self", ".", "mask", ")", "\n", "\n", "", "samples", "=", "torch", ".", "cat", "(", "gen_samples", ",", "1", ")", "\n", "return", "samples", ",", "sampleLens", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.evalOptions": [[237, 266], ["options.size", "options.contiguous().view", "gen.Decoder.forward", "scoringFunction", "scoringFunction.view", "x.unsqueeze().repeat().view", "options.contiguous", "x.unsqueeze().repeat", "x.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.forward"], ["", "def", "evalOptions", "(", "self", ",", "encStates", ",", "options", ",", "optionLens", ",", "scoringFunction", ")", ":", "\n", "        ", "'''\n        Forward pass a set of candidate options to get log probabilities\n\n        Arguments:\n            encStates : (H, C) Tuple of hidden and cell encoder states\n            options   : (batchSize, numOptions, maxSequenceLength) sized\n                        tensor with <START> and <END> tokens\n\n            scoringFunction : A function which computes negative log\n                              likelihood of a sequence (answer) given log\n                              probabilities under an RNN model. Currently\n                              utils.maskedNll is the only such function used.\n\n        Output:\n            A (batchSize, numOptions) tensor containing the score\n            of each option sentence given by the generator\n        '''", "\n", "batchSize", ",", "numOptions", ",", "maxLen", "=", "options", ".", "size", "(", ")", "\n", "optionsFlat", "=", "options", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "maxLen", ")", "\n", "\n", "# Reshaping H, C for each option", "\n", "encStates", "=", "[", "x", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "numOptions", ",", "1", ")", ".", "view", "(", "self", ".", "numLayers", ",", "-", "1", ",", "self", ".", "rnnHiddenSize", ")", "\n", "for", "x", "in", "encStates", "]", "\n", "\n", "logProbs", "=", "self", ".", "forward", "(", "encStates", ",", "inputSeq", "=", "optionsFlat", ")", "\n", "scores", "=", "scoringFunction", "(", "logProbs", ",", "optionsFlat", ",", "returnScores", "=", "True", ")", "\n", "return", "scores", ".", "view", "(", "batchSize", ",", "numOptions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.reinforce": [[268, 310], ["len", "RuntimeError", "enumerate", "print", "enumerate", "enumerate", "reward.detach", "gen.Decoder.mask[].float", "reward[].detach", "gen.Decoder.mask[].float", "cur_reward.detach", "mask[].float"], "methods", ["None"], ["", "def", "reinforce", "(", "self", ",", "reward", ",", "futureReward", "=", "False", ",", "mcts", "=", "False", ")", ":", "\n", "        ", "'''\n        Compute loss using REINFORCE on log probabilities of tokens\n        sampled from decoder RNN, scaled by input 'reward'.\n\n        Note that an earlier call to forwardDecode must have been\n        made in order to have samples for which REINFORCE can be\n        applied. These samples are stored in 'self.saved_log_probs'.\n        '''", "\n", "loss", "=", "0", "\n", "# samples = torch.stack(self.samples, 1)", "\n", "# sampleLens = self.sampleLens - 1", "\n", "if", "len", "(", "self", ".", "saved_log_probs", ")", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Reinforce called without sampling in Decoder\"", ")", "\n", "\n", "", "if", "not", "futureReward", ":", "\n", "            ", "for", "t", ",", "log_prob", "in", "enumerate", "(", "self", ".", "saved_log_probs", ")", ":", "\n", "\n", "                ", "if", "not", "mcts", ":", "\n", "# reward is a single vector", "\n", "                    ", "loss", "+=", "-", "1", "*", "log_prob", "*", "(", "reward", ".", "detach", "(", ")", "*", "(", "self", ".", "mask", "[", ":", ",", "t", "]", ".", "float", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "# reward is a matrix, different token have different returns from the environment", "\n", "                    ", "loss", "+=", "-", "1", "*", "log_prob", "*", "(", "reward", "[", ":", ",", "t", "]", ".", "detach", "(", ")", "*", "(", "self", ".", "mask", "[", ":", ",", "t", "]", ".", "float", "(", ")", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "print", "(", "\"Using future reward\"", ")", "\n", "# print(reward)", "\n", "\n", "for", "ind", ",", "log_probs", "in", "enumerate", "(", "self", ".", "all_log_probs", ")", ":", "\n", "\n", "                ", "mask", "=", "self", ".", "all_mask", "[", "ind", "]", "\n", "cur_reward", "=", "reward", "[", ":", ",", "ind", "]", "\n", "# print(cur_reward)", "\n", "\n", "for", "t", ",", "log_prob", "in", "enumerate", "(", "log_probs", ")", ":", "\n", "                    ", "loss", "+=", "-", "1", "*", "log_prob", "*", "(", "cur_reward", ".", "detach", "(", ")", "*", "(", "mask", "[", ":", ",", "t", "]", ".", "float", "(", ")", ")", ")", "\n", "\n", "# resetting the logs", "\n", "", "", "self", ".", "all_mask", "=", "[", "]", "\n", "self", ".", "all_log_probs", "=", "[", "]", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.beamSearchDecoder": [[311, 493], ["initStates[].size", "th.LongTensor().fill_", "th.LongTensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "th.LongTensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "th.LongTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "th.LongTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "beamTokensTable[].eq().unsqueeze", "range", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.reverse", "torch.cat.reverse", "torch.cat.reverse", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.ne().long().sum", "torch.cat.ne().long().sum", "torch.cat.ne().long().sum", "beamTokensTable[].ne", "beamTokensTable[].ne.data.long().sum", "torch.cat.append", "torch.cat.append", "torch.cat.append", "backIndices[].gather", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "th.LongTensor", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "th.LongTensor", "th.LongTensor", "beamTokensTable[].eq", "gen.Decoder.wordEmbed", "gen.Decoder.rnn", "gen.Decoder.outNet", "gen.Decoder.logSoftmax", "logProbs.view.view.topk", "gen.Decoder.wordEmbed", "gen.Decoder.rnn", "gen.Decoder.outNet", "gen.Decoder.logSoftmax", "logProbsCurrent.view.view.view", "beamTokensTable[].ne.eq().repeat", "logProbs.view.view.data.masked_fill_", "logProbs.view.view.view", "torch.autograd.Variable.unsqueeze().unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().unsqueeze().repeat", "tokensArray.view.view.masked_fill_", "tokensArray.view.view.view", "torch.autograd.Variable.unsqueeze().repeat().view", "torch.autograd.Variable.unsqueeze().repeat().view", "torch.autograd.Variable.unsqueeze().repeat().view", "logProbs.view.view.topk", "tokensArray.view.view.gather", "torch.autograd.Variable.unsqueeze().repeat().view.gather", "hiddenCurrent.view.view.size", "hiddenCurrent.view.view.view", "cellCurrent.view.view.view", "backIndices[].unsqueeze().unsqueeze().repeat", "hiddenCurrent.view.view.gather", "cellCurrent.view.view.gather", "hiddenCurrent.view.view.view", "cellCurrent.view.view.view", "beamTokensTable[].gather().unsqueeze", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "torch.cat.ne().long", "torch.cat.ne().long", "torch.cat.ne().long", "output.squeeze", "topIdx.transpose", "x.unsqueeze().repeat", "x.view", "gen.Decoder.view", "output.squeeze", "logProbSums.unsqueeze", "beamTokensTable[].ne.eq", "beamTokensTable[].ne.data.long", "beamTokensTable[].ne.eq().float", "logProbSums.unsqueeze", "beamTokensTable[].ne.float", "beamTokensTable[].ne.eq", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.autograd.Variable.unsqueeze().unsqueeze", "torch.autograd.Variable.unsqueeze().unsqueeze", "torch.autograd.Variable.unsqueeze().unsqueeze", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "torch.autograd.Variable.unsqueeze().repeat", "backIndices[].unsqueeze().unsqueeze", "beamTokensTable[].gather", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.cat.ne", "torch.cat.ne", "torch.cat.ne", "x.unsqueeze", "beamTokensTable[].ne.float", "beamTokensTable[].ne.eq", "beamTokensTable[].ne.float", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "torch.autograd.Variable.unsqueeze", "backIndices[].unsqueeze"], "methods", ["None"], ["", "def", "beamSearchDecoder", "(", "self", ",", "initStates", ",", "beamSize", ",", "maxSeqLen", ")", ":", "\n", "        ", "'''\n        Beam search for sequence generation\n        Arguments:\n            initStates - Initial encoder states tuple\n            beamSize - Beam Size\n            maxSeqLen - Maximum length of sequence to decode\n        '''", "\n", "\n", "# For now, use beam search for evaluation only", "\n", "assert", "self", ".", "training", "==", "False", "\n", "\n", "# Determine if cuda tensors are being used", "\n", "if", "self", ".", "wordEmbed", ".", "weight", ".", "is_cuda", ":", "\n", "            ", "th", "=", "torch", ".", "cuda", "\n", "", "else", ":", "\n", "            ", "th", "=", "torch", "\n", "\n", "", "LENGTH_NORM", "=", "True", "\n", "maxLen", "=", "maxSeqLen", "+", "1", "# Extra <END> token", "\n", "batchSize", "=", "initStates", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "\n", "startTokenArray", "=", "th", ".", "LongTensor", "(", "batchSize", ",", "1", ")", ".", "fill_", "(", "self", ".", "startToken", ")", "\n", "backVector", "=", "th", ".", "LongTensor", "(", "beamSize", ")", "\n", "torch", ".", "arange", "(", "0", ",", "beamSize", ",", "out", "=", "backVector", ")", "\n", "backVector", "=", "backVector", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "batchSize", ",", "1", ")", "\n", "\n", "tokenArange", "=", "th", ".", "LongTensor", "(", "self", ".", "vocabSize", ")", "\n", "torch", ".", "arange", "(", "0", ",", "self", ".", "vocabSize", ",", "out", "=", "tokenArange", ")", "\n", "tokenArange", "=", "Variable", "(", "tokenArange", ")", "\n", "\n", "startTokenArray", "=", "Variable", "(", "startTokenArray", ")", "\n", "backVector", "=", "Variable", "(", "backVector", ")", "\n", "hiddenStates", "=", "initStates", "\n", "\n", "# Inits", "\n", "beamTokensTable", "=", "th", ".", "LongTensor", "(", "batchSize", ",", "beamSize", ",", "maxLen", ")", ".", "fill_", "(", "\n", "self", ".", "endToken", ")", "\n", "beamTokensTable", "=", "Variable", "(", "beamTokensTable", ")", "\n", "backIndices", "=", "th", ".", "LongTensor", "(", "batchSize", ",", "beamSize", ",", "maxLen", ")", ".", "fill_", "(", "-", "1", ")", "\n", "backIndices", "=", "Variable", "(", "backIndices", ")", "\n", "\n", "aliveVector", "=", "beamTokensTable", "[", ":", ",", ":", ",", "0", "]", ".", "eq", "(", "self", ".", "endToken", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "for", "t", "in", "range", "(", "maxLen", "-", "1", ")", ":", "# Beam expansion till maxLen]", "\n", "            ", "if", "t", "==", "0", ":", "\n", "# First column of beamTokensTable is generated from <START> token", "\n", "                ", "emb", "=", "self", ".", "wordEmbed", "(", "startTokenArray", ")", "\n", "# emb has shape (batchSize, 1, embedSize)", "\n", "output", ",", "hiddenStates", "=", "self", ".", "rnn", "(", "emb", ",", "hiddenStates", ")", "\n", "# output has shape (batchSize, 1, rnnHiddenSize)", "\n", "scores", "=", "self", ".", "outNet", "(", "output", ".", "squeeze", "(", "1", ")", ")", "\n", "logProbs", "=", "self", ".", "logSoftmax", "(", "scores", ")", "\n", "# scores & logProbs has shape (batchSize, vocabSize)", "\n", "\n", "# Find top beamSize logProbs", "\n", "topLogProbs", ",", "topIdx", "=", "logProbs", ".", "topk", "(", "beamSize", ",", "dim", "=", "1", ")", "\n", "beamTokensTable", "[", ":", ",", ":", ",", "0", "]", "=", "topIdx", ".", "transpose", "(", "0", ",", "1", ")", ".", "data", "\n", "logProbSums", "=", "topLogProbs", "\n", "\n", "# Repeating hiddenStates 'beamSize' times for subsequent self.rnn calls", "\n", "hiddenStates", "=", "[", "\n", "x", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "beamSize", ",", "1", ")", "\n", "for", "x", "in", "hiddenStates", "\n", "]", "\n", "hiddenStates", "=", "[", "\n", "x", ".", "view", "(", "self", ".", "numLayers", ",", "-", "1", ",", "self", ".", "rnnHiddenSize", ")", "\n", "for", "x", "in", "hiddenStates", "\n", "]", "\n", "# H_0 and C_0 have shape (numLayers, batchSize*beamSize, rnnHiddenSize)", "\n", "", "else", ":", "\n", "# Subsequent columns are generated from previous tokens", "\n", "                ", "emb", "=", "self", ".", "wordEmbed", "(", "beamTokensTable", "[", ":", ",", ":", ",", "t", "-", "1", "]", ")", "\n", "# emb has shape (batchSize, beamSize, embedSize)", "\n", "output", ",", "hiddenStates", "=", "self", ".", "rnn", "(", "\n", "emb", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "embedSize", ")", ",", "hiddenStates", ")", "\n", "# output has shape (batchSize*beamSize, 1, rnnHiddenSize)", "\n", "scores", "=", "self", ".", "outNet", "(", "output", ".", "squeeze", "(", ")", ")", "\n", "logProbsCurrent", "=", "self", ".", "logSoftmax", "(", "scores", ")", "\n", "# logProbs has shape (batchSize*beamSize, vocabSize)", "\n", "# NOTE: Padding token has been removed from generator output during", "\n", "# sampling (RL fine-tuning). However, the padding token is still", "\n", "# present in the generator vocab and needs to be handled in this", "\n", "# beam search function. This will be supported in a future release.", "\n", "logProbsCurrent", "=", "logProbsCurrent", ".", "view", "(", "batchSize", ",", "beamSize", ",", "\n", "self", ".", "vocabSize", ")", "\n", "\n", "if", "LENGTH_NORM", ":", "\n", "# Add (current log probs / (t+1))", "\n", "                    ", "logProbs", "=", "logProbsCurrent", "*", "(", "aliveVector", ".", "float", "(", ")", "/", "\n", "(", "t", "+", "1", ")", ")", "\n", "# Add (previous log probs * (t/t+1) ) <- Mean update", "\n", "coeff_", "=", "aliveVector", ".", "eq", "(", "0", ")", ".", "float", "(", ")", "+", "(", "\n", "aliveVector", ".", "float", "(", ")", "*", "t", "/", "(", "t", "+", "1", ")", ")", "\n", "logProbs", "+=", "logProbSums", ".", "unsqueeze", "(", "2", ")", "*", "coeff_", "\n", "", "else", ":", "\n", "# Add currrent token logProbs for alive beams only", "\n", "                    ", "logProbs", "=", "logProbsCurrent", "*", "(", "aliveVector", ".", "float", "(", ")", ")", "\n", "# Add previous logProbSums upto t-1", "\n", "logProbs", "+=", "logProbSums", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Masking out along |V| dimension those sequence logProbs", "\n", "# which correspond to ended beams so as to only compare", "\n", "# one copy when sorting logProbs", "\n", "", "mask_", "=", "aliveVector", ".", "eq", "(", "0", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "vocabSize", ")", "\n", "mask_", "[", ":", ",", ":", ",", "\n", "0", "]", "=", "0", "# Zeroing all except first row for ended beams", "\n", "minus_infinity_", "=", "torch", ".", "min", "(", "logProbs", ")", ".", "data", "[", "0", "]", "\n", "logProbs", ".", "data", ".", "masked_fill_", "(", "mask_", ".", "data", ",", "minus_infinity_", ")", "\n", "\n", "logProbs", "=", "logProbs", ".", "view", "(", "batchSize", ",", "-", "1", ")", "\n", "tokensArray", "=", "tokenArange", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "batchSize", ",", "beamSize", ",", "1", ")", "\n", "tokensArray", ".", "masked_fill_", "(", "aliveVector", ".", "eq", "(", "0", ")", ",", "self", ".", "endToken", ")", "\n", "tokensArray", "=", "tokensArray", ".", "view", "(", "batchSize", ",", "-", "1", ")", "\n", "backIndexArray", "=", "backVector", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "vocabSize", ")", ".", "view", "(", "batchSize", ",", "-", "1", ")", "\n", "\n", "topLogProbs", ",", "topIdx", "=", "logProbs", ".", "topk", "(", "beamSize", ",", "dim", "=", "1", ")", "\n", "\n", "logProbSums", "=", "topLogProbs", "\n", "beamTokensTable", "[", ":", ",", ":", ",", "t", "]", "=", "tokensArray", ".", "gather", "(", "1", ",", "topIdx", ")", "\n", "backIndices", "[", ":", ",", ":", ",", "t", "]", "=", "backIndexArray", ".", "gather", "(", "1", ",", "topIdx", ")", "\n", "\n", "# Update corresponding hidden and cell states for next time step", "\n", "hiddenCurrent", ",", "cellCurrent", "=", "hiddenStates", "\n", "\n", "# Reshape to get explicit beamSize dim", "\n", "original_state_size", "=", "hiddenCurrent", ".", "size", "(", ")", "\n", "num_layers", ",", "_", ",", "rnnHiddenSize", "=", "original_state_size", "\n", "hiddenCurrent", "=", "hiddenCurrent", ".", "view", "(", "\n", "num_layers", ",", "batchSize", ",", "beamSize", ",", "rnnHiddenSize", ")", "\n", "cellCurrent", "=", "cellCurrent", ".", "view", "(", "\n", "num_layers", ",", "batchSize", ",", "beamSize", ",", "rnnHiddenSize", ")", "\n", "\n", "# Update states according to the next top beams", "\n", "backIndexVector", "=", "backIndices", "[", ":", ",", ":", ",", "t", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "num_layers", ",", "1", ",", "1", ",", "rnnHiddenSize", ")", "\n", "hiddenCurrent", "=", "hiddenCurrent", ".", "gather", "(", "2", ",", "backIndexVector", ")", "\n", "cellCurrent", "=", "cellCurrent", ".", "gather", "(", "2", ",", "backIndexVector", ")", "\n", "\n", "# Restore original shape for next rnn forward", "\n", "hiddenCurrent", "=", "hiddenCurrent", ".", "view", "(", "*", "original_state_size", ")", "\n", "cellCurrent", "=", "cellCurrent", ".", "view", "(", "*", "original_state_size", ")", "\n", "hiddenStates", "=", "(", "hiddenCurrent", ",", "cellCurrent", ")", "\n", "\n", "# Detecting endToken to end beams", "\n", "", "aliveVector", "=", "beamTokensTable", "[", ":", ",", ":", ",", "t", ":", "t", "+", "1", "]", ".", "ne", "(", "self", ".", "endToken", ")", "\n", "aliveBeams", "=", "aliveVector", ".", "data", ".", "long", "(", ")", ".", "sum", "(", ")", "\n", "finalLen", "=", "t", "\n", "if", "aliveBeams", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# Backtracking to get final beams", "\n", "", "", "beamTokensTable", "=", "beamTokensTable", ".", "data", "\n", "backIndices", "=", "backIndices", ".", "data", "\n", "\n", "# Keep this on when returning the top beam", "\n", "RECOVER_TOP_BEAM_ONLY", "=", "True", "\n", "\n", "tokenIdx", "=", "finalLen", "\n", "backID", "=", "backIndices", "[", ":", ",", ":", ",", "tokenIdx", "]", "\n", "tokens", "=", "[", "]", "\n", "while", "(", "tokenIdx", ">=", "0", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "beamTokensTable", "[", ":", ",", ":", ",", "tokenIdx", "]", ".", "gather", "(", "1", ",", "backID", ")", ".", "unsqueeze", "(", "2", ")", ")", "\n", "backID", "=", "backIndices", "[", ":", ",", ":", ",", "tokenIdx", "]", ".", "gather", "(", "1", ",", "backID", ")", "\n", "tokenIdx", "=", "tokenIdx", "-", "1", "\n", "\n", "", "tokens", ".", "append", "(", "startTokenArray", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ".", "data", ")", "\n", "tokens", ".", "reverse", "(", ")", "\n", "tokens", "=", "torch", ".", "cat", "(", "tokens", ",", "2", ")", "\n", "seqLens", "=", "tokens", ".", "ne", "(", "self", ".", "endToken", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "\n", "if", "RECOVER_TOP_BEAM_ONLY", ":", "\n", "# 'tokens' has shape (batchSize, beamSize, maxLen)", "\n", "# 'seqLens' has shape (batchSize, beamSize)", "\n", "            ", "tokens", "=", "tokens", "[", ":", ",", "0", "]", "# Keep only top beam", "\n", "seqLens", "=", "seqLens", "[", ":", ",", "0", "]", "\n", "\n", "", "return", "Variable", "(", "tokens", ")", ",", "Variable", "(", "seqLens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.get_mcts_samples": [[494, 577], ["initStates[].size", "th.LongTensor().fill_", "th.LongTensor().fill_", "th.LongTensor().fill_", "range", "th.LongTensor().fill_.masked_fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "th.LongTensor", "th.LongTensor", "th.LongTensor", "gen.Decoder.wordEmbed", "gen.Decoder.unsqueeze", "gen.Decoder.rnn", "gen.Decoder.outNet", "gen.Decoder.logSoftmax", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gen.Decoder.wordEmbed", "gen.Decoder.rnn", "gen.Decoder.outNet", "gen.Decoder.logSoftmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "samples.view.view.view", "beamTokensTable[].eq", "output.squeeze", "torch.distributions.Categorical.sample().unsqueeze", "torch.distributions.Categorical.sample().unsqueeze", "torch.distributions.Categorical.sample().unsqueeze", "x.unsqueeze().repeat", "x.view", "gen.Decoder.view", "output.squeeze", "torch.distributions.Categorical.sample().unsqueeze", "torch.distributions.Categorical.sample().unsqueeze", "torch.distributions.Categorical.sample().unsqueeze", "range", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "x.unsqueeze", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample"], "methods", ["None"], ["", "def", "get_mcts_samples", "(", "self", ",", "initStates", ",", "beamSize", ",", "maxLen", ",", "startTokens", ")", ":", "\n", "\n", "        ", "if", "self", ".", "wordEmbed", ".", "weight", ".", "is_cuda", ":", "\n", "            ", "th", "=", "torch", ".", "cuda", "\n", "", "else", ":", "\n", "            ", "th", "=", "torch", "\n", "\n", "", "batchSize", "=", "initStates", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "\n", "startTokenArray", "=", "startTokens", "\n", "\n", "# startTokenArray = Variable(startTokenArray)", "\n", "hiddenStates", "=", "initStates", "\n", "\n", "# Inits", "\n", "beamTokensTable", "=", "th", ".", "LongTensor", "(", "batchSize", ",", "beamSize", ",", "maxLen", ")", ".", "fill_", "(", "self", ".", "endToken", ")", "\n", "seqLenTable", "=", "th", ".", "LongTensor", "(", "batchSize", ",", "beamSize", ")", ".", "fill_", "(", "0", ")", "\n", "unitMat", "=", "th", ".", "LongTensor", "(", "batchSize", ",", "beamSize", ")", ".", "fill_", "(", "1", ")", "\n", "END_TOKEN_IDX", "=", "self", ".", "endToken", "-", "1", "\n", "\n", "for", "t", "in", "range", "(", "maxLen", ")", ":", "# Beam expansion till maxLen", "\n", "            ", "if", "t", "==", "0", ":", "\n", "# First column of beamTokensTable is generated from <START> token", "\n", "                ", "emb", "=", "self", ".", "wordEmbed", "(", "startTokenArray", ")", "\n", "emb", "=", "emb", ".", "unsqueeze", "(", "1", ")", "\n", "# emb has shape (batchSize, 1, embedSize)", "\n", "output", ",", "hiddenStates", "=", "self", ".", "rnn", "(", "emb", ",", "hiddenStates", ")", "\n", "# output has shape (batchSize, 1, rnnHiddenSize)", "\n", "scores", "=", "self", ".", "outNet", "(", "output", ".", "squeeze", "(", "1", ")", ")", "\n", "logProbs", "=", "self", ".", "logSoftmax", "(", "scores", ")", "\n", "\n", "# Additionally, remove <END> token in addition to removing the padding and start token from the first sample", "\n", "# to prevent the sampling of an empty sequence.", "\n", "logProbs", "=", "logProbs", "[", ":", ",", "1", ":", "-", "2", "]", "\n", "\n", "# scores & logProbs has shape (batchSize, vocabSize)", "\n", "probs", "=", "torch", ".", "exp", "(", "logProbs", ")", "\n", "categorical_dist", "=", "Categorical", "(", "probs", ")", "\n", "samples", "=", "[", "categorical_dist", ".", "sample", "(", ")", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "range", "(", "beamSize", ")", "]", "\n", "samples", "=", "torch", ".", "cat", "(", "samples", ",", "1", ")", "\n", "samples", "=", "samples", "+", "1", "\n", "\n", "beamTokensTable", "[", ":", ",", ":", ",", "0", "]", "=", "samples", ".", "data", "\n", "\n", "# Repeating hiddenStates 'beamSize' times for subsequent self.rnn calls", "\n", "hiddenStates", "=", "[", "\n", "x", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "beamSize", ",", "1", ")", "\n", "for", "x", "in", "hiddenStates", "\n", "]", "\n", "hiddenStates", "=", "[", "\n", "x", ".", "view", "(", "self", ".", "numLayers", ",", "-", "1", ",", "self", ".", "rnnHiddenSize", ")", "\n", "for", "x", "in", "hiddenStates", "\n", "]", "\n", "\n", "# H_0 and C_0 have shape (numLayers, batchSize*beamSize, rnnHiddenSize)", "\n", "", "else", ":", "\n", "# Subsequent columns are generated from previous tokens", "\n", "                ", "emb", "=", "self", ".", "wordEmbed", "(", "beamTokensTable", "[", ":", ",", ":", ",", "t", "-", "1", "]", ")", "\n", "# emb has shape (batchSize, beamSize, embedSize)", "\n", "output", ",", "hiddenStates", "=", "self", ".", "rnn", "(", "emb", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "embedSize", ")", ",", "hiddenStates", ")", "\n", "# output has shape (batchSize*beamSize, 1, rnnHiddenSize)", "\n", "scores", "=", "self", ".", "outNet", "(", "output", ".", "squeeze", "(", ")", ")", "\n", "logProbsCurrent", "=", "self", ".", "logSoftmax", "(", "scores", ")", "\n", "# Explicitly removing padding token (index 0) and <START> token", "\n", "# (index -2) from logProbs so that they are never sampled.", "\n", "# This is allows us to keep <START> and padding token in", "\n", "# the decoder vocab without any problems in RL sampling.", "\n", "logProbsCurrent", "=", "torch", ".", "cat", "(", "[", "logProbsCurrent", "[", ":", ",", "1", ":", "-", "2", "]", ",", "logProbsCurrent", "[", ":", ",", "-", "1", ":", "]", "]", ",", "1", ")", "\n", "probs", "=", "torch", ".", "exp", "(", "logProbsCurrent", ")", "\n", "categorical_dist", "=", "Categorical", "(", "probs", ")", "\n", "samples", "=", "[", "categorical_dist", ".", "sample", "(", ")", ".", "unsqueeze", "(", "1", ")", "]", "\n", "samples", "=", "torch", ".", "cat", "(", "samples", ",", "1", ")", "\n", "samples", "=", "samples", ".", "view", "(", "batchSize", ",", "beamSize", ")", "\n", "samples", "=", "samples", "+", "1", "# adding one offset as we deleted the padding token.", "\n", "# computational graph deliberately broken at this point", "\n", "beamTokensTable", "[", ":", ",", ":", ",", "t", "]", "=", "samples", ".", "data", "\n", "\n", "# update lengths here; check if an end token was generated", "\n", "", "unitMat", ".", "masked_fill_", "(", "beamTokensTable", "[", ":", ",", ":", ",", "t", "]", ".", "eq", "(", "END_TOKEN_IDX", ")", ",", "0", ")", "\n", "# Add +1 length to all un-ended sequences", "\n", "seqLenTable", "=", "seqLenTable", "+", "unitMat", "\n", "\n", "", "return", "Variable", "(", "beamTokensTable", ")", ",", "Variable", "(", "seqLenTable", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.__init__": [[10, 81], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocabSize", ",", "\n", "embedSize", ",", "\n", "rnnHiddenSize", ",", "\n", "numLayers", ",", "\n", "useIm", ",", "\n", "imgEmbedSize", ",", "\n", "imgFeatureSize", ",", "\n", "numRounds", ",", "\n", "isAnswerer", ",", "\n", "dropout", "=", "0", ",", "\n", "startToken", "=", "None", ",", "\n", "endToken", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabSize", "=", "vocabSize", "\n", "self", ".", "embedSize", "=", "embedSize", "\n", "self", ".", "rnnHiddenSize", "=", "rnnHiddenSize", "\n", "self", ".", "numLayers", "=", "numLayers", "\n", "assert", "self", ".", "numLayers", ">", "1", ",", "\"Less than 2 layers not supported!\"", "\n", "if", "useIm", ":", "\n", "            ", "self", ".", "useIm", "=", "useIm", "if", "useIm", "!=", "True", "else", "'early'", "\n", "", "else", ":", "\n", "            ", "self", ".", "useIm", "=", "False", "\n", "", "self", ".", "imgEmbedSize", "=", "imgEmbedSize", "\n", "self", ".", "imgFeatureSize", "=", "imgFeatureSize", "\n", "self", ".", "numRounds", "=", "numRounds", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "isAnswerer", "=", "isAnswerer", "\n", "self", ".", "startToken", "=", "startToken", "\n", "self", ".", "endToken", "=", "endToken", "\n", "\n", "# modules", "\n", "self", ".", "wordEmbed", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocabSize", ",", "self", ".", "embedSize", ",", "padding_idx", "=", "0", ")", "\n", "\n", "# question encoder", "\n", "# image fuses early with words", "\n", "if", "self", ".", "useIm", "==", "'early'", ":", "\n", "            ", "quesInputSize", "=", "self", ".", "embedSize", "+", "self", ".", "imgEmbedSize", "\n", "dialogInputSize", "=", "2", "*", "self", ".", "rnnHiddenSize", "\n", "self", ".", "imgNet", "=", "nn", ".", "Linear", "(", "self", ".", "imgFeatureSize", ",", "self", ".", "imgEmbedSize", ")", "\n", "self", ".", "imgEmbedDropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "", "elif", "self", ".", "useIm", "==", "'late'", ":", "\n", "            ", "quesInputSize", "=", "self", ".", "embedSize", "\n", "dialogInputSize", "=", "2", "*", "self", ".", "rnnHiddenSize", "+", "self", ".", "imgEmbedSize", "\n", "self", ".", "imgNet", "=", "nn", ".", "Linear", "(", "self", ".", "imgFeatureSize", ",", "self", ".", "imgEmbedSize", ")", "\n", "self", ".", "imgEmbedDropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "", "elif", "self", ".", "isAnswerer", ":", "\n", "            ", "quesInputSize", "=", "self", ".", "embedSize", "\n", "dialogInputSize", "=", "2", "*", "self", ".", "rnnHiddenSize", "\n", "", "else", ":", "\n", "            ", "dialogInputSize", "=", "self", ".", "rnnHiddenSize", "\n", "", "if", "self", ".", "isAnswerer", ":", "\n", "            ", "self", ".", "quesRNN", "=", "nn", ".", "LSTM", "(", "\n", "quesInputSize", ",", "\n", "self", ".", "rnnHiddenSize", ",", "\n", "self", ".", "numLayers", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "0", ")", "\n", "\n", "# history encoder", "\n", "", "self", ".", "factRNN", "=", "nn", ".", "LSTM", "(", "\n", "self", ".", "embedSize", ",", "\n", "self", ".", "rnnHiddenSize", ",", "\n", "self", ".", "numLayers", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "0", ")", "\n", "\n", "# dialog rnn", "\n", "self", ".", "dialogRNN", "=", "nn", ".", "LSTMCell", "(", "dialogInputSize", ",", "self", ".", "rnnHiddenSize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset": [[82, 107], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# batchSize is inferred from input", "\n", "        ", "self", ".", "batchSize", "=", "0", "\n", "\n", "# Input data", "\n", "self", ".", "image", "=", "None", "\n", "self", ".", "imageEmbed", "=", "None", "\n", "\n", "self", ".", "captionTokens", "=", "None", "\n", "self", ".", "captionEmbed", "=", "None", "\n", "self", ".", "captionLens", "=", "None", "\n", "\n", "self", ".", "questionTokens", "=", "[", "]", "\n", "self", ".", "questionEmbeds", "=", "[", "]", "\n", "self", ".", "questionLens", "=", "[", "]", "\n", "\n", "self", ".", "answerTokens", "=", "[", "]", "\n", "self", ".", "answerEmbeds", "=", "[", "]", "\n", "self", ".", "answerLengths", "=", "[", "]", "\n", "\n", "# Hidden embeddings", "\n", "self", ".", "factEmbeds", "=", "[", "]", "\n", "self", ".", "questionRNNStates", "=", "[", "]", "\n", "self", ".", "dialogRNNInputs", "=", "[", "]", "\n", "self", ".", "dialogHiddens", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder._initHidden": [[108, 116], ["someTensor.new().zero_", "someTensor.new().zero_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "someTensor.new", "someTensor.new"], "methods", ["None"], ["", "def", "_initHidden", "(", "self", ")", ":", "\n", "        ", "'''Initial dialog rnn state - initialize with zeros'''", "\n", "# Dynamic batch size inference", "\n", "assert", "self", ".", "batchSize", "!=", "0", ",", "'Observe something to infer batch size.'", "\n", "someTensor", "=", "self", ".", "dialogRNN", ".", "weight_hh", ".", "data", "\n", "h", "=", "someTensor", ".", "new", "(", "self", ".", "batchSize", ",", "self", ".", "dialogRNN", ".", "hidden_size", ")", ".", "zero_", "(", ")", "\n", "c", "=", "someTensor", ".", "new", "(", "self", ".", "batchSize", ",", "self", ".", "dialogRNN", ".", "hidden_size", ")", ".", "zero_", "(", ")", "\n", "return", "(", "Variable", "(", "h", ")", ",", "Variable", "(", "c", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe": [[117, 157], ["len", "hre.Encoder.processSequence", "len", "hre.Encoder.processSequence", "hre.Encoder.questionTokens.append", "hre.Encoder.questionLens.append", "hre.Encoder.processSequence", "hre.Encoder.answerTokens.append", "hre.Encoder.answerLengths.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence"], ["", "def", "observe", "(", "self", ",", "\n", "round", ",", "\n", "image", "=", "None", ",", "\n", "caption", "=", "None", ",", "\n", "ques", "=", "None", ",", "\n", "ans", "=", "None", ",", "\n", "captionLens", "=", "None", ",", "\n", "quesLens", "=", "None", ",", "\n", "ansLens", "=", "None", ")", ":", "\n", "        ", "'''\n        Store dialog input to internal model storage\n\n        Note that all input sequences are assumed to be left-aligned (i.e.\n        right-padded). Internally this alignment is changed to right-align\n        for ease in computing final time step hidden states of each RNN\n        '''", "\n", "if", "image", "is", "not", "None", ":", "\n", "            ", "assert", "round", "==", "-", "1", "\n", "self", ".", "image", "=", "image", "\n", "self", ".", "imageEmbed", "=", "None", "\n", "self", ".", "batchSize", "=", "len", "(", "self", ".", "image", ")", "\n", "", "if", "caption", "is", "not", "None", ":", "\n", "            ", "assert", "round", "==", "-", "1", "\n", "assert", "captionLens", "is", "not", "None", ",", "\"Caption lengths required!\"", "\n", "caption", ",", "captionLens", "=", "self", ".", "processSequence", "(", "caption", ",", "captionLens", ")", "\n", "self", ".", "captionTokens", "=", "caption", "\n", "self", ".", "captionLens", "=", "captionLens", "\n", "self", ".", "batchSize", "=", "len", "(", "self", ".", "captionTokens", ")", "\n", "", "if", "ques", "is", "not", "None", ":", "\n", "            ", "assert", "round", "==", "len", "(", "self", ".", "questionEmbeds", ")", "\n", "assert", "quesLens", "is", "not", "None", ",", "\"Questions lengths required!\"", "\n", "ques", ",", "quesLens", "=", "self", ".", "processSequence", "(", "ques", ",", "quesLens", ")", "\n", "self", ".", "questionTokens", ".", "append", "(", "ques", ")", "\n", "self", ".", "questionLens", ".", "append", "(", "quesLens", ")", "\n", "", "if", "ans", "is", "not", "None", ":", "\n", "            ", "assert", "round", "==", "len", "(", "self", ".", "answerEmbeds", ")", "\n", "assert", "ansLens", "is", "not", "None", ",", "\"Answer lengths required!\"", "\n", "ans", ",", "ansLens", "=", "self", ".", "processSequence", "(", "ans", ",", "ansLens", ")", "\n", "self", ".", "answerTokens", ".", "append", "(", "ans", ")", "\n", "self", ".", "answerLengths", ".", "append", "(", "ansLens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.processSequence": [[158, 161], ["None"], "methods", ["None"], ["", "", "def", "processSequence", "(", "self", ",", "seq", ",", "seqLen", ")", ":", "\n", "        ", "''' Strip <START> and <END> token from a left-aligned sequence'''", "\n", "return", "seq", "[", ":", ",", "1", ":", "]", ",", "seqLen", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedInputDialog": [[162, 185], ["hre.Encoder.imgNet", "hre.Encoder.wordEmbed", "len", "len", "len", "hre.Encoder.questionEmbeds.append", "len", "len", "len", "hre.Encoder.answerEmbeds.append", "hre.Encoder.imgEmbedDropout", "hre.Encoder.wordEmbed", "hre.Encoder.wordEmbed"], "methods", ["None"], ["", "def", "embedInputDialog", "(", "self", ")", ":", "\n", "        ", "'''\n        Lazy embedding of input:\n            Calling observe does not process (embed) any inputs. Since\n            self.forward requires embedded inputs, this function lazily\n            embeds them so that they are not re-computed upon multiple\n            calls to forward in the same round of dialog.\n        '''", "\n", "# Embed image, occurs once per dialog", "\n", "if", "self", ".", "isAnswerer", "and", "self", ".", "imageEmbed", "is", "None", ":", "\n", "            ", "self", ".", "imageEmbed", "=", "self", ".", "imgNet", "(", "self", ".", "imgEmbedDropout", "(", "self", ".", "image", ")", ")", "\n", "# Embed caption, occurs once per dialog", "\n", "", "if", "self", ".", "captionEmbed", "is", "None", ":", "\n", "            ", "self", ".", "captionEmbed", "=", "self", ".", "wordEmbed", "(", "self", ".", "captionTokens", ")", "\n", "# Embed questions", "\n", "", "while", "len", "(", "self", ".", "questionEmbeds", ")", "<", "len", "(", "self", ".", "questionTokens", ")", ":", "\n", "            ", "idx", "=", "len", "(", "self", ".", "questionEmbeds", ")", "\n", "self", ".", "questionEmbeds", ".", "append", "(", "\n", "self", ".", "wordEmbed", "(", "self", ".", "questionTokens", "[", "idx", "]", ")", ")", "\n", "# Embed answers", "\n", "", "while", "len", "(", "self", ".", "answerEmbeds", ")", "<", "len", "(", "self", ".", "answerTokens", ")", ":", "\n", "            ", "idx", "=", "len", "(", "self", ".", "answerEmbeds", ")", "\n", "self", ".", "answerEmbeds", ".", "append", "(", "self", ".", "wordEmbed", "(", "self", ".", "answerTokens", "[", "idx", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedFact": [[186, 209], ["hre.Encoder.factEmbeds.append", "utils.utilities.utilities.dynamicRNN", "utils.utilities.utilities.concatPaddedSequences", "hre.Encoder.wordEmbed", "utils.utilities.utilities.dynamicRNN"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.dynamicRNN", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.concatPaddedSequences", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.dynamicRNN"], ["", "", "def", "embedFact", "(", "self", ",", "factIdx", ")", ":", "\n", "        ", "'''Embed facts i.e. caption and round 0 or question-answer pair otherwise'''", "\n", "# Caption", "\n", "if", "factIdx", "==", "0", ":", "\n", "            ", "seq", ",", "seqLens", "=", "self", ".", "captionEmbed", ",", "self", ".", "captionLens", "\n", "factEmbed", ",", "states", "=", "utils", ".", "dynamicRNN", "(", "\n", "self", ".", "factRNN", ",", "seq", ",", "seqLens", ",", "returnStates", "=", "True", ")", "\n", "# QA pairs", "\n", "", "elif", "factIdx", ">", "0", ":", "\n", "            ", "quesTokens", ",", "quesLens", "=", "self", ".", "questionTokens", "[", "factIdx", "-", "1", "]", ",", "self", ".", "questionLens", "[", "factIdx", "-", "1", "]", "\n", "ansTokens", ",", "ansLens", "=", "self", ".", "answerTokens", "[", "factIdx", "-", "1", "]", ",", "self", ".", "answerLengths", "[", "factIdx", "-", "1", "]", "\n", "\n", "qaTokens", "=", "utils", ".", "concatPaddedSequences", "(", "\n", "quesTokens", ",", "quesLens", ",", "ansTokens", ",", "ansLens", ",", "padding", "=", "'right'", ")", "\n", "qa", "=", "self", ".", "wordEmbed", "(", "qaTokens", ")", "\n", "qaLens", "=", "quesLens", "+", "ansLens", "\n", "qaEmbed", ",", "states", "=", "utils", ".", "dynamicRNN", "(", "\n", "self", ".", "factRNN", ",", "qa", ",", "qaLens", ",", "returnStates", "=", "True", ")", "\n", "factEmbed", "=", "qaEmbed", "\n", "", "factRNNstates", "=", "states", "\n", "self", ".", "factEmbeds", ".", "append", "(", "(", "factEmbed", ",", "factRNNstates", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedQuestion": [[210, 221], ["utils.utilities.utilities.dynamicRNN", "hre.Encoder.questionRNNStates.append", "hre.Encoder.imageEmbed.unsqueeze().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "hre.Encoder.imageEmbed.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.dynamicRNN"], ["", "def", "embedQuestion", "(", "self", ",", "qIdx", ")", ":", "\n", "        ", "'''Embed questions'''", "\n", "quesIn", "=", "self", ".", "questionEmbeds", "[", "qIdx", "]", "\n", "quesLens", "=", "self", ".", "questionLens", "[", "qIdx", "]", "\n", "if", "self", ".", "useIm", "==", "'early'", ":", "\n", "            ", "image", "=", "self", ".", "imageEmbed", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "quesIn", ".", "size", "(", "1", ")", ",", "1", ")", "\n", "quesIn", "=", "torch", ".", "cat", "(", "[", "quesIn", ",", "image", "]", ",", "2", ")", "\n", "", "qEmbed", ",", "states", "=", "utils", ".", "dynamicRNN", "(", "\n", "self", ".", "quesRNN", ",", "quesIn", ",", "quesLens", ",", "returnStates", "=", "True", ")", "\n", "quesRNNstates", "=", "states", "\n", "self", ".", "questionRNNStates", ".", "append", "(", "(", "qEmbed", ",", "quesRNNstates", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.concatDialogRNNInput": [[222, 230], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hre.Encoder.dialogRNNInputs.append", "currIns.append", "currIns.append"], "methods", ["None"], ["", "def", "concatDialogRNNInput", "(", "self", ",", "histIdx", ")", ":", "\n", "        ", "currIns", "=", "[", "self", ".", "factEmbeds", "[", "histIdx", "]", "[", "0", "]", "]", "\n", "if", "self", ".", "isAnswerer", ":", "\n", "            ", "currIns", ".", "append", "(", "self", ".", "questionRNNStates", "[", "histIdx", "]", "[", "0", "]", ")", "\n", "", "if", "self", ".", "useIm", "==", "'late'", ":", "\n", "            ", "currIns", ".", "append", "(", "self", ".", "imageEmbed", ")", "\n", "", "hist_t", "=", "torch", ".", "cat", "(", "currIns", ",", "-", "1", ")", "\n", "self", ".", "dialogRNNInputs", ".", "append", "(", "hist_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedDialog": [[231, 239], ["hre.Encoder.dialogRNN", "hre.Encoder.dialogHiddens.append", "hre.Encoder._initHidden"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder._initHidden"], ["", "def", "embedDialog", "(", "self", ",", "dialogIdx", ")", ":", "\n", "        ", "if", "dialogIdx", "==", "0", ":", "\n", "            ", "hPrev", "=", "self", ".", "_initHidden", "(", ")", "\n", "", "else", ":", "\n", "            ", "hPrev", "=", "self", ".", "dialogHiddens", "[", "-", "1", "]", "\n", "", "inpt", "=", "self", ".", "dialogRNNInputs", "[", "dialogIdx", "]", "\n", "hNew", "=", "self", ".", "dialogRNN", "(", "inpt", ",", "hPrev", ")", "\n", "self", ".", "dialogHiddens", ".", "append", "(", "hNew", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.forward": [[240, 314], ["hre.Encoder.embedInputDialog", "len", "len", "len", "hre.Encoder.embedFact", "len", "len", "hre.Encoder.concatDialogRNNInput", "len", "len", "hre.Encoder.embedDialog", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "len", "len", "hre.Encoder.embedQuestion", "dialogHidden.unsqueeze", "dialogHidden.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedInputDialog", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedFact", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.concatDialogRNNInput", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedDialog", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.embedQuestion"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "'''\n        Returns:\n            A tuple of tensors (H, C) each of shape (batchSize, rnnHiddenSize)\n            to be used as the initial Hidden and Cell states of the Decoder.\n            See notes at the end on how (H, C) are computed.\n        '''", "\n", "\n", "# Lazily embed input Image, Captions, Questions and Answers", "\n", "self", ".", "embedInputDialog", "(", ")", "\n", "\n", "if", "self", ".", "isAnswerer", ":", "\n", "# For A-Bot, current round is the number of facts present,", "\n", "# which is number of questions observed - 1 (as opposed", "\n", "# to len(self.answerEmbeds), which may be inaccurate as", "\n", "            ", "round", "=", "len", "(", "self", ".", "questionEmbeds", ")", "-", "1", "\n", "", "else", ":", "\n", "# For Q-Bot, current round is the number of facts present,", "\n", "# which is same as the number of answers observed", "\n", "            ", "round", "=", "len", "(", "self", ".", "answerEmbeds", ")", "\n", "\n", "# Lazy computation of internal hidden embeddings (hence the while loops)", "\n", "\n", "# Infer any missing facts", "\n", "", "while", "len", "(", "self", ".", "factEmbeds", ")", "<=", "round", ":", "\n", "            ", "factIdx", "=", "len", "(", "self", ".", "factEmbeds", ")", "\n", "self", ".", "embedFact", "(", "factIdx", ")", "\n", "\n", "# Embed any un-embedded questions (A-Bot only)", "\n", "", "if", "self", ".", "isAnswerer", ":", "\n", "            ", "while", "len", "(", "self", ".", "questionRNNStates", ")", "<=", "round", ":", "\n", "                ", "qIdx", "=", "len", "(", "self", ".", "questionRNNStates", ")", "\n", "self", ".", "embedQuestion", "(", "qIdx", ")", "\n", "\n", "# Concat facts and/or questions (i.e. history) for input to dialogRNN", "\n", "", "", "while", "len", "(", "self", ".", "dialogRNNInputs", ")", "<=", "round", ":", "\n", "            ", "histIdx", "=", "len", "(", "self", ".", "dialogRNNInputs", ")", "\n", "self", ".", "concatDialogRNNInput", "(", "histIdx", ")", "\n", "\n", "# Forward dialogRNN one step", "\n", "", "while", "len", "(", "self", ".", "dialogHiddens", ")", "<=", "round", ":", "\n", "            ", "dialogIdx", "=", "len", "(", "self", ".", "dialogHiddens", ")", "\n", "self", ".", "embedDialog", "(", "dialogIdx", ")", "\n", "\n", "# Latest dialogRNN hidden state", "\n", "", "dialogHidden", "=", "self", ".", "dialogHiddens", "[", "-", "1", "]", "[", "0", "]", "\n", "\n", "'''\n        Return hidden (H_link) and cell (C_link) states as per the following rule:\n        (Currently this is defined only for numLayers == 2)\n        If A-Bot:\n          C_link == Question encoding RNN cell state (quesRNN)\n          H_link ==\n              Layer 0 : Question encoding RNN hidden state (quesRNN)t\n              Layer 1 : DialogRNN hidden state (dialogRNN)\n\n        If Q-Bot:\n            C_link == Fact encoding RNN cell state (factRNN)\n            H_link ==\n                Layer 0 : Fact encoding RNN hidden state (factRNN)\n                Layer 1 : DialogRNN hidden state (dialogRNN)\n        '''", "\n", "if", "self", ".", "isAnswerer", ":", "\n", "            ", "quesRNNstates", "=", "self", ".", "questionRNNStates", "[", "-", "1", "]", "[", "1", "]", "# Latest quesRNN states", "\n", "C_link", "=", "quesRNNstates", "[", "1", "]", "\n", "H_link", "=", "quesRNNstates", "[", "0", "]", "[", ":", "-", "1", "]", "\n", "H_link", "=", "torch", ".", "cat", "(", "[", "H_link", ",", "dialogHidden", ".", "unsqueeze", "(", "0", ")", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "factRNNstates", "=", "self", ".", "factEmbeds", "[", "-", "1", "]", "[", "1", "]", "# Latest factRNN states", "\n", "C_link", "=", "factRNNstates", "[", "1", "]", "\n", "H_link", "=", "factRNNstates", "[", "0", "]", "[", ":", "-", "1", "]", "\n", "H_link", "=", "torch", ".", "cat", "(", "[", "H_link", ",", "dialogHidden", ".", "unsqueeze", "(", "0", ")", "]", ",", "0", ")", "\n", "\n", "", "return", "H_link", ",", "C_link", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.human_study_data.dumpData": [[7, 43], ["human_study_data.run_dialog", "os.path.join", "print", "open", "print", "json.dump"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.dialog_generate.run_dialog"], ["def", "dumpData", "(", "params", ",", "\n", "dataset", ",", "\n", "split", ",", "\n", "aBot", ",", "\n", "qBot", ",", "\n", "beamSize", "=", "5", ",", "\n", "saveFolder", "=", "\"dialog_output\"", ")", ":", "\n", "    ", "'''\n        Generates dialog and saves it to a json for later visualization.\n        Dialog is generated by both agents conversing (A-Bot is shown the GT image and both\n        agents have access to a caption generated by a pre-trained captioning model).\n\n        Arguments:\n            params  : Parameter dict for all options\n            dataset : VisDialDataset instance\n            split   : Dataset split, can be 'val' or 'test'\n            aBot    : A-Bot\n            qBot    : Q-Bot\n\n            beamSize : Beam search width for generating utterrances\n            saveFolder : Folder path for saving dialog related files\n    '''", "\n", "text", "=", "run_dialog", "(", "params", ",", "\n", "dataset", ",", "\n", "split", ",", "\n", "aBot", ",", "\n", "qBot", ",", "\n", "beamSize", "=", "beamSize", ")", "\n", "\n", "savePathJson", "=", "os", ".", "path", ".", "join", "(", "saveFolder", ",", "\"results.json\"", ")", "\n", "\n", "with", "open", "(", "savePathJson", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "print", "(", "\"Writing dialog text data to file: {}\"", ".", "format", "(", "savePathJson", ")", ")", "\n", "json", ".", "dump", "(", "text", ",", "fp", ")", "\n", "\n", "", "print", "(", "\"Done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.human_study_data.run_dialog": [[44, 154], ["torch.utils.data.DataLoader", "enumerate", "str", "str", "dataset.data.keys", "print", "print", "open", "json.load", "print", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "six.moves.range", "six.moves.range", "getImgFileName", "aBot.observe", "qBot.observe", "qBot.forwardDecode", "qBot.observe", "aBot.observe", "aBot.forwardDecode", "aBot.observe", "qBot.observe", "qBot.encoder", "six.moves.range", "text[].extend", "aBot.eval", "aBot.reset", "qBot.eval", "qBot.reset", "to_str_gt", "to_str_pred", "to_str_pred", "hasattr", "v.cuda", "batch.items", "[].append", "filter", "w.data.cpu().numpy", "list", "l.data.cpu", "filter", "w.data.cpu", "w.data.cpu().numpy", "w.data.cpu"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset"], ["", "def", "run_dialog", "(", "params", ",", "\n", "dataset", ",", "\n", "split", ",", "\n", "aBot", ",", "\n", "qBot", ",", "\n", "beamSize", "=", "5", ")", ":", "\n", "\n", "    ", "assert", "(", "qBot", "is", "not", "None", "and", "aBot", "is", "not", "None", ")", ",", "\"Must provide both Q-Bot and A-Bot when generating dialog\"", "\n", "old_split", "=", "dataset", ".", "split", "\n", "batchSize", "=", "dataset", ".", "batchSize", "\n", "numRounds", "=", "dataset", ".", "numRounds", "\n", "\n", "ind2word", "=", "dataset", ".", "ind2word", "\n", "to_str_gt", "=", "lambda", "w", ":", "str", "(", "\" \"", ".", "join", "(", "[", "ind2word", "[", "x", "]", "for", "x", "in", "filter", "(", "lambda", "x", ":", "x", ">", "0", ",", "w", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "]", ")", ")", "#.encode('utf-8','ignore')", "\n", "to_str_pred", "=", "lambda", "w", ",", "l", ":", "str", "(", "\" \"", ".", "join", "(", "[", "ind2word", "[", "x", "]", "for", "x", "in", "list", "(", "filter", "(", "\n", "lambda", "x", ":", "x", ">", "0", ",", "w", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "]", "[", ":", "l", ".", "data", ".", "cpu", "(", ")", "[", "0", "]", "]", ")", ")", "#.encode('utf-8','ignore')", "\n", "\n", "dataset", ".", "split", "=", "split", "\n", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batchSize", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "\n", "text", "=", "{", "'data'", ":", "[", "]", "}", "\n", "if", "'%s_img_fnames'", "%", "split", "not", "in", "dataset", ".", "data", ".", "keys", "(", ")", ":", "\n", "        ", "print", "(", "\"[Error] Need coco directory and info as input \"", "\"to -cocoDir and -cocoInfo arguments for locating \"", "\"coco image files.\"", ")", "\n", "print", "(", "\"Exiting dialogDump without saving files.\"", ")", "\n", "return", "None", "\n", "\n", "", "getImgFileName", "=", "lambda", "x", ":", "dataset", ".", "data", "[", "'%s_img_fnames'", "%", "split", "]", "[", "x", "]", "\n", "\n", "tot_idx", "=", "0", "\n", "output_dialog", "=", "True", "\n", "img_pool", "=", "None", "\n", "# this file consists a mapping between a image and pool of images. The list of images is the set of images the ", "\n", "# human study is done on. The image pool is relevant for evaluation purposes. The first 6 images are the 6 closest", "\n", "# images to a given image in the test split of v1.0 visdial. Therefore, this consists of the image itself along with", "\n", "# 5 nearest neighbors based on fc7 similarity. The images after these 6 images are randomly selected images.", "\n", "with", "open", "(", "'data/human_study/img_pool.json'", ",", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "img_pool", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "for", "idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "print", "(", "\"current batch:\"", ",", "idx", ")", "\n", "tot_idx", "=", "tot_idx", "+", "1", "\n", "imgIds", "=", "[", "getImgFileName", "(", "x", ")", "for", "x", "in", "batch", "[", "'index'", "]", "]", "\n", "dialog", "=", "[", "{", "'dialog'", ":", "[", "]", ",", "'image_id'", ":", "imgId", ",", "'img_pool'", ":", "img_pool", "[", "imgId", "]", "}", "for", "imgId", "in", "imgIds", "]", "\n", "\n", "if", "dataset", ".", "useGPU", ":", "\n", "            ", "batch", "=", "{", "key", ":", "v", ".", "cuda", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "else", "v", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "\n", "", "image", "=", "Variable", "(", "batch", "[", "'img_feat'", "]", ",", "volatile", "=", "True", ")", "\n", "caption", "=", "Variable", "(", "batch", "[", "'cap'", "]", ",", "volatile", "=", "True", ")", "\n", "captionLens", "=", "Variable", "(", "batch", "[", "'cap_len'", "]", ",", "volatile", "=", "True", ")", "\n", "\n", "if", "aBot", ":", "\n", "            ", "aBot", ".", "eval", "(", ")", ",", "aBot", ".", "reset", "(", ")", "\n", "aBot", ".", "observe", "(", "\n", "-", "1", ",", "image", "=", "image", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "", "if", "qBot", ":", "\n", "            ", "qBot", ".", "eval", "(", ")", ",", "qBot", ".", "reset", "(", ")", "\n", "qBot", ".", "observe", "(", "-", "1", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "", "questions", "=", "[", "]", "\n", "\n", "for", "j", "in", "range", "(", "batchSize", ")", ":", "\n", "            ", "caption_str", "=", "to_str_gt", "(", "caption", "[", "j", "]", ")", "[", "8", ":", "-", "6", "]", "\n", "dialog", "[", "j", "]", "[", "'caption'", "]", "=", "caption_str", "\n", "\n", "", "for", "round", "in", "range", "(", "numRounds", ")", ":", "\n", "\n", "            ", "questions", ",", "quesLens", "=", "qBot", ".", "forwardDecode", "(", "\n", "beamSize", "=", "beamSize", ",", "inference", "=", "'greedy'", ")", "\n", "qBot", ".", "observe", "(", "round", ",", "ques", "=", "questions", ",", "quesLens", "=", "quesLens", ")", "\n", "aBot", ".", "observe", "(", "round", ",", "ques", "=", "questions", ",", "quesLens", "=", "quesLens", ")", "\n", "answers", ",", "ansLens", "=", "aBot", ".", "forwardDecode", "(", "\n", "beamSize", "=", "beamSize", ",", "inference", "=", "'greedy'", ")", "\n", "aBot", ".", "observe", "(", "round", ",", "ans", "=", "answers", ",", "ansLens", "=", "ansLens", ")", "\n", "qBot", ".", "observe", "(", "round", ",", "ans", "=", "answers", ",", "ansLens", "=", "ansLens", ")", "\n", "qBot", ".", "encoder", "(", ")", "\n", "\n", "for", "j", "in", "range", "(", "batchSize", ")", ":", "\n", "                ", "question_str", "=", "to_str_pred", "(", "questions", "[", "j", "]", ",", "quesLens", "[", "j", "]", ")", "\n", "answer_str", "=", "to_str_pred", "(", "answers", "[", "j", "]", ",", "ansLens", "[", "j", "]", ")", "\n", "if", "output_dialog", ":", "\n", "                    ", "dialog", "[", "j", "]", "[", "'dialog'", "]", ".", "append", "(", "{", "\n", "\"answer\"", ":", "answer_str", "[", "8", ":", "]", ",", "\n", "\"question\"", ":", "question_str", "[", "8", ":", "]", "+", "\" \"", "\n", "}", ")", "# \"8:\" for indexing out initial <START>", "\n", "\n", "", "", "", "if", "output_dialog", ":", "\n", "            ", "text", "[", "'data'", "]", ".", "extend", "(", "dialog", ")", "\n", "\n", "", "", "text", "[", "'opts'", "]", "=", "{", "\n", "'qbot'", ":", "params", "[", "'qstartFrom'", "]", ",", "\n", "'abot'", ":", "params", "[", "'startFrom'", "]", ",", "\n", "'beamSize'", ":", "beamSize", ",", "\n", "'decoder'", ":", "params", "[", "'decoder'", "]", ",", "\n", "'encoder'", ":", "params", "[", "'encoder'", "]", ",", "\n", "}", "\n", "\n", "dataset", ".", "split", "=", "old_split", "\n", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.dialog_generate.dialogDump": [[20, 179], ["dialog_generate.run_dialog", "os.path.join", "os.path.join", "os.path.join", "print", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.legend", "plt.figure.savefig", "matplotlib.figure", "matplotlib.plot", "matplotlib.title", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.legend", "plt.figure.savefig", "open", "fp.write", "open", "print", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "fp.write", "open", "print", "json.dump", "open", "print", "fp.write", "os.path.join", "os.path.join", "str", "round", "map", "map", "map", "map", "map", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round", "str", "round"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.dialog_generate.run_dialog"], ["def", "dialogDump", "(", "params", ",", "\n", "dataset", ",", "\n", "split", ",", "\n", "aBot", ",", "\n", "qBot", "=", "None", ",", "\n", "beamSize", "=", "1", ",", "\n", "saveFolder", "=", "\"dialog_output\"", ")", ":", "\n", "    ", "'''\n        Generates dialog and saves it to a json for later visualization.\n        If only A-Bot is given, A-Bot answers are generated given GT image,\n        caption and questions. If both agents are given, dialog is generated\n        by both agents conversing (A-Bot is shown the GT image and both\n        agents have access to a caption generated by a pre-trained captioning\n        model).\n\n        Arguments:\n            params  : Parameter dict for all options\n            dataset : VisDialDataset instance\n            split   : Dataset split, can be 'val' or 'test'\n            aBot    : A-Bot\n            qBot    : Q-Bot (Optional)\n\n            beamSize : Beam search width for generating utterrances\n            saveFolder : Folder path for saving dialog related files\n    '''", "\n", "text", ",", "dialog_metrics", "=", "run_dialog", "(", "params", ",", "\n", "dataset", ",", "\n", "split", ",", "\n", "aBot", ",", "\n", "qBot", ",", "\n", "beamSize", "=", "beamSize", ")", "\n", "\n", "dist_1", "=", "dialog_metrics", "[", "\"dist_1\"", "]", "\n", "dist_2", "=", "dialog_metrics", "[", "\"dist_2\"", "]", "\n", "dist_1_CI", "=", "dialog_metrics", "[", "\"dist_1_CI\"", "]", "\n", "dist_2_CI", "=", "dialog_metrics", "[", "\"dist_2_CI\"", "]", "\n", "\n", "average_precision_CI", "=", "dialog_metrics", "[", "\"average_precision_CI\"", "]", "\n", "ent_1_CI", "=", "dialog_metrics", "[", "\"ent_1_CI\"", "]", "\n", "ent_2_CI", "=", "dialog_metrics", "[", "\"ent_2_CI\"", "]", "\n", "unique_questions_CI", "=", "dialog_metrics", "[", "\"unique_questions_CI\"", "]", "\n", "mutual_overlap_CI", "=", "dialog_metrics", "[", "\"mutual_overlap_CI\"", "]", "\n", "\n", "unique_questions", "=", "dialog_metrics", "[", "\"tot_unique_questions\"", "]", "\n", "tot_examples", "=", "dialog_metrics", "[", "\"tot_examples\"", "]", "\n", "mean_unique_questions", "=", "dialog_metrics", "[", "\"mean_unique_questions\"", "]", "\n", "std_unique_questions", "=", "dialog_metrics", "[", "\"std_unique_questions\"", "]", "\n", "\n", "similarity_scores_mean", "=", "dialog_metrics", "[", "\"similarity_scores_mean\"", "]", "\n", "norm_difference_scores_mean", "=", "dialog_metrics", "[", "\"norm_difference_scores_mean\"", "]", "\n", "norm_scores_mean", "=", "dialog_metrics", "[", "\"norm_scores_mean\"", "]", "\n", "huber_scores_mean", "=", "dialog_metrics", "[", "\"huber_scores_mean\"", "]", "\n", "\n", "average_precision", "=", "dialog_metrics", "[", "\"average_precision\"", "]", "\n", "per_round_precision", "=", "dialog_metrics", "[", "\"per_round_precision\"", "]", "\n", "\n", "bleu_metric", "=", "dialog_metrics", "[", "\"mutual_overlap_score\"", "]", "\n", "novel_questions", "=", "dialog_metrics", "[", "\"tot_novel_questions\"", "]", "\n", "avg_novel_questions", "=", "dialog_metrics", "[", "\"avg_novel_questions\"", "]", "\n", "tot_questions", "=", "dialog_metrics", "[", "\"tot_questions\"", "]", "\n", "\n", "nll", "=", "dialog_metrics", "[", "'NLL'", "]", "\n", "\n", "ent_1", "=", "dialog_metrics", "[", "\"ent_1\"", "]", "\n", "ent_2", "=", "dialog_metrics", "[", "\"ent_2\"", "]", "\n", "\n", "savePathJson", "=", "os", ".", "path", ".", "join", "(", "saveFolder", ",", "\"results.json\"", ")", "\n", "saveMetricsFile", "=", "os", ".", "path", ".", "join", "(", "saveFolder", ",", "\"metrics.txt\"", ")", "\n", "saveLatexFile", "=", "os", ".", "path", ".", "join", "(", "saveFolder", ",", "\"latex.txt\"", ")", "\n", "\n", "with", "open", "(", "saveMetricsFile", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "fp", ".", "write", "(", "\"Metrics: \\n\"", ")", "\n", "\n", "", "with", "open", "(", "saveMetricsFile", ",", "\"w\"", ")", "as", "fp", ":", "\n", "\n", "        ", "print", "(", "\"Writing dialog metrics data to file: {}\"", ".", "format", "(", "saveMetricsFile", ")", ")", "\n", "\n", "fp", ".", "write", "(", "\"tot unique questions: %d\"", "%", "unique_questions", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"tot examples: %d\"", "%", "tot_examples", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"avg unique questions per example: %f\"", "%", "mean_unique_questions", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"std unique questions per example: %f\"", "%", "std_unique_questions", "+", "\"\\n\"", ")", "\n", "\n", "fp", ".", "write", "(", "\"Mutual Overlap: %f\"", "%", "bleu_metric", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Ent-1: %f\"", "%", "ent_1", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Ent-2: %f\"", "%", "ent_2", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Dist-1: %f\"", "%", "dist_1", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Dist-2: %f\"", "%", "dist_2", "+", "\"\\n\"", ")", "\n", "\n", "fp", ".", "write", "(", "\"novel questions: %d\"", "%", "novel_questions", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"avg novel questions: %f\"", "%", "avg_novel_questions", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"tot_questions: %d\"", "%", "tot_questions", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"average precision for questions: %f\"", "%", "average_precision", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"nll of GT questions: %f\"", "%", "nll", "+", "\"\\n\"", ")", "\n", "\n", "fp", ".", "write", "(", "\"Mutual Overlap CI: %f\"", "%", "mutual_overlap_CI", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Average Precision CI: %f\"", "%", "average_precision_CI", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Unique Question CI: %f\"", "%", "unique_questions_CI", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Ent-1-CI: %f\"", "%", "ent_1_CI", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Ent-2-CI: %f\"", "%", "ent_2_CI", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Dist-1-CI: %f\"", "%", "dist_1_CI", "+", "\"\\n\"", ")", "\n", "fp", ".", "write", "(", "\"Dist-2-CI: %f\"", "%", "dist_2_CI", "+", "\"\\n\"", ")", "\n", "\n", "\n", "fp", ".", "write", "(", "\"cos similarity between consecutive rounds \\n\"", ")", "\n", "fp", ".", "write", "(", "\",\"", ".", "join", "(", "map", "(", "str", ",", "similarity_scores_mean", ")", ")", "+", "\"\\n\"", ")", "\n", "\n", "fp", ".", "write", "(", "\"difference of norms between consecutive rounds \\n\"", ")", "\n", "fp", ".", "write", "(", "\",\"", ".", "join", "(", "map", "(", "str", ",", "norm_difference_scores_mean", ")", ")", "+", "\"\\n\"", ")", "\n", "\n", "fp", ".", "write", "(", "\"mean norm at each round \\n\"", ")", "\n", "fp", ".", "write", "(", "\",\"", ".", "join", "(", "map", "(", "str", ",", "norm_scores_mean", ")", ")", "+", "\"\\n\"", ")", "\n", "\n", "fp", ".", "write", "(", "\"huber loss between consecutive rounds \\n\"", ")", "\n", "fp", ".", "write", "(", "\",\"", ".", "join", "(", "map", "(", "str", ",", "huber_scores_mean", ")", ")", "+", "\"\\n\"", ")", "\n", "\n", "fp", ".", "write", "(", "\"round to round precision for questions \\n\"", ")", "\n", "fp", ".", "write", "(", "\",\"", ".", "join", "(", "map", "(", "str", ",", "per_round_precision", ")", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "savePathJson", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "print", "(", "\"Writing dialog text data to file: {}\"", ".", "format", "(", "savePathJson", ")", ")", "\n", "json", ".", "dump", "(", "text", ",", "fp", ")", "\n", "\n", "# with open(saveMetricsJson, \"w\") as fp:", "\n", "#     print(\"Writing dialog metrics to file: {}\".format(saveMetricsJson))", "\n", "#     json.dump(dialog_metrics, fp)", "\n", "\n", "# write latex string", "\n", "", "latex_code", "=", "\" $ \"", "+", "str", "(", "round", "(", "novel_questions", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" & \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "mean_unique_questions", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" \\pm \"", "+", "str", "(", "round", "(", "unique_questions_CI", ",", "2", ")", ")", "+", "\" $ \\pm $ \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "bleu_metric", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" $ \\pm $ \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "mutual_overlap_CI", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" & \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "ent_1", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" $\\pm$ \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "ent_1_CI", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" & \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "ent_2", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" $\\pm$ \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "ent_2_CI", ",", "2", ")", ")", "+", "\" $ \"", "+", "\"& $\"", "+", "str", "(", "round", "(", "dist_1", ",", "2", ")", ")", "+", "\" $ &\"", "+", "\"$ \\pm $\"", "+", "\"& $\"", "+", "str", "(", "round", "(", "dist_1_CI", ",", "2", ")", ")", "+", "\" $ \"", "+", "\"& $\"", "+", "str", "(", "round", "(", "dist_2", ",", "2", ")", ")", "+", "\" $ &\"", "+", "\"$ \\pm $\"", "+", "\"& $\"", "+", "str", "(", "round", "(", "dist_2_CI", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" && \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "nll", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" & \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "average_precision", ",", "2", ")", ")", "+", "\" $ \"", "+", "\" $ \\pm$ \"", "+", "\" $ \"", "+", "str", "(", "round", "(", "average_precision_CI", ",", "2", ")", ")", "+", "\" $ \"", "\n", "\n", "with", "open", "(", "saveLatexFile", ",", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "print", "(", "\"Writing latex code to file: {}\"", ".", "format", "(", "saveLatexFile", ")", ")", "\n", "fp", ".", "write", "(", "latex_code", ")", "\n", "\n", "", "print", "(", "\"Done!\"", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "similarity_scores_mean", ",", "label", "=", "'Cos'", ")", "\n", "plt", ".", "plot", "(", "norm_difference_scores_mean", ",", "label", "=", "'Norm Penalty'", ")", "\n", "plt", ".", "plot", "(", "huber_scores_mean", ",", "label", "=", "'Huber'", ")", "\n", "plt", ".", "title", "(", "'Similarity of consecutive embeddings'", ")", "\n", "plt", ".", "ylabel", "(", "'Similarity'", ")", "\n", "plt", ".", "xlabel", "(", "\"Round\"", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "fig", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "saveFolder", ",", "'Similarity_Metrics_Plot.png'", ")", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "norm_scores_mean", ")", "\n", "plt", ".", "title", "(", "'Norm vs Round'", ")", "\n", "plt", ".", "ylabel", "(", "'Norm'", ")", "\n", "plt", ".", "xlabel", "(", "\"Round\"", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "fig", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "saveFolder", ",", "'norms.png'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.dialog_generate.run_dialog": [[180, 561], ["eval_utils.rank_questioner.rankQBot", "set", "torch.utils.data.DataLoader", "enumerate", "print", "torch.utils.data.DataLoader", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "numpy.zeros", "enumerate", "print", "print", "print", "print", "numpy.array", "similarity_scores_mean.cuda.cpu().data.numpy().tolist", "norm_difference_scores_mean.cuda.cpu().data.numpy().tolist", "norm_scores_mean.cuda.cpu().data.numpy().tolist", "huber_scores_mean.cuda.cpu().data.numpy().tolist", "float", "float", "float", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.mean", "np.zeros.tolist", "numpy.mean", "numpy.mean", "str", "str", "torch.autograd.Variable", "torch.autograd.Variable", "six.moves.range", "len", "dataset.data.keys", "print", "print", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "similarity_scores_mean.cuda.cuda", "norm_difference_scores_mean.cuda.cuda", "norm_scores_mean.cuda.cuda", "huber_scores_mean.cuda.cuda", "print", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "six.moves.range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "six.moves.range", "numpy.zeros", "six.moves.range", "numpy.sum", "avg_precision_list.extend", "float", "float", "int", "int", "float", "float", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "six.moves.range", "getImgId", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "aBot.observe", "qBot.observe", "torch.CosineSimilarity", "nn.CosineSimilarity.", "torch.abs", "torch.abs", "torch.norm", "torch.norm", "torch.abs", "torch.abs", "torch.sum", "torch.sum", "six.moves.range", "six.moves.range", "float", "mutual_overlap_list.append", "len", "collections.Counter", "collections.Counter", "dialog_generate.get_entropy_ctr", "ent_1_list.append", "dialog_generate.get_entropy_ctr", "ent_2_list.append", "dist_1_list.append", "dist_2_list.append", "len", "unique_questions_list.append", "text[].extend", "numpy.mean().tolist", "similarity_scores_mean.cuda.cpu().data.numpy", "norm_difference_scores_mean.cuda.cpu().data.numpy", "norm_scores_mean.cuda.cpu().data.numpy", "huber_scores_mean.cuda.cpu().data.numpy", "float", "numpy.std", "float", "float", "float", "numpy.std", "len", "numpy.std", "len", "numpy.std", "len", "numpy.std", "len", "numpy.std", "len", "numpy.std", "len", "numpy.std", "len", "to_str_pred", "set.add", "torch.autograd.Variable.size", "aBot.eval", "aBot.reset", "qBot.eval", "qBot.reset", "to_str_gt", "six.moves.range", "six.moves.range", "aBot.observe", "aBot.observe", "aBot.forward", "aBot.forwardDecode", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "to_str_pred", "gt_questions_str[].append", "question_str_list[].append", "to_str_pred", "six.moves.range", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "unigrams.extend", "bigrams.extend", "len", "float", "len", "float", "set", "float", "getImgFileName", "hasattr", "v.cuda", "batch.items", "qBot.forwardDecode", "qBot.observe", "aBot.observe", "aBot.forwardDecode", "aBot.observe", "qBot.observe", "qBot.encoder", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "to_str_pred", "to_str_gt", "nltk.word_tokenize", "nltk.word_tokenize", "list", "list", "collections.Counter.keys", "collections.Counter.keys", "numpy.mean", "float", "numpy.std", "filter", "float", "[].append", "float", "float", "float", "float", "[].append", "references.append", "nltk.word_tokenize", "nltk.util.ngrams", "nltk.util.ngrams", "similarity_scores_mean.cuda.cpu", "norm_difference_scores_mean.cuda.cpu", "norm_scores_mean.cuda.cpu", "huber_scores_mean.cuda.cpu", "w.data.cpu().numpy", "list", "l.data.cpu", "nltk.word_tokenize", "nltk.word_tokenize", "nltk.word_tokenize", "filter", "w.data.cpu", "w.data.cpu().numpy", "w.data.cpu"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.rank_questioner.rankQBot", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.dialog_generate.get_entropy_ctr", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.dialog_generate.get_entropy_ctr", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.forward", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe"], ["", "def", "run_dialog", "(", "params", ",", "\n", "dataset", ",", "\n", "split", ",", "\n", "aBot", ",", "\n", "qBot", "=", "None", ",", "\n", "beamSize", "=", "1", ")", ":", "\n", "\n", "    ", "assert", "aBot", "is", "not", "None", "or", "(", "qBot", "is", "not", "None", "and", "aBot", "is", "not", "None", ")", ",", "\"Must provide either an A-Bot alone or both \\\n                            Q-Bot and A-Bot when generating dialog\"", "\n", "rankMetrics", ",", "_", "=", "rankQBot", "(", "qBot", ",", "dataset", ",", "'val'", ")", "\n", "\n", "old_split", "=", "dataset", ".", "split", "\n", "batchSize", "=", "dataset", ".", "batchSize", "\n", "numRounds", "=", "dataset", ".", "numRounds", "\n", "train_questions", "=", "set", "(", ")", "\n", "\n", "dataset", ".", "split", "=", "'train'", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batchSize", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "\n", "ind2word", "=", "dataset", ".", "ind2word", "\n", "to_str_gt", "=", "lambda", "w", ":", "str", "(", "\" \"", ".", "join", "(", "[", "ind2word", "[", "x", "]", "for", "x", "in", "filter", "(", "lambda", "x", ":", "x", ">", "0", ",", "w", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "]", ")", ")", "#.encode('utf-8','ignore')", "\n", "to_str_pred", "=", "lambda", "w", ",", "l", ":", "str", "(", "\" \"", ".", "join", "(", "[", "ind2word", "[", "x", "]", "for", "x", "in", "list", "(", "filter", "(", "\n", "lambda", "x", ":", "x", ">", "0", ",", "w", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "]", "[", ":", "l", ".", "data", ".", "cpu", "(", ")", "[", "0", "]", "]", ")", ")", "#.encode('utf-8','ignore')", "\n", "\n", "for", "idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# append all questions in train in a set to calculate downstream metrics", "\n", "        ", "gtQuestions", "=", "Variable", "(", "batch", "[", "'ques'", "]", ",", "requires_grad", "=", "False", ")", "\n", "gtQuesLens", "=", "Variable", "(", "batch", "[", "'ques_len'", "]", ",", "requires_grad", "=", "False", ")", "\n", "if", "gtQuesLens", ".", "shape", "[", "0", "]", "<", "batchSize", ":", "\n", "            ", "break", "\n", "\n", "# iterate through the batch and add to dictionary", "\n", "", "for", "j", "in", "range", "(", "batchSize", ")", ":", "\n", "            ", "for", "rnd", "in", "range", "(", "numRounds", ")", ":", "\n", "                ", "question_str", "=", "to_str_pred", "(", "gtQuestions", "[", "j", ",", "rnd", ",", ":", "]", ",", "gtQuesLens", "[", "j", ",", "rnd", "]", ")", "\n", "train_questions", ".", "add", "(", "question_str", "[", "8", ":", "]", ")", "\n", "\n", "", "", "", "print", "(", "\"train questions len:\"", ",", "len", "(", "train_questions", ")", ")", "\n", "\n", "dataset", ".", "split", "=", "split", "\n", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batchSize", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "\n", "text", "=", "{", "'data'", ":", "[", "]", "}", "\n", "if", "'%s_img_fnames'", "%", "split", "not", "in", "dataset", ".", "data", ".", "keys", "(", ")", ":", "\n", "        ", "print", "(", "\"[Error] Need coco directory and info as input \"", "\"to -cocoDir and -cocoInfo arguments for locating \"", "\"coco image files.\"", ")", "\n", "print", "(", "\"Exiting dialogDump without saving files.\"", ")", "\n", "return", "None", "\n", "\n", "", "getImgFileName", "=", "lambda", "x", ":", "dataset", ".", "data", "[", "'%s_img_fnames'", "%", "split", "]", "[", "x", "]", "\n", "getImgId", "=", "lambda", "x", ":", "int", "(", "getImgFileName", "(", "x", ")", "[", ":", "-", "4", "]", "[", "-", "12", ":", "]", ")", "\n", "\n", "similarity_scores_mean", "=", "Variable", "(", "torch", ".", "zeros", "(", "numRounds", ")", ")", "\n", "norm_difference_scores_mean", "=", "Variable", "(", "torch", ".", "zeros", "(", "numRounds", ")", ")", "\n", "norm_scores_mean", "=", "Variable", "(", "torch", ".", "zeros", "(", "numRounds", ")", ")", "\n", "huber_scores_mean", "=", "Variable", "(", "torch", ".", "zeros", "(", "numRounds", ")", ")", "\n", "\n", "if", "params", "[", "\"useGPU\"", "]", ":", "\n", "\n", "        ", "similarity_scores_mean", "=", "similarity_scores_mean", ".", "cuda", "(", ")", "\n", "norm_difference_scores_mean", "=", "norm_difference_scores_mean", ".", "cuda", "(", ")", "\n", "norm_scores_mean", "=", "norm_scores_mean", ".", "cuda", "(", ")", "\n", "huber_scores_mean", "=", "huber_scores_mean", ".", "cuda", "(", ")", "\n", "\n", "", "tot_idx", "=", "0", "\n", "output_dialog", "=", "True", "\n", "tot_examples", "=", "0", "\n", "unique_questions", "=", "0", "\n", "unique_questions_list", "=", "[", "]", "\n", "mutual_overlap_list", "=", "[", "]", "\n", "ent_1_list", "=", "[", "]", "\n", "ent_2_list", "=", "[", "]", "\n", "dist_1_list", "=", "[", "]", "\n", "dist_2_list", "=", "[", "]", "\n", "avg_precision_list", "=", "[", "]", "\n", "\n", "bleu_metric", "=", "0", "\n", "novel_questions", "=", "0", "\n", "oscillating_questions_cnt", "=", "0", "\n", "per_round_bleu", "=", "np", ".", "zeros", "(", "numRounds", ")", "\n", "ent_1", "=", "0", "\n", "ent_2", "=", "0", "\n", "\n", "for", "idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "print", "(", "\"current batch:\"", ",", "idx", ")", "\n", "if", "idx", ">", "3", ":", "\n", "            ", "output_dialog", "=", "False", "\n", "", "tot_idx", "=", "tot_idx", "+", "1", "\n", "imgIds", "=", "[", "getImgId", "(", "x", ")", "for", "x", "in", "batch", "[", "'index'", "]", "]", "\n", "dialog", "=", "[", "{", "'dialog'", ":", "[", "]", ",", "'image_id'", ":", "imgId", "}", "for", "imgId", "in", "imgIds", "]", "\n", "\n", "if", "dataset", ".", "useGPU", ":", "\n", "            ", "batch", "=", "{", "key", ":", "v", ".", "cuda", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "else", "v", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "\n", "", "image", "=", "Variable", "(", "batch", "[", "'img_feat'", "]", ",", "volatile", "=", "True", ")", "\n", "caption", "=", "Variable", "(", "batch", "[", "'cap'", "]", ",", "volatile", "=", "True", ")", "\n", "# ignoring the last batch", "\n", "if", "caption", ".", "size", "(", ")", "[", "0", "]", "<", "batchSize", ":", "\n", "            ", "break", "\n", "", "captionLens", "=", "Variable", "(", "batch", "[", "'cap_len'", "]", ",", "volatile", "=", "True", ")", "\n", "if", "qBot", "is", "None", ":", "# A-Bot alone needs ground truth dialog", "\n", "            ", "gtQuestions", "=", "Variable", "(", "batch", "[", "'ques'", "]", ",", "volatile", "=", "True", ")", "\n", "gtQuesLens", "=", "Variable", "(", "batch", "[", "'ques_len'", "]", ",", "volatile", "=", "True", ")", "\n", "gtAnswers", "=", "Variable", "(", "batch", "[", "'ans'", "]", ",", "volatile", "=", "True", ")", "\n", "gtAnsLens", "=", "Variable", "(", "batch", "[", "'ans_len'", "]", ",", "volatile", "=", "True", ")", "\n", "\n", "", "if", "aBot", ":", "\n", "            ", "aBot", ".", "eval", "(", ")", ",", "aBot", ".", "reset", "(", ")", "\n", "aBot", ".", "observe", "(", "\n", "-", "1", ",", "image", "=", "image", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "", "if", "qBot", ":", "\n", "            ", "qBot", ".", "eval", "(", ")", ",", "qBot", ".", "reset", "(", ")", "\n", "qBot", ".", "observe", "(", "-", "1", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "", "questions", "=", "[", "]", "\n", "\n", "for", "j", "in", "range", "(", "batchSize", ")", ":", "\n", "            ", "caption_str", "=", "to_str_gt", "(", "caption", "[", "j", "]", ")", "[", "8", ":", "-", "6", "]", "\n", "dialog", "[", "j", "]", "[", "'caption'", "]", "=", "caption_str", "\n", "", "past_dialog_hidden", "=", "None", "\n", "cur_dialog_hidden", "=", "None", "\n", "question_str_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batchSize", ")", "]", "\n", "gt_questions_str", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batchSize", ")", "]", "\n", "\n", "gtQuestions", "=", "Variable", "(", "batch", "[", "'ques'", "]", ",", "volatile", "=", "True", ")", "\n", "gtQuesLens", "=", "Variable", "(", "batch", "[", "'ques_len'", "]", ",", "volatile", "=", "True", ")", "\n", "gtAnswers", "=", "Variable", "(", "batch", "[", "'ans'", "]", ",", "volatile", "=", "True", ")", "\n", "gtAnsLens", "=", "Variable", "(", "batch", "[", "'ans_len'", "]", ",", "volatile", "=", "True", ")", "\n", "\n", "for", "round", "in", "range", "(", "numRounds", ")", ":", "\n", "\n", "            ", "if", "aBot", "is", "not", "None", "and", "qBot", "is", "None", ":", "\n", "                ", "aBot", ".", "observe", "(", "\n", "round", ",", "\n", "ques", "=", "gtQuestions", "[", ":", ",", "round", "]", ",", "\n", "quesLens", "=", "gtQuesLens", "[", ":", ",", "round", "]", ")", "\n", "aBot", ".", "observe", "(", "\n", "round", ",", "\n", "ans", "=", "gtAnswers", "[", ":", ",", "round", "]", ",", "\n", "ansLens", "=", "gtAnsLens", "[", ":", ",", "round", "]", ")", "\n", "_", "=", "aBot", ".", "forward", "(", ")", "\n", "answers", ",", "ansLens", "=", "aBot", ".", "forwardDecode", "(", "\n", "inference", "=", "'greedy'", ",", "beamSize", "=", "beamSize", ")", "\n", "\n", "", "elif", "aBot", "is", "not", "None", "and", "qBot", "is", "not", "None", ":", "\n", "                ", "questions", ",", "quesLens", "=", "qBot", ".", "forwardDecode", "(", "\n", "beamSize", "=", "beamSize", ",", "inference", "=", "'greedy'", ")", "\n", "qBot", ".", "observe", "(", "round", ",", "ques", "=", "questions", ",", "quesLens", "=", "quesLens", ")", "\n", "aBot", ".", "observe", "(", "round", ",", "ques", "=", "questions", ",", "quesLens", "=", "quesLens", ")", "\n", "answers", ",", "ansLens", "=", "aBot", ".", "forwardDecode", "(", "\n", "beamSize", "=", "beamSize", ",", "inference", "=", "'greedy'", ")", "\n", "aBot", ".", "observe", "(", "round", ",", "ans", "=", "answers", ",", "ansLens", "=", "ansLens", ")", "\n", "qBot", ".", "observe", "(", "round", ",", "ans", "=", "answers", ",", "ansLens", "=", "ansLens", ")", "\n", "qBot", ".", "encoder", "(", ")", "\n", "\n", "", "cur_dialog_hidden", "=", "qBot", ".", "encoder", ".", "dialogHiddens", "[", "-", "1", "]", "[", "0", "]", "\n", "if", "round", "==", "0", ":", "\n", "                ", "past_dialog_hidden", "=", "qBot", ".", "encoder", ".", "dialogHiddens", "[", "-", "1", "]", "[", "0", "]", "\n", "", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "1", ",", "eps", "=", "1e-6", ")", "\n", "similarity_scores", "=", "cos", "(", "cur_dialog_hidden", ",", "past_dialog_hidden", ")", "\n", "norm_difference_scores", "=", "torch", ".", "abs", "(", "torch", ".", "norm", "(", "cur_dialog_hidden", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "-", "torch", ".", "norm", "(", "past_dialog_hidden", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ")", "\n", "# calculate norm", "\n", "norm_scores", "=", "torch", ".", "norm", "(", "cur_dialog_hidden", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "# calculate Huber Loss/ Difference at consecutive rounds with Huber Threshold = 0.1", "\n", "threshold", "=", "0.1", "\n", "norm_differences", "=", "torch", ".", "abs", "(", "cur_dialog_hidden", "-", "past_dialog_hidden", ")", "\n", "l2_mask", "=", "norm_differences", "<=", "threshold", "\n", "norm_differences_new", "=", "0.5", "*", "norm_differences", "*", "norm_differences", "*", "(", "l2_mask", "==", "1", ")", ".", "float", "(", ")", "\n", "l1_mask", "=", "norm_differences", ">", "threshold", "\n", "norm_differences_new", "=", "norm_differences_new", "+", "(", "(", "(", "l1_mask", "==", "1", ")", ".", "float", "(", ")", ")", "*", "(", "threshold", "*", "\n", "(", "norm_differences", "-", "(", "0.5", "*", "threshold", ")", ")", ")", ")", "\n", "\n", "huber_scores", "=", "torch", ".", "sum", "(", "norm_differences_new", ",", "dim", "=", "1", ")", "\n", "\n", "past_dialog_hidden", "=", "cur_dialog_hidden", "\n", "similarity_scores_mean", "[", "round", "]", "=", "similarity_scores_mean", "[", "round", "]", "+", "torch", ".", "mean", "(", "similarity_scores", ")", "\n", "\n", "norm_difference_scores_mean", "[", "round", "]", "=", "norm_difference_scores_mean", "[", "round", "]", "+", "torch", ".", "mean", "(", "norm_difference_scores", ")", "\n", "norm_scores_mean", "[", "round", "]", "=", "norm_scores_mean", "[", "round", "]", "+", "torch", ".", "mean", "(", "norm_scores", ")", "\n", "huber_scores_mean", "[", "round", "]", "=", "huber_scores_mean", "[", "round", "]", "+", "torch", ".", "mean", "(", "huber_scores", ")", "\n", "\n", "for", "j", "in", "range", "(", "batchSize", ")", ":", "\n", "                ", "question_str", "=", "to_str_pred", "(", "questions", "[", "j", "]", ",", "quesLens", "[", "j", "]", ")", "if", "qBot", "is", "not", "None", "else", "to_str_gt", "(", "gtQuestions", "[", "j", "]", ")", "\n", "\n", "gt_question_str", "=", "to_str_pred", "(", "gtQuestions", "[", "j", ",", "round", ",", ":", "]", ",", "gtQuesLens", "[", "j", ",", "round", "]", ")", "\n", "\n", "gt_questions_str", "[", "j", "]", ".", "append", "(", "gt_question_str", "[", "8", ":", "]", ")", "\n", "\n", "question_str_list", "[", "j", "]", ".", "append", "(", "question_str", "[", "8", ":", "]", ")", "\n", "answer_str", "=", "to_str_pred", "(", "answers", "[", "j", "]", ",", "ansLens", "[", "j", "]", ")", "\n", "if", "output_dialog", ":", "\n", "                    ", "if", "round", "==", "0", ":", "\n", "                        ", "norm_score", "=", "float", "(", "norm_scores", "[", "j", "]", ")", "\n", "dialog", "[", "j", "]", "[", "'dialog'", "]", ".", "append", "(", "{", "\n", "\"answer\"", ":", "answer_str", "[", "8", ":", "]", ",", "\n", "\"question\"", ":", "question_str", "[", "8", ":", "]", "+", "\":\"", "+", "\"N:%.2f\"", "%", "norm_score", "+", "\" \"", "\n", "}", ")", "# \"8:\" for indexing out initial <START>", "\n", "", "else", ":", "\n", "                        ", "similarity_score", "=", "float", "(", "similarity_scores", "[", "j", "]", ")", "\n", "norm_difference_score", "=", "float", "(", "norm_difference_scores", "[", "j", "]", ")", "\n", "norm_score", "=", "float", "(", "norm_scores", "[", "j", "]", ")", "\n", "huber_score", "=", "float", "(", "huber_scores", "[", "j", "]", ")", "\n", "dialog", "[", "j", "]", "[", "'dialog'", "]", ".", "append", "(", "{", "\n", "\"answer\"", ":", "answer_str", "[", "8", ":", "]", ",", "\n", "\"question\"", ":", "question_str", "[", "8", ":", "]", "+", "\":\"", "+", "\"C:%.2f\"", "%", "similarity_score", "+", "\";\"", "+", "\n", "\"NP:%.2f\"", "%", "norm_difference_score", "+", "\"H:%.2f\"", "%", "huber_score", "+", "\";\"", "+", "\n", "\"N:%.2f\"", "%", "norm_score", "+", "\" \"", "\n", "}", ")", "# \"8:\" for indexing out initial <START>", "\n", "", "", "", "", "per_round_bleu_batch", "=", "np", ".", "zeros", "(", "(", "numRounds", ",", "batchSize", ")", ")", "\n", "for", "j", "in", "range", "(", "batchSize", ")", ":", "\n", "# calculate bleu scores for each question str, with other questions as references to calculate", "\n", "# mutual overlap", "\n", "# also calculate round by round bleu score", "\n", "            ", "unigrams", "=", "[", "]", "\n", "bigrams", "=", "[", "]", "\n", "avg_bleu_score", "=", "0", "\n", "for", "rnd", "in", "range", "(", "numRounds", ")", ":", "\n", "# Novel sentences metric", "\n", "                ", "cur_ques", "=", "question_str_list", "[", "j", "]", "[", "rnd", "]", "\n", "gt_ques", "=", "gt_questions_str", "[", "j", "]", "[", "rnd", "]", "\n", "if", "cur_ques", "not", "in", "train_questions", ":", "\n", "                    ", "novel_questions", "+=", "1", "\n", "\n", "# question oscillation metrics", "\n", "", "if", "rnd", ">=", "2", ":", "\n", "                    ", "if", "cur_ques", "==", "question_str_list", "[", "j", "]", "[", "rnd", "-", "2", "]", ":", "\n", "                        ", "oscillating_questions_cnt", "+=", "1", "\n", "\n", "# bleu/mutual overlap metric", "\n", "", "", "references", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "numRounds", ")", ":", "\n", "                    ", "if", "rnd", "!=", "k", ":", "\n", "                        ", "references", ".", "append", "(", "nltk", ".", "word_tokenize", "(", "question_str_list", "[", "j", "]", "[", "k", "]", ")", ")", "\n", "\n", "", "", "avg_bleu_score", "+=", "sentence_bleu", "(", "references", ",", "nltk", ".", "word_tokenize", "(", "cur_ques", ")", ")", "\n", "per_round_bleu_batch", "[", "rnd", "]", "[", "j", "]", "=", "sentence_bleu", "(", "[", "nltk", ".", "word_tokenize", "(", "gt_ques", ")", "]", ",", "\n", "nltk", ".", "word_tokenize", "(", "cur_ques", ")", ")", "\n", "unigrams", ".", "extend", "(", "list", "(", "ngrams", "(", "nltk", ".", "word_tokenize", "(", "cur_ques", ")", ",", "1", ")", ")", ")", "\n", "bigrams", ".", "extend", "(", "list", "(", "ngrams", "(", "nltk", ".", "word_tokenize", "(", "cur_ques", ")", ",", "2", ")", ")", ")", "\n", "\n", "", "avg_bleu_score", "/=", "float", "(", "numRounds", ")", "\n", "mutual_overlap_list", ".", "append", "(", "avg_bleu_score", ")", "\n", "bleu_metric", "+=", "avg_bleu_score", "\n", "tot_tokens", "=", "len", "(", "unigrams", ")", "\n", "\n", "unigram_ctr", "=", "Counter", "(", "unigrams", ")", "\n", "bigram_ctr", "=", "Counter", "(", "bigrams", ")", "\n", "cur_ent_1", "=", "get_entropy_ctr", "(", "unigram_ctr", ")", "\n", "ent_1", "+=", "cur_ent_1", "\n", "ent_1_list", ".", "append", "(", "cur_ent_1", ")", "\n", "cur_ent_2", "=", "get_entropy_ctr", "(", "bigram_ctr", ")", "\n", "ent_2", "+=", "cur_ent_2", "\n", "ent_2_list", ".", "append", "(", "cur_ent_2", ")", "\n", "\n", "dist_1", "=", "len", "(", "unigram_ctr", ".", "keys", "(", ")", ")", "/", "float", "(", "tot_tokens", ")", "\n", "dist_2", "=", "len", "(", "bigram_ctr", ".", "keys", "(", ")", ")", "/", "float", "(", "tot_tokens", ")", "\n", "\n", "dist_1_list", ".", "append", "(", "dist_1", ")", "\n", "dist_2_list", ".", "append", "(", "dist_2", ")", "\n", "\n", "cur_unique_ques", "=", "len", "(", "set", "(", "question_str_list", "[", "j", "]", ")", ")", "\n", "unique_questions", "+=", "cur_unique_ques", "\n", "unique_questions_list", ".", "append", "(", "cur_unique_ques", ")", "\n", "# dialog[j]['caption'] += ':' + str(cur_unique_ques)", "\n", "\n", "", "tot_examples", "+=", "batchSize", "\n", "\n", "if", "output_dialog", ":", "\n", "            ", "text", "[", "'data'", "]", ".", "extend", "(", "dialog", ")", "\n", "\n", "", "per_round_bleu", "+=", "np", ".", "sum", "(", "per_round_bleu_batch", ",", "axis", "=", "1", ")", "\n", "avg_precision_list", ".", "extend", "(", "np", ".", "mean", "(", "per_round_bleu_batch", ",", "axis", "=", "0", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "similarity_scores_mean", "=", "similarity_scores_mean", "*", "(", "1.0", "/", "tot_idx", ")", "\n", "norm_difference_scores_mean", "=", "norm_difference_scores_mean", "*", "(", "1.0", "/", "tot_idx", ")", "\n", "norm_scores_mean", "=", "norm_scores_mean", "*", "(", "1.0", "/", "tot_idx", ")", "\n", "huber_scores_mean", "=", "huber_scores_mean", "*", "(", "1.0", "/", "tot_idx", ")", "\n", "\n", "print", "(", "\"Mean Cos Similarity Scores:\"", ",", "similarity_scores_mean", ")", "\n", "print", "(", "\"Mean Difference of Norms Scores:\"", ",", "norm_difference_scores_mean", ")", "\n", "print", "(", "\"Mean Norm of Dialog State:\"", ",", "norm_scores_mean", ")", "\n", "print", "(", "\"Mean Huber Loss(Norm of differences):\"", ",", "huber_scores_mean", ")", "\n", "\n", "text", "[", "'opts'", "]", "=", "{", "\n", "'qbot'", ":", "params", "[", "'qstartFrom'", "]", ",", "\n", "'abot'", ":", "params", "[", "'startFrom'", "]", ",", "\n", "'backend'", ":", "'cudnn'", ",", "\n", "'beamLen'", ":", "20", ",", "\n", "'beamSize'", ":", "beamSize", ",", "\n", "'decoder'", ":", "params", "[", "'decoder'", "]", ",", "\n", "'encoder'", ":", "params", "[", "'encoder'", "]", ",", "\n", "'gpuid'", ":", "0", ",", "\n", "'imgNorm'", ":", "params", "[", "'imgNorm'", "]", ",", "\n", "'inputImg'", ":", "params", "[", "'inputImg'", "]", ",", "\n", "'inputJson'", ":", "params", "[", "'inputJson'", "]", ",", "\n", "'inputQues'", ":", "params", "[", "'inputQues'", "]", ",", "\n", "'loadPath'", ":", "'checkpoints/'", ",", "\n", "'maxThreads'", ":", "1", ",", "\n", "'resultPath'", ":", "'dialog_output/results'", ",", "\n", "'sampleWords'", ":", "0", ",", "\n", "'temperature'", ":", "1", ",", "\n", "'useHistory'", ":", "True", ",", "\n", "'useIm'", ":", "True", ",", "\n", "}", "\n", "unique_questions_arr", "=", "np", ".", "array", "(", "unique_questions_list", ")", "\n", "\n", "# converting metrics to numpy arrays", "\n", "similarity_scores_mean", "=", "similarity_scores_mean", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "norm_difference_scores_mean", "=", "norm_difference_scores_mean", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "norm_scores_mean", "=", "norm_scores_mean", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "huber_scores_mean", "=", "huber_scores_mean", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "bleu_metric", "/=", "float", "(", "tot_examples", ")", "\n", "ent_1", "/=", "float", "(", "tot_examples", ")", "\n", "ent_2", "/=", "float", "(", "tot_examples", ")", "\n", "per_round_bleu", "=", "per_round_bleu", "/", "float", "(", "tot_examples", ")", "\n", "\n", "print", "(", "\"tot unique questions: \"", ",", "unique_questions", ")", "\n", "print", "(", "\"tot examples: \"", ",", "tot_examples", ")", "\n", "print", "(", "\"avg unique questions per example: \"", ",", "float", "(", "unique_questions", ")", "/", "tot_examples", ")", "\n", "print", "(", "\"std unique questions per example: \"", ",", "float", "(", "np", ".", "std", "(", "unique_questions_arr", ")", ")", ")", "\n", "print", "(", "\"Mutual Overlap (Bleu Metric): \"", ",", "bleu_metric", ")", "\n", "print", "(", "\"tot novel questions: \"", ",", "novel_questions", ")", "\n", "tot_questions", "=", "tot_examples", "*", "numRounds", "\n", "print", "(", "\"tot questions: \"", ",", "tot_questions", ")", "\n", "print", "(", "\"avg novel questions: \"", ",", "float", "(", "novel_questions", ")", "/", "float", "(", "tot_questions", ")", ")", "\n", "\n", "print", "(", "\"avg oscillating questions count\"", ",", "float", "(", "oscillating_questions_cnt", ")", "/", "tot_questions", ")", "\n", "print", "(", "\"osciallation questions count\"", ",", "oscillating_questions_cnt", ")", "\n", "\n", "dataset", ".", "split", "=", "old_split", "\n", "\n", "ret_metrics", "=", "{", "}", "\n", "ret_metrics", "[", "\"tot_unique_questions\"", "]", "=", "unique_questions", "\n", "ret_metrics", "[", "\"tot_examples\"", "]", "=", "tot_examples", "\n", "ret_metrics", "[", "\"mean_unique_questions\"", "]", "=", "int", "(", "(", "float", "(", "unique_questions", ")", "/", "tot_examples", ")", "*", "100", ")", "/", "100.0", "\n", "ret_metrics", "[", "\"std_unique_questions\"", "]", "=", "int", "(", "float", "(", "np", ".", "std", "(", "unique_questions_arr", ")", ")", "*", "100", ")", "/", "100.0", "\n", "\n", "ret_metrics", "[", "\"similarity_scores_mean\"", "]", "=", "similarity_scores_mean", "\n", "ret_metrics", "[", "\"norm_difference_scores_mean\"", "]", "=", "norm_difference_scores_mean", "\n", "ret_metrics", "[", "\"norm_scores_mean\"", "]", "=", "norm_scores_mean", "\n", "ret_metrics", "[", "\"huber_scores_mean\"", "]", "=", "huber_scores_mean", "\n", "\n", "ret_metrics", "[", "\"mutual_overlap_score\"", "]", "=", "bleu_metric", "\n", "ret_metrics", "[", "\"tot_novel_questions\"", "]", "=", "novel_questions", "\n", "ret_metrics", "[", "\"avg_novel_questions\"", "]", "=", "float", "(", "novel_questions", ")", "/", "float", "(", "tot_questions", ")", "\n", "ret_metrics", "[", "\"tot_questions\"", "]", "=", "tot_questions", "\n", "ret_metrics", "[", "'NLL'", "]", "=", "rankMetrics", "[", "'logProbsMean'", "]", "\n", "\n", "ret_metrics", "[", "\"average_precision\"", "]", "=", "np", ".", "mean", "(", "per_round_bleu", ")", "\n", "ret_metrics", "[", "\"per_round_precision\"", "]", "=", "per_round_bleu", ".", "tolist", "(", ")", "\n", "ret_metrics", "[", "\"ent_1\"", "]", "=", "ent_1", "\n", "ret_metrics", "[", "\"ent_2\"", "]", "=", "ent_2", "\n", "ret_metrics", "[", "\"dist_1\"", "]", "=", "np", ".", "mean", "(", "dist_1_list", ")", "\n", "ret_metrics", "[", "\"dist_2\"", "]", "=", "np", ".", "mean", "(", "dist_2_list", ")", "\n", "\n", "ret_metrics", "[", "\"average_precision_CI\"", "]", "=", "(", "1.96", "*", "np", ".", "std", "(", "avg_precision_list", ")", ")", "/", "math", ".", "sqrt", "(", "len", "(", "avg_precision_list", ")", ")", "\n", "ret_metrics", "[", "\"ent_1_CI\"", "]", "=", "(", "1.96", "*", "np", ".", "std", "(", "ent_1_list", ")", ")", "/", "math", ".", "sqrt", "(", "len", "(", "ent_1_list", ")", ")", "\n", "ret_metrics", "[", "\"ent_2_CI\"", "]", "=", "(", "1.96", "*", "np", ".", "std", "(", "ent_2_list", ")", ")", "/", "math", ".", "sqrt", "(", "len", "(", "ent_2_list", ")", ")", "\n", "ret_metrics", "[", "\"unique_questions_CI\"", "]", "=", "(", "1.96", "*", "np", ".", "std", "(", "unique_questions_list", ")", ")", "/", "math", ".", "sqrt", "(", "len", "(", "unique_questions_list", ")", ")", "\n", "ret_metrics", "[", "\"mutual_overlap_CI\"", "]", "=", "(", "1.96", "*", "np", ".", "std", "(", "mutual_overlap_list", ")", ")", "/", "math", ".", "sqrt", "(", "len", "(", "mutual_overlap_list", ")", ")", "\n", "ret_metrics", "[", "\"dist_1_CI\"", "]", "=", "(", "1.96", "*", "np", ".", "std", "(", "dist_1_list", ")", ")", "/", "math", ".", "sqrt", "(", "len", "(", "dist_1_list", ")", ")", "\n", "ret_metrics", "[", "\"dist_2_CI\"", "]", "=", "(", "1.96", "*", "np", ".", "std", "(", "dist_2_list", ")", ")", "/", "math", ".", "sqrt", "(", "len", "(", "dist_2_list", ")", ")", "\n", "\n", "return", "text", ",", "ret_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.dialog_generate.get_entropy_ctr": [[562, 568], ["list", "float", "scipy.stats.entropy", "ctr.values", "sum"], "function", ["None"], ["", "def", "get_entropy_ctr", "(", "ctr", ")", ":", "\n", "\n", "    ", "values", "=", "list", "(", "ctr", ".", "values", "(", ")", ")", "\n", "sum_values", "=", "float", "(", "sum", "(", "values", ")", ")", "\n", "probs", "=", "[", "x", "/", "sum_values", "for", "x", "in", "values", "]", "\n", "return", "entropy", "(", "probs", ")", "", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.rank_answerer.rankOptions": [[20, 29], ["scores.gather", "torch.sort", "torch.sum", "gtOptions.unsqueeze", "sortedScore.gt().float", "sortedScore.gt"], "function", ["None"], ["def", "rankOptions", "(", "options", ",", "gtOptions", ",", "scores", ")", ":", "\n", "    ", "'''Rank a batch of examples against a list of options.'''", "\n", "# Compute score of GT options in 'scores'", "\n", "gtScores", "=", "scores", ".", "gather", "(", "1", ",", "gtOptions", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# Sort all predicted scores", "\n", "sortedScore", ",", "_", "=", "torch", ".", "sort", "(", "scores", ",", "1", ")", "\n", "# In sorted scores, count how many are greater than the GT score", "\n", "ranks", "=", "torch", ".", "sum", "(", "sortedScore", ".", "gt", "(", "gtScores", ")", ".", "float", "(", ")", ",", "1", ")", "\n", "return", "ranks", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.rank_answerer.rankABot": [[30, 212], ["torch.utils.data.DataLoader", "timeit.default_timer", "enumerate", "sys.stdout.write", "print", "torch.cat", "visdial.computeMetrics", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy.mean", "visdial.metrics.NDCG", "int", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "aBot.reset", "aBot.observe", "six.moves.range", "batch[].squeeze", "timeit.default_timer", "sys.stdout.write", "sys.stdout.flush", "json.dump", "torch.cat.cpu", "torch.cat().mean", "metrics.computeMetrics.update", "metrics.computeMetrics.items", "six.moves.range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "aBot.observe", "aBot.evalOptions", "aBot.forward", "logProbsAll[].append", "torch.cat", "visdial.metrics.scores_to_ranks", "six.moves.range", "open", "torch.cat().data.cpu", "visdial.metrics.NDCG.retrieve", "print", "getImgId", "log_probs_rounds.append", "scoringFunction", "rank_answerer.rankOptions", "torch.cat.append", "len", "torch.arange().long().cpu().numpy", "torch.autograd.Variable.long().cpu().data.numpy", "round_id_numpy.reshape.reshape", "torch.autograd.Variable.cpu().data.numpy", "torch.autograd.Variable", "visdial.metrics.NDCG.observe", "torch.cat", "getImgFileName", "hasattr", "v.cuda", "batch.items", "hasattr", "v.contiguous", "batch.items", "aBot.evalOptions.unsqueeze", "answers[].contiguous", "ranks_json.append", "six.moves.range", "torch.from_numpy", "ranks_json.append", "torch.arange().long().cpu", "torch.cat", "int", "[].data.cpu().tolist", "torch.autograd.Variable.long().cpu", "torch.autograd.Variable.cpu", "int", "torch.arange().long", "[].data.cpu", "torch.autograd.Variable.long", "torch.arange"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.computeMetrics", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.evalOptions", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.forward", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.scores_to_ranks", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.NDCG.retrieve", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.rank_answerer.rankOptions", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe"], ["", "def", "rankABot", "(", "aBot", ",", "dataset", ",", "split", ",", "scoringFunction", ",", "exampleLimit", "=", "None", ",", "useNDCG", "=", "False", ")", ":", "\n", "    ", "'''\n        Evaluate A-Bot performance on ranking answer option when it is\n        shown ground truth image features, captions and questions.\n\n        Arguments:\n            aBot    : A-Bot\n            dataset : VisDialDataset instance\n            split   : Dataset split, can be 'val' or 'test'\n\n            scoringFunction : A function which computes negative log\n                              likelihood of a sequence (answer) given log\n                              probabilities under an RNN model. Currently\n                              utils.maskedNll is the only such function used.\n            exampleLimit    : Maximum number of data points to use from\n                              the dataset split. If None, all data points.\n    '''", "\n", "\n", "batchSize", "=", "dataset", ".", "batchSize", "\n", "numRounds", "=", "dataset", ".", "numRounds", "\n", "if", "exampleLimit", "is", "None", ":", "\n", "        ", "numExamples", "=", "dataset", ".", "numDataPoints", "[", "split", "]", "\n", "", "else", ":", "\n", "        ", "numExamples", "=", "exampleLimit", "\n", "\n", "", "numBatches", "=", "(", "numExamples", "-", "1", ")", "//", "batchSize", "+", "1", "\n", "\n", "original_split", "=", "dataset", ".", "split", "\n", "dataset", ".", "split", "=", "split", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batchSize", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "1", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "\n", "# sparse_metrics = SparseGTMetrics()", "\n", "ndcg", "=", "None", "\n", "if", "useNDCG", ":", "\n", "        ", "ndcg", "=", "NDCG", "(", ")", "\n", "", "ranks_json", "=", "[", "]", "\n", "\n", "totalLoss", ",", "totalTokens", "=", "0", ",", "0", "\n", "ranks", "=", "[", "]", "\n", "logProbsAll", "=", "[", "[", "]", "for", "_", "in", "range", "(", "numRounds", ")", "]", "\n", "start_t", "=", "timer", "(", ")", "\n", "\n", "getImgFileName", "=", "lambda", "x", ":", "dataset", ".", "data", "[", "'%s_img_fnames'", "%", "split", "]", "[", "x", "]", "\n", "getImgId", "=", "lambda", "x", ":", "int", "(", "getImgFileName", "(", "x", ")", "[", ":", "-", "4", "]", "[", "-", "12", ":", "]", ")", "\n", "\n", "for", "idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "if", "idx", "==", "numBatches", ":", "\n", "            ", "break", "\n", "\n", "", "if", "dataset", ".", "useGPU", ":", "\n", "            ", "batch", "=", "{", "\n", "key", ":", "v", ".", "cuda", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "else", "v", "\n", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "batch", "=", "{", "\n", "key", ":", "v", ".", "contiguous", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "else", "v", "\n", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "\n", "}", "\n", "\n", "", "image", "=", "Variable", "(", "batch", "[", "'img_feat'", "]", ",", "volatile", "=", "True", ")", "\n", "caption", "=", "Variable", "(", "batch", "[", "'cap'", "]", ",", "volatile", "=", "True", ")", "\n", "captionLens", "=", "Variable", "(", "batch", "[", "'cap_len'", "]", ",", "volatile", "=", "True", ")", "\n", "questions", "=", "Variable", "(", "batch", "[", "'ques'", "]", ",", "volatile", "=", "True", ")", "\n", "quesLens", "=", "Variable", "(", "batch", "[", "'ques_len'", "]", ",", "volatile", "=", "True", ")", "\n", "answers", "=", "Variable", "(", "batch", "[", "'ans'", "]", ",", "volatile", "=", "True", ")", "\n", "ansLens", "=", "Variable", "(", "batch", "[", "'ans_len'", "]", ",", "volatile", "=", "True", ")", "\n", "options", "=", "Variable", "(", "batch", "[", "'opt'", "]", ",", "volatile", "=", "True", ")", "\n", "optionLens", "=", "Variable", "(", "batch", "[", "'opt_len'", "]", ",", "volatile", "=", "True", ")", "\n", "\n", "gtRelevance", "=", "None", "\n", "round_id", "=", "None", "\n", "img_ids", "=", "None", "\n", "correctOptionInds", "=", "None", "\n", "\n", "if", "split", "!=", "'test'", ":", "\n", "            ", "correctOptionInds", "=", "Variable", "(", "batch", "[", "'ans_id'", "]", ",", "volatile", "=", "True", ")", "\n", "\n", "", "if", "split", "==", "'val'", "and", "useNDCG", ":", "\n", "# read in gtRelevance and round", "\n", "            ", "gtRelevance", "=", "Variable", "(", "batch", "[", "'gt_relevance'", "]", ",", "volatile", "=", "True", ")", "\n", "round_id", "=", "Variable", "(", "batch", "[", "'round_id'", "]", ",", "volatile", "=", "True", ")", "\n", "img_ids", "=", "Variable", "(", "batch", "[", "'image_id'", "]", ",", "volatile", "=", "True", ")", "\n", "\n", "", "if", "split", "==", "'test'", ":", "\n", "            ", "img_ids", "=", "[", "getImgId", "(", "x", ")", "for", "x", "in", "batch", "[", "'index'", "]", "]", "\n", "\n", "", "aBot", ".", "reset", "(", ")", "\n", "aBot", ".", "observe", "(", "-", "1", ",", "image", "=", "image", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "log_probs_rounds", "=", "[", "]", "\n", "for", "round", "in", "range", "(", "numRounds", ")", ":", "\n", "            ", "aBot", ".", "observe", "(", "\n", "round", ",", "\n", "ques", "=", "questions", "[", ":", ",", "round", "]", ",", "\n", "quesLens", "=", "quesLens", "[", ":", ",", "round", "]", ",", "\n", "ans", "=", "answers", "[", ":", ",", "round", "]", ",", "\n", "ansLens", "=", "ansLens", "[", ":", ",", "round", "]", ")", "\n", "logProbs", "=", "aBot", ".", "evalOptions", "(", "options", "[", ":", ",", "round", "]", ",", "\n", "optionLens", "[", ":", ",", "round", "]", ",", "scoringFunction", ")", "\n", "if", "useNDCG", ":", "\n", "                ", "log_probs_rounds", ".", "append", "(", "logProbs", ".", "unsqueeze", "(", "1", ")", ")", "\n", "", "logProbsCurrent", "=", "aBot", ".", "forward", "(", ")", "\n", "logProbsAll", "[", "round", "]", ".", "append", "(", "\n", "scoringFunction", "(", "logProbsCurrent", ",", "\n", "answers", "[", ":", ",", "round", "]", ".", "contiguous", "(", ")", ")", ")", "\n", "if", "split", "!=", "'test'", ":", "\n", "                ", "batchRanks", "=", "rankOptions", "(", "options", "[", ":", ",", "round", "]", ",", "\n", "correctOptionInds", "[", ":", ",", "round", "]", ",", "logProbs", ")", "\n", "ranks", ".", "append", "(", "batchRanks", ")", "\n", "", "", "batch", "[", "'num_rounds'", "]", "=", "batch", "[", "'num_rounds'", "]", ".", "squeeze", "(", "1", ")", "\n", "output", "=", "None", "\n", "if", "useNDCG", "or", "split", "==", "'test'", ":", "\n", "\n", "            ", "output", "=", "torch", ".", "cat", "(", "log_probs_rounds", ",", "dim", "=", "1", ")", "\n", "ranks_cur", "=", "scores_to_ranks", "(", "output", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "img_ids", ")", ")", ":", "\n", "# cast into types explicitly to ensure no errors in schema", "\n", "# round ids are 1-10, not 0-9", "\n", "# \"ranks\": [rank.data[0] for rank in ranks_cur[i][batch[\"num_rounds\"][i] - 1]]", "\n", "\n", "                ", "if", "split", "==", "\"test\"", ":", "\n", "                    ", "ranks_json", ".", "append", "(", "{", "\n", "\"image_id\"", ":", "img_ids", "[", "i", "]", ",", "\n", "\"round_id\"", ":", "int", "(", "batch", "[", "\"num_rounds\"", "]", "[", "i", "]", ")", ",", "\n", "\"ranks\"", ":", "ranks_cur", "[", "i", "]", "[", "batch", "[", "\"num_rounds\"", "]", "[", "i", "]", "-", "1", "]", ".", "data", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "}", ")", "\n", "", "else", ":", "\n", "                    ", "for", "j", "in", "range", "(", "numRounds", ")", ":", "\n", "                        ", "ranks_json", ".", "append", "(", "{", "\n", "\"image_id\"", ":", "img_ids", "[", "i", "]", ".", "data", "[", "0", "]", ",", "\n", "\"round_id\"", ":", "int", "(", "j", "+", "1", ")", ",", "\n", "\"ranks\"", ":", "[", "rank", ".", "data", "[", "0", "]", "for", "rank", "in", "ranks_cur", "[", "i", "]", "[", "j", "]", "]", "\n", "}", ")", "\n", "\n", "", "", "", "", "if", "split", "==", "\"val\"", ":", "\n", "# sparse_metrics.observe(output, correctOptionInds)", "\n", "            ", "if", "\"gt_relevance\"", "in", "batch", "and", "useNDCG", ":", "\n", "                ", "indices", "=", "torch", ".", "arange", "(", "output", ".", "shape", "[", "0", "]", ")", ".", "long", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "round_id_numpy", "=", "round_id", ".", "long", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "round_id_numpy", "=", "round_id_numpy", ".", "reshape", "(", "-", "1", ")", "\n", "output", "=", "output", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "output", "=", "output", "[", "indices", ",", "round_id_numpy", "-", "1", ",", ":", "]", "\n", "output", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "output", ")", ",", "volatile", "=", "True", ")", "\n", "ndcg", ".", "observe", "(", "output", ",", "gtRelevance", ")", "\n", "\n", "", "", "end_t", "=", "timer", "(", ")", "\n", "delta_t", "=", "\" Rate: %5.2fs\"", "%", "(", "end_t", "-", "start_t", ")", "\n", "start_t", "=", "end_t", "\n", "progressString", "=", "\"\\r[Abot] Evaluating split '%s' [%d/%d]\\t\"", "+", "delta_t", "\n", "sys", ".", "stdout", ".", "write", "(", "progressString", "%", "(", "split", ",", "idx", "+", "1", ",", "numBatches", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "\n", "dataloader", "=", "None", "\n", "print", "(", "\"Sleeping for 3 seconds to let dataloader subprocesses exit...\"", ")", "\n", "dataset", ".", "split", "=", "original_split", "\n", "\n", "if", "split", "==", "'test'", ":", "\n", "# dump eval AI file", "\n", "        ", "dir_out", "=", "'predictions.txt'", "\n", "json", ".", "dump", "(", "ranks_json", ",", "open", "(", "dir_out", ",", "\"w\"", ")", ")", "\n", "return", "\n", "\n", "", "ranks", "=", "torch", ".", "cat", "(", "ranks", ",", "0", ")", "\n", "rankMetrics", "=", "metrics", ".", "computeMetrics", "(", "ranks", ".", "cpu", "(", ")", ")", "\n", "\n", "logProbsAll", "=", "[", "torch", ".", "cat", "(", "lprobs", ",", "0", ")", ".", "mean", "(", ")", "for", "lprobs", "in", "logProbsAll", "]", "\n", "roundwiseLogProbs", "=", "torch", ".", "cat", "(", "logProbsAll", ",", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "logProbsMean", "=", "roundwiseLogProbs", ".", "mean", "(", ")", "\n", "rankMetrics", "[", "'logProbsMean'", "]", "=", "logProbsMean", "\n", "\n", "if", "split", "==", "\"val\"", "and", "useNDCG", ":", "\n", "        ", "rankMetrics", ".", "update", "(", "ndcg", ".", "retrieve", "(", "reset", "=", "True", ")", ")", "\n", "for", "metric_name", ",", "metric_value", "in", "rankMetrics", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "f\"{metric_name}: {metric_value}\"", ")", "\n", "", "", "return", "rankMetrics", "\n", "", ""]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.rank_questioner.rankQBot": [[22, 185], ["torch.utils.data.DataLoader", "timeit.default_timer", "enumerate", "sys.stdout.write", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "len", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy.mean", "torch.cat().data.cpu().numpy.mean", "six.moves.range", "huber_loss.data.cpu().numpy", "cos_similarity_loss.data.cpu().numpy", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "qBot.reset", "qBot.observe", "qBot.predictImage", "torch.mse_loss", "featLossAll[].append", "roundwiseFeaturePreds[].append", "six.moves.range", "gtImgFeatures.append", "timeit.default_timer", "sys.stdout.write", "sys.stdout.flush", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "print", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "sklearn.metrics.pairwise.pairwise_distances", "six.moves.range", "numpy.array", "visdial.computeMetrics", "np.array.mean", "rankMetricsRounds.append", "six.moves.range", "six.moves.range", "six.moves.range", "torch.mean", "torch.mean", "qBot.observe", "qBot.observe", "qBot.forward", "logProbsAll[].append", "qBot.predictImage", "torch.mse_loss", "featLossAll[].append", "roundwiseFeaturePreds[].append", "torch.cat().data.cpu", "torch.cat().data.cpu", "torch.cat().data.cpu", "torch.cat().data.cpu", "torch.cat().data.cpu", "torch.cat().data.cpu", "np.array.append", "torch.autograd.Variable", "np.array.std", "numpy.sqrt", "print", "len", "huber_loss.data.cpu", "cos_similarity_loss.data.cpu", "v.cuda", "v.contiguous", "utils.utilities.cosinePenalty", "utils.utilities.huberPenalty", "utils.utilities.maskedNll", "torch.mean", "torch.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().data.cpu", "torch.cat().data.cpu", "int", "torch.from_numpy", "torch.from_numpy", "batch.items", "hasattr", "batch.items", "hasattr", "gtQuestions[].contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.where", "torch.cat", "torch.cat", "dists[].argsort"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.predictImage", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.computeMetrics", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.forward", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.predictImage", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.cosinePenalty", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.huberPenalty", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.utils.utilities.maskedNll"], ["def", "rankQBot", "(", "qBot", ",", "dataset", ",", "split", ",", "exampleLimit", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "    ", "'''\n        Evaluates Q-Bot performance on image retrieval when it is shown\n        ground truth captions, questions and answers. Q-Bot does not\n        generate dialog in this setting - it only encodes ground truth\n        captions and dialog in order to perform image retrieval by\n        predicting FC-7 image features after each round of dialog.\n\n        Arguments:\n            qBot    : Q-Bot\n            dataset : VisDialDataset instance\n            split   : Dataset split, can be 'val' or 'test'\n\n            exampleLimit : Maximum number of data points to use from\n                           the dataset split. If None, all data points.\n    '''", "\n", "batchSize", "=", "dataset", ".", "batchSize", "\n", "numRounds", "=", "dataset", ".", "numRounds", "\n", "if", "exampleLimit", "is", "None", ":", "\n", "        ", "numExamples", "=", "dataset", ".", "numDataPoints", "[", "split", "]", "\n", "", "else", ":", "\n", "        ", "numExamples", "=", "exampleLimit", "\n", "", "numBatches", "=", "(", "numExamples", "-", "1", ")", "//", "batchSize", "+", "1", "\n", "original_split", "=", "dataset", ".", "split", "\n", "dataset", ".", "split", "=", "split", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batchSize", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "\n", "# enumerate all gt features and all predicted features", "\n", "gtImgFeatures", "=", "[", "]", "\n", "# caption + dialog rounds", "\n", "roundwiseFeaturePreds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "numRounds", "+", "1", ")", "]", "\n", "logProbsAll", "=", "[", "[", "]", "for", "_", "in", "range", "(", "numRounds", ")", "]", "\n", "featLossAll", "=", "[", "[", "]", "for", "_", "in", "range", "(", "numRounds", "+", "1", ")", "]", "\n", "start_t", "=", "timer", "(", ")", "\n", "\n", "cos_similarity_loss", "=", "0", "\n", "huber_loss", "=", "0", "\n", "\n", "for", "idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "if", "idx", "==", "numBatches", ":", "\n", "            ", "break", "\n", "\n", "", "if", "dataset", ".", "useGPU", ":", "\n", "            ", "batch", "=", "{", "\n", "key", ":", "v", ".", "cuda", "(", ")", "\n", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "batch", "=", "{", "\n", "key", ":", "v", ".", "contiguous", "(", ")", "\n", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "\n", "}", "\n", "", "caption", "=", "Variable", "(", "batch", "[", "'cap'", "]", ",", "volatile", "=", "True", ")", "\n", "captionLens", "=", "Variable", "(", "batch", "[", "'cap_len'", "]", ",", "volatile", "=", "True", ")", "\n", "gtQuestions", "=", "Variable", "(", "batch", "[", "'ques'", "]", ",", "volatile", "=", "True", ")", "\n", "gtQuesLens", "=", "Variable", "(", "batch", "[", "'ques_len'", "]", ",", "volatile", "=", "True", ")", "\n", "answers", "=", "Variable", "(", "batch", "[", "'ans'", "]", ",", "volatile", "=", "True", ")", "\n", "ansLens", "=", "Variable", "(", "batch", "[", "'ans_len'", "]", ",", "volatile", "=", "True", ")", "\n", "gtFeatures", "=", "Variable", "(", "batch", "[", "'img_feat'", "]", ",", "volatile", "=", "True", ")", "\n", "qBot", ".", "reset", "(", ")", "\n", "qBot", ".", "observe", "(", "-", "1", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "predFeatures", "=", "qBot", ".", "predictImage", "(", ")", "\n", "# Evaluating round 0 feature regression network", "\n", "featLoss", "=", "F", ".", "mse_loss", "(", "predFeatures", ",", "gtFeatures", ")", "\n", "featLossAll", "[", "0", "]", ".", "append", "(", "torch", ".", "mean", "(", "featLoss", ")", ")", "\n", "# Keeping round 0 predictions", "\n", "roundwiseFeaturePreds", "[", "0", "]", ".", "append", "(", "predFeatures", ")", "\n", "cur_dialog_hidden", "=", "None", "\n", "past_dialog_hidden", "=", "None", "\n", "for", "round", "in", "range", "(", "numRounds", ")", ":", "\n", "            ", "qBot", ".", "observe", "(", "\n", "round", ",", "\n", "ques", "=", "gtQuestions", "[", ":", ",", "round", "]", ",", "\n", "quesLens", "=", "gtQuesLens", "[", ":", ",", "round", "]", ")", "\n", "qBot", ".", "observe", "(", "\n", "round", ",", "ans", "=", "answers", "[", ":", ",", "round", "]", ",", "ansLens", "=", "ansLens", "[", ":", ",", "round", "]", ")", "\n", "logProbsCurrent", "=", "qBot", ".", "forward", "(", ")", "\n", "cur_dialog_hidden", "=", "qBot", ".", "encoder", ".", "dialogHiddens", "[", "-", "1", "]", "[", "0", "]", "\n", "if", "round", ">", "0", ":", "\n", "# calculate diversity losses", "\n", "\n", "# cos similarity", "\n", "                ", "cos_similarity_loss", "+=", "utils", ".", "cosinePenalty", "(", "cur_dialog_hidden", ",", "past_dialog_hidden", ")", "\n", "\n", "# huber loss", "\n", "huber_loss", "+=", "utils", ".", "huberPenalty", "(", "cur_dialog_hidden", ",", "past_dialog_hidden", ",", "threshold", "=", "0.1", ")", "\n", "\n", "", "past_dialog_hidden", "=", "cur_dialog_hidden", "\n", "\n", "# Evaluating logProbs for cross entropy", "\n", "logProbsAll", "[", "round", "]", ".", "append", "(", "\n", "utils", ".", "maskedNll", "(", "logProbsCurrent", ",", "\n", "gtQuestions", "[", ":", ",", "round", "]", ".", "contiguous", "(", ")", ")", ")", "\n", "predFeatures", "=", "qBot", ".", "predictImage", "(", ")", "\n", "# Evaluating feature regression network", "\n", "featLoss", "=", "F", ".", "mse_loss", "(", "predFeatures", ",", "gtFeatures", ")", "\n", "featLossAll", "[", "round", "+", "1", "]", ".", "append", "(", "torch", ".", "mean", "(", "featLoss", ")", ")", "\n", "# Keeping predictions", "\n", "roundwiseFeaturePreds", "[", "round", "+", "1", "]", ".", "append", "(", "predFeatures", ")", "\n", "", "gtImgFeatures", ".", "append", "(", "gtFeatures", ")", "\n", "\n", "end_t", "=", "timer", "(", ")", "\n", "delta_t", "=", "\" Time: %5.2fs\"", "%", "(", "end_t", "-", "start_t", ")", "\n", "start_t", "=", "end_t", "\n", "progressString", "=", "\"\\r[Qbot] Evaluating split '%s' [%d/%d]\\t\"", "+", "delta_t", "\n", "sys", ".", "stdout", ".", "write", "(", "progressString", "%", "(", "split", ",", "idx", "+", "1", ",", "numBatches", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "gtFeatures", "=", "torch", ".", "cat", "(", "gtImgFeatures", ",", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "rankMetricsRounds", "=", "[", "]", "\n", "poolSize", "=", "len", "(", "dataset", ")", "\n", "\n", "# Keeping tracking of feature regression loss and CE logprobs", "\n", "logProbsAll", "=", "[", "torch", ".", "cat", "(", "lprobs", ",", "0", ")", ".", "mean", "(", ")", "for", "lprobs", "in", "logProbsAll", "]", "\n", "\n", "featLossAll", "=", "[", "torch", ".", "cat", "(", "floss", ",", "0", ")", ".", "mean", "(", ")", "for", "floss", "in", "featLossAll", "]", "\n", "roundwiseLogProbs", "=", "torch", ".", "cat", "(", "logProbsAll", ",", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "roundwiseFeatLoss", "=", "torch", ".", "cat", "(", "featLossAll", ",", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "logProbsMean", "=", "roundwiseLogProbs", ".", "mean", "(", ")", "\n", "featLossMean", "=", "roundwiseFeatLoss", ".", "mean", "(", ")", "\n", "\n", "huber_loss", "=", "huber_loss", "/", "(", "numRounds", "*", "numBatches", ")", "\n", "cos_similarity_loss", "=", "cos_similarity_loss", "/", "(", "numRounds", "*", "numBatches", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Percentile mean rank (round, mean, low, high)\"", ")", "\n", "", "for", "round", "in", "range", "(", "numRounds", "+", "1", ")", ":", "\n", "        ", "predFeatures", "=", "torch", ".", "cat", "(", "roundwiseFeaturePreds", "[", "round", "]", ",", "\n", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# num_examples x num_examples", "\n", "dists", "=", "pairwise_distances", "(", "predFeatures", ",", "gtFeatures", ")", "\n", "ranks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "dists", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "rank", "=", "int", "(", "np", ".", "where", "(", "dists", "[", "i", ",", ":", "]", ".", "argsort", "(", ")", "==", "i", ")", "[", "0", "]", ")", "+", "1", "\n", "ranks", ".", "append", "(", "rank", ")", "\n", "", "ranks", "=", "np", ".", "array", "(", "ranks", ")", "\n", "rankMetrics", "=", "metrics", ".", "computeMetrics", "(", "Variable", "(", "torch", ".", "from_numpy", "(", "ranks", ")", ")", ")", "\n", "meanRank", "=", "ranks", ".", "mean", "(", ")", "\n", "se", "=", "ranks", ".", "std", "(", ")", "/", "np", ".", "sqrt", "(", "poolSize", ")", "\n", "meanPercRank", "=", "100", "*", "(", "1", "-", "(", "meanRank", "/", "poolSize", ")", ")", "\n", "percRankLow", "=", "100", "*", "(", "1", "-", "(", "(", "meanRank", "+", "se", ")", "/", "poolSize", ")", ")", "\n", "percRankHigh", "=", "100", "*", "(", "1", "-", "(", "(", "meanRank", "-", "se", ")", "/", "poolSize", ")", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "(", "round", ",", "meanPercRank", ",", "percRankLow", ",", "percRankHigh", ")", ")", "\n", "", "rankMetrics", "[", "'percentile'", "]", "=", "meanPercRank", "\n", "# rankMetrics['featLoss'] = roundwiseFeatLoss[round]", "\n", "if", "round", "<", "len", "(", "roundwiseLogProbs", ")", ":", "\n", "            ", "rankMetrics", "[", "'logProbs'", "]", "=", "roundwiseLogProbs", "[", "round", "]", "\n", "", "rankMetricsRounds", ".", "append", "(", "rankMetrics", ")", "\n", "\n", "", "rankMetricsRounds", "[", "-", "1", "]", "[", "'logProbsMean'", "]", "=", "logProbsMean", "\n", "rankMetricsRounds", "[", "-", "1", "]", "[", "'featLossMean'", "]", "=", "featLossMean", "\n", "rankMetricsRounds", "[", "-", "1", "]", "[", "'huberLossMean'", "]", "=", "huber_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "rankMetricsRounds", "[", "-", "1", "]", "[", "\"cosSimilarityLossMean\"", "]", "=", "cos_similarity_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "dataset", ".", "split", "=", "original_split", "\n", "return", "rankMetricsRounds", "[", "-", "1", "]", ",", "rankMetricsRounds", "\n", "\n"]], "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.eval_utils.rank_questioner.rankQABots": [[186, 303], ["torch.utils.data.DataLoader", "timeit.default_timer", "enumerate", "sys.stdout.write", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "print", "six.moves.range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "aBot.observe", "qBot.observe", "qBot.predictImage", "roundwiseFeaturePreds[].append", "six.moves.range", "gtImgFeatures.append", "timeit.default_timer", "sys.stdout.write", "sys.stdout.flush", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "sklearn.metrics.pairwise.pairwise_distances", "six.moves.range", "numpy.array", "visdial.computeMetrics", "len", "np.array.mean", "print", "rankMetricsRounds.append", "six.moves.range", "aBot.eval", "aBot.reset", "qBot.eval", "qBot.reset", "qBot.forwardDecode", "qBot.observe", "aBot.observe", "aBot.forwardDecode", "aBot.observe", "qBot.observe", "qBot.predictImage", "roundwiseFeaturePreds[].append", "torch.cat().data.cpu", "torch.cat().data.cpu", "np.array.append", "torch.autograd.Variable", "len", "len", "np.array.std", "numpy.sqrt", "v.cuda", "v.contiguous", "torch.cat().data.cpu", "torch.cat().data.cpu", "int", "torch.from_numpy", "torch.from_numpy", "batch.items", "hasattr", "batch.items", "hasattr", "torch.cat", "torch.cat", "numpy.where", "torch.cat", "torch.cat", "dists[].argsort"], "function", ["home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.predictImage", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.visdial.metrics.computeMetrics", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.reset", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.decoders.gen.Decoder.forwardDecode", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.encoders.hre.Encoder.observe", "home.repos.pwc.inspect_result.vmurahari3_visdial-diversity.models.questioner.Questioner.predictImage"], ["", "def", "rankQABots", "(", "qBot", ",", "aBot", ",", "dataset", ",", "split", ",", "exampleLimit", "=", "None", ",", "beamSize", "=", "1", ")", ":", "\n", "    ", "'''\n        Evaluates Q-Bot and A-Bot performance on image retrieval where\n        both agents must converse with each other without any ground truth\n        dialog. The common caption shown to both agents is not the ground\n        truth caption, but is instead a caption generated (pre-computed)\n        by a pre-trained captioning model (neuraltalk2).\n\n        Arguments:\n            qBot    : Q-Bot\n            aBot    : A-Bot\n            dataset : VisDialDataset instance\n            split   : Dataset split, can be 'val' or 'test'\n\n            exampleLimit : Maximum number of data points to use from\n                           the dataset split. If None, all data points.\n            beamSize     : Beam search width for generating utterrances\n    '''", "\n", "\n", "batchSize", "=", "dataset", ".", "batchSize", "\n", "numRounds", "=", "dataset", ".", "numRounds", "\n", "if", "exampleLimit", "is", "None", ":", "\n", "        ", "numExamples", "=", "dataset", ".", "numDataPoints", "[", "split", "]", "\n", "", "else", ":", "\n", "        ", "numExamples", "=", "exampleLimit", "\n", "", "numBatches", "=", "(", "numExamples", "-", "1", ")", "//", "batchSize", "+", "1", "\n", "original_split", "=", "dataset", ".", "split", "\n", "dataset", ".", "split", "=", "split", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batchSize", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "\n", "gtImgFeatures", "=", "[", "]", "\n", "roundwiseFeaturePreds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "numRounds", "+", "1", ")", "]", "\n", "\n", "start_t", "=", "timer", "(", ")", "\n", "for", "idx", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "if", "idx", "==", "numBatches", ":", "\n", "            ", "break", "\n", "\n", "", "if", "dataset", ".", "useGPU", ":", "\n", "            ", "batch", "=", "{", "key", ":", "v", ".", "cuda", "(", ")", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "}", "\n", "", "else", ":", "\n", "            ", "batch", "=", "{", "key", ":", "v", ".", "contiguous", "(", ")", "for", "key", ",", "v", "in", "batch", ".", "items", "(", ")", "if", "hasattr", "(", "v", ",", "'cuda'", ")", "}", "\n", "\n", "", "caption", "=", "Variable", "(", "batch", "[", "'cap'", "]", ",", "volatile", "=", "True", ")", "\n", "captionLens", "=", "Variable", "(", "batch", "[", "'cap_len'", "]", ",", "volatile", "=", "True", ")", "\n", "gtQuestions", "=", "Variable", "(", "batch", "[", "'ques'", "]", ",", "volatile", "=", "True", ")", "\n", "gtQuesLens", "=", "Variable", "(", "batch", "[", "'ques_len'", "]", ",", "volatile", "=", "True", ")", "\n", "answers", "=", "Variable", "(", "batch", "[", "'ans'", "]", ",", "volatile", "=", "True", ")", "\n", "ansLens", "=", "Variable", "(", "batch", "[", "'ans_len'", "]", ",", "volatile", "=", "True", ")", "\n", "gtFeatures", "=", "Variable", "(", "batch", "[", "'img_feat'", "]", ",", "volatile", "=", "True", ")", "\n", "image", "=", "Variable", "(", "batch", "[", "'img_feat'", "]", ",", "volatile", "=", "True", ")", "\n", "\n", "aBot", ".", "eval", "(", ")", ",", "aBot", ".", "reset", "(", ")", "\n", "aBot", ".", "observe", "(", "-", "1", ",", "image", "=", "image", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "qBot", ".", "eval", "(", ")", ",", "qBot", ".", "reset", "(", ")", "\n", "qBot", ".", "observe", "(", "-", "1", ",", "caption", "=", "caption", ",", "captionLens", "=", "captionLens", ")", "\n", "\n", "predFeatures", "=", "qBot", ".", "predictImage", "(", ")", "\n", "roundwiseFeaturePreds", "[", "0", "]", ".", "append", "(", "predFeatures", ")", "\n", "\n", "for", "round", "in", "range", "(", "numRounds", ")", ":", "\n", "            ", "questions", ",", "quesLens", "=", "qBot", ".", "forwardDecode", "(", "\n", "inference", "=", "'greedy'", ",", "beamSize", "=", "beamSize", ")", "\n", "qBot", ".", "observe", "(", "round", ",", "ques", "=", "questions", ",", "quesLens", "=", "quesLens", ")", "\n", "aBot", ".", "observe", "(", "round", ",", "ques", "=", "questions", ",", "quesLens", "=", "quesLens", ")", "\n", "answers", ",", "ansLens", "=", "aBot", ".", "forwardDecode", "(", "\n", "inference", "=", "'greedy'", ",", "beamSize", "=", "beamSize", ")", "\n", "aBot", ".", "observe", "(", "round", ",", "ans", "=", "answers", ",", "ansLens", "=", "ansLens", ")", "\n", "qBot", ".", "observe", "(", "round", ",", "ans", "=", "answers", ",", "ansLens", "=", "ansLens", ")", "\n", "predFeatures", "=", "qBot", ".", "predictImage", "(", ")", "\n", "roundwiseFeaturePreds", "[", "round", "+", "1", "]", ".", "append", "(", "predFeatures", ")", "\n", "", "gtImgFeatures", ".", "append", "(", "gtFeatures", ")", "\n", "\n", "end_t", "=", "timer", "(", ")", "\n", "delta_t", "=", "\" Rate: %5.2fs\"", "%", "(", "end_t", "-", "start_t", ")", "\n", "start_t", "=", "end_t", "\n", "progressString", "=", "\"\\r[Qbot] Evaluating split '%s' [%d/%d]\\t\"", "+", "delta_t", "\n", "sys", ".", "stdout", ".", "write", "(", "progressString", "%", "(", "split", ",", "idx", "+", "1", ",", "numBatches", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "gtFeatures", "=", "torch", ".", "cat", "(", "gtImgFeatures", ",", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "rankMetricsRounds", "=", "[", "]", "\n", "\n", "print", "(", "\"Percentile mean rank (round, mean, low, high)\"", ")", "\n", "for", "round", "in", "range", "(", "numRounds", "+", "1", ")", ":", "\n", "        ", "predFeatures", "=", "torch", ".", "cat", "(", "roundwiseFeaturePreds", "[", "round", "]", ",", "\n", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "dists", "=", "pairwise_distances", "(", "predFeatures", ",", "gtFeatures", ")", "\n", "# num_examples x num_examples", "\n", "ranks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "dists", ".", "shape", "[", "0", "]", ")", ":", "\n", "# Computing rank of i-th prediction vs all images in split", "\n", "            ", "rank", "=", "int", "(", "np", ".", "where", "(", "dists", "[", "i", ",", ":", "]", ".", "argsort", "(", ")", "==", "i", ")", "[", "0", "]", ")", "+", "1", "\n", "ranks", ".", "append", "(", "rank", ")", "\n", "", "ranks", "=", "np", ".", "array", "(", "ranks", ")", "\n", "rankMetrics", "=", "metrics", ".", "computeMetrics", "(", "Variable", "(", "torch", ".", "from_numpy", "(", "ranks", ")", ")", ")", "\n", "assert", "len", "(", "ranks", ")", "==", "len", "(", "dataset", ")", "\n", "poolSize", "=", "len", "(", "dataset", ")", "\n", "meanRank", "=", "ranks", ".", "mean", "(", ")", "\n", "se", "=", "ranks", ".", "std", "(", ")", "/", "np", ".", "sqrt", "(", "poolSize", ")", "\n", "meanPercRank", "=", "100", "*", "(", "1", "-", "(", "meanRank", "/", "poolSize", ")", ")", "\n", "percRankLow", "=", "100", "*", "(", "1", "-", "(", "(", "meanRank", "+", "se", ")", "/", "poolSize", ")", ")", "\n", "percRankHigh", "=", "100", "*", "(", "1", "-", "(", "(", "meanRank", "-", "se", ")", "/", "poolSize", ")", ")", "\n", "print", "(", "(", "round", ",", "meanPercRank", ",", "percRankLow", ",", "percRankHigh", ")", ")", "\n", "rankMetrics", "[", "'percentile'", "]", "=", "meanPercRank", "\n", "rankMetricsRounds", ".", "append", "(", "rankMetrics", ")", "\n", "\n", "", "dataset", ".", "split", "=", "original_split", "\n", "return", "rankMetricsRounds", "[", "-", "1", "]", ",", "rankMetricsRounds", "\n", "", ""]]}