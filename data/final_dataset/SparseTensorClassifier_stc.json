{"home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.__init__": [[81, 187], ["isinstance", "__init__.SparseTensorClassifier.connect", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier._sanitize", "__init__.SparseTensorClassifier._sanitize", "__init__.SparseTensorClassifier._encrypt", "__init__.SparseTensorClassifier._encrypt", "__init__.SparseTensorClassifier.set", "Exception", "sqlalchemy.create_engine", "__init__.SparseTensorClassifier.engine.url.get_dialect", "set().intersection", "__init__.SparseTensorClassifier.read_sql", "x[].tolist", "dict", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier.read_sql", "__init__.SparseTensorClassifier._defaultdict", "__init__.SparseTensorClassifier.set"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.connect", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._sanitize", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._sanitize", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.set", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.read_sql", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.read_sql", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.set"], ["def", "__init__", "(", "self", ",", "targets", ":", "List", "[", "str", "]", ",", "features", ":", "List", "[", "str", "]", "=", "None", ",", "collapse", ":", "bool", "=", "True", ",", "\n", "engine", ":", "Union", "[", "Engine", ",", "str", "]", "=", "\"sqlite://\"", ",", "prefix", ":", "str", "=", "\"stc\"", ",", "\n", "chunksize", ":", "int", "=", "100", ",", "cache", ":", "bool", "=", "True", ",", "\n", "power", ":", "float", "=", "0.5", ",", "balance", ":", "float", "=", "1", ",", "entropy", ":", "float", "=", "1", ",", "\n", "loss", ":", "str", "=", "'norm'", ",", "tol", ":", "float", "=", "1e-15", ",", "\n", "verbose", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "\n", "# validate", "\n", "        ", "if", "not", "targets", ":", "\n", "            ", "raise", "Exception", "(", "\"No target found. Set the target variable(s) with: targets=['t1','t2','...']\"", ")", "\n", "\n", "# engine", "\n", "", "if", "isinstance", "(", "engine", ",", "str", ")", ":", "\n", "            ", "self", ".", "engine", "=", "create_engine", "(", "engine", ",", "echo", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "engine", "=", "engine", "\n", "\n", "# db name", "\n", "", "self", ".", "db", "=", "self", ".", "engine", ".", "url", ".", "get_dialect", "(", ")", ".", "name", "\n", "\n", "# connect", "\n", "self", ".", "conn", "=", "None", "\n", "self", ".", "connect", "(", ")", "\n", "\n", "# fields", "\n", "self", ".", "name_field", "=", "\"name\"", "\n", "self", ".", "item_field", "=", "\"item\"", "\n", "self", ".", "dim_field", "=", "\"dimension\"", "\n", "self", ".", "value_field", "=", "\"value\"", "\n", "self", ".", "score_field", "=", "\"score\"", "\n", "\n", "# tables", "\n", "self", ".", "tmp_table", "=", "f\"{prefix}_tmp\"", "\n", "self", ".", "meta_table", "=", "f\"{prefix}_meta\"", "\n", "self", ".", "dim_table", "=", "f\"{prefix}_dims\"", "\n", "self", ".", "value_table", "=", "f\"{prefix}_values\"", "\n", "self", ".", "train_table", "=", "f\"{prefix}_train\"", "\n", "self", ".", "corpus_table", "=", "f\"{prefix}_corpus\"", "\n", "\n", "# collapse key", "\n", "self", ".", "collapse_key", "=", "\"features\"", "\n", "self", ".", "collapse", "=", "self", ".", "_meta", "(", "key", "=", "self", ".", "collapse_key", ",", "default", "=", "None", ")", "\n", "\n", "# sanitize dims", "\n", "dims", "=", "None", "\n", "targets", "=", "self", ".", "_sanitize", "(", "targets", ")", "\n", "features", "=", "self", ".", "_sanitize", "(", "features", ")", "\n", "if", "features", ":", "\n", "            ", "if", "set", "(", "features", ")", ".", "intersection", "(", "set", "(", "targets", ")", ")", ":", "\n", "                ", "raise", "Exception", "(", "\"Features should not contain any target variable\"", ")", "\n", "", "if", "collapse", ":", "\n", "                ", "dims", "=", "[", "self", ".", "collapse_key", "]", "+", "targets", "\n", "", "else", ":", "\n", "                ", "dims", "=", "features", "+", "targets", "\n", "\n", "# try to read the dimensions from the DB", "\n", "", "", "try", ":", "\n", "            ", "x", "=", "self", ".", "read_sql", "(", "f\"SELECT * FROM {self.dim_table}\"", ")", "\n", "self", ".", "dims", "=", "x", "[", "self", ".", "name_field", "]", ".", "tolist", "(", ")", "\n", "self", ".", "dims_map", "=", "dict", "(", "zip", "(", "x", "[", "self", ".", "name_field", "]", ",", "x", "[", "self", ".", "dim_field", "]", ")", ")", "\n", "\n", "# otherwise read from argument", "\n", "", "except", "SQLAlchemyError", ":", "\n", "            ", "if", "dims", ":", "\n", "                ", "self", ".", "dims", "=", "dims", "\n", "self", ".", "dims_map", "=", "dict", "(", "[", "(", "d", ",", "i", ")", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "dims", ")", "]", ")", "\n", "x", "=", "pd", ".", "DataFrame", "(", "[", "{", "self", ".", "name_field", ":", "k", ",", "self", ".", "dim_field", ":", "v", "}", "for", "k", ",", "v", "in", "self", ".", "dims_map", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "to_sql", "(", "x", ",", "self", ".", "dim_table", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"No dimensions provided and no dimensions found in DB\"", ")", "\n", "\n", "# check dimensions mismatch", "\n", "", "", "if", "dims", ":", "\n", "            ", "if", "set", "(", "dims", ")", "!=", "set", "(", "self", ".", "dims", ")", ":", "\n", "                ", "raise", "Exception", "(", "\"Dimensions found in DB different from the dimensions provided\"", ")", "\n", "\n", "# check collapse mismatch", "\n", "", "", "if", "self", ".", "collapse", "is", "None", ":", "\n", "            ", "self", ".", "collapse", "=", "features", "if", "collapse", "else", "[", "]", "\n", "self", ".", "_meta", "(", "key", "=", "self", ".", "collapse_key", ",", "value", "=", "self", ".", "collapse", ")", "\n", "", "elif", "collapse", "and", "features", ":", "\n", "            ", "if", "set", "(", "self", ".", "collapse", ")", "!=", "set", "(", "features", ")", ":", "\n", "                ", "raise", "Exception", "(", "\"Dimensions found in DB different from the dimensions provided\"", ")", "\n", "\n", "# init values map from DB or from scratch", "\n", "", "", "try", ":", "\n", "            ", "x", "=", "self", ".", "read_sql", "(", "f\"SELECT * FROM {self.value_table}\"", ")", "\n", "self", ".", "values_map", "=", "self", ".", "_defaultdict", "(", "zip", "(", "x", "[", "self", ".", "name_field", "]", ",", "x", "[", "self", ".", "value_field", "]", ")", ")", "\n", "", "except", "SQLAlchemyError", ":", "\n", "            ", "self", ".", "values_map", "=", "self", ".", "_defaultdict", "(", ")", "\n", "\n", "# encrypt", "\n", "", "self", ".", "dims", "=", "self", ".", "_encrypt", "(", "self", ".", "dims", ")", "\n", "self", ".", "targets", "=", "self", ".", "_encrypt", "(", "targets", ")", "\n", "\n", "# set params", "\n", "self", ".", "chunksize", "=", "chunksize", "\n", "self", ".", "cache", "=", "cache", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "balance", "=", "balance", "\n", "self", ".", "entropy", "=", "entropy", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "tol", "=", "tol", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "qtable", "=", "{", "}", "\n", "self", ".", "set", "(", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.connect": [[192, 204], ["__init__.SparseTensorClassifier.engine.connect", "__init__.SparseTensorClassifier.conn.connection.create_function", "__init__.SparseTensorClassifier.conn.connection.create_function"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.connect"], ["def", "connect", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Open the connection to the database.\n\n        \"\"\"", "\n", "\n", "self", ".", "conn", "=", "self", ".", "engine", ".", "connect", "(", ")", "\n", "\n", "# add POW & LOG support to SQLite", "\n", "if", "self", ".", "db", "==", "\"sqlite\"", ":", "\n", "            ", "self", ".", "conn", ".", "connection", ".", "create_function", "(", "\"POW\"", ",", "2", ",", "pow", ")", "\n", "self", ".", "conn", ".", "connection", ".", "create_function", "(", "\"LOG\"", ",", "1", ",", "np", ".", "log", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.close": [[205, 212], ["__init__.SparseTensorClassifier.conn.close"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.close"], ["", "", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Close the connection to the database.\n\n        \"\"\"", "\n", "\n", "self", ".", "conn", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.clean": [[213, 236], ["__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier.conn.execute", "sqlalchemy.text", "__init__.SparseTensorClassifier.close", "__init__.SparseTensorClassifier._DROP", "__init__.SparseTensorClassifier._DROP"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.close", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP"], ["", "def", "clean", "(", "self", ",", "deep", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Clean the database.\n\n        :param deep: If ``False`` (the default) drops temporary tables and cache. If ``True``, deletes all tables and\n                     closes the connection.\n        \"\"\"", "\n", "\n", "# drop tmp tables", "\n", "tmp", "=", "self", ".", "_meta", "(", "key", "=", "self", ".", "tmp_table", ")", "\n", "if", "tmp", "is", "not", "None", ":", "\n", "            ", "for", "table", "in", "tmp", ":", "\n", "                ", "self", ".", "_DROP", "(", "table", ")", "\n", "\n", "# clear cache", "\n", "", "", "self", ".", "conn", ".", "execute", "(", "text", "(", "f\"DELETE FROM {self.meta_table} WHERE {self.name_field} LIKE :like\"", ")", ",", "like", "=", "'cache-%'", ")", "\n", "\n", "# drop all tables and destroy connection", "\n", "if", "deep", ":", "\n", "            ", "for", "table", "in", "[", "self", ".", "meta_table", ",", "self", ".", "dim_table", ",", "self", ".", "value_table", ",", "self", ".", "train_table", ",", "self", ".", "corpus_table", "]", ":", "\n", "                ", "self", ".", "_DROP", "(", "table", ")", "\n", "", "self", ".", "engine", "=", "None", "\n", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.set": [[237, 265], ["params.keys", "params.items", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier.set"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.set"], ["", "", "def", "set", "(", "self", ",", "params", ":", "dict", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set parameters. Changing parameters does NOT need to re-fit STC. The fitting of STC is independent\n        from the parameters. In particular, also the ``targets`` can be changed on the fly (if initialized\n        with ``collapse=False``).\n\n        :param params: Dictionary of parameters to set in the form of ``{'param': value}``. Supported parameters are:\n                       ``targets``, ``chunksize``, ``cache``, ``power``, ``balance``, ``entropy``, ``loss``, ``tol``.\n\n        \"\"\"", "\n", "\n", "allow", "=", "{", "\"chunksize\"", ",", "\"cache\"", ",", "\"targets\"", ",", "\"power\"", ",", "\"balance\"", ",", "\"entropy\"", ",", "\"loss\"", ",", "\"tol\"", "}", "\n", "keys", "=", "params", ".", "keys", "(", ")", "\n", "extra", "=", "set", "(", "keys", ")", "-", "allow", "\n", "if", "len", "(", "extra", ")", ">", "0", ":", "\n", "            ", "ee", "=", "\", \"", ".", "join", "(", "extra", ")", "\n", "aa", "=", "\", \"", ".", "join", "(", "allow", ")", "\n", "raise", "Exception", "(", "f'The parameters \"{ee}\" cannot be set. Allowed parameters: \"{aa}\"'", ")", "\n", "\n", "", "def", "set_param", "(", "param", ",", "val", ")", ":", "\n", "            ", "if", "param", "in", "[", "\"targets\"", "]", ":", "\n", "                ", "val", "=", "self", ".", "_encrypt", "(", "self", ".", "_sanitize", "(", "val", ")", ")", "\n", "", "setattr", "(", "self", ",", "param", ",", "val", ")", "\n", "\n", "", "for", "param", ",", "val", "in", "params", ".", "items", "(", ")", ":", "\n", "            ", "set_param", "(", "param", ",", "val", ")", "\n", "\n", "", "self", ".", "qtable", "=", "self", ".", "_meta", "(", "key", "=", "self", ".", "_qkey", "(", ")", ",", "default", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.get": [[266, 288], ["isinstance", "getattr", "__init__.SparseTensorClassifier.get.get_param"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "params", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ")", "->", "Any", ":", "\n", "        ", "\"\"\"\n        Get parameters. Read the parameters provided upon initialization.\n        \n        :param params: Name(s) of the parameters to return.\n        :return: Value(s) of the parameters.\n        \"\"\"", "\"\"", "\n", "\n", "def", "get_param", "(", "param", ")", ":", "\n", "            ", "val", "=", "getattr", "(", "self", ",", "param", ")", "\n", "if", "param", "in", "[", "\"dims\"", ",", "\"targets\"", "]", ":", "\n", "                ", "val", "=", "self", ".", "_decrypt", "(", "val", ")", "\n", "", "return", "val", "\n", "\n", "", "if", "isinstance", "(", "params", ",", "str", ")", ":", "\n", "            ", "return", "get_param", "(", "params", ")", "\n", "\n", "", "val", "=", "{", "}", "\n", "for", "param", "in", "params", ":", "\n", "            ", "val", "[", "param", "]", "=", "get_param", "(", "param", ")", "\n", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.fit": [[289, 368], ["__init__.SparseTensorClassifier._stringify", "len", "__init__.SparseTensorClassifier._uids", "__init__.SparseTensorClassifier._progress", "range", "__init__.SparseTensorClassifier.clean", "enumerate", "__init__.SparseTensorClassifier._transform", "isinstance", "pandas.DataFrame", "__init__.SparseTensorClassifier.to_sql", "__init__.SparseTensorClassifier.update", "len", "item.items", "__init__.SparseTensorClassifier.set"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._stringify", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._uids", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.clean", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._transform", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.to_sql", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.set"], ["", "def", "fit", "(", "self", ",", "items", ":", "Union", "[", "List", "[", "dict", "]", ",", "pd", ".", "DataFrame", "]", ",", "keep_items", ":", "bool", "=", "None", ",", "if_exists", ":", "str", "=", "\"fail\"", ",", "\n", "clean", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Fit the training data. The data must contain both ``targets`` and ``features`` and must be structured\n        as described above. Supports incremental fit and it is ready to use in an online learning context.\n\n        :param items: The training data in JSON or tabular format as described above.\n        :param keep_items: If ``True``, stores the individual items seen during fit. This requires longer computational\n                           times but allows to estimate the policy with :meth:`stc.SparseTensorClassifier.learn`.\n                           By default, it is ``False`` when ``collapse=True`` or when only\n                           a single ``target`` and a single ``feature`` have been provided upon initialization. In this\n                           case, there is no need to estimate the policy and no need to store the individual items.\n        :param if_exists: The action to take if STC has already been fitted. One of ``fail``: raise exception,\n                          ``append``: incremental fit in online learning, ``replace``: re-fit from scratch.\n        :param clean: If ``True`` (the default) invalidates the cache used for prediction.\n        \"\"\"", "\n", "\n", "# clean cache", "\n", "if", "clean", ":", "\n", "            ", "self", ".", "clean", "(", ")", "\n", "\n", "# keep items", "\n", "", "if", "keep_items", "is", "None", ":", "\n", "            ", "keep_items", "=", "False", "if", "len", "(", "self", ".", "dims", ")", "==", "2", "else", "True", "\n", "\n", "# sanitize", "\n", "", "items_all", "=", "self", ".", "_stringify", "(", "items", ")", "\n", "\n", "# number of items", "\n", "n_all", "=", "len", "(", "items_all", ")", "\n", "\n", "# universal identifiers", "\n", "uids_all", "=", "self", ".", "_uids", "(", "n", "=", "n_all", ",", "data_table", "=", "self", ".", "train_table", ",", "if_exists", "=", "if_exists", ")", "\n", "\n", "# progress bar", "\n", "progress", "=", "self", ".", "_progress", "(", "total", "=", "n_all", ",", "status", "=", "\"Fitting\"", ")", "\n", "\n", "# fit chunks", "\n", "for", "c", "in", "range", "(", "0", ",", "n_all", ",", "self", ".", "chunksize", ")", ":", "\n", "\n", "# chunk", "\n", "            ", "items", "=", "items_all", "[", "c", ":", "c", "+", "self", ".", "chunksize", "]", "\n", "uids", "=", "uids_all", "[", "c", ":", "c", "+", "self", ".", "chunksize", "]", "\n", "\n", "# add key:value pairs to the dictionary", "\n", "new", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "items", ")", ":", "\n", "\n", "                ", "if", "isinstance", "(", "item", ",", "dict", ")", ":", "\n", "                    ", "dv", "=", "item", ".", "items", "(", ")", "\n", "", "else", ":", "\n", "                    ", "dv", "=", "[", "(", "item", ",", "items", ".", "iloc", "[", ":", ",", "i", "]", ".", "values", ")", "]", "\n", "\n", "", "for", "dim", ",", "values", "in", "dv", ":", "\n", "                    ", "try", ":", "\n", "                        ", "for", "v", "in", "set", "(", "values", ")", ":", "\n", "                            ", "n", "=", "len", "(", "self", ".", "values_map", ")", "\n", "m", "=", "self", ".", "values_map", ".", "setdefault", "(", "v", ",", "n", ")", "\n", "if", "n", "==", "m", ":", "\n", "                                ", "new", ".", "append", "(", "{", "self", ".", "name_field", ":", "v", ",", "self", ".", "value_field", ":", "m", "}", ")", "\n", "", "", "", "except", "KeyError", ":", "\n", "                        ", "pass", "\n", "\n", "# update the dictionary", "\n", "", "", "", "if", "new", ":", "\n", "                ", "x", "=", "pd", ".", "DataFrame", "(", "new", ")", "\n", "self", ".", "to_sql", "(", "x", ",", "self", ".", "value_table", ",", "if_exists", "=", "\"append\"", ")", "\n", "\n", "# transform", "\n", "", "self", ".", "_transform", "(", "items", "=", "items", ",", "uids", "=", "uids", ",", "dims", "=", "self", ".", "dims", ",", "\n", "data_table", "=", "self", ".", "train_table", "if", "keep_items", "else", "None", ",", "\n", "corpus_table", "=", "self", ".", "corpus_table", ",", "if_exists", "=", "if_exists", ")", "\n", "\n", "# append chunks", "\n", "if_exists", "=", "\"append\"", "\n", "\n", "# update progressbar", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "progress", ".", "update", "(", "c", "+", "self", ".", "chunksize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.explain": [[369, 397], ["__init__.SparseTensorClassifier._decrypt", "__init__.SparseTensorClassifier._decrypt", "__init__.SparseTensorClassifier.sort_values", "__init__.SparseTensorClassifier.set_index", "__init__.SparseTensorClassifier._encrypt", "__init__.SparseTensorClassifier._difflst", "__init__.SparseTensorClassifier._SELECT_cache", "__init__.SparseTensorClassifier._SELECT_robust", "__init__.SparseTensorClassifier.read_sql", "__init__.SparseTensorClassifier._sanitize", "__init__.SparseTensorClassifier._encrypt", "__init__.SparseTensorClassifier._flatten", "__init__.SparseTensorClassifier.policy"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_cache", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_robust", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.read_sql", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._sanitize", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._flatten", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.policy"], ["", "", "", "def", "explain", "(", "self", ",", "features", ":", "List", "[", "str", "]", "=", "None", ")", "->", "pd", ".", "DataFrame", ":", "\n", "        ", "\"\"\"\n        Global explainability. Compute the global contribution of each feature value to each target class label.\n\n        :param features: The features to use. By default, it uses the ``features`` used for prediction.\n        :return: Global explainability table giving the contribution of each feature value to each target class label.\n        \"\"\"", "\n", "\n", "# features", "\n", "if", "features", "is", "not", "None", ":", "\n", "            ", "features", "=", "self", ".", "_encrypt", "(", "self", ".", "_sanitize", "(", "features", ")", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "self", ".", "_difflst", "(", "self", ".", "_encrypt", "(", "self", ".", "_flatten", "(", "self", ".", "policy", "(", ")", "[", "0", "]", ")", ")", ",", "self", ".", "targets", ")", "\n", "\n", "# weights", "\n", "", "if", "self", ".", "cache", ":", "\n", "            ", "sql", "=", "self", ".", "_SELECT_cache", "(", "features", "=", "features", ",", "corpus_table", "=", "self", ".", "corpus_table", ")", "\n", "", "else", ":", "\n", "            ", "sql", "=", "self", ".", "_SELECT_robust", "(", "features", "=", "features", ",", "corpus_table", "=", "self", ".", "corpus_table", ")", "\n", "sql", "=", "f\"WITH {sql[1]} {sql[0]}\"", "\n", "\n", "# query", "\n", "", "t", "=", "self", ".", "_decrypt", "(", "self", ".", "targets", ")", "\n", "w", "=", "self", ".", "_decrypt", "(", "self", ".", "read_sql", "(", "sql", ")", ")", "\n", "w", ".", "sort_values", "(", "t", "+", "[", "self", ".", "score_field", "]", ",", "ascending", "=", "[", "True", "for", "_", "in", "self", ".", "targets", "]", "+", "[", "False", "]", ",", "inplace", "=", "True", ")", "\n", "\n", "# return", "\n", "return", "w", ".", "set_index", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.predict": [[398, 545], ["__init__.SparseTensorClassifier._stringify", "len", "__init__.SparseTensorClassifier._uids", "__init__.SparseTensorClassifier._encrypt", "__init__.SparseTensorClassifier._progress", "range", "__init__.SparseTensorClassifier._decrypt", "__init__.SparseTensorClassifier._decrypt", "x.append.set_index.sort_index", "warnings.warn", "__init__.SparseTensorClassifier._flatten", "__init__.SparseTensorClassifier._tmp_table", "__init__.SparseTensorClassifier._transform", "__init__.SparseTensorClassifier._DROP", "x.append.append.set_index().sort_values", "x.append.set_index().sort_values.groupby().agg", "pow", "__init__.SparseTensorClassifier.reset_index", "__init__.SparseTensorClassifier.pivot().fillna().sort_index", "__init__.SparseTensorClassifier.reindex", "__init__.SparseTensorClassifier.idxmax", "pandas.DataFrame", "x.append.append.set_index", "__init__.SparseTensorClassifier.set"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._stringify", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._uids", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._flatten", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._tmp_table", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._transform", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.set"], ["", "def", "predict", "(", "self", ",", "items", ":", "Union", "[", "List", "[", "dict", "]", ",", "pd", ".", "DataFrame", "]", ",", "policy", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ",", "probability", ":", "bool", "=", "True", ",", "\n", "explain", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "pd", ".", "DataFrame", ",", "Union", "[", "pd", ".", "DataFrame", ",", "None", "]", ",", "Union", "[", "pd", ".", "DataFrame", ",", "None", "]", "]", ":", "\n", "        ", "\"\"\"\n        Predict the test data. The data must be structured as described above and must contain the ``features``.\n        All additional keys are ignored (included ``targets``).\n        If all the attributes of an item are associated with features never seen in the training set, STC will not be\n        able to provide a prediction. In this case, a fallback mechanism is needed: the ``policy``. The ``policy`` is\n        a list of sets of features to use subsequently for prediction.\n        The algorithm starts with the first element of the policy (first set of features).\n        If no prediction could be produced, the second set of features is used, and so on.\n        If the policy ends with the empy list ``[]``, then all the item are guaranteed to be predicted\n        (eventually using no features, i.e., they will be attributed the most likely class in the trainig set).\n        If the policy does not end with the empy list ``[]``, some predictions may miss for some items.\n\n        :param items: The test data in JSON or tabular format as described above.\n        :param policy: List of lists of features to use for prediction, such as ``[[f1,f2],[f1],[]]``.\n                       First lists are applied first. By default, it uses the policy ``[[features],[]]`` when\n                       only one feature is provided upon initialization or when ``collapse=True``. In the other cases,\n                       it uses the policy ``[[features]]`` and raises a warning as some predictions may miss for some\n                       items. If a policy has been learnt with :meth:`stc.SparseTensorClassifier.learn`, it uses that\n                       policy instead.\n        :param probability: If ``True`` (the default) returns the probability of the target class label for\n                            each predicted item. If ``False``, and also ``explain=False``, returns the final\n                            classification only (saves computational time).\n        :param explain: If ``True`` (the default) returns the contribution of each feature to the target class label\n                        for each predicted item.\n        :return: Tuple of (classification, probability, explainability). The classification table contains the final\n                 predictions for each item. Missing predictions are encoded as ``NaN``. The probability table contains\n                 the probabilities of the target class labels for each predicted item. Labels that do not appear in\n                 this table are associated with zero probability. The explainability table provides the contribution of\n                 each feature to the target class label for each predicted item.\n        \"\"\"", "\n", "\n", "# sanitize", "\n", "items_all", "=", "self", ".", "_stringify", "(", "items", ")", "\n", "\n", "# number of items", "\n", "n_all", "=", "len", "(", "items_all", ")", "\n", "\n", "# universal identifiers", "\n", "uids_all", "=", "self", ".", "_uids", "(", "n", "=", "n_all", ")", "\n", "\n", "# policy", "\n", "if", "policy", "is", "None", ":", "\n", "            ", "policy", "=", "self", ".", "policy", "(", ")", "[", "0", "]", "\n", "\n", "# check policy", "\n", "", "if", "policy", "[", "-", "1", "]", ":", "\n", "            ", "warn", "(", "\"Bad policy.\"", "\n", "\" The last element of the policy is not empty and predictions may miss for some items.\"", "\n", "\" Use the method 'learn()' to learn the optimal policy or specify a custom policy ending with\"", "\n", "\" the empty list [].\"", ")", "\n", "\n", "# features", "\n", "", "features", "=", "self", ".", "_encrypt", "(", "self", ".", "_flatten", "(", "policy", ")", ")", "\n", "\n", "# progress bar", "\n", "progress", "=", "self", ".", "_progress", "(", "total", "=", "n_all", ",", "status", "=", "\"Predicting\"", ")", "\n", "\n", "# fit chunks", "\n", "x", "=", "None", "\n", "for", "c", "in", "range", "(", "0", ",", "n_all", ",", "self", ".", "chunksize", ")", ":", "\n", "\n", "# chunk", "\n", "            ", "items", "=", "items_all", "[", "c", ":", "c", "+", "self", ".", "chunksize", "]", "\n", "uids", "=", "uids_all", "[", "c", ":", "c", "+", "self", ".", "chunksize", "]", "\n", "\n", "# tmp table", "\n", "tmp_test", "=", "self", ".", "_tmp_table", "(", ")", "\n", "\n", "# transform data", "\n", "self", ".", "_transform", "(", "items", "=", "items", ",", "uids", "=", "uids", ",", "dims", "=", "features", ",", "data_table", "=", "tmp_test", ")", "\n", "\n", "# predict", "\n", "miss", "=", "None", "\n", "for", "p", "in", "policy", ":", "\n", "\n", "# features", "\n", "                ", "p", "=", "self", ".", "_encrypt", "(", "self", ".", "_sanitize", "(", "p", ")", ")", "\n", "\n", "# predict query", "\n", "sql_select", ",", "sql_with", "=", "self", ".", "_SELECT_predict", "(", "\n", "features", "=", "p", ",", "corpus_table", "=", "self", ".", "corpus_table", ",", "data_table", "=", "tmp_test", ",", "\n", "ids", "=", "miss", ",", "probability", "=", "probability", ",", "explain", "=", "explain", ",", "cache", "=", "self", ".", "cache", ")", "\n", "sql", "=", "f\"WITH {sql_with} {sql_select}\"", "\n", "\n", "# append to explanatory table", "\n", "if", "x", "is", "None", ":", "\n", "                    ", "x", "=", "self", ".", "read_sql", "(", "sql", ")", "\n", "", "else", ":", "\n", "                    ", "x", "=", "x", ".", "append", "(", "self", ".", "read_sql", "(", "sql", ")", ")", "\n", "\n", "# missing predictions", "\n", "", "miss", "=", "\",\"", ".", "join", "(", "map", "(", "str", ",", "set", "(", "uids", ")", "-", "set", "(", "x", "[", "self", ".", "item_field", "]", ".", "values", ")", ")", ")", "\n", "if", "not", "miss", ":", "\n", "                    ", "break", "\n", "\n", "# clean", "\n", "", "", "self", ".", "_DROP", "(", "tmp_test", ")", "\n", "\n", "# update progressbar", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "progress", ".", "update", "(", "c", "+", "self", ".", "chunksize", ")", "\n", "\n", "# back to original dims and values", "\n", "", "", "t", "=", "self", ".", "_decrypt", "(", "self", ".", "targets", ")", "\n", "x", "=", "self", ".", "_decrypt", "(", "x", ")", "\n", "\n", "# explainability -> probability", "\n", "e", ",", "p", "=", "None", ",", "None", "\n", "if", "explain", ":", "\n", "# explainability", "\n", "            ", "e", "=", "x", ".", "set_index", "(", "[", "self", ".", "item_field", "]", "+", "t", ")", ".", "sort_values", "(", "\n", "[", "self", ".", "item_field", "]", "+", "t", "+", "[", "self", ".", "score_field", "]", ",", "ascending", "=", "[", "True", "]", "+", "[", "True", "for", "_", "in", "t", "]", "+", "[", "False", "]", ")", "\n", "# probability", "\n", "p", "=", "e", ".", "groupby", "(", "[", "self", ".", "item_field", "]", "+", "t", ")", ".", "agg", "(", "{", "self", ".", "score_field", ":", "'sum'", "}", ")", "\n", "p", "[", "self", ".", "score_field", "]", "=", "pow", "(", "p", "[", "self", ".", "score_field", "]", ",", "1.", "/", "self", ".", "power", ")", "\n", "p", "[", "self", ".", "score_field", "]", "=", "p", "[", "self", ".", "score_field", "]", "/", "p", ".", "groupby", "(", "self", ".", "item_field", ")", "[", "self", ".", "score_field", "]", ".", "transform", "(", "'sum'", ")", "\n", "p", ".", "reset_index", "(", "inplace", "=", "True", ")", "\n", "", "elif", "probability", ":", "\n", "# probability", "\n", "            ", "p", "=", "x", "\n", "\n", "# probability -> classification", "\n", "", "if", "p", "is", "not", "None", ":", "\n", "# probability", "\n", "            ", "p", "=", "p", ".", "pivot", "(", "index", "=", "self", ".", "item_field", ",", "columns", "=", "t", ",", "values", "=", "self", ".", "score_field", ")", ".", "fillna", "(", "0", ")", ".", "sort_index", "(", ")", "\n", "p", "=", "p", ".", "reindex", "(", "sorted", "(", "p", ".", "columns", ")", ",", "axis", "=", "1", ")", "\n", "# classification", "\n", "c", "=", "p", ".", "idxmax", "(", "axis", "=", "1", ")", "\n", "c", "=", "pd", ".", "DataFrame", "(", "[", "i", "for", "i", "in", "c", ".", "values", "]", ",", "columns", "=", "t", ",", "index", "=", "c", ".", "index", ")", "\n", "", "else", ":", "\n", "# classification", "\n", "            ", "c", "=", "x", ".", "set_index", "(", "self", ".", "item_field", ")", "\n", "\n", "# fill missing predictions", "\n", "", "miss", "=", "set", "(", "uids_all", ")", "-", "set", "(", "c", ".", "index", ")", "\n", "if", "miss", ":", "\n", "            ", "n", "=", "range", "(", "len", "(", "t", ")", ")", "\n", "for", "m", "in", "miss", ":", "\n", "                ", "c", ".", "loc", "[", "m", "]", "=", "[", "np", ".", "nan", "for", "_", "in", "n", "]", "\n", "\n", "# sort index", "\n", "", "", "c", ".", "sort_index", "(", "inplace", "=", "True", ")", "\n", "\n", "# return", "\n", "return", "c", ",", "p", ",", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.learn": [[546, 704], ["__init__.SparseTensorClassifier._difflst", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier.read_sql", "time.time.time", "time.time.time", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier.policy", "Exception", "Exception", "__init__.SparseTensorClassifier._encrypt", "__init__.SparseTensorClassifier._train_test_split", "len", "__init__.SparseTensorClassifier._tmp_table", "__init__.SparseTensorClassifier._SELECT_marginal", "__init__.SparseTensorClassifier._CREATE", "__init__.SparseTensorClassifier._DROP", "__init__.SparseTensorClassifier._DROP", "time.time.time", "__init__.SparseTensorClassifier._sanitize", "map", "map", "__init__.SparseTensorClassifier._progress", "__init__.SparseTensorClassifier._next", "__init__.SparseTensorClassifier._actions", "__init__.SparseTensorClassifier._SELECT_loss", "__init__.SparseTensorClassifier._tmp_table", "__init__.SparseTensorClassifier._CREATE", "time.time.time", "__init__.SparseTensorClassifier._qkey", "__init__.SparseTensorClassifier._SELECT_loss", "__init__.SparseTensorClassifier.conn.execute().scalar", "__init__.SparseTensorClassifier._hash", "numpy.array", "time.time.time", "__init__.SparseTensorClassifier._DROP", "len", "__init__.SparseTensorClassifier._action", "__init__.SparseTensorClassifier.step", "len", "__init__.SparseTensorClassifier.conn.execute", "len"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.read_sql", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.policy", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._train_test_split", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._tmp_table", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_marginal", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._sanitize", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._next", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._actions", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_loss", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._tmp_table", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._qkey", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_loss", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._hash", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._action"], ["", "def", "learn", "(", "self", ",", "test_size", ":", "float", "=", "None", ",", "train_size", ":", "float", "=", "None", ",", "stratify", ":", "bool", "=", "True", ",", "\n", "priority", ":", "List", "[", "str", "]", "=", "None", ",", "max_features", ":", "int", "=", "0", ",", "max_actions", ":", "int", "=", "0", ",", "\n", "max_iter", ":", "int", "=", "1", ",", "max_runtime", ":", "int", "=", "0", ",", "random_state", ":", "bool", "=", "None", ")", "->", "Tuple", "[", "List", "[", "List", "[", "str", "]", "]", ",", "List", "[", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Learn the ``policy``. Learn the ``policy`` via reinforcement learning by optimizing the ``loss`` function\n        on cross validation. Before learning, STC must be fitted with ``keep_items=True``. Then, proceeds as follows.\n        For each episode, split the train set in train-validation sets.\n        Start with a set of empy features and compute the reward of the state (-loss).\n        Add the value to the Q-table. Explore all the next states generated by adding 1 feature to the empty set.\n        Compute the values of the states. Add to the Q-table. Select the state with the maximum value.\n        Move to that state. Explore all the next states generated by adding 1 feature to the current set of features...\n        Stop when all features are used or when the value of all the next states is less than the value of the current\n        state.\n\n        :param test_size: Train-test cross validation split (percentage of the training sample).\n        :param train_size: Train-test cross validation split (percentage of the training sample).\n        :param stratify: If ``True``, the folds are made by preserving the percentage of samples for each class.\n        :param priority: List of features to learn first.\n        :param max_features: Number of maximum features to return in the policy. If 0, no limit.\n        :param max_actions: Number of maximum states to explore at once. If 0, no limit.\n        :param max_iter: Maximum number of iterations to train the algorithm. If 0, no limit.\n        :param max_runtime: How long to train the algorithm, in seconds. If 0, no time limit.\n        :param random_state: Random number generator seed, used for reproducible output across function calls.\n        :return: Tuple of (policy, loss). The policy is saved internally and used by default in\n                 :meth:`stc.SparseTensorClassifier.predict`. The second element of the tuple provides the loss\n                 associated with the policy.\n        \"\"\"", "\n", "\n", "# validate", "\n", "if", "max_iter", "<=", "0", "and", "max_runtime", "<=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Cannot set both 'max_iter' and 'max_runtime' to 0. The algorithm would run endlessly.\"", ")", "\n", "", "if", "max_runtime", ">", "0", "and", "random_state", "is", "not", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Cannot set 'random_state' with runtime limit. This would lead to undesired results on \"", "\n", "\"machines with different computational resources. Set 'max_runtime=0' and use 'max_iter' \"", "\n", "\"instead.\"", ")", "\n", "\n", "# features", "\n", "", "features", "=", "self", ".", "_difflst", "(", "self", ".", "dims", ",", "self", ".", "targets", ")", "\n", "\n", "# priority", "\n", "if", "priority", "is", "not", "None", ":", "\n", "            ", "priority", "=", "self", ".", "_encrypt", "(", "self", ".", "_sanitize", "(", "priority", ")", ")", "\n", "\n", "# items", "\n", "", "t", "=", "self", ".", "_COLS", "(", "self", ".", "train_table", ",", "self", ".", "targets", ")", "\n", "items", "=", "self", ".", "read_sql", "(", "\n", "f\"SELECT DISTINCT {self.item_field}, {t} FROM {self.train_table} ORDER BY {self.item_field}, {t}\"", ")", "\n", "\n", "# start countdown", "\n", "tic", "=", "time", "(", ")", "\n", "toc", "=", "time", "(", ")", "\n", "iteration", "=", "0", "\n", "while", "(", "toc", "-", "tic", "<", "max_runtime", "or", "max_runtime", "<=", "0", ")", "and", "(", "iteration", "<", "max_iter", "or", "max_iter", "<=", "0", ")", ":", "\n", "\n", "# train-test split", "\n", "            ", "train", ",", "test", "=", "self", ".", "_train_test_split", "(", "\n", "items", ",", "test_size", "=", "test_size", ",", "train_size", "=", "train_size", ",", "stratify", "=", "stratify", ",", "random_state", "=", "random_state", ")", "\n", "\n", "# unset random_state", "\n", "random_state", "=", "None", "\n", "\n", "# convert to ids", "\n", "ids_train", "=", "\",\"", ".", "join", "(", "map", "(", "str", ",", "train", ")", ")", "\n", "ids_test", "=", "\",\"", ".", "join", "(", "map", "(", "str", ",", "test", ")", ")", "\n", "\n", "# number of test items", "\n", "n", "=", "len", "(", "test", ")", "\n", "\n", "# fallback and corpus tables", "\n", "tmp_state", "=", "None", "\n", "tmp_corpus", "=", "self", ".", "_tmp_table", "(", ")", "\n", "\n", "# create the corpus from the train set", "\n", "sql_select", "=", "self", ".", "_SELECT_marginal", "(", "dims", "=", "self", ".", "dims", ",", "table", "=", "self", ".", "train_table", ",", "ids", "=", "ids_train", ",", "corpus", "=", "True", ")", "\n", "self", ".", "_CREATE", "(", "table", "=", "tmp_corpus", ",", "sql_select", "=", "sql_select", ")", "\n", "\n", "# start with an empty policy", "\n", "state", "=", "[", "]", "\n", "actions", "=", "[", "[", "]", "]", "\n", "while", "toc", "-", "tic", "<", "max_runtime", "or", "max_runtime", "<=", "0", ":", "\n", "\n", "# progress bar", "\n", "                ", "progress", "=", "self", ".", "_progress", "(", "\n", "total", "=", "len", "(", "actions", ")", ",", "status", "=", "f\"Learning iteration {iteration+1} state {len(state)}\"", ")", "\n", "\n", "# explore all actions", "\n", "for", "a", "in", "actions", ":", "\n", "\n", "# compute the distance in the next state. Use current distances as fallback", "\n", "                    ", "loss", "=", "self", ".", "_SELECT_loss", "(", "\n", "features", "=", "a", "+", "state", "[", "0", "]", "if", "state", "else", "a", ",", "corpus_table", "=", "tmp_corpus", ",", "\n", "data_table", "=", "self", ".", "train_table", ",", "fallback_table", "=", "tmp_state", ",", "ids", "=", "ids_test", ")", "\n", "\n", "# compute the reward", "\n", "reward", "=", "self", ".", "conn", ".", "execute", "(", "(", "\n", "f\"WITH {loss[1]}, loss AS ({loss[0]}) \"", "\n", "f\"SELECT -SUM({self.score_field}) AS {self.score_field} \"", "\n", "f\"FROM loss\"", "\n", ")", ")", ".", "scalar", "(", ")", "\n", "\n", "# add the reward to the Q-table", "\n", "key", "=", "self", ".", "_hash", "(", "self", ".", "_action", "(", "state", ",", "a", ")", ")", "\n", "val", "=", "np", ".", "array", "(", "[", "n", ",", "reward", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "if", "key", "in", "self", ".", "qtable", ":", "\n", "                        ", "self", ".", "qtable", "[", "key", "]", "+=", "val", "\n", "", "else", ":", "\n", "                        ", "self", ".", "qtable", "[", "key", "]", "=", "val", "\n", "\n", "# update progressbar", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                        ", "progress", ".", "step", "(", ")", "\n", "\n", "# check runtime", "\n", "", "toc", "=", "time", "(", ")", "\n", "if", "toc", "-", "tic", ">", "max_runtime", ">", "0", ":", "\n", "                        ", "break", "\n", "\n", "# select the best action and move to the next state", "\n", "", "", "state", ",", "action", ",", "value", "=", "self", ".", "_next", "(", "state", "=", "state", ",", "actions", "=", "actions", ")", "\n", "if", "action", "is", "None", "or", "0", "<", "max_features", "<=", "len", "(", "state", "[", "0", "]", ")", ":", "\n", "                    ", "break", "\n", "\n", "# generate actions for the state", "\n", "", "actions", "=", "self", ".", "_actions", "(", "state", "=", "state", ",", "priority", "=", "priority", ",", "max_actions", "=", "max_actions", ")", "\n", "if", "actions", "is", "None", ":", "\n", "                    ", "break", "\n", "\n", "# compute the loss in the state", "\n", "", "loss", "=", "self", ".", "_SELECT_loss", "(", "\n", "features", "=", "state", "[", "0", "]", ",", "corpus_table", "=", "tmp_corpus", ",", "data_table", "=", "self", ".", "train_table", ",", "\n", "fallback_table", "=", "tmp_state", ",", "ids", "=", "ids_test", ")", "\n", "\n", "# store the distances", "\n", "tmp_fallback", "=", "self", ".", "_tmp_table", "(", ")", "\n", "self", ".", "_CREATE", "(", "table", "=", "tmp_fallback", ",", "sql_with", "=", "loss", "[", "1", "]", ",", "sql_select", "=", "loss", "[", "0", "]", ")", "\n", "\n", "# drop previous loss", "\n", "tmp_fallback", ",", "tmp_state", "=", "tmp_state", ",", "tmp_fallback", "\n", "if", "tmp_fallback", "is", "not", "None", ":", "\n", "                    ", "self", ".", "_DROP", "(", "tmp_fallback", ")", "\n", "\n", "# check runtime", "\n", "", "toc", "=", "time", "(", ")", "\n", "\n", "# clean DB", "\n", "", "self", ".", "_DROP", "(", "tmp_state", ")", "\n", "self", ".", "_DROP", "(", "tmp_corpus", ")", "\n", "\n", "# update runtime", "\n", "toc", "=", "time", "(", ")", "\n", "iteration", "+=", "1", "\n", "\n", "# store the Q-table in the DB", "\n", "", "self", ".", "_meta", "(", "key", "=", "self", ".", "_qkey", "(", ")", ",", "value", "=", "self", ".", "qtable", ")", "\n", "\n", "# return the best policy", "\n", "return", "self", ".", "policy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.policy": [[705, 736], ["range", "__init__.SparseTensorClassifier._next", "__init__.SparseTensorClassifier._difflst", "len", "__init__.SparseTensorClassifier._decrypt", "len"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._next", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt"], ["", "def", "policy", "(", "self", ")", "->", "Tuple", "[", "List", "[", "List", "[", "str", "]", "]", ",", "List", "[", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Get the ``policy``.\n\n        :return: Output of :meth:`stc.SparseTensorClassifier.learn`\n        \"\"\"", "\n", "\n", "# init state and values", "\n", "state", ",", "values", "=", "[", "]", ",", "[", "]", "\n", "\n", "# generate policy", "\n", "while", "True", ":", "\n", "            ", "state", ",", "action", ",", "value", "=", "self", ".", "_next", "(", "state", "=", "state", ")", "\n", "if", "action", "is", "None", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "values", "=", "[", "value", "]", "+", "values", "\n", "\n", "# fallback if no policy: use all features", "\n", "", "", "if", "not", "state", ":", "\n", "            ", "features", "=", "self", ".", "_difflst", "(", "self", ".", "dims", ",", "self", ".", "targets", ")", "\n", "state", "=", "[", "features", "]", "\n", "if", "len", "(", "features", ")", "==", "1", ":", "\n", "                ", "state", "+=", "[", "[", "]", "]", "\n", "\n", "# map policy to original dimensions", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "state", ")", ")", ":", "\n", "            ", "state", "[", "i", "]", "=", "self", ".", "_decrypt", "(", "state", "[", "i", "]", ")", "\n", "\n", "# return policy and values", "\n", "", "return", "state", ",", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.read_sql": [[737, 746], ["pandas.read_sql"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.read_sql"], ["", "def", "read_sql", "(", "self", ",", "sql", ":", "str", ")", "->", "pd", ".", "DataFrame", ":", "\n", "        ", "\"\"\"\n        Read SQL query into a pandas ``DataFrame``.\n\n        :param sql: SQL query to SELECT data.\n        :return: Output of the SQL query.\n        \"\"\"", "\n", "\n", "return", "pd", ".", "read_sql", "(", "sql", ",", "self", ".", "conn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.to_sql": [[747, 778], ["pandas.DataFrame.to_sql", "pandas.DataFrame", "pandas.DataFrame.to_csv", "conn.execute", "list", "pandas.DataFrame", "pandas.DataFrame.to_csv", "conn.execute", "list", "len"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.to_sql"], ["", "def", "to_sql", "(", "self", ",", "x", ":", "pd", ".", "DataFrame", ",", "table", ":", "str", ",", "if_exists", ":", "str", "=", "'fail'", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write a pandas ``DataFrame`` into a SQL table.\n\n        :param x: A pandas ``DataFrame`` to write into ``table``.\n        :param table: The name of the table to write ``x`` into.\n        :param if_exists: The action to take when the table already exists. One of ``fail``: raise exception,\n                          ``append``: insert new values to the existing table, ``replace``: drop the table before\n                          inserting new values.\n        \"\"\"", "\n", "\n", "def", "csv_insert", "(", "table", ",", "conn", ",", "keys", ",", "data_iter", ")", ":", "\n", "            ", "x", "=", "pd", ".", "DataFrame", "(", "list", "(", "data_iter", ")", ")", "\n", "c", "=", "\",\"", ".", "join", "(", "keys", ")", "\n", "v", "=", "x", ".", "to_csv", "(", "line_terminator", "=", "\"),(\"", ",", "header", "=", "False", ",", "index", "=", "False", ",", "quoting", "=", "csv", ".", "QUOTE_NONNUMERIC", ",", "quotechar", "=", "\"'\"", ")", "\n", "sql", "=", "f\"INSERT INTO {table.name} ({c}) VALUES({v})\"", "\n", "conn", ".", "execute", "(", "sql", "[", ":", "-", "3", "]", ")", "\n", "\n", "", "if", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "def", "csv_insert", "(", "table", ",", "conn", ",", "keys", ",", "data_iter", ")", ":", "\n", "                ", "x", "=", "pd", ".", "DataFrame", "(", "list", "(", "data_iter", ")", ")", "\n", "c", "=", "\",\"", ".", "join", "(", "keys", ")", "\n", "t", "=", "f\") INTO {table.name} ({c}) VALUES (\"", "\n", "v", "=", "x", ".", "to_csv", "(", "line_terminator", "=", "t", ",", "header", "=", "False", ",", "index", "=", "False", ",", "quoting", "=", "csv", ".", "QUOTE_NONNUMERIC", ",", "quotechar", "=", "\"'\"", ")", "\n", "sql", "=", "f\"INSERT ALL INTO {table.name} ({c}) VALUES({v})\"", "\n", "sql", "=", "sql", "[", ":", "-", "len", "(", "t", ")", "]", "\n", "sql", "+=", "\"SELECT * FROM DUAL\"", "\n", "conn", ".", "execute", "(", "sql", ")", "\n", "\n", "# SQL Server requires chunksize=1000: maximum allowed rows in bulk insert.", "\n", "", "", "x", ".", "to_sql", "(", "table", ",", "self", ".", "conn", ",", "if_exists", "=", "if_exists", ",", "index", "=", "False", ",", "method", "=", "csv_insert", ",", "chunksize", "=", "1000", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt": [[783, 798], ["isinstance", "pandas.DataFrame", "x[].map", "str", "str"], "methods", ["None"], ["def", "_encrypt", "(", "self", ",", "x", ":", "Union", "[", "List", "[", "str", "]", ",", "pd", ".", "DataFrame", "]", ")", "->", "Union", "[", "List", "[", "str", "]", ",", "pd", ".", "DataFrame", "]", ":", "\n", "        ", "\"\"\"Encryption\"\"\"", "\n", "\n", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "'d'", "+", "str", "(", "self", ".", "dims_map", "[", "d", "]", ")", "for", "d", "in", "x", "]", "\n", "\n", "", "y", "=", "pd", ".", "DataFrame", "(", ")", "\n", "for", "d", "in", "x", ".", "columns", ":", "\n", "            ", "if", "d", "in", "self", ".", "dims_map", ":", "\n", "                ", "i", "=", "self", ".", "dims_map", "[", "d", "]", "\n", "y", "[", "'d'", "+", "str", "(", "i", ")", "]", "=", "x", "[", "d", "]", ".", "map", "(", "self", ".", "values_map", ")", "\n", "", "else", ":", "\n", "                ", "y", "[", "d", "]", "=", "x", "[", "d", "]", "\n", "\n", "", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt": [[799, 818], ["isinstance", "pandas.DataFrame", "str", "__init__.SparseTensorClassifier.dims_map.items", "__init__.SparseTensorClassifier.values_map.items", "x[].map"], "methods", ["None"], ["", "def", "_decrypt", "(", "self", ",", "x", ":", "Union", "[", "List", "[", "str", "]", ",", "pd", ".", "DataFrame", "]", ")", "->", "Union", "[", "List", "[", "str", "]", ",", "pd", ".", "DataFrame", "]", ":", "\n", "        ", "\"\"\"Decryption\"\"\"", "\n", "\n", "dinv", "=", "{", "'d'", "+", "str", "(", "d", ")", ":", "k", "for", "k", ",", "d", "in", "self", ".", "dims_map", ".", "items", "(", ")", "}", "\n", "\n", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "dinv", "[", "d", "]", "for", "d", "in", "x", "]", "\n", "\n", "", "vinv", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "values_map", ".", "items", "(", ")", "}", "\n", "\n", "y", "=", "pd", ".", "DataFrame", "(", ")", "\n", "for", "i", "in", "x", ".", "columns", ":", "\n", "            ", "if", "i", "in", "dinv", ":", "\n", "                ", "d", "=", "dinv", "[", "i", "]", "\n", "y", "[", "d", "]", "=", "x", "[", "i", "]", ".", "map", "(", "vinv", ")", "\n", "", "else", ":", "\n", "                ", "y", "[", "i", "]", "=", "x", "[", "i", "]", "\n", "\n", "", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._flatten": [[819, 826], ["__init__.SparseTensorClassifier._sanitize", "all", "Exception", "isinstance"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._sanitize"], ["", "def", "_flatten", "(", "self", ",", "policy", ":", "List", "[", "List", "[", "str", "]", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"Convert a list of lists to a list\"\"\"", "\n", "\n", "if", "not", "all", "(", "isinstance", "(", "dims", ",", "list", ")", "for", "dims", "in", "policy", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid policy. Policy must be a list of lists: [[],[],...,[]]\"", ")", "\n", "\n", "", "return", "self", ".", "_sanitize", "(", "[", "dim", "for", "dims", "in", "policy", "for", "dim", "in", "dims", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._sanitize": [[827, 838], ["isinstance", "__init__.SparseTensorClassifier._unique", "isinstance", "list", "str"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique"], ["", "def", "_sanitize", "(", "self", ",", "dims", ":", "List", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"Return list of strings with unique elements in the same order\"\"\"", "\n", "\n", "if", "dims", "is", "None", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "isinstance", "(", "dims", ",", "str", ")", ":", "\n", "            ", "dims", "=", "[", "dims", "]", "\n", "", "if", "not", "isinstance", "(", "dims", ",", "list", ")", ":", "\n", "            ", "dims", "=", "list", "(", "dims", ")", "\n", "\n", "", "return", "self", ".", "_unique", "(", "[", "str", "(", "d", ")", "for", "d", "in", "dims", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique": [[839, 848], ["u.append"], "methods", ["None"], ["", "def", "_unique", "(", "self", ",", "x", ":", "List", ")", "->", "List", ":", "\n", "        ", "\"\"\"Drop duplicates from list and maintain the order\"\"\"", "\n", "\n", "u", "=", "[", "]", "\n", "for", "i", "in", "x", ":", "\n", "            ", "if", "i", "not", "in", "u", ":", "\n", "                ", "u", ".", "append", "(", "i", ")", "\n", "\n", "", "", "return", "u", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst": [[849, 853], ["None"], "methods", ["None"], ["", "def", "_difflst", "(", "self", ",", "x", ":", "List", ",", "y", ":", "List", ")", "->", "List", ":", "\n", "        ", "\"\"\"List difference\"\"\"", "\n", "\n", "return", "[", "i", "for", "i", "in", "x", "if", "i", "not", "in", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._stringify": [[854, 890], ["isinstance", "items[].astype.columns.astype", "items[].astype", "__init__.SparseTensorClassifier._decrypt", "items[].astype.iterrows", "__init__.SparseTensorClassifier._decrypt", "data.items", "json.append", "data.items", "json.append", "str", "isinstance", "str", "str"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt"], ["", "def", "_stringify", "(", "self", ",", "items", ":", "Union", "[", "List", "[", "dict", "]", ",", "pd", ".", "DataFrame", "]", ")", "->", "Union", "[", "List", "[", "dict", "]", ",", "pd", ".", "DataFrame", "]", ":", "\n", "        ", "\"\"\"Convert keys and values to string\"\"\"", "\n", "\n", "# dims", "\n", "dims", "=", "self", ".", "_decrypt", "(", "self", ".", "targets", ")", "+", "self", ".", "collapse", "if", "self", ".", "collapse", "else", "self", ".", "_decrypt", "(", "self", ".", "dims", ")", "\n", "\n", "# json data", "\n", "if", "isinstance", "(", "items", ",", "list", ")", ":", "\n", "            ", "json", "=", "[", "]", "\n", "for", "data", "in", "items", ":", "\n", "                ", "item", "=", "{", "self", ".", "collapse_key", ":", "[", "]", "}", "if", "self", ".", "collapse", "else", "{", "}", "\n", "for", "key", ",", "val", "in", "data", ".", "items", "(", ")", ":", "\n", "                    ", "key", ",", "val", "=", "str", "(", "key", ")", ",", "val", "if", "isinstance", "(", "val", ",", "list", ")", "else", "[", "val", "]", "\n", "if", "key", "in", "self", ".", "collapse", ":", "\n", "                        ", "item", "[", "self", ".", "collapse_key", "]", "+=", "[", "key", "+", "\": \"", "+", "str", "(", "v", ")", "for", "v", "in", "val", "]", "\n", "", "elif", "key", "in", "dims", ":", "\n", "                        ", "item", "[", "key", "]", "=", "[", "str", "(", "v", ")", "for", "v", "in", "val", "]", "\n", "", "", "json", ".", "append", "(", "item", ")", "\n", "", "return", "json", "\n", "\n", "# tabular data", "\n", "", "items", ".", "columns", "=", "items", ".", "columns", ".", "astype", "(", "str", ")", "\n", "items", "=", "items", "[", "dims", "]", ".", "astype", "(", "str", ")", "\n", "if", "self", ".", "collapse", ":", "\n", "            ", "json", "=", "[", "]", "\n", "for", "_", ",", "data", "in", "items", ".", "iterrows", "(", ")", ":", "\n", "                ", "item", "=", "{", "self", ".", "collapse_key", ":", "[", "]", "}", "\n", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "                    ", "if", "k", "in", "self", ".", "collapse", ":", "\n", "                        ", "item", "[", "self", ".", "collapse_key", "]", "+=", "[", "k", "+", "\": \"", "+", "v", "]", "\n", "", "else", ":", "\n", "                        ", "item", "[", "k", "]", "=", "[", "v", "]", "\n", "", "", "json", ".", "append", "(", "item", ")", "\n", "", "return", "json", "\n", "\n", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ckey": [[891, 897], ["hashlib.md5().hexdigest", "sorted", "sorted", "hashlib.md5", "map"], "methods", ["None"], ["", "def", "_ckey", "(", "self", ",", "corpus_table", ":", "str", ",", "features", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"Generate key for cache\"\"\"", "\n", "\n", "key", "=", "sorted", "(", "self", ".", "targets", ")", "+", "[", "corpus_table", "]", "+", "sorted", "(", "features", ")", "+", "[", "self", ".", "power", ",", "self", ".", "balance", ",", "self", ".", "entropy", "]", "\n", "\n", "return", "\"cache-\"", "+", "md5", "(", "\"#\"", ".", "join", "(", "map", "(", "str", ",", "key", ")", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._qkey": [[898, 904], ["sorted", "hashlib.md5().hexdigest", "hashlib.md5", "map"], "methods", ["None"], ["", "def", "_qkey", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"Generate key for qtable\"\"\"", "\n", "\n", "key", "=", "sorted", "(", "self", ".", "targets", ")", "+", "[", "self", ".", "power", ",", "self", ".", "balance", ",", "self", ".", "entropy", ",", "self", ".", "loss", ",", "self", ".", "tol", "]", "\n", "\n", "return", "\"qtable-\"", "+", "md5", "(", "\"#\"", ".", "join", "(", "map", "(", "str", ",", "key", ")", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._hash": [[905, 916], ["tuple", "frozenset"], "methods", ["None"], ["", "def", "_hash", "(", "self", ",", "state", ":", "List", "[", "List", "[", "str", "]", "]", ")", "->", "Tuple", "[", "FrozenSet", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"Hash a state\n\n        A state represents a policy. The order of the lists of features composing the policy does count, but the order\n        of the features in each list does not. Generate the corresponding hash.\n\n        :param state: a policy, list of lists of features\n        :return: hashable object, tuple of frozensets\n        \"\"\"", "\n", "\n", "return", "tuple", "(", "[", "frozenset", "(", "s", ")", "for", "s", "in", "state", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._action": [[917, 928], ["None"], "methods", ["None"], ["", "def", "_action", "(", "self", ",", "state", ":", "List", "[", "List", "[", "str", "]", "]", ",", "action", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"Do action and generate the new set of features\n\n        Add the features to the last policy and return the list of features.\n\n        :param state: a policy, list of lists of features\n        :param action: list of features\n        :return: list of features\n        \"\"\"", "\n", "\n", "return", "[", "action", "+", "state", "[", "0", "]", "]", "+", "state", "if", "state", "else", "[", "action", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._actions": [[929, 972], ["__init__.SparseTensorClassifier._difflst", "len", "__init__.SparseTensorClassifier._action", "rank.sort", "__init__.SparseTensorClassifier._difflst", "__init__.SparseTensorClassifier._difflst", "__init__.SparseTensorClassifier._hash"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._action", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._hash"], ["", "def", "_actions", "(", "self", ",", "state", ":", "List", "[", "List", "[", "str", "]", "]", ",", "priority", ":", "List", "[", "str", "]", "=", "None", ",", "max_actions", ":", "int", "=", "0", ")", "->", "Union", "[", "List", "[", "List", "[", "str", "]", "]", ",", "None", "]", ":", "\n", "        ", "\"\"\"Generate actions for the current state\"\"\"", "\n", "\n", "# features", "\n", "features", "=", "self", ".", "_difflst", "(", "self", ".", "dims", ",", "self", ".", "targets", ")", "\n", "\n", "# empty action", "\n", "actions", "=", "[", "[", "]", "]", "\n", "if", "not", "state", ":", "\n", "            ", "return", "actions", "\n", "\n", "# priority actions", "\n", "", "if", "priority", "is", "not", "None", ":", "\n", "            ", "actions", "=", "[", "[", "a", "]", "for", "a", "in", "self", ".", "_difflst", "(", "priority", ",", "state", "[", "0", "]", ")", "]", "\n", "\n", "# all actions", "\n", "", "if", "priority", "is", "None", "or", "not", "actions", ":", "\n", "            ", "actions", "=", "[", "[", "a", "]", "for", "a", "in", "self", ".", "_difflst", "(", "features", ",", "state", "[", "0", "]", ")", "]", "\n", "if", "not", "actions", ":", "\n", "                ", "return", "None", "\n", "\n", "# top actions", "\n", "", "", "if", "0", "<", "max_actions", "<", "len", "(", "actions", ")", ":", "\n", "            ", "miss", "=", "[", "]", "\n", "rank", "=", "[", "]", "\n", "# rank actions and identify unexplored actions", "\n", "for", "a", "in", "actions", ":", "\n", "                ", "s", "=", "self", ".", "_action", "(", "state", ",", "a", ")", "\n", "try", ":", "\n", "                    ", "v", "=", "self", ".", "qtable", "[", "self", ".", "_hash", "(", "s", ")", "]", "\n", "v", "=", "v", "[", "1", "]", "/", "v", "[", "0", "]", "\n", "rank", "+=", "[", "(", "v", ",", "a", ")", "]", "\n", "", "except", "KeyError", ":", "\n", "                    ", "miss", "+=", "[", "a", "]", "\n", "# sort best to worst", "\n", "", "", "if", "rank", ":", "\n", "                ", "rank", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "x", "[", "0", "]", ")", "\n", "# merge top and unexplored actions", "\n", "", "actions", "=", "miss", "+", "[", "x", "[", "1", "]", "for", "x", "in", "rank", "[", "0", ":", "max_actions", "]", "]", "\n", "\n", "# return", "\n", "", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._next": [[973, 1008], ["__init__.SparseTensorClassifier._actions", "__init__.SparseTensorClassifier._hash", "__init__.SparseTensorClassifier._action", "__init__.SparseTensorClassifier._hash", "__init__.SparseTensorClassifier._hash"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._actions", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._hash", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._action", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._hash", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._hash"], ["", "def", "_next", "(", "self", ",", "state", ":", "List", "[", "List", "[", "str", "]", "]", ",", "actions", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ")", "->", "Tuple", "[", "List", "[", "List", "[", "str", "]", "]", ",", "List", "[", "str", "]", ",", "float", "]", ":", "\n", "        ", "\"\"\"Move to the next state\n\n        Generate the next state based on the best action. The best action is found by exploiting the Q-table.\n\n        :param state: current policy\n        :param actions: possible actions from the current state\n        :return: next state generated by the best action\n        \"\"\"", "\n", "\n", "# actions", "\n", "if", "actions", "is", "None", ":", "\n", "            ", "actions", "=", "self", ".", "_actions", "(", "state", "=", "state", ")", "\n", "\n", "# init state, action, value", "\n", "", "s_", ",", "a_", ",", "v_", "=", "state", ",", "None", ",", "None", "\n", "if", "self", ".", "_hash", "(", "s_", ")", "in", "self", ".", "qtable", ":", "\n", "            ", "v_", "=", "self", ".", "qtable", "[", "self", ".", "_hash", "(", "s_", ")", "]", "\n", "v_", "=", "v_", "[", "1", "]", "/", "v_", "[", "0", "]", "\n", "\n", "# best action -> next state", "\n", "", "if", "actions", "is", "not", "None", ":", "\n", "            ", "for", "a", "in", "actions", ":", "\n", "                ", "s", "=", "self", ".", "_action", "(", "state", ",", "a", ")", "\n", "try", ":", "\n", "                    ", "v", "=", "self", ".", "qtable", "[", "self", ".", "_hash", "(", "s", ")", "]", "\n", "v", "=", "v", "[", "1", "]", "/", "v", "[", "0", "]", "\n", "if", "v_", "is", "None", "or", "v", ">", "v_", ":", "\n", "                        ", "s_", ",", "a_", ",", "v_", "=", "s", ",", "a", ",", "v", "\n", "", "", "except", "KeyError", ":", "\n", "                    ", "pass", "\n", "\n", "# return", "\n", "", "", "", "return", "s_", ",", "a_", ",", "v_", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._train_test_split": [[1009, 1054], ["numpy.random.seed", "Exception", "Exception", "numpy.unique", "numpy.random.choice", "numpy.random.choice", "numpy.unique.groupby().apply", "numpy.unique.groupby().apply", "int", "int", "numpy.unique.groupby", "numpy.unique.groupby", "numpy.isin", "items[].isin", "len", "len", "numpy.random.choice", "numpy.random.choice", "int", "int", "len", "len"], "methods", ["None"], ["", "def", "_train_test_split", "(", "self", ",", "items", ":", "pd", ".", "DataFrame", ",", "test_size", ":", "float", "=", "None", ",", "\n", "train_size", ":", "float", "=", "None", ",", "stratify", ":", "bool", "=", "True", ",", "\n", "random_state", ":", "int", "=", "None", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"Train-Test Split\n\n        Split data into random train and test subsets.\n\n        :param items: the data in tabular format\n        :param test_size: train-test cross validation split, percentage of train data\n        :param train_size: train-test cross validation split, percentage of test data\n        :param stratify: if True, the folds are made by preserving the percentage of samples for each class\n        :param random_state: random number generator seed. Pass an int for reproducible output across function calls.\n        :return: Tuple of arrays containing the IDs of the train-test data\n        \"\"\"", "\n", "\n", "if", "random_state", "is", "not", "None", ":", "\n", "            ", "np", ".", "random", ".", "seed", "(", "random_state", ")", "\n", "\n", "", "if", "train_size", "is", "None", "and", "test_size", "is", "None", ":", "\n", "            ", "test_size", "=", "0.25", "\n", "", "if", "train_size", "is", "None", ":", "\n", "            ", "train_size", "=", "1", "-", "test_size", "\n", "", "if", "test_size", "is", "None", ":", "\n", "            ", "test_size", "=", "1", "-", "train_size", "\n", "\n", "", "if", "train_size", "<", "0", "or", "train_size", ">", "1", ":", "\n", "            ", "raise", "Exception", "(", "\"train_size represents the proportion of the dataset to include in the train split.\"", ")", "\n", "", "if", "test_size", "<", "0", "or", "test_size", ">", "1", ":", "\n", "            ", "raise", "Exception", "(", "\"test_size represents the proportion of the dataset to include in the test split.\"", ")", "\n", "\n", "", "if", "not", "stratify", ":", "\n", "            ", "items", "=", "np", ".", "unique", "(", "items", "[", "self", ".", "item_field", "]", ")", "\n", "train", "=", "np", ".", "random", ".", "choice", "(", "items", ",", "size", "=", "int", "(", "len", "(", "items", ")", "*", "train_size", ")", ",", "replace", "=", "False", ")", "\n", "items", "=", "items", "[", "~", "np", ".", "isin", "(", "items", ",", "train", ")", "]", "\n", "test", "=", "np", ".", "random", ".", "choice", "(", "items", ",", "size", "=", "int", "(", "len", "(", "items", ")", "*", "test_size", "/", "(", "1", "-", "train_size", ")", ")", ",", "replace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "train", "=", "items", ".", "groupby", "(", "self", ".", "targets", ",", "as_index", "=", "False", ")", ".", "apply", "(", "lambda", "x", ":", "x", ".", "loc", "[", "np", ".", "random", ".", "choice", "(", "\n", "x", ".", "index", ",", "size", "=", "int", "(", "len", "(", "x", ")", "*", "train_size", ")", ",", "replace", "=", "False", ")", ",", ":", "]", ")", "\n", "items", "=", "items", "[", "~", "items", "[", "self", ".", "item_field", "]", ".", "isin", "(", "train", "[", "self", ".", "item_field", "]", ")", "]", "\n", "test", "=", "items", ".", "groupby", "(", "self", ".", "targets", ",", "as_index", "=", "False", ")", ".", "apply", "(", "lambda", "x", ":", "x", ".", "loc", "[", "np", ".", "random", ".", "choice", "(", "\n", "x", ".", "index", ",", "size", "=", "int", "(", "len", "(", "x", ")", "*", "test_size", "/", "(", "1", "-", "train_size", ")", ")", ",", "replace", "=", "False", ")", ",", ":", "]", ")", "\n", "train", "=", "train", "[", "self", ".", "item_field", "]", ".", "values", "\n", "test", "=", "test", "[", "self", ".", "item_field", "]", ".", "values", "\n", "\n", "", "return", "train", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._tmp_table": [[1055, 1066], ["hashlib.md5().hexdigest", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier._meta", "hashlib.md5", "str().encode", "str", "uuid.uuid1"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta"], ["", "def", "_tmp_table", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"Generate a unique name for temporary tables and store in DB\"\"\"", "\n", "\n", "uid", "=", "md5", "(", "str", "(", "uuid1", "(", ")", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "tmp", "=", "self", ".", "tmp_table", "+", "\"_\"", "+", "uid", "[", ":", "16", "]", "\n", "\n", "meta", "=", "self", ".", "_meta", "(", "key", "=", "self", ".", "tmp_table", ")", "\n", "meta", "=", "[", "tmp", "]", "if", "meta", "is", "None", "else", "[", "tmp", "]", "+", "meta", "\n", "self", ".", "_meta", "(", "key", "=", "self", ".", "tmp_table", ",", "value", "=", "meta", ")", "\n", "\n", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta": [[1067, 1101], ["pickle.dumps", "__init__.SparseTensorClassifier.conn.execute().scalar", "pickle.loads", "__init__.SparseTensorClassifier.conn.execute", "sqlalchemy.text", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier._UPDATE_meta", "__init__.SparseTensorClassifier._CREATE_meta", "sqlalchemy.text", "__init__.SparseTensorClassifier._SELECT_meta", "__init__.SparseTensorClassifier._UPDATE_meta"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._UPDATE_meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE_meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._UPDATE_meta"], ["", "def", "_meta", "(", "self", ",", "key", ":", "str", ",", "value", ":", "Any", "=", "None", ",", "default", ":", "Any", "=", "None", ")", "->", "Any", ":", "\n", "        ", "\"\"\"Get/Set meta values\n\n        Meta values are stored in the DB. If no value is provided then the key is read from the DB.\n        If a key:value pair is provided, the value is updated in the DB.\n\n        :param key: meta value key\n        :param value: meta value\n        :param default: value to return if no key was found\n        :return: meta value or default\n        \"\"\"", "\n", "\n", "# dump", "\n", "if", "value", "is", "not", "None", ":", "\n", "            ", "value", "=", "dumps", "(", "value", ")", "\n", "\n", "# read or update", "\n", "", "try", ":", "\n", "            ", "if", "value", "is", "None", ":", "\n", "                ", "binary", "=", "self", ".", "conn", ".", "execute", "(", "self", ".", "_SELECT_meta", "(", "key", "=", "key", ")", ")", ".", "scalar", "(", ")", "\n", "if", "binary", "is", "None", ":", "\n", "                    ", "return", "default", "\n", "", "return", "loads", "(", "binary", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "conn", ".", "execute", "(", "text", "(", "self", ".", "_UPDATE_meta", "(", "key", "=", "key", ")", ")", ",", "value", "=", "value", ")", "\n", "\n", "# create table and insert", "\n", "", "", "except", "SQLAlchemyError", ":", "\n", "            ", "if", "value", "is", "not", "None", ":", "\n", "                ", "self", ".", "conn", ".", "execute", "(", "self", ".", "_CREATE_meta", "(", "table", "=", "self", ".", "meta_table", ")", ")", "\n", "self", ".", "conn", ".", "execute", "(", "text", "(", "self", ".", "_UPDATE_meta", "(", "key", "=", "key", ")", ")", ",", "value", "=", "value", ")", "\n", "\n", "# fallback", "\n", "", "", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._uids": [[1102, 1114], ["range", "__init__.SparseTensorClassifier.conn.execute().scalar", "__init__.SparseTensorClassifier.conn.execute"], "methods", ["None"], ["", "def", "_uids", "(", "self", ",", "n", ":", "int", ",", "data_table", ":", "str", "=", "None", ",", "if_exists", ":", "str", "=", "'fail'", ")", "->", "range", ":", "\n", "\n", "# last item id", "\n", "        ", "last", "=", "0", "\n", "if", "data_table", "is", "not", "None", "and", "if_exists", "==", "\"append\"", ":", "\n", "            ", "try", ":", "\n", "                ", "last", "=", "self", ".", "conn", ".", "execute", "(", "f\"SELECT MAX({self.item_field})+1 from {data_table}\"", ")", ".", "scalar", "(", ")", "\n", "", "except", "SQLAlchemyError", ":", "\n", "                ", "pass", "\n", "\n", "# universal item ids", "\n", "", "", "return", "range", "(", "last", ",", "last", "+", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._transform": [[1115, 1264], ["isinstance", "dict", "__init__.SparseTensorClassifier._decrypt", "__init__.SparseTensorClassifier._tmp_table", "__init__.SparseTensorClassifier.to_sql", "isinstance", "__init__.SparseTensorClassifier._CREATE_corpus", "__init__.SparseTensorClassifier._UPDATE_corpus", "__init__.SparseTensorClassifier._DROP", "__init__.SparseTensorClassifier._DROP", "zip", "__init__.SparseTensorClassifier.items", "pandas.DataFrame", "pandas.DataFrame", "__init__.SparseTensorClassifier._CREATE_data", "__init__.SparseTensorClassifier._UPDATE_data", "pandas.DataFrame", "__init__.SparseTensorClassifier.to_sql", "Exception", "__init__.SparseTensorClassifier._difflst", "item.items", "[].transform", "__init__.SparseTensorClassifier._encrypt", "pandas.concat", "__init__.SparseTensorClassifier._tmp_table", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier._DROP", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "item.keys", "warnings.warn", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier._DROP", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.reset_index", "map", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "warnings.warn", "__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier.conn.execute", "collections.Counter().most_common", "pandas.concat.groupby", "rows.append", "collections.Counter", "rows.append"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._decrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._tmp_table", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.to_sql", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE_corpus", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._UPDATE_corpus", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE_data", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._UPDATE_data", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier.to_sql", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._encrypt", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._tmp_table", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP"], ["", "def", "_transform", "(", "self", ",", "items", ":", "Union", "[", "List", "[", "dict", "]", ",", "pd", ".", "DataFrame", "]", ",", "uids", ":", "range", ",", "dims", ":", "List", "[", "str", "]", ",", "\n", "data_table", ":", "str", "=", "None", ",", "corpus_table", ":", "str", "=", "None", ",", "if_exists", ":", "str", "=", "'fail'", ")", "->", "None", ":", "\n", "        ", "\"\"\"Transformer\n\n        Transform the data from JSON or tabular format to DB tables.\n        Generate the table containing individual items, the corpus, or both.\n\n        :param items: the data in JSON or tabular format\n        :param uids: universal identifiers\n        :param dims: the dimensions to transform. Additional dimensions are ignored\n        :param data_table: the name of the table to store individual items. If None, it is not generated\n        :param corpus_table: the name of the table to store the corpus. If None, it is not generated\n        :return: list of ids of the items transformed\n        \"\"\"", "\n", "\n", "# tmp tables", "\n", "tmp_items", "=", "None", "\n", "is_tmp_data", "=", "False", "\n", "\n", "# transform dictionary to data table", "\n", "if", "isinstance", "(", "items", ",", "list", ")", ":", "\n", "\n", "# add uids to items", "\n", "            ", "items", "=", "dict", "(", "zip", "(", "uids", ",", "items", ")", ")", "\n", "\n", "# all dims as set", "\n", "keys", "=", "self", ".", "_decrypt", "(", "dims", ")", "\n", "\n", "# map the data in form of a table with 'item': i, 'dimension': k, 'value': z, 'score': w", "\n", "if", "dims", ":", "\n", "\n", "# map values", "\n", "                ", "rid", "=", "-", "1", "\n", "rows", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "items", ".", "items", "(", ")", ":", "\n", "                    ", "rid", "+=", "1", "\n", "miss", "=", "self", ".", "_difflst", "(", "keys", ",", "item", ".", "keys", "(", ")", ")", "\n", "if", "miss", ":", "\n", "                        ", "warn", "(", "\"Missing value.\"", "\n", "f\" Item {rid} misses {', '.join(miss)} and it will be ignored.\"", "\n", "f\" Consider setting a string to represent the missing value(s).\"", ")", "\n", "", "for", "dim", ",", "value_list", "in", "item", ".", "items", "(", ")", ":", "\n", "                        ", "if", "not", "value_list", ":", "\n", "                            ", "warn", "(", "\"Missing value.\"", "\n", "f\" Item {rid} has no value for '{dim}' and it will be ignored.\"", "\n", "f\" Consider setting a string to represent the missing value(s).\"", ")", "\n", "", "elif", "dim", "in", "self", ".", "dims_map", ":", "\n", "                            ", "m", "=", "0", "\n", "k", "=", "self", ".", "dims_map", "[", "dim", "]", "\n", "for", "v", ",", "n", "in", "Counter", "(", "value_list", ")", ".", "most_common", "(", ")", ":", "\n", "                                ", "v", "=", "self", ".", "values_map", "[", "v", "]", "\n", "if", "v", "==", "-", "1", ":", "\n", "                                    ", "m", "+=", "n", "\n", "", "else", ":", "\n", "# insert values", "\n", "                                    ", "rows", ".", "append", "(", "{", "\n", "self", ".", "item_field", ":", "i", ",", "self", ".", "dim_field", ":", "k", ",", "\n", "self", ".", "value_field", ":", "v", ",", "self", ".", "score_field", ":", "n", "}", ")", "\n", "", "", "if", "m", ">", "0", ":", "\n", "# insert missing values", "\n", "                                ", "rows", ".", "append", "(", "{", "\n", "self", ".", "item_field", ":", "i", ",", "self", ".", "dim_field", ":", "k", ",", "\n", "self", ".", "value_field", ":", "-", "1", ",", "self", ".", "score_field", ":", "m", "}", ")", "\n", "\n", "# convert to data frame", "\n", "", "", "", "", "x", "=", "pd", ".", "DataFrame", "(", "rows", ")", "\n", "\n", "# normalize", "\n", "x", "[", "self", ".", "score_field", "]", "=", "x", "[", "self", ".", "score_field", "]", "/", "x", ".", "groupby", "(", "[", "self", ".", "item_field", ",", "self", ".", "dim_field", "]", ")", "[", "\n", "self", ".", "score_field", "]", ".", "transform", "(", "'sum'", ")", "\n", "\n", "# empty features", "\n", "", "else", ":", "\n", "                ", "x", "=", "pd", ".", "DataFrame", "(", "{", "self", ".", "item_field", ":", "uids", ",", "self", ".", "score_field", ":", "1.", "}", ")", "\n", "\n", "# store items in temporary table", "\n", "", "tmp_items", "=", "self", ".", "_tmp_table", "(", ")", "\n", "self", ".", "to_sql", "(", "x", ",", "tmp_items", ")", "\n", "\n", "# update data", "\n", "if", "data_table", "is", "not", "None", ":", "\n", "                ", "create", "=", "self", ".", "_CREATE_data", "(", "dims", "=", "dims", ",", "table", "=", "data_table", ")", "\n", "update", "=", "self", ".", "_UPDATE_data", "(", "dims", "=", "dims", ",", "data_table", "=", "data_table", ",", "items_table", "=", "tmp_items", ")", "\n", "\n", "if", "if_exists", "==", "\"append\"", ":", "\n", "                    ", "try", ":", "\n", "                        ", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "", "except", "SQLAlchemyError", ":", "\n", "                        ", "self", ".", "conn", ".", "execute", "(", "create", ")", "\n", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "\n", "", "", "elif", "if_exists", "==", "\"replace\"", ":", "\n", "                    ", "self", ".", "_DROP", "(", "data_table", ")", "\n", "self", ".", "conn", ".", "execute", "(", "create", ")", "\n", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "self", ".", "conn", ".", "execute", "(", "create", ")", "\n", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "\n", "# transform DataFrame to data table", "\n", "", "", "", "elif", "isinstance", "(", "items", ",", "pd", ".", "DataFrame", ")", ":", "\n", "\n", "# map data", "\n", "            ", "x", "=", "pd", ".", "DataFrame", "(", "{", "self", ".", "item_field", ":", "uids", ",", "self", ".", "score_field", ":", "1.", "}", ")", "\n", "if", "dims", ":", "\n", "                ", "items", "=", "self", ".", "_encrypt", "(", "items", ".", "reset_index", "(", "drop", "=", "True", ")", ")", "\n", "x", "=", "pd", ".", "concat", "(", "[", "x", ",", "items", "[", "dims", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# switch data table", "\n", "", "if", "data_table", "is", "None", ":", "\n", "                ", "data_table", "=", "self", ".", "_tmp_table", "(", ")", "\n", "is_tmp_data", "=", "True", "\n", "\n", "# store data", "\n", "", "self", ".", "to_sql", "(", "x", ",", "data_table", ",", "if_exists", "=", "if_exists", ")", "\n", "\n", "# transform not supported", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Data format not supported. Use List[dict] for JSON or DataFrame for tabular data\"", ")", "\n", "\n", "# update corpus", "\n", "", "if", "corpus_table", "is", "not", "None", ":", "\n", "            ", "create", "=", "self", ".", "_CREATE_corpus", "(", "dims", "=", "dims", ",", "table", "=", "corpus_table", ")", "\n", "update", "=", "self", ".", "_UPDATE_corpus", "(", "dims", "=", "dims", ",", "corpus_table", "=", "corpus_table", ",", "\n", "data_table", "=", "data_table", ",", "items_table", "=", "tmp_items", ",", "\n", "ids", "=", "\",\"", ".", "join", "(", "map", "(", "str", ",", "uids", ")", ")", ")", "\n", "\n", "if", "if_exists", "==", "\"append\"", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "", "except", "SQLAlchemyError", ":", "\n", "                    ", "self", ".", "conn", ".", "execute", "(", "create", ")", "\n", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "\n", "", "", "elif", "if_exists", "==", "\"replace\"", ":", "\n", "                ", "self", ".", "_DROP", "(", "corpus_table", ")", "\n", "self", ".", "conn", ".", "execute", "(", "create", ")", "\n", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "conn", ".", "execute", "(", "create", ")", "\n", "self", ".", "conn", ".", "execute", "(", "update", ")", "\n", "\n", "# clean", "\n", "", "", "if", "tmp_items", "is", "not", "None", ":", "\n", "            ", "self", ".", "_DROP", "(", "tmp_items", ")", "\n", "", "if", "is_tmp_data", ":", "\n", "            ", "self", ".", "_DROP", "(", "data_table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._AS": [[1265, 1272], ["None"], "methods", ["None"], ["", "", "def", "_AS", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL AS table alias\"\"\"", "\n", "\n", "if", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "return", "\"\"", "\n", "\n", "", "return", "\"AS\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW": [[1273, 1280], ["None"], "methods", ["None"], ["", "def", "_POW", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL function POW\"\"\"", "\n", "\n", "if", "self", ".", "db", "==", "\"mssql\"", "or", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "return", "\"POWER\"", "\n", "\n", "", "return", "\"POW\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._LOG": [[1281, 1288], ["None"], "methods", ["None"], ["", "def", "_LOG", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL function natural logarithm\"\"\"", "\n", "\n", "if", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "return", "\"LN\"", "\n", "\n", "", "return", "\"LOG\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS": [[1289, 1296], ["isinstance"], "methods", ["None"], ["", "def", "_COLS", "(", "self", ",", "table", ":", "str", ",", "cols", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"Formatting fields for SQL clauses\"\"\"", "\n", "\n", "if", "isinstance", "(", "cols", ",", "str", ")", ":", "\n", "            ", "cols", "=", "[", "cols", "]", "\n", "\n", "", "return", "\",\"", ".", "join", "(", "[", "f\"{table}.{i}\"", "for", "i", "in", "cols", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL": [[1297, 1304], ["None"], "methods", ["None"], ["", "def", "_ON_NATURAL", "(", "self", ",", "x", ":", "str", ",", "y", ":", "str", ",", "on", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"ON clause to mimic NATURAL JOIN\"\"\"", "\n", "\n", "if", "not", "on", ":", "\n", "            ", "return", "\"ON (1=1)\"", "\n", "\n", "", "return", "\"ON ({})\"", ".", "format", "(", "\" AND \"", ".", "join", "(", "[", "f\"{x}.{i}={y}.{i}\"", "for", "i", "in", "on", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._DROP": [[1305, 1319], ["__init__.SparseTensorClassifier.conn.execute", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier._difflst"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._difflst"], ["", "def", "_DROP", "(", "self", ",", "table", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"Drop SQL table\"\"\"", "\n", "\n", "# try", "\n", "try", ":", "\n", "# drop table", "\n", "            ", "self", ".", "conn", ".", "execute", "(", "f\"DROP TABLE {table}\"", ")", "\n", "# drop from tmp tables", "\n", "meta", "=", "self", ".", "_meta", "(", "key", "=", "self", ".", "tmp_table", ")", "\n", "if", "meta", "is", "not", "None", ":", "\n", "                ", "self", ".", "_meta", "(", "key", "=", "self", ".", "tmp_table", ",", "value", "=", "self", ".", "_difflst", "(", "meta", ",", "[", "table", "]", ")", ")", "\n", "# pass", "\n", "", "", "except", "SQLAlchemyError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE": [[1320, 1335], ["__init__.SparseTensorClassifier.conn.execute"], "methods", ["None"], ["", "", "def", "_CREATE", "(", "self", ",", "table", ":", "str", ",", "sql_select", ":", "str", ",", "sql_with", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create SQL table from SELECT statement\"\"\"", "\n", "\n", "if", "self", ".", "db", "==", "\"mssql\"", ":", "\n", "            ", "if", "sql_with", "is", "not", "None", ":", "\n", "                ", "sql", "=", "f\"WITH {sql_with} SELECT * INTO {table} FROM ({sql_select}) AS {table}_\"", "\n", "", "else", ":", "\n", "                ", "sql", "=", "f\"SELECT * INTO {table} FROM ({sql_select}) AS {table}_\"", "\n", "", "", "else", ":", "\n", "            ", "if", "sql_with", "is", "not", "None", ":", "\n", "                ", "sql", "=", "f\"CREATE TABLE {table} AS WITH {sql_with} {sql_select}\"", "\n", "", "else", ":", "\n", "                ", "sql", "=", "f\"CREATE TABLE {table} AS {sql_select}\"", "\n", "\n", "", "", "return", "self", ".", "conn", ".", "execute", "(", "sql", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE_meta": [[1336, 1373], ["Exception"], "methods", ["None"], ["", "def", "_CREATE_meta", "(", "self", ",", "table", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to create the meta table\"\"\"", "\n", "\n", "if", "self", ".", "db", "==", "\"sqlite\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{self.name_field} VARCHAR(255) PRIMARY KEY, \"", "\n", "f\"{self.value_field} BLOB \"", "\n", "f\")\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"postgresql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{self.name_field} VARCHAR(255) PRIMARY KEY, \"", "\n", "f\"{self.value_field} BYTEA \"", "\n", "f\")\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mysql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{self.name_field} VARCHAR(255) PRIMARY KEY, \"", "\n", "f\"{self.value_field} LONGBLOB \"", "\n", "f\")\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mssql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{self.name_field} VARCHAR(255) PRIMARY KEY, \"", "\n", "f\"{self.value_field} VARBINARY(MAX) \"", "\n", "f\")\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{self.name_field} VARCHAR2(255) PRIMARY KEY, \"", "\n", "f\"{self.value_field} BLOB \"", "\n", "f\")\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"DB {self.db} is not supported\"", ")", "\n", "\n", "", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE_data": [[1374, 1385], ["None"], "methods", ["None"], ["", "def", "_CREATE_data", "(", "self", ",", "dims", ":", "List", "[", "str", "]", ",", "table", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to create the data table\"\"\"", "\n", "\n", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{self.item_field} INTEGER, \"", "\n", "f\"{' '.join([f'{d} INTEGER,' for d in dims])}\"", "\n", "f\"{self.score_field} FLOAT \"", "\n", "f\")\"", ")", "\n", "\n", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE_corpus": [[1386, 1426], ["Exception"], "methods", ["None"], ["", "def", "_CREATE_corpus", "(", "self", ",", "dims", ":", "List", "[", "str", "]", ",", "table", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to create the corpus table\"\"\"", "\n", "\n", "d", "=", "\",\"", ".", "join", "(", "dims", ")", "\n", "d_integer", "=", "\", \"", ".", "join", "(", "[", "f\"{d} INTEGER\"", "for", "d", "in", "dims", "]", ")", "\n", "\n", "if", "self", ".", "db", "==", "\"sqlite\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{d_integer}, \"", "\n", "f\"{self.score_field} FLOAT, \"", "\n", "f\"PRIMARY KEY ({d}))\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"postgresql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{d_integer}, \"", "\n", "f\"{self.score_field} FLOAT, \"", "\n", "f\"PRIMARY KEY ({d}))\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mysql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"id BINARY(16) AS (UNHEX(MD5(CONCAT_WS('#',{d})))) STORED PRIMARY KEY, \"", "\n", "f\"{d_integer}, \"", "\n", "f\"{self.score_field} FLOAT)\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mssql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"id INTEGER IDENTITY(1,1) PRIMARY KEY, \"", "\n", "f\"{d_integer}, \"", "\n", "f\"{self.score_field} FLOAT)\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"CREATE TABLE {table} ( \"", "\n", "f\"{d_integer}, \"", "\n", "f\"{self.score_field} FLOAT, \"", "\n", "f\"PRIMARY KEY ({d}))\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"DB {self.db} is not supported\"", ")", "\n", "\n", "", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._UPDATE_meta": [[1427, 1468], ["Exception"], "methods", ["None"], ["", "def", "_UPDATE_meta", "(", "self", ",", "key", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to update the meta table\"\"\"", "\n", "\n", "if", "self", ".", "db", "==", "\"sqlite\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"INSERT OR REPLACE INTO {self.meta_table} ({self.name_field}, {self.value_field}) \"", "\n", "f\"VALUES ('{key}', :value)\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"postgresql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"INSERT INTO {self.meta_table} ({self.name_field}, {self.value_field}) \"", "\n", "f\"VALUES ('{key}', :value) \"", "\n", "f\"ON CONFLICT ({self.name_field}) DO UPDATE SET {self.value_field}=excluded.{self.value_field}\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mysql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"INSERT INTO {self.meta_table} ({self.name_field}, {self.value_field}) \"", "\n", "f\"VALUES ('{key}', :value) \"", "\n", "f\"ON DUPLICATE KEY UPDATE {self.value_field}=VALUES({self.value_field})\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mssql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"IF NOT EXISTS (SELECT * FROM {self.meta_table} WHERE {self.name_field} = '{key}') \"", "\n", "f\"INSERT INTO {self.meta_table}({self.name_field}, {self.value_field}) \"", "\n", "f\"VALUES('{key}', :value) \"", "\n", "f\"ELSE \"", "\n", "f\"UPDATE {self.meta_table} \"", "\n", "f\"SET {self.value_field} = :value \"", "\n", "f\"WHERE {self.name_field} = '{key}'\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"BEGIN \"", "\n", "f\"INSERT INTO {self.meta_table} ({self.name_field}, {self.value_field}) \"", "\n", "f\"VALUES ('{key}', :value); \"", "\n", "f\"EXCEPTION \"", "\n", "f\"WHEN DUP_VAL_ON_INDEX THEN \"", "\n", "f\"UPDATE {self.meta_table} \"", "\n", "f\"SET {self.value_field} = :value \"", "\n", "f\"WHERE {self.name_field} = '{key}'; \"", "\n", "f\"END;\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"DB {self.db} is not supported\"", ")", "\n", "\n", "", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._UPDATE_data": [[1469, 1477], ["__init__.SparseTensorClassifier._SELECT_data"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_data"], ["", "def", "_UPDATE_data", "(", "self", ",", "dims", ":", "List", "[", "str", "]", ",", "data_table", ":", "str", ",", "items_table", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to update the data table\"\"\"", "\n", "\n", "data", "=", "self", ".", "_SELECT_data", "(", "dims", "=", "dims", ",", "items_table", "=", "items_table", ")", "\n", "cols", "=", "\",\"", ".", "join", "(", "[", "self", ".", "item_field", "]", "+", "dims", "+", "[", "self", ".", "score_field", "]", ")", "\n", "sql", "=", "f\"INSERT INTO {data_table} ({cols}) {data}\"", "\n", "\n", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._UPDATE_corpus": [[1478, 1532], ["__init__.SparseTensorClassifier._SELECT_marginal", "__init__.SparseTensorClassifier._SELECT_data", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._ON_NATURAL", "Exception", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._COLS"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_marginal", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_data", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS"], ["", "def", "_UPDATE_corpus", "(", "self", ",", "dims", ":", "List", "[", "str", "]", ",", "corpus_table", ":", "str", ",", "data_table", ":", "str", "=", "None", ",", "items_table", ":", "str", "=", "None", ",", "\n", "ids", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to update the corpus table\"\"\"", "\n", "\n", "d", "=", "\",\"", ".", "join", "(", "dims", ")", "\n", "s", "=", "self", ".", "score_field", "\n", "\n", "if", "data_table", "is", "not", "None", ":", "\n", "            ", "data", "=", "self", ".", "_SELECT_marginal", "(", "dims", "=", "dims", ",", "table", "=", "data_table", ",", "ids", "=", "ids", ",", "corpus", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "self", ".", "_SELECT_data", "(", "dims", "=", "dims", ",", "items_table", "=", "items_table", ",", "corpus", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "db", "==", "\"sqlite\"", ":", "\n", "            ", "if", "sqlite3", ".", "sqlite_version_info", "<", "(", "3", ",", "24", ",", "0", ")", ":", "\n", "                ", "sql", "=", "(", "\n", "f\"WITH corpus_ AS ({data}) \"", "\n", "f\"INSERT OR REPLACE INTO {corpus_table} ({d}, {s}) \"", "\n", "f\"SELECT {self._COLS('corpus_', dims)}, corpus_.{s}+COALESCE({corpus_table}.{s}, 0) AS {s} \"", "\n", "f\"FROM corpus_ LEFT JOIN {corpus_table} {self._ON_NATURAL('corpus_', corpus_table, dims)}\"", ")", "\n", "", "else", ":", "\n", "                ", "sql", "=", "(", "\n", "f\"WITH corpus_ AS ({data}) \"", "\n", "f\"INSERT INTO {corpus_table} ({d}, {s}) \"", "\n", "f\"SELECT * FROM corpus_ WHERE true \"", "\n", "f\"ON CONFLICT ({d}) \"", "\n", "f\"DO UPDATE SET {s}={corpus_table}.{s}+excluded.{s}\"", ")", "\n", "", "", "elif", "self", ".", "db", "==", "\"postgresql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"WITH corpus_ AS ({data}) \"", "\n", "f\"INSERT INTO {corpus_table} ({d}, {s}) \"", "\n", "f\"SELECT * FROM corpus_ WHERE true \"", "\n", "f\"ON CONFLICT ({d}) \"", "\n", "f\"DO UPDATE SET {s}={corpus_table}.{s}+excluded.{s}\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mysql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"INSERT INTO {corpus_table} ({d}, {s}) \"", "\n", "f\"SELECT * FROM ({data}) AS excluded \"", "\n", "f\"ON DUPLICATE KEY UPDATE {s}={corpus_table}.{s}+excluded.{s}\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"mssql\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"MERGE {corpus_table} USING ({data}) AS excluded \"", "\n", "f\"{self._ON_NATURAL(corpus_table, 'excluded', dims)} \"", "\n", "f\"WHEN MATCHED THEN UPDATE SET {s}={corpus_table}.{s}+excluded.{s} \"", "\n", "f\"WHEN NOT MATCHED THEN INSERT ({d},{s}) VALUES ({self._COLS('excluded', dims)}, excluded.{s});\"", ")", "\n", "", "elif", "self", ".", "db", "==", "\"oracle\"", ":", "\n", "            ", "sql", "=", "(", "\n", "f\"MERGE INTO {corpus_table} USING ({data}) excluded \"", "\n", "f\"{self._ON_NATURAL(corpus_table, 'excluded', dims)} \"", "\n", "f\"WHEN MATCHED THEN UPDATE SET {s}={corpus_table}.{s}+excluded.{s} \"", "\n", "f\"WHEN NOT MATCHED THEN INSERT ({d},{s}) VALUES ({self._COLS('excluded', dims)}, excluded.{s})\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"DB {self.db} is not supported\"", ")", "\n", "\n", "", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_meta": [[1533, 1537], ["None"], "methods", ["None"], ["", "def", "_SELECT_meta", "(", "self", ",", "key", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to select values from the meta table\"\"\"", "\n", "\n", "return", "f\"SELECT {self.value_field} FROM {self.meta_table} WHERE {self.name_field}='{key}'\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_data": [[1538, 1573], ["len", "__init__.SparseTensorClassifier._AS", "__init__.SparseTensorClassifier._AS"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._AS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._AS"], ["", "def", "_SELECT_data", "(", "self", ",", "dims", ":", "List", "[", "str", "]", ",", "items_table", ":", "str", ",", "corpus", ":", "bool", "=", "False", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to select the data as tensors\n\n        Generate the SQL to select the data as tensors.\n        Read the values from a table of items and generate the tensor representation.\n\n        :param dims: the dimensions of the tensors\n        :param items_table: the table of items in the form 'item': i, 'dimension': k, 'value': z, 'score': w\n        :param corpus: select the corpus or the table containing individual items\n        :return: SQL query\n        \"\"\"", "\n", "\n", "if", "not", "dims", ":", "\n", "            ", "return", "f\"SELECT DISTINCT {self.item_field}, 1 AS {self.score_field} FROM {items_table}\"", "\n", "\n", "", "i", "=", "[", "d", "[", "1", ":", "]", "for", "d", "in", "dims", "]", "\n", "\n", "s1", "=", "f\"I{i[0]}.{self.item_field} AS {self.item_field}\"", "\n", "s2", "=", "\", \"", ".", "join", "(", "[", "f\"I{j}.{self.value_field} AS d{j}\"", "for", "j", "in", "i", "]", ")", "\n", "s3", "=", "\" * \"", ".", "join", "(", "[", "f\"I{j}.{self.score_field}\"", "for", "j", "in", "i", "]", ")", "\n", "\n", "f", "=", "f\"{items_table} {self._AS()} I{i[0]}\"", "\n", "if", "len", "(", "i", ")", ">", "1", ":", "\n", "            ", "f", "+=", "\" JOIN \"", "+", "\" JOIN \"", ".", "join", "(", "[", "\n", "f\"{items_table} {self._AS()} I{j} ON I{i[0]}.{self.item_field} = I{j}.{self.item_field}\"", "\n", "for", "j", "in", "i", "[", "1", ":", "]", "]", ")", "\n", "\n", "", "w", "=", "\" AND \"", ".", "join", "(", "[", "f\"I{j}.{self.dim_field} = {j}\"", "for", "j", "in", "i", "]", ")", "\n", "\n", "if", "not", "corpus", ":", "\n", "            ", "sql", "=", "f\"SELECT {s1}, {s2}, {s3} AS {self.score_field} FROM {f} WHERE {w}\"", "\n", "", "else", ":", "\n", "            ", "sql", "=", "f\"SELECT {s2}, SUM({s3}) AS {self.score_field} FROM {f} WHERE {w} GROUP BY {','.join(dims)}\"", "\n", "\n", "", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_marginal": [[1574, 1599], ["s.insert", "s.insert", "len"], "methods", ["None"], ["", "def", "_SELECT_marginal", "(", "self", ",", "dims", ":", "List", "[", "str", "]", ",", "table", ":", "str", ",", "ids", ":", "str", "=", "None", ",", "corpus", ":", "bool", "=", "False", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to select the marginal probability\n\n        Generate the SQL to select the marginal probability from a table of individual items or a corpus.\n\n        :param dims: the dimensions of the marginals\n        :param table: table of tensor(s) to compute the marginals\n        :param ids: filter by id and select only a subset of items\n        :param corpus: generate the marginal for the corpus or for each individual item\n        :return: SQL query\n        \"\"\"", "\n", "\n", "s", "=", "[", "f\"SUM({self.score_field}) AS {self.score_field}\"", "]", "\n", "if", "dims", ":", "\n", "            ", "s", ".", "insert", "(", "0", ",", "\",\"", ".", "join", "(", "dims", ")", ")", "\n", "", "if", "not", "corpus", ":", "\n", "            ", "s", ".", "insert", "(", "0", ",", "self", ".", "item_field", ")", "\n", "\n", "", "sql", "=", "f\"SELECT {', '.join(s)} FROM {table}\"", "\n", "if", "ids", "is", "not", "None", ":", "\n", "            ", "sql", "+=", "f\" WHERE {self.item_field} IN ({ids})\"", "\n", "", "if", "len", "(", "s", ")", ">", "1", ":", "\n", "            ", "sql", "+=", "f\" GROUP BY {', '.join(s[:-1])}\"", "\n", "\n", "", "return", "sql", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_norm": [[1600, 1615], ["__init__.SparseTensorClassifier._COLS"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS"], ["", "def", "_SELECT_norm", "(", "self", ",", "dims", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to select normalization factors\"\"\"", "\n", "\n", "if", "not", "dims", ":", "\n", "            ", "sql_select", "=", "(", "\n", "f\"SELECT SUM({self.score_field}) AS {self.score_field} \"", "\n", "f\"FROM corpus\"", ")", "\n", "", "else", ":", "\n", "            ", "d", "=", "self", ".", "_COLS", "(", "\"corpus\"", ",", "dims", ")", "\n", "sql_select", "=", "(", "\n", "f\"SELECT {d}, SUM({self.score_field}) AS {self.score_field} \"", "\n", "f\"FROM corpus \"", "\n", "f\"GROUP BY {d}\"", ")", "\n", "\n", "", "return", "sql_select", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_weight": [[1616, 1654], ["__init__.SparseTensorClassifier._SELECT_marginal", "__init__.SparseTensorClassifier._SELECT_norm", "__init__.SparseTensorClassifier._SELECT_norm", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._unique", "__init__.SparseTensorClassifier._unique", "__init__.SparseTensorClassifier._POW", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._POW", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._POW", "__init__.SparseTensorClassifier._POW", "__init__.SparseTensorClassifier._POW", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._ON_NATURAL"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_marginal", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_norm", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_norm", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL"], ["", "def", "_SELECT_weight", "(", "self", ",", "features", ":", "List", "[", "str", "]", ",", "corpus_table", ":", "str", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "        ", "\"\"\"SQL to select weights\"\"\"", "\n", "\n", "corpus", "=", "self", ".", "_SELECT_marginal", "(", "dims", "=", "self", ".", "_unique", "(", "self", ".", "targets", "+", "features", ")", ",", "table", "=", "corpus_table", ",", "corpus", "=", "True", ")", "\n", "norm_f", "=", "self", ".", "_SELECT_norm", "(", "dims", "=", "features", ")", "\n", "norm_t", "=", "self", ".", "_SELECT_norm", "(", "dims", "=", "self", ".", "targets", ")", "\n", "\n", "sql_with", "=", "f\"corpus AS ({corpus})\"", "\n", "if", "self", ".", "balance", "!=", "0", ":", "\n", "            ", "sql_with", "+=", "f\", norm_t AS ({norm_t})\"", "\n", "", "if", "self", ".", "balance", "!=", "1", ":", "\n", "            ", "sql_with", "+=", "f\", norm_f AS ({norm_f})\"", "\n", "\n", "", "d", "=", "self", ".", "_COLS", "(", "\"corpus\"", ",", "self", ".", "_unique", "(", "self", ".", "targets", "+", "features", ")", ")", "\n", "if", "self", ".", "balance", "==", "0", ":", "\n", "            ", "sql_select", "=", "(", "\n", "f\"SELECT {d}, \"", "\n", "f\"{self._POW()}(corpus.{self.score_field}/norm_f.{self.score_field}, {self.power}) \"", "\n", "f\"AS {self.score_field} \"", "\n", "f\"FROM corpus JOIN norm_f {self._ON_NATURAL('corpus', 'norm_f', features)}\"", ")", "\n", "", "elif", "self", ".", "balance", "==", "1", ":", "\n", "            ", "sql_select", "=", "(", "\n", "f\"SELECT {d}, \"", "\n", "f\"{self._POW()}(corpus.{self.score_field}/norm_t.{self.score_field}, {self.power}) \"", "\n", "f\"AS {self.score_field} \"", "\n", "f\"FROM corpus JOIN norm_t {self._ON_NATURAL('corpus', 'norm_t', self.targets)}\"", ")", "\n", "", "else", ":", "\n", "            ", "sql_select", "=", "(", "\n", "f\"SELECT {d}, {self._POW()}( \"", "\n", "f\" corpus.{self.score_field} / ( \"", "\n", "f\"  {self._POW()}(norm_f.{self.score_field}, {1-self.balance}) * \"", "\n", "f\"  {self._POW()}(norm_t.{self.score_field}, {self.balance}) \"", "\n", "f\" ), {self.power}) AS {self.score_field} \"", "\n", "f\"FROM corpus \"", "\n", "f\" JOIN norm_f {self._ON_NATURAL('corpus', 'norm_f', features)} \"", "\n", "f\" JOIN norm_t {self._ON_NATURAL('corpus', 'norm_t', self.targets)}\"", ")", "\n", "\n", "", "return", "sql_select", ",", "sql_with", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_entropy": [[1655, 1703], ["__init__.SparseTensorClassifier._SELECT_norm", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._unique", "__init__.SparseTensorClassifier._unique", "__init__.SparseTensorClassifier._LOG", "__init__.SparseTensorClassifier._AS", "__init__.SparseTensorClassifier._LOG"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_norm", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._LOG", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._AS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._LOG"], ["", "def", "_SELECT_entropy", "(", "self", ",", "features", ":", "List", "[", "str", "]", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "        ", "\"\"\"SQL to select entropy\"\"\"", "\n", "\n", "# normalization factor (balance)", "\n", "sql", "=", "self", ".", "_SELECT_norm", "(", "dims", "=", "self", ".", "targets", ")", "\n", "sql_with", "=", "f\"entropy_balance AS ({sql})\"", "\n", "\n", "# probability (non-normalized)", "\n", "d", "=", "self", ".", "_COLS", "(", "\"corpus\"", ",", "self", ".", "_unique", "(", "self", ".", "targets", "+", "features", ")", ")", "\n", "on_t", "=", "self", ".", "_ON_NATURAL", "(", "\"corpus\"", ",", "\"entropy_balance\"", ",", "self", ".", "targets", ")", "\n", "sql", "=", "(", "\n", "f\"SELECT {d}, \"", "\n", "f\"corpus.{self.score_field}/entropy_balance.{self.score_field} AS {self.score_field} \"", "\n", "f\"FROM corpus JOIN entropy_balance {on_t}\"", ")", "\n", "sql_with", "+=", "f\", entropy_prob_nn AS ({sql})\"", "\n", "\n", "# normalization factor (probability)", "\n", "f", "=", "self", ".", "_COLS", "(", "\"entropy_prob_nn\"", ",", "features", ")", "\n", "sql", "=", "(", "\n", "f\"SELECT {f}, SUM({self.score_field}) AS {self.score_field} \"", "\n", "f\"FROM entropy_prob_nn \"", "\n", "f\"GROUP BY {f}\"", ")", "\n", "sql_with", "+=", "f\", entropy_norm AS ({sql})\"", "\n", "\n", "# probability (normalized)", "\n", "d", "=", "self", ".", "_COLS", "(", "\"entropy_prob_nn\"", ",", "self", ".", "_unique", "(", "self", ".", "targets", "+", "features", ")", ")", "\n", "on_f", "=", "self", ".", "_ON_NATURAL", "(", "\"entropy_prob_nn\"", ",", "\"entropy_norm\"", ",", "features", ")", "\n", "sql", "=", "(", "\n", "f\"SELECT {d}, entropy_prob_nn.{self.score_field}/entropy_norm.{self.score_field} AS {self.score_field} \"", "\n", "f\"FROM entropy_prob_nn JOIN entropy_norm {on_f}\"", ")", "\n", "sql_with", "+=", "f\", entropy_prob AS ({sql})\"", "\n", "\n", "# number of target states", "\n", "t", "=", "self", ".", "_COLS", "(", "\"corpus\"", ",", "self", ".", "targets", ")", "\n", "sql", "=", "(", "\n", "f\"SELECT {self._LOG()}(COUNT(*)) AS {self.score_field} \"", "\n", "f\"FROM (SELECT DISTINCT {t} FROM corpus) {self._AS()} states\"", ")", "\n", "sql_with", "+=", "f\", entropy_states AS ({sql})\"", "\n", "\n", "# entropy", "\n", "f", "=", "self", ".", "_COLS", "(", "\"entropy_prob\"", ",", "features", ")", "\n", "h", "=", "f\"entropy_prob.{self.score_field} * {self._LOG()}(entropy_prob.{self.score_field})\"", "\n", "sql_select", "=", "(", "\n", "f\"SELECT {f}, 1 + SUM({h})/(SELECT {self.score_field} FROM entropy_states) AS {self.score_field} \"", "\n", "f\"FROM entropy_prob \"", "\n", "f\"GROUP BY {f}\"", ")", "\n", "\n", "return", "sql_select", ",", "sql_with", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_robust": [[1704, 1726], ["__init__.SparseTensorClassifier._SELECT_weight", "__init__.SparseTensorClassifier._SELECT_entropy", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._unique", "__init__.SparseTensorClassifier._POW"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_weight", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_entropy", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW"], ["", "def", "_SELECT_robust", "(", "self", ",", "features", ":", "List", "[", "str", "]", ",", "corpus_table", ":", "str", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "        ", "\"\"\"SQL to select robust weights\"\"\"", "\n", "\n", "sql_weight", "=", "self", ".", "_SELECT_weight", "(", "features", "=", "features", ",", "corpus_table", "=", "corpus_table", ")", "\n", "if", "not", "self", ".", "entropy", "or", "not", "features", ":", "\n", "            ", "return", "sql_weight", "\n", "\n", "", "sql_entropy", "=", "self", ".", "_SELECT_entropy", "(", "features", "=", "features", ")", "\n", "sql_with", "=", "f\"{sql_weight[1]}, weight AS ({sql_weight[0]}), {sql_entropy[1]}, entropy AS ({sql_entropy[0]})\"", "\n", "\n", "d", "=", "self", ".", "_COLS", "(", "\"weight\"", ",", "self", ".", "_unique", "(", "self", ".", "targets", "+", "features", ")", ")", "\n", "on_f", "=", "self", ".", "_ON_NATURAL", "(", "\"weight\"", ",", "\"entropy\"", ",", "features", ")", "\n", "\n", "h", "=", "f\"entropy.{self.score_field}\"", "\n", "if", "self", ".", "entropy", "!=", "1", ":", "\n", "            ", "h", "=", "f\"{self._POW()}(entropy.{self.score_field}, {self.entropy})\"", "\n", "\n", "", "sql_select", "=", "(", "\n", "f\"SELECT {d}, weight.{self.score_field} * {h} AS {self.score_field} \"", "\n", "f\"FROM weight JOIN entropy {on_f}\"", ")", "\n", "\n", "return", "sql_select", ",", "sql_with", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_cache": [[1727, 1740], ["__init__.SparseTensorClassifier._ckey", "__init__.SparseTensorClassifier._meta", "__init__.SparseTensorClassifier._SELECT_robust", "__init__.SparseTensorClassifier._tmp_table", "__init__.SparseTensorClassifier._CREATE", "__init__.SparseTensorClassifier._meta"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ckey", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_robust", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._tmp_table", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._CREATE", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._meta"], ["", "def", "_SELECT_cache", "(", "self", ",", "features", ":", "List", "[", "str", "]", ",", "corpus_table", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"SQL to select cached robust weights\"\"\"", "\n", "\n", "key", "=", "self", ".", "_ckey", "(", "corpus_table", "=", "corpus_table", ",", "features", "=", "features", ")", "\n", "cache_table", "=", "self", ".", "_meta", "(", "key", "=", "key", ",", "default", "=", "None", ")", "\n", "\n", "if", "cache_table", "is", "None", ":", "\n", "            ", "sql", "=", "self", ".", "_SELECT_robust", "(", "features", "=", "features", ",", "corpus_table", "=", "corpus_table", ")", "\n", "cache_table", "=", "self", ".", "_tmp_table", "(", ")", "\n", "self", ".", "_CREATE", "(", "table", "=", "cache_table", ",", "sql_select", "=", "sql", "[", "0", "]", ",", "sql_with", "=", "sql", "[", "1", "]", ")", "\n", "self", ".", "_meta", "(", "key", "=", "key", ",", "value", "=", "cache_table", ")", "\n", "\n", "", "return", "f\"SELECT * FROM {cache_table}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_predict": [[1741, 1814], ["__init__.SparseTensorClassifier._SELECT_marginal", "__init__.SparseTensorClassifier._ON_NATURAL", "__init__.SparseTensorClassifier._SELECT_cache", "__init__.SparseTensorClassifier._SELECT_robust", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._POW", "__init__.SparseTensorClassifier._unique", "__init__.SparseTensorClassifier._COLS", "__init__.SparseTensorClassifier._POW"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_marginal", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_cache", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_robust", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._unique", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._COLS", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._POW"], ["", "def", "_SELECT_predict", "(", "self", ",", "features", ":", "List", "[", "str", "]", ",", "corpus_table", ":", "str", ",", "data_table", ":", "str", ",", "cache", ":", "bool", ",", "\n", "ids", ":", "str", "=", "None", ",", "probability", ":", "bool", "=", "True", ",", "explain", ":", "bool", "=", "False", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "        ", "\"\"\"SQL to select probability\n\n        :param features: features to use for prediction\n        :param corpus_table: table containing the corpus\n        :param data_table: table containing the data to predict\n        :param cache: use cache\n        :param ids: filter by id and select only a subset of items\n        :param explain: select addends contributing to the summation or the probability itself\n        :return: SQL to select the probability (or addends)\n        \"\"\"", "\n", "\n", "# items", "\n", "items", "=", "self", ".", "_SELECT_marginal", "(", "dims", "=", "features", ",", "table", "=", "data_table", ",", "ids", "=", "ids", ",", "corpus", "=", "False", ")", "\n", "sql_with", "=", "f\"items AS ({items})\"", "\n", "\n", "# weights", "\n", "if", "cache", ":", "\n", "            ", "robust", "=", "self", ".", "_SELECT_cache", "(", "features", "=", "features", ",", "corpus_table", "=", "corpus_table", ")", "\n", "sql_with", "+=", "f\", robust AS ({robust})\"", "\n", "", "else", ":", "\n", "            ", "robust", "=", "self", ".", "_SELECT_robust", "(", "features", "=", "features", ",", "corpus_table", "=", "corpus_table", ")", "\n", "sql_with", "+=", "f\", {robust[1]}, robust AS ({robust[0]})\"", "\n", "\n", "# on and score", "\n", "", "on_f", "=", "self", ".", "_ON_NATURAL", "(", "\"robust\"", ",", "\"items\"", ",", "features", ")", "\n", "score", "=", "f\"robust.{self.score_field} * {self._POW()}(items.{self.score_field}, {self.power})\"", "\n", "\n", "# query", "\n", "if", "explain", ":", "\n", "# explainability", "\n", "            ", "d", "=", "self", ".", "_COLS", "(", "\"robust\"", ",", "self", ".", "_unique", "(", "self", ".", "targets", "+", "features", ")", ")", "\n", "sql_select", "=", "(", "\n", "f\"SELECT {self.item_field}, {d}, {score} AS {self.score_field} \"", "\n", "f\"FROM robust JOIN items {on_f}\"", ")", "\n", "\n", "", "else", ":", "\n", "# probability (non-normalized)", "\n", "            ", "t", "=", "self", ".", "_COLS", "(", "\"robust\"", ",", "self", ".", "targets", ")", "\n", "sql", "=", "(", "\n", "f\"SELECT {self.item_field}, {t}, {self._POW()}(SUM({score}), 1./{self.power}) AS {self.score_field} \"", "\n", "f\"FROM robust JOIN items {on_f} \"", "\n", "f\"GROUP BY {self.item_field}, {t}\"", ")", "\n", "sql_with", "+=", "f\", prob_nn AS ({sql})\"", "\n", "\n", "if", "probability", ":", "\n", "# probability norm", "\n", "                ", "sql", "=", "(", "\n", "f\"SELECT {self.item_field}, SUM({self.score_field}) AS {self.score_field} \"", "\n", "f\"FROM prob_nn \"", "\n", "f\"GROUP BY {self.item_field}\"", ")", "\n", "sql_with", "+=", "f\", prob_norm AS ({sql})\"", "\n", "\n", "# probability (normalized)", "\n", "t", "=", "self", ".", "_COLS", "(", "\"prob_nn\"", ",", "self", ".", "targets", ")", "\n", "sql_select", "=", "(", "\n", "f\"SELECT prob_nn.{self.item_field}, {t}, \"", "\n", "f\"prob_nn.{self.score_field}/prob_norm.{self.score_field} AS {self.score_field} \"", "\n", "f\"FROM prob_nn JOIN prob_norm ON prob_nn.{self.item_field}=prob_norm.{self.item_field}\"", ")", "\n", "\n", "", "else", ":", "\n", "# classification", "\n", "                ", "t", "=", "\",\"", ".", "join", "(", "self", ".", "targets", ")", "\n", "sql", "=", "(", "\n", "f\"SELECT {self.item_field}, {t}, \"", "\n", "f\"ROW_NUMBER() OVER(PARTITION BY {self.item_field} ORDER BY {self.score_field} DESC) AS idx \"", "\n", "f\"FROM prob_nn\"", ")", "\n", "sql_with", "+=", "f\", labels AS ({sql})\"", "\n", "sql_select", "=", "f\"SELECT {self.item_field}, {t} FROM labels WHERE idx = 1\"", "\n", "\n", "# return", "\n", "", "", "return", "sql_select", ",", "sql_with", "\n", "\n"]], "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_loss": [[1815, 1857], ["__init__.SparseTensorClassifier._SELECT_marginal", "__init__.SparseTensorClassifier._SELECT_predict", "__init__.SparseTensorClassifier._ON_NATURAL", "Exception", "__init__.SparseTensorClassifier._LOG"], "methods", ["home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_marginal", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._SELECT_predict", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._ON_NATURAL", "home.repos.pwc.inspect_result.SparseTensorClassifier_stc.stc.__init__.SparseTensorClassifier._LOG"], ["", "def", "_SELECT_loss", "(", "self", ",", "features", ":", "List", "[", "str", "]", ",", "corpus_table", ":", "str", ",", "data_table", ":", "str", ",", "\n", "fallback_table", ":", "str", "=", "None", ",", "ids", ":", "str", "=", "None", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "        ", "\"\"\"SQL to select the evaluation metric\"\"\"", "\n", "\n", "targets", "=", "self", ".", "targets", "\n", "\n", "# select the marginals of the given ids as true probability", "\n", "true", "=", "self", ".", "_SELECT_marginal", "(", "dims", "=", "targets", ",", "table", "=", "data_table", ",", "ids", "=", "ids", ",", "corpus", "=", "False", ")", "\n", "\n", "# select the predicted probabilities", "\n", "prob", "=", "self", ".", "_SELECT_predict", "(", "\n", "features", "=", "features", ",", "corpus_table", "=", "corpus_table", ",", "data_table", "=", "data_table", ",", "ids", "=", "ids", ",", "\n", "probability", "=", "True", ",", "explain", "=", "False", ",", "cache", "=", "False", ")", "\n", "\n", "# with clause", "\n", "sql_with", "=", "f\"{prob[1]}, prob AS ({prob[0]}), prob_true AS ({true})\"", "\n", "\n", "# query variables", "\n", "i", "=", "self", ".", "item_field", "\n", "s", "=", "self", ".", "score_field", "\n", "on_it", "=", "self", ".", "_ON_NATURAL", "(", "\"prob\"", ",", "\"prob_true\"", ",", "[", "self", ".", "item_field", "]", "+", "targets", ")", "\n", "\n", "# select clause", "\n", "if", "self", ".", "loss", "==", "'norm'", ":", "\n", "            ", "sql_select", "=", "(", "\n", "f\"SELECT prob.{i}, 0.5*(SUM(ABS(prob.{s}-COALESCE(prob_true.{s},0))) + (1-SUM(prob_true.{s}))) AS {s} \"", "\n", "f\"FROM prob LEFT JOIN prob_true {on_it} \"", "\n", "f\"GROUP BY prob.{i}\"", ")", "\n", "", "elif", "self", ".", "loss", "==", "'log'", ":", "\n", "            ", "sql_select", "=", "(", "\n", "f\"SELECT prob_true.{i}, -SUM(prob_true.{s}*{self._LOG()}(COALESCE(prob.{s},{self.tol}))) AS {s} \"", "\n", "f\"FROM prob_true LEFT JOIN prob {on_it} \"", "\n", "f\"GROUP BY prob.{i}\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Loss not supported. Use 'norm' for p-norm(1) loss or 'log' for cross-entropy.\"", ")", "\n", "\n", "# add fallback for missing predictions", "\n", "", "if", "fallback_table", "is", "not", "None", ":", "\n", "            ", "sql_select", "+=", "f\" UNION ALL SELECT {i}, {s} FROM {fallback_table} WHERE {i} NOT IN (SELECT {i} FROM prob)\"", "\n", "\n", "# return SQL", "\n", "", "return", "sql_select", ",", "sql_with", "\n", "\n"]]}