{"home.repos.pwc.inspect_result.dreasysnail_RetGen.None.preprocess_reader_data.main": [[22, 29], ["dpr.models.init_tenzorizer", "dpr.models.init_tenzorizer.set_pad_to_max", "dpr.data.reader_data.convert_retriever_results"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_tenzorizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.set_pad_to_max", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.convert_retriever_results"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "tensorizer", "=", "init_tenzorizer", "(", "args", ".", "encoder_model_type", ",", "args", ")", "\n", "\n", "tensorizer", ".", "set_pad_to_max", "(", "False", ")", "\n", "\n", "convert_retriever_results", "(", "args", ".", "is_train_set", ",", "args", ".", "retriever_results", ",", "args", ".", "out_file", ",", "args", ".", "gold_passages_src", ",", "\n", "tensorizer", ",", "args", ".", "num_workers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.generate_dense_embeddings.gen_ctx_vectors": [[43, 76], ["len", "enumerate", "range", "dpr.utils.model_utils.move_to_device", "dpr.utils.model_utils.move_to_device", "dpr.utils.model_utils.move_to_device", "out.cpu.cpu", "len", "results.extend", "tensorizer.text_to_tensor", "torch.stack", "torch.zeros_like", "tensorizer.get_attn_mask", "torch.no_grad", "model", "len", "out.cpu.size", "logger.info", "out[].view().numpy", "range", "out.cpu.size", "out[].view"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.move_to_device", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.move_to_device", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.move_to_device", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["def", "gen_ctx_vectors", "(", "ctx_rows", ":", "List", "[", "Tuple", "[", "object", ",", "str", ",", "str", "]", "]", ",", "model", ":", "nn", ".", "Module", ",", "tensorizer", ":", "Tensorizer", ",", "\n", "args", ",", "insert_title", ":", "bool", "=", "False", ")", "->", "List", "[", "Tuple", "[", "object", ",", "np", ".", "array", "]", "]", ":", "\n", "    ", "n", "=", "len", "(", "ctx_rows", ")", "\n", "bsz", "=", "args", ".", "batch_size", "\n", "total", "=", "0", "\n", "results", "=", "[", "]", "\n", "for", "j", ",", "batch_start", "in", "enumerate", "(", "range", "(", "0", ",", "n", ",", "bsz", ")", ")", ":", "\n", "\n", "        ", "batch_token_tensors", "=", "[", "tensorizer", ".", "text_to_tensor", "(", "ctx", "[", "1", "]", ",", "title", "=", "ctx", "[", "2", "]", "if", "insert_title", "else", "None", ")", "for", "ctx", "in", "\n", "ctx_rows", "[", "batch_start", ":", "batch_start", "+", "bsz", "]", "]", "\n", "\n", "ctx_ids_batch", "=", "move_to_device", "(", "torch", ".", "stack", "(", "batch_token_tensors", ",", "dim", "=", "0", ")", ",", "args", ".", "device", ")", "\n", "ctx_seg_batch", "=", "move_to_device", "(", "torch", ".", "zeros_like", "(", "ctx_ids_batch", ")", ",", "args", ".", "device", ")", "\n", "ctx_attn_mask", "=", "move_to_device", "(", "tensorizer", ".", "get_attn_mask", "(", "ctx_ids_batch", ")", ",", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "_", ",", "out", ",", "_", "=", "model", "(", "ctx_ids_batch", ",", "ctx_seg_batch", ",", "ctx_attn_mask", ")", "\n", "", "out", "=", "out", ".", "cpu", "(", ")", "\n", "\n", "ctx_ids", "=", "[", "r", "[", "0", "]", "for", "r", "in", "ctx_rows", "[", "batch_start", ":", "batch_start", "+", "bsz", "]", "]", "\n", "\n", "assert", "len", "(", "ctx_ids", ")", "==", "out", ".", "size", "(", "0", ")", "\n", "\n", "total", "+=", "len", "(", "ctx_ids", ")", "\n", "\n", "results", ".", "extend", "(", "[", "\n", "(", "ctx_ids", "[", "i", "]", ",", "out", "[", "i", "]", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "out", ".", "size", "(", "0", ")", ")", "\n", "]", ")", "\n", "\n", "if", "total", "%", "100000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Encoded passages %d'", ",", "total", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.generate_dense_embeddings.main": [[77, 132], ["dpr.options.set_encoder_params_from_state", "dpr.options.print_args", "dpr.models.init_biencoder_components", "dpr.utils.model_utils.setup_for_distributed_mode", "encoder.eval", "dpr.utils.model_utils.get_model_obj", "logger.info", "logger.debug", "len", "dpr.utils.model_utils.get_model_obj.load_state_dict", "logger.info", "int", "logger.info", "generate_dense_embeddings.gen_ctx_vectors", "pathlib.Path().mkdir", "logger.info", "logger.info", "dpr.utils.model_utils.load_states_from_checkpoint", "dpr.utils.model_utils.load_states_from_checkpoint_only_model", "dpr.utils.model_utils.load_states_from_checkpoint_only_model.model_dict.keys", "open", "csv.reader", "rows.extend", "hasattr", "len", "str", "open", "pickle.dump", "len", "hasattr", "dpr.utils.model_utils.load_states_from_checkpoint_only_model.model_dict.items", "key.startswith", "len", "pathlib.Path", "os.path.dirname", "all", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_encoder_params_from_state", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.print_args", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_biencoder_components", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.setup_for_distributed_mode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_obj", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.generate_dense_embeddings.gen_ctx_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint_only_model"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "args", ",", "'load_trained_model'", ")", "or", "not", "args", ".", "load_trained_model", ":", "\n", "        ", "saved_state", "=", "load_states_from_checkpoint", "(", "args", ".", "model_file", ")", "\n", "", "else", ":", "\n", "        ", "saved_state", "=", "load_states_from_checkpoint_only_model", "(", "args", ".", "model_file", ")", "\n", "\n", "", "set_encoder_params_from_state", "(", "saved_state", ".", "encoder_params", ",", "args", ")", "\n", "print_args", "(", "args", ")", "\n", "tensorizer", ",", "encoder", ",", "_", "=", "init_biencoder_components", "(", "args", ".", "encoder_model_type", ",", "args", ",", "inference_only", "=", "True", ")", "\n", "\n", "encoder", "=", "encoder", ".", "ctx_model", "\n", "\n", "encoder", ",", "_", "=", "setup_for_distributed_mode", "(", "encoder", ",", "None", ",", "args", ".", "device", ",", "args", ".", "n_gpu", ",", "\n", "args", ".", "local_rank", ",", "\n", "args", ".", "fp16", ",", "\n", "args", ".", "fp16_opt_level", ")", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "model_to_load", "=", "get_model_obj", "(", "encoder", ")", "\n", "logger", ".", "info", "(", "'Loading saved model state ...'", ")", "\n", "logger", ".", "debug", "(", "'saved model keys =%s'", ",", "saved_state", ".", "model_dict", ".", "keys", "(", ")", ")", "\n", "\n", "prefix_len", "=", "len", "(", "'ctx_model.'", ")", "\n", "ctx_state", "=", "{", "key", "[", "prefix_len", ":", "]", ":", "value", "for", "(", "key", ",", "value", ")", "in", "saved_state", ".", "model_dict", ".", "items", "(", ")", "if", "\n", "key", ".", "startswith", "(", "'ctx_model.'", ")", "}", "\n", "\n", "model_to_load", ".", "load_state_dict", "(", "ctx_state", ")", "\n", "\n", "logger", ".", "info", "(", "'reading data from file=%s'", ",", "args", ".", "ctx_file", ")", "\n", "\n", "rows", "=", "[", "]", "\n", "with", "open", "(", "args", ".", "ctx_file", ")", "as", "tsvfile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "tsvfile", ",", "delimiter", "=", "'\\t'", ")", "\n", "\n", "rows", ".", "extend", "(", "[", "(", "row", "[", "0", "]", ",", "row", "[", "1", "]", ",", "row", "[", "2", "]", ")", "for", "row", "in", "reader", "if", "row", "[", "0", "]", "!=", "'id'", "and", "all", "(", "[", "len", "(", "row", "[", "0", "]", ")", "!=", "0", ",", "len", "(", "row", "[", "1", "]", ")", ">=", "10", ",", "len", "(", "row", "[", "2", "]", ")", "!=", "0", "]", ")", "]", ")", "\n", "\n", "", "if", "hasattr", "(", "args", ",", "'change_id_over_card'", ")", "and", "args", ".", "change_id_over_card", ":", "\n", "        ", "args", ".", "shard_id", "=", "args", ".", "local_rank", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "0", "\n", "\n", "", "shard_size", "=", "int", "(", "len", "(", "rows", ")", "/", "args", ".", "num_shards", ")", "\n", "start_idx", "=", "args", ".", "shard_id", "*", "shard_size", "\n", "end_idx", "=", "start_idx", "+", "shard_size", "\n", "\n", "logger", ".", "info", "(", "'Producing encodings for passages range: %d to %d (out of total %d)'", ",", "start_idx", ",", "end_idx", ",", "len", "(", "rows", ")", ")", "\n", "rows", "=", "rows", "[", "start_idx", ":", "end_idx", "]", "\n", "\n", "data", "=", "gen_ctx_vectors", "(", "rows", ",", "encoder", ",", "tensorizer", ",", "args", ",", "False", ")", "\n", "\n", "file", "=", "args", ".", "out_file", "+", "'_'", "+", "str", "(", "args", ".", "shard_id", ")", "\n", "pathlib", ".", "Path", "(", "os", ".", "path", ".", "dirname", "(", "file", ")", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "logger", ".", "info", "(", "'Writing results to %s'", "%", "file", ")", "\n", "with", "open", "(", "file", ",", "mode", "=", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "data", ",", "f", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Total passages processed %d. Written to %s'", ",", "len", "(", "data", ")", ",", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.extract_top_docs.init_retriever_single_rank": [[23, 118], ["torch.cuda.set_device", "torch.device", "dpr.options.print_args", "load_states_from_checkpoint", "set_encoder_params_from_state", "init_biencoder_components", "encoder.to", "encoder.eval", "logger.info", "sorted", "logger.info", "get_model_obj", "logger.info", "len", "get_model_obj.load_state_dict", "get_model_obj.get_out_size", "logger.info", "dense_retriever.DenseRetriever", "os.path.join", "logger.info", "sorted", "logger.info", "glob.glob", "DenseHNSWFlatIndexer", "DenseFlatIndexer", "os.path.dirname", "hasattr", "os.path.join", "generate_dense_embeddings.main", "exit", "glob.glob", "os.path.join", "os.path.join", "dense_retriever.DenseRetriever.index_encoded_data", "str", "load_states_from_checkpoint.model_dict.items", "key.startswith", "os.path.basename", "os.path.dirname", "os.path.basename", "str", "os.path.dirname", "os.path.dirname", "hasattr", "os.path.join", "os.path.join", "os.path.exists", "time.time", "glob.glob", "logger.info", "logger.info", "dense_retriever.DenseRetriever.index_encoded_data", "print", "dense_retriever.DenseRetriever.index.serialize", "DenseHNSWFlatIndexer", "dense_retriever.DenseRetriever", "dense_retriever.DenseRetriever.index.deserialize_from", "os.path.basename", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.basename", "os.path.basename", "os.path.dirname", "os.path.basename", "os.path.dirname", "os.path.basename", "time.time", "os.path.basename", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.print_args", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_encoder_params_from_state", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_biencoder_components", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_obj", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.get_out_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.__main__.main", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.index_encoded_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.index_encoded_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer.serialize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.deserialize_from"], ["def", "init_retriever_single_rank", "(", "args", ",", "eval_on_each", "=", "EVAL_ON_EACH", ")", ":", "\n", "# evaluate based on ranking setting", "\n", "    ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "\n", "print_args", "(", "args", ")", "\n", "args", ".", "do_lower_case", "=", "True", "\n", "saved_state", "=", "load_states_from_checkpoint", "(", "args", ".", "model_file", ")", "\n", "set_encoder_params_from_state", "(", "saved_state", ".", "encoder_params", ",", "args", ")", "\n", "\n", "tensorizer", ",", "encoder", ",", "_", "=", "init_biencoder_components", "(", "args", ".", "encoder_model_type", ",", "args", ",", "inference_only", "=", "True", ")", "\n", "\n", "encoder", "=", "encoder", ".", "question_model", "\n", "encoder", ".", "to", "(", "device", ")", "\n", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "args", ".", "encoded_ctx_file", "=", "args", ".", "out_file", "+", "'_*'", "\n", "if", "eval_on_each", ":", "\n", "        ", "args", ".", "encoded_ctx_file", "=", "args", ".", "out_file", "+", "'_'", "+", "str", "(", "args", ".", "shard_id", ")", "\n", "\n", "# index all passages", "\n", "", "ctx_files_pattern", "=", "args", ".", "encoded_ctx_file", "\n", "logger", ".", "info", "(", "'encoded files: %s'", ",", "ctx_files_pattern", ")", "\n", "input_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "ctx_files_pattern", ")", ")", "\n", "logger", ".", "info", "(", "'Reading all passages data from files: %s'", ",", "input_paths", ")", "\n", "\n", "# index all passages", "\n", "args", ".", "encoded_file_patterns", "=", "ctx_files_pattern", "\n", "\n", "# load weights from the model file", "\n", "model_to_load", "=", "get_model_obj", "(", "encoder", ")", "\n", "logger", ".", "info", "(", "'Loading saved model state ...'", ")", "\n", "\n", "prefix_len", "=", "len", "(", "'question_model.'", ")", "\n", "question_encoder_state", "=", "{", "key", "[", "prefix_len", ":", "]", ":", "value", "for", "(", "key", ",", "value", ")", "in", "saved_state", ".", "model_dict", ".", "items", "(", ")", "if", "\n", "key", ".", "startswith", "(", "'question_model.'", ")", "}", "\n", "model_to_load", ".", "load_state_dict", "(", "question_encoder_state", ")", "\n", "vector_size", "=", "model_to_load", ".", "get_out_size", "(", ")", "\n", "logger", ".", "info", "(", "'Encoder vector_size=%d'", ",", "vector_size", ")", "\n", "\n", "index_buffer_sz", "=", "args", ".", "index_buffer", "\n", "if", "args", ".", "hnsw_index", ":", "\n", "        ", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ")", "\n", "index_buffer_sz", "=", "-", "1", "# encode all at once", "\n", "", "else", ":", "\n", "        ", "index", "=", "DenseFlatIndexer", "(", "vector_size", ")", "\n", "\n", "", "retriever", "=", "DenseRetriever", "(", "encoder", ",", "args", ".", "batch_size", ",", "tensorizer", ",", "index", ")", "\n", "\n", "args", ".", "out_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "model_file", ")", ",", "'dense_embedding'", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "model_file", ")", "+", "'.'", "+", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", ")", "\n", "if", "hasattr", "(", "args", ",", "'load_old_model'", ")", "and", "args", ".", "load_old_model", ":", "\n", "        ", "args", ".", "out_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "model_file", ")", ",", "'dense_embedding'", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", ")", "\n", "", "if", "args", ".", "encoding", ":", "\n", "        ", "dense_encoding", "(", "args", ")", "\n", "exit", "(", ")", "\n", "\n", "", "args", ".", "encoded_ctx_file", "=", "args", ".", "out_file", "+", "'_*'", "\n", "if", "eval_on_each", ":", "\n", "        ", "args", ".", "encoded_ctx_file", "=", "args", ".", "out_file", "+", "'_'", "+", "str", "(", "args", ".", "shard_id", ")", "\n", "\n", "# index all passages", "\n", "", "ctx_files_pattern", "=", "args", ".", "encoded_ctx_file", "\n", "logger", ".", "info", "(", "'encoded files: %s'", ",", "ctx_files_pattern", ")", "\n", "input_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "ctx_files_pattern", ")", ")", "\n", "logger", ".", "info", "(", "'Reading all passages data from files: %s'", ",", "input_paths", ")", "\n", "\n", "# index all passages", "\n", "args", ".", "encoded_file_patterns", "=", "ctx_files_pattern", "\n", "\n", "\n", "if", "args", ".", "hnsw_index", ":", "\n", "        ", "indexer_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "model_file", ")", "+", "'.'", "+", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp'", ")", "\n", "indexer_file_dpr", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "model_file", ")", "+", "'.'", "+", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp.index.dpr'", ")", "\n", "if", "hasattr", "(", "args", ",", "'load_old_model'", ")", "and", "args", ".", "load_old_model", ":", "\n", "            ", "indexer_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp'", ")", "\n", "indexer_file_dpr", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp.index.dpr'", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "indexer_file_dpr", ")", ":", "\n", "            ", "assert", "ctx_files_pattern", "is", "not", "None", ",", "'encode file patterns cannot be None'", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "input_paths", "=", "glob", ".", "glob", "(", "ctx_files_pattern", ")", "\n", "logger", ".", "info", "(", "'Reading all passages data from files: \\n%s'", ",", "'\\n'", ".", "join", "(", "input_paths", ")", ")", "\n", "logger", ".", "info", "(", "f'Indexing to file {indexer_file}'", ")", "\n", "retriever", ".", "index_encoded_data", "(", "input_paths", ",", "buffer_size", "=", "index_buffer_sz", ")", "\n", "print", "(", "'time cost ='", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "'s'", ")", "\n", "retriever", ".", "index", ".", "serialize", "(", "indexer_file", ")", "\n", "", "else", ":", "\n", "            ", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ")", "\n", "retriever", "=", "DenseRetriever", "(", "encoder", ",", "args", ".", "batch_size", ",", "tensorizer", ",", "index", ")", "\n", "retriever", ".", "index", ".", "deserialize_from", "(", "indexer_file", ")", "\n", "", "", "else", ":", "\n", "        ", "retriever", ".", "index_encoded_data", "(", "input_paths", ",", "buffer_size", "=", "index_buffer_sz", ",", "remove_duplicates", "=", "False", ")", "\n", "\n", "", "return", "retriever", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.extract_top_docs.init_retriever": [[120, 255], ["encoder.eval", "encoder.get_out_size", "logger.info", "setup_for_distributed_mode", "dense_retriever.DenseRetriever", "os.path.join", "logger.info", "sorted", "logger.info", "dense_retriever.load_passages", "set_encoder_params_from_state", "init_biencoder_components", "get_model_obj", "logger.info", "len", "get_model_obj.load_state_dict", "DenseHNSWFlatIndexer", "DenseFlatIndexer", "os.path.dirname", "hasattr", "os.path.join", "int", "logger.info", "logger.info", "generate_dense_embeddings.gen_ctx_vectors", "pathlib.Path().mkdir", "logger.info", "generate_dense_embeddings.main", "glob.glob", "os.path.join", "os.path.join", "dense_retriever.DenseRetriever.index_encoded_data", "len", "RuntimeError", "load_states_from_checkpoint", "dpr.utils.model_utils.load_states_from_checkpoint_only_model", "os.path.basename", "os.path.dirname", "os.path.basename", "open", "csv.reader", "rows.extend", "hasattr", "len", "str", "open", "pickle.dump", "torch.distributed.barrier", "str", "os.path.dirname", "os.path.dirname", "hasattr", "os.path.join", "os.path.join", "logger.info", "DenseHNSWFlatIndexer", "dense_retriever.DenseRetriever", "dense_retriever.DenseRetriever.index.deserialize_from", "hasattr", "dpr.utils.model_utils.load_states_from_checkpoint_only_model.model_dict.items", "key.startswith", "os.path.basename", "len", "pathlib.Path", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.exists", "torch.distributed.barrier", "time.time", "glob.glob", "logger.info", "logger.info", "dense_retriever.DenseRetriever.index_encoded_data", "print", "dense_retriever.DenseRetriever.index.serialize", "torch.distributed.barrier", "logger.info", "DenseHNSWFlatIndexer", "dense_retriever.DenseRetriever", "dense_retriever.DenseRetriever.index.deserialize_from", "os.path.dirname", "os.path.basename", "os.path.basename", "os.path.dirname", "os.path.basename", "os.path.dirname", "os.path.basename", "len", "os.path.basename", "os.path.basename", "time.time", "all", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.get_out_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.setup_for_distributed_mode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.load_passages", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_encoder_params_from_state", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_biencoder_components", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_obj", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.generate_dense_embeddings.gen_ctx_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.__main__.main", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.index_encoded_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint_only_model", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.deserialize_from", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.index_encoded_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer.serialize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.deserialize_from"], ["", "def", "init_retriever", "(", "args", ",", "eval_on_each", "=", "EVAL_ON_EACH", ",", "encoder", "=", "None", ",", "tensorizer", "=", "None", ",", "force_index", "=", "False", ",", "file_suffix", "=", "''", ")", ":", "\n", "    ", "args", ".", "do_lower_case", "=", "True", "\n", "# evaluate based on ranking setting", "\n", "if", "encoder", "is", "None", ":", "\n", "        ", "if", "not", "hasattr", "(", "args", ",", "'load_trained_model'", ")", "or", "not", "args", ".", "load_trained_model", ":", "\n", "            ", "saved_state", "=", "load_states_from_checkpoint", "(", "args", ".", "model_file", ")", "\n", "", "else", ":", "\n", "            ", "saved_state", "=", "load_states_from_checkpoint_only_model", "(", "args", ".", "model_file", ")", "\n", "\n", "", "set_encoder_params_from_state", "(", "saved_state", ".", "encoder_params", ",", "args", ")", "\n", "\n", "tensorizer", ",", "encoder", ",", "_", "=", "init_biencoder_components", "(", "args", ".", "encoder_model_type", ",", "args", ",", "inference_only", "=", "True", ")", "\n", "\n", "encoder", "=", "encoder", ".", "question_model", "\n", "\n", "# load weights from the model file", "\n", "model_to_load", "=", "get_model_obj", "(", "encoder", ")", "\n", "logger", ".", "info", "(", "'Loading saved model state ...'", ")", "\n", "\n", "prefix_len", "=", "len", "(", "'question_model.'", ")", "\n", "question_encoder_state", "=", "{", "key", "[", "prefix_len", ":", "]", ":", "value", "for", "(", "key", ",", "value", ")", "in", "saved_state", ".", "model_dict", ".", "items", "(", ")", "if", "\n", "key", ".", "startswith", "(", "'question_model.'", ")", "}", "\n", "model_to_load", ".", "load_state_dict", "(", "question_encoder_state", ")", "\n", "\n", "", "encoder", ".", "eval", "(", ")", "\n", "vector_size", "=", "encoder", ".", "get_out_size", "(", ")", "\n", "logger", ".", "info", "(", "'Encoder vector_size=%d'", ",", "vector_size", ")", "\n", "encoder", ",", "_", "=", "setup_for_distributed_mode", "(", "encoder", ",", "None", ",", "args", ".", "device", ",", "args", ".", "n_gpu", ",", "\n", "args", ".", "local_rank", ",", "\n", "args", ".", "fp16", ")", "\n", "\n", "index_buffer_sz", "=", "args", ".", "index_buffer", "\n", "if", "args", ".", "hnsw_index", ":", "\n", "        ", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ")", "\n", "index_buffer_sz", "=", "-", "1", "# encode all at once", "\n", "", "else", ":", "\n", "        ", "index", "=", "DenseFlatIndexer", "(", "vector_size", ")", "\n", "\n", "", "retriever", "=", "DenseRetriever", "(", "encoder", ",", "args", ".", "batch_size", ",", "tensorizer", ",", "index", ")", "\n", "# TODO", "\n", "\n", "\n", "args", ".", "out_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "model_file", ")", ",", "'dense_embedding'", ",", "file_suffix", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "model_file", ")", "+", "'.'", "+", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", ")", "\n", "if", "hasattr", "(", "args", ",", "'load_old_model'", ")", "and", "args", ".", "load_old_model", ":", "\n", "        ", "args", ".", "out_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "model_file", ")", ",", "'dense_embedding'", ",", "file_suffix", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", ")", "\n", "\n", "", "if", "force_index", ":", "\n", "        ", "rows", "=", "[", "]", "\n", "with", "open", "(", "args", ".", "ctx_file", ")", "as", "tsvfile", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "tsvfile", ",", "delimiter", "=", "'\\t'", ")", "\n", "# file format: doc_id, doc_text, title", "\n", "### TODO: potential error", "\n", "rows", ".", "extend", "(", "[", "(", "row", "[", "0", "]", ",", "row", "[", "1", "]", ",", "row", "[", "2", "]", ")", "for", "row", "in", "reader", "if", "\n", "row", "[", "0", "]", "!=", "'id'", "and", "all", "(", "[", "len", "(", "row", "[", "0", "]", ")", "!=", "0", ",", "len", "(", "row", "[", "1", "]", ")", ">=", "10", ",", "len", "(", "row", "[", "2", "]", ")", "!=", "0", "]", ")", "]", ")", "\n", "\n", "", "if", "hasattr", "(", "args", ",", "'change_id_over_card'", ")", "and", "args", ".", "change_id_over_card", ":", "\n", "            ", "args", ".", "shard_id", "=", "args", ".", "local_rank", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "0", "\n", "\n", "\n", "", "shard_size", "=", "int", "(", "len", "(", "rows", ")", "/", "args", ".", "num_shards", ")", "\n", "start_idx", "=", "args", ".", "shard_id", "*", "shard_size", "\n", "end_idx", "=", "start_idx", "+", "shard_size", "\n", "logger", ".", "info", "(", "'Producing encodings to file(s): %s'", ",", "args", ".", "out_file", ")", "\n", "logger", ".", "info", "(", "'Producing encodings for passages range: %d to %d (out of total %d)'", ",", "start_idx", ",", "end_idx", ",", "len", "(", "rows", ")", ")", "\n", "rows", "=", "rows", "[", "start_idx", ":", "end_idx", "]", "\n", "\n", "data", "=", "gen_ctx_vectors", "(", "rows", ",", "encoder", ",", "tensorizer", ",", "args", ",", "False", ")", "\n", "\n", "\n", "file", "=", "args", ".", "out_file", "+", "'_'", "+", "str", "(", "args", ".", "shard_id", ")", "\n", "pathlib", ".", "Path", "(", "os", ".", "path", ".", "dirname", "(", "file", ")", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "logger", ".", "info", "(", "' %s'", "%", "file", ")", "\n", "with", "open", "(", "file", ",", "mode", "=", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "data", ",", "f", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "", "args", ".", "encoded_ctx_file", "=", "args", ".", "out_file", "+", "'_*'", "\n", "if", "eval_on_each", ":", "\n", "        ", "args", ".", "encoded_ctx_file", "=", "args", ".", "out_file", "+", "'_'", "+", "str", "(", "args", ".", "shard_id", ")", "\n", "\n", "\n", "", "if", "args", ".", "encoding", ":", "\n", "        ", "dense_encoding", "(", "args", ")", "\n", "\n", "# index all passages", "\n", "", "ctx_files_pattern", "=", "args", ".", "encoded_ctx_file", "\n", "logger", ".", "info", "(", "'encoded files: %s'", ",", "ctx_files_pattern", ")", "\n", "input_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "ctx_files_pattern", ")", ")", "\n", "logger", ".", "info", "(", "'Reading all passages data from files: %s'", ",", "input_paths", ")", "\n", "# index all passages", "\n", "if", "args", ".", "hnsw_index", ":", "\n", "        ", "indexer_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "file_suffix", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "model_file", ")", "+", "'.'", "+", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp'", ")", "\n", "indexer_file_dpr", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "file_suffix", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "model_file", ")", "+", "'.'", "+", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp.index.dpr'", ")", "\n", "if", "hasattr", "(", "args", ",", "'load_old_model'", ")", "and", "args", ".", "load_old_model", ":", "\n", "            ", "indexer_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "file_suffix", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp'", ")", "\n", "indexer_file_dpr", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ctx_files_pattern", ")", ")", ",", "file_suffix", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "ctx_file", ")", "+", "'.indexer.cp.index.dpr'", ")", "\n", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "indexer_file_dpr", ")", "or", "force_index", ":", "\n", "            ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "0", ",", "-", "1", "]", ":", "\n", "                ", "assert", "ctx_files_pattern", "is", "not", "None", ",", "'encode file patterns cannot be None'", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "input_paths", "=", "glob", ".", "glob", "(", "ctx_files_pattern", ")", "\n", "assert", "len", "(", "input_paths", ")", ">", "0", ",", "f\"input path {input_paths} needs to be larger than 0\"", "\n", "logger", ".", "info", "(", "'HNSW: Reading all passages data from files: \\n%s'", ",", "'\\n'", ".", "join", "(", "input_paths", ")", ")", "\n", "logger", ".", "info", "(", "f'Indexing to file {indexer_file}'", ")", "\n", "retriever", ".", "index_encoded_data", "(", "input_paths", ",", "buffer_size", "=", "index_buffer_sz", ")", "\n", "print", "(", "'time cost ='", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "'s, local_rank ='", ",", "args", ".", "local_rank", ")", "\n", "retriever", ".", "index", ".", "serialize", "(", "indexer_file", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "                ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "logger", ".", "info", "(", "'file exist and not force index, read from files'", ")", "\n", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ")", "\n", "retriever", "=", "DenseRetriever", "(", "encoder", ",", "args", ".", "batch_size", ",", "tensorizer", ",", "index", ")", "\n", "retriever", ".", "index", ".", "deserialize_from", "(", "indexer_file", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'file exist and not force index, read from files'", ")", "\n", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ")", "\n", "retriever", "=", "DenseRetriever", "(", "encoder", ",", "args", ".", "batch_size", ",", "tensorizer", ",", "index", ")", "\n", "retriever", ".", "index", ".", "deserialize_from", "(", "indexer_file", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "retriever", ".", "index_encoded_data", "(", "input_paths", ",", "buffer_size", "=", "index_buffer_sz", ",", "remove_duplicates", "=", "False", ")", "\n", "\n", "", "all_passages", "=", "load_passages", "(", "args", ".", "ctx_file", ")", "# {'1':doc, ctx}", "\n", "if", "len", "(", "all_passages", ")", "==", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "'No passages data found. Please specify ctx_file param properly.'", ")", "\n", "", "return", "retriever", ",", "all_passages", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.extract_top_docs.main": [[257, 324], ["dense_retriever.parse_qa_csv_file", "init_retriever_single_rank.generate_question_vectors", "init_retriever_single_rank.get_top_docs", "print", "logger.info", "dpr.options.set_seed", "dense_retriever.load_passages", "extract_top_docs.init_retriever", "questions.append", "question_answers.append", "retriever.generate_question_vectors.numpy", "os.path.join", "logger.info", "logger.info", "open", "extract_top_docs.init_retriever_single_rank", "len", "RuntimeError", "os.path.dirname", "os.path.join", "open", "open", "tqdm.tqdm", "enumerate", "os.path.dirname", "tqdm.tqdm", "enumerate", "tqdm.tqdm", "enumerate", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm", "len", "len", "out_f.write", "out_f.write", "len", "len", "out_d_f.write", "out_d_f.write", "len", "len", "out_d_p.write", "out_d_p.write", "str", "str", "re.sub", "zip", "str().strip", "str().strip", "str().strip", "str", "str", "str().strip", "str", "str().strip", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.parse_qa_csv_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.generate_question_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.get_top_docs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_seed", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.load_passages", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.extract_top_docs.init_retriever", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.extract_top_docs.init_retriever_single_rank"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "retriever_master_rank", "and", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "set_seed", "(", "args", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "# only exist in master rank", "\n", "            ", "retriever", "=", "init_retriever_single_rank", "(", "args", ",", "eval_on_each", "=", "args", ".", "eval_on_each", ")", "\n", "", "all_passages", "=", "load_passages", "(", "args", ".", "ctx_file", ")", "# exist on all ranks because of ret_passages", "\n", "if", "len", "(", "all_passages", ")", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'No passages data found. Please specify ctx_file param properly.'", ")", "\n", "", "", "else", ":", "\n", "        ", "retriever", ",", "all_passages", "=", "init_retriever", "(", "args", ",", "eval_on_each", "=", "args", ".", "eval_on_each", ")", "\n", "\n", "\n", "", "questions", "=", "[", "]", "\n", "question_answers", "=", "[", "]", "\n", "\n", "for", "ds_item", "in", "parse_qa_csv_file", "(", "args", ".", "qa_file", ",", "simple_parser", "=", "True", ")", ":", "\n", "        ", "question", ",", "answers", "=", "ds_item", "\n", "questions", ".", "append", "(", "question", ")", "\n", "question_answers", ".", "append", "(", "answers", ")", "\n", "", "questions_tensor", "=", "retriever", ".", "generate_question_vectors", "(", "questions", ")", "\n", "top_ids_and_scores", "=", "retriever", ".", "get_top_docs", "(", "questions_tensor", ".", "numpy", "(", ")", ",", "args", ".", "n_docs", ",", "is_hnsw", "=", "args", ".", "hnsw_index", ")", "\n", "print", "(", "top_ids_and_scores", "[", "0", "]", ")", "\n", "\n", "if", "not", "args", ".", "save_to", ":", "\n", "# TODO", "\n", "        ", "save_to", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "qa_file", ")", ",", "(", "args", ".", "output_name", "+", "\".\"", "if", "args", ".", "output_name", "else", "\"\"", ")", "+", "\"top_doc.id.txt\"", ")", "\n", "if", "EVAL_ON_EACH", ":", "\n", "            ", "save_to", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "qa_file", ")", ",", "(", "args", ".", "output_name", "+", "\".\"", "if", "args", ".", "output_name", "else", "\"\"", ")", "+", "f\"shard{args.shard_id}.top_doc.id.txt\"", ")", "\n", "", "", "else", ":", "\n", "        ", "save_to", "=", "args", ".", "save_to", "\n", "\n", "\n", "", "if", "args", ".", "output_doc", ":", "\n", "        ", "save_to_doc", "=", "save_to", "[", ":", "-", "6", "]", "+", "\"doc.txt\"", "\n", "logger", ".", "info", "(", "'Save top doc to: %s'", ",", "save_to_doc", ")", "\n", "with", "open", "(", "save_to_doc", ",", "'w'", ")", "as", "out_d_f", ":", "\n", "            ", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "top_ids_and_scores", ")", ",", "desc", "=", "f\"Extract top {args.n_docs} docs\"", ")", "as", "pbar", ":", "\n", "                ", "for", "idx", ",", "res", "in", "enumerate", "(", "tqdm", ".", "tqdm", "(", "top_ids_and_scores", ",", "desc", "=", "\"Iteration\"", ")", ")", ":", "\n", "                    ", "assert", "(", "args", ".", "n_docs", "<=", "len", "(", "res", "[", "0", "]", ")", ")", "\n", "if", "args", ".", "remove_positive", ":", "\n", "                        ", "out_d_f", ".", "write", "(", "\"\\t\"", ".", "join", "(", "[", "all_passages", "[", "str", "(", "x", ")", ".", "strip", "(", ")", "]", "[", "0", "]", "for", "x", "in", "res", "[", "0", "]", "[", ":", "args", ".", "n_print_docs", "]", "if", "all_passages", "[", "str", "(", "x", ")", ".", "strip", "(", ")", "]", "[", "0", "]", "!=", "all_passages", "[", "str", "(", "idx", "+", "1", ")", "]", "[", "0", "]", "]", ")", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                        ", "out_d_f", ".", "write", "(", "\"\\t\"", ".", "join", "(", "[", "re", ".", "sub", "(", "'[\\t\\n]'", ",", "''", ",", "all_passages", "[", "str", "(", "x", ")", ".", "strip", "(", ")", "]", "[", "0", "]", ")", "for", "x", "in", "res", "[", "0", "]", "[", ":", "args", ".", "n_print_docs", "]", "]", ")", "+", "'\\n'", ")", "\n", "\n", "\n", "", "", "", "", "", "if", "args", ".", "output_prob", ":", "\n", "        ", "save_to_prob", "=", "save_to", "[", ":", "-", "6", "]", "+", "\"prob.txt\"", "\n", "logger", ".", "info", "(", "'Save prob to: %s'", ",", "save_to_prob", ")", "\n", "with", "open", "(", "save_to_prob", ",", "'w'", ")", "as", "out_d_p", ":", "\n", "            ", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "top_ids_and_scores", ")", ",", "desc", "=", "f\"Extract top {args.n_docs} docs\"", ")", "as", "pbar", ":", "\n", "                ", "for", "idx", ",", "res", "in", "enumerate", "(", "tqdm", ".", "tqdm", "(", "top_ids_and_scores", ",", "desc", "=", "\"Iteration\"", ")", ")", ":", "\n", "                    ", "assert", "(", "args", ".", "n_docs", "<=", "len", "(", "res", "[", "0", "]", ")", ")", "\n", "if", "args", ".", "remove_positive", ":", "\n", "                        ", "out_d_p", ".", "write", "(", "\"\\t\"", ".", "join", "(", "[", "f\"{s:.2f}\"", "for", "x", ",", "s", "in", "zip", "(", "res", "[", "0", "]", "[", ":", "args", ".", "n_print_docs", "]", ",", "res", "[", "1", "]", "[", ":", "args", ".", "n_print_docs", "]", ")", "if", "all_passages", "[", "str", "(", "x", ")", ".", "strip", "(", ")", "]", "[", "0", "]", "!=", "all_passages", "[", "str", "(", "idx", "+", "1", ")", "]", "[", "0", "]", "]", ")", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                        ", "out_d_p", ".", "write", "(", "\"\\t\"", ".", "join", "(", "[", "f\"{s:.2f}\"", "for", "s", "in", "res", "[", "1", "]", "[", ":", "args", ".", "n_print_docs", "]", "]", ")", "+", "'\\n'", ")", "\n", "\n", "\n", "", "", "", "", "", "logger", ".", "info", "(", "'Save top id to: %s'", ",", "save_to", ")", "\n", "with", "open", "(", "save_to", ",", "'w'", ")", "as", "out_f", ":", "\n", "        ", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "top_ids_and_scores", ")", ",", "desc", "=", "f\"Extract top {args.n_docs} docs\"", ")", "as", "pbar", ":", "\n", "            ", "for", "idx", ",", "res", "in", "enumerate", "(", "tqdm", ".", "tqdm", "(", "top_ids_and_scores", ",", "desc", "=", "\"Iteration\"", ")", ")", ":", "\n", "                ", "assert", "(", "args", ".", "n_docs", "<=", "len", "(", "res", "[", "0", "]", ")", ")", "\n", "if", "args", ".", "remove_positive", ":", "\n", "                    ", "out_f", ".", "write", "(", "\"\\t\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "res", "[", "0", "]", "[", ":", "args", ".", "n_docs", "]", "if", "all_passages", "[", "str", "(", "x", ")", ".", "strip", "(", ")", "]", "[", "0", "]", "!=", "all_passages", "[", "str", "(", "idx", "+", "1", ")", "]", "[", "0", "]", "]", ")", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                    ", "out_f", ".", "write", "(", "\"\\t\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "res", "[", "0", "]", "[", ":", "args", ".", "n_docs", "]", "]", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.retriever_ft.generate_str_vectors": [[22, 49], ["len", "enumerate", "torch.cat().to", "range", "torch.stack().cuda", "torch.zeros_like().cuda", "tensorizer.get_attn_mask", "torch.stack().cuda.to", "torch.zeros_like().cuda.to", "tensorizer.get_attn_mask.to", "encoder", "query_vectors.extend", "torch.cat().to.size", "len", "tensorizer.text_to_tensor", "out.cpu().split", "logger.info", "torch.cat", "torch.stack", "torch.zeros_like", "len", "len", "out.cpu"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor"], ["def", "generate_str_vectors", "(", "encoder", ",", "tensorizer", ",", "questions", ",", "device", ",", "bsz", "=", "1", ")", ":", "\n", "    ", "n", "=", "len", "(", "questions", ")", "\n", "query_vectors", "=", "[", "]", "\n", "\n", "for", "j", ",", "batch_start", "in", "enumerate", "(", "range", "(", "0", ",", "n", ",", "bsz", ")", ")", ":", "\n", "\n", "        ", "batch_token_tensors", "=", "[", "tensorizer", ".", "text_to_tensor", "(", "q", ")", "for", "q", "in", "\n", "questions", "[", "batch_start", ":", "batch_start", "+", "bsz", "]", "]", "\n", "\n", "q_ids_batch", "=", "torch", ".", "stack", "(", "batch_token_tensors", ",", "dim", "=", "0", ")", ".", "cuda", "(", ")", "\n", "q_seg_batch", "=", "torch", ".", "zeros_like", "(", "q_ids_batch", ")", ".", "cuda", "(", ")", "\n", "q_attn_mask", "=", "tensorizer", ".", "get_attn_mask", "(", "q_ids_batch", ")", "\n", "q_ids_batch", ".", "to", "(", "device", ")", "\n", "q_seg_batch", ".", "to", "(", "device", ")", "\n", "q_attn_mask", ".", "to", "(", "device", ")", "\n", "\n", "_", ",", "out", ",", "_", "=", "encoder", "(", "q_ids_batch", ",", "q_seg_batch", ",", "q_attn_mask", ")", "\n", "\n", "query_vectors", ".", "extend", "(", "out", ".", "cpu", "(", ")", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ")", "\n", "\n", "if", "len", "(", "query_vectors", ")", "%", "100", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Encoded queries %d'", ",", "len", "(", "query_vectors", ")", ")", "\n", "\n", "", "", "query_tensor", "=", "torch", ".", "cat", "(", "query_vectors", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "\n", "\n", "assert", "query_tensor", ".", "size", "(", "0", ")", "==", "len", "(", "questions", ")", "\n", "return", "query_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.retriever_ft.retriever_finetune": [[50, 257], ["generator_model.eval", "retriever_model.train", "time.time", "tuple", "time.time", "torch.exp", "hasattr", "torch.stack", "loss.mean.sum().mean", "dot_product.mean.sum().mean", "reward.mean.sum().mean", "input_ids.size", "time.time", "generator_model.train", "retriever_model.eval", "retriever_model.train", "torch.no_grad", "dialogpt.gpt2_training.eval_utils.retrieve_top_docs", "int", "time.time", "range", "retriever_ft.generate_str_vectors", "torch.stack", "retriever_ft.generate_str_vectors", "torch.stack", "torch.no_grad", "torch.softmax", "torch.log_softmax", "NotImplementedError", "loss.mean.mean", "dot_product.mean.mean", "reward.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "float", "float", "torch.exp().mean().item", "input_ids.size", "dialogpt.gpt2_training.train_utils.set_lr", "optimizer.step", "retriever_model.zero_grad", "hasattr", "torch.save", "dialogpt.gpt2_training.eval_utils.eval_model_loss_joint_training", "print", "print", "logger.info", "hasattr", "torch.distributed.barrier", "t.to", "dialogpt.data_loader.convert_examples_to_features_dynamic", "eval_dataloader_loss._batch_feature", "tuple", "generator_model.forward_pointwise", "loss_ret_topK.append", "all_example.extend", "torch.stack", "torch.mv", "torch.mean", "d_scores.to", "torch.mean", "loss.mean.sum", "dot_product.mean.sum", "reward.mean.sum", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "loss.mean.item", "dot_product.mean.item", "dialogpt.gpt2_training.distributed.all_reduce_and_rescale_tensors", "sum", "sum", "print", "print", "extract_top_docs.init_retriever", "extract_top_docs.init_retriever", "torch.distributed.get_rank", "k.replace", "collections.OrderedDict", "os.path.join", "experiment.log_metrics", "dialogpt.gpt2_training.train_utils.RedditExample", "retriever_ft.generate_str_vectors", "retriever_ft.generate_str_vectors", "range", "torch.exp().mean", "float", "sum", "torch.distributed.get_world_size", "sum", "torch.distributed.get_world_size", "sum", "torch.distributed.get_world_size", "sum", "torch.distributed.get_world_size", "dialogpt.gpt2_training.distributed.all_gather_list", "dialogpt.gpt2_training.distributed.all_gather_list", "torch.distributed.get_rank", "time.time", "pbar.set_postfix_str", "pbar.update", "v.cpu", "retriever_model.state_dict().items", "str", "doc.strip().split", "enumerate", "t.to", "range", "range", "len", "retriever_model.parameters", "dialogpt.gpt2_training.distributed.all_gather_list", "dialogpt.gpt2_training.distributed.all_gather_list", "dialogpt.gpt2_training.distributed.all_gather_list", "dialogpt.gpt2_training.distributed.all_gather_list", "copy.deepcopy", "copy.deepcopy", "zip", "len", "len", "torch.exp", "retriever_model.state_dict", "doc.strip", "range", "range", "torch.stack"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.retrieve_top_docs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.retriever_ft.generate_str_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.retriever_ft.generate_str_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.set_lr", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.step", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.eval_model_loss_joint_training", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.convert_examples_to_features_dynamic", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader._batch_feature", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.forward_pointwise", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.extract_top_docs.init_retriever", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.extract_top_docs.init_retriever", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_rank", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.retriever_ft.generate_str_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.retriever_ft.generate_str_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_rank", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list"], ["", "def", "retriever_finetune", "(", "args", ",", "batch", ",", "eval_dataloader_loss", ",", "global_step", ",", "EPS", ",", "device", ",", "step", ",", "n_gpu", ",", "\n", "enc", ",", "retriever_last", ",", "generator_model", ",", "retriever_model", ",", "\n", "optimizer", ",", "tensorizer", ",", "all_passages", ",", "\n", "config", ",", "epoch", ",", "pbar", ",", "train_logger", ",", "eval_logger", ",", "output_dir", ",", "stats", ",", "experiment", "=", "None", ")", ":", "\n", "\n", "    ", "generator_model", ".", "eval", "(", ")", "\n", "retriever_model", ".", "train", "(", ")", "\n", "step", "-=", "1", "\n", "(", "tr_loss", ",", "tr_ppl", ",", "mean_ppl", ",", "nb_tr_examples", ",", "nb_tr_steps", ")", "=", "stats", "[", "'tr_loss'", "]", ",", "stats", "[", "'tr_ppl'", "]", ",", "stats", "[", "'mean_ppl'", "]", ",", "stats", "[", "'nb_tr_examples'", "]", ",", "stats", "[", "'nb_tr_steps'", "]", "\n", "tr_dot_product", ",", "tr_reward", "=", "stats", "[", "'tr_dot_product'", "]", ",", "stats", "[", "'tr_reward'", "]", "\n", "n_token_real", ",", "n_token_total", "=", "stats", "[", "'n_token_real'", "]", ",", "stats", "[", "'n_token_total'", "]", "\n", "train_start_time_epoch", "=", "time", ".", "time", "(", ")", "\n", "ret_time", ",", "gen_time", "=", "stats", "[", "'ret_time'", "]", ",", "stats", "[", "'gen_time'", "]", "\n", "\n", "if", "(", "global_step", ")", "%", "args", ".", "valid_step", "==", "0", ":", "\n", "        ", "retriever_model", ".", "eval", "(", ")", "\n", "if", "global_step", "!=", "0", ":", "\n", "            ", "if", "hasattr", "(", "retriever_model", ",", "'module'", ")", ":", "\n", "                ", "retriever_last", ",", "all_passages", "=", "init_retriever", "(", "args", ",", "eval_on_each", "=", "args", ".", "eval_on_each", ",", "\n", "encoder", "=", "copy", ".", "deepcopy", "(", "retriever_model", ".", "module", ".", "question_model", ")", ",", "tensorizer", "=", "tensorizer", ",", "\n", "force_index", "=", "True", ",", "file_suffix", "=", "args", ".", "file_suffix", ")", "\n", "", "else", ":", "\n", "                ", "retriever_last", ",", "all_passages", "=", "init_retriever", "(", "args", ",", "eval_on_each", "=", "args", ".", "eval_on_each", ",", "\n", "encoder", "=", "copy", ".", "deepcopy", "(", "retriever_model", ".", "question_model", ")", ",", "tensorizer", "=", "tensorizer", ",", "\n", "force_index", "=", "True", ",", "file_suffix", "=", "args", ".", "file_suffix", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "state_dict", "=", "{", "k", ".", "replace", "(", "'module.'", ",", "''", ")", ":", "(", "v", ".", "cpu", "(", ")", "if", "v", "is", "not", "None", "else", "None", ")", "\n", "for", "k", ",", "v", "in", "retriever_model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "}", "\n", "torch", ".", "save", "(", "OrderedDict", "(", "[", "(", "'model_dict'", ",", "state_dict", ")", ",", "\n", "(", "'optimizer_dict'", ",", "None", ")", ",", "\n", "(", "'scheduler_dict'", ",", "None", ")", ",", "\n", "(", "'offset'", ",", "None", ")", ",", "\n", "(", "'epoch'", ",", "None", ")", ",", "\n", "(", "'encoder_params'", ",", "None", ")", "]", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\n", "f'retriever-pretrain-step-{global_step}.pkl'", ")", ")", "\n", "eval_loss", ",", "eval_ppl", ",", "eval_reward", "=", "eval_model_loss_joint_training", "(", "\n", "generator_model", ",", "retriever_last", ",", "all_passages", ",", "enc", ",", "eval_dataloader_loss", ",", "epoch", ",", "args", ")", "\n", "print", "(", "'r step:{},eval_loss:{},eval_ppl:{},eval_reward:{}'", ".", "format", "(", "global_step", "+", "1", ",", "eval_loss", ",", "eval_ppl", ",", "eval_reward", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "'R,{},{},{},{},{},{}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "global_step", "+", "1", ",", "step", "+", "1", ",", "eval_loss", ",", "eval_ppl", ",", "eval_reward", ")", ",", "\n", "file", "=", "eval_logger", ",", "flush", "=", "True", ")", "\n", "if", "experiment", "is", "not", "None", ":", "\n", "                ", "experiment", ".", "log_metrics", "(", "{", "\n", "'epoch_ret'", ":", "epoch", "+", "1", ",", "\n", "'global_step_ret'", ":", "global_step", "+", "1", ",", "\n", "'step_ret'", ":", "step", "+", "1", ",", "\n", "'eval_loss_ret'", ":", "eval_loss", ",", "\n", "'eval_ppl_ret'", ":", "eval_ppl", ",", "\n", "'eval_reward_ret'", ":", "eval_reward", "\n", "}", ")", "\n", "\n", "", "logger", ".", "info", "(", "'current learning rate: '", "\n", "+", "str", "(", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "retriever_model", ",", "'module'", ")", "and", "n_gpu", ">", "1", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "retriever_model", ".", "train", "(", ")", "\n", "\n", "", "seq_len", "=", "batch", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "input_ids", ",", "position_ids", ",", "token_ids", ",", "label_ids", ",", "*", "_", "=", "batch", "\n", "\n", "ret_start_time", "=", "time", ".", "time", "(", ")", "\n", "SUMMATION_RANGE", "=", "1", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "args", ".", "n_docs", "*=", "SUMMATION_RANGE", "\n", "\n", "ret_passages", ",", "ret_scores", ",", "cxt_str", ",", "rsp_str", "=", "retrieve_top_docs", "(", "input_ids", ",", "enc", ",", "retriever_last", ",", "all_passages", ",", "args", ")", "\n", "args", ".", "n_docs", "=", "int", "(", "args", ".", "n_docs", "/", "SUMMATION_RANGE", ")", "\n", "\n", "ret_end_time", "=", "time", ".", "time", "(", ")", "\n", "loss_ret_topK", "=", "[", "]", "\n", "all_example", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "args", ".", "n_docs", "*", "SUMMATION_RANGE", ")", ":", "\n", "\n", "            ", "doc_lines", "=", "[", "' '", ".", "join", "(", "doc", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "for", "doc", "in", "ret_passages", "[", "t", "]", "]", "\n", "examples", "=", "[", "RedditExample", "(", "i", ",", "doc_line", ",", "src_line", ",", "tgt_line", ")", "for", "i", ",", "(", "doc_line", ",", "src_line", ",", "tgt_line", ")", "in", "\n", "enumerate", "(", "zip", "(", "doc_lines", ",", "cxt_str", ",", "rsp_str", ")", ")", "]", "\n", "features", "=", "convert_examples_to_features_dynamic", "(", "examples", ",", "enc", ",", "\n", "args", ".", "max_seq_length", ")", "\n", "batch_ret", "=", "eval_dataloader_loss", ".", "_batch_feature", "(", "features", ")", "\n", "batch_ret", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch_ret", ")", "\n", "input_ids_ret", ",", "position_ids_ret", ",", "token_ids_ret", ",", "label_ids_ret", ",", "*", "_", "=", "batch_ret", "\n", "loss_ret", ",", "_", "=", "generator_model", ".", "forward_pointwise", "(", "input_ids_ret", ",", "position_ids_ret", ",", "token_ids_ret", ",", "\n", "label_ids_ret", ")", "\n", "loss_ret_topK", ".", "append", "(", "loss_ret", ")", "\n", "all_example", ".", "extend", "(", "examples", ")", "\n", "\n", "", "", "coeff", "=", "torch", ".", "exp", "(", "-", "torch", ".", "stack", "(", "loss_ret_topK", ")", ")", "\n", "\n", "if", "hasattr", "(", "retriever_model", ",", "'module'", ")", ":", "\n", "        ", "query_vector", "=", "generate_str_vectors", "(", "retriever_model", ".", "module", ".", "question_model", ",", "tensorizer", ",", "cxt_str", ",", "args", ".", "device", ")", "\n", "psg_vector", "=", "torch", ".", "stack", "(", "[", "generate_str_vectors", "(", "retriever_model", ".", "module", ".", "ctx_model", ",", "tensorizer", ",", "\n", "[", "ret_passages", "[", "i", "]", "[", "j", "]", "for", "i", "in", "range", "(", "args", ".", "n_docs", ")", "]", ",", "args", ".", "device", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "ret_passages", "[", "0", "]", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "query_vector", "=", "generate_str_vectors", "(", "retriever_model", ".", "question_model", ",", "tensorizer", ",", "cxt_str", ",", "args", ".", "device", ",", "args", ".", "train_batch_size", ")", "\n", "psg_vector", "=", "torch", ".", "stack", "(", "[", "generate_str_vectors", "(", "retriever_model", ".", "ctx_model", ",", "tensorizer", ",", "\n", "[", "ret_passages", "[", "i", "]", "[", "j", "]", "for", "i", "in", "range", "(", "args", ".", "n_docs", ")", "]", ",", "args", ".", "device", ",", "args", ".", "train_batch_size", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "ret_passages", "[", "0", "]", ")", ")", "]", ")", "\n", "\n", "", "mapping_dim", "=", "psg_vector", ".", "shape", "[", "-", "1", "]", "\n", "dot_product", "=", "torch", ".", "stack", "(", "[", "torch", ".", "mv", "(", "psg_vector", "[", "i", "]", ",", "query_vector", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "query_vector", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "        ", "d_scores", "=", "dot_product", "+", "EPS", "\n", "d_scores", "=", "d_scores", "-", "torch", ".", "mean", "(", "d_scores", ",", "axis", "=", "0", ")", "\n", "\n", "normalized_score", "=", "torch", ".", "softmax", "(", "d_scores", ".", "to", "(", "device", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "if", "args", ".", "rl_method", "==", "\"simple\"", ":", "\n", "        ", "reward", "=", "coeff", "\n", "reward", "=", "reward", "-", "torch", ".", "mean", "(", "reward", ",", "0", ")", "\n", "logpz_x", "=", "torch", ".", "log_softmax", "(", "dot_product", ",", "dim", "=", "0", ")", "\n", "loss", "=", "-", "logpz_x", "*", "normalized_score", "*", "reward", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'rl method cannot be '", "+", "args", ".", "rl_method", ")", "\n", "\n", "", "loss", "=", "loss", ".", "sum", "(", "0", ")", ".", "mean", "(", ")", "\n", "dot_product", "=", "dot_product", ".", "sum", "(", "0", ")", ".", "mean", "(", ")", "\n", "reward", "=", "reward", ".", "sum", "(", "0", ")", ".", "mean", "(", ")", "\n", "\n", "if", "n_gpu", ">", "1", ":", "\n", "        ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "dot_product", "=", "dot_product", ".", "mean", "(", ")", "\n", "reward", "=", "reward", ".", "mean", "(", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "from", "apex", "import", "amp", "\n", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "max_norm", "=", "1.0", ")", "\n", "", "else", ":", "\n", "        ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "float", "(", "loss", ".", "item", "(", ")", ")", "*", "(", "args", ".", "train_batch_size", "/", "input_ids", ".", "shape", "[", "0", "]", ")", "\n", "tr_dot_product", "+=", "float", "(", "dot_product", ".", "item", "(", ")", ")", "*", "(", "args", ".", "train_batch_size", "/", "input_ids", ".", "shape", "[", "0", "]", ")", "\n", "\n", "tr_reward", "+=", "torch", ".", "exp", "(", "-", "torch", ".", "stack", "(", "loss_ret_topK", ")", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "*", "input_ids", ".", "size", "(", "0", ")", "\n", "\n", "nb_tr_examples", "+=", "input_ids", ".", "size", "(", "0", ")", "\n", "nb_tr_steps", "+=", "1", "\n", "mean_loss", "=", "tr_loss", "/", "nb_tr_steps", "\n", "mean_dot_product", "=", "tr_dot_product", "/", "nb_tr_steps", "\n", "mean_reward", "=", "tr_reward", "/", "nb_tr_steps", "\n", "\n", "n_token_total", "+=", "input_ids", ".", "shape", "[", "0", "]", "*", "input_ids", ".", "shape", "[", "1", "]", "\n", "n_token_real", "+=", "(", "input_ids", "!=", "0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "gen_end_time", "=", "time", ".", "time", "(", ")", "\n", "ret_time", "+=", "(", "ret_end_time", "-", "ret_start_time", ")", "\n", "gen_time", "+=", "(", "gen_end_time", "-", "ret_end_time", ")", "\n", "\n", "step", "+=", "1", "\n", "if", "step", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "        ", "global_step", "-=", "1", "\n", "set_lr", "(", "optimizer", ",", "global_step", ",", "\n", "args", ".", "lr_schedule", ",", "args", ".", "learning_rate", ",", "\n", "args", ".", "warmup_steps", ",", "args", ".", "warmup_proportion", ",", "\n", "config", ".", "n_embd", ",", "args", ".", "num_optim_steps", ")", "\n", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "            ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "retriever_model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "all_reduce_and_rescale_tensors", "(", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "retriever_model", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "            ", "mean_loss", "=", "sum", "(", "all_gather_list", "(", "mean_loss", ")", ")", "/", "get_world_size", "(", ")", "\n", "mean_dot_product", "=", "sum", "(", "all_gather_list", "(", "mean_dot_product", ")", ")", "/", "get_world_size", "(", ")", "\n", "mean_reward", "=", "sum", "(", "all_gather_list", "(", "mean_reward", ")", ")", "/", "get_world_size", "(", ")", "\n", "mean_ppl", "=", "sum", "(", "all_gather_list", "(", "mean_ppl", ")", ")", "/", "get_world_size", "(", ")", "\n", "n_token_real_all_proc", "=", "sum", "(", "all_gather_list", "(", "n_token_real", ")", ")", "\n", "n_token_total_all_proc", "=", "sum", "(", "all_gather_list", "(", "n_token_total", ")", ")", "\n", "", "else", ":", "\n", "            ", "n_token_real_all_proc", "=", "n_token_real", "\n", "n_token_total_all_proc", "=", "n_token_total", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "epoch_time", "=", "time", ".", "time", "(", ")", "-", "train_start_time_epoch", "\n", "if", "pbar", "is", "not", "None", ":", "\n", "                ", "pbar", ".", "set_postfix_str", "(", "\n", "f\"tok/s: {n_token_real_all_proc // epoch_time // 1000}k \"", "\n", "f\"ppl: {mean_ppl:.2f}   loss:{mean_loss:.2f}   epoch: {epoch}\"", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "print", "(", "'Epoch:{}, Retrival step:{},loss:{:.3f},ppl:{:.3f},ret_time:{:.3f},gen_time:{:.3f},reward:{:.3f},dot_prod:{:.3f}'", ".", "format", "(", "epoch", "+", "1", ",", "global_step", "+", "1", ",", "mean_loss", ",", "mean_ppl", ",", "ret_time", ",", "gen_time", ",", "mean_reward", ",", "mean_dot_product", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "'R,{},{},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "global_step", "+", "1", ",", "mean_loss", ",", "mean_ppl", ",", "ret_time", ",", "gen_time", ",", "mean_reward", ",", "mean_dot_product", ")", ",", "\n", "file", "=", "train_logger", ",", "flush", "=", "True", ")", "\n", "ret_time", ",", "gen_time", "=", "0.0", ",", "0.0", "\n", "\n", "", "", "generator_model", ".", "train", "(", ")", "\n", "\n", "stats", "[", "'tr_loss'", "]", ",", "stats", "[", "'tr_ppl'", "]", ",", "stats", "[", "'mean_ppl'", "]", ",", "stats", "[", "'nb_tr_examples'", "]", ",", "stats", "[", "'nb_tr_steps'", "]", "=", "(", "tr_loss", ",", "tr_ppl", ",", "mean_ppl", ",", "nb_tr_examples", ",", "nb_tr_steps", ")", "\n", "stats", "[", "'tr_dot_product'", "]", ",", "stats", "[", "'tr_reward'", "]", "=", "tr_dot_product", ",", "tr_reward", "\n", "stats", "[", "'n_token_real'", "]", ",", "stats", "[", "'n_token_total'", "]", "=", "n_token_real", ",", "n_token_total", "\n", "stats", "[", "'ret_time'", "]", ",", "stats", "[", "'gen_time'", "]", "=", "ret_time", ",", "gen_time", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.__init__": [[50, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "question_encoder", ":", "nn", ".", "Module", ",", "batch_size", ":", "int", ",", "tensorizer", ":", "Tensorizer", ",", "index", ":", "DenseIndexer", ")", ":", "\n", "        ", "self", ".", "question_encoder", "=", "question_encoder", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "tensorizer", "=", "tensorizer", "\n", "self", ".", "index", "=", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.generate_question_vectors": [[56, 83], ["len", "dense_retriever.DenseRetriever.question_encoder.eval", "torch.cat", "torch.no_grad", "enumerate", "torch.cat.size", "len", "range", "torch.stack().cuda", "torch.zeros_like().cuda", "dense_retriever.DenseRetriever.tensorizer.get_attn_mask", "dense_retriever.DenseRetriever.question_encoder", "query_vectors.extend", "dense_retriever.DenseRetriever.tensorizer.text_to_tensor", "out.cpu().split", "logger.info", "torch.stack", "torch.zeros_like", "len", "len", "out.cpu"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor"], ["", "def", "generate_question_vectors", "(", "self", ",", "questions", ":", "List", "[", "str", "]", ")", "->", "T", ":", "\n", "        ", "n", "=", "len", "(", "questions", ")", "\n", "bsz", "=", "self", ".", "batch_size", "\n", "query_vectors", "=", "[", "]", "\n", "\n", "self", ".", "question_encoder", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "j", ",", "batch_start", "in", "enumerate", "(", "range", "(", "0", ",", "n", ",", "bsz", ")", ")", ":", "\n", "\n", "                ", "batch_token_tensors", "=", "[", "self", ".", "tensorizer", ".", "text_to_tensor", "(", "q", ")", "for", "q", "in", "\n", "questions", "[", "batch_start", ":", "batch_start", "+", "bsz", "]", "]", "\n", "\n", "q_ids_batch", "=", "torch", ".", "stack", "(", "batch_token_tensors", ",", "dim", "=", "0", ")", ".", "cuda", "(", ")", "\n", "q_seg_batch", "=", "torch", ".", "zeros_like", "(", "q_ids_batch", ")", ".", "cuda", "(", ")", "\n", "q_attn_mask", "=", "self", ".", "tensorizer", ".", "get_attn_mask", "(", "q_ids_batch", ")", "\n", "_", ",", "out", ",", "_", "=", "self", ".", "question_encoder", "(", "q_ids_batch", ",", "q_seg_batch", ",", "q_attn_mask", ")", "\n", "\n", "query_vectors", ".", "extend", "(", "out", ".", "cpu", "(", ")", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ")", "\n", "\n", "if", "len", "(", "query_vectors", ")", "%", "100", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'Encoded queries %d'", ",", "len", "(", "query_vectors", ")", ")", "\n", "\n", "", "", "", "query_tensor", "=", "torch", ".", "cat", "(", "query_vectors", ",", "dim", "=", "0", ")", "\n", "\n", "assert", "query_tensor", ".", "size", "(", "0", ")", "==", "len", "(", "questions", ")", "\n", "return", "query_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.index_encoded_data": [[84, 107], ["set", "enumerate", "dense_retriever.DenseRetriever.index.index_data", "logger.info", "dense_retriever.iterate_encoded_files", "buffer.append", "len", "dense_retriever.DenseRetriever.index.index_data", "doc_vector.tostring", "set.add", "doc_vector.tostring"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.index_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.iterate_encoded_files", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.index_data"], ["", "def", "index_encoded_data", "(", "self", ",", "vector_files", ":", "List", "[", "str", "]", ",", "buffer_size", ":", "int", "=", "50000", ",", "remove_duplicates", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Indexes encoded passages takes form a list of files\n        :param vector_files: file names to get passages vectors from\n        :param buffer_size: size of a buffer (amount of passages) to send for the indexing at once\n        :return:\n        \"\"\"", "\n", "existing", "=", "set", "(", "[", "]", ")", "\n", "buffer", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "iterate_encoded_files", "(", "vector_files", ")", ")", ":", "\n", "            ", "db_id", ",", "doc_vector", "=", "item", "\n", "\n", "if", "remove_duplicates", ":", "\n", "                ", "if", "doc_vector", ".", "tostring", "(", ")", "in", "existing", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "existing", ".", "add", "(", "doc_vector", ".", "tostring", "(", ")", ")", "\n", "", "", "buffer", ".", "append", "(", "(", "db_id", ",", "doc_vector", ")", ")", "\n", "if", "0", "<", "buffer_size", "==", "len", "(", "buffer", ")", ":", "\n", "                ", "self", ".", "index", ".", "index_data", "(", "buffer", ")", "\n", "buffer", "=", "[", "]", "\n", "", "", "self", ".", "index", ".", "index_data", "(", "buffer", ")", "\n", "logger", ".", "info", "(", "'Data indexing completed.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.get_top_docs": [[108, 126], ["time.time", "dense_retriever.DenseRetriever.index.search_knn", "numpy.array", "numpy.dot", "dense_retriever.DenseRetriever.index.index_id_to_db_id.index", "range", "range", "dense_retriever.DenseRetriever.index.index.reconstruct", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.search_knn"], ["", "def", "get_top_docs", "(", "self", ",", "query_vectors", ":", "np", ".", "array", ",", "top_docs", ":", "int", "=", "100", ",", "is_hnsw", ":", "bool", "=", "False", ")", "->", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Does the retrieval of the best matching passages given the query vectors batch\n        :param query_vectors:\n        :param top_docs:\n        :return:\n        \"\"\"", "\n", "time0", "=", "time", ".", "time", "(", ")", "\n", "\n", "results", "=", "self", ".", "index", ".", "search_knn", "(", "query_vectors", ",", "top_docs", ")", "\n", "\n", "if", "is_hnsw", ":", "\n", "            ", "top_index_ids", "=", "[", "[", "self", ".", "index", ".", "index_id_to_db_id", ".", "index", "(", "i", ")", "for", "i", "in", "x", "[", "0", "]", "]", "for", "x", "in", "results", "]", "\n", "top_vecs", "=", "np", ".", "array", "(", "[", "[", "self", ".", "index", ".", "index", ".", "reconstruct", "(", "i", ")", "for", "i", "in", "x", "]", "for", "x", "in", "top_index_ids", "]", ")", "\n", "new_score", "=", "[", "np", ".", "dot", "(", "top_vecs", "[", "i", ",", ":", ",", ":", "-", "1", "]", ",", "query_vectors", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "query_vectors", ")", ")", "]", "\n", "results", "=", "[", "(", "results", "[", "i", "]", "[", "0", "]", ",", "new_score", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "query_vectors", ")", ")", "]", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.parse_qa_csv_file": [[127, 137], ["open", "csv.reader", "eval"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval"], ["", "", "def", "parse_qa_csv_file", "(", "location", ",", "simple_parser", "=", "False", ")", "->", "Iterator", "[", "Tuple", "[", "str", ",", "List", "[", "str", "]", "]", "]", ":", "\n", "    ", "with", "open", "(", "location", ")", "as", "ifile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "ifile", ",", "delimiter", "=", "'\\t'", ")", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "question", "=", "row", "[", "0", "]", "\n", "if", "simple_parser", ":", "\n", "                ", "answers", "=", "[", "row", "[", "1", "]", "[", "2", ":", "-", "2", "]", "]", "\n", "", "else", ":", "\n", "                ", "answers", "=", "eval", "(", "row", "[", "1", "]", ")", "\n", "", "yield", "question", ",", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.validate": [[138, 148], ["dpr.data.qa_validation.calculate_matches", "logger.info", "logger.info", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.calculate_matches"], ["", "", "", "def", "validate", "(", "passages", ":", "Dict", "[", "object", ",", "Tuple", "[", "str", ",", "str", "]", "]", ",", "answers", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "result_ctx_ids", ":", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ",", "\n", "workers_num", ":", "int", ",", "match_type", ":", "str", ")", "->", "List", "[", "List", "[", "bool", "]", "]", ":", "\n", "    ", "match_stats", "=", "calculate_matches", "(", "passages", ",", "answers", ",", "result_ctx_ids", ",", "workers_num", ",", "match_type", ")", "\n", "top_k_hits", "=", "match_stats", ".", "top_k_hits", "\n", "\n", "logger", ".", "info", "(", "'Validation results: top k documents hits %s'", ",", "top_k_hits", ")", "\n", "top_k_hits", "=", "[", "v", "/", "len", "(", "result_ctx_ids", ")", "for", "v", "in", "top_k_hits", "]", "\n", "logger", ".", "info", "(", "'Validation results: top k documents hits accuracy %s'", ",", "top_k_hits", ")", "\n", "return", "match_stats", ".", "questions_doc_hits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.load_passages": [[149, 159], ["logger.info", "open", "row.strip().split.strip().split", "row.strip().split.strip", "row[].strip"], "function", ["None"], ["", "def", "load_passages", "(", "ctx_file", ":", "str", ")", "->", "Dict", "[", "object", ",", "Tuple", "[", "str", ",", "str", "]", "]", ":", "\n", "    ", "docs", "=", "{", "}", "\n", "logger", ".", "info", "(", "'Reading data from: %s'", ",", "ctx_file", ")", "\n", "with", "open", "(", "ctx_file", ")", "as", "tsvfile", ":", "\n", "\n", "        ", "for", "row", "in", "tsvfile", ":", "\n", "            ", "row", "=", "row", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "row", "[", "0", "]", "!=", "'id'", ":", "\n", "                ", "docs", "[", "row", "[", "0", "]", ".", "strip", "(", ")", "]", "=", "(", "row", "[", "1", "]", ",", "row", "[", "2", "]", ")", "\n", "", "", "", "return", "docs", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.save_results": [[160, 192], ["enumerate", "logger.info", "len", "len", "len", "len", "merged_data.append", "open", "writer.write", "str", "json.dumps", "range"], "function", ["None"], ["", "def", "save_results", "(", "passages", ":", "Dict", "[", "object", ",", "Tuple", "[", "str", ",", "str", "]", "]", ",", "questions", ":", "List", "[", "str", "]", ",", "answers", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "top_passages_and_scores", ":", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ",", "per_question_hits", ":", "List", "[", "List", "[", "bool", "]", "]", ",", "\n", "out_file", ":", "str", "\n", ")", ":", "\n", "\n", "    ", "merged_data", "=", "[", "]", "\n", "assert", "len", "(", "per_question_hits", ")", "==", "len", "(", "questions", ")", "==", "len", "(", "answers", ")", "\n", "for", "i", ",", "q", "in", "enumerate", "(", "questions", ")", ":", "\n", "        ", "q_answers", "=", "answers", "[", "i", "]", "\n", "results_and_scores", "=", "top_passages_and_scores", "[", "i", "]", "\n", "hits", "=", "per_question_hits", "[", "i", "]", "\n", "docs", "=", "[", "passages", "[", "doc_id", "]", "for", "doc_id", "in", "results_and_scores", "[", "0", "]", "]", "\n", "scores", "=", "[", "str", "(", "score", ")", "for", "score", "in", "results_and_scores", "[", "1", "]", "]", "\n", "ctxs_num", "=", "len", "(", "hits", ")", "\n", "\n", "merged_data", ".", "append", "(", "{", "\n", "'question'", ":", "q", ",", "\n", "'answers'", ":", "q_answers", ",", "\n", "'ctxs'", ":", "[", "\n", "{", "\n", "'id'", ":", "results_and_scores", "[", "0", "]", "[", "c", "]", ",", "\n", "'title'", ":", "docs", "[", "c", "]", "[", "1", "]", ",", "\n", "'text'", ":", "docs", "[", "c", "]", "[", "0", "]", ",", "\n", "'score'", ":", "scores", "[", "c", "]", ",", "\n", "'has_answer'", ":", "hits", "[", "c", "]", ",", "\n", "}", "for", "c", "in", "range", "(", "ctxs_num", ")", "\n", "]", "\n", "}", ")", "\n", "\n", "", "with", "open", "(", "out_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "merged_data", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "", "logger", ".", "info", "(", "'Saved results * scores  to %s'", ",", "out_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.iterate_encoded_files": [[193, 201], ["enumerate", "logger.info", "open", "pickle.load"], "function", ["None"], ["", "def", "iterate_encoded_files", "(", "vector_files", ":", "list", ")", "->", "Iterator", "[", "Tuple", "[", "object", ",", "np", ".", "array", "]", "]", ":", "\n", "    ", "for", "i", ",", "file", "in", "enumerate", "(", "vector_files", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Reading file %s'", ",", "file", ")", "\n", "with", "open", "(", "file", ",", "\"rb\"", ")", "as", "reader", ":", "\n", "            ", "doc_vectors", "=", "pickle", ".", "load", "(", "reader", ")", "\n", "for", "doc", "in", "doc_vectors", ":", "\n", "                ", "db_id", ",", "doc_vector", "=", "doc", "\n", "yield", "db_id", ",", "doc_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.main": [[202, 262], ["dpr.utils.model_utils.load_states_from_checkpoint", "dpr.options.set_encoder_params_from_state", "dpr.models.init_biencoder_components", "dpr.utils.model_utils.setup_for_distributed_mode", "encoder.eval", "dpr.utils.model_utils.get_model_obj", "logger.info", "len", "dpr.utils.model_utils.get_model_obj.load_state_dict", "dpr.utils.model_utils.get_model_obj.get_out_size", "logger.info", "dense_retriever.DenseRetriever", "glob.glob", "logger.info", "dense_retriever.DenseRetriever.index_encoded_data", "dense_retriever.parse_qa_csv_file", "dense_retriever.DenseRetriever.generate_question_vectors", "dense_retriever.DenseRetriever.get_top_docs", "dense_retriever.load_passages", "dense_retriever.validate", "dpr.indexer.faiss_indexers.DenseHNSWFlatIndexer", "dpr.indexer.faiss_indexers.DenseFlatIndexer", "questions.append", "question_answers.append", "retriever.generate_question_vectors.numpy", "len", "RuntimeError", "dense_retriever.save_results", "dpr.utils.model_utils.load_states_from_checkpoint.model_dict.items", "key.startswith"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_encoder_params_from_state", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_biencoder_components", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.setup_for_distributed_mode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_obj", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.get_out_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.index_encoded_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.parse_qa_csv_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.generate_question_vectors", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.DenseRetriever.get_top_docs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.load_passages", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.validate", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.dense_retriever.save_results"], ["", "", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "saved_state", "=", "load_states_from_checkpoint", "(", "args", ".", "model_file", ")", "\n", "set_encoder_params_from_state", "(", "saved_state", ".", "encoder_params", ",", "args", ")", "\n", "\n", "tensorizer", ",", "encoder", ",", "_", "=", "init_biencoder_components", "(", "args", ".", "encoder_model_type", ",", "args", ",", "inference_only", "=", "True", ")", "\n", "\n", "encoder", "=", "encoder", ".", "question_model", "\n", "\n", "encoder", ",", "_", "=", "setup_for_distributed_mode", "(", "encoder", ",", "None", ",", "args", ".", "device", ",", "args", ".", "n_gpu", ",", "\n", "args", ".", "local_rank", ",", "\n", "args", ".", "fp16", ")", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "model_to_load", "=", "get_model_obj", "(", "encoder", ")", "\n", "logger", ".", "info", "(", "'Loading saved model state ...'", ")", "\n", "\n", "prefix_len", "=", "len", "(", "'question_model.'", ")", "\n", "question_encoder_state", "=", "{", "key", "[", "prefix_len", ":", "]", ":", "value", "for", "(", "key", ",", "value", ")", "in", "saved_state", ".", "model_dict", ".", "items", "(", ")", "if", "\n", "key", ".", "startswith", "(", "'question_model.'", ")", "}", "\n", "model_to_load", ".", "load_state_dict", "(", "question_encoder_state", ")", "\n", "vector_size", "=", "model_to_load", ".", "get_out_size", "(", ")", "\n", "logger", ".", "info", "(", "'Encoder vector_size=%d'", ",", "vector_size", ")", "\n", "\n", "index_buffer_sz", "=", "args", ".", "index_buffer", "\n", "if", "args", ".", "hnsw_index", ":", "\n", "        ", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ")", "\n", "index_buffer_sz", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "index", "=", "DenseFlatIndexer", "(", "vector_size", ")", "\n", "\n", "", "retriever", "=", "DenseRetriever", "(", "encoder", ",", "args", ".", "batch_size", ",", "tensorizer", ",", "index", ")", "\n", "\n", "ctx_files_pattern", "=", "args", ".", "encoded_ctx_file", "\n", "input_paths", "=", "glob", ".", "glob", "(", "ctx_files_pattern", ")", "\n", "logger", ".", "info", "(", "'Reading all passages data from files: %s'", ",", "input_paths", ")", "\n", "retriever", ".", "index_encoded_data", "(", "input_paths", ",", "buffer_size", "=", "index_buffer_sz", ")", "\n", "\n", "questions", "=", "[", "]", "\n", "question_answers", "=", "[", "]", "\n", "\n", "for", "ds_item", "in", "parse_qa_csv_file", "(", "args", ".", "qa_file", ")", ":", "\n", "        ", "question", ",", "answers", "=", "ds_item", "\n", "questions", ".", "append", "(", "question", ")", "\n", "question_answers", ".", "append", "(", "answers", ")", "\n", "\n", "", "questions_tensor", "=", "retriever", ".", "generate_question_vectors", "(", "questions", ")", "\n", "\n", "top_ids_and_scores", "=", "retriever", ".", "get_top_docs", "(", "questions_tensor", ".", "numpy", "(", ")", ",", "args", ".", "n_docs", ",", "is_hnsw", "=", "args", ".", "hnsw_index", ")", "\n", "\n", "all_passages", "=", "load_passages", "(", "args", ".", "ctx_file", ")", "\n", "\n", "if", "len", "(", "all_passages", ")", "==", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "'No passages data found. Please specify ctx_file param properly.'", ")", "\n", "\n", "", "questions_doc_hits", "=", "validate", "(", "all_passages", ",", "question_answers", ",", "top_ids_and_scores", ",", "args", ".", "validation_workers", ",", "\n", "args", ".", "match", ")", "\n", "\n", "if", "args", ".", "out_file", ":", "\n", "        ", "save_results", "(", "all_passages", ",", "questions", ",", "question_answers", ",", "top_ids_and_scores", ",", "questions_doc_hits", ",", "args", ".", "out_file", ")", "\n", "", "return", "questions_doc_hits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.__init__": [[59, 95], ["logger.info", "dpr.models.init_biencoder_components", "dpr.utils.model_utils.setup_for_distributed_mode", "dpr.utils.model_utils.get_model_file", "dpr.utils.model_utils.load_states_from_checkpoint", "dpr.options.set_encoder_params_from_state", "train_dense_encoder_modified.BiEncoderTrainer._load_saved_state"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_biencoder_components", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.setup_for_distributed_mode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_encoder_params_from_state", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer._load_saved_state"], ["def", "__init__", "(", "self", ",", "args", ",", "experiment", "=", "None", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "shard_id", "=", "args", ".", "local_rank", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "0", "\n", "self", ".", "distributed_factor", "=", "args", ".", "distributed_world_size", "or", "1", "\n", "\n", "logger", ".", "info", "(", "\"***** Initializing components for training *****\"", ")", "\n", "\n", "# if model file is specified, encoder parameters from saved state should be used for initialization", "\n", "if", "self", ".", "args", ".", "model_file", ":", "\n", "            ", "model_file", "=", "self", ".", "args", ".", "model_file", "\n", "", "else", ":", "\n", "            ", "model_file", "=", "get_model_file", "(", "self", ".", "args", ",", "self", ".", "args", ".", "checkpoint_file_name", ")", "\n", "\n", "", "saved_state", "=", "None", "\n", "if", "model_file", ":", "\n", "            ", "saved_state", "=", "load_states_from_checkpoint", "(", "model_file", ")", "\n", "set_encoder_params_from_state", "(", "saved_state", ".", "encoder_params", ",", "args", ")", "\n", "\n", "", "tensorizer", ",", "model", ",", "optimizer", "=", "init_biencoder_components", "(", "args", ".", "encoder_model_type", ",", "args", ")", "\n", "\n", "model", ",", "optimizer", "=", "setup_for_distributed_mode", "(", "model", ",", "optimizer", ",", "args", ".", "device", ",", "args", ".", "n_gpu", ",", "\n", "args", ".", "local_rank", ",", "\n", "args", ".", "fp16", ",", "\n", "args", ".", "fp16_opt_level", ")", "\n", "self", ".", "experiment", "=", "experiment", "\n", "self", ".", "biencoder", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "tensorizer", "=", "tensorizer", "\n", "self", ".", "start_epoch", "=", "0", "\n", "self", ".", "start_batch", "=", "0", "\n", "self", ".", "scheduler_state", "=", "None", "\n", "self", ".", "best_validation_result", "=", "None", "\n", "self", ".", "best_cp_name", "=", "None", "\n", "if", "saved_state", ":", "\n", "            ", "strict", "=", "True", "if", "args", ".", "projection_dim", "==", "0", "else", "False", "\n", "self", ".", "_load_saved_state", "(", "saved_state", ",", "strict", "=", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_data_iterator": [[96, 111], ["glob.glob", "dpr.utils.data_utils.read_data_from_json_files", "dpr.utils.dist_utils.is_main_process", "dpr.utils.data_utils.ShardedDataIterator", "logger.info", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.read_data_from_json_files", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process"], ["", "", "def", "get_data_iterator", "(", "self", ",", "path", ":", "str", ",", "batch_size", ":", "int", ",", "shuffle", "=", "True", ",", "\n", "shuffle_seed", ":", "int", "=", "0", ",", "\n", "offset", ":", "int", "=", "0", ",", "upsample_rates", ":", "list", "=", "None", ")", "->", "ShardedDataIterator", ":", "\n", "        ", "data_files", "=", "glob", ".", "glob", "(", "path", ")", "\n", "data", "=", "read_data_from_json_files", "(", "data_files", ",", "upsample_rates", ")", "\n", "\n", "# filter those without positive ctx", "\n", "data", "=", "[", "r", "for", "r", "in", "data", "if", "len", "(", "r", "[", "'positive_ctxs'", "]", ")", ">", "0", "]", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'Total cleaned data size: {}'", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "\n", "", "return", "ShardedDataIterator", "(", "data", ",", "shard_id", "=", "self", ".", "shard_id", ",", "\n", "num_shards", "=", "self", ".", "distributed_factor", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "shuffle_seed", "=", "shuffle_seed", ",", "offset", "=", "offset", ",", "\n", "strict_batch_size", "=", "True", ",", "# this is not really necessary, one can probably disable it", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_wiki_iterator": [[113, 128], ["glob.glob", "dpr.utils.data_utils.read_data_from_wiki_to_json", "dpr.utils.dist_utils.is_main_process", "dpr.utils.data_utils.ShardedDataIterator", "logger.info", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.read_data_from_wiki_to_json", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process"], ["", "def", "get_wiki_iterator", "(", "self", ",", "path", ":", "str", ",", "batch_size", ":", "int", ",", "shuffle", "=", "True", ",", "\n", "shuffle_seed", ":", "int", "=", "0", ",", "\n", "offset", ":", "int", "=", "0", ",", "upsample_rates", ":", "list", "=", "None", ")", "->", "ShardedDataIterator", ":", "\n", "        ", "data_files", "=", "glob", ".", "glob", "(", "path", ")", "\n", "data", "=", "read_data_from_wiki_to_json", "(", "data_files", ",", "shuffle_seed", ",", "upsample_rates", ")", "\n", "\n", "# filter those without positive ctx", "\n", "data", "=", "[", "r", "for", "r", "in", "data", "if", "len", "(", "r", "[", "'positive_ctxs'", "]", ")", ">", "0", "]", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'Total cleaned data size: {}'", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "\n", "", "return", "ShardedDataIterator", "(", "data", ",", "shard_id", "=", "self", ".", "shard_id", ",", "\n", "num_shards", "=", "self", ".", "distributed_factor", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "shuffle_seed", "=", "shuffle_seed", ",", "offset", "=", "offset", ",", "\n", "strict_batch_size", "=", "True", ",", "# this is not really necessary, one can probably disable it", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_dialog_iterator": [[130, 145], ["glob.glob", "dpr.utils.data_utils.read_data_from_wiki_to_json", "dpr.utils.dist_utils.is_main_process", "dpr.utils.data_utils.ShardedDataIterator", "logger.info", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.read_data_from_wiki_to_json", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process"], ["", "def", "get_dialog_iterator", "(", "self", ",", "path", ":", "str", ",", "batch_size", ":", "int", ",", "shuffle", "=", "True", ",", "\n", "shuffle_seed", ":", "int", "=", "0", ",", "\n", "offset", ":", "int", "=", "0", ",", "upsample_rates", ":", "list", "=", "None", ",", "hard_negative_path", ":", "str", "=", "None", ")", "->", "ShardedDataIterator", ":", "\n", "        ", "data_files", "=", "glob", ".", "glob", "(", "path", ")", "\n", "data", "=", "read_data_from_wiki_to_json", "(", "data_files", ",", "shuffle_seed", ",", "upsample_rates", ",", "is_dialog", "=", "True", ",", "hard_negative_path", "=", "hard_negative_path", ")", "\n", "\n", "# filter those without positive ctx", "\n", "data", "=", "[", "r", "for", "r", "in", "data", "if", "len", "(", "r", "[", "'positive_ctxs'", "]", ")", ">", "0", "]", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'Total cleaned data size: {}'", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "\n", "", "return", "ShardedDataIterator", "(", "data", ",", "shard_id", "=", "self", ".", "shard_id", ",", "\n", "num_shards", "=", "self", ".", "distributed_factor", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "shuffle_seed", "=", "shuffle_seed", ",", "offset", "=", "offset", ",", "\n", "strict_batch_size", "=", "True", ",", "# this is not really necessary, one can probably disable it", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.run_train": [[147, 202], ["print", "dpr.utils.dist_utils.is_main_process", "dpr.utils.dist_utils.is_main_process", "dpr.utils.model_utils.get_schedule_linear", "math.ceil", "dpr.utils.dist_utils.is_main_process", "range", "eval", "train_dense_encoder_modified.BiEncoderTrainer.get_wiki_iterator", "logger.info", "max", "logger.info", "dpr.utils.dist_utils.is_main_process", "dpr.utils.model_utils.get_schedule_linear.load_state_dict", "logger.info", "logger.info", "int", "dpr.utils.dist_utils.is_main_process", "train_dense_encoder_modified.BiEncoderTrainer._train_epoch", "logger.info", "train_dense_encoder_modified.BiEncoderTrainer.get_data_iterator", "logger.info", "logger.info", "train_dense_encoder_modified.BiEncoderTrainer.get_dialog_iterator", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_schedule_linear", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_wiki_iterator", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer._train_epoch", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_data_iterator", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_dialog_iterator"], ["", "def", "run_train", "(", "self", ",", ")", ":", "\n", "        ", "args", "=", "self", ".", "args", "\n", "print", "(", "args", ")", "\n", "upsample_rates", "=", "None", "\n", "if", "args", ".", "train_files_upsample_rates", "is", "not", "None", ":", "\n", "            ", "upsample_rates", "=", "eval", "(", "args", ".", "train_files_upsample_rates", ")", "\n", "\n", "\n", "", "if", "args", ".", "dataloader", "==", "\"ict\"", ":", "\n", "            ", "train_iterator", "=", "self", ".", "get_wiki_iterator", "(", "args", ".", "train_file", ",", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "shuffle_seed", "=", "args", ".", "seed", ",", "offset", "=", "self", ".", "start_batch", ",", "\n", "upsample_rates", "=", "upsample_rates", ")", "\n", "", "elif", "args", ".", "dataloader", "==", "\"qa\"", ":", "\n", "            ", "train_iterator", "=", "self", ".", "get_data_iterator", "(", "args", ".", "train_file", ",", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "shuffle_seed", "=", "args", ".", "seed", ",", "offset", "=", "self", ".", "start_batch", ",", "\n", "upsample_rates", "=", "upsample_rates", ")", "\n", "", "elif", "args", ".", "dataloader", "==", "\"dialog\"", ":", "\n", "            ", "train_iterator", "=", "self", ".", "get_dialog_iterator", "(", "args", ".", "train_file", ",", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "shuffle_seed", "=", "args", ".", "seed", ",", "offset", "=", "self", ".", "start_batch", ",", "\n", "upsample_rates", "=", "upsample_rates", ",", "\n", "hard_negative_path", "=", "args", ".", "hard_negative_path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "\n", "", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Total iterations per epoch=%d\"", ",", "train_iterator", ".", "max_iterations", ")", "\n", "", "updates_per_epoch", "=", "train_iterator", ".", "max_iterations", "//", "args", ".", "gradient_accumulation_steps", "\n", "total_updates", "=", "max", "(", "updates_per_epoch", "*", "(", "args", ".", "num_train_epochs", "-", "self", ".", "start_epoch", "-", "1", ")", ",", "0", ")", "+", "(", "train_iterator", ".", "max_iterations", "-", "self", ".", "start_batch", ")", "//", "args", ".", "gradient_accumulation_steps", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\" Total updates=%d\"", ",", "total_updates", ")", "\n", "", "warmup_steps", "=", "args", ".", "warmup_steps", "\n", "scheduler", "=", "get_schedule_linear", "(", "self", ".", "optimizer", ",", "warmup_steps", ",", "total_updates", ")", "\n", "\n", "if", "self", ".", "scheduler_state", ":", "\n", "            ", "if", "is_main_process", "(", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"Loading scheduler state %s\"", ",", "self", ".", "scheduler_state", ")", "\n", "", "scheduler", ".", "load_state_dict", "(", "self", ".", "scheduler_state", ")", "\n", "\n", "", "eval_step", "=", "math", ".", "ceil", "(", "updates_per_epoch", "/", "args", ".", "eval_per_epoch", ")", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Eval step = %d\"", ",", "eval_step", ")", "\n", "logger", ".", "info", "(", "\"***** Training *****\"", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "self", ".", "start_epoch", ",", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "            ", "if", "is_main_process", "(", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Epoch %d *****\"", ",", "epoch", ")", "\n", "", "self", ".", "_train_epoch", "(", "scheduler", ",", "epoch", ",", "eval_step", ",", "train_iterator", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "'Training finished. Best validation checkpoint %s'", ",", "self", ".", "best_cp_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_and_save": [[203, 225], ["train_dense_encoder_modified.BiEncoderTrainer.validate_average_rank", "train_dense_encoder_modified.BiEncoderTrainer.validate_nll", "train_dense_encoder_modified.BiEncoderTrainer._save_checkpoint", "logger.info", "logger.info"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_average_rank", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_nll", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer._save_checkpoint"], ["", "", "def", "validate_and_save", "(", "self", ",", "epoch", ":", "int", ",", "iteration", ":", "int", ",", "scheduler", ")", ":", "\n", "        ", "args", "=", "self", ".", "args", "\n", "# for distributed mode, save checkpoint for only one process", "\n", "save_cp", "=", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "\n", "\n", "if", "epoch", "==", "args", ".", "val_av_rank_start_epoch", ":", "\n", "            ", "self", ".", "best_validation_result", "=", "None", "\n", "\n", "", "if", "epoch", ">=", "args", ".", "val_av_rank_start_epoch", ":", "\n", "            ", "validation_loss", "=", "self", ".", "validate_average_rank", "(", ")", "\n", "", "else", ":", "\n", "            ", "validation_loss", "=", "self", ".", "validate_nll", "(", ")", "\n", "\n", "\n", "", "if", "save_cp", ":", "\n", "            ", "cp_name", "=", "self", ".", "_save_checkpoint", "(", "scheduler", ",", "epoch", ",", "iteration", ")", "\n", "logger", ".", "info", "(", "'Saved checkpoint to %s'", ",", "cp_name", ")", "\n", "\n", "if", "validation_loss", "<", "(", "self", ".", "best_validation_result", "or", "validation_loss", "+", "1", ")", ":", "\n", "                ", "self", ".", "best_validation_result", "=", "validation_loss", "\n", "self", ".", "best_cp_name", "=", "cp_name", "\n", "logger", ".", "info", "(", "'New Best validation checkpoint %s'", ",", "cp_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_nll": [[226, 268], ["logger.info", "train_dense_encoder_modified.BiEncoderTrainer.biencoder.eval", "time.time", "enumerate", "float", "dpr.utils.dist_utils.is_main_process", "train_dense_encoder_modified.BiEncoderTrainer.get_wiki_iterator", "train_dense_encoder_modified.BiEncoderTrainer.iterate_data", "dpr.models.biencoder.BiEncoder.create_biencoder_input", "train_dense_encoder_modified._do_biencoder_fwd_pass", "loss.item", "logger.info", "train_dense_encoder_modified.BiEncoderTrainer.get_data_iterator", "logger.info", "train_dense_encoder_modified.BiEncoderTrainer.get_dialog_iterator", "NotImplementedError", "dpr.utils.dist_utils.is_main_process", "loss.item", "time.time"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_wiki_iterator", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.iterate_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.create_biencoder_input", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified._do_biencoder_fwd_pass", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_data_iterator", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_dialog_iterator", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process"], ["", "", "", "def", "validate_nll", "(", "self", ")", "->", "float", ":", "\n", "        ", "logger", ".", "info", "(", "'NLL validation ...'", ")", "\n", "args", "=", "self", ".", "args", "\n", "self", ".", "biencoder", ".", "eval", "(", ")", "\n", "if", "args", ".", "dataloader", "==", "\"ict\"", ":", "\n", "            ", "data_iterator", "=", "self", ".", "get_wiki_iterator", "(", "args", ".", "dev_file", ",", "args", ".", "dev_batch_size", ",", "shuffle", "=", "False", ")", "\n", "", "elif", "args", ".", "dataloader", "==", "\"qa\"", ":", "\n", "            ", "data_iterator", "=", "self", ".", "get_data_iterator", "(", "args", ".", "dev_file", ",", "args", ".", "dev_batch_size", ",", "shuffle", "=", "False", ")", "\n", "", "elif", "args", ".", "dataloader", "==", "\"dialog\"", ":", "\n", "            ", "data_iterator", "=", "self", ".", "get_dialog_iterator", "(", "args", ".", "dev_file", ",", "args", ".", "dev_batch_size", ",", "shuffle", "=", "False", ",", "hard_negative_path", "=", "args", ".", "hard_negative_path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "total_loss", "=", "0.0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "total_correct_predictions", "=", "0", "\n", "num_hard_negatives", "=", "args", ".", "hard_negatives", "\n", "num_other_negatives", "=", "args", ".", "other_negatives", "\n", "log_result_step", "=", "args", ".", "log_batch_step", "\n", "batches", "=", "0", "\n", "for", "i", ",", "samples_batch", "in", "enumerate", "(", "data_iterator", ".", "iterate_data", "(", ")", ")", ":", "\n", "            ", "biencoder_input", "=", "BiEncoder", ".", "create_biencoder_input", "(", "samples_batch", ",", "self", ".", "tensorizer", ",", "\n", "True", ",", "\n", "num_hard_negatives", ",", "num_other_negatives", ",", "shuffle", "=", "False", ")", "\n", "\n", "loss", ",", "correct_cnt", "=", "_do_biencoder_fwd_pass", "(", "self", ".", "biencoder", ",", "biencoder_input", ",", "self", ".", "tensorizer", ",", "args", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_correct_predictions", "+=", "correct_cnt", "\n", "batches", "+=", "1", "\n", "if", "(", "i", "+", "1", ")", "%", "log_result_step", "and", "is_main_process", "(", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'Eval step: %d , used_time=%f sec., loss=%f '", ",", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "", "total_loss", "=", "total_loss", "/", "batches", "\n", "total_samples", "=", "batches", "*", "args", ".", "dev_batch_size", "*", "self", ".", "distributed_factor", "\n", "correct_ratio", "=", "float", "(", "total_correct_predictions", "/", "total_samples", ")", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'NLL Validation: loss = %f. correct prediction ratio  %d/%d ~  %f'", ",", "total_loss", ",", "\n", "total_correct_predictions", ",", "\n", "total_samples", ",", "\n", "correct_ratio", "\n", ")", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_average_rank": [[269, 374], ["logger.info", "train_dense_encoder_modified.BiEncoderTrainer.biencoder.eval", "train_dense_encoder_modified.BiEncoderTrainer.get_data_iterator", "dpr.models.biencoder.BiEncoderNllLoss.get_similarity_function", "enumerate", "torch.cat", "torch.cat", "logger.info", "logger.info", "torch.cat.size", "dpr.models.biencoder.BiEncoderNllLoss.get_similarity_function.", "torch.sort", "enumerate", "float", "logger.info", "train_dense_encoder_modified.BiEncoderTrainer.iterate_data", "dpr.models.biencoder.BiEncoder.create_biencoder_input", "len", "ctxs_ids.size", "enumerate", "positive_idx_per_question.extend", "torch.cat.size", "torch.cat.size", "len", "gold_idx.item", "dpr.utils.dist_utils.all_gather_list", "enumerate", "len", "range", "train_dense_encoder_modified.BiEncoderTrainer.tensorizer.get_attn_mask", "train_dense_encoder_modified.BiEncoderTrainer.tensorizer.get_attn_mask", "torch.cat.extend", "dpr.utils.dist_utils.is_main_process", "logger.info", "torch.no_grad", "train_dense_encoder_modified.BiEncoderTrainer.biencoder", "torch.cat.extend", "ctx_dense.cpu().split", "len", "len", "q_ids.size", "q_dense.cpu().split", "ctx_dense.cpu", "q_dense.cpu"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.get_data_iterator", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.get_similarity_function", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.iterate_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.create_biencoder_input", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "validate_average_rank", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Validates biencoder model using each question's gold passage's rank across the set of passages from the dataset.\n        It generates vectors for specified amount of negative passages from each question (see --val_av_rank_xxx params)\n        and stores them in RAM as well as question vectors.\n        Then the similarity scores are calculted for the entire\n        num_questions x (num_questions x num_passages_per_question) matrix and sorted per quesrtion.\n        Each question's gold passage rank in that  sorted list of scores is averaged across all the questions.\n        :return: averaged rank number\n        \"\"\"", "\n", "logger", ".", "info", "(", "'Average rank validation ...'", ")", "\n", "\n", "args", "=", "self", ".", "args", "\n", "self", ".", "biencoder", ".", "eval", "(", ")", "\n", "distributed_factor", "=", "self", ".", "distributed_factor", "\n", "\n", "data_iterator", "=", "self", ".", "get_data_iterator", "(", "args", ".", "dev_file", ",", "args", ".", "dev_batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "sub_batch_size", "=", "args", ".", "val_av_rank_bsz", "\n", "sim_score_f", "=", "BiEncoderNllLoss", ".", "get_similarity_function", "(", ")", "\n", "q_represenations", "=", "[", "]", "\n", "ctx_represenations", "=", "[", "]", "\n", "positive_idx_per_question", "=", "[", "]", "\n", "\n", "num_hard_negatives", "=", "args", ".", "val_av_rank_hard_neg", "\n", "num_other_negatives", "=", "args", ".", "val_av_rank_other_neg", "\n", "\n", "log_result_step", "=", "args", ".", "log_batch_step", "\n", "\n", "for", "i", ",", "samples_batch", "in", "enumerate", "(", "data_iterator", ".", "iterate_data", "(", ")", ")", ":", "\n", "# samples += 1", "\n", "            ", "if", "len", "(", "q_represenations", ")", ">", "args", ".", "val_av_rank_max_qs", "/", "distributed_factor", ":", "\n", "                ", "break", "\n", "\n", "", "biencoder_input", "=", "BiEncoder", ".", "create_biencoder_input", "(", "samples_batch", ",", "self", ".", "tensorizer", ",", "\n", "True", ",", "\n", "num_hard_negatives", ",", "num_other_negatives", ",", "shuffle", "=", "False", ")", "\n", "total_ctxs", "=", "len", "(", "ctx_represenations", ")", "\n", "ctxs_ids", "=", "biencoder_input", ".", "context_ids", "\n", "ctxs_segments", "=", "biencoder_input", ".", "ctx_segments", "\n", "bsz", "=", "ctxs_ids", ".", "size", "(", "0", ")", "\n", "\n", "# split contexts batch into sub batches since it is supposed to be too large to be processed in one batch", "\n", "for", "j", ",", "batch_start", "in", "enumerate", "(", "range", "(", "0", ",", "bsz", ",", "sub_batch_size", ")", ")", ":", "\n", "\n", "                ", "q_ids", ",", "q_segments", "=", "(", "biencoder_input", ".", "question_ids", ",", "biencoder_input", ".", "question_segments", ")", "if", "j", "==", "0", "else", "(", "None", ",", "None", ")", "\n", "\n", "if", "j", "==", "0", "and", "args", ".", "n_gpu", ">", "1", "and", "q_ids", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "# if we are in DP (but not in DDP) mode, all model input tensors should have batch size >1 or 0,", "\n", "# otherwise the other input tensors will be split but only the first split will be called", "\n", "                    ", "continue", "\n", "\n", "", "ctx_ids_batch", "=", "ctxs_ids", "[", "batch_start", ":", "batch_start", "+", "sub_batch_size", "]", "\n", "ctx_seg_batch", "=", "ctxs_segments", "[", "batch_start", ":", "batch_start", "+", "sub_batch_size", "]", "\n", "\n", "q_attn_mask", "=", "self", ".", "tensorizer", ".", "get_attn_mask", "(", "q_ids", ")", "\n", "ctx_attn_mask", "=", "self", ".", "tensorizer", ".", "get_attn_mask", "(", "ctx_ids_batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "q_dense", ",", "ctx_dense", "=", "self", ".", "biencoder", "(", "q_ids", ",", "q_segments", ",", "q_attn_mask", ",", "ctx_ids_batch", ",", "ctx_seg_batch", ",", "\n", "ctx_attn_mask", ")", "\n", "\n", "", "if", "q_dense", "is", "not", "None", ":", "\n", "                    ", "q_represenations", ".", "extend", "(", "q_dense", ".", "cpu", "(", ")", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ")", "\n", "\n", "", "ctx_represenations", ".", "extend", "(", "ctx_dense", ".", "cpu", "(", ")", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ")", "\n", "\n", "", "batch_positive_idxs", "=", "biencoder_input", ".", "is_positive", "\n", "positive_idx_per_question", ".", "extend", "(", "[", "total_ctxs", "+", "v", "for", "v", "in", "batch_positive_idxs", "]", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "log_result_step", "==", "0", "and", "is_main_process", "(", ")", ":", "\n", "                ", "logger", ".", "info", "(", "'Av.rank validation: step %d, computed ctx_vectors %d, q_vectors %d'", ",", "i", ",", "\n", "len", "(", "ctx_represenations", ")", ",", "len", "(", "q_represenations", ")", ")", "\n", "\n", "", "", "ctx_represenations", "=", "torch", ".", "cat", "(", "ctx_represenations", ",", "dim", "=", "0", ")", "\n", "q_represenations", "=", "torch", ".", "cat", "(", "q_represenations", ",", "dim", "=", "0", ")", "\n", "\n", "logger", ".", "info", "(", "'Av.rank validation: total q_vectors size=%s'", ",", "q_represenations", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "'Av.rank validation: total ctx_vectors size=%s'", ",", "ctx_represenations", ".", "size", "(", ")", ")", "\n", "\n", "q_num", "=", "q_represenations", ".", "size", "(", "0", ")", "\n", "assert", "q_num", "==", "len", "(", "positive_idx_per_question", ")", "\n", "\n", "scores", "=", "sim_score_f", "(", "q_represenations", ",", "ctx_represenations", ")", "\n", "values", ",", "indices", "=", "torch", ".", "sort", "(", "scores", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "rank", "=", "0", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "positive_idx_per_question", ")", ":", "\n", "# aggregate the rank of the known gold passage in the sorted results for each question", "\n", "            ", "gold_idx", "=", "(", "indices", "[", "i", "]", "==", "idx", ")", ".", "nonzero", "(", ")", "\n", "rank", "+=", "gold_idx", ".", "item", "(", ")", "\n", "\n", "", "if", "distributed_factor", ">", "1", ":", "\n", "# each node calcuated its own rank, exchange the information between node and calculate the \"global\" average rank", "\n", "# NOTE: the set of passages is still unique for every node", "\n", "            ", "eval_stats", "=", "all_gather_list", "(", "[", "rank", ",", "q_num", "]", ",", "max_size", "=", "100", ")", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "eval_stats", ")", ":", "\n", "                ", "remote_rank", ",", "remote_q_num", "=", "item", "\n", "if", "i", "!=", "args", ".", "local_rank", ":", "\n", "                    ", "rank", "+=", "remote_rank", "\n", "q_num", "+=", "remote_q_num", "\n", "\n", "", "", "", "av_rank", "=", "float", "(", "rank", "/", "q_num", ")", "\n", "logger", ".", "info", "(", "'Av.rank validation: average rank %s, total questions=%d'", ",", "av_rank", ",", "q_num", ")", "\n", "return", "av_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer._train_epoch": [[375, 456], ["train_dense_encoder_modified.BiEncoderTrainer.biencoder.train", "enumerate", "train_dense_encoder_modified.BiEncoderTrainer.validate_and_save", "max", "dpr.utils.dist_utils.is_main_process", "train_data_iterator.iterate_data", "train_data_iterator.get_iteration", "random.seed", "dpr.models.biencoder.BiEncoder.create_biencoder_input", "train_dense_encoder_modified._do_biencoder_fwd_pass", "loss.item", "loss.item", "logger.info", "logger.info", "loss.backward", "train_dense_encoder_modified.BiEncoderTrainer.optimizer.step", "scheduler.step", "train_dense_encoder_modified.BiEncoderTrainer.biencoder.zero_grad", "dpr.utils.dist_utils.is_main_process", "dpr.utils.dist_utils.is_main_process", "dpr.utils.dist_utils.is_main_process", "train_dense_encoder_modified.BiEncoderTrainer.validate_and_save", "train_dense_encoder_modified.BiEncoderTrainer.biencoder.train", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logger.info", "logger.info", "logger.info", "logger.info", "train_data_iterator.get_iteration", "amp.master_params", "train_dense_encoder_modified.BiEncoderTrainer.biencoder.parameters", "loss.item"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_and_save", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.iterate_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.get_iteration", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.create_biencoder_input", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified._do_biencoder_fwd_pass", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.step", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.step", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_and_save", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.get_iteration"], ["", "def", "_train_epoch", "(", "self", ",", "scheduler", ",", "epoch", ":", "int", ",", "eval_step", ":", "int", ",", "\n", "train_data_iterator", ":", "ShardedDataIterator", ",", ")", ":", "\n", "\n", "        ", "args", "=", "self", ".", "args", "\n", "rolling_train_loss", "=", "0.0", "\n", "epoch_loss", "=", "0", "\n", "epoch_correct_predictions", "=", "0", "\n", "\n", "log_result_step", "=", "args", ".", "log_batch_step", "\n", "rolling_loss_step", "=", "args", ".", "train_rolling_loss_step", "\n", "num_hard_negatives", "=", "args", ".", "hard_negatives", "\n", "num_other_negatives", "=", "args", ".", "other_negatives", "\n", "seed", "=", "args", ".", "seed", "\n", "self", ".", "biencoder", ".", "train", "(", ")", "\n", "epoch_batches", "=", "train_data_iterator", ".", "max_iterations", "\n", "data_iteration", "=", "0", "\n", "train_batch_count", "=", "0", "\n", "for", "i", ",", "samples_batch", "in", "enumerate", "(", "train_data_iterator", ".", "iterate_data", "(", "epoch", "=", "epoch", ")", ")", ":", "\n", "# samples_batch[0].keys()", "\n", "# dict_keys(['dataset', 'question', 'answers' (22) (75), 'positive_ctxs' (11) (29), 'negative_ctxs' (0), 'hard_negative_ctxs' (89) (71)])", "\n", "# to be able to resume shuffled ctx- pools", "\n", "# import pdb; pdb.set_trace()", "\n", "            ", "data_iteration", "=", "train_data_iterator", ".", "get_iteration", "(", ")", "\n", "random", ".", "seed", "(", "seed", "+", "epoch", "+", "data_iteration", ")", "\n", "biencoder_batch", "=", "BiEncoder", ".", "create_biencoder_input", "(", "samples_batch", ",", "self", ".", "tensorizer", ",", "\n", "True", ",", "\n", "num_hard_negatives", ",", "num_other_negatives", ",", "shuffle", "=", "True", ",", "\n", "shuffle_positives", "=", "args", ".", "shuffle_positive_ctx", "\n", ")", "\n", "train_batch_count", "+=", "1", "\n", "# biencoder_batch = BiEncoder.create_biencoder_input(samples_batch, self.tensorizer, True, num_hard_negatives, num_other_negatives, shuffle=True, shuffle_positives=args.shuffle_positive_ctx)", "\n", "# self.tensorizer.to_string(biencoder_batch.question_ids[0])  2  # self.tensorizer.to_string(biencoder_batch.context_ids[0])  4   1p 1n 2p 2n", "\n", "\n", "loss", ",", "correct_cnt", "=", "_do_biencoder_fwd_pass", "(", "self", ".", "biencoder", ",", "biencoder_batch", ",", "self", ".", "tensorizer", ",", "args", ")", "\n", "\n", "epoch_correct_predictions", "+=", "correct_cnt", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "rolling_train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                ", "from", "apex", "import", "amp", "\n", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "if", "args", ".", "max_grad_norm", ">", "0", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "self", ".", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "if", "args", ".", "max_grad_norm", ">", "0", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "biencoder", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "", "if", "(", "i", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "self", ".", "biencoder", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "i", "%", "log_result_step", "==", "0", ":", "\n", "                ", "lr", "=", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "if", "is_main_process", "(", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\n", "'Epoch: %d: Step: %d/%d, loss=%f, lr=%f'", ",", "epoch", ",", "data_iteration", ",", "epoch_batches", ",", "loss", ".", "item", "(", ")", ",", "lr", ")", "\n", "\n", "", "", "if", "(", "i", "+", "1", ")", "%", "rolling_loss_step", "==", "0", ":", "\n", "                ", "latest_rolling_train_av_loss", "=", "rolling_train_loss", "/", "rolling_loss_step", "\n", "if", "is_main_process", "(", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "'Train batch %d'", ",", "data_iteration", ")", "\n", "logger", ".", "info", "(", "'Avg. loss per last %d batches: %f'", ",", "rolling_loss_step", ",", "latest_rolling_train_av_loss", ")", "\n", "", "rolling_train_loss", "=", "0.0", "\n", "\n", "", "if", "data_iteration", "%", "eval_step", "==", "0", ":", "\n", "                ", "if", "is_main_process", "(", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "'Validation: Epoch: %d Step: %d/%d'", ",", "epoch", ",", "data_iteration", ",", "epoch_batches", ")", "\n", "", "self", ".", "validate_and_save", "(", "epoch", ",", "train_data_iterator", ".", "get_iteration", "(", ")", ",", "scheduler", ")", "\n", "self", ".", "biencoder", ".", "train", "(", ")", "\n", "\n", "", "", "self", ".", "validate_and_save", "(", "epoch", ",", "data_iteration", ",", "scheduler", ")", "\n", "\n", "epoch_loss", "=", "(", "epoch_loss", "/", "epoch_batches", ")", "if", "epoch_batches", ">", "0", "else", "0", "\n", "total_samples", "=", "max", "(", "train_batch_count", "*", "args", ".", "batch_size", "*", "self", ".", "distributed_factor", ",", "1", ")", "\n", "if", "is_main_process", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'Av Loss per epoch=%f'", ",", "epoch_loss", ")", "\n", "logger", ".", "info", "(", "'epoch total correct predictions=%d'", ",", "epoch_correct_predictions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer._save_checkpoint": [[457, 474], ["dpr.utils.model_utils.get_model_obj", "os.path.join", "dpr.options.get_encoder_params_state", "dpr.utils.model_utils.CheckpointState", "torch.save", "logger.info", "dpr.utils.model_utils.get_model_obj.state_dict", "train_dense_encoder_modified.BiEncoderTrainer.optimizer.state_dict", "scheduler.state_dict", "dpr.utils.model_utils.CheckpointState._asdict", "str", "str"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_obj", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.get_encoder_params_state"], ["", "", "def", "_save_checkpoint", "(", "self", ",", "scheduler", ",", "epoch", ":", "int", ",", "offset", ":", "int", ")", "->", "str", ":", "\n", "        ", "args", "=", "self", ".", "args", "\n", "model_to_save", "=", "get_model_obj", "(", "self", ".", "biencoder", ")", "\n", "cp", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "args", ".", "checkpoint_file_name", "+", "'.'", "+", "str", "(", "epoch", ")", "+", "(", "'.'", "+", "str", "(", "offset", ")", "if", "offset", ">", "0", "else", "''", ")", ")", "\n", "\n", "meta_params", "=", "get_encoder_params_state", "(", "args", ")", "\n", "\n", "state", "=", "CheckpointState", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "offset", ",", "\n", "epoch", ",", "meta_params", "\n", ")", "\n", "torch", ".", "save", "(", "state", ".", "_asdict", "(", ")", ",", "cp", ")", "\n", "logger", ".", "info", "(", "'Saved checkpoint at %s'", ",", "cp", ")", "\n", "return", "cp", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer._load_saved_state": [[475, 498], ["logger.info", "dpr.utils.model_utils.get_model_obj", "logger.info", "dpr.utils.model_utils.get_model_obj.load_state_dict", "logger.info", "train_dense_encoder_modified.BiEncoderTrainer.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_obj"], ["", "def", "_load_saved_state", "(", "self", ",", "saved_state", ":", "CheckpointState", ",", "strict", "=", "True", ")", ":", "\n", "        ", "epoch", "=", "saved_state", ".", "epoch", "\n", "offset", "=", "saved_state", ".", "offset", "\n", "if", "offset", "==", "0", ":", "# epoch has been completed", "\n", "            ", "epoch", "+=", "1", "\n", "", "logger", ".", "info", "(", "'Loading checkpoint @ batch=%s and epoch=%s'", ",", "offset", ",", "epoch", ")", "\n", "\n", "self", ".", "start_epoch", "=", "epoch", "\n", "self", ".", "start_batch", "=", "offset", "\n", "\n", "model_to_load", "=", "get_model_obj", "(", "self", ".", "biencoder", ")", "\n", "logger", ".", "info", "(", "'Loading saved model state ...'", ")", "\n", "model_to_load", ".", "load_state_dict", "(", "saved_state", ".", "model_dict", ",", "strict", "=", "strict", ")", "\n", "\n", "if", "self", ".", "args", ".", "reset_optimizer", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "saved_state", ".", "optimizer_dict", ":", "\n", "                ", "logger", ".", "info", "(", "'Loading saved optimizer state ...'", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "saved_state", ".", "optimizer_dict", ")", "\n", "\n", "", "if", "saved_state", ".", "scheduler_dict", ":", "\n", "                ", "self", ".", "scheduler_state", "=", "saved_state", ".", "scheduler_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified._calc_loss": [[500, 553], ["loss_function.calc", "torch.empty_like().cpu().copy_().detach_", "torch.empty_like().cpu().copy_().detach_", "dpr.utils.dist_utils.all_gather_list", "enumerate", "torch.cat", "torch.cat", "ctx_vectors.size", "torch.empty_like().cpu().copy_", "torch.empty_like().cpu().copy_", "torch.cat.append", "torch.cat.append", "positive_idx_per_question.extend", "hard_negatives_per_question.extend", "torch.cat.append", "torch.cat.append", "positive_idx_per_question.extend", "hard_negatives_per_question.extend", "q_vector.to", "ctx_vectors.to", "torch.empty_like().cpu", "torch.empty_like().cpu", "torch.empty_like", "torch.empty_like"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.calc", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["", "", "", "", "def", "_calc_loss", "(", "args", ",", "loss_function", ",", "local_q_vector", ",", "local_ctx_vectors", ",", "local_positive_idxs", ",", "\n", "local_hard_negatives_idxs", ":", "list", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "T", ",", "bool", "]", ":", "\n", "    ", "\"\"\"\n    Calculates In-batch negatives schema loss and supports to run it in DDP mode by exchanging the representations\n    across all the nodes.\n    \"\"\"", "\n", "distributed_world_size", "=", "args", ".", "distributed_world_size", "or", "1", "\n", "if", "distributed_world_size", ">", "1", ":", "\n", "        ", "q_vector_to_send", "=", "torch", ".", "empty_like", "(", "local_q_vector", ")", ".", "cpu", "(", ")", ".", "copy_", "(", "local_q_vector", ")", ".", "detach_", "(", ")", "\n", "ctx_vector_to_send", "=", "torch", ".", "empty_like", "(", "local_ctx_vectors", ")", ".", "cpu", "(", ")", ".", "copy_", "(", "local_ctx_vectors", ")", ".", "detach_", "(", ")", "\n", "\n", "global_question_ctx_vectors", "=", "all_gather_list", "(", "\n", "[", "q_vector_to_send", ",", "ctx_vector_to_send", ",", "local_positive_idxs", ",", "local_hard_negatives_idxs", "]", ",", "\n", "max_size", "=", "args", ".", "global_loss_buf_sz", ")", "\n", "\n", "global_q_vector", "=", "[", "]", "\n", "global_ctxs_vector", "=", "[", "]", "\n", "\n", "# ctxs_per_question = local_ctx_vectors.size(0)", "\n", "positive_idx_per_question", "=", "[", "]", "\n", "hard_negatives_per_question", "=", "[", "]", "\n", "\n", "total_ctxs", "=", "0", "\n", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "global_question_ctx_vectors", ")", ":", "\n", "            ", "q_vector", ",", "ctx_vectors", ",", "positive_idx", ",", "hard_negatives_idxs", "=", "item", "\n", "\n", "if", "i", "!=", "args", ".", "local_rank", ":", "\n", "                ", "global_q_vector", ".", "append", "(", "q_vector", ".", "to", "(", "local_q_vector", ".", "device", ")", ")", "\n", "global_ctxs_vector", ".", "append", "(", "ctx_vectors", ".", "to", "(", "local_q_vector", ".", "device", ")", ")", "\n", "positive_idx_per_question", ".", "extend", "(", "[", "v", "+", "total_ctxs", "for", "v", "in", "positive_idx", "]", ")", "\n", "hard_negatives_per_question", ".", "extend", "(", "[", "[", "v", "+", "total_ctxs", "for", "v", "in", "l", "]", "for", "l", "in", "hard_negatives_idxs", "]", ")", "\n", "", "else", ":", "\n", "                ", "global_q_vector", ".", "append", "(", "local_q_vector", ")", "\n", "global_ctxs_vector", ".", "append", "(", "local_ctx_vectors", ")", "\n", "positive_idx_per_question", ".", "extend", "(", "[", "v", "+", "total_ctxs", "for", "v", "in", "local_positive_idxs", "]", ")", "\n", "hard_negatives_per_question", ".", "extend", "(", "[", "[", "v", "+", "total_ctxs", "for", "v", "in", "l", "]", "for", "l", "in", "local_hard_negatives_idxs", "]", ")", "\n", "", "total_ctxs", "+=", "ctx_vectors", ".", "size", "(", "0", ")", "\n", "\n", "", "global_q_vector", "=", "torch", ".", "cat", "(", "global_q_vector", ",", "dim", "=", "0", ")", "\n", "global_ctxs_vector", "=", "torch", ".", "cat", "(", "global_ctxs_vector", ",", "dim", "=", "0", ")", "\n", "\n", "", "else", ":", "\n", "        ", "global_q_vector", "=", "local_q_vector", "\n", "global_ctxs_vector", "=", "local_ctx_vectors", "\n", "positive_idx_per_question", "=", "local_positive_idxs", "\n", "hard_negatives_per_question", "=", "local_hard_negatives_idxs", "\n", "\n", "", "loss", ",", "is_correct", "=", "loss_function", ".", "calc", "(", "global_q_vector", ",", "global_ctxs_vector", ",", "positive_idx_per_question", ",", "\n", "hard_negatives_per_question", ")", "\n", "\n", "return", "loss", ",", "is_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified._do_biencoder_fwd_pass": [[555, 585], ["dpr.models.biencoder.BiEncoderBatch", "tensorizer.get_attn_mask", "tensorizer.get_attn_mask", "dpr.models.biencoder.BiEncoderNllLoss", "train_dense_encoder_modified._calc_loss", "is_correct.sum().item.sum().item", "model", "loss.mean.mean", "dpr.utils.model_utils.move_to_device", "torch.no_grad", "model", "is_correct.sum().item.sum", "dpr.models.biencoder.BiEncoderBatch._asdict"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified._calc_loss", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.move_to_device"], ["", "def", "_do_biencoder_fwd_pass", "(", "model", ":", "nn", ".", "Module", ",", "input", ":", "BiEncoderBatch", ",", "tensorizer", ":", "Tensorizer", ",", "args", ")", "->", "(", "\n", "torch", ".", "Tensor", ",", "int", ")", ":", "\n", "    ", "input", "=", "BiEncoderBatch", "(", "**", "move_to_device", "(", "input", ".", "_asdict", "(", ")", ",", "args", ".", "device", ")", ")", "\n", "\n", "q_attn_mask", "=", "tensorizer", ".", "get_attn_mask", "(", "input", ".", "question_ids", ")", "\n", "ctx_attn_mask", "=", "tensorizer", ".", "get_attn_mask", "(", "input", ".", "context_ids", ")", "\n", "\n", "if", "model", ".", "training", ":", "\n", "        ", "model_out", "=", "model", "(", "input", ".", "question_ids", ",", "input", ".", "question_segments", ",", "q_attn_mask", ",", "input", ".", "context_ids", ",", "\n", "input", ".", "ctx_segments", ",", "ctx_attn_mask", ")", "\n", "", "else", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model_out", "=", "model", "(", "input", ".", "question_ids", ",", "input", ".", "question_segments", ",", "q_attn_mask", ",", "input", ".", "context_ids", ",", "\n", "input", ".", "ctx_segments", ",", "ctx_attn_mask", ")", "\n", "\n", "", "", "local_q_vector", ",", "local_ctx_vectors", "=", "model_out", "\n", "\n", "loss_function", "=", "BiEncoderNllLoss", "(", ")", "\n", "\n", "loss", ",", "is_correct", "=", "_calc_loss", "(", "args", ",", "loss_function", ",", "local_q_vector", ",", "local_ctx_vectors", ",", "input", ".", "is_positive", ",", "\n", "input", ".", "hard_negatives", ")", "\n", "\n", "is_correct", "=", "is_correct", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "        ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "return", "loss", ",", "is_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.train_dpr_parser": [[587, 634], ["dpr.options.add_encoder_params", "dpr.options.add_training_params", "dpr.options.add_tokenizer_params", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_encoder_params", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_training_params", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_tokenizer_params"], ["", "def", "train_dpr_parser", "(", "parser", ")", ":", "\n", "    ", "add_encoder_params", "(", "parser", ")", "\n", "add_training_params", "(", "parser", ")", "\n", "add_tokenizer_params", "(", "parser", ")", "\n", "\n", "# biencoder specific training features", "\n", "parser", ".", "add_argument", "(", "\"--comet_config\"", ",", "default", "=", "'./configs/comet_siqi.json'", ",", "type", "=", "str", ",", "help", "=", "\"comet config file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_per_epoch\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"How many times it evaluates on dev set per epoch and saves a checkpoint\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--global_loss_buf_sz\"", ",", "type", "=", "int", ",", "default", "=", "300000", ",", "\n", "help", "=", "'Buffer size for distributed mode representations al gather operation. \\\n                                    Increase this if you see errors like \"encoded data exceeds max_size ...\"'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--fix_ctx_encoder\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--shuffle_positive_ctx\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--reset_optimizer\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# input/output src params", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The output directory where the model checkpoints will be written or resumed from\"", ")", "\n", "\n", "# data handling parameters", "\n", "parser", ".", "add_argument", "(", "\"--hard_negatives\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"amount of hard negative ctx per question\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--other_negatives\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"amount of 'other' negative ctx per question\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_files_upsample_rates\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"list of up-sample rates per each train file. Example: [1,2,1]\"", ")", "\n", "\n", "# parameters for Av.rank validation method", "\n", "parser", ".", "add_argument", "(", "\"--val_av_rank_start_epoch\"", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Av.rank validation: the epoch from which to enable this validation\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_av_rank_hard_neg\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"Av.rank validation: how many hard negatives to take from each question pool\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_av_rank_other_neg\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"Av.rank validation: how many 'other' negatives to take from each question pool\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_av_rank_bsz\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "\"Av.rank validation: batch size to process passages\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_av_rank_max_qs\"", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Av.rank validation: max num of questions\"", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_file_name'", ",", "type", "=", "str", ",", "default", "=", "'dpr_biencoder'", ",", "help", "=", "\"Checkpoints file prefix\"", ")", "\n", "parser", ".", "add_argument", "(", "'--hard_negative_path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"hard negative id file\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataloader'", ",", "type", "=", "str", ",", "default", "=", "\"qa\"", ",", "help", "=", "\"qa:original ict:ICT pretraining dialog: dialog context finetuning\"", ")", "\n", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.main": [[636, 668], ["argparse.ArgumentParser", "train_dense_encoder_modified.train_dpr_parser", "train_dpr_parser.parse_args", "dpr.options.setup_args_gpu", "dpr.options.set_seed", "dpr.utils.dist_utils.is_main_process", "train_dense_encoder_modified.BiEncoderTrainer", "ValueError", "os.makedirs", "dpr.options.print_args", "train_dense_encoder_modified.BiEncoderTrainer.run_train", "logger.info", "train_dense_encoder_modified.BiEncoderTrainer.validate_nll", "train_dense_encoder_modified.BiEncoderTrainer.validate_average_rank", "logger.warning"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.train_dpr_parser", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.setup_args_gpu", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_seed", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.print_args", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.run_train", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_nll", "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.train_dense_encoder_modified.BiEncoderTrainer.validate_average_rank"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "train_dpr_parser", "(", "parser", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "if", "args", ".", "output_dir", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "setup_args_gpu", "(", "args", ")", "\n", "set_seed", "(", "args", ")", "\n", "\n", "if", "is_main_process", "(", ")", ":", "\n", "        ", "print_args", "(", "args", ")", "\n", "experiment", "=", "None", "\n", "", "else", ":", "\n", "        ", "experiment", "=", "None", "\n", "\n", "", "trainer", "=", "BiEncoderTrainer", "(", "args", ",", "experiment", ")", "\n", "\n", "if", "args", ".", "train_file", "is", "not", "None", ":", "\n", "        ", "trainer", ".", "run_train", "(", ")", "\n", "", "elif", "args", ".", "model_file", "and", "args", ".", "dev_file", ":", "\n", "        ", "logger", ".", "info", "(", "\"No train files are specified. Run 2 types of validation for specified model file\"", ")", "\n", "trainer", ".", "validate_nll", "(", ")", "\n", "trainer", ".", "validate_average_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Neither train_file or (model_file & dev_file) parameters are specified. Nothing to do.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.None.eval_checkpoint.recall_k": [[21, 33], ["len", "enumerate", "float", "logger.info", "set", "len", "str"], "function", ["None"], ["def", "recall_k", "(", "result_ctx_ids", ":", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ",", "topK", ":", "int", ")", "->", "float", ":", "\n", "\n", "    ", "top_k_hits", "=", "0", "\n", "total_ref", "=", "len", "(", "result_ctx_ids", ")", "\n", "for", "idx", ",", "res", "in", "enumerate", "(", "result_ctx_ids", ")", ":", "\n", "        ", "assert", "(", "topK", "<=", "len", "(", "res", "[", "0", "]", ")", ")", "\n", "candidates", "=", "set", "(", "res", "[", "0", "]", "[", ":", "topK", "]", ")", "\n", "if", "str", "(", "idx", "+", "1", ")", "in", "candidates", ":", "\n", "            ", "top_k_hits", "+=", "1", "\n", "", "", "recall", "=", "float", "(", "top_k_hits", "/", "total_ref", ")", "\n", "logger", ".", "info", "(", "f'Validation results: recall@{topK}:{recall:.3f}'", ")", "\n", "return", "recall", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.demo_utils.download_file": [[46, 60], ["os.path.basename", "os.path.isfile", "os.path.exists", "os.makedirs", "os.path.join", "logger.info", "open", "pytorch_pretrained_bert.file_utils.http_get", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.http_get"], ["def", "download_file", "(", "url", ",", "folder", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "file_name", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "if", "'pytorch_model.bin'", "in", "file_name", ":", "\n", "        ", "file_name", "=", "'pytorch_model.bin'", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "file_name", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f'{os.path.join(folder, file_name)} exists, return!'", ")", "\n", "return", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "file_name", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "http_get", "(", "url", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.demo_utils.download_model_folder": [[61, 83], ["os.path.join", "demo_utils.download_file", "demo_utils.download_file", "demo_utils.download_file", "demo_utils.download_file", "demo_utils.download_file", "ValueError", "list", "LSP_MODEL_URL[].keys"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.demo_utils.download_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.demo_utils.download_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.demo_utils.download_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.demo_utils.download_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.demo_utils.download_file"], ["", "", "def", "download_model_folder", "(", "model_size", ",", "dataset", "=", "None", ",", "from_scratch", "=", "None", ",", "DATA_FOLDER", "=", "None", ")", ":", "\n", "    ", "assert", "DATA_FOLDER", "is", "not", "None", ",", "'DATA_FOLDER cannot be None'", "\n", "assert", "model_size", "in", "[", "'small'", ",", "'medium'", ",", "'large'", "]", ",", "'model size should be one of \\'small\\', \\'medium\\' or \\'large\\''", "\n", "target_folder", "=", "os", ".", "path", ".", "join", "(", "DATA_FOLDER", ",", "model_size", ")", "\n", "download_file", "(", "CONFIG_FILE", "[", "model_size", "]", ",", "target_folder", ")", "\n", "download_file", "(", "VOCAB_FILE", "[", "model_size", "]", ",", "target_folder", ")", "\n", "download_file", "(", "MERGE_FILE", "[", "model_size", "]", ",", "target_folder", ")", "\n", "download_file", "(", "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP", "[", "model_size", "]", ",", "target_folder", ")", "\n", "if", "dataset", "is", "not", "None", ":", "\n", "        ", "assert", "dataset", "in", "[", "'multiref'", ",", "'dstc'", "]", ",", "'dataset has to be \\'multiref\\' or \\'dstc\\''", "\n", "assert", "from_scratch", "in", "[", "True", ",", "False", "]", ",", "'from scratch has to be True or False'", "\n", "\n", "if", "from_scratch", ":", "\n", "            ", "model_train_type", "=", "model_size", "+", "'_fs'", "\n", "", "else", ":", "\n", "            ", "model_train_type", "=", "model_size", "+", "'_ft'", "\n", "", "if", "model_train_type", "not", "in", "LSP_MODEL_URL", "[", "dataset", "]", ":", "\n", "            ", "k", "=", "','", ".", "join", "(", "list", "(", "LSP_MODEL_URL", "[", "dataset", "]", ".", "keys", "(", ")", ")", ")", "\n", "raise", "ValueError", "(", "f'\\'{model_train_type}\\' not exist for dataset \\'{dataset}\\', please choose from [{k}]'", ")", "\n", "", "download_file", "(", "LSP_MODEL_URL", "[", "dataset", "]", "[", "model_train_type", "]", ",", "target_folder", ")", "\n", "", "return", "target_folder", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketSampler.__init__": [[22, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lens", ",", "bucket_size", ",", "batch_size", ",", "\n", "droplast", "=", "False", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "_lens", "=", "lens", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_bucket_size", "=", "bucket_size", "\n", "self", ".", "_droplast", "=", "droplast", "\n", "self", ".", "_shuf", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketSampler.__iter__": [[30, 46], ["list", "iter", "range", "random.shuffle", "sorted", "random.shuffle", "len", "range", "range", "len", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "ids", "=", "list", "(", "range", "(", "len", "(", "self", ".", "_lens", ")", ")", ")", "\n", "if", "self", ".", "_shuf", ":", "\n", "            ", "random", ".", "shuffle", "(", "ids", ")", "\n", "", "buckets", "=", "[", "sorted", "(", "ids", "[", "i", ":", "i", "+", "self", ".", "_bucket_size", "]", ",", "\n", "key", "=", "lambda", "i", ":", "self", ".", "_lens", "[", "i", "]", ",", "reverse", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "ids", ")", ",", "self", ".", "_bucket_size", ")", "]", "\n", "batches", "=", "[", "bucket", "[", "i", ":", "i", "+", "self", ".", "_batch_size", "]", "\n", "for", "bucket", "in", "buckets", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "bucket", ")", ",", "self", ".", "_batch_size", ")", "]", "\n", "if", "self", ".", "_droplast", ":", "\n", "            ", "batches", "=", "[", "batch", "for", "batch", "in", "batches", "\n", "if", "len", "(", "batch", ")", "==", "self", ".", "_batch_size", "]", "\n", "", "if", "self", ".", "_shuf", ":", "\n", "            ", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "return", "iter", "(", "batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketSampler.__len__": [[47, 55], ["sum", "sum", "len", "len", "math.ceil"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "bucket_sizes", "=", "(", "[", "self", ".", "_bucket_size", "]", "\n", "*", "(", "len", "(", "self", ".", "_lens", ")", "//", "self", ".", "_bucket_size", ")", "\n", "+", "[", "len", "(", "self", ".", "_lens", ")", "%", "self", ".", "_bucket_size", "]", ")", "\n", "if", "self", ".", "_droplast", ":", "\n", "            ", "return", "sum", "(", "s", "//", "self", ".", "_batch_size", "for", "s", "in", "bucket_sizes", ")", "\n", "", "else", ":", "\n", "            ", "return", "sum", "(", "math", ".", "ceil", "(", "s", "/", "self", ".", "_batch_size", ")", "for", "s", "in", "bucket_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.GPT2FeatureDataset.__init__": [[58, 61], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "features", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "self", ".", "features", "=", "features", "\n", "self", ".", "max_len", "=", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.GPT2FeatureDataset.__getitem__": [[62, 83], ["gpt2_training.train_utils.InputFeatures_train", "pdb.set_trace", "feat_dict.keys", "print"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "feat_dict", "=", "self", ".", "features", "[", "i", "]", "\n", "if", "self", ".", "max_len", "is", "not", "None", "and", "feat_dict", "[", "'input_len'", "]", ">", "self", ".", "max_len", ":", "\n", "\n", "            ", "feat_dict", "[", "'input_ids'", "]", "=", "feat_dict", "[", "'input_ids'", "]", "[", "-", "self", ".", "max_len", ":", "]", "\n", "feat_dict", "[", "'position_ids'", "]", "=", "feat_dict", "[", "'position_ids'", "]", "[", "\n", "-", "self", ".", "max_len", ":", "]", "\n", "feat_dict", "[", "'token_type_ids'", "]", "=", "feat_dict", "[", "'token_type_ids'", "]", "[", "\n", "-", "self", ".", "max_len", ":", "]", "\n", "feat_dict", "[", "'lm_labels'", "]", "=", "feat_dict", "[", "'lm_labels'", "]", "[", "-", "self", ".", "max_len", ":", "]", "\n", "", "try", ":", "\n", "            ", "for", "s", "in", "[", "'context_len'", ",", "'response_len'", "]", ":", "\n", "                ", "if", "s", "in", "feat_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "print", "(", "\"db file missing \"", "+", "s", ")", "\n", "del", "feat_dict", "[", "s", "]", "\n", "", "", "", "except", "Exception", ":", "\n", "            ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "", "feat", "=", "InputFeatures_train", "(", "**", "feat_dict", ")", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.GPT2FeatureDataset.__len__": [[84, 86], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.GPT2FeatureDataset.collate": [[87, 104], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate", "(", "features", ")", ":", "\n", "        ", "input_ids", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "f", ".", "input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "position_ids", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "f", ".", "position_ids", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "token_type_ids", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "f", ".", "token_type_ids", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "labels", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "f", ".", "lm_labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "return", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketingDataLoader.__init__": [[107, 114], ["shelve.open"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "db_name", ",", "batch_size", ",", "max_seq_len", ",", "\n", "bucket", "=", "100", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "db", "=", "shelve", ".", "open", "(", "f'{db_name}/db'", ",", "'r'", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "max_len", "=", "max_seq_len", "\n", "self", ".", "bucket_size", "=", "bucket", "*", "batch_size", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketingDataLoader._get_keys": [[115, 118], ["list", "data_loader.BucketingDataLoader.db.keys"], "methods", ["None"], ["", "def", "_get_keys", "(", "self", ")", ":", "\n", "        ", "keys", "=", "list", "(", "self", ".", "db", ".", "keys", "(", ")", ")", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketingDataLoader.__iter__": [[119, 144], ["data_loader.BucketingDataLoader._get_keys", "random.shuffle", "json.loads", "data_loader.GPT2FeatureDataset", "data_loader.BucketSampler", "torch.utils.data.DataLoader", "gzip.decompress().decode", "trunc_chunk.append", "lens.append", "print", "gzip.decompress"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DistributedBucketingDataLoader._get_keys", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "keys", "=", "self", ".", "_get_keys", "(", ")", "\n", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "random", ".", "shuffle", "(", "keys", ")", "\n", "", "for", "key", "in", "keys", ":", "\n", "            ", "chunk", "=", "json", ".", "loads", "(", "gzip", ".", "decompress", "(", "self", ".", "db", "[", "key", "]", ")", ".", "decode", "(", "'utf-8'", ")", ")", "\n", "\n", "trunc_chunk", "=", "[", "]", "\n", "lens", "=", "[", "]", "\n", "for", "feat", "in", "chunk", ":", "\n", "\n", "                ", "if", "feat", "[", "'input_len'", "]", ">", "self", ".", "max_len", ":", "\n", "                    ", "print", "(", "\"maximum length exceed!!\"", ")", "\n", "continue", "\n", "", "trunc_chunk", ".", "append", "(", "feat", ")", "\n", "lens", ".", "append", "(", "feat", "[", "'input_len'", "]", ")", "\n", "\n", "", "dataset", "=", "GPT2FeatureDataset", "(", "trunc_chunk", ",", "self", ".", "max_len", ")", "\n", "sampler", "=", "BucketSampler", "(", "lens", ",", "self", ".", "bucket_size", ",", "self", ".", "batch_size", ",", "\n", "droplast", "=", "True", ",", "shuffle", "=", "self", ".", "shuffle", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_sampler", "=", "sampler", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "GPT2FeatureDataset", ".", "collate", ")", "\n", "yield", "from", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketingDataLoader.__len__": [[145, 147], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.BucketingDataLoader.__del__": [[148, 150], ["data_loader.BucketingDataLoader.db.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "db", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DistributedBucketingDataLoader.__init__": [[153, 157], ["data_loader.BucketingDataLoader.__init__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "rank", ",", "num_replica", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "num_replica", "=", "num_replica", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DistributedBucketingDataLoader._get_keys": [[158, 161], ["list", "data_loader.DistributedBucketingDataLoader.db.keys"], "methods", ["None"], ["", "def", "_get_keys", "(", "self", ")", ":", "\n", "        ", "keys", "=", "list", "(", "self", ".", "db", ".", "keys", "(", ")", ")", "[", "self", ".", "rank", ":", ":", "self", ".", "num_replica", "]", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader.__init__": [[240, 249], ["data_loader.DynamicBatchingLoader.get_len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader.get_len"], ["def", "__init__", "(", "self", ",", "corpus_file", ",", "tokenizer", ",", "normalize_data", ",", "\n", "batch_size", ",", "max_seq_length", ",", "reverse", "=", "False", ")", ":", "\n", "        ", "self", ".", "corpus", "=", "corpus_file", "\n", "self", ".", "toker", "=", "tokenizer", "\n", "self", ".", "norm", "=", "normalize_data", "\n", "self", ".", "bs", "=", "batch_size", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "num_examples", "=", "self", ".", "get_len", "(", "corpus_file", ")", "\n", "self", ".", "reverse", "=", "reverse", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader.__iter__": [[250, 257], ["range", "data_loader.DynamicBatchingLoader._iter_epoch", "data_loader.DynamicBatchingLoader._iter_epoch"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader._iter_epoch", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader._iter_epoch"], ["", "def", "__iter__", "(", "self", ",", "epoch", "=", "1", ")", ":", "\n", "        ", "if", "epoch", ">", "0", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "epoch", ")", ":", "\n", "                ", "yield", "from", "self", ".", "_iter_epoch", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "yield", "from", "self", ".", "_iter_epoch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader.__len__": [[258, 260], ["math.ceil"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "ceil", "(", "self", ".", "num_examples", "/", "self", ".", "bs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader._iter_epoch": [[261, 298], ["open", "data_loader.DynamicBatchingLoader._batch_feature", "next().encode().decode", "next().encode().decode.split", "data_loader.convert_examples_to_features_dynamic_rev", "data_loader.convert_examples_to_features_dynamic", "examples.append", "next().encode", "doc.strip", "src.strip", "tgt.strip", "gpt2_training.train_utils.RedditExample", "doc.strip().split", "src.strip().split", "tgt.strip().split", "next", "doc.strip", "src.strip", "tgt.strip"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader._batch_feature", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.convert_examples_to_features_dynamic_rev", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.convert_examples_to_features_dynamic", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "def", "_iter_epoch", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "self", ".", "corpus", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "corpus", ":", "\n", "                ", "i", "=", "0", "\n", "while", "True", ":", "\n", "                    ", "examples", "=", "[", "]", "\n", "cur_bs", "=", "0", "\n", "while", "True", ":", "\n", "                        ", "line", "=", "next", "(", "corpus", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "contents", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "doc", ",", "src", ",", "tgt_all", "=", "contents", "[", "0", "]", ",", "contents", "[", "1", "]", ",", "contents", "[", "2", ":", "]", "\n", "for", "tgt", "in", "tgt_all", ":", "\n", "                            ", "if", "self", ".", "norm", ":", "\n", "                                ", "doc_line", "=", "' '", ".", "join", "(", "doc", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "src_line", "=", "' '", ".", "join", "(", "src", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "tgt_line", "=", "' '", ".", "join", "(", "tgt", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "                                ", "doc_line", "=", "doc", ".", "strip", "(", ")", "\n", "src_line", "=", "src", ".", "strip", "(", ")", "\n", "tgt_line", "=", "tgt", ".", "strip", "(", ")", "\n", "", "examples", ".", "append", "(", "\n", "RedditExample", "(", "i", ",", "doc_line", ",", "src_line", ",", "tgt_line", ")", ",", "\n", ")", "\n", "i", "+=", "1", "\n", "cur_bs", "+=", "1", "\n", "", "if", "cur_bs", ">=", "self", ".", "bs", ":", "\n", "                            ", "break", "\n", "", "", "if", "self", ".", "reverse", ":", "\n", "                        ", "features", "=", "convert_examples_to_features_dynamic_rev", "(", "\n", "examples", ",", "self", ".", "toker", ",", "self", ".", "max_seq_length", ")", "\n", "", "else", ":", "\n", "                        ", "features", "=", "convert_examples_to_features_dynamic", "(", "\n", "examples", ",", "self", ".", "toker", ",", "self", ".", "max_seq_length", ")", "\n", "", "batch", "=", "self", ".", "_batch_feature", "(", "features", ")", "\n", "yield", "batch", "\n", "", "", "", "except", "StopIteration", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader._batch_feature": [[299, 325], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "", "def", "_batch_feature", "(", "self", ",", "features", ")", ":", "\n", "        ", "input_ids", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'input_ids'", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "position_ids", "=", "pad_sequence", "(", "\n", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'position_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "token_type_ids", "=", "pad_sequence", "(", "\n", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'token_type_ids'", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "TOKEN_TYPE_CXT", ")", "\n", "labels", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "f", ".", "lm_labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "doc_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "doc_len", "for", "f", "in", "features", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "context_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "context_len", "for", "f", "in", "features", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "response_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "response_len", "for", "f", "in", "features", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "labels", ",", "doc_len", ",", "\n", "context_len", ",", "response_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader.get_len": [[326, 330], ["int", "subprocess.check_output().split", "subprocess.check_output"], "methods", ["None"], ["", "def", "get_len", "(", "self", ",", "corpus", ")", ":", "\n", "        ", "n_line", "=", "int", "(", "sp", ".", "check_output", "(", "f\"wc -l {corpus}\"", ".", "split", "(", ")", ",", "\n", "universal_newlines", "=", "True", ")", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "return", "n_line", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.convert_examples_to_features_dynamic": [[162, 201], ["tokenizer.encode", "tokenizer.encode", "gpt2_training.train_utils.InputFeatures", "len", "list", "list", "len", "len", "len", "len", "len", "len", "len", "tokenizer.encode", "example.context.split", "len", "len", "len", "range", "range", "data_loader.convert_examples_to_features_dynamic.featurize"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "", "def", "convert_examples_to_features_dynamic", "(", "examples", ",", "tokenizer", ",", "\n", "max_seq_length", "=", "512", ",", "doc_limit", "=", "256", ",", "cxt_limit", "=", "128", ",", "rsp_limit", "=", "128", ",", "doc_start_pos", "=", "400", ")", ":", "\n", "    ", "\"\"\"\n    do not pad\n    \"\"\"", "\n", "def", "featurize", "(", "example", ")", ":", "\n", "        ", "conv_id", "=", "example", ".", "conv_id", "\n", "\n", "end_of_text_id", "=", "tokenizer", ".", "encoder", "[", "END_OF_TEXT_TOKEN", "]", "\n", "\n", "context_id", "=", "[", "tokenizer", ".", "encode", "(", "x", ")", "+", "[", "end_of_text_id", "]", "for", "x", "in", "example", ".", "context", ".", "split", "(", "' EOS '", ")", "]", "\n", "context_id", "=", "[", "x", "for", "sublist", "in", "context_id", "for", "x", "in", "sublist", "]", "\n", "context_id", "=", "context_id", "[", ":", "-", "1", "]", "\n", "\n", "doc_id", "=", "tokenizer", ".", "encode", "(", "example", ".", "doc", ")", "\n", "\n", "response_id", "=", "tokenizer", ".", "encode", "(", "example", ".", "response", ")", "\n", "\n", "doc_id", "=", "doc_id", "[", ":", "doc_limit", "]", "if", "len", "(", "doc_id", ")", ">", "doc_limit", "else", "doc_id", "\n", "context_id", "=", "context_id", "[", "-", "cxt_limit", ":", "]", "if", "len", "(", "context_id", ")", ">", "cxt_limit", "else", "context_id", "\n", "response_id", "=", "response_id", "[", ":", "rsp_limit", "]", "if", "len", "(", "response_id", ")", ">", "rsp_limit", "else", "response_id", "\n", "\n", "input_ids", "=", "doc_id", "+", "[", "end_of_text_id", "]", "+", "context_id", "+", "[", "end_of_text_id", "]", "+", "response_id", "\n", "\n", "lm_labels", "=", "[", "-", "1", "]", "*", "len", "(", "doc_id", ")", "+", "[", "-", "1", "]", "*", "len", "(", "context_id", ")", "+", "[", "-", "1", "]", "+", "response_id", "+", "(", "[", "end_of_text_id", "]", "if", "len", "(", "response_id", ")", ">", "0", "else", "[", "-", "1", "]", ")", "\n", "\n", "doc_len", "=", "len", "(", "doc_id", ")", "+", "1", "\n", "\n", "position_ids", "=", "list", "(", "range", "(", "doc_start_pos", ",", "doc_start_pos", "+", "doc_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "len", "(", "input_ids", ")", "-", "doc_len", ")", ")", "\n", "\n", "token_type_ids", "=", "[", "TOKEN_TYPE_DOC", "]", "*", "doc_len", "+", "[", "TOKEN_TYPE_CXT", "]", "*", "(", "len", "(", "input_ids", ")", "-", "doc_len", ")", "\n", "\n", "assert", "(", "len", "(", "input_ids", ")", "==", "len", "(", "position_ids", ")", "==", "len", "(", "token_type_ids", ")", "==", "len", "(", "lm_labels", ")", ")", "\n", "\n", "return", "InputFeatures", "(", "conv_id", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "\n", "lm_labels", ",", "len", "(", "doc_id", ")", ",", "len", "(", "context_id", ")", ",", "len", "(", "response_id", ")", ")", "\n", "\n", "", "features", "=", "[", "f", "for", "f", "in", "[", "featurize", "(", "ex", ")", "for", "ex", "in", "examples", "]", "if", "f", "is", "not", "None", "]", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.convert_examples_to_features_dynamic_rev": [[202, 237], ["tokenizer.encode", "tokenizer.encode", "gpt2_training.train_utils.InputFeatures", "len", "len", "list", "len", "len", "len", "len", "len", "len", "len", "tokenizer.encode", "example.context.split", "len", "len", "len", "list", "list", "range", "data_loader.convert_examples_to_features_dynamic.featurize"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "def", "convert_examples_to_features_dynamic_rev", "(", "examples", ",", "tokenizer", ",", "\n", "max_seq_length", "=", "512", ",", "doc_limit", "=", "256", ",", "cxt_limit", "=", "128", ",", "rsp_limit", "=", "128", ",", "doc_start_pos", "=", "400", ")", ":", "\n", "    ", "\"\"\"\n    do not pad\n    \"\"\"", "\n", "def", "featurize", "(", "example", ")", ":", "\n", "        ", "conv_id", "=", "example", ".", "conv_id", "\n", "end_of_text_id", "=", "tokenizer", ".", "encoder", "[", "END_OF_TEXT_TOKEN", "]", "\n", "context_id", "=", "[", "tokenizer", ".", "encode", "(", "x", ")", "+", "[", "end_of_text_id", "]", "for", "x", "in", "example", ".", "context", ".", "split", "(", "' EOS '", ")", "]", "\n", "context_id", "=", "[", "x", "for", "sublist", "in", "context_id", "for", "x", "in", "sublist", "]", "\n", "context_id", "=", "context_id", "[", ":", "-", "1", "]", "\n", "doc_id", "=", "tokenizer", ".", "encode", "(", "example", ".", "doc", ")", "\n", "\n", "response_id", "=", "tokenizer", ".", "encode", "(", "example", ".", "response", ")", "\n", "\n", "doc_id", "=", "doc_id", "[", ":", "doc_limit", "]", "if", "len", "(", "doc_id", ")", ">", "doc_limit", "else", "doc_id", "\n", "context_id", "=", "context_id", "[", "-", "cxt_limit", ":", "]", "if", "len", "(", "context_id", ")", ">", "cxt_limit", "else", "context_id", "\n", "response_id", "=", "response_id", "[", ":", "rsp_limit", "]", "if", "len", "(", "response_id", ")", ">", "rsp_limit", "else", "response_id", "\n", "\n", "input_ids", "=", "response_id", "+", "[", "end_of_text_id", "]", "+", "doc_id", "+", "[", "end_of_text_id", "]", "+", "context_id", "\n", "\n", "lm_labels", "=", "[", "-", "1", "]", "*", "len", "(", "response_id", ")", "+", "doc_id", "+", "context_id", "+", "[", "end_of_text_id", "]", "\n", "\n", "rsp_len", "=", "len", "(", "response_id", ")", "+", "1", "\n", "doc_len", "=", "len", "(", "doc_id", ")", "+", "1", "\n", "position_ids", "=", "list", "(", "range", "(", "0", ",", "rsp_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "doc_start_pos", ",", "doc_start_pos", "+", "doc_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "rsp_len", ",", "len", "(", "input_ids", ")", "-", "doc_len", ",", "1", ")", ")", "\n", "token_type_ids", "=", "[", "TOKEN_TYPE_CXT", "]", "*", "rsp_len", "+", "[", "TOKEN_TYPE_DOC", "]", "*", "doc_len", "+", "[", "TOKEN_TYPE_CXT", "]", "*", "(", "len", "(", "input_ids", ")", "-", "doc_len", "-", "rsp_len", ")", "\n", "\n", "assert", "(", "len", "(", "input_ids", ")", "==", "len", "(", "position_ids", ")", "==", "len", "(", "token_type_ids", ")", "==", "len", "(", "lm_labels", ")", ")", "\n", "\n", "return", "InputFeatures", "(", "conv_id", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "\n", "lm_labels", ",", "len", "(", "doc_id", ")", ",", "len", "(", "context_id", ")", ",", "len", "(", "response_id", ")", ")", "\n", "\n", "", "features", "=", "[", "f", "for", "f", "in", "[", "featurize", "(", "ex", ")", "for", "ex", "in", "examples", "]", "if", "f", "is", "not", "None", "]", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._get_file_len": [[20, 24], ["int", "subprocess.check_output().split", "subprocess.check_output"], "function", ["None"], ["def", "_get_file_len", "(", "corpus", ")", ":", "\n", "    ", "n_line", "=", "int", "(", "sp", ".", "check_output", "(", "f\"wc -l {corpus}\"", ".", "split", "(", ")", ",", "\n", "universal_newlines", "=", "True", ")", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "return", "n_line", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._norm_text": [[25, 33], ["text.strip().split", "float", "text.strip"], "function", ["None"], ["", "def", "_norm_text", "(", "text", ")", ":", "\n", "    ", "w", ",", "*", "toks", "=", "text", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "try", ":", "\n", "        ", "w", "=", "float", "(", "w", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "toks", "=", "[", "w", "]", "+", "toks", "\n", "w", "=", "1.0", "\n", "", "return", "w", ",", "' '", ".", "join", "(", "toks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._get_inputs_from_text": [[34, 53], ["text.strip().split", "tokenizer.encode", "srcs.split", "tokenizer.encode", "weights.append", "inputs.append", "doc.strip", "tokenizer.encode", "weights.append", "inputs.append", "text.strip", "src.lstrip().rstrip", "src.lstrip"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "def", "_get_inputs_from_text", "(", "text", ",", "tokenizer", ")", ":", "\n", "    ", "doc", ",", "srcs", ",", "tgt", "=", "text", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "doc_inputs", "=", "tokenizer", ".", "encode", "(", "doc", ".", "strip", "(", ")", ")", "\n", "\n", "weights", "=", "[", "]", "\n", "inputs", "=", "[", "]", "\n", "for", "src", "in", "srcs", ".", "split", "(", "' EOS '", ")", ":", "\n", "\n", "        ", "src_weight", "=", "0.0", "\n", "context_id", "=", "tokenizer", ".", "encode", "(", "src", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", ")", "\n", "weights", ".", "append", "(", "src_weight", ")", "\n", "inputs", ".", "append", "(", "context_id", ")", "\n", "\n", "", "tgt_weight", "=", "1.0", "\n", "response_id", "=", "tokenizer", ".", "encode", "(", "tgt", ")", "\n", "weights", ".", "append", "(", "tgt_weight", ")", "\n", "inputs", ".", "append", "(", "response_id", ")", "\n", "\n", "return", "doc_inputs", ",", "weights", ",", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._make_features": [[54, 73], ["prepro._make_feature", "features.append", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._make_feature"], ["", "def", "_make_features", "(", "id_", ",", "doc_inputs", ",", "weights", ",", "inputs", ",", "tokenizer", ",", "max_len", ",", "reverse", "=", "False", ",", "doc_limit", "=", "256", ",", "cxt_limit", "=", "128", ",", "rsp_limit", "=", "128", ")", ":", "\n", "    ", "end_of_text_id", "=", "tokenizer", ".", "encoder", "[", "END_OF_TEXT_TOKEN", "]", "\n", "features", "=", "[", "]", "\n", "\n", "doc", "=", "doc_inputs", "[", ":", "doc_limit", "]", "if", "len", "(", "doc_inputs", ")", ">", "doc_limit", "else", "doc_inputs", "\n", "cxt", "=", "inputs", "[", "0", "]", "\n", "for", "x", "in", "inputs", "[", "1", ":", "-", "1", "]", ":", "\n", "        ", "cxt", "+=", "[", "end_of_text_id", "]", "+", "x", "\n", "", "cxt", "=", "cxt", "[", "-", "cxt_limit", ":", "]", "if", "len", "(", "cxt", ")", ">", "cxt_limit", "else", "cxt", "\n", "rsp", "=", "inputs", "[", "-", "1", "]", "[", ":", "rsp_limit", "]", "if", "len", "(", "inputs", "[", "1", "]", ")", ">", "rsp_limit", "else", "inputs", "[", "-", "1", "]", "\n", "\n", "sents", "=", "[", "doc", ",", "cxt", ",", "rsp", "]", "\n", "ws", "=", "[", "0.0", ",", "0.0", ",", "1", ",", "0", "]", "\n", "feat", "=", "_make_feature", "(", "id_", ",", "sents", ",", "ws", ",", "end_of_text_id", ",", "reverse", "=", "reverse", ")", "\n", "\n", "if", "feat", "is", "not", "None", ":", "\n", "        ", "features", ".", "append", "(", "feat", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._make_feature": [[74, 144], ["all", "gpt2_training.train_utils.InputFeatures_train", "enumerate", "enumerate", "len", "input_ids.append", "token_type_ids.append", "lm_labels.append", "weights.append", "len", "len", "len", "len", "len", "len", "pdb.set_trace", "zip", "zip", "len", "len", "list", "list", "len", "len", "list", "len", "range", "range", "list", "list", "range", "len", "len", "len", "len", "len", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "_make_feature", "(", "id_", ",", "sents", ",", "ws", ",", "eos", ",", "reverse", "=", "False", ",", "doc_start_pos", "=", "400", ")", ":", "\n", "    ", "if", "all", "(", "w", "==", "0", "for", "w", "in", "ws", "[", "1", ":", "]", ")", ":", "\n", "        ", "return", "None", "\n", "", "lm_labels", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "token_type_ids", "=", "[", "]", "\n", "if", "not", "reverse", ":", "\n", "        ", "input_ids", "=", "[", "i", "for", "s", "in", "sents", "for", "i", "in", "s", "+", "[", "eos", "]", "]", "[", ":", "-", "1", "]", "\n", "for", "i", ",", "(", "s", ",", "w", ")", "in", "enumerate", "(", "zip", "(", "sents", ",", "ws", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "lm_labels", "+=", "[", "-", "1", "]", "*", "len", "(", "s", ")", "\n", "weights", "+=", "[", "0.0", "]", "*", "len", "(", "s", ")", "\n", "token_type_ids", "+=", "[", "TOKEN_TYPE_DOC", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "continue", "\n", "\n", "", "token_type_ids", "+=", "[", "TOKEN_TYPE_CXT", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "if", "w", "==", "0.0", ":", "\n", "                ", "lm_labels", "+=", "[", "-", "1", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "weights", "+=", "[", "0.0", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "", "else", ":", "\n", "                ", "lm_labels", "+=", "(", "s", "+", "[", "eos", "]", ")", "\n", "weights", "+=", "[", "w", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "", "", "", "else", ":", "\n", "        ", "sents", "=", "[", "sents", "[", "2", "]", ",", "sents", "[", "0", "]", ",", "sents", "[", "1", "]", "]", "\n", "ws", "=", "[", "0.0", ",", "1.0", ",", "1.0", "]", "\n", "input_ids", "=", "[", "i", "for", "s", "in", "sents", "for", "i", "in", "s", "+", "[", "eos", "]", "]", "[", ":", "-", "1", "]", "\n", "for", "i", ",", "(", "s", ",", "w", ")", "in", "enumerate", "(", "zip", "(", "sents", ",", "ws", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "lm_labels", "+=", "[", "-", "1", "]", "*", "len", "(", "s", ")", "\n", "weights", "+=", "[", "0.0", "]", "*", "len", "(", "s", ")", "\n", "token_type_ids", "+=", "[", "TOKEN_TYPE_CXT", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                ", "token_type_ids", "+=", "[", "TOKEN_TYPE_DOC", "if", "i", "==", "1", "else", "TOKEN_TYPE_CXT", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "lm_labels", "+=", "(", "s", "+", "[", "eos", "]", ")", "\n", "weights", "+=", "[", "w", "]", "*", "(", "len", "(", "s", ")", "+", "1", ")", "\n", "\n", "", "", "", "token_type_ids", "=", "token_type_ids", "[", ":", "-", "1", "]", "\n", "\n", "i", "=", "len", "(", "lm_labels", ")", "-", "1", "\n", "while", "i", ">=", "0", ":", "\n", "        ", "if", "lm_labels", "[", "i", "]", "!=", "-", "1", ":", "\n", "            ", "break", "\n", "", "i", "-=", "1", "\n", "", "input_ids", "=", "input_ids", "[", ":", "i", "+", "1", "]", "\n", "lm_labels", "=", "lm_labels", "[", ":", "i", "+", "1", "]", "\n", "weights", "=", "weights", "[", ":", "i", "+", "1", "]", "\n", "token_type_ids", "=", "token_type_ids", "[", ":", "i", "+", "1", "]", "\n", "\n", "while", "len", "(", "input_ids", ")", "%", "8", "!=", "0", ":", "\n", "        ", "input_ids", ".", "append", "(", "0", ")", "\n", "token_type_ids", ".", "append", "(", "TOKEN_TYPE_CXT", ")", "\n", "lm_labels", ".", "append", "(", "-", "1", ")", "\n", "weights", ".", "append", "(", "0.0", ")", "\n", "\n", "", "if", "not", "reverse", ":", "\n", "        ", "doc_len", "=", "len", "(", "sents", "[", "0", "]", ")", "+", "1", "\n", "position_ids", "=", "list", "(", "range", "(", "doc_start_pos", ",", "doc_start_pos", "+", "doc_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "len", "(", "input_ids", ")", "-", "doc_len", ")", ")", "\n", "", "else", ":", "\n", "        ", "rsp_len", "=", "len", "(", "sents", "[", "0", "]", ")", "+", "1", "\n", "doc_len", "=", "len", "(", "sents", "[", "1", "]", ")", "+", "1", "\n", "position_ids", "=", "list", "(", "range", "(", "0", ",", "rsp_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "doc_start_pos", ",", "doc_start_pos", "+", "doc_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "rsp_len", ",", "len", "(", "input_ids", ")", "-", "doc_len", ",", "1", ")", ")", "\n", "\n", "", "assert", "(", "len", "(", "input_ids", ")", "==", "len", "(", "position_ids", ")", "==", "len", "(", "token_type_ids", ")", "==", "len", "(", "lm_labels", ")", "==", "len", "(", "weights", ")", ")", "\n", "assert", "len", "(", "input_ids", ")", "%", "8", "==", "0", "\n", "if", "len", "(", "input_ids", ")", "==", "0", ":", "\n", "        ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "feature", "=", "InputFeatures", "(", "id_", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "lm_labels", ",", "weights", ")", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro.main": [[145, 208], ["lsp_model.GPT2Tokenizer.from_pretrained", "os.path.exists", "torch.save", "attrs.append", "attrs.append", "os.path.dirname", "ValueError", "os.makedirs", "open", "shelve.open", "tqdm.tqdm", "gzip.compress", "open", "json.dump", "os.path.join", "os.path.dirname", "json.dumps().encode", "os.path.join", "os.path.dirname", "prepro._get_file_len", "prepro._get_inputs_from_text", "prepro._make_features", "os.path.dirname", "os.path.dirname", "len", "gzip.compress", "len", "len", "len", "chunk.append", "print", "json.dumps", "json.dumps().encode", "vars", "json.dumps"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._get_file_len", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._get_inputs_from_text", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.prepro._make_features", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "toker", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "'gpt2'", ")", "\n", "attrs", "=", "[", "]", "\n", "if", "args", ".", "reverse", ":", "\n", "        ", "attrs", ".", "append", "(", "'reverse'", ")", "\n", "", "if", "args", ".", "two_turn", ":", "\n", "        ", "attrs", ".", "append", "(", "'2turn'", ")", "\n", "", "if", "attrs", ":", "\n", "        ", "db_path", "=", "(", "f'{args.corpus[:-4]}.{args.max_seq_len}len.'", "\n", "f'{\".\".join(attrs)}.db/db'", ")", "\n", "", "else", ":", "\n", "        ", "db_path", "=", "f'{args.corpus[:-4]}.{args.max_seq_len}len.db/db'", "\n", "", "if", "exists", "(", "dirname", "(", "db_path", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'Found existing DB {dirname(db_path)}, please backup'", ")", "\n", "", "else", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", "(", "db_path", ")", ")", "\n", "", "with", "open", "(", "args", ".", "corpus", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ",", "shelve", ".", "open", "(", "db_path", ",", "'n'", ")", "as", "db", ":", "\n", "        ", "chunk", "=", "[", "]", "\n", "n_chunk", "=", "0", "\n", "n_example", "=", "0", "\n", "for", "line", "in", "tqdm", "(", "reader", ",", "total", "=", "_get_file_len", "(", "args", ".", "corpus", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "len", "(", "chunk", ")", ">=", "args", ".", "chunk_size", ":", "\n", "\n", "                    ", "db", "[", "f'chunk_{n_chunk}'", "]", "=", "gzip", ".", "compress", "(", "\n", "json", ".", "dumps", "(", "chunk", "[", ":", "args", ".", "chunk_size", "]", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "chunk", "=", "chunk", "[", "args", ".", "chunk_size", ":", "]", "\n", "n_chunk", "+=", "1", "\n", "", "if", "len", "(", "line", ")", "<", "25", ":", "\n", "                    ", "continue", "\n", "\n", "", "doc_inputs", ",", "weights", ",", "inputs", "=", "_get_inputs_from_text", "(", "line", ",", "toker", ")", "\n", "if", "len", "(", "doc_inputs", ")", "<", "args", ".", "doc_limit", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "args", ".", "two_turn", ":", "\n", "                    ", "weights", "=", "weights", "[", ":", "2", "]", "\n", "inputs", "=", "inputs", "[", ":", "2", "]", "\n", "", "if", "len", "(", "weights", ")", "<", "2", ":", "\n", "                    ", "continue", "\n", "\n", "", "features", "=", "_make_features", "(", "n_example", ",", "doc_inputs", ",", "weights", ",", "inputs", ",", "\n", "toker", ",", "args", ".", "max_seq_len", ",", "reverse", "=", "args", ".", "reverse", ")", "\n", "for", "feature", "in", "features", ":", "\n", "                    ", "chunk", ".", "append", "(", "vars", "(", "feature", ")", ")", "\n", "n_example", "+=", "1", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "'!!! prepro exception !!!'", ",", "e", ")", "\n", "continue", "\n", "\n", "", "", "db", "[", "f'chunk_{n_chunk}'", "]", "=", "gzip", ".", "compress", "(", "\n", "json", ".", "dumps", "(", "chunk", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "", "meta", "=", "{", "'n_example'", ":", "n_example", ",", "\n", "'chunk_size'", ":", "args", ".", "chunk_size", ",", "\n", "'max_seq_len'", ":", "args", ".", "max_seq_len", ",", "\n", "'reverse'", ":", "args", ".", "reverse", ",", "\n", "'two_turn'", ":", "args", ".", "two_turn", "}", "\n", "with", "open", "(", "join", "(", "dirname", "(", "db_path", ")", ",", "'meta.json'", ")", ",", "'w'", ")", "as", "writer", ":", "\n", "        ", "json", ".", "dump", "(", "meta", ",", "writer", ",", "indent", "=", "4", ")", "\n", "", "torch", ".", "save", "(", "toker", ",", "join", "(", "dirname", "(", "db_path", ")", ",", "'tokenizer.pt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.eval_gpt2.top_k_logits": [[30, 42], ["values[].view().expand_as", "torch.where", "torch.where", "torch.topk", "torch.topk", "values[].view", "torch.ones_like", "torch.ones_like"], "function", ["None"], ["def", "top_k_logits", "(", "logits", ",", "k", ")", ":", "\n", "    ", "\"\"\"\n    Masks everything but the k top entries as -infinity (1e10).\n    Used to mask logits such that e^-infinity -> 0 won't contribute to the\n    sum of the denominator.\n    \"\"\"", "\n", "if", "k", "==", "0", ":", "\n", "        ", "return", "logits", "\n", "", "else", ":", "\n", "        ", "values", "=", "torch", ".", "topk", "(", "logits", ",", "k", ")", "[", "0", "]", "\n", "batch_mins", "=", "values", "[", ":", ",", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "logits", ")", "\n", "return", "torch", ".", "where", "(", "logits", "<", "batch_mins", ",", "torch", ".", "ones_like", "(", "logits", ")", "*", "-", "1e10", ",", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.eval_gpt2.sample_sequence": [[43, 65], ["torch.tensor().unsqueeze().repeat", "torch.tensor().unsqueeze().repeat", "torch.full", "torch.full", "torch.no_grad", "torch.no_grad", "tqdm.trange", "model", "eval_gpt2.top_k_logits", "torch.softmax", "torch.cat", "torch.cat", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.multinomial", "torch.multinomial", "torch.topk", "torch.topk", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.top_k_logits"], ["", "", "def", "sample_sequence", "(", "model", ",", "length", ",", "start_token", "=", "None", ",", "batch_size", "=", "None", ",", "context", "=", "None", ",", "temperature", "=", "1", ",", "top_k", "=", "0", ",", "device", "=", "'cuda'", ",", "sample", "=", "True", ")", ":", "\n", "    ", "if", "start_token", "is", "None", ":", "\n", "        ", "assert", "context", "is", "not", "None", ",", "'Specify exactly one of start_token and context!'", "\n", "context", "=", "torch", ".", "tensor", "(", "context", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "long", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "assert", "context", "is", "None", ",", "'Specify exactly one of start_token and context!'", "\n", "context", "=", "torch", ".", "full", "(", "(", "batch_size", ",", "1", ")", ",", "start_token", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "prev", "=", "context", "\n", "output", "=", "context", "\n", "past", "=", "None", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "trange", "(", "length", ")", ":", "\n", "            ", "logits", ",", "past", "=", "model", "(", "prev", ",", "past", "=", "past", ")", "\n", "logits", "=", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", "\n", "logits", "=", "top_k_logits", "(", "logits", ",", "k", "=", "top_k", ")", "\n", "log_probs", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "if", "sample", ":", "\n", "                ", "prev", "=", "torch", ".", "multinomial", "(", "log_probs", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "_", ",", "prev", "=", "torch", ".", "topk", "(", "log_probs", ",", "k", "=", "1", ",", "dim", "=", "-", "1", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "prev", ")", ",", "dim", "=", "1", ")", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.eval_gpt2.run_model": [[66, 207], ["print", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "pprint.pprint", "numpy.random.seed", "torch.random.manual_seed", "torch.random.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "pytorch_pretrained_bert.GPT2Config.from_json_file", "pytorch_pretrained_bert.GPT2Tokenizer.from_pretrained", "gpt2_training.train_utils.load_model", "gpt2_training.train_utils.load_model.to", "gpt2_training.train_utils.load_model.eval", "pytorch_pretrained_bert.GPT2LMHeadModel", "gpt2_training.train_utils.fix_state_dict_namespace", "start_model.load_state_dict", "pytorch_pretrained_bert.GPT2LMHeadModel.to", "pytorch_pretrained_bert.GPT2LMHeadModel.eval", "gpt2_training.train_utils.get_eval_list_same_length_with_order", "gpt2_training.train_utils.load_model.eval", "socket.gethostname", "json.load", "json.load.items", "argparse.ArgumentParser.parse_known_args", "vars().items", "os.path.join", "pytorch_pretrained_bert.GPT2LMHeadModel", "torch.load", "torch.load", "hasattr", "all", "print", "pytorch_pretrained_bert.GPT2LMHeadModel.half", "torch.no_grad", "torch.no_grad", "open", "isinstance", "setattr", "tqdm.tqdm", "enumerate", "sys.stdout.flush", "vars", "setattr", "torch.cuda.is_available", "torch.cuda.is_available", "tqdm.tqdm", "eval_gpt2.run_model.cal_ppl"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.load_model", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.fix_state_dict_namespace", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.get_eval_list_same_length_with_order", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval"], ["", "def", "run_model", "(", ")", ":", "\n", "    ", "print", "(", "socket", ".", "gethostname", "(", ")", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model_name_or_path'", ",", "type", "=", "str", ",", "default", "=", "'/philly/sc3/resrchvc/yizzhang/GPT/pretrained/117M'", ",", "help", "=", "'pretrained model name or path to local checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ")", "\n", "parser", ".", "add_argument", "(", "\"--load_checkpoint\"", ",", "'-c'", ",", "type", "=", "str", ",", "default", "=", "'/philly/sc3/resrchvc/yizzhang/GPT/pretrained/117M/pytorch_model.bin'", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp16\"", ",", "type", "=", "boolean_string", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_file\"", ",", "'-t'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'input file for testing'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--normalize_data\"", ",", "type", "=", "boolean_string", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "'-b'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_token_id\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_eos\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_gpu'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "help", "=", "'JSON config file'", ")", "\n", "parser", ".", "add_argument", "(", "\"--rev_model_checkpoint\"", ",", "type", "=", "str", ",", "default", "=", "\"../Dialogpt_dev_data/small_reverse.pkl\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_file\"", ",", "'-o'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'output file for testing'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "\n", "if", "args", ".", "config", "is", "not", "None", ":", "\n", "\n", "        ", "opts", "=", "json", ".", "load", "(", "open", "(", "args", ".", "config", ")", ")", "\n", "for", "k", ",", "v", "in", "opts", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "str", ")", ":", "\n", "\n", "                ", "if", "'PHILLY_JOB_DIRECTORY'", "in", "v", ":", "\n", "                    ", "v", "=", "v", ".", "replace", "(", "'PHILLY_JOB_DIRECTORY'", ",", "\n", "os", ".", "environ", "[", "'PHILLY_JOB_DIRECTORY'", "]", ")", "\n", "", "elif", "'PHILLY_LOG_DIRECTORY'", "in", "v", ":", "\n", "                    ", "v", "=", "v", ".", "replace", "(", "'PHILLY_LOG_DIRECTORY'", ",", "\n", "os", ".", "environ", "[", "'PHILLY_LOG_DIRECTORY'", "]", ")", "\n", "", "", "setattr", "(", "args", ",", "k", ",", "v", ")", "\n", "\n", "", "argv", "=", "sys", ".", "argv", "[", "1", ":", "]", "\n", "overrides", ",", "_", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "for", "k", ",", "v", "in", "vars", "(", "overrides", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "f'--{k}'", "in", "argv", ":", "\n", "                ", "setattr", "(", "args", ",", "k", ",", "v", ")", "\n", "\n", "", "", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "args", ".", "use_gpu", "else", "\"cpu\"", ")", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "args", ".", "device", ",", "args", ".", "n_gpu", "=", "device", ",", "n_gpu", "\n", "pprint", "(", "args", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "random", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "config", "=", "GPT2Config", ".", "from_json_file", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "'config.json'", ")", ")", "\n", "enc", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "load_model", "(", "GPT2LMHeadModel", "(", "config", ")", ",", "args", ".", "load_checkpoint", ",", "args", ",", "verbose", "=", "True", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "rev_model", "=", "GPT2LMHeadModel", "(", "config", ")", "\n", "model_state_dict", "=", "fix_state_dict_namespace", "(", "torch", ".", "load", "(", "args", ".", "rev_model_checkpoint", ")", ")", "\n", "start_model", "=", "rev_model", "\n", "if", "hasattr", "(", "rev_model", ",", "\"transformer\"", ")", "and", "all", "(", "not", "s", ".", "startswith", "(", "'transformer.'", ")", "for", "s", "in", "model_state_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "print", "(", "'loading transfomer only'", ")", "\n", "start_model", "=", "rev_model", ".", "transformer", "\n", "", "start_model", ".", "load_state_dict", "(", "model_state_dict", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "rev_model", ".", "half", "(", ")", "\n", "", "rev_model", ".", "to", "(", "device", ")", "\n", "rev_model", ".", "eval", "(", ")", "\n", "\n", "eval_dataloader", "=", "get_eval_list_same_length_with_order", "(", "args", ".", "test_file", ",", "enc", ",", "args", ".", "batch_size", ",", "True", ",", "for_eval", "=", "True", ")", "\n", "model", ".", "eval", "(", ")", "\n", "outs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "loss_all", "=", "[", "]", "\n", "ppl_all", "=", "[", "]", "\n", "rev_ppl_all", "=", "[", "]", "\n", "sources", "=", "[", "]", "\n", "conv_ids", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "eval_dataloader", ")", ",", "desc", "=", "f\"Test\"", ")", "as", "pbar", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "tqdm", ".", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Iteration\"", ")", ")", ":", "\n", "                ", "new_batch", "=", "[", "]", "\n", "for", "t", "in", "batch", ":", "\n", "                    ", "if", "isinstance", "(", "t", ",", "list", ")", ":", "\n", "                        ", "new_batch", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "                        ", "new_batch", ".", "append", "(", "t", ".", "to", "(", "device", ")", ")", "\n", "", "", "input_ids", ",", "position_ids", ",", "token_ids", ",", "label_ids", ",", "doc_len", ",", "context_len", ",", "target_len", ",", "conv_id", "=", "new_batch", "\n", "\n", "if", "args", ".", "no_token_id", ":", "\n", "                    ", "token_ids", "=", "None", "\n", "", "if", "args", ".", "no_eos", ":", "\n", "                    ", "input_ids", "=", "input_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "", "def", "cal_ppl", "(", "input_ids", ",", "label_ids", ",", "model", ",", "rev", "=", "False", ")", ":", "\n", "                    ", "if", "rev", ":", "\n", "\n", "                        ", "lab_end_idx", "=", "[", "np", ".", "where", "(", "o", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "==", "EOS_ID", ")", "[", "0", "]", "for", "o", "in", "label_ids", "]", "\n", "lab_end_idx", "=", "[", "o", "[", "-", "2", "]", "if", "len", "(", "o", ")", ">", "1", "else", "-", "1", "for", "o", "in", "lab_end_idx", "]", "\n", "_label_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "cat", "(", "[", "torch", ".", "ones_like", "(", "src", "[", ":", "-", "1", "]", ")", "*", "-", "1", ",", "lab", "[", "idx", "+", "1", ":", "]", ",", "torch", ".", "ones_like", "(", "lab", "[", ":", "idx", "+", "1", "]", ")", ".", "view", "(", "-", "1", ")", "*", "-", "1", ",", "torch", ".", "ones_like", "(", "src", "[", "-", "1", "]", ")", ".", "view", "(", "-", "1", ")", "*", "-", "1", "]", ")", "for", "src", ",", "lab", ",", "idx", "in", "zip", "(", "input_ids", ",", "label_ids", ",", "lab_end_idx", ")", "]", ")", "\n", "_input_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "cat", "(", "[", "src", ",", "lab", "[", "idx", "+", "1", ":", "]", ",", "lab", "[", ":", "idx", "+", "1", "]", "]", ")", "for", "src", ",", "lab", ",", "idx", "in", "zip", "(", "input_ids", ",", "label_ids", ",", "lab_end_idx", ")", "]", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "_label_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "cat", "(", "[", "torch", ".", "ones_like", "(", "src", "[", ":", "-", "1", "]", ")", "*", "-", "1", ",", "lab", ",", "torch", ".", "ones_like", "(", "src", "[", "-", "1", "]", ")", ".", "view", "(", "-", "1", ")", "*", "-", "1", "]", ")", "for", "src", ",", "lab", "in", "zip", "(", "input_ids", ",", "label_ids", ")", "]", ")", "\n", "_input_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "cat", "(", "[", "src", ",", "lab", "]", ")", "for", "src", ",", "lab", "in", "zip", "(", "input_ids", ",", "label_ids", ")", "]", ")", "\n", "", "_input_ids", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "o", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "for", "o", "in", "_input_ids", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "EOS_ID", ")", "\n", "_label_ids", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "o", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "for", "o", "in", "_label_ids", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "\n", "_", ",", "_ppl", "=", "model", ".", "forward_pointwise", "(", "_input_ids", ",", "None", ",", "None", ",", "_label_ids", ")", "\n", "return", "_ppl", "\n", "", "ppl", "=", "cal_ppl", "(", "input_ids", ",", "label_ids", ",", "model", ")", "\n", "rev_ppl", "=", "cal_ppl", "(", "label_ids", ",", "input_ids", ",", "rev_model", ",", "rev", "=", "True", ")", "\n", "\n", "sources", ".", "extend", "(", "[", "i", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "i", "in", "input_ids", "]", ")", "\n", "targets", ".", "extend", "(", "[", "i", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "i", "in", "label_ids", "]", ")", "\n", "conv_ids", ".", "extend", "(", "conv_id", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "ppl_all", ".", "extend", "(", "ppl", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "rev_ppl_all", ".", "extend", "(", "rev_ppl", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "conv_id_map", "=", "{", "conv_ids", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "conv_ids", ")", ")", "}", "\n", "\n", "src", "=", "[", "enc", ".", "decode", "(", "s", ")", ".", "encode", "(", "'ascii'", ",", "'ignore'", ")", ".", "decode", "(", "'ascii'", ")", "for", "s", "in", "sources", "]", "\n", "\n", "tgt", "=", "[", "enc", ".", "decode", "(", "s", ")", ".", "encode", "(", "'ascii'", ",", "'ignore'", ")", ".", "decode", "(", "'ascii'", ")", "for", "s", "in", "targets", "]", "\n", "\n", "src_orders", "=", "[", "src", "[", "conv_id_map", "[", "i", "]", "]", "for", "i", "in", "sorted", "(", "conv_id_map", ")", "]", "\n", "tgt_orders", "=", "[", "tgt", "[", "conv_id_map", "[", "i", "]", "]", "for", "i", "in", "sorted", "(", "conv_id_map", ")", "]", "\n", "ppl_orders", "=", "[", "ppl_all", "[", "conv_id_map", "[", "i", "]", "]", "for", "i", "in", "sorted", "(", "conv_id_map", ")", "]", "\n", "rev_ppl_orders", "=", "[", "rev_ppl_all", "[", "conv_id_map", "[", "i", "]", "]", "for", "i", "in", "sorted", "(", "conv_id_map", ")", "]", "\n", "\n", "with", "open", "(", "args", ".", "test_file", "[", ":", "-", "3", "]", "+", "(", "args", ".", "output_file", "+", "'.'", "if", "args", ".", "output_file", "else", "''", ")", "+", "'eval.txt'", ",", "\"w\"", ")", "as", "eval_f", ":", "\n", "                ", "eval_f", ".", "write", "(", "f\"Source\\tTarget\\tPPL\\tRev_PPL\\n\"", ")", "\n", "for", "i", ",", "r", "in", "enumerate", "(", "src_orders", ")", ":", "\n", "                    ", "r", "=", "re", ".", "sub", "(", "\"\\n\"", ",", "\"\"", ",", "r", ")", "\n", "eval_f", ".", "write", "(", "f\"{src_orders[i]}\\t{tgt_orders[i]}\\t{ppl_orders[i]:.3f}\\t{rev_ppl_orders[i]:.3f}\\n\"", ")", "\n", "\n", "", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.extract_cells": [[6, 15], ["dict", "open", "line.strip", "line.strip().split", "open", "line.strip"], "function", ["None"], ["def", "extract_cells", "(", "path_in", ",", "path_hash", ")", ":", "\n", "\t", "keys", "=", "[", "line", ".", "strip", "(", "'\\n'", ")", "for", "line", "in", "open", "(", "path_hash", ")", "]", "\n", "cells", "=", "dict", "(", ")", "\n", "for", "line", "in", "open", "(", "path_in", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "\t\t", "c", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "k", "=", "c", "[", "0", "]", "\n", "if", "k", "in", "keys", ":", "\n", "\t\t\t", "cells", "[", "k", "]", "=", "c", "[", "1", ":", "]", "\n", "", "", "return", "cells", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.extract_linc_cells": [[16, 34], ["dict", "enumerate", "set", "dict", "enumerate", "k.strip", "open", "line.strip", "k.strip", "open", "line.strip", "open", "line.strip", "open", "open"], "function", ["None"], ["", "def", "extract_linc_cells", "(", "path_in", ",", "path_hash", ")", ":", "\n", "\t", "if", "\"valid\"", "in", "path_hash", ":", "\n", "\t\t", "cells", "=", "dict", "(", ")", "\n", "external_keys", "=", "[", "k", ".", "strip", "(", ")", "for", "k", "in", "open", "(", "r\"./data/processed/valid.keys.txt\"", ")", "]", "\n", "for", "no", ",", "line", "in", "enumerate", "(", "open", "(", "path_in", ",", "encoding", "=", "'utf-8'", ")", ")", ":", "\n", "\t\t\t", "c", "=", "line", ".", "strip", "(", "'\\n'", ")", "\n", "k", "=", "external_keys", "[", "no", "]", "\n", "cells", "[", "k", "]", "=", "[", "c", "]", "\n", "", "", "else", ":", "\n", "\t\t", "keys", "=", "set", "(", "[", "line", ".", "strip", "(", "'\\n'", ")", "for", "line", "in", "open", "(", "path_hash", ")", "]", ")", "\n", "cells", "=", "dict", "(", ")", "\n", "external_keys", "=", "[", "k", ".", "strip", "(", ")", "for", "k", "in", "open", "(", "r\"./data/processed/test_real.keys.txt\"", ")", "]", "\n", "for", "no", ",", "line", "in", "enumerate", "(", "open", "(", "path_in", ",", "encoding", "=", "'utf-8'", ")", ")", ":", "\n", "\t\t\t", "c", "=", "line", ".", "strip", "(", "'\\n'", ")", "\n", "k", "=", "external_keys", "[", "no", "]", "\n", "if", "k", "in", "keys", ":", "\n", "\t\t\t\t", "cells", "[", "k", "]", "=", "[", "c", "]", "\n", "", "", "", "return", "cells", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.extract_hyp_refs": [[35, 79], ["dstc.extract_linc_cells", "dstc.extract_cells", "sorted", "range", "range", "os.path.exists", "os.makedirs", "extract_linc_cells.keys", "open", "f.write", "dstc.extract_hyp_refs._clean"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.extract_linc_cells", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.extract_cells", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs"], ["", "def", "extract_hyp_refs", "(", "raw_hyp", ",", "raw_ref", ",", "path_hash", ",", "fld_out", ",", "n_refs", "=", "6", ",", "clean", "=", "False", ",", "vshuman", "=", "-", "1", ")", ":", "\n", "\t", "cells_hyp", "=", "extract_linc_cells", "(", "raw_hyp", ",", "path_hash", ")", "\n", "cells_ref", "=", "extract_cells", "(", "raw_ref", ",", "path_hash", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "fld_out", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "fld_out", ")", "\n", "\n", "", "def", "_clean", "(", "s", ")", ":", "\n", "\t\t", "if", "clean", ":", "\n", "\t\t\t", "return", "clean_str", "(", "s", ")", "\n", "", "else", ":", "\n", "\t\t\t", "return", "s", "\n", "\n", "", "", "keys", "=", "sorted", "(", "cells_hyp", ".", "keys", "(", ")", ")", "\n", "with", "open", "(", "fld_out", "+", "'/hash.txt'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "unicode", "(", "'\\n'", ".", "join", "(", "keys", ")", ")", ")", "\n", "\n", "", "lines", "=", "[", "_clean", "(", "cells_hyp", "[", "k", "]", "[", "-", "1", "]", ")", "for", "k", "in", "keys", "]", "\n", "path_hyp", "=", "fld_out", "+", "'/hyp.txt'", "\n", "with", "open", "(", "path_hyp", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "unicode", "(", "'\\n'", ".", "join", "(", "lines", ")", ")", ")", "\n", "\n", "", "lines", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n_refs", ")", ":", "\n", "\t\t", "lines", ".", "append", "(", "[", "]", ")", "\n", "", "for", "k", "in", "keys", ":", "\n", "\t\t", "refs", "=", "cells_ref", "[", "k", "]", "\n", "for", "i", "in", "range", "(", "n_refs", ")", ":", "\n", "\t\t\t", "idx", "=", "i", "%", "len", "(", "refs", ")", "\n", "if", "idx", "==", "vshuman", ":", "\n", "\t\t\t    ", "idx", "=", "(", "idx", "+", "1", ")", "%", "len", "(", "refs", ")", "\n", "", "if", "\"|\"", "in", "refs", "[", "idx", "]", ":", "\n", "\t\t\t\t", "final_ref", "=", "refs", "[", "idx", "]", ".", "split", "(", "'|'", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "\t\t\t\t", "final_ref", "=", "refs", "[", "idx", "]", "\n", "", "lines", "[", "i", "]", ".", "append", "(", "_clean", "(", "final_ref", ")", ")", "\n", "\n", "", "", "path_refs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_refs", ")", ":", "\n", "\t\t", "path_ref", "=", "fld_out", "+", "'/ref%i.txt'", "%", "i", "\n", "with", "open", "(", "path_ref", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "unicode", "(", "'\\n'", ".", "join", "(", "lines", "[", "i", "]", ")", ")", ")", "\n", "", "path_refs", ".", "append", "(", "path_ref", ")", "\n", "\n", "", "return", "path_hyp", ",", "path_refs", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.eval_one_system": [[80, 103], ["print", "submitted.replace", "dstc.extract_hyp_refs", "metrics.nlp_metrics", "len", "print", "print", "print", "print", "print", "print", "print", "open().readlines", "str", "str", "str", "str", "str", "str", "str", "open"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.extract_hyp_refs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.nlp_metrics"], ["", "def", "eval_one_system", "(", "submitted", ",", "keys", ",", "multi_ref", ",", "n_refs", "=", "6", ",", "n_lines", "=", "None", ",", "clean", "=", "False", ",", "vshuman", "=", "-", "1", ",", "PRINT", "=", "True", ")", ":", "\n", "\n", "\t", "print", "(", "'evaluating %s'", "%", "submitted", ")", "\n", "\n", "fld_out", "=", "submitted", ".", "replace", "(", "'.txt'", ",", "''", ")", "\n", "if", "clean", ":", "\n", "\t\t", "fld_out", "+=", "'_cleaned'", "\n", "", "path_hyp", ",", "path_refs", "=", "extract_hyp_refs", "(", "submitted", ",", "multi_ref", ",", "keys", ",", "fld_out", ",", "n_refs", ",", "clean", "=", "clean", ",", "vshuman", "=", "vshuman", ")", "\n", "nist", ",", "bleu", ",", "meteor", ",", "entropy", ",", "div", ",", "avg_len", "=", "nlp_metrics", "(", "path_refs", ",", "path_hyp", ",", "fld_out", ",", "n_lines", "=", "n_lines", ")", "\n", "\n", "if", "n_lines", "is", "None", ":", "\n", "\t\t", "n_lines", "=", "len", "(", "open", "(", "path_hyp", ",", "encoding", "=", "'utf-8'", ")", ".", "readlines", "(", ")", ")", "\n", "\n", "", "if", "PRINT", ":", "\n", "\t\t", "print", "(", "'n_lines = '", "+", "str", "(", "n_lines", ")", ")", "\n", "print", "(", "'NIST = '", "+", "str", "(", "nist", ")", ")", "\n", "print", "(", "'BLEU = '", "+", "str", "(", "bleu", ")", ")", "\n", "print", "(", "'METEOR = '", "+", "str", "(", "meteor", ")", ")", "\n", "print", "(", "'entropy = '", "+", "str", "(", "entropy", ")", ")", "\n", "print", "(", "'diversity = '", "+", "str", "(", "div", ")", ")", "\n", "print", "(", "'avg_len = '", "+", "str", "(", "avg_len", ")", ")", "\n", "\n", "", "return", "[", "n_lines", "]", "+", "nist", "+", "bleu", "+", "[", "meteor", "]", "+", "entropy", "+", "div", "+", "[", "avg_len", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.eval_all_systems": [[104, 132], ["print", "open", "f.write", "fl.endswith", "dstc.eval_one_system", "os.listdir", "open", "f.write", "fname.endswith", "dstc.eval_one_system", "open", "f.write", "map", "range", "map", "range", "range"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.eval_one_system", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.dstc.eval_one_system"], ["", "def", "eval_all_systems", "(", "files", ",", "path_report", ",", "keys", ",", "multi_ref", ",", "n_refs", "=", "6", ",", "n_lines", "=", "None", ",", "clean", "=", "False", ",", "vshuman", "=", "False", ")", ":", "\n", "# evaluate all systems (*.txt) in each folder `files`", "\n", "\n", "\t", "with", "open", "(", "path_report", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "\n", "[", "'fname'", ",", "'n_lines'", "]", "+", "[", "'nist%i'", "%", "i", "for", "i", "in", "range", "(", "1", ",", "4", "+", "1", ")", "]", "+", "[", "'bleu%i'", "%", "i", "for", "i", "in", "range", "(", "1", ",", "4", "+", "1", ")", "]", "+", "[", "'meteor'", "]", "+", "[", "'entropy%i'", "%", "i", "for", "i", "in", "range", "(", "1", ",", "4", "+", "1", ")", "]", "+", "[", "'div1'", ",", "'div2'", ",", "'avg_len'", "]", "\n", ")", "+", "'\\n'", ")", "\n", "\n", "", "for", "fl", "in", "files", ":", "\n", "\t\t", "if", "fl", ".", "endswith", "(", "'.txt'", ")", ":", "\n", "\t\t\t", "submitted", "=", "fl", "\n", "results", "=", "eval_one_system", "(", "submitted", ",", "keys", "=", "keys", ",", "multi_ref", "=", "multi_ref", ",", "n_refs", "=", "n_refs", ",", "clean", "=", "clean", ",", "n_lines", "=", "n_lines", ",", "vshuman", "=", "vshuman", ",", "PRINT", "=", "False", ")", "\n", "with", "open", "(", "path_report", ",", "'a'", ")", "as", "f", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "map", "(", "str", ",", "[", "submitted", "]", "+", "results", ")", ")", "+", "'\\n'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "for", "fname", "in", "os", ".", "listdir", "(", "fl", ")", ":", "\n", "\t\t\t\t", "if", "fname", ".", "endswith", "(", "'.txt'", ")", ":", "\n", "\t\t\t\t\t", "submitted", "=", "fl", "+", "'/'", "+", "fname", "\n", "results", "=", "eval_one_system", "(", "submitted", ",", "keys", "=", "keys", ",", "multi_ref", "=", "multi_ref", ",", "n_refs", "=", "n_refs", ",", "clean", "=", "clean", ",", "n_lines", "=", "n_lines", ",", "vshuman", "=", "vshuman", ",", "PRINT", "=", "False", ")", "\n", "with", "open", "(", "path_report", ",", "'a'", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "map", "(", "str", ",", "[", "submitted", "]", "+", "results", ")", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "", "", "", "print", "(", "'report saved to: '", "+", "path_report", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_nist_bleu": [[6, 44], ["util.makedirs", "metrics._write_xml", "metrics._write_xml", "metrics._write_xml", "time.sleep", "subprocess.Popen", "subprocess.Popen.communicate", "output.decode().split", "len", "open().readlines", "output.decode", "lines[].strip().split", "lines[].strip().split", "print", "print", "print", "print", "float", "float", "output.decode", "error.decode", "open", "lines[].strip", "lines[].strip", "str"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics._write_xml", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics._write_xml", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics._write_xml", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode"], ["def", "calc_nist_bleu", "(", "path_refs", ",", "path_hyp", ",", "fld_out", "=", "'temp'", ",", "n_lines", "=", "None", ")", ":", "\n", "# call mteval-v14c.pl", "\n", "# ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v14c.pl", "\n", "# you may need to cpan install XML:Twig Sort:Naturally String:Util ", "\n", "\n", "\t", "makedirs", "(", "fld_out", ")", "\n", "\n", "if", "n_lines", "is", "None", ":", "\n", "\t\t", "n_lines", "=", "len", "(", "open", "(", "path_refs", "[", "0", "]", ",", "encoding", "=", "'utf-8'", ")", ".", "readlines", "(", ")", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "", "_write_xml", "(", "[", "''", "]", ",", "fld_out", "+", "'/src.xml'", ",", "'src'", ",", "n_lines", "=", "n_lines", ")", "\n", "_write_xml", "(", "[", "path_hyp", "]", ",", "fld_out", "+", "'/hyp.xml'", ",", "'hyp'", ")", "#, n_lines=n_lines)", "\n", "_write_xml", "(", "path_refs", ",", "fld_out", "+", "'/ref.xml'", ",", "'ref'", ")", "#, n_lines=n_lines)", "\n", "\n", "time", ".", "sleep", "(", "1", ")", "\n", "cmd", "=", "[", "\n", "'perl'", ",", "'3rdparty/mteval-v14c.pl'", ",", "\n", "'-s'", ",", "'%s/src.xml'", "%", "fld_out", ",", "\n", "'-t'", ",", "'%s/hyp.xml'", "%", "fld_out", ",", "\n", "'-r'", ",", "'%s/ref.xml'", "%", "fld_out", ",", "\n", "]", "\n", "process", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "output", ",", "error", "=", "process", ".", "communicate", "(", ")", "\n", "\n", "lines", "=", "output", ".", "decode", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "\n", "try", ":", "\n", "\t\t", "nist", "=", "lines", "[", "-", "6", "]", ".", "strip", "(", "'\\r'", ")", ".", "split", "(", ")", "[", "1", ":", "5", "]", "\n", "bleu", "=", "lines", "[", "-", "4", "]", ".", "strip", "(", "'\\r'", ")", ".", "split", "(", ")", "[", "1", ":", "5", "]", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "nist", "]", ",", "[", "float", "(", "x", ")", "for", "x", "in", "bleu", "]", "\n", "\n", "", "except", "Exception", ":", "\n", "\t\t", "print", "(", "'mteval-v14c.pl returns unexpected message'", ")", "\n", "print", "(", "'cmd = '", "+", "str", "(", "cmd", ")", ")", "\n", "print", "(", "output", ".", "decode", "(", ")", ")", "\n", "print", "(", "error", ".", "decode", "(", ")", ")", "\n", "return", "[", "-", "1", "]", "*", "4", ",", "[", "-", "1", "]", "*", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_cum_bleu": [[45, 63], ["subprocess.Popen", "subprocess.Popen.communicate", "output.decode", "open", "f.readlines", "subprocess.Popen.stdin.write", "line.encode"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "", "def", "calc_cum_bleu", "(", "path_refs", ",", "path_hyp", ")", ":", "\n", "# call multi-bleu.pl", "\n", "# https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl", "\n", "# the 4-gram cum BLEU returned by this one should be very close to calc_nist_bleu", "\n", "# however multi-bleu.pl doesn't return cum BLEU of lower rank, so in nlp_metrics we preferr calc_nist_bleu", "\n", "# NOTE: this func doesn't support n_lines argument and output is not parsed yet", "\n", "\n", "\t", "process", "=", "subprocess", ".", "Popen", "(", "\n", "[", "'perl'", ",", "'3rdparty/multi-bleu.perl'", "]", "+", "path_refs", ",", "\n", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "stdin", "=", "subprocess", ".", "PIPE", "\n", ")", "\n", "with", "open", "(", "path_hyp", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "for", "line", "in", "lines", ":", "\n", "\t\t", "process", ".", "stdin", ".", "write", "(", "line", ".", "encode", "(", ")", ")", "\n", "", "output", ",", "error", "=", "process", ".", "communicate", "(", ")", "\n", "return", "output", ".", "decode", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_meteor": [[64, 90], ["util.makedirs", "metrics._write_merged_refs", "print", "subprocess.Popen", "subprocess.Popen.communicate", "output.decode().split", "print", "print", "print", "print", "output.decode", "error.decode", "len", "output.decode", "float", "line.split"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics._write_merged_refs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode"], ["", "def", "calc_meteor", "(", "path_refs", ",", "path_hyp", ",", "fld_out", "=", "'temp'", ",", "n_lines", "=", "None", ",", "pretokenized", "=", "True", ")", ":", "\n", "# Call METEOR code.", "\n", "# http://www.cs.cmu.edu/~alavie/METEOR/index.html", "\n", "\n", "\t", "makedirs", "(", "fld_out", ")", "\n", "path_merged_refs", "=", "fld_out", "+", "'/refs_merged.txt'", "\n", "_write_merged_refs", "(", "path_refs", ",", "path_merged_refs", ")", "\n", "cmd", "=", "[", "\n", "'java'", ",", "'-Xmx1g'", ",", "# heapsize of 1G to avoid OutOfMemoryError", "\n", "'-jar'", ",", "'3rdparty/meteor-1.5/meteor-1.5.jar'", ",", "\n", "path_hyp", ",", "path_merged_refs", ",", "\n", "'-r'", ",", "'%i'", "%", "len", "(", "path_refs", ")", ",", "# refCount ", "\n", "'-l'", ",", "'en'", ",", "'-norm'", "# also supports language: cz de es fr ar", "\n", "]", "\n", "print", "(", "cmd", ")", "\n", "process", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "output", ",", "error", "=", "process", ".", "communicate", "(", ")", "\n", "for", "line", "in", "output", ".", "decode", "(", ")", ".", "split", "(", "'\\n'", ")", ":", "\n", "\t\t", "if", "\"Final score:\"", "in", "line", ":", "\n", "\t\t\t", "return", "float", "(", "line", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "\n", "", "", "print", "(", "'meteor-1.5.jar returns unexpected message'", ")", "\n", "print", "(", "\"cmd = \"", "+", "\" \"", ".", "join", "(", "cmd", ")", ")", "\n", "print", "(", "output", ".", "decode", "(", ")", ")", "\n", "print", "(", "error", ".", "decode", "(", ")", ")", "\n", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_entropy": [[91, 112], ["open", "range", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "line.strip().split", "range", "sum", "counter[].values", "range", "counter[].values", "line.strip", "len", "np.log", "np.log"], "function", ["None"], ["", "def", "calc_entropy", "(", "path_hyp", ",", "n_lines", "=", "None", ")", ":", "\n", "# based on Yizhe Zhang's code", "\n", "\t", "etp_score", "=", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "\n", "counter", "=", "[", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", "]", "\n", "i", "=", "0", "\n", "for", "line", "in", "open", "(", "path_hyp", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "\t\t", "i", "+=", "1", "\n", "words", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", ")", "\n", "for", "n", "in", "range", "(", "4", ")", ":", "\n", "\t\t\t", "for", "idx", "in", "range", "(", "len", "(", "words", ")", "-", "n", ")", ":", "\n", "\t\t\t\t", "ngram", "=", "' '", ".", "join", "(", "words", "[", "idx", ":", "idx", "+", "n", "+", "1", "]", ")", "\n", "counter", "[", "n", "]", "[", "ngram", "]", "+=", "1", "\n", "", "", "if", "i", "==", "n_lines", ":", "\n", "\t\t\t", "break", "\n", "\n", "", "", "for", "n", "in", "range", "(", "4", ")", ":", "\n", "\t\t", "total", "=", "sum", "(", "counter", "[", "n", "]", ".", "values", "(", ")", ")", "\n", "for", "v", "in", "counter", "[", "n", "]", ".", "values", "(", ")", ":", "\n", "\t\t\t", "etp_score", "[", "n", "]", "+=", "-", "v", "/", "total", "*", "(", "np", ".", "log", "(", "v", ")", "-", "np", ".", "log", "(", "total", ")", ")", "\n", "\n", "", "", "return", "etp_score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_len": [[113, 120], ["open", "np.mean", "l.append", "len", "len", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "calc_len", "(", "path", ",", "n_lines", ")", ":", "\n", "\t", "l", "=", "[", "]", "\n", "for", "line", "in", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", ":", "\n", "\t\t", "l", ".", "append", "(", "len", "(", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", ")", ")", ")", "\n", "if", "len", "(", "l", ")", "==", "n_lines", ":", "\n", "\t\t\t", "break", "\n", "", "", "return", "np", ".", "mean", "(", "l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_diversity": [[121, 134], ["open", "collections.defaultdict", "collections.defaultdict", "line.strip().split", "range", "len", "len", "range", "types[].keys", "types[].keys", "line.strip", "len"], "function", ["None"], ["", "def", "calc_diversity", "(", "path_hyp", ")", ":", "\n", "\t", "tokens", "=", "[", "0.0", ",", "0.0", "]", "\n", "types", "=", "[", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", "]", "\n", "for", "line", "in", "open", "(", "path_hyp", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "\t\t", "words", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", ")", "\n", "for", "n", "in", "range", "(", "2", ")", ":", "\n", "\t\t\t", "for", "idx", "in", "range", "(", "len", "(", "words", ")", "-", "n", ")", ":", "\n", "\t\t\t\t", "ngram", "=", "' '", ".", "join", "(", "words", "[", "idx", ":", "idx", "+", "n", "+", "1", "]", ")", "\n", "types", "[", "n", "]", "[", "ngram", "]", "=", "1", "\n", "tokens", "[", "n", "]", "+=", "1", "\n", "", "", "", "div1", "=", "len", "(", "types", "[", "0", "]", ".", "keys", "(", ")", ")", "/", "tokens", "[", "0", "]", "\n", "div2", "=", "len", "(", "types", "[", "1", "]", ".", "keys", "(", ")", ")", "/", "tokens", "[", "1", "]", "\n", "return", "[", "div1", ",", "div2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.nlp_metrics": [[135, 142], ["metrics.calc_nist_bleu", "metrics.calc_meteor", "metrics.calc_entropy", "metrics.calc_diversity", "metrics.calc_len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_nist_bleu", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_meteor", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_entropy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_diversity", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics.calc_len"], ["", "def", "nlp_metrics", "(", "path_refs", ",", "path_hyp", ",", "fld_out", "=", "'temp'", ",", "n_lines", "=", "None", ")", ":", "\n", "\t", "nist", ",", "bleu", "=", "calc_nist_bleu", "(", "path_refs", ",", "path_hyp", ",", "fld_out", ",", "n_lines", ")", "\n", "meteor", "=", "calc_meteor", "(", "path_refs", ",", "path_hyp", ",", "fld_out", ",", "n_lines", ")", "\n", "entropy", "=", "calc_entropy", "(", "path_hyp", ",", "n_lines", ")", "\n", "div", "=", "calc_diversity", "(", "path_hyp", ")", "\n", "avg_len", "=", "calc_len", "(", "path_hyp", ",", "n_lines", ")", "\n", "return", "nist", ",", "bleu", ",", "meteor", ",", "entropy", ",", "div", ",", "avg_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics._write_merged_refs": [[143, 155], ["lines.append", "open", "range", "len", "range", "line.strip", "len", "f.write", "open", "unicode"], "function", ["None"], ["", "def", "_write_merged_refs", "(", "paths_in", ",", "path_out", ",", "n_lines", "=", "None", ")", ":", "\n", "# prepare merged ref file for meteor-1.5.jar (calc_meteor)", "\n", "# lines[i][j] is the ref from i-th ref set for the j-th query", "\n", "\n", "\t", "lines", "=", "[", "]", "\n", "for", "path_in", "in", "paths_in", ":", "\n", "\t\t", "lines", ".", "append", "(", "[", "line", ".", "strip", "(", "'\\n'", ")", "for", "line", "in", "open", "(", "path_in", ",", "encoding", "=", "'utf-8'", ")", "]", ")", "\n", "\n", "", "with", "open", "(", "path_out", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "for", "j", "in", "range", "(", "len", "(", "lines", "[", "0", "]", ")", ")", ":", "\n", "\t\t\t", "for", "i", "in", "range", "(", "len", "(", "paths_in", ")", ")", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "unicode", "(", "lines", "[", "i", "]", "[", "j", "]", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.metrics._write_xml": [[156, 216], ["enumerate", "lines.append", "lines.append", "lines.append", "open", "f.write", "lines.append", "b.strip", "line.replace().replace.replace().replace", "lines.append", "lines.append", "unicode", "lines.append", "open", "f.readlines", "lines.append", "lines.append", "line.replace().replace.replace", "lines.append"], "function", ["None"], ["", "", "", "", "def", "_write_xml", "(", "paths_in", ",", "path_out", ",", "role", ",", "n_lines", "=", "None", ")", ":", "\n", "# prepare .xml files for mteval-v14c.pl (calc_nist_bleu)", "\n", "# role = 'src', 'hyp' or 'ref'", "\n", "\n", "\t", "lines", "=", "[", "\n", "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>'", ",", "\n", "'<!DOCTYPE mteval SYSTEM \"\">'", ",", "\n", "'<!-- generated by https://github.com/golsun/NLP-tools -->'", ",", "\n", "'<!-- from: %s -->'", "%", "paths_in", ",", "\n", "'<!-- as inputs for ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v14c.pl -->'", ",", "\n", "'<mteval>'", ",", "\n", "]", "\n", "\n", "for", "i_in", ",", "path_in", "in", "enumerate", "(", "paths_in", ")", ":", "\n", "\n", "# header ----", "\n", "\n", "\t\t", "if", "role", "==", "'src'", ":", "\n", "\t\t\t", "lines", ".", "append", "(", "'<srcset setid=\"unnamed\" srclang=\"src\">'", ")", "\n", "set_ending", "=", "'</srcset>'", "\n", "", "elif", "role", "==", "'hyp'", ":", "\n", "\t\t\t", "lines", ".", "append", "(", "'<tstset setid=\"unnamed\" srclang=\"src\" trglang=\"tgt\" sysid=\"unnamed\">'", ")", "\n", "set_ending", "=", "'</tstset>'", "\n", "", "elif", "role", "==", "'ref'", ":", "\n", "\t\t\t", "lines", ".", "append", "(", "'<refset setid=\"unnamed\" srclang=\"src\" trglang=\"tgt\" refid=\"ref%i\">'", "%", "i_in", ")", "\n", "set_ending", "=", "'</refset>'", "\n", "\n", "", "lines", ".", "append", "(", "'<doc docid=\"unnamed\" genre=\"unnamed\">'", ")", "\n", "\n", "# body -----", "\n", "\n", "if", "role", "==", "'src'", ":", "\n", "\t\t\t", "body", "=", "[", "'__src__'", "]", "*", "n_lines", "\n", "", "else", ":", "\n", "\t\t\t", "with", "open", "(", "path_in", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t\t\t", "body", "=", "f", ".", "readlines", "(", ")", "\n", "", "if", "n_lines", "is", "not", "None", ":", "\n", "\t\t\t\t", "body", "=", "body", "[", ":", "n_lines", "]", "\n", "#for i in range(len(body)):", "\n", "", "", "i", "=", "0", "\n", "for", "b", "in", "body", ":", "\n", "\t\t\t", "line", "=", "b", ".", "strip", "(", "'\\n'", ")", "\n", "line", "=", "line", ".", "replace", "(", "'&'", ",", "' '", ")", ".", "replace", "(", "'<'", ",", "' '", ")", "# remove illegal xml char", "\n", "# if len(line) > 0:", "\n", "lines", ".", "append", "(", "'<p><seg id=\"%i\"> %s </seg></p>'", "%", "(", "i", "+", "1", ",", "line", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "# ending -----", "\n", "\n", "", "lines", ".", "append", "(", "'</doc>'", ")", "\n", "if", "role", "==", "'src'", ":", "\n", "\t\t\t", "lines", ".", "append", "(", "'</srcset>'", ")", "\n", "", "elif", "role", "==", "'hyp'", ":", "\n", "\t\t\t", "lines", ".", "append", "(", "'</tstset>'", ")", "\n", "", "elif", "role", "==", "'ref'", ":", "\n", "\t\t\t", "lines", ".", "append", "(", "'</refset>'", ")", "\n", "\n", "", "", "lines", ".", "append", "(", "'</mteval>'", ")", "\n", "with", "open", "(", "path_out", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "unicode", "(", "'\\n'", ".", "join", "(", "lines", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval": [[9, 27], ["os.chdir", "print", "subprocess.run", "open", "out_f.write", "cmd.split", "sp.run.stdout.decode"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode"], ["def", "eval", "(", "prediction_path", ",", "output_path", ",", "data_type", ")", ":", "\n", "    ", "os", ".", "chdir", "(", "CODE_ROOT", ")", "\n", "ref_path", "=", "f'{CODE_ROOT}/data/test.refs.txt'", "\n", "key_path", "=", "f'{CODE_ROOT}/data/keys.2k.txt'", "\n", "cmd", "=", "[", "'dstc.py'", ",", "\n", "prediction_path", ",", "\n", "'--refs'", ",", "\n", "ref_path", ",", "\n", "'--keys'", ",", "\n", "key_path", ",", "\n", "'--clean'", "]", "\n", "cmd", "=", "\" \"", ".", "join", "(", "cmd", ")", "#% {\"CODE_ROOT\": CODE_ROOT}", "\n", "print", "(", "cmd", ")", "\n", "\n", "ret", "=", "sp", ".", "run", "(", "[", "PYTHON_EXE", "]", "+", "cmd", ".", "split", "(", "\" \"", ")", ",", "stdout", "=", "sp", ".", "PIPE", ",", "stderr", "=", "sp", ".", "STDOUT", ")", "\n", "\n", "with", "open", "(", "output_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "out_f", ":", "\n", "        ", "out_f", ".", "write", "(", "ret", ".", "stdout", ".", "decode", "(", "\"utf-8\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.tokenizers.clean_str": [[6, 44], ["txt.replace.lower", "re.sub", "re.sub", "txt.replace.split", "re.sub", "re.sub", "re.sub", "re.sub", "nltk.tokenize.TweetTokenizer", "txt.replace.replace", "txt.replace.replace", "re.sub", "re.sub", "re.sub", "word.find", "words.append", "txt.replace.replace", "word.strip", "nltk.tokenize.TweetTokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize"], ["def", "clean_str", "(", "txt", ")", ":", "\n", "#print(\"in=[%s]\" % txt)", "\n", "\t", "txt", "=", "txt", ".", "lower", "(", ")", "\n", "txt", "=", "re", ".", "sub", "(", "'^'", ",", "' '", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "'$'", ",", "' '", ",", "txt", ")", "\n", "\n", "# url and tag", "\n", "words", "=", "[", "]", "\n", "for", "word", "in", "txt", ".", "split", "(", ")", ":", "\n", "\t\t", "i", "=", "word", ".", "find", "(", "'http'", ")", "\n", "if", "i", ">=", "0", ":", "\n", "\t\t\t", "word", "=", "word", "[", ":", "i", "]", "+", "' '", "+", "'__url__'", "\n", "", "words", ".", "append", "(", "word", ".", "strip", "(", ")", ")", "\n", "", "txt", "=", "' '", ".", "join", "(", "words", ")", "\n", "\n", "# remove markdown URL", "\n", "txt", "=", "re", ".", "sub", "(", "r'\\[([^\\]]*)\\] \\( *__url__ *\\)'", ",", "r'\\1'", ",", "txt", ")", "\n", "\n", "# remove illegal char", "\n", "txt", "=", "re", ".", "sub", "(", "'__url__'", ",", "'URL'", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "r\"[^A-Za-z0-9():,.!?\\\"\\']\"", ",", "\" \"", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "'URL'", ",", "'__url__'", ",", "txt", ")", "\n", "\n", "# contraction", "\n", "add_space", "=", "[", "\"'s\"", ",", "\"'m\"", ",", "\"'re\"", ",", "\"n't\"", ",", "\"'ll\"", ",", "\"'ve\"", ",", "\"'d\"", ",", "\"'em\"", "]", "\n", "tokenizer", "=", "TweetTokenizer", "(", "preserve_case", "=", "False", ")", "\n", "txt", "=", "' '", "+", "' '", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "txt", ")", ")", "+", "' '", "\n", "txt", "=", "txt", ".", "replace", "(", "\" won't \"", ",", "\" will n't \"", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\" can't \"", ",", "\" can n't \"", ")", "\n", "for", "a", "in", "add_space", ":", "\n", "\t\t", "txt", "=", "txt", ".", "replace", "(", "a", "+", "' '", ",", "' '", "+", "a", "+", "' '", ")", "\n", "\n", "", "txt", "=", "re", ".", "sub", "(", "r'^\\s+'", ",", "''", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "r'\\s+$'", ",", "''", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "txt", ")", "# remove extra spaces", "\n", "\n", "#print(\"out=[%s]\" % txt)", "\n", "return", "txt", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.util.makedirs": [[10, 13], ["os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs"], ["", "def", "makedirs", "(", "fld", ")", ":", "\n", "\t", "if", "not", "os", ".", "path", ".", "exists", "(", "fld", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "fld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.util.str2bool": [[14, 22], ["s.lower", "s.lower"], "function", ["None"], ["", "", "def", "str2bool", "(", "s", ")", ":", "\n", "# to avoid issue like this: https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse", "\n", "\t", "if", "s", ".", "lower", "(", ")", "in", "[", "'t'", ",", "'true'", ",", "'1'", ",", "'y'", "]", ":", "\n", "\t\t", "return", "True", "\n", "", "elif", "s", ".", "lower", "(", ")", "in", "[", "'f'", ",", "'false'", ",", "'0'", ",", "'n'", "]", ":", "\n", "\t\t", "return", "False", "\n", "", "else", ":", "\n", "\t\t", "raise", "ValueError", "", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.AttentionFP16.__init__": [[18, 20], ["pytorch_pretrained_bert.modeling_gpt2.Attention.__init__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "AttentionFP16", ",", "self", ")", ".", "__init__", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.AttentionFP16._attn": [[21, 31], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size", "torch.Softmax", "torch.Softmax", "math.sqrt", "v.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "return", "torch", ".", "matmul", "(", "w", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.BlockFP16.__init__": [[33, 40], ["pytorch_pretrained_bert.modeling_gpt2.Block.__init__", "pytorch_pretrained_bert.modeling_gpt2.LayerNorm", "modeling_gpt2.AttentionFP16", "pytorch_pretrained_bert.modeling_gpt2.LayerNorm", "pytorch_pretrained_bert.modeling_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "BlockFP16", ",", "self", ")", ".", "__init__", "(", "n_ctx", ",", "config", ",", "scale", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "AttentionFP16", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.GPT2ModelFP16.__init__": [[42, 51], ["pytorch_pretrained_bert.modeling_gpt2.GPT2Model.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_gpt2.BlockFP16", "torch.ModuleList", "torch.ModuleList", "pytorch_pretrained_bert.modeling_gpt2.LayerNorm", "modeling_gpt2.GPT2ModelFP16.apply", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2ModelFP16", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "block", "=", "BlockFP16", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "block", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.GPT2LMHeadModel.__init__": [[53, 58], ["pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2ModelFP16", "pytorch_pretrained_bert.modeling_gpt2.GPT2LMHead", "modeling_gpt2.GPT2LMHeadModel.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2ModelFP16", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "GPT2LMHead", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ",", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.GPT2LMHeadModel.set_tied": [[59, 63], ["modeling_gpt2.GPT2LMHeadModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["", "def", "set_tied", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.GPT2LMHeadModel.forward": [[64, 80], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "loss1.view.view.view", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "modeling_gpt2.GPT2LMHeadModel.view", "lm_labels.view", "lm_labels.size", "lm_labels.size", "loss1.view.view.type", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "modeling_gpt2.GPT2LMHeadModel.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum().float", "torch.sum().float", "torch.sum().float", "torch.sum().float", "torch.sum().type.float", "torch.sum().type.float", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "past", "=", "None", ")", ":", "\n", "        ", "hidden_states", ",", "presents", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "past", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "\n", "            ", "loss_fct1", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n", "loss1", "=", "loss_fct1", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "loss1", "=", "loss1", ".", "view", "(", "lm_labels", ".", "size", "(", "0", ")", ",", "lm_labels", ".", "size", "(", "1", ")", ")", "\n", "label_size", "=", "torch", ".", "sum", "(", "lm_labels", "!=", "-", "1", ",", "dim", "=", "1", ")", ".", "type", "(", "loss1", ".", "type", "(", ")", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "loss1", ")", "/", "torch", ".", "sum", "(", "label_size", ")", "\n", "ppl", "=", "torch", ".", "exp", "(", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "loss1", ",", "dim", "=", "1", ")", ".", "float", "(", ")", "\n", "/", "label_size", ".", "float", "(", ")", ")", ")", "\n", "\n", "return", "loss", ",", "ppl", "\n", "", "return", "lm_logits", ",", "presents", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.modeling_gpt2.GPT2LMHeadModel.forward_pointwise": [[81, 97], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "loss1.view.view.view", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "modeling_gpt2.GPT2LMHeadModel.view", "lm_labels.view", "lm_labels.size", "lm_labels.size", "loss1.view.view.type", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "modeling_gpt2.GPT2LMHeadModel.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward_pointwise", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "past", "=", "None", ")", ":", "\n", "        ", "hidden_states", ",", "presents", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "past", ")", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "\n", "            ", "loss_fct1", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n", "loss1", "=", "loss_fct1", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "loss1", "=", "loss1", ".", "view", "(", "lm_labels", ".", "size", "(", "0", ")", ",", "lm_labels", ".", "size", "(", "1", ")", ")", "\n", "label_size", "=", "torch", ".", "sum", "(", "lm_labels", "!=", "-", "1", ",", "dim", "=", "1", ")", ".", "type", "(", "loss1", ".", "type", "(", ")", ")", "\n", "loss1", "=", "torch", ".", "sum", "(", "loss1", ",", "dim", "=", "1", ")", "/", "label_size", "\n", "ppl1", "=", "torch", ".", "exp", "(", "loss1", ")", "\n", "\n", "return", "loss1", ",", "ppl1", "\n", "", "return", "lm_logits", ",", "presents", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adam.__init__": [[70, 89], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay_rate", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "not", "lr", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay_rate", "=", "weight_decay_rate", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "Adam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adam.get_lr": [[90, 104], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adam.to": [[105, 110], ["optim.Adam.state.values", "state[].to", "state[].to"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "\"\"\" Move the optimizer state to a specified device\"\"\"", "\n", "for", "state", "in", "self", ".", "state", ".", "values", "(", ")", ":", "\n", "            ", "state", "[", "'exp_avg'", "]", ".", "to", "(", "device", ")", "\n", "state", "[", "'exp_avg_sq'", "]", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adam.initialize_step": [[111, 125], ["torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "", "def", "initialize_step", "(", "self", ",", "initial_step", ")", ":", "\n", "        ", "\"\"\"Initialize state with a defined step (but we don't have stored averaged).\n        Arguments:\n            initial_step (int): Initial step number.\n        \"\"\"", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "state", "[", "'step'", "]", "=", "initial_step", "\n", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adam.step": [[126, 179], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct"], "methods", ["None"], ["", "", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "if", "group", "[", "'weight_decay_rate'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay_rate'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.__init__": [[194, 213], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "weight_decay_rate", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "not", "lr", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay_rate", "=", "weight_decay_rate", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "Adamax", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.get_lr": [[214, 228], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to": [[229, 234], ["optim.Adamax.state.values", "state[].to", "state[].to"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "\"\"\" Move the optimizer state to a specified device\"\"\"", "\n", "for", "state", "in", "self", ".", "state", ".", "values", "(", ")", ":", "\n", "            ", "state", "[", "'exp_avg'", "]", ".", "to", "(", "device", ")", "\n", "state", "[", "'exp_avg_sq'", "]", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.initialize_step": [[235, 249], ["torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "", "def", "initialize_step", "(", "self", ",", "initial_step", ")", ":", "\n", "        ", "\"\"\"Initialize state with a defined step (but we don't have stored averaged).\n        Arguments:\n            initial_step (int): Initial step number.\n        \"\"\"", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "state", "[", "'step'", "]", "=", "initial_step", "\n", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.step": [[250, 317], ["closure", "exp_avg.mul_().add_", "torch.cat", "torch.max", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "exp_avg.mul_", "exp_inf.mul_().unsqueeze", "grad.abs().add_().unsqueeze_", "schedule_fct", "schedule_fct", "exp_inf.new().long", "exp_inf.mul_", "grad.abs().add_", "exp_inf.new", "grad.abs"], "methods", ["None"], ["", "", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "state", "[", "'exp_inf'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_inf", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_inf'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "eps", "=", "group", "[", "'eps'", "]", "\n", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "norm_buf", "=", "torch", ".", "cat", "(", "[", "\n", "exp_inf", ".", "mul_", "(", "beta2", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "grad", ".", "abs", "(", ")", ".", "add_", "(", "eps", ")", ".", "unsqueeze_", "(", "0", ")", "\n", "]", ",", "0", ")", "\n", "torch", ".", "max", "(", "norm_buf", ",", "0", ",", "keepdim", "=", "False", ",", "out", "=", "(", "exp_inf", ",", "exp_inf", ".", "new", "(", ")", ".", "long", "(", ")", ")", ")", "\n", "update", "=", "exp_avg", "/", "(", "exp_inf", "+", "eps", ")", "\n", "\n", "if", "group", "[", "'weight_decay_rate'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay_rate'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "if", "group", "[", "'weight_decay_rate'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay_rate'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.warmup_cosine": [[8, 12], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "0.5", "*", "(", "1.0", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.warmup_constant": [[13, 17], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.warmup_linear": [[18, 22], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "(", "1.0", "-", "x", ")", "/", "(", "1.0", "-", "warmup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.noam_decay": [[23, 30], ["min"], "function", ["None"], ["", "def", "noam_decay", "(", "step", ",", "warmup_steps", ",", "model_size", ")", ":", "\n", "    ", "\"\"\"Learning rate schedule described in\n    https://arxiv.org/pdf/1706.03762.pdf.\n    \"\"\"", "\n", "return", "(", "\n", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.noamwd_decay": [[31, 39], ["min", "max"], "function", ["None"], ["", "def", "noamwd_decay", "(", "step", ",", "warmup_steps", ",", "\n", "model_size", ",", "rate", "=", "0.5", ",", "decay_steps", "=", "1000", ",", "start_step", "=", "500", ")", ":", "\n", "    ", "\"\"\"Learning rate schedule optimized for huge batches\n    \"\"\"", "\n", "return", "(", "\n", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "warmup_steps", "**", "(", "-", "1.5", ")", ")", "*", "\n", "rate", "**", "(", "max", "(", "step", "-", "start_step", "+", "decay_steps", ",", "0", ")", "//", "decay_steps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.exponential_decay": [[40, 45], ["max"], "function", ["None"], ["", "def", "exponential_decay", "(", "step", ",", "rate", ",", "decay_steps", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "\"\"\"A standard exponential decay, scaling the learning rate by :obj:`rate`\n    every :obj:`decay_steps` steps.\n    \"\"\"", "\n", "return", "rate", "**", "(", "max", "(", "step", "-", "start_step", "+", "decay_steps", ",", "0", ")", "//", "decay_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.rsqrt_decay": [[46, 49], ["math.sqrt", "max"], "function", ["None"], ["", "def", "rsqrt_decay", "(", "step", ",", "warmup_steps", ")", ":", "\n", "    ", "\"\"\"Decay based on the reciprocal of the step square root.\"\"\"", "\n", "return", "1.0", "/", "math", ".", "sqrt", "(", "max", "(", "step", ",", "warmup_steps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained": [[56, 91], ["cls", "torch.load", "torch.load.items", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "logger.error", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path"], ["@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a TransfoXLTokenizer.\n        The TransfoXLTokenizer.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "vocab_dict", "=", "torch", ".", "load", "(", "resolved_vocab_file", ")", "\n", "for", "key", ",", "value", "in", "vocab_dict", ".", "items", "(", ")", ":", "\n", "            ", "tokenizer", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.__init__": [[92, 102], ["collections.Counter"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "special", "=", "[", "]", ",", "min_freq", "=", "0", ",", "max_size", "=", "None", ",", "lower_case", "=", "False", ",", "\n", "delimiter", "=", "None", ",", "vocab_file", "=", "None", ",", "never_split", "=", "(", "\"<unk>\"", ",", "\"<eos>\"", ",", "\"<formula>\"", ")", ")", ":", "\n", "        ", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "special", "=", "special", "\n", "self", ".", "min_freq", "=", "min_freq", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "lower_case", "=", "lower_case", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file": [[103, 117], ["os.path.exists", "print", "io.open", "enumerate", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "sents.append", "print"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize"], ["", "def", "count_file", "(", "self", ",", "path", ",", "verbose", "=", "False", ",", "add_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "print", "(", "'counting file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "\n", "sents", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ")", "\n", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "sents", ".", "append", "(", "symbols", ")", "\n", "\n", "", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_sents": [[118, 127], ["enumerate", "print", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "print", "len"], "methods", ["None"], ["", "def", "count_sents", "(", "self", ",", "sents", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            sents : a list of sentences, each a list of tokenized symbols\n        \"\"\"", "\n", "if", "verbose", ":", "print", "(", "'counting {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file": [[128, 142], ["collections.OrderedDict", "io.open", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "ValueError", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "", "def", "_build_from_file", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "symb", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "self", ".", "add_symbol", "(", "symb", ")", "\n", "", "", "if", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'No <unkown> token in vocabulary'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab": [[143, 163], ["print", "tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "print", "print", "collections.OrderedDict", "tokenization_transfo_xl.TransfoXLTokenizer.counter.most_common", "print", "tokenization_transfo_xl.TransfoXLTokenizer.add_special", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_special", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "", "def", "build_vocab", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "vocab_file", ":", "\n", "            ", "print", "(", "'building vocab from {}'", ".", "format", "(", "self", ".", "vocab_file", ")", ")", "\n", "self", ".", "_build_from_file", "(", "self", ".", "vocab_file", ")", "\n", "print", "(", "'final vocab size {}'", ".", "format", "(", "len", "(", "self", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'building vocab with min_freq={}, max_size={}'", ".", "format", "(", "\n", "self", ".", "min_freq", ",", "self", ".", "max_size", ")", ")", "\n", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "sym", "in", "self", ".", "special", ":", "\n", "                ", "self", ".", "add_special", "(", "sym", ")", "\n", "\n", "", "for", "sym", ",", "cnt", "in", "self", ".", "counter", ".", "most_common", "(", "self", ".", "max_size", ")", ":", "\n", "                ", "if", "cnt", "<", "self", ".", "min_freq", ":", "break", "\n", "self", ".", "add_symbol", "(", "sym", ")", "\n", "\n", "", "print", "(", "'final vocab size {} from {} unique tokens'", ".", "format", "(", "\n", "len", "(", "self", ")", ",", "len", "(", "self", ".", "counter", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file": [[164, 181], ["os.path.exists", "print", "io.open", "enumerate", "torch.cat", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "torch.cat.append", "print", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "", "def", "encode_file", "(", "self", ",", "path", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ",", "add_eos", "=", "True", ",", "\n", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "print", "(", "'encoding file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "encoded", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ",", "\n", "add_double_eos", "=", "add_double_eos", ")", "\n", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_sents": [[182, 194], ["enumerate", "print", "torch.cat.append", "torch.cat", "print", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "def", "encode_sents", "(", "self", ",", "sents", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "print", "(", "'encoding {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "encoded", "=", "[", "]", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_special": [[195, 200], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "setattr", "len", "sym.strip"], "methods", ["None"], ["", "def", "add_special", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "setattr", "(", "self", ",", "'{}_idx'", ".", "format", "(", "sym", ".", "strip", "(", "'<>'", ")", ")", ",", "self", ".", "sym2idx", "[", "sym", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol": [[201, 205], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "len"], "methods", ["None"], ["", "", "def", "add_symbol", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym": [[206, 209], ["len"], "methods", ["None"], ["", "", "def", "get_sym", "(", "self", ",", "idx", ")", ":", "\n", "        ", "assert", "0", "<=", "idx", "<", "len", "(", "self", ")", ",", "'Index {} out of vocabulary range'", ".", "format", "(", "idx", ")", "\n", "return", "self", ".", "idx2sym", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_idx": [[210, 225], ["hasattr", "tokenization_transfo_xl.TransfoXLTokenizer.sym2idx.get", "ValueError"], "methods", ["None"], ["", "def", "get_idx", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "in", "self", ".", "sym2idx", ":", "\n", "            ", "return", "self", ".", "sym2idx", "[", "sym", "]", "\n", "", "else", ":", "\n", "# print('encounter unk {}'.format(sym))", "\n", "# assert '<eos>' not in sym", "\n", "            ", "if", "hasattr", "(", "self", ",", "'unk_idx'", ")", ":", "\n", "                ", "return", "self", ".", "sym2idx", ".", "get", "(", "sym", ",", "self", ".", "unk_idx", ")", "\n", "# Backward compatibility with pre-trained models", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "elif", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Token not in vocabulary and no <unk> token in vocabulary for replacement'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_ids_to_tokens": [[226, 229], ["tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], ["", "", "", "def", "convert_ids_to_tokens", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of indices in symbols using the vocab.\"\"\"", "\n", "return", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids": [[230, 233], ["tokenization_transfo_xl.TransfoXLTokenizer.get_idx"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_idx"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of symbols into ids using the vocab.\"\"\"", "\n", "return", "[", "self", ".", "get_idx", "(", "sym", ")", "for", "sym", "in", "symbols", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor": [[234, 236], ["torch.LongTensor", "tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_ids"], ["", "def", "convert_to_tensor", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "self", ".", "convert_tokens_to_ids", "(", "symbols", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.decode": [[237, 243], ["tokenization_transfo_xl.TransfoXLTokenizer.get_sym", "tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], ["", "def", "decode", "(", "self", ",", "indices", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of indices in a string.\"\"\"", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "return", "' '", ".", "join", "(", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "' '", ".", "join", "(", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "if", "idx", "not", "in", "exclude", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.__len__": [[244, 246], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2sym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._run_split_on_punc": [[247, 268], ["list", "len", "tokenization_transfo_xl._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "text", "in", "self", ".", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._run_strip_accents": [[269, 279], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._clean_text": [[280, 292], ["ord", "tokenization_transfo_xl._is_whitespace", "tokenization_transfo_xl._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.whitespace_tokenize": [[293, 303], ["text.strip.strip.strip", "text.strip.strip.split"], "methods", ["None"], ["", "def", "whitespace_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "self", ".", "delimiter", "==", "''", ":", "\n", "            ", "tokens", "=", "text", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "text", ".", "split", "(", "self", ".", "delimiter", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.tokenize": [[304, 323], ["tokenization_transfo_xl.TransfoXLTokenizer._clean_text", "line.strip.strip.strip", "tokenization_transfo_xl.TransfoXLTokenizer.whitespace_tokenize", "split_symbols.extend", "tokenization_transfo_xl.TransfoXLTokenizer.lower", "tokenization_transfo_xl.TransfoXLTokenizer._run_strip_accents", "tokenization_transfo_xl.TransfoXLTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "line", ",", "add_eos", "=", "False", ",", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "line", "=", "self", ".", "_clean_text", "(", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "\n", "symbols", "=", "self", ".", "whitespace_tokenize", "(", "line", ")", "\n", "\n", "split_symbols", "=", "[", "]", "\n", "for", "symbol", "in", "symbols", ":", "\n", "            ", "if", "self", ".", "lower_case", "and", "symbol", "not", "in", "self", ".", "never_split", ":", "\n", "                ", "symbol", "=", "symbol", ".", "lower", "(", ")", "\n", "symbol", "=", "self", ".", "_run_strip_accents", "(", "symbol", ")", "\n", "", "split_symbols", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "symbol", ")", ")", "\n", "\n", "", "if", "add_double_eos", ":", "# lm1b", "\n", "            ", "return", "[", "'<S>'", "]", "+", "split_symbols", "+", "[", "'<S>'", "]", "\n", "", "elif", "add_eos", ":", "\n", "            ", "return", "split_symbols", "+", "[", "'<eos>'", "]", "\n", "", "else", ":", "\n", "            ", "return", "split_symbols", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.__init__": [[325, 346], ["data.narrow.narrow.narrow", "data.narrow.narrow.view().t().contiguous().to", "data.narrow.narrow.size", "data.narrow.narrow.view().t().contiguous", "data.narrow.narrow.view().t", "data.narrow.narrow.view"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            data -- LongTensor -- the LongTensor is strictly ordered\n        \"\"\"", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "self", ".", "n_step", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "self", ".", "n_step", "*", "bsz", ")", "\n", "\n", "# Evenly divide the data across the bsz batches.", "\n", "self", ".", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Number of mini-batches", "\n", "self", ".", "n_batch", "=", "(", "self", ".", "n_step", "+", "self", ".", "bptt", "-", "1", ")", "//", "self", ".", "bptt", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_batch": [[347, 361], ["min", "max", "data.transpose().contiguous().to", "target.transpose().contiguous().to", "data.transpose().contiguous", "target.transpose().contiguous", "tokenization_transfo_xl.LMOrderedIterator.data.size", "data.transpose", "target.transpose"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "get_batch", "(", "self", ",", "i", ",", "bptt", "=", "None", ")", ":", "\n", "        ", "if", "bptt", "is", "None", ":", "bptt", "=", "self", ".", "bptt", "\n", "seq_len", "=", "min", "(", "bptt", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", "-", "i", ")", "\n", "\n", "end_idx", "=", "i", "+", "seq_len", "\n", "beg_idx", "=", "max", "(", "0", ",", "i", "-", "self", ".", "ext_len", ")", "\n", "\n", "data", "=", "self", ".", "data", "[", "beg_idx", ":", "end_idx", "]", "\n", "target", "=", "self", ".", "data", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", "\n", "\n", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "data_out", ",", "target_out", ",", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter": [[362, 365], ["range", "tokenization_transfo_xl.LMOrderedIterator.data.size", "tokenization_transfo_xl.LMOrderedIterator.get_batch"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "def", "get_fixlen_iter", "(", "self", ",", "start", "=", "0", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "start", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "self", ".", "bptt", ")", ":", "\n", "            ", "yield", "self", ".", "get_batch", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_varlen_iter": [[366, 377], ["min", "tokenization_transfo_xl.LMOrderedIterator.get_batch", "max", "numpy.random.random", "int", "tokenization_transfo_xl.LMOrderedIterator.data.size", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_batch", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "def", "get_varlen_iter", "(", "self", ",", "start", "=", "0", ",", "std", "=", "5", ",", "min_len", "=", "5", ",", "max_deviation", "=", "3", ")", ":", "\n", "        ", "max_len", "=", "self", ".", "bptt", "+", "max_deviation", "*", "std", "\n", "i", "=", "start", "\n", "while", "True", ":", "\n", "            ", "bptt", "=", "self", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "self", ".", "bptt", "/", "2.", "\n", "bptt", "=", "min", "(", "max_len", ",", "max", "(", "min_len", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "std", ")", ")", ")", ")", "\n", "data", ",", "target", ",", "seq_len", "=", "self", ".", "get_batch", "(", "i", ",", "bptt", ")", "\n", "i", "+=", "seq_len", "\n", "yield", "data", ",", "target", ",", "seq_len", "\n", "if", "i", ">=", "self", ".", "data", ".", "size", "(", "0", ")", "-", "2", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.__iter__": [[378, 380], ["tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_fixlen_iter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.__init__": [[382, 394], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            data -- list[LongTensor] -- there is no order among the LongTensors\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.get_sent_stream": [[395, 403], ["numpy.random.permutation", "numpy.array", "len", "range", "len"], "methods", ["None"], ["", "def", "get_sent_stream", "(", "self", ")", ":", "\n", "# index iterator", "\n", "        ", "epoch_indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "data", ")", ")", "if", "self", ".", "shuffle", "else", "np", ".", "array", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n", "# sentence iterator", "\n", "for", "idx", "in", "epoch_indices", ":", "\n", "            ", "yield", "self", ".", "data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.stream_iterator": [[404, 452], ["torch.LongTensor", "torch.LongTensor", "data[].fill_", "torch.LongTensor.fill_", "range", "torch.LongTensor.transpose().contiguous().to", "torch.LongTensor.transpose().contiguous().to", "min", "torch.LongTensor.resize_", "torch.LongTensor.size", "torch.LongTensor.size", "torch.LongTensor.transpose().contiguous", "torch.LongTensor.transpose().contiguous", "min", "next", "torch.LongTensor.transpose", "torch.LongTensor.transpose", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "def", "stream_iterator", "(", "self", ",", "sent_stream", ")", ":", "\n", "# streams for each data in the batch", "\n", "        ", "streams", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "\n", "data", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "\n", "n_retain", "=", "0", "\n", "\n", "while", "True", ":", "\n", "# data   : [n_retain+bptt x bsz]", "\n", "# target : [bptt x bsz]", "\n", "            ", "data", "[", "n_retain", ":", "]", ".", "fill_", "(", "-", "1", ")", "\n", "target", ".", "fill_", "(", "-", "1", ")", "\n", "\n", "valid_batch", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "bsz", ")", ":", "\n", "                ", "n_filled", "=", "0", "\n", "try", ":", "\n", "                    ", "while", "n_filled", "<", "self", ".", "bptt", ":", "\n", "                        ", "if", "streams", "[", "i", "]", "is", "None", "or", "len", "(", "streams", "[", "i", "]", ")", "<=", "1", ":", "\n", "                            ", "streams", "[", "i", "]", "=", "next", "(", "sent_stream", ")", "\n", "# number of new tokens to fill in", "\n", "", "n_new", "=", "min", "(", "len", "(", "streams", "[", "i", "]", ")", "-", "1", ",", "self", ".", "bptt", "-", "n_filled", ")", "\n", "# first n_retain tokens are retained from last batch", "\n", "data", "[", "n_retain", "+", "n_filled", ":", "n_retain", "+", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", ":", "n_new", "]", "\n", "target", "[", "n_filled", ":", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", "1", ":", "n_new", "+", "1", "]", "\n", "streams", "[", "i", "]", "=", "streams", "[", "i", "]", "[", "n_new", ":", "]", "\n", "n_filled", "+=", "n_new", "\n", "", "", "except", "StopIteration", ":", "\n", "                    ", "valid_batch", "=", "False", "\n", "break", "\n", "\n", "", "", "if", "not", "valid_batch", ":", "\n", "                ", "return", "\n", "\n", "", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "yield", "data_out", ",", "target_out", ",", "self", ".", "bptt", "\n", "\n", "n_retain", "=", "min", "(", "data", ".", "size", "(", "0", ")", ",", "self", ".", "ext_len", ")", "\n", "if", "n_retain", ">", "0", ":", "\n", "                ", "data", "[", ":", "n_retain", "]", "=", "data", "[", "-", "n_retain", ":", "]", "\n", "", "data", ".", "resize_", "(", "n_retain", "+", "self", ".", "bptt", ",", "data", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.__iter__": [[453, 459], ["tokenization_transfo_xl.LMShuffledIterator.get_sent_stream", "tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "# sent_stream is an iterator", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.__init__": [[461, 473], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "paths", ",", "vocab", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "\n", "shuffle", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "paths", "=", "paths", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream": [[474, 481], ["tokenization_transfo_xl.LMMultiFileIterator.vocab.encode_file", "iter", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "get_sent_stream", "(", "self", ",", "path", ")", ":", "\n", "        ", "sents", "=", "self", ".", "vocab", ".", "encode_file", "(", "path", ",", "add_double_eos", "=", "True", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "sents", ")", "\n", "", "sent_stream", "=", "iter", "(", "sents", ")", "\n", "\n", "return", "sent_stream", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.__iter__": [[482, 491], ["numpy.random.shuffle", "tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "tokenization_transfo_xl.LMMultiFileIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "paths", ")", "\n", "\n", "", "for", "path", "in", "self", ".", "paths", ":", "\n", "# sent_stream is an iterator", "\n", "            ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", "path", ")", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "                ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.from_pretrained": [[493, 535], ["tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained", "cls", "torch.load", "torch.load.items", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "logger.error", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path"], ["    ", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a pre-processed corpus.\n        \"\"\"", "\n", "vocab", "=", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_CORPUS_ARCHIVE_MAP", ":", "\n", "            ", "corpus_file", "=", "PRETRAINED_CORPUS_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "corpus_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CORPUS_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_corpus_file", "=", "cached_path", "(", "corpus_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Corpus '{}' was not found in corpus list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "corpus_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_corpus_file", "==", "corpus_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {}\"", ".", "format", "(", "corpus_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {} from cache at {}\"", ".", "format", "(", "\n", "corpus_file", ",", "resolved_corpus_file", ")", ")", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "corpus", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "corpus_dict", "=", "torch", ".", "load", "(", "resolved_corpus_file", ")", "\n", "for", "key", ",", "value", "in", "corpus_dict", ".", "items", "(", ")", ":", "\n", "            ", "corpus", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "corpus", ".", "vocab", "=", "vocab", "\n", "if", "corpus", ".", "train", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "train", "=", "torch", ".", "tensor", "(", "corpus", ".", "train", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "valid", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "valid", "=", "torch", ".", "tensor", "(", "corpus", ".", "valid", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "test", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "test", "=", "torch", ".", "tensor", "(", "corpus", ".", "test", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.__init__": [[536, 542], ["tokenization_transfo_xl.TransfoXLTokenizer"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "TransfoXLTokenizer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "train", "=", "None", "\n", "self", ".", "valid", "=", "None", "\n", "self", ".", "test", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.build_corpus": [[543, 581], ["tokenization_transfo_xl.TransfoXLCorpus.vocab.build_vocab", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "glob.glob", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "build_corpus", "(", "self", ",", "path", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'wt103'", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "train_path_pattern", "=", "os", ".", "path", ".", "join", "(", "\n", "path", ",", "'1-billion-word-language-modeling-benchmark-r13output'", ",", "\n", "'training-monolingual.tokenized.shuffled'", ",", "'news.en-*'", ")", "\n", "train_paths", "=", "glob", ".", "glob", "(", "train_path_pattern", ")", "\n", "# the vocab will load from file when build_vocab() is called", "\n", "\n", "", "self", ".", "vocab", ".", "build_vocab", "(", ")", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "", "elif", "self", ".", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "self", ".", "train", "=", "train_paths", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.get_iterator": [[582, 597], ["tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMMultiFileIterator", "tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMShuffledIterator"], "methods", ["None"], ["", "", "def", "get_iterator", "(", "self", ",", "split", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "self", ".", "train", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "kwargs", "[", "'shuffle'", "]", "=", "True", "\n", "data_iter", "=", "LMMultiFileIterator", "(", "self", ".", "train", ",", "self", ".", "vocab", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "elif", "split", "in", "[", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "data", "=", "self", ".", "valid", "if", "split", "==", "'valid'", "else", "self", ".", "test", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "data_iter", "=", "LMShuffledIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "data_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl.get_lm_corpus": [[598, 628], ["os.path.join", "os.path.join", "os.path.exists", "print", "torch.load", "os.path.exists", "print", "print", "tokenization_transfo_xl.TransfoXLCorpus", "torch.save", "io.open", "pickle.load", "os.path.join"], "function", ["None"], ["", "", "def", "get_lm_corpus", "(", "datadir", ",", "dataset", ")", ":", "\n", "    ", "fn", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pt'", ")", "\n", "fn_pickle", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "print", "(", "'Loading cached dataset...'", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "fn_pickle", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "print", "(", "'Loading cached dataset from pickle...'", ")", "\n", "with", "open", "(", "fn", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'Producing dataset {}...'", ".", "format", "(", "dataset", ")", ")", "\n", "kwargs", "=", "{", "}", "\n", "if", "dataset", "in", "[", "'wt103'", ",", "'wt2'", "]", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "", "elif", "dataset", "==", "'ptb'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "True", "\n", "", "elif", "dataset", "==", "'lm1b'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "kwargs", "[", "'vocab_file'", "]", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'1b_word_vocab.txt'", ")", "\n", "", "elif", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "pass", "\n", "\n", "", "corpus", "=", "TransfoXLCorpus", "(", "datadir", ",", "dataset", ",", "**", "kwargs", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "fn", ")", "\n", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl._is_whitespace": [[629, 639], ["unicodedata.category"], "function", ["None"], ["", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl._is_control": [[640, 650], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_transfo_xl._is_punctuation": [[651, 665], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertConfig.__init__": [[128, 184], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs BertConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `BertModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertConfig.from_dict": [[186, 193], ["modeling.BertConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "BertConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertConfig.from_json_file": [[194, 200], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertConfig.__repr__": [[201, 203], ["str", "modeling.BertConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertConfig.to_dict": [[204, 208], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertConfig.to_json_string": [[209, 212], ["json.dumps", "modeling.BertConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertLayerNorm.__init__": [[218, 225], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "eps", "=", "1e-12", ")", ":", "\n", "        ", "\"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n        \"\"\"", "\n", "super", "(", "BertLayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "hidden_size", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "hidden_size", ")", ")", "\n", "self", ".", "variance_epsilon", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertLayerNorm.forward": [[226, 231], ["x.mean", "torch.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "u", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "s", "=", "(", "x", "-", "u", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "u", ")", "/", "torch", ".", "sqrt", "(", "s", "+", "self", ".", "variance_epsilon", ")", "\n", "return", "self", ".", "weight", "*", "x", "+", "self", ".", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertEmbeddings.__init__": [[235, 245], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "modeling.BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertEmbeddings.forward": [[246, 261], ["input_ids.size", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling.BertEmbeddings.word_embeddings", "modeling.BertEmbeddings.position_embeddings", "modeling.BertEmbeddings.token_type_embeddings", "modeling.BertEmbeddings.LayerNorm", "modeling.BertEmbeddings.dropout", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfAttention.__init__": [[263, 278], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores": [[279, 283], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfAttention.forward": [[284, 311], ["modeling.BertSelfAttention.query", "modeling.BertSelfAttention.key", "modeling.BertSelfAttention.value", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfOutput.__init__": [[313, 318], ["torch.nn.Module.__init__", "torch.nn.Linear", "modeling.BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertSelfOutput.forward": [[319, 324], ["modeling.BertSelfOutput.dense", "modeling.BertSelfOutput.dropout", "modeling.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertAttention.__init__": [[326, 330], ["torch.nn.Module.__init__", "modeling.BertSelfAttention", "modeling.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertAttention.forward": [[331, 335], ["modeling.BertAttention.self", "modeling.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ")", ":", "\n", "        ", "self_output", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_output", ",", "input_tensor", ")", "\n", "return", "attention_output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertIntermediate.__init__": [[337, 344], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertIntermediate.forward": [[345, 349], ["modeling.BertIntermediate.dense", "modeling.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertOutput.__init__": [[351, 356], ["torch.nn.Module.__init__", "torch.nn.Linear", "modeling.BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertOutput.forward": [[357, 362], ["modeling.BertOutput.dense", "modeling.BertOutput.dropout", "modeling.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertLayer.__init__": [[364, 369], ["torch.nn.Module.__init__", "modeling.BertAttention", "modeling.BertIntermediate", "modeling.BertOutput"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertLayer.forward": [[370, 375], ["modeling.BertLayer.attention", "modeling.BertLayer.intermediate", "modeling.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ")", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertEncoder.__init__": [[377, 381], ["torch.nn.Module.__init__", "modeling.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "BertLayer", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertEncoder.forward": [[382, 391], ["layer_module", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ")", "\n", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPooler.__init__": [[393, 397], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPooler.forward": [[398, 405], ["modeling.BertPooler.dense", "modeling.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.__init__": [[407, 415], ["torch.nn.Module.__init__", "torch.nn.Linear", "modeling.BertLayerNorm", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.forward": [[416, 421], ["modeling.BertPredictionHeadTransform.dense", "modeling.BertPredictionHeadTransform.transform_act_fn", "modeling.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertLMPredictionHead.__init__": [[423, 434], ["torch.nn.Module.__init__", "modeling.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "bert_model_embedding_weights.size", "bert_model_embedding_weights.size", "torch.zeros", "bert_model_embedding_weights.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "bert_model_embedding_weights", ".", "size", "(", "1", ")", ",", "\n", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "bert_model_embedding_weights", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertLMPredictionHead.forward": [[435, 439], ["modeling.BertLMPredictionHead.transform", "modeling.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.__init__": [[441, 444], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.forward": [[445, 448], ["modeling.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.__init__": [[450, 453], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.forward": [[454, 457], ["modeling.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.__init__": [[459, 463], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.forward": [[464, 468], ["modeling.BertPreTrainingHeads.predictions", "modeling.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPreTrainedModel.__init__": [[473, 483], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertPreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"", "\n", "\"To create a model from a Google pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPreTrainedModel.init_bert_weights": [[484, 496], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertPreTrainedModel.from_pretrained": [[497, 619], ["os.path.join", "modeling.BertConfig.from_json_file", "logger.info", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling.BertPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "\n", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a BertPreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `bert-base-uncased`\n                    . `bert-large-uncased`\n                    . `bert-base-cased`\n                    . `bert-large-cased`\n                    . `bert-base-multilingual-uncased`\n                    . `bert-base-multilingual-cased`\n                    . `bert-base-chinese`\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `model.chkpt` a TensorFlow checkpoint\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "tempdir", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", "or", "from_tf", ":", "\n", "            ", "serialization_dir", "=", "resolved_archive_file", "\n", "", "else", ":", "\n", "# Extract archive to temp dir", "\n", "            ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", ")", ")", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "'r:gz'", ")", "as", "archive", ":", "\n", "                ", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "serialization_dir", "=", "tempdir", "\n", "# Load config", "\n", "", "config_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", "\n", "config", "=", "BertConfig", ".", "from_json_file", "(", "config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "WEIGHTS_NAME", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "weights_path", ",", "map_location", "=", "'cpu'", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ")", "\n", "", "if", "tempdir", ":", "\n", "# Clean up temp dir", "\n", "            ", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "TF_WEIGHTS_NAME", ")", "\n", "return", "load_tf_weights_in_bert", "(", "model", ",", "weights_path", ")", "\n", "# Load from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "", "", "", "start_prefix", "=", "''", "\n", "if", "not", "hasattr", "(", "model", ",", "'bert'", ")", "and", "any", "(", "s", ".", "startswith", "(", "'bert.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "'bert.'", "\n", "", "load", "(", "model", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertModel.__init__": [[664, 670], ["modeling.BertPreTrainedModel.__init__", "modeling.BertEmbeddings", "modeling.BertEncoder", "modeling.BertPooler", "modeling.BertModel.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertModel.forward": [[671, 701], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling.BertModel.embeddings", "modeling.BertModel.encoder", "modeling.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "torch.ones_like.unsqueeze", "next", "modeling.BertModel.parameters"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "token_type_ids", ")", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForPreTraining.__init__": [[752, 757], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertPreTrainingHeads", "modeling.BertForPreTraining.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForPreTraining.forward": [[758, 771], ["modeling.BertForPreTraining.bert", "modeling.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForMaskedLM.__init__": [[814, 819], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertOnlyMLMHead", "modeling.BertForMaskedLM.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForMaskedLM.forward": [[820, 831], ["modeling.BertForMaskedLM.bert", "modeling.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "masked_lm_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.__init__": [[875, 880], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertOnlyNSPHead", "modeling.BertForNextSentencePrediction.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.forward": [[881, 892], ["modeling.BertForNextSentencePrediction.bert", "modeling.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "next_sentence_loss", "\n", "", "else", ":", "\n", "            ", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForSequenceClassification.__init__": [[938, 945], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForSequenceClassification.forward": [[946, 957], ["modeling.BertForSequenceClassification.bert", "modeling.BertForSequenceClassification.dropout", "modeling.BertForSequenceClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForMultipleChoice.__init__": [[1002, 1009], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForMultipleChoice.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ",", "num_choices", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_choices", "=", "num_choices", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForMultipleChoice.forward": [[1010, 1025], ["input_ids.view", "token_type_ids.view", "attention_mask.view", "modeling.BertForMultipleChoice.bert", "modeling.BertForMultipleChoice.dropout", "modeling.BertForMultipleChoice.classifier", "modeling.BertForMultipleChoice.view", "input_ids.size", "token_type_ids.size", "attention_mask.size", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss."], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "\n", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "flat_token_type_ids", ",", "flat_attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_choices", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "reshaped_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForTokenClassification.__init__": [[1071, 1078], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForTokenClassification.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForTokenClassification.forward": [[1079, 1097], ["modeling.BertForTokenClassification.bert", "modeling.BertForTokenClassification.dropout", "modeling.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling.BertForTokenClassification.view", "labels.view", "modeling.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.__init__": [[1145, 1152], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Linear", "modeling.BertForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "# TODO check with Google if it's normal there is no dropout on the token classifier of SQuAD in the TF version", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.forward": [[1153, 1178], ["modeling.BertForQuestionAnswering.bert", "modeling.BertForQuestionAnswering.qa_outputs", "modeling.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "start_logits", ",", "end_logits", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.load_tf_weights_in_bert": [[52, 111], ["os.path.abspath", "print", "tf.train.list_variables", "zip", "print", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "print", "torch.from_numpy", "print", "print", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "print", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "print", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "print", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "print", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+_\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'_(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'kernel'", "or", "l", "[", "0", "]", "==", "'gamma'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_bias'", "or", "l", "[", "0", "]", "==", "'beta'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_weights'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "'_embeddings'", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "m_name", "==", "'kernel'", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.gelu": [[112, 119], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.swish": [[120, 122], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.__init__": [[92, 135], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["loss1", "=", "torch", ".", "sum", "(", "loss1", ",", "dim", "=", "1", ")", "/", "label_size", "\n", "ppl1", "=", "torch", ".", "exp", "(", "loss1", ")", "\n", "\n", "return", "loss1", ",", "ppl1", "\n", "", "return", "lm_logits", ",", "presents", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.from_dict": [[138, 145], ["modeling_gpt2.GPT2Config", "json_object.items"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.from_json_file": [[146, 152], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.__repr__": [[153, 155], ["str", "modeling_gpt2.GPT2Config.to_json_string"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.to_dict": [[156, 160], ["copy.deepcopy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.to_json_string": [[161, 164], ["json.dumps", "modeling_gpt2.GPT2Config.to_dict"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Conv1D.__init__": [[166, 173], ["torch.Module.__init__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.normal_", "torch.init.normal_", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Conv1D.forward": [[174, 179], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Attention.__init__": [[181, 192], ["torch.Module.__init__", "modeling_gpt2.Attention.register_buffer", "modeling_gpt2.Conv1D", "modeling_gpt2.Conv1D", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Attention._attn": [[193, 203], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size", "torch.Softmax", "torch.Softmax", "math.sqrt", "v.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Attention.merge_heads": [[204, 208], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Attention.split_heads": [[209, 216], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Attention.forward": [[217, 232], ["modeling_gpt2.Attention.c_attn", "modeling_gpt2.Attention.split", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_gpt2.Attention._attn", "modeling_gpt2.Attention.merge_heads", "modeling_gpt2.Attention.c_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.merge_heads"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.MLP.__init__": [[234, 240], ["torch.Module.__init__", "modeling_gpt2.Conv1D", "modeling_gpt2.Conv1D"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.MLP.forward": [[241, 245], ["modeling_gpt2.MLP.act", "modeling_gpt2.MLP.c_proj", "modeling_gpt2.MLP.c_fc"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Block.__init__": [[247, 254], ["torch.Module.__init__", "modeling.BertLayerNorm", "modeling_gpt2.Attention", "modeling.BertLayerNorm", "modeling_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.Block.forward": [[255, 261], ["modeling_gpt2.Block.attn", "modeling_gpt2.Block.mlp", "modeling_gpt2.Block.ln_1", "modeling_gpt2.Block.ln_2"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHead.__init__": [[265, 269], ["torch.Module.__init__", "modeling_gpt2.GPT2LMHead.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHead.set_embeddings_weights": [[270, 275], ["torch.Linear", "torch.Linear"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHead.forward": [[276, 280], ["modeling_gpt2.GPT2LMHead.decoder"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2MultipleChoiceHead.__init__": [[284, 291], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2MultipleChoiceHead.forward": [[292, 301], ["mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand", "hidden_states.gather().squeeze", "modeling_gpt2.GPT2MultipleChoiceHead.linear().squeeze", "hidden_states.size", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze", "hidden_states.gather", "modeling_gpt2.GPT2MultipleChoiceHead.linear", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.__init__": [[307, 318], ["torch.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.set_tied": [[319, 321], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.init_weights": [[322, 333], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.from_pretrained": [[334, 451], ["modeling_gpt2.GPT2Config.from_json_file", "logger.info", "cls", "torch.load.keys", "torch.load.keys", "zip", "getattr", "torch.load.copy", "torch.load.copy", "modeling_gpt2.GPT2PreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Model.__init__": [[491, 500], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_gpt2.Block", "torch.ModuleList", "torch.ModuleList", "modeling.BertLayerNorm", "modeling_gpt2.GPT2Model.apply", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Model.forward": [[501, 532], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.wpe", "zip", "modeling_gpt2.GPT2Model.ln_f", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.size", "token_type_ids.view.view.view", "hasattr", "block", "presents.append", "modeling_gpt2.GPT2Model.view", "len", "token_type_ids.view.view.size", "modeling_gpt2.GPT2Model.turn_emb", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.size", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.__init__": [[577, 582], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "modeling_gpt2.GPT2LMHead", "modeling_gpt2.GPT2LMHeadModel.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.set_tied": [[583, 587], ["modeling_gpt2.GPT2LMHeadModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.forward": [[588, 605], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "loss1.view.view.view", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "modeling_gpt2.GPT2LMHeadModel.view", "lm_labels.view", "lm_labels.size", "lm_labels.size", "loss1.view.view.type", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "modeling_gpt2.GPT2LMHeadModel.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum().float", "torch.sum().float", "torch.sum().float", "torch.sum().float", "torch.sum().type.float", "torch.sum().type.float", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.forward_pointwise": [[606, 622], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "loss1.view.view.view", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "modeling_gpt2.GPT2LMHeadModel.view", "lm_labels.view", "lm_labels.size", "lm_labels.size", "loss1.view.view.type", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "modeling_gpt2.GPT2LMHeadModel.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2DoubleHeadsModel.__init__": [[672, 678], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "modeling_gpt2.GPT2LMHead", "modeling_gpt2.GPT2MultipleChoiceHead", "modeling_gpt2.GPT2DoubleHeadsModel.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2DoubleHeadsModel.set_tied": [[679, 683], ["modeling_gpt2.GPT2DoubleHeadsModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2DoubleHeadsModel.forward": [[684, 698], ["modeling_gpt2.GPT2DoubleHeadsModel.transformer", "modeling_gpt2.GPT2DoubleHeadsModel.lm_head", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_gpt2.GPT2DoubleHeadsModel.view", "lm_labels.view", "modeling_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "modeling_gpt2.GPT2DoubleHeadsModel.size", "modeling_gpt2.GPT2DoubleHeadsModel.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.load_tf_weights_in_gpt2": [[32, 84], ["os.path.abspath", "print", "tf.train.list_variables", "zip", "print", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "print", "torch.from_numpy", "torch.from_numpy", "print", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["", "", "class", "BlockFP16", "(", "Block", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "BlockFP16", ",", "self", ")", ".", "__init__", "(", "n_ctx", ",", "config", ",", "scale", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "AttentionFP16", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n", "", "", "class", "GPT2ModelFP16", "(", "GPT2Model", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2ModelFP16", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "block", "=", "BlockFP16", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "block", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "", "class", "GPT2LMHeadModel", "(", "GPT2PreTrainedModel", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2ModelFP16", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "GPT2LMHead", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ",", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "", "def", "set_tied", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "past", "=", "None", ")", ":", "\n", "        ", "hidden_states", ",", "presents", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "past", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "\n", "            ", "loss_fct1", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n", "loss1", "=", "loss_fct1", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "loss1", "=", "loss1", ".", "view", "(", "lm_labels", ".", "size", "(", "0", ")", ",", "lm_labels", ".", "size", "(", "1", ")", ")", "\n", "label_size", "=", "torch", ".", "sum", "(", "lm_labels", "!=", "-", "1", ",", "dim", "=", "1", ")", ".", "type", "(", "loss1", ".", "type", "(", ")", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "loss1", ")", "/", "torch", ".", "sum", "(", "label_size", ")", "\n", "ppl", "=", "torch", ".", "exp", "(", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "loss1", ",", "dim", "=", "1", ")", ".", "float", "(", ")", "\n", "/", "label_size", ".", "float", "(", ")", ")", ")", "\n", "\n", "return", "loss", ",", "ppl", "\n", "", "return", "lm_logits", ",", "presents", "\n", "\n", "", "def", "forward_pointwise", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "past", "=", "None", ")", ":", "\n", "        ", "hidden_states", ",", "presents", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "past", ")", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.gelu": [[85, 87], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["if", "lm_labels", "is", "not", "None", ":", "\n", "\n", "            ", "loss_fct1", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[16, 28], ["pytorch_pretrained_bert.modeling.BertConfig.from_json_file", "print", "pytorch_pretrained_bert.modeling.BertForPreTraining", "pytorch_pretrained_bert.modeling.load_tf_weights_in_bert", "print", "torch.save", "pytorch_pretrained_bert.modeling.BertForPreTraining.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling.load_tf_weights_in_bert"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "BertConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "BertForPreTraining", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_bert", "(", "model", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_openai_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch": [[15, 34], ["pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel", "pytorch_pretrained_bert.modeling_openai.load_tf_weights_in_openai_gpt", "print", "torch.save", "print", "pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig", "pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig", "pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.state_dict", "io.open", "f.write", "pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.load_tf_weights_in_openai_gpt", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["def", "convert_openai_checkpoint_to_pytorch", "(", "openai_checkpoint_folder_path", ",", "openai_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "openai_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", "openai_config_file", ")", "\n", "", "model", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_openai_gpt", "(", "model", ",", "openai_checkpoint_folder_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization.BertAdam.__init__": [[65, 84], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "BertAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization.BertAdam.get_lr": [[85, 99], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization.BertAdam.step": [[100, 179], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct", "logger.warning"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "warned_for_t_total", "=", "False", "\n", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "progress", "=", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "progress", ",", "group", "[", "'warmup'", "]", ")", "\n", "# warning for exceeding t_total (only active with warmup_linear", "\n", "if", "group", "[", "'schedule'", "]", "==", "\"warmup_linear\"", "and", "progress", ">", "1.", "and", "not", "warned_for_t_total", ":", "\n", "                        ", "logger", ".", "warning", "(", "\n", "\"Training beyond specified 't_total' steps with schedule '{}'. Learning rate set to {}. \"", "\n", "\"Please set 't_total' of {} correctly.\"", ".", "format", "(", "group", "[", "'schedule'", "]", ",", "lr_scheduled", ",", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "warned_for_t_total", "=", "True", "\n", "# end warning", "\n", "", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization.warmup_cosine": [[26, 30], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "0.5", "*", "(", "1.0", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization.warmup_constant": [[31, 37], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "\"\"\" Linearly increases learning rate over `warmup`*`t_total` (as provided to BertAdam) training steps.\n        Learning rate is 1. afterwards. \"\"\"", "\n", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization.warmup_linear": [[38, 44], ["max"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "\"\"\" Specifies a triangular learning rate schedule where peak is reached at `warmup`*`t_total`-th (as provided to BertAdam) training step.\n        After `t_total`-th training step, learning rate is zero. \"\"\"", "\n", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "max", "(", "(", "x", "-", "1.", ")", "/", "(", "warmup", "-", "1.", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.from_pretrained": [[88, 130], ["cls", "os.path.join", "os.path.join", "file_utils.cached_path", "file_utils.cached_path", "logger.info", "logger.info", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path"], ["@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "merges_file", "=", "PRETRAINED_MERGES_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "VOCAB_NAME", ")", "\n", "merges_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "MERGES_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_merges_file", "=", "cached_path", "(", "merges_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "vocab_file", ",", "merges_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", "and", "resolved_merges_file", "==", "merges_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {}\"", ".", "format", "(", "merges_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {} from cache at {}\"", ".", "format", "(", "\n", "merges_file", ",", "resolved_merges_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "resolved_merges_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.__init__": [[131, 145], ["json.load", "tokenization_gpt2.bytes_to_unicode", "dict", "regex.compile", "int", "io.open", "io.open().read().split", "tuple", "zip", "tokenization_gpt2.GPT2Tokenizer.encoder.items", "tokenization_gpt2.GPT2Tokenizer.byte_encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.bytes_to_unicode"], ["", "def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "errors", "=", "'replace'", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "bpe_data", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_data", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.add_special_token": [[146, 159], ["logger.info", "len", "logger.info", "logger.info"], "methods", ["None"], ["", "def", "add_special_token", "(", "self", ",", "special_token", ")", ":", "\n", "# Code modification here, add special tokens", "\n", "        ", "if", "special_token", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "'adding None, return'", ")", "\n", "return", "\n", "", "if", "special_token", "in", "self", ".", "encoder", ":", "\n", "            ", "logger", ".", "info", "(", "'{} found in encoder, return'", ".", "format", "(", "special_token", ")", ")", "\n", "return", "\n", "\n", "", "logger", ".", "info", "(", "'adding special tokens: {}'", ".", "format", "(", "special_token", ")", ")", "\n", "encoder_len", "=", "len", "(", "self", ".", "encoder", ")", "\n", "self", ".", "encoder", "[", "special_token", "]", "=", "encoder_len", "\n", "self", ".", "decoder", "[", "encoder_len", "]", "=", "special_token", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.__len__": [[160, 162], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.bpe": [[163, 203], ["tuple", "tokenization_gpt2.get_pairs", "min", "tuple", "len", "len", "tokenization_gpt2.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode": [[204, 216], ["regex.findall", "bpe_tokens.extend", "len", "logger.warning", "len", "token.encode", "tokenization_gpt2.GPT2Tokenizer.bpe().split", "tokenization_gpt2.GPT2Tokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "bpe_tokens", ".", "extend", "(", "self", ".", "encoder", "[", "bpe_token", "]", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "if", "len", "(", "bpe_tokens", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this OpenAI GPT-2 model ({} > {}). Running this\"", "\n", "\" sequence through the model will result in indexing errors\"", ".", "format", "(", "len", "(", "bpe_tokens", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.decode": [[217, 221], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "text", "=", "''", ".", "join", "(", "[", "self", ".", "decoder", "[", "token", "]", "for", "token", "in", "tokens", "]", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.bytes_to_unicode": [[49, 70], ["lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "bs", "=", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.get_pairs": [[71, 82], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.__init__": [[187, 289], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "modeling_transfo_xl.TransfoXLConfig.cutoffs.extend", "ValueError", "reader.read", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "267735", ",", "\n", "cutoffs", "=", "[", "20000", ",", "40000", ",", "200000", "]", ",", "\n", "d_model", "=", "1024", ",", "\n", "d_embed", "=", "1024", ",", "\n", "n_head", "=", "16", ",", "\n", "d_head", "=", "64", ",", "\n", "d_inner", "=", "4096", ",", "\n", "div_val", "=", "4", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "n_layer", "=", "18", ",", "\n", "tgt_len", "=", "128", ",", "\n", "ext_len", "=", "0", ",", "\n", "mem_len", "=", "1600", ",", "\n", "clamp_len", "=", "1000", ",", "\n", "same_length", "=", "True", ",", "\n", "proj_share_all_but_first", "=", "True", ",", "\n", "attn_type", "=", "0", ",", "\n", "sample_softmax", "=", "-", "1", ",", "\n", "adaptive", "=", "True", ",", "\n", "tie_weight", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "dropatt", "=", "0.0", ",", "\n", "untie_r", "=", "True", ",", "\n", "init", "=", "\"normal\"", ",", "\n", "init_range", "=", "0.01", ",", "\n", "proj_init_std", "=", "0.01", ",", "\n", "init_std", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs TransfoXLConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `TransfoXLModel` or a configuration json file.\n            cutoffs: cutoffs for the adaptive softmax\n            d_model: Dimensionality of the model's hidden states.\n            d_embed: Dimensionality of the embeddings\n            d_head: Dimensionality of the model's heads.\n            div_val: divident value for adapative input and softmax\n            pre_lnorm: apply LayerNorm to the input instead of the output\n            d_inner: Inner dimension in FF\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            tgt_len: number of tokens to predict\n            ext_len: length of the extended context\n            mem_len: length of the retained previous heads\n            same_length: use the same attn length for all tokens\n            proj_share_all_but_first: True to share all but first projs, False not to share.\n            attn_type: attention type. 0 for Transformer-XL, 1 for Shaw et al, 2 for Vaswani et al, 3 for Al Rfou et al.\n            clamp_len: use the same pos embeddings after clamp_len\n            sample_softmax: number of samples in sampled softmax\n            adaptive: use adaptive softmax\n            tie_weight: tie the word embedding and softmax weights\n            dropout: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            dropatt: The dropout ratio for the attention probabilities.\n            untie_r: untie relative position biases           \n            embd_pdrop: The dropout ratio for the embeddings.\n            init: parameter initializer to use\n            init_range: parameters initialized by U(-init_range, init_range).\n            proj_init_std: parameters initialized by N(0, init_std)\n            init_std: parameters initialized by N(0, init_std)\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_token", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "cutoffs", "=", "[", "]", "\n", "self", ".", "cutoffs", ".", "extend", "(", "cutoffs", ")", "\n", "self", ".", "tie_weight", "=", "tie_weight", "\n", "if", "proj_share_all_but_first", ":", "\n", "                ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "True", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "False", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "sample_softmax", "=", "sample_softmax", "\n", "self", ".", "adaptive", "=", "adaptive", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropatt", "=", "dropatt", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "init", "=", "init", "\n", "self", ".", "init_range", "=", "init_range", "\n", "self", ".", "proj_init_std", "=", "proj_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.from_dict": [[291, 298], ["modeling_transfo_xl.TransfoXLConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `TransfoXLConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "TransfoXLConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.from_json_file": [[299, 305], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `TransfoXLConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.__repr__": [[306, 308], ["str", "modeling_transfo_xl.TransfoXLConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.to_dict": [[309, 313], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.to_json_string": [[314, 317], ["json.dumps", "modeling_transfo_xl.TransfoXLConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionalEmbedding.__init__": [[319, 326], ["torch.Module.__init__", "modeling_transfo_xl.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inv_freq'", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionalEmbedding.forward": [[327, 335], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionwiseFF.__init__": [[337, 354], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modeling.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionwiseFF.forward": [[355, 370], ["modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.layer_norm", "modeling_transfo_xl.PositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "self", ".", "layer_norm", "(", "inp", ")", ")", "\n", "\n", "##### residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "##### positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.MultiHeadAttn.__init__": [[372, 400], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "modeling.BertLayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "pre_lnorm", "=", "False", ",", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "q_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "self", ".", "kv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "2", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.MultiHeadAttn.forward": [[401, 451], ["modeling_transfo_xl.MultiHeadAttn.q_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "head_q.view.view.view", "head_k.view.view.view", "head_v.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum.mul_", "torch.einsum.mul_", "torch.einsum.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.MultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.MultiHeadAttn.o_net", "modeling_transfo_xl.MultiHeadAttn.drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.MultiHeadAttn.layer_norm", "modeling_transfo_xl.MultiHeadAttn.kv_net", "h.size", "h.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "modeling_transfo_xl.MultiHeadAttn.layer_norm", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "attn_mask.any", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "float", "float"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "def", "forward", "(", "self", ",", "h", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "##### multihead attention", "\n", "# [hlen x bsz x n_head x d_head]", "\n", "\n", "        ", "if", "mems", "is", "not", "None", ":", "\n", "            ", "c", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "h", "\n", "\n", "", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization", "\n", "            ", "c", "=", "self", ".", "layer_norm", "(", "c", ")", "\n", "\n", "", "head_q", "=", "self", ".", "q_net", "(", "h", ")", "\n", "head_k", ",", "head_v", "=", "torch", ".", "chunk", "(", "self", ".", "kv_net", "(", "c", ")", ",", "2", ",", "-", "1", ")", "\n", "\n", "head_q", "=", "head_q", ".", "view", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_k", "=", "head_k", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_v", "=", "head_v", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "head_q", ",", "head_k", ")", ")", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "# [qlen x klen x bsz x n_head] + [klen x bsz x n_head x d_head] -> [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "head_v", ")", ")", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "h", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "h", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn.__init__": [[453, 481], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "modeling.BertLayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "pre_lnorm", "=", "False", ",", "\n", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ")", ":", "\n", "        ", "super", "(", "RelMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._parallelogram_mask": [[482, 492], ["torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "min", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "", "def", "_parallelogram_mask", "(", "self", ",", "h", ",", "w", ",", "left", "=", "False", ")", ":", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "(", "h", ",", "w", ")", ")", ".", "byte", "(", ")", "\n", "m", "=", "min", "(", "h", ",", "w", ")", "\n", "mask", "[", ":", "m", ",", ":", "m", "]", "=", "torch", ".", "triu", "(", "mask", "[", ":", "m", ",", ":", "m", "]", ")", "\n", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", "=", "torch", ".", "tril", "(", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", ")", "\n", "\n", "if", "left", ":", "\n", "            ", "return", "mask", "\n", "", "else", ":", "\n", "            ", "return", "mask", ".", "flip", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._shift": [[493, 510], ["torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask.flip.flip.flip", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "def", "_shift", "(", "self", ",", "x", ",", "qlen", ",", "klen", ",", "mask", ",", "left", "=", "False", ")", ":", "\n", "        ", "if", "qlen", ">", "1", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "qlen", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "0", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n", "", "if", "left", ":", "\n", "            ", "mask", "=", "mask", ".", "flip", "(", "1", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_padded", "=", "torch", ".", "cat", "(", "[", "x", ",", "zero_pad", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "x", "=", "x_padded", ".", "masked_select", "(", "mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ".", "view", "(", "qlen", ",", "klen", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._rel_shift": [[511, 526], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_rel_shift", "(", "self", ",", "x", ",", "zero_triu", "=", "False", ")", ":", "\n", "        ", "zero_pad_shape", "=", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "zero_pad", "=", "torch", ".", "zeros", "(", "zero_pad_shape", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded_shape", "=", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "*", "x_padded_shape", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "if", "zero_triu", ":", "\n", "            ", "ones", "=", "torch", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", ")", "\n", "x", "=", "x", "*", "torch", ".", "tril", "(", "ones", ",", "x", ".", "size", "(", "1", ")", "-", "x", ".", "size", "(", "0", ")", ")", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn.forward": [[527, 529], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.__init__": [[531, 535], ["modeling_transfo_xl.RelMultiHeadAttn.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.forward": [[536, 610], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "attn_mask.any", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._rel_shift", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "self", ".", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "self", ".", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "#### compute attention vector", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "w", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableMultiHeadAttn.__init__": [[612, 614], ["modeling_transfo_xl.RelMultiHeadAttn.__init__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableMultiHeadAttn.forward": [[615, 695], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelLearnableMultiHeadAttn._rel_shift", "attn_score.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.drop", "w.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat.size", "torch.cat.size", "torch.cat.size", "r_emb[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "r_bias[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "attn_mask.any", "attn_mask.dim", "attn_score.masked_fill_", "float", "float"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._rel_shift", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "w", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "# r_emb: [klen, n_head, d_head], used for term B", "\n", "# r_w_bias: [n_head, d_head], used for term C", "\n", "# r_bias: [klen, n_head], used for term D", "\n", "\n", "        ", "qlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "\n", "if", "klen", ">", "r_emb", ".", "size", "(", "0", ")", ":", "\n", "            ", "r_emb_pad", "=", "r_emb", "[", "0", ":", "1", "]", ".", "expand", "(", "klen", "-", "r_emb", ".", "size", "(", "0", ")", ",", "-", "1", ",", "-", "1", ")", "\n", "r_emb", "=", "torch", ".", "cat", "(", "[", "r_emb_pad", ",", "r_emb", "]", ",", "0", ")", "\n", "r_bias_pad", "=", "r_bias", "[", "0", ":", "1", "]", ".", "expand", "(", "klen", "-", "r_bias", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "r_bias", "=", "torch", ".", "cat", "(", "[", "r_bias_pad", ",", "r_bias", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "r_emb", "=", "r_emb", "[", "-", "klen", ":", "]", "\n", "r_bias", "=", "r_bias", "[", "-", "klen", ":", "]", "\n", "\n", "#### compute attention score", "\n", "", "rw_head_q", "=", "w_head_q", "+", "r_w_bias", "[", "None", "]", "# qlen x bsz x n_head x d_head", "\n", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "B_", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "w_head_q", ",", "r_emb", ")", ")", "# qlen x klen x bsz x n_head", "\n", "D_", "=", "r_bias", "[", "None", ",", ":", ",", "None", "]", "# 1    x klen x 1   x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "B_", "+", "D_", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "#### compute attention vector", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "w", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.DecoderLayer.__init__": [[697, 703], ["torch.Module.__init__", "modeling_transfo_xl.MultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "MultiHeadAttn", "(", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.DecoderLayer.forward": [[704, 711], ["modeling_transfo_xl.DecoderLayer.dec_attn", "modeling_transfo_xl.DecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableDecoderLayer.__init__": [[713, 721], ["torch.Module.__init__", "modeling_transfo_xl.RelLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableDecoderLayer.forward": [[722, 730], ["modeling_transfo_xl.RelLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableDecoderLayer.__init__": [[732, 740], ["torch.Module.__init__", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableDecoderLayer.forward": [[741, 749], ["modeling_transfo_xl.RelPartialLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.AdaptiveEmbedding.__init__": [[751, 780], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "range", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "len", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "sample_softmax", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "self", ".", "emb_layers", ".", "append", "(", "\n", "nn", ".", "Embedding", "(", "n_token", ",", "d_embed", ",", "sparse", "=", "sample_softmax", ">", "0", ")", "\n", ")", "\n", "if", "d_proj", "!=", "d_embed", ":", "\n", "                ", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_embed", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ")", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_emb_i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.AdaptiveEmbedding.forward": [[781, 812], ["torch.linear.mul_", "next", "inp.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view", "torch.zeros.view", "torch.linear", "torch.linear", "torch.linear", "modeling_transfo_xl.AdaptiveEmbedding.parameters", "len", "mask_i.nonzero().squeeze", "torch.linear", "torch.linear", "torch.linear", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "inp.size", "inp.view.size", "mask_i.nonzero().squeeze.numel", "inp.view.index_select", "mask_i.nonzero"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "embed", "=", "self", ".", "emb_layers", "[", "0", "]", "(", "inp", ")", "\n", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "                ", "embed", "=", "F", ".", "linear", "(", "embed", ",", "self", ".", "emb_projs", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "inp_flat", "=", "inp", ".", "view", "(", "-", "1", ")", "\n", "emb_flat", "=", "torch", ".", "zeros", "(", "[", "inp_flat", ".", "size", "(", "0", ")", ",", "self", ".", "d_proj", "]", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "\n", "mask_i", "=", "(", "inp_flat", ">=", "l_idx", ")", "&", "(", "inp_flat", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "inp_i", "=", "inp_flat", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "inp_i", ")", "\n", "emb_i", "=", "F", ".", "linear", "(", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "\n", "emb_flat", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "emb_i", ")", "\n", "\n", "", "embed_shape", "=", "inp", ".", "size", "(", ")", "+", "(", "self", ".", "d_proj", ",", ")", "\n", "embed", "=", "emb_flat", ".", "view", "(", "embed_shape", ")", "\n", "\n", "", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.__init__": [[817, 827], ["torch.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TransfoXLPreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "TransfoXLConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `TransfoXLConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight": [[828, 833], ["torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "init", "==", "'uniform'", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "self", ".", "config", ".", "init_range", ",", "self", ".", "config", ".", "init_range", ")", "\n", "", "elif", "self", ".", "config", ".", "init", "==", "'normal'", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias": [[834, 836], ["torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "", "def", "init_bias", "(", "self", ",", "bias", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weights": [[837, 877], ["classname.find", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "classname.find", "hasattr", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "range", "classname.find", "hasattr", "len", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias"], ["", "def", "init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'TransformerLM'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.set_num_special_tokens": [[878, 880], ["None"], "methods", ["None"], ["", "", "", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.from_pretrained": [[881, 978], ["modeling_transfo_xl.TransfoXLConfig.from_json_file", "logger.info", "cls", "getattr", "torch.load.copy", "torch.load.copy", "torch.load.copy", "modeling_transfo_xl.TransfoXLPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "\n", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a TransfoXLPreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `transfo-xl`\n                - a path or url to a pretrained model archive containing:\n                    . `transfo_xl_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a TransfoXLModel instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `model.chkpt` a TensorFlow checkpoint\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "config_file", "=", "PRETRAINED_CONFIG_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "archive_file", ",", "config_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", "and", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "# Load config", "\n", "", "config", "=", "TransfoXLConfig", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "return", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "pretrained_model_name_or_path", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "", "", "", "start_prefix", "=", "''", "\n", "if", "not", "hasattr", "(", "model", ",", "'transformer'", ")", "and", "any", "(", "s", ".", "startswith", "(", "'transformer.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "'transformer.'", "\n", "", "load", "(", "model", ",", "prefix", "=", "start_prefix", ")", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "# Make sure we are still sharing the input and output embeddings", "\n", "", "if", "hasattr", "(", "model", ",", "'tie_weights'", ")", ":", "\n", "            ", "model", ".", "tie_weights", "(", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.__init__": [[1019, 1093], ["modeling_transfo_xl.TransfoXLPreTrainedModel.__init__", "modeling_transfo_xl.AdaptiveEmbedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "modeling_transfo_xl.TransfoXLModel.apply", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl.PositionalEmbedding", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "modeling_transfo_xl.TransfoXLModel.layers.append", "range", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.RelPartialLearnableDecoderLayer", "modeling_transfo_xl.TransfoXLModel.layers.append", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "modeling_transfo_xl.PositionalEmbedding", "modeling_transfo_xl.RelLearnableDecoderLayer", "modeling_transfo_xl.TransfoXLModel.layers.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.DecoderLayer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "n_token", "=", "config", ".", "n_token", "\n", "\n", "self", ".", "d_embed", "=", "config", ".", "d_embed", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "\n", "self", ".", "word_emb", "=", "AdaptiveEmbedding", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "\n", "div_val", "=", "config", ".", "div_val", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "config", ".", "tgt_len", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "ext_len", "=", "config", ".", "ext_len", "\n", "self", ".", "max_klen", "=", "config", ".", "tgt_len", "+", "config", ".", "ext_len", "+", "config", ".", "mem_len", "\n", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "\n", "if", "not", "config", ".", "untie_r", ":", "\n", "            ", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "config", ".", "attn_type", "==", "0", ":", "# the default attention", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ")", "\n", ")", "\n", "", "", "elif", "config", ".", "attn_type", "==", "1", ":", "# learnable embeddings", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ")", "\n", ")", "\n", "", "", "elif", "config", ".", "attn_type", "in", "[", "2", ",", "3", "]", ":", "# absolute embeddings", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "DecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default attention", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "1", ":", "# learnable", "\n", "            ", "self", ".", "r_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ")", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "2", ":", "# absolute standard", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "3", ":", "# absolute deeper SA", "\n", "            ", "self", ".", "r_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.backward_compatible": [[1094, 1096], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.reset_length": [[1097, 1101], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.init_mems": [[1102, 1114], ["next", "range", "modeling_transfo_xl.TransfoXLModel.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mems.append", "data.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", ")", ":", "\n", "                ", "empty", "=", "torch", ".", "zeros", "(", "self", ".", "mem_len", ",", "data", ".", "size", "(", "1", ")", ",", "self", ".", "config", ".", "d_model", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel._update_mems": [[1115, 1137], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_mems.append", "cat[].detach"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel._forward": [[1138, 1227], ["dec_inp.size", "modeling_transfo_xl.TransfoXLModel.word_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel._update_mems", "mems[].size", "modeling_transfo_xl.TransfoXLModel.new_ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "hids.append", "layer", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "hids.append", "layer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "hids.append", "layer", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "modeling_transfo_xl.TransfoXLModel.new_ones", "hids.append", "[].view", "layer", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.view", "torch.cat.view", "torch.cat.view", "cur_emb[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel._update_mems", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_forward", "(", "self", ",", "dec_inp", ",", "mems", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "bsz", "=", "dec_inp", ".", "size", "(", ")", "\n", "\n", "word_emb", "=", "self", ".", "word_emb", "(", "dec_inp", ")", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "all_ones", "=", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", "\n", "mask_len", "=", "klen", "-", "self", ".", "mem_len", "\n", "if", "mask_len", ">", "0", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "-", "mask_len", "\n", "", "else", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "\n", "", "dec_attn_mask", "=", "(", "torch", ".", "triu", "(", "all_ones", ",", "1", "+", "mlen", ")", "\n", "+", "torch", ".", "tril", "(", "all_ones", ",", "-", "mask_shift_len", ")", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "# -1", "\n", "", "else", ":", "\n", "            ", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", ",", "diagonal", "=", "1", "+", "mlen", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "hids", "=", "[", "]", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "core_out", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "1", ":", "# learnable", "\n", "            ", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                    ", "r_emb", "=", "self", ".", "r_emb", "[", "i", "]", "[", "-", "self", ".", "clamp_len", ":", "]", "\n", "r_bias", "=", "self", ".", "r_bias", "[", "i", "]", "[", "-", "self", ".", "clamp_len", ":", "]", "\n", "", "else", ":", "\n", "                    ", "r_emb", ",", "r_bias", "=", "self", ".", "r_emb", "[", "i", "]", ",", "self", ".", "r_bias", "[", "i", "]", "\n", "\n", "", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "core_out", "=", "layer", "(", "core_out", ",", "r_emb", ",", "self", ".", "r_w_bias", "[", "i", "]", ",", "\n", "r_bias", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "2", ":", "# absolute", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", "+", "pos_emb", "[", "-", "qlen", ":", "]", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "if", "mems_i", "is", "not", "None", "and", "i", "==", "0", ":", "\n", "                    ", "mems_i", "+=", "pos_emb", "[", ":", "mlen", "]", "\n", "", "core_out", "=", "layer", "(", "core_out", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "3", ":", "\n", "            ", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "if", "mems_i", "is", "not", "None", "and", "mlen", ">", "0", ":", "\n", "                    ", "cur_emb", "=", "self", ".", "r_emb", "[", "i", "]", "[", ":", "-", "qlen", "]", "\n", "cur_size", "=", "cur_emb", ".", "size", "(", "0", ")", "\n", "if", "cur_size", "<", "mlen", ":", "\n", "                        ", "cur_emb_pad", "=", "cur_emb", "[", "0", ":", "1", "]", ".", "expand", "(", "mlen", "-", "cur_size", ",", "-", "1", ",", "-", "1", ")", "\n", "cur_emb", "=", "torch", ".", "cat", "(", "[", "cur_emb_pad", ",", "cur_emb", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "cur_emb", "=", "cur_emb", "[", "-", "mlen", ":", "]", "\n", "", "mems_i", "+=", "cur_emb", ".", "view", "(", "mlen", ",", "1", ",", "-", "1", ")", "\n", "", "core_out", "+=", "self", ".", "r_emb", "[", "i", "]", "[", "-", "qlen", ":", "]", ".", "view", "(", "qlen", ",", "1", ",", "-", "1", ")", "\n", "\n", "core_out", "=", "layer", "(", "core_out", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ")", "\n", "\n", "", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "return", "core_out", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.forward": [[1228, 1253], ["input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_transfo_xl.TransfoXLModel._forward", "last_hidden.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_transfo_xl.TransfoXLModel.init_mems", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "last_hidden.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader._forward", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mems", "=", "None", ")", ":", "\n", "        ", "\"\"\" Params:\n                input_ids :: [bsz, len]\n                mems :: optional mems from previous forwar passes (or init_mems)\n                    list (num layers) of mem states at the entry of each layer\n                        shape :: [self.config.mem_len, bsz, self.config.d_model]\n                    Note that the first two dimensions are transposed in `mems` with regards to `input_ids` and `target`\n            Returns:\n                tuple (last_hidden, new_mems) where:\n                    new_mems: list (num layers) of mem states at the entry of each layer\n                        shape :: [self.config.mem_len, bsz, self.config.d_model]\n                    last_hidden: output of the last layer:\n                        shape :: [bsz, len, self.config.d_model]\n        \"\"\"", "\n", "# the original code for Transformer-XL used shapes [len, bsz] but we want a unified interface in the library", "\n", "# so we transpose here from shape [bsz, len] to shape [len, bsz]", "\n", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", "input_ids", ")", "\n", "", "last_hidden", ",", "new_mems", "=", "self", ".", "_forward", "(", "input_ids", ",", "mems", "=", "mems", ")", "\n", "\n", "# We transpose back here to shape [bsz, len, hidden_dim]", "\n", "last_hidden", "=", "last_hidden", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "(", "last_hidden", ",", "new_mems", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.__init__": [[1304, 1318], ["modeling_transfo_xl.TransfoXLPreTrainedModel.__init__", "modeling_transfo_xl.TransfoXLModel", "modeling_transfo_xl.TransfoXLLMHeadModel.apply", "modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights", "torch.Linear", "torch.Linear", "torch.Linear", "LogUniformSampler", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "TransfoXLModel", "(", "config", ")", "\n", "self", ".", "sample_softmax", "=", "config", ".", "sample_softmax", "\n", "# use sampled softmax", "\n", "if", "config", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "self", ".", "out_layer", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "n_token", ")", "\n", "self", ".", "sampler", "=", "LogUniformSampler", "(", "config", ".", "n_token", ",", "config", ".", "sample_softmax", ")", "\n", "# use adaptive softmax (including standard softmax)", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "ProjectedAdaptiveLogSoftmax", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "\n", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", ")", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights": [[1319, 1336], ["range", "enumerate", "len"], "methods", ["None"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Run this to be sure output and input (adaptive) softmax weights are tied \"\"\"", "\n", "# sampled softmax", "\n", "if", "self", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "self", ".", "out_layer", ".", "weight", "=", "self", ".", "transformer", ".", "word_emb", ".", "weight", "\n", "# adaptive softmax (including standard softmax)", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "crit", ".", "out_layers", ")", ")", ":", "\n", "                    ", "self", ".", "crit", ".", "out_layers", "[", "i", "]", ".", "weight", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_layers", "[", "i", "]", ".", "weight", "\n", "", "", "if", "self", ".", "config", ".", "tie_projs", ":", "\n", "                ", "for", "i", ",", "tie_proj", "in", "enumerate", "(", "self", ".", "config", ".", "tie_projs", ")", ":", "\n", "                    ", "if", "tie_proj", "and", "self", ".", "config", ".", "div_val", "==", "1", "and", "self", ".", "config", ".", "d_model", "!=", "self", ".", "config", ".", "d_embed", ":", "\n", "                        ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", "\n", "", "elif", "tie_proj", "and", "self", ".", "config", ".", "div_val", "!=", "1", ":", "\n", "                        ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length": [[1337, 1339], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.reset_length"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length"], ["", "", "", "", "", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "reset_length", "(", "tgt_len", ",", "ext_len", ",", "mem_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems": [[1340, 1342], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.init_mems"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "init_mems", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.forward": [[1343, 1376], ["input_ids.size", "input_ids.size", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer", "modeling_transfo_xl_utilities.sample_logits", "modeling_transfo_xl.TransfoXLLMHeadModel.crit", "pred_hid.view", "softmax_output.view.view.view", "softmax_output.view.view.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "pred_hid.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.sample_logits", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "target", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "\"\"\" Params:\n                input_ids :: [bsz, len]\n                target :: [bsz, len]\n            Returns:\n                tuple(softmax_output, new_mems) where:\n                    new_mems: list (num layers) of hidden states at the entry of each layer\n                        shape :: [mem_len, bsz, self.config.d_model] :: Warning: shapes are transposed here w. regards to input_ids\n                    softmax_output: output of the (adaptive) softmax:\n                        if target is None:\n                            Negative log likelihood of shape :: [bsz, len] \n                        else:\n                            log probabilities of tokens, shape :: [bsz, len, n_tokens]\n        \"\"\"", "\n", "bsz", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "tgt_len", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "\n", "last_hidden", ",", "new_mems", "=", "self", ".", "transformer", "(", "input_ids", ",", "mems", ")", "\n", "\n", "pred_hid", "=", "last_hidden", "[", ":", ",", "-", "tgt_len", ":", "]", "\n", "if", "self", ".", "sample_softmax", ">", "0", "and", "self", ".", "training", ":", "\n", "            ", "assert", "self", ".", "config", ".", "tie_weight", "\n", "logit", "=", "sample_logits", "(", "self", ".", "transformer", ".", "word_emb", ",", "self", ".", "out_layer", ".", "bias", ",", "target", ",", "pred_hid", ",", "self", ".", "sampler", ")", "\n", "softmax_output", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "-", "1", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "softmax_output", "=", "self", ".", "crit", "(", "pred_hid", ".", "view", "(", "-", "1", ",", "pred_hid", ".", "size", "(", "-", "1", ")", ")", ",", "target", ")", "\n", "if", "target", "is", "None", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ")", "\n", "\n", "# We transpose back", "\n", "", "", "return", "(", "softmax_output", ",", "new_mems", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.build_tf_to_pytorch_map": [[57, 128], ["hasattr", "enumerate", "enumerate", "tf_to_pt_map.update", "tf_to_pt_map.update", "enumerate", "zip", "tf_to_pt_map.update", "tf_to_pt_map.update", "zip", "r_r_list.append", "r_w_list.append", "tf_to_pt_map.update", "tf_to_pt_map.update", "tf_to_pt_map.update"], "function", ["None"], ["def", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        This time I use a map to keep the PyTorch model as identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "# We are loading in a TransfoXLLMHeadModel => we will load also the Adaptive Softmax", "\n", "        ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_W\"", ":", "model", ".", "crit", ".", "cluster_weight", ",", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_b\"", ":", "model", ".", "crit", ".", "cluster_bias", "}", ")", "\n", "for", "i", ",", "(", "out_l", ",", "proj_l", ",", "tie_proj", ")", "in", "enumerate", "(", "zip", "(", "\n", "model", ".", "crit", ".", "out_layers", ",", "\n", "model", ".", "crit", ".", "out_projs", ",", "\n", "config", ".", "tie_projs", ")", ")", ":", "\n", "            ", "layer_str", "=", "\"transformer/adaptive_softmax/cutoff_%d/\"", "%", "i", "\n", "if", "config", ".", "tie_weight", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "# I don't think this is implemented in the TF code", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "out_l", ".", "weight", ",", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "if", "not", "tie_proj", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'proj'", ":", "proj_l", "\n", "}", ")", "\n", "# Now load the rest of the transformer", "\n", "", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings", "\n", "", "for", "i", ",", "(", "embed_l", ",", "proj_l", ")", "in", "enumerate", "(", "zip", "(", "model", ".", "word_emb", ".", "emb_layers", ",", "model", ".", "word_emb", ".", "emb_projs", ")", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/adaptive_embed/cutoff_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "embed_l", ".", "weight", ",", "\n", "layer_str", "+", "'proj_W'", ":", "proj_l", "\n", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layers", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "dec_attn", ".", "o_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/qkv/kernel\"", ":", "b", ".", "dec_attn", ".", "qkv_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "dec_attn", ".", "r_net", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layers", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_w_bias", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'transformer/r_w_bias'", ":", "r_w_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.load_tf_weights_in_transfo_xl": [[129, 183], ["modeling_transfo_xl.build_tf_to_pytorch_map", "tf.train.list_variables", "build_tf_to_pytorch_map.items", "print", "print", "tf.train.load_variable", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "print", "np.transpose", "enumerate", "print", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "print", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.build_tf_to_pytorch_map"], ["", "def", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "print", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", "\n", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "print", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "assert", "name", "in", "tf_weights", "\n", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "or", "'proj'", "in", "name", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "(", "'r_r_bias'", "in", "name", "or", "'r_w_bias'", "in", "name", ")", "and", "len", "(", "pointer", ")", ">", "1", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "print", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.__init__": [[32, 77], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.Linear", "torch.Linear", "torch.Linear", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "keep_order", "=", "False", ")", ":", "\n", "        ", "super", "(", "ProjectedAdaptiveLogSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "if", "self", ".", "n_clusters", ">", "0", ":", "\n", "            ", "self", ".", "cluster_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ",", "self", ".", "d_embed", ")", ")", "\n", "self", ".", "cluster_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ")", ")", "\n", "\n", "", "self", ".", "out_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "d_proj", "!=", "d_embed", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_embed", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "None", ")", "\n", "\n", "", "", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_embed", ",", "n_token", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "\n", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_emb_i", ")", ")", "\n", ")", "\n", "\n", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "r_idx", "-", "l_idx", ")", ")", "\n", "\n", "", "", "self", ".", "keep_order", "=", "keep_order", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit": [[78, 91], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "proj.t().contiguous", "proj.t"], "methods", ["None"], ["", "def", "_compute_logit", "(", "self", ",", "hidden", ",", "weight", ",", "bias", ",", "proj", ")", ":", "\n", "        ", "if", "proj", "is", "None", ":", "\n", "            ", "logit", "=", "F", ".", "linear", "(", "hidden", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# if CUDA_MAJOR <= 9 and CUDA_MINOR <= 1:", "\n", "            ", "proj_hid", "=", "F", ".", "linear", "(", "hidden", ",", "proj", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "\n", "logit", "=", "F", ".", "linear", "(", "proj_hid", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "# else:", "\n", "#     logit = torch.einsum('bd,de,ev->bv', (hidden, proj, weight.t()))", "\n", "#     if bias is not None:", "\n", "#         logit = logit + bias", "\n", "\n", "", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.forward": [[92, 196], ["target.view.view.view", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "hidden.size", "target.view.view.size", "RuntimeError", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "len", "weights.append", "biases.append", "hidden.new_empty", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "mask_i.nonzero().squeeze", "torch.log_softmax.index_select", "hidden.index_select", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "head_logprob.index_select.gather().squeeze.size", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "mask_i.nonzero().squeeze.numel", "target.view.view.index_select", "F.log_softmax.index_select.gather().squeeze", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "out[].copy_", "torch.log_softmax().gather", "torch.log_softmax().gather", "torch.log_softmax().gather", "mask_i.nonzero", "torch.log_softmax.gather().squeeze", "hasattr", "target.view.view.unsqueeze", "F.log_softmax.index_select.gather", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.gather", "head_logprob.index_select.gather().squeeze.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "target", "=", "None", ",", "keep_order", "=", "False", ")", ":", "\n", "        ", "'''\n            Params:\n                hidden :: [len*bsz x d_proj]\n                target :: [len*bsz]\n            Return:\n                if target is None:\n                    out :: [len*bsz] Negative log likelihood\n                else:\n                    out :: [len*bsz x n_tokens] log probabilities of tokens over the vocabulary\n            We could replace this implementation by the native PyTorch one\n            if their's had an option to set bias on all clusters in the native one.\n            here: https://github.com/pytorch/pytorch/blob/dbe6a7a9ff1a364a8706bf5df58a1ca96d2fd9da/torch/nn/modules/adaptive.py#L138\n        '''", "\n", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "if", "hidden", ".", "size", "(", "0", ")", "!=", "target", ".", "size", "(", "0", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Input and target should have the same size '", "\n", "'in the batch dimension.'", ")", "\n", "\n", "", "", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                ", "output", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", ".", "gather", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "if", "target", "is", "None", ":", "\n", "                ", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "torch", ".", "zeros_like", "(", "target", ",", "dtype", "=", "hidden", ".", "dtype", ",", "device", "=", "hidden", ".", "device", ")", "\n", "\n", "", "offset", "=", "0", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "target", "is", "not", "None", ":", "\n", "                    ", "mask_i", "=", "(", "target", ">=", "l_idx", ")", "&", "(", "target", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "target_i", "=", "target", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "head_logprob_i", "=", "head_logprob", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "hidden_i", "=", "hidden", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "", "else", ":", "\n", "                    ", "hidden_i", "=", "hidden", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "if", "target", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden_i", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "cluster_prob_idx", "=", "self", ".", "cutoffs", "[", "0", "]", "+", "i", "-", "1", "# No probability for the head cluster", "\n", "if", "target", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", "[", ":", ",", "cluster_prob_idx", "]", "+", "tail_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "logprob_i", "=", "head_logprob", "[", ":", ",", "cluster_prob_idx", ",", "None", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "l_idx", ":", "r_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "if", "target", "is", "not", "None", ":", "\n", "                    ", "if", "(", "hasattr", "(", "self", ",", "'keep_order'", ")", "and", "self", ".", "keep_order", ")", "or", "keep_order", ":", "\n", "                        ", "out", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "-", "logprob_i", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", "offset", ":", "offset", "+", "logprob_i", ".", "size", "(", "0", ")", "]", ".", "copy_", "(", "-", "logprob_i", ")", "\n", "", "offset", "+=", "logprob_i", ".", "size", "(", "0", ")", "\n", "\n", "", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob": [[197, 257], ["modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "hidden.new_empty", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "len", "weights.append", "biases.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "log_prob", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "r\"\"\" Computes log probabilities for all :math:`n\\_classes`\n        From: https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/adaptive.py\n        Args:\n            hidden (Tensor): a minibatch of examples\n        Returns:\n            log-probabilities of for each class :math:`c`\n            in range :math:`0 <= c <= n\\_classes`, where :math:`n\\_classes` is a\n            parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.\n        Shape:\n            - Input: :math:`(N, in\\_features)`\n            - Output: :math:`(N, n\\_classes)`\n        \"\"\"", "\n", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "return", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "\n", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "start_idx", ",", "stop_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "\n", "logprob_i", "=", "head_logprob", "[", ":", ",", "-", "i", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "start_idx", ",", "stop_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.LogUniformSampler.__init__": [[259, 278], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double().log1p_", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "range_max", ",", "n_sample", ")", ":", "\n", "        ", "\"\"\"\n        Reference : https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/ops/candidate_sampling_ops.py\n            `P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)`\n\n        expected count can be approximated by 1 - (1 - p)^n\n        and we use a numerically stable version -expm1(num_tries * log1p(-p))\n\n        Our implementation fixes num_tries at 2 * n_sample, and the actual #samples will vary from run to run\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "range_max", "=", "range_max", "\n", "log_indices", "=", "torch", ".", "arange", "(", "1.", ",", "range_max", "+", "2.", ",", "1.", ")", ".", "log_", "(", ")", "\n", "self", ".", "dist", "=", "(", "log_indices", "[", "1", ":", "]", "-", "log_indices", "[", ":", "-", "1", "]", ")", "/", "log_indices", "[", "-", "1", "]", "\n", "# print('P', self.dist.numpy().tolist()[-30:])", "\n", "\n", "self", ".", "log_q", "=", "(", "-", "(", "-", "self", ".", "dist", ".", "double", "(", ")", ".", "log1p_", "(", ")", "*", "2", "*", "n_sample", ")", ".", "expm1_", "(", ")", ")", ".", "log_", "(", ")", ".", "float", "(", ")", "\n", "\n", "", "self", ".", "n_sample", "=", "n_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.LogUniformSampler.sample": [[279, 299], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "neg_samples.to.to.to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["", "def", "sample", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n            labels: [b1, b2]\n        Return\n            true_log_probs: [b1, b2]\n            samp_log_probs: [n_sample]\n            neg_samples: [n_sample]\n        \"\"\"", "\n", "\n", "# neg_samples = torch.empty(0).long()", "\n", "n_sample", "=", "self", ".", "n_sample", "\n", "n_tries", "=", "2", "*", "n_sample", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "neg_samples", "=", "torch", ".", "multinomial", "(", "self", ".", "dist", ",", "n_tries", ",", "replacement", "=", "True", ")", ".", "unique", "(", ")", "\n", "device", "=", "labels", ".", "device", "\n", "neg_samples", "=", "neg_samples", ".", "to", "(", "device", ")", "\n", "true_log_probs", "=", "self", ".", "log_q", "[", "labels", "]", ".", "to", "(", "device", ")", "\n", "samp_log_probs", "=", "self", ".", "log_q", "[", "neg_samples", "]", ".", "to", "(", "device", ")", "\n", "return", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.sample_logits": [[300, 332], ["sampler.sample", "neg_samples.size", "torch.cat", "torch.cat", "torch.cat", "embedding", "all_w[].view", "all_w[].view", "all_b[].view", "sample_logits.masked_fill_", "torch.cat", "torch.cat", "torch.cat", "labels.size", "labels.size", "labels.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.LogUniformSampler.sample", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "", "def", "sample_logits", "(", "embedding", ",", "bias", ",", "labels", ",", "inputs", ",", "sampler", ")", ":", "\n", "    ", "\"\"\"\n        embedding: an nn.Embedding layer\n        bias: [n_vocab]\n        labels: [b1, b2]\n        inputs: [b1, b2, n_emb]\n        sampler: you may use a LogUniformSampler\n    Return\n        logits: [b1, b2, 1 + n_sample]\n    \"\"\"", "\n", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "=", "sampler", ".", "sample", "(", "labels", ")", "\n", "n_sample", "=", "neg_samples", ".", "size", "(", "0", ")", "\n", "b1", ",", "b2", "=", "labels", ".", "size", "(", "0", ")", ",", "labels", ".", "size", "(", "1", ")", "\n", "all_ids", "=", "torch", ".", "cat", "(", "[", "labels", ".", "view", "(", "-", "1", ")", ",", "neg_samples", "]", ")", "\n", "all_w", "=", "embedding", "(", "all_ids", ")", "\n", "true_w", "=", "all_w", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ",", "-", "1", ")", "\n", "sample_w", "=", "all_w", "[", "-", "n_sample", ":", "]", ".", "view", "(", "n_sample", ",", "-", "1", ")", "\n", "\n", "all_b", "=", "bias", "[", "all_ids", "]", "\n", "true_b", "=", "all_b", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ")", "\n", "sample_b", "=", "all_b", "[", "-", "n_sample", ":", "]", "\n", "\n", "hit", "=", "(", "labels", "[", ":", ",", ":", ",", "None", "]", "==", "neg_samples", ")", ".", "detach", "(", ")", "\n", "\n", "true_logits", "=", "torch", ".", "einsum", "(", "'ijk,ijk->ij'", ",", "\n", "[", "true_w", ",", "inputs", "]", ")", "+", "true_b", "-", "true_log_probs", "\n", "sample_logits", "=", "torch", ".", "einsum", "(", "'lk,ijk->ijl'", ",", "\n", "[", "sample_w", ",", "inputs", "]", ")", "+", "sample_b", "-", "samp_log_probs", "\n", "sample_logits", ".", "masked_fill_", "(", "hit", ",", "-", "1e30", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "true_logits", "[", ":", ",", ":", ",", "None", "]", ",", "sample_logits", "]", ",", "-", "1", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.url_to_filename": [[38, 54], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.filename_to_url": [[55, 79], ["os.path.join", "isinstance", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path": [[80, 108], ["urlparse", "isinstance", "str", "isinstance", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.split_s3_path": [[109, 120], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.s3_request": [[121, 138], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.s3_etag": [[139, 146], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.s3_get": [[147, 153], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.http_get": [[154, 164], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["None"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.get_from_cache": [[165, 223], ["url.startswith", "file_utils.url_to_filename", "os.path.join", "isinstance", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "requests.head", "requests.head.headers.get", "os.path.exists", "IOError", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dump"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.url_to_filename", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.s3_etag", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.s3_get", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "            ", "raise", "IOError", "(", "\"HEAD request failed for url {} with status code {}\"", "\n", ".", "format", "(", "url", ",", "response", ".", "status_code", ")", ")", "\n", "", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "                ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.read_set_from_file": [[224, 234], ["set", "io.open", "set.add", "line.rstrip"], "function", ["None"], ["", "def", "read_set_from_file", "(", "filename", ")", ":", "\n", "    ", "'''\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    '''", "\n", "collection", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "file_", ":", "\n", "        ", "for", "line", "in", "file_", ":", "\n", "            ", "collection", ".", "add", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "return", "collection", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.get_file_extension": [[235, 239], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ",", "dot", "=", "True", ",", "lower", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BertTokenizer.__init__": [[74, 103], ["tokenization.load_vocab", "collections.OrderedDict", "tokenization.WordpieceTokenizer", "os.path.isfile", "ValueError", "tokenization.BasicTokenizer", "int", "tokenization.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ",", "max_len", "=", "None", ",", "do_basic_tokenize", "=", "True", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ")", ")", ":", "\n", "        ", "\"\"\"Constructs a BertTokenizer.\n\n        Args:\n          vocab_file: Path to a one-wordpiece-per-line vocabulary file\n          do_lower_case: Whether to lower case the input\n                         Only has an effect when do_wordpiece_only=False\n          do_basic_tokenize: Whether to do basic tokenization before wordpiece.\n          max_len: An artificial maximum length to truncate tokenized sequences to;\n                         Effective maximum length is always the minimum of this\n                         value (if specified) and the underlying BERT model's\n                         sequence length.\n          never_split: List of tokens which will never be split during tokenization.\n                         Only has an effect when do_wordpiece_only=False\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "do_basic_tokenize", "=", "do_basic_tokenize", "\n", "if", "do_basic_tokenize", ":", "\n", "          ", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ",", "\n", "never_split", "=", "never_split", ")", "\n", "", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ")", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BertTokenizer.tokenize": [[104, 113], ["tokenization.BertTokenizer.basic_tokenizer.tokenize", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization.BertTokenizer.append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "do_basic_tokenize", ":", "\n", "          ", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ")", ":", "\n", "              ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                  ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "", "else", ":", "\n", "          ", "split_tokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids": [[114, 126], ["ids.append", "len", "logger.warning", "len"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"", "\n", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "vocab", "[", "token", "]", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this BERT model ({} > {}). Running this\"", "\n", "\" sequence through BERT will result in indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens": [[127, 133], ["tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in wordpiece tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "ids_to_tokens", "[", "i", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained": [[134, 171], ["os.path.isdir", "cls", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "pretrained_model_name_or_path", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "vocab_file", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_file", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer.__init__": [[175, 185], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "do_lower_case", "=", "True", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ")", ")", ":", "\n", "        ", "\"\"\"Constructs a BasicTokenizer.\n\n        Args:\n          do_lower_case: Whether to lower case the input.\n        \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer.tokenize": [[186, 206], ["tokenization.BasicTokenizer._clean_text", "tokenization.BasicTokenizer._tokenize_chinese_chars", "tokenization.whitespace_tokenize", "tokenization.whitespace_tokenize", "split_tokens.extend", "tokenization.BasicTokenizer.lower", "tokenization.BasicTokenizer._run_strip_accents", "tokenization.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "self", ".", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents": [[207, 217], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc": [[218, 239], ["list", "len", "tokenization._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "text", "in", "self", ".", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars": [[240, 252], ["ord", "tokenization.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char": [[253, 274], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text": [[275, 287], ["ord", "tokenization._is_whitespace", "tokenization._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__": [[291, 295], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize": [[296, 346], ["tokenization.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.load_vocab": [[49, 62], ["collections.OrderedDict", "io.open", "reader.readline", "token.strip.strip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "index", "=", "0", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "token", "=", "reader", ".", "readline", "(", ")", "\n", "if", "not", "token", ":", "\n", "                ", "break", "\n", "", "token", "=", "token", ".", "strip", "(", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize": [[63, 70], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_whitespace": [[347, 357], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_control": [[358, 368], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization._is_punctuation": [[369, 383], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.__main__.main": [[1, 81], ["print", "len", "len", "len", "print", "sys.argv.pop", "sys.argv.pop", "sys.argv.pop", "convert_tf_checkpoint_to_pytorch", "convert_openai_checkpoint_to_pytorch", "print", "len", "convert_transfo_xl_checkpoint_to_pytorch", "convert_gpt2_checkpoint_to_pytorch", "sys.argv[].lower", "len", "len", "print", "print"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_openai_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_transfo_xl_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_gpt2_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch"], ["def", "main", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "if", "(", "len", "(", "sys", ".", "argv", ")", "!=", "4", "and", "len", "(", "sys", ".", "argv", ")", "!=", "5", ")", "or", "sys", ".", "argv", "[", "1", "]", "not", "in", "[", "\n", "\"convert_tf_checkpoint_to_pytorch\"", ",", "\n", "\"convert_openai_checkpoint\"", ",", "\n", "\"convert_transfo_xl_checkpoint\"", ",", "\n", "\"convert_gpt2_checkpoint\"", ",", "\n", "]", ":", "\n", "        ", "print", "(", "\n", "\"Should be used as one of: \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT`, \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_openai_checkpoint OPENAI_GPT_CHECKPOINT_FOLDER_PATH PYTORCH_DUMP_OUTPUT [OPENAI_GPT_CONFIG]`, \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_transfo_xl_checkpoint TF_CHECKPOINT_OR_DATASET PYTORCH_DUMP_OUTPUT [TF_CONFIG]` or \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_gpt2_checkpoint TF_CHECKPOINT PYTORCH_DUMP_OUTPUT [GPT2_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "sys", ".", "argv", "[", "1", "]", "==", "\"convert_tf_checkpoint_to_pytorch\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_tf_checkpoint_to_pytorch", "import", "convert_tf_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_pretrained_bert can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "!=", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT`\"", ")", "\n", "", "else", ":", "\n", "                ", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CONFIG", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CHECKPOINT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "convert_tf_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"convert_openai_checkpoint\"", ":", "\n", "            ", "from", ".", "convert_openai_checkpoint_to_pytorch", "import", "convert_openai_checkpoint_to_pytorch", "\n", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                ", "OPENAI_GPT_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                ", "OPENAI_GPT_CONFIG", "=", "\"\"", "\n", "", "convert_openai_checkpoint_to_pytorch", "(", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", ",", "\n", "OPENAI_GPT_CONFIG", ",", "\n", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"convert_transfo_xl_checkpoint\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_transfo_xl_checkpoint_to_pytorch", "import", "convert_transfo_xl_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_pretrained_bert can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "'ckpt'", "in", "sys", ".", "argv", "[", "2", "]", ".", "lower", "(", ")", ":", "\n", "                ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_DATASET_FILE", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "TF_DATASET_FILE", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_CHECKPOINT", "=", "\"\"", "\n", "", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_transfo_xl_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ",", "TF_DATASET_FILE", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_gpt2_checkpoint_to_pytorch", "import", "convert_gpt2_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_pretrained_bert can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_gpt2_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_gpt2_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch": [[15, 34], ["pytorch_pretrained_bert.modeling_gpt2.GPT2Model", "pytorch_pretrained_bert.modeling_gpt2.load_tf_weights_in_gpt2", "print", "torch.save", "print", "pytorch_pretrained_bert.modeling_gpt2.GPT2Config", "pytorch_pretrained_bert.modeling_gpt2.GPT2Config", "pytorch_pretrained_bert.modeling_gpt2.GPT2Model.state_dict", "io.open", "f.write", "pytorch_pretrained_bert.modeling_gpt2.GPT2Config.to_json_string"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.load_tf_weights_in_gpt2", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["def", "convert_gpt2_checkpoint_to_pytorch", "(", "gpt2_checkpoint_path", ",", "gpt2_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "gpt2_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "GPT2Config", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "GPT2Config", "(", "gpt2_config_file", ")", "\n", "", "model", "=", "GPT2Model", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_gpt2", "(", "model", ",", "gpt2_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.convert_transfo_xl_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch": [[31, 74], ["print", "torch.save", "corpus_dict_no_vocab.pop", "print", "torch.save", "os.path.abspath", "os.path.abspath", "print", "print", "pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel", "pytorch_pretrained_bert.modeling_transfo_xl.load_tf_weights_in_transfo_xl", "os.path.join", "os.path.join", "print", "torch.save", "print", "io.open", "pickle.load", "pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig", "pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig", "pytorch_pretrained_bert.modeling_transfo_xl.load_tf_weights_in_transfo_xl.state_dict", "io.open", "f.write", "str", "os.path.abspath", "os.path.abspath", "pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.to_json_string"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_transfo_xl.load_tf_weights_in_transfo_xl", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["def", "convert_transfo_xl_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "\n", "transfo_xl_config_file", ",", "\n", "pytorch_dump_folder_path", ",", "\n", "transfo_xl_dataset_file", ")", ":", "\n", "    ", "if", "transfo_xl_dataset_file", ":", "\n", "# Convert a pre-processed corpus (see original TensorFlow repo)", "\n", "        ", "with", "open", "(", "transfo_xl_dataset_file", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ",", "encoding", "=", "\"latin1\"", ")", "\n", "# Save vocabulary and dataset cache as Dictionaries (should be better than pickles for the long-term)", "\n", "", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "VOCAB_NAME", "\n", "print", "(", "\"Save vocabulary to {}\"", ".", "format", "(", "pytorch_vocab_dump_path", ")", ")", "\n", "corpus_vocab_dict", "=", "corpus", ".", "vocab", ".", "__dict__", "\n", "torch", ".", "save", "(", "corpus_vocab_dict", ",", "pytorch_vocab_dump_path", ")", "\n", "\n", "corpus_dict_no_vocab", "=", "corpus", ".", "__dict__", "\n", "corpus_dict_no_vocab", ".", "pop", "(", "'vocab'", ",", "None", ")", "\n", "pytorch_dataset_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CORPUS_NAME", "\n", "print", "(", "\"Save dataset to {}\"", ".", "format", "(", "pytorch_dataset_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "corpus_dict_no_vocab", ",", "pytorch_dataset_dump_path", ")", "\n", "\n", "", "if", "tf_checkpoint_path", ":", "\n", "# Convert a pre-trained TensorFlow model", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "abspath", "(", "transfo_xl_config_file", ")", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "\n", "print", "(", "\"Converting Transformer XL checkpoint from {} with config at {}\"", ".", "format", "(", "tf_path", ",", "config_path", ")", ")", "\n", "# Initialise PyTorch model", "\n", "if", "transfo_xl_config_file", "==", "\"\"", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", ")", "\n", "", "else", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", "transfo_xl_config_file", ")", "\n", "", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "TransfoXLLMHeadModel", "(", "config", ")", "\n", "\n", "model", "=", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.__init__": [[114, 175], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "40478", ",", "\n", "n_special", "=", "0", ",", "\n", "n_positions", "=", "512", ",", "\n", "n_ctx", "=", "512", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "afn", "=", "\"gelu\"", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs OpenAIGPTConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `OpenAIGPTModel` or a configuration json file.\n            n_special: The number of special tokens to learn during fine-tuning ('[SEP]', '[CLF]', ...)\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            afn: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            resid_pdrop: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attn_pdrop: The dropout ratio for the attention\n                probabilities.\n            embd_pdrop: The dropout ratio for the embeddings.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "n_special", "=", "n_special", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "afn", "=", "afn", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.total_tokens_embeddings": [[178, 181], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "total_tokens_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "+", "self", ".", "n_special", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict": [[182, 189], ["modeling_openai.OpenAIGPTConfig", "json_object.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `OpenAIGPTConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "OpenAIGPTConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file": [[190, 196], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `OpenAIGPTConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.__repr__": [[197, 199], ["str", "modeling_openai.OpenAIGPTConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict": [[200, 204], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string": [[205, 208], ["json.dumps", "modeling_openai.OpenAIGPTConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Conv1D.__init__": [[210, 221], ["torch.Module.__init__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.normal_", "torch.init.normal_", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "rf", ",", "nx", ")", ":", "\n", "        ", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rf", "=", "rf", "\n", "self", ".", "nf", "=", "nf", "\n", "if", "rf", "==", "1", ":", "# faster 1x1 conv", "\n", "            ", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "", "else", ":", "# was used to train LM", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Conv1D.forward": [[222, 230], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "rf", "==", "1", ":", "\n", "            ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.__init__": [[232, 245], ["torch.Module.__init__", "modeling_openai.Attention.register_buffer", "modeling_openai.Conv1D", "modeling_openai.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "1", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention._attn": [[246, 258], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_openai.Attention.attn_dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.Softmax", "torch.Softmax", "math.sqrt", "v.size", "modeling_openai.Attention.size", "modeling_openai.Attention.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "# w = w * self.bias + -1e9 * (1 - self.bias)  # TF implem method: mask_attn_weights", "\n", "# XD: self.b may be larger than w, so we need to crop it", "\n", "", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", ":", "w", ".", "size", "(", "-", "2", ")", ",", ":", "w", ".", "size", "(", "-", "1", ")", "]", "\n", "w", "=", "w", "*", "b", "+", "-", "1e9", "*", "(", "1", "-", "b", ")", "\n", "\n", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "return", "torch", ".", "matmul", "(", "w", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.merge_heads": [[259, 263], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads": [[264, 271], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.forward": [[272, 283], ["modeling_openai.Attention.c_attn", "modeling_openai.Attention.split", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention._attn", "modeling_openai.Attention.merge_heads", "modeling_openai.Attention.c_proj", "modeling_openai.Attention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "a", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ")", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.MLP.__init__": [[285, 292], ["torch.Module.__init__", "modeling_openai.Conv1D", "modeling_openai.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "1", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT_FNS", "[", "config", ".", "afn", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.MLP.forward": [[293, 297], ["modeling_openai.MLP.act", "modeling_openai.MLP.c_proj", "modeling_openai.MLP.dropout", "modeling_openai.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Block.__init__": [[299, 306], ["torch.Module.__init__", "modeling_openai.Attention", "modeling.BertLayerNorm", "modeling_openai.MLP", "modeling.BertLayerNorm"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.Block.forward": [[307, 313], ["modeling_openai.Block.attn", "modeling_openai.Block.ln_1", "modeling_openai.Block.mlp", "modeling_openai.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "a", "=", "self", ".", "attn", "(", "x", ")", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.__init__": [[317, 321], ["torch.Module.__init__", "modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["def", "__init__", "(", "self", ",", "model_embeddings_weights", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "self", ".", "set_embeddings_weights", "(", "model_embeddings_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights": [[322, 326], ["torch.Linear", "torch.Linear"], "methods", ["None"], ["", "def", "set_embeddings_weights", "(", "self", ",", "model_embeddings_weights", ")", ":", "\n", "        ", "embed_shape", "=", "model_embeddings_weights", ".", "shape", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "embed_shape", "[", "1", "]", ",", "embed_shape", "[", "0", "]", ",", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "model_embeddings_weights", "# Tied weights", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.forward": [[327, 332], ["modeling_openai.OpenAIGPTLMHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_state", ")", ":", "\n", "# Truncated Language modeling logits (we remove the last token)", "\n", "# h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)", "\n", "        ", "lm_logits", "=", "self", ".", "decoder", "(", "hidden_state", ")", "\n", "return", "lm_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTMultipleChoiceHead.__init__": [[336, 345], ["torch.Module.__init__", "torch.Dropout2d", "torch.Dropout2d", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTMultipleChoiceHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "# self.multiple_choice_token = multiple_choice_token", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout2d", "(", "config", ".", "resid_pdrop", ")", "# To reproduce the noise_shape parameter of TF implementation", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "1", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTMultipleChoiceHead.forward": [[346, 358], ["mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand", "hidden_states.gather().squeeze", "modeling_openai.OpenAIGPTMultipleChoiceHead.dropout().transpose", "modeling_openai.OpenAIGPTMultipleChoiceHead.linear().squeeze", "hidden_states.size", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze", "hidden_states.gather", "modeling_openai.OpenAIGPTMultipleChoiceHead.dropout", "modeling_openai.OpenAIGPTMultipleChoiceHead.linear", "modeling_openai.OpenAIGPTMultipleChoiceHead.transpose", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "mc_token_ids", ")", ":", "\n", "# Classification logits", "\n", "# hidden_state (bsz, num_choices, seq_length, hidden_size)", "\n", "# mc_token_ids (bsz, num_choices)", "\n", "        ", "mc_token_ids", "=", "mc_token_ids", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "hidden_states", ".", "size", "(", "-", "1", ")", ")", "\n", "# (bsz, num_choices, 1, hidden_size)", "\n", "multiple_choice_h", "=", "hidden_states", ".", "gather", "(", "2", ",", "mc_token_ids", ")", ".", "squeeze", "(", "2", ")", "\n", "# (bsz, num_choices, hidden_size)", "\n", "multiple_choice_h", "=", "self", ".", "dropout", "(", "multiple_choice_h", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "multiple_choice_logits", "=", "self", ".", "linear", "(", "multiple_choice_h", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# (bsz, num_choices)", "\n", "return", "multiple_choice_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.__init__": [[364, 375], ["torch.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTPreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "OpenAIGPTConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `OpenAIGPTConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.init_weights": [[376, 388], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.set_num_special_tokens": [[389, 391], ["None"], "methods", ["None"], ["", "", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.from_pretrained": [[392, 511], ["modeling_openai.OpenAIGPTConfig.from_json_file", "logger.info", "cls", "torch.load.keys", "torch.load.keys", "zip", "getattr", "torch.load.copy", "torch.load.copy", "modeling_openai.OpenAIGPTPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "pretrained_model_name_or_path", ",", "num_special_tokens", "=", "None", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a OpenAIGPTPreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `openai-gpt`\n                - a path or url to a pretrained model archive containing:\n                    . `openai_gpt_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a OpenAIGPTModel instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . a series of NumPy files containing OpenAI TensorFlow trained weights\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "config_file", "=", "PRETRAINED_CONFIG_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\", \"", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "pretrained_model_name_or_path", ",", "\n", "archive_file", ",", "config_file", "\n", ")", "\n", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", "and", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "# Load config", "\n", "", "config", "=", "OpenAIGPTConfig", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint (stored as NumPy array)", "\n", "            ", "return", "load_tf_weights_in_openai_gpt", "(", "model", ",", "resolved_archive_file", ")", "\n", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "key", ".", "endswith", "(", "\".g\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".weight\"", "\n", "", "elif", "key", ".", "endswith", "(", "\".b\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".bias\"", "\n", "", "elif", "key", ".", "endswith", "(", "\".w\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".weight\"", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "\"_metadata\"", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "\"\"", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "\".\"", ")", "\n", "\n", "", "", "", "start_model", "=", "model", "\n", "if", "hasattr", "(", "model", ",", "\"transformer\"", ")", "and", "all", "(", "not", "s", ".", "startswith", "(", "'transformer.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_model", "=", "model", ".", "transformer", "\n", "", "load", "(", "start_model", ",", "prefix", "=", "\"\"", ")", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error(s) in loading state_dict for {}:\\n\\t{}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", "\n", ")", "\n", "\n", "# Add additional embeddings for special tokens if needed", "\n", "# This step also make sure we are still sharing the output and input embeddings after loading weights", "\n", "", "model", ".", "set_num_special_tokens", "(", "num_special_tokens", "if", "num_special_tokens", "is", "not", "None", "else", "config", ".", "n_special", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.__init__": [[563, 573], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "modeling_openai.Block", "torch.ModuleList", "torch.ModuleList", "modeling_openai.OpenAIGPTModel.apply", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "num_tokens", "=", "config", ".", "vocab_size", "+", "config", ".", "n_special", "\n", "self", ".", "tokens_embed", "=", "nn", ".", "Embedding", "(", "num_tokens", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "positions_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "block", "=", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "block", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "# nn.init.normal_(self.embed.weight, std=0.02)", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.set_num_special_tokens": [[575, 589], ["torch.Embedding", "torch.Embedding", "modeling_openai.OpenAIGPTModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.init_weights"], ["", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "\" Update input embeddings with new embedding matrice if needed \"", "\n", "if", "self", ".", "config", ".", "n_special", "==", "num_special_tokens", ":", "\n", "            ", "return", "\n", "# Update config", "\n", "", "self", ".", "config", ".", "n_special", "=", "num_special_tokens", "\n", "# # Build new embeddings and initialize", "\n", "old_embed", "=", "self", ".", "tokens_embed", "\n", "self", ".", "tokens_embed", "=", "nn", ".", "Embedding", "(", "self", ".", "config", ".", "total_tokens_embeddings", ",", "self", ".", "config", ".", "n_embd", ")", "\n", "# Initialize all new embeddings (in particular the special tokens)", "\n", "self", ".", "init_weights", "(", "self", ".", "tokens_embed", ")", "\n", "# Copy word and positional embeddings from the previous weights", "\n", "self", ".", "tokens_embed", ".", "weight", ".", "data", "[", ":", "self", ".", "config", ".", "vocab_size", ",", ":", "]", "=", "old_embed", ".", "weight", ".", "data", "[", ":", "self", ".", "config", ".", "vocab_size", ",", ":", "]", "\n", "self", ".", "tokens_embed", ".", "weight", ".", "data", "[", "-", "self", ".", "config", ".", "n_positions", ":", ",", ":", "]", "=", "old_embed", ".", "weight", ".", "data", "[", "-", "self", ".", "config", ".", "n_positions", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.forward": [[590, 617], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "modeling_openai.OpenAIGPTModel.positions_embed", "block.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.size", "token_type_ids.view.view.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "block", "input_ids.view.view.size", "token_type_ids.view.view.size", "block.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "if", "position_ids", "is", "None", ":", "\n", "# This was used when we had a single embedding matrice from position and token embeddings", "\n", "# start = self.config.vocab_size + self.config.n_special", "\n", "# end = start + input_ids.size(-1)", "\n", "# position_ids = torch.arange(start, end, dtype=torch.long, device=input_ids.device)", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "input_ids", ".", "size", "(", "-", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "tokens_embed", "(", "input_ids", ")", "\n", "position_embeds", "=", "self", ".", "positions_embed", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "token_type_embeds", "=", "self", ".", "tokens_embed", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "# Add the position information to the input embeddings", "\n", "# h = e.sum(dim=2)", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "for", "block", "in", "self", ".", "h", ":", "\n", "            ", "hidden_states", "=", "block", "(", "hidden_states", ")", "\n", "", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHeadModel.__init__": [[674, 679], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "modeling_openai.OpenAIGPTLMHead", "modeling_openai.OpenAIGPTLMHeadModel.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "OpenAIGPTLMHead", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ",", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHeadModel.set_num_special_tokens": [[680, 686], ["modeling_openai.OpenAIGPTLMHeadModel.transformer.set_num_special_tokens", "modeling_openai.OpenAIGPTLMHeadModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.set_num_special_tokens", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "\"\"\" Update input and output embeddings with new embedding matrice\n            Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "transformer", ".", "set_num_special_tokens", "(", "num_special_tokens", ")", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHeadModel.forward": [[687, 695], ["modeling_openai.OpenAIGPTLMHeadModel.transformer", "modeling_openai.OpenAIGPTLMHeadModel.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_openai.OpenAIGPTLMHeadModel.view", "lm_labels.view", "modeling_openai.OpenAIGPTLMHeadModel.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "lm_labels", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "return", "lm_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.__init__": [[757, 763], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "modeling_openai.OpenAIGPTLMHead", "modeling_openai.OpenAIGPTMultipleChoiceHead", "modeling_openai.OpenAIGPTDoubleHeadsModel.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTDoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "OpenAIGPTLMHead", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ",", "config", ")", "\n", "self", ".", "multiple_choice_head", "=", "OpenAIGPTMultipleChoiceHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.set_num_special_tokens": [[764, 770], ["modeling_openai.OpenAIGPTDoubleHeadsModel.transformer.set_num_special_tokens", "modeling_openai.OpenAIGPTDoubleHeadsModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.set_num_special_tokens", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "\"\"\" Update input and output embeddings with new embedding matrice\n            Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "transformer", ".", "set_num_special_tokens", "(", "num_special_tokens", ")", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.forward": [[771, 785], ["modeling_openai.OpenAIGPTDoubleHeadsModel.transformer", "modeling_openai.OpenAIGPTDoubleHeadsModel.lm_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_openai.OpenAIGPTDoubleHeadsModel.view", "lm_labels.view", "modeling_openai.OpenAIGPTDoubleHeadsModel.view", "mc_labels.view", "modeling_openai.OpenAIGPTDoubleHeadsModel.size", "modeling_openai.OpenAIGPTDoubleHeadsModel.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mc_token_ids", ",", "lm_labels", "=", "None", ",", "mc_labels", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", "\n", "losses", "=", "[", "]", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "losses", ".", "append", "(", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "losses", ".", "append", "(", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "", "if", "losses", ":", "\n", "            ", "return", "losses", "\n", "", "return", "lm_logits", ",", "mc_logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.load_tf_weights_in_openai_gpt": [[33, 101], ["print", "json.load", "json.load", "np.cumsum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "json.load.pop", "init_params.pop", "init_params.pop", "zip", "io.open", "io.open", "np.load", "np.split", "param.reshape", "arr.squeeze", "name.split.split", "print", "torch.from_numpy", "torch.from_numpy", "np.prod", "range", "np.concatenate", "zip", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_openai_gpt", "(", "model", ",", "openai_checkpoint_folder_path", ")", ":", "\n", "    ", "\"\"\" Load tf pre-trained weights in a pytorch model (from NumPy arrays here)\n    \"\"\"", "\n", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "print", "(", "\"Loading weights...\"", ")", "\n", "names", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/parameters_names.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "shapes", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/params_shapes.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "offsets", "=", "np", ".", "cumsum", "(", "[", "np", ".", "prod", "(", "shape", ")", "for", "shape", "in", "shapes", "]", ")", "\n", "init_params", "=", "[", "np", ".", "load", "(", "openai_checkpoint_folder_path", "+", "'/params_{}.npy'", ".", "format", "(", "n", ")", ")", "for", "n", "in", "range", "(", "10", ")", "]", "\n", "init_params", "=", "np", ".", "split", "(", "np", ".", "concatenate", "(", "init_params", ",", "0", ")", ",", "offsets", ")", "[", ":", "-", "1", "]", "\n", "init_params", "=", "[", "param", ".", "reshape", "(", "shape", ")", "for", "param", ",", "shape", "in", "zip", "(", "init_params", ",", "shapes", ")", "]", "\n", "\n", "# This was used when we had a single embedding matrix for positions and tokens", "\n", "# init_params[0] = np.concatenate([init_params[1], init_params[0]], 0)", "\n", "# del init_params[1]", "\n", "init_params", "=", "[", "arr", ".", "squeeze", "(", ")", "for", "arr", "in", "init_params", "]", "\n", "\n", "try", ":", "\n", "        ", "assert", "model", ".", "tokens_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "1", "]", ".", "shape", "\n", "assert", "model", ".", "positions_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "0", "]", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "e", ".", "args", "+=", "(", "model", ".", "tokens_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "1", "]", ".", "shape", ")", "\n", "e", ".", "args", "+=", "(", "model", ".", "positions_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "0", "]", ".", "shape", ")", "\n", "raise", "\n", "\n", "", "model", ".", "tokens_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "1", "]", ")", "\n", "model", ".", "positions_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "0", "]", ")", "\n", "names", ".", "pop", "(", "0", ")", "\n", "# Pop position and token embedding arrays", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "\n", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "init_params", ")", ":", "# names[1:n_transfer], init_params[1:n_transfer]):", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "assert", "name", "[", "-", "2", ":", "]", "==", "\":0\"", "\n", "name", "=", "name", "[", ":", "-", "2", "]", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'g'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'b'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'w'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.gelu": [[102, 104], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_openai.swish": [[105, 107], ["torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.__init__": [[54, 73], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "schedule", "=", "'warmup_linear'", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-8", ",", "weight_decay", "=", "0", ",", "\n", "vector_l2", "=", "False", ",", "max_grad_norm", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {}\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {}\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "vector_l2", "=", "vector_l2", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "OpenAIAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.get_lr": [[74, 88], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.step": [[89, 160], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "schedule_fct", "logger.warning", "math.sqrt", "len", "p.size"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "warned_for_t_total", "=", "False", "\n", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'e'", "]", ")", "\n", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "\n", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "progress", "=", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "progress", ",", "group", "[", "'warmup'", "]", ")", "\n", "# warning for exceeding t_total (only active with warmup_linear", "\n", "if", "group", "[", "'schedule'", "]", "==", "\"warmup_linear\"", "and", "progress", ">", "1.", "and", "not", "warned_for_t_total", ":", "\n", "                        ", "logger", ".", "warning", "(", "\n", "\"Training beyond specified 't_total' steps with schedule '{}'. Learning rate set to {}. \"", "\n", "\"Please set 't_total' of {} correctly.\"", ".", "format", "(", "group", "[", "'schedule'", "]", ",", "lr_scheduled", ",", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "warned_for_t_total", "=", "True", "\n", "# end warning", "\n", "", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "step_size", "=", "lr_scheduled", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "(", "len", "(", "p", ".", "size", "(", ")", ")", ">", "1", "or", "group", "[", "'vector_l2'", "]", ")", "and", "group", "[", "'weight_decay'", "]", ">", "0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "lr_scheduled", "*", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.warmup_cosine": [[26, 30], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "0.5", "*", "(", "1.0", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.warmup_constant": [[31, 37], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "\"\"\" Linearly increases learning rate over `warmup`*`t_total` (as provided to OpenAIAdam) training steps.\n        Learning rate is 1. afterwards. \"\"\"", "\n", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.warmup_linear": [[38, 44], ["max"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "\"\"\" Specifies a triangular learning rate schedule where peak is reached at `warmup`*`t_total`-th (as provided to OpenAIAdam) training step.\n        After `t_total`-th training step, learning rate is zero. \"\"\"", "\n", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "max", "(", "(", "x", "-", "1.", ")", "/", "(", "warmup", "-", "1.", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.from_pretrained": [[80, 122], ["cls", "os.path.join", "os.path.join", "file_utils.cached_path", "file_utils.cached_path", "logger.info", "logger.info", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.file_utils.cached_path"], ["@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "merges_file", "=", "PRETRAINED_MERGES_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "VOCAB_NAME", ")", "\n", "merges_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "MERGES_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_merges_file", "=", "cached_path", "(", "merges_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "vocab_file", ",", "merges_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", "and", "resolved_merges_file", "==", "merges_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {}\"", ".", "format", "(", "merges_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {} from cache at {}\"", ".", "format", "(", "\n", "merges_file", ",", "resolved_merges_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "resolved_merges_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.__init__": [[123, 143], ["json.load", "dict", "tokenization_openai.OpenAIGPTTokenizer.set_special_tokens", "spacy.load", "int", "io.open", "io.open().read().split", "tuple", "zip", "logger.warning", "tokenization.BasicTokenizer", "tokenization_openai.OpenAIGPTTokenizer.encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.set_special_tokens"], ["", "def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "special_tokens", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "ftfy", "\n", "import", "spacy", "\n", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en'", ",", "disable", "=", "[", "'parser'", ",", "'tagger'", ",", "'ner'", ",", "'textcat'", "]", ")", "\n", "self", ".", "fix_text", "=", "ftfy", ".", "fix_text", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"", ")", "\n", "self", ".", "nlp", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ",", "\n", "never_split", "=", "special_tokens", "if", "special_tokens", "is", "not", "None", "else", "[", "]", ")", "\n", "self", ".", "fix_text", "=", "None", "\n", "\n", "", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "set_special_tokens", "(", "special_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.__len__": [[144, 146], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "+", "len", "(", "self", ".", "special_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.set_special_tokens": [[147, 162], ["dict", "logger.info", "tokenization_openai.OpenAIGPTTokenizer.special_tokens.items", "enumerate", "len"], "methods", ["None"], ["", "def", "set_special_tokens", "(", "self", ",", "special_tokens", ")", ":", "\n", "        ", "\"\"\" Add a list of additional tokens to the encoder.\n            The additional tokens are indexed starting from the last index of the\n            current vocabulary in the order of the `special_tokens` list.\n        \"\"\"", "\n", "if", "not", "special_tokens", ":", "\n", "            ", "self", ".", "special_tokens", "=", "{", "}", "\n", "self", ".", "special_tokens_decoder", "=", "{", "}", "\n", "return", "\n", "", "self", ".", "special_tokens", "=", "dict", "(", "(", "tok", ",", "len", "(", "self", ".", "encoder", ")", "+", "i", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "special_tokens", ")", ")", "\n", "self", ".", "special_tokens_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "special_tokens", ".", "items", "(", ")", "}", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer: we can update the tokenizer", "\n", "            ", "self", ".", "nlp", ".", "never_split", "=", "special_tokens", "\n", "", "logger", ".", "info", "(", "\"Special tokens {}\"", ".", "format", "(", "self", ".", "special_tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.bpe": [[163, 205], ["tokenization_openai.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_openai.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "'\\n</w>'", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.tokenize": [[206, 220], ["tokenization_openai.OpenAIGPTTokenizer.nlp.tokenize", "tokenization_openai.OpenAIGPTTokenizer.nlp", "split_tokens.extend", "tokenization_openai.text_standardize", "split_tokens.extend", "tokenization_openai.OpenAIGPTTokenizer.fix_text", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe", "tokenization_openai.OpenAIGPTTokenizer.bpe", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.text_standardize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.bpe", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer", "\n", "            ", "text", "=", "self", ".", "nlp", ".", "tokenize", "(", "text", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "else", ":", "\n", "# Using SpaCy & ftfy (original tokenization process of OpenAI GPT)", "\n", "            ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "self", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_ids": [[221, 241], ["isinstance", "len", "logger.warning", "isinstance", "tokenization_openai.OpenAIGPTTokenizer.encoder.get", "ids.append", "ids.append", "tokenization_openai.OpenAIGPTTokenizer.encoder.get", "len"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens into ids using the vocab. \"\"\"", "\n", "ids", "=", "[", "]", "\n", "if", "isinstance", "(", "tokens", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "tokens", ",", "unicode", ")", ")", ":", "\n", "            ", "if", "tokens", "in", "self", ".", "special_tokens", ":", "\n", "                ", "return", "self", ".", "special_tokens", "[", "tokens", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "encoder", ".", "get", "(", "tokens", ",", "0", ")", "\n", "", "", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "token", "in", "self", ".", "special_tokens", ":", "\n", "                ", "ids", ".", "append", "(", "self", ".", "special_tokens", "[", "token", "]", ")", "\n", "", "else", ":", "\n", "                ", "ids", ".", "append", "(", "self", ".", "encoder", ".", "get", "(", "token", ",", "0", ")", ")", "\n", "", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this OpenAI GPT model ({} > {}). Running this\"", "\n", "\" sequence through the model will result in indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.convert_ids_to_tokens": [[242, 252], ["tokens.append", "tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in BPE tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "if", "i", "in", "self", ".", "special_tokens_decoder", ":", "\n", "                ", "if", "not", "skip_special_tokens", ":", "\n", "                    ", "tokens", ".", "append", "(", "self", ".", "special_tokens_decoder", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "decoder", "[", "i", "]", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode": [[253, 264], ["tokenization_openai.OpenAIGPTTokenizer.convert_ids_to_tokens", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.convert_ids_to_tokens"], ["", "def", "decode", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "False", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in a string.\"\"\"", "\n", "tokens", "=", "self", ".", "convert_ids_to_tokens", "(", "ids", ",", "skip_special_tokens", "=", "skip_special_tokens", ")", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "if", "clean_up_tokenization_spaces", ":", "\n", "            ", "out_string", "=", "out_string", ".", "replace", "(", "'<unk>'", ",", "''", ")", "\n", "out_string", "=", "out_string", ".", "replace", "(", "' .'", ",", "'.'", ")", ".", "replace", "(", "' ?'", ",", "'?'", ")", ".", "replace", "(", "' !'", ",", "'!'", ")", ".", "replace", "(", "' ,'", ",", "','", ")", ".", "replace", "(", "' ,'", ",", "','", "\n", ")", ".", "replace", "(", "\" n't\"", ",", "\"n't\"", ")", ".", "replace", "(", "\" 'm\"", ",", "\"'m\"", ")", ".", "replace", "(", "\" 're\"", ",", "\"'re\"", ")", ".", "replace", "(", "\" do not\"", ",", "\" don't\"", "\n", ")", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "\" t \"", ",", "\"'t \"", ")", ".", "replace", "(", "\" s \"", ",", "\"'s \"", ")", ".", "replace", "(", "\" m \"", ",", "\"'m \"", "\n", ")", ".", "replace", "(", "\" 've\"", ",", "\"'ve\"", ")", "\n", "", "return", "out_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.get_pairs": [[45, 56], ["set", "set.add"], "function", ["None"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.text_standardize": [[57, 71], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "'\u2014'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2013'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2015'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u00b4'", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)'''", ",", "r' \\1 '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\s*\\n\\s*'", ",", "' \\n '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^\\S\\n]+'", ",", "' '", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.__init__": [[10, 17], ["coco.getImgIds"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "coco", ",", "cocoRes", ")", ":", "\n", "        ", "self", ".", "evalImgs", "=", "[", "]", "\n", "self", ".", "eval", "=", "{", "}", "\n", "self", ".", "imgToEval", "=", "{", "}", "\n", "self", ".", "coco", "=", "coco", "\n", "self", ".", "cocoRes", "=", "cocoRes", "\n", "self", ".", "params", "=", "{", "'image_id'", ":", "coco", ".", "getImgIds", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.evaluate": [[18, 62], ["print", "tokenizer.ptbtokenizer.PTBTokenizer.ptbtokenizer.PTBTokenizer", "tokenizer.ptbtokenizer.PTBTokenizer.ptbtokenizer.PTBTokenizer.tokenize", "tokenizer.ptbtokenizer.PTBTokenizer.ptbtokenizer.PTBTokenizer.tokenize", "print", "eval.COCOEvalCap.setEvalImgs", "print", "scorer.compute_score", "bleu.bleu.Bleu", "meteor.meteor.Meteor", "rouge.rouge.Rouge", "cider.cider.Cider", "type", "zip", "eval.COCOEvalCap.setEval", "eval.COCOEvalCap.setImgToEvalImgs", "print", "scorer.method", "eval.COCOEvalCap.setEval", "eval.COCOEvalCap.setImgToEvalImgs", "print", "tokenizer.ptbtokenizer.PTBTokenizer.tokenize.keys", "tokenizer.ptbtokenizer.PTBTokenizer.tokenize.keys"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setEvalImgs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setEval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setImgToEvalImgs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.method", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setEval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setImgToEvalImgs"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "imgIds", "=", "self", ".", "params", "[", "'image_id'", "]", "\n", "# imgIds = self.coco.getImgIds()", "\n", "gts", "=", "{", "}", "\n", "res", "=", "{", "}", "\n", "for", "imgId", "in", "imgIds", ":", "\n", "            ", "gts", "[", "imgId", "]", "=", "self", ".", "coco", ".", "imgToAnns", "[", "imgId", "]", "\n", "res", "[", "imgId", "]", "=", "self", ".", "cocoRes", ".", "imgToAnns", "[", "imgId", "]", "\n", "\n", "# =================================================", "\n", "# Set up scorers", "\n", "# =================================================", "\n", "", "print", "(", "'tokenization...'", ")", "\n", "tokenizer", "=", "PTBTokenizer", "(", ")", "\n", "gts", "=", "tokenizer", ".", "tokenize", "(", "gts", ")", "\n", "res", "=", "tokenizer", ".", "tokenize", "(", "res", ")", "\n", "\n", "# =================================================", "\n", "# Set up scorers", "\n", "# =================================================", "\n", "print", "(", "'setting up scorers...'", ")", "\n", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", ",", "\n", "(", "Meteor", "(", ")", ",", "\"METEOR\"", ")", ",", "\n", "(", "Rouge", "(", ")", ",", "\"ROUGE_L\"", ")", ",", "\n", "(", "Cider", "(", ")", ",", "\"CIDEr\"", ")", "\n", "]", "\n", "\n", "# =================================================", "\n", "# Compute scores", "\n", "# =================================================", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "            ", "print", "(", "'computing %s score...'", "%", "(", "scorer", ".", "method", "(", ")", ")", ")", "\n", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "gts", ",", "res", ")", "\n", "if", "type", "(", "method", ")", "==", "list", ":", "\n", "                ", "for", "sc", ",", "scs", ",", "m", "in", "zip", "(", "score", ",", "scores", ",", "method", ")", ":", "\n", "                    ", "self", ".", "setEval", "(", "sc", ",", "m", ")", "\n", "self", ".", "setImgToEvalImgs", "(", "scs", ",", "gts", ".", "keys", "(", ")", ",", "m", ")", "\n", "print", "(", "\"%s: %0.3f\"", "%", "(", "m", ",", "sc", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "setEval", "(", "score", ",", "method", ")", "\n", "self", ".", "setImgToEvalImgs", "(", "scores", ",", "gts", ".", "keys", "(", ")", ",", "method", ")", "\n", "print", "(", "\"%s: %0.3f\"", "%", "(", "method", ",", "score", ")", ")", "\n", "", "", "self", ".", "setEvalImgs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setEval": [[63, 65], ["None"], "methods", ["None"], ["", "def", "setEval", "(", "self", ",", "score", ",", "method", ")", ":", "\n", "        ", "self", ".", "eval", "[", "method", "]", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setImgToEvalImgs": [[66, 72], ["zip"], "methods", ["None"], ["", "def", "setImgToEvalImgs", "(", "self", ",", "scores", ",", "imgIds", ",", "method", ")", ":", "\n", "        ", "for", "imgId", ",", "score", "in", "zip", "(", "imgIds", ",", "scores", ")", ":", "\n", "            ", "if", "not", "imgId", "in", "self", ".", "imgToEval", ":", "\n", "                ", "self", ".", "imgToEval", "[", "imgId", "]", "=", "{", "}", "\n", "self", ".", "imgToEval", "[", "imgId", "]", "[", "\"image_id\"", "]", "=", "imgId", "\n", "", "self", ".", "imgToEval", "[", "imgId", "]", "[", "method", "]", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.pycocoevalcap.eval.COCOEvalCap.setEvalImgs": [[73, 75], ["eval.COCOEvalCap.imgToEval.items"], "methods", ["None"], ["", "", "def", "setEvalImgs", "(", "self", ")", ":", "\n", "        ", "self", ".", "evalImgs", "=", "[", "eval", "for", "imgId", ",", "eval", "in", "self", ".", "imgToEval", ".", "items", "(", ")", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu.Bleu.__init__": [[5, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n", "=", "4", ")", ":", "\n", "# default compute Blue score up to 4", "\n", "        ", "self", ".", "_n", "=", "n", "\n", "self", ".", "_hypo_for_image", "=", "{", "}", "\n", "self", ".", "ref_for_image", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu.Bleu.compute_score": [[11, 36], ["gts.keys", "bleu_scorer.BleuScorer.BleuScorer", "bleu_scorer.BleuScorer.BleuScorer.compute_score", "gts.keys", "res.keys", "type", "len", "type"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "\n", "        ", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "self", ".", "_n", ")", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "#print(ref)", "\n", "#assert(len(ref) > 1)", "\n", "\n", "bleu_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "#score, scores = bleu_scorer.compute_score(option='shortest')", "\n", "", "score", ",", "scores", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ",", "verbose", "=", "1", ")", "\n", "#score, scores = bleu_scorer.compute_score(option='average', verbose=1)", "\n", "\n", "# return (bleu, bleu_info)", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu.Bleu.method": [[37, 39], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"Bleu\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.copy": [[80, 87], ["bleu_scorer.BleuScorer", "copy.copy", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy"], ["def", "copy", "(", "self", ")", ":", "\n", "        ", "''' copy the refs.'''", "\n", "new", "=", "BleuScorer", "(", "n", "=", "self", ".", "n", ")", "\n", "new", ".", "ctest", "=", "copy", ".", "copy", "(", "self", ".", "ctest", ")", "\n", "new", ".", "crefs", "=", "copy", ".", "copy", "(", "self", ".", "crefs", ")", "\n", "new", ".", "_score", "=", "None", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.__init__": [[88, 96], ["bleu_scorer.BleuScorer.cook_append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "special_reflen", "=", "None", ")", ":", "\n", "        ", "''' singular instance '''", "\n", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "self", ".", "cook_append", "(", "test", ",", "refs", ")", "\n", "self", ".", "special_reflen", "=", "special_reflen", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.cook_append": [[97, 109], ["bleu_scorer.BleuScorer.crefs.append", "bleu_scorer.cook_refs", "bleu_scorer.cook_test", "bleu_scorer.BleuScorer.ctest.append", "bleu_scorer.BleuScorer.ctest.append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.cook_refs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.cook_test"], ["", "def", "cook_append", "(", "self", ",", "test", ",", "refs", ")", ":", "\n", "        ", "'''called by constructor and __iadd__ to avoid creating new instances.'''", "\n", "\n", "if", "refs", "is", "not", "None", ":", "\n", "            ", "self", ".", "crefs", ".", "append", "(", "cook_refs", "(", "refs", ")", ")", "\n", "if", "test", "is", "not", "None", ":", "\n", "                ", "cooked_test", "=", "cook_test", "(", "test", ",", "self", ".", "crefs", "[", "-", "1", "]", ")", "\n", "self", ".", "ctest", ".", "append", "(", "cooked_test", ")", "## N.B.: -1", "\n", "", "else", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "None", ")", "# lens of crefs and ctest have to match", "\n", "\n", "", "", "self", ".", "_score", "=", "None", "## need to recompute", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.ratio": [[110, 113], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score"], ["", "def", "ratio", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "self", ".", "compute_score", "(", "option", "=", "option", ")", "\n", "return", "self", ".", "_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.score_ratio": [[114, 117], ["bleu_scorer.BleuScorer.fscore", "bleu_scorer.BleuScorer.ratio"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.ratio"], ["", "def", "score_ratio", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "'''return (bleu, len_ratio) pair'''", "\n", "return", "(", "self", ".", "fscore", "(", "option", "=", "option", ")", ",", "self", ".", "ratio", "(", "option", "=", "option", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.score_ratio_str": [[118, 120], ["bleu_scorer.BleuScorer.score_ratio"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.score_ratio"], ["", "def", "score_ratio_str", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "return", "\"%.4f (%.2f)\"", "%", "self", ".", "score_ratio", "(", "option", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.reflen": [[121, 124], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score"], ["", "def", "reflen", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "self", ".", "compute_score", "(", "option", "=", "option", ")", "\n", "return", "self", ".", "_reflen", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.testlen": [[125, 128], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score"], ["", "def", "testlen", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "self", ".", "compute_score", "(", "option", "=", "option", ")", "\n", "return", "self", ".", "_testlen", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.retest": [[129, 139], ["zip", "type", "len", "len", "bleu_scorer.BleuScorer.ctest.append", "bleu_scorer.cook_test"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.cook_test"], ["", "def", "retest", "(", "self", ",", "new_test", ")", ":", "\n", "        ", "if", "type", "(", "new_test", ")", "is", "str", ":", "\n", "            ", "new_test", "=", "[", "new_test", "]", "\n", "", "assert", "len", "(", "new_test", ")", "==", "len", "(", "self", ".", "crefs", ")", ",", "new_test", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "for", "t", ",", "rs", "in", "zip", "(", "new_test", ",", "self", ".", "crefs", ")", ":", "\n", "            ", "self", ".", "ctest", ".", "append", "(", "cook_test", "(", "t", ",", "rs", ")", ")", "\n", "", "self", ".", "_score", "=", "None", "\n", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.rescore": [[140, 144], ["bleu_scorer.BleuScorer.retest().compute_score", "bleu_scorer.BleuScorer.retest"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score", "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.retest"], ["", "def", "rescore", "(", "self", ",", "new_test", ")", ":", "\n", "        ", "''' replace test(s) with new test(s), and returns the new score.'''", "\n", "\n", "return", "self", ".", "retest", "(", "new_test", ")", ".", "compute_score", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.size": [[145, 148], ["len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "crefs", ")", "==", "len", "(", "self", ".", "ctest", ")", ",", "\"refs/test mismatch! %d<>%d\"", "%", "(", "len", "(", "self", ".", "crefs", ")", ",", "len", "(", "self", ".", "ctest", ")", ")", "\n", "return", "len", "(", "self", ".", "crefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.__iadd__": [[149, 162], ["type", "bleu_scorer.BleuScorer.cook_append", "bleu_scorer.BleuScorer.compatible", "bleu_scorer.BleuScorer.ctest.extend", "bleu_scorer.BleuScorer.crefs.extend"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.cook_append", "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.compatible"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "'''add an instance (e.g., from another sentence).'''", "\n", "\n", "if", "type", "(", "other", ")", "is", "tuple", ":", "\n", "## avoid creating new BleuScorer instances", "\n", "            ", "self", ".", "cook_append", "(", "other", "[", "0", "]", ",", "other", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "compatible", "(", "other", ")", ",", "\"incompatible BLEUs.\"", "\n", "self", ".", "ctest", ".", "extend", "(", "other", ".", "ctest", ")", "\n", "self", ".", "crefs", ".", "extend", "(", "other", ".", "crefs", ")", "\n", "self", ".", "_score", "=", "None", "## need to recompute", "\n", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.compatible": [[163, 165], ["isinstance"], "methods", ["None"], ["", "def", "compatible", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "isinstance", "(", "other", ",", "BleuScorer", ")", "and", "self", ".", "n", "==", "other", ".", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.single_reflen": [[166, 168], ["bleu_scorer.BleuScorer._single_reflen"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer._single_reflen"], ["", "def", "single_reflen", "(", "self", ",", "option", "=", "\"average\"", ")", ":", "\n", "        ", "return", "self", ".", "_single_reflen", "(", "self", ".", "crefs", "[", "0", "]", "[", "0", "]", ",", "option", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer._single_reflen": [[169, 181], ["min", "float", "len", "sum", "min", "abs"], "methods", ["None"], ["", "def", "_single_reflen", "(", "self", ",", "reflens", ",", "option", "=", "None", ",", "testlen", "=", "None", ")", ":", "\n", "\n", "        ", "if", "option", "==", "\"shortest\"", ":", "\n", "            ", "reflen", "=", "min", "(", "reflens", ")", "\n", "", "elif", "option", "==", "\"average\"", ":", "\n", "            ", "reflen", "=", "float", "(", "sum", "(", "reflens", ")", ")", "/", "len", "(", "reflens", ")", "\n", "", "elif", "option", "==", "\"closest\"", ":", "\n", "            ", "reflen", "=", "min", "(", "(", "abs", "(", "l", "-", "testlen", ")", ",", "l", ")", "for", "l", "in", "reflens", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"unsupported reflen option %s\"", "%", "option", "\n", "\n", "", "return", "reflen", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.recompute_score": [[182, 185], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score"], ["", "def", "recompute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "self", ".", "_score", "=", "None", "\n", "return", "self", ".", "compute_score", "(", "option", ",", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer.compute_score": [[186, 252], ["range", "range", "bleus.append", "range", "range", "bleu_scorer.BleuScorer._single_reflen", "range", "bleu_list[].append", "range", "print", "float", "math.exp", "len", "math.exp", "float", "float"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.BleuScorer._single_reflen"], ["", "def", "compute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "n", "=", "self", ".", "n", "\n", "small", "=", "1e-9", "\n", "tiny", "=", "1e-15", "## so that if guess is 0 still return 0", "\n", "bleu_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "if", "self", ".", "_score", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_score", "\n", "\n", "", "if", "option", "is", "None", ":", "\n", "            ", "option", "=", "\"average\"", "if", "len", "(", "self", ".", "crefs", ")", "==", "1", "else", "\"closest\"", "\n", "\n", "", "self", ".", "_testlen", "=", "0", "\n", "self", ".", "_reflen", "=", "0", "\n", "totalcomps", "=", "{", "'testlen'", ":", "0", ",", "'reflen'", ":", "0", ",", "'guess'", ":", "[", "0", "]", "*", "n", ",", "'correct'", ":", "[", "0", "]", "*", "n", "}", "\n", "\n", "# for each sentence", "\n", "for", "comps", "in", "self", ".", "ctest", ":", "\n", "            ", "testlen", "=", "comps", "[", "'testlen'", "]", "\n", "self", ".", "_testlen", "+=", "testlen", "\n", "\n", "if", "self", ".", "special_reflen", "is", "None", ":", "## need computation", "\n", "                ", "reflen", "=", "self", ".", "_single_reflen", "(", "comps", "[", "'reflen'", "]", ",", "option", ",", "testlen", ")", "\n", "", "else", ":", "\n", "                ", "reflen", "=", "self", ".", "special_reflen", "\n", "\n", "", "self", ".", "_reflen", "+=", "reflen", "\n", "\n", "for", "key", "in", "[", "'guess'", ",", "'correct'", "]", ":", "\n", "                ", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                    ", "totalcomps", "[", "key", "]", "[", "k", "]", "+=", "comps", "[", "key", "]", "[", "k", "]", "\n", "\n", "# append per image bleu score", "\n", "", "", "bleu", "=", "1.", "\n", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                ", "bleu", "*=", "(", "float", "(", "comps", "[", "'correct'", "]", "[", "k", "]", ")", "+", "tiny", ")", "/", "(", "float", "(", "comps", "[", "'guess'", "]", "[", "k", "]", ")", "+", "small", ")", "\n", "bleu_list", "[", "k", "]", ".", "append", "(", "bleu", "**", "(", "1.", "/", "(", "k", "+", "1", ")", ")", ")", "\n", "", "ratio", "=", "(", "testlen", "+", "tiny", ")", "/", "(", "reflen", "+", "small", ")", "## N.B.: avoid zero division", "\n", "if", "ratio", "<", "1", ":", "\n", "                ", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                    ", "bleu_list", "[", "k", "]", "[", "-", "1", "]", "*=", "math", ".", "exp", "(", "1", "-", "1", "/", "ratio", ")", "\n", "\n", "", "", "if", "verbose", ">", "1", ":", "\n", "                ", "print", "(", "comps", ",", "reflen", ")", "\n", "\n", "", "", "totalcomps", "[", "'reflen'", "]", "=", "self", ".", "_reflen", "\n", "totalcomps", "[", "'testlen'", "]", "=", "self", ".", "_testlen", "\n", "\n", "bleus", "=", "[", "]", "\n", "bleu", "=", "1.", "\n", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "            ", "bleu", "*=", "float", "(", "totalcomps", "[", "'correct'", "]", "[", "k", "]", "+", "tiny", ")", "/", "(", "totalcomps", "[", "'guess'", "]", "[", "k", "]", "+", "small", ")", "\n", "bleus", ".", "append", "(", "bleu", "**", "(", "1.", "/", "(", "k", "+", "1", ")", ")", ")", "\n", "", "ratio", "=", "(", "self", ".", "_testlen", "+", "tiny", ")", "/", "(", "self", ".", "_reflen", "+", "small", ")", "## N.B.: avoid zero division", "\n", "if", "ratio", "<", "1", ":", "\n", "            ", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                ", "bleus", "[", "k", "]", "*=", "math", ".", "exp", "(", "1", "-", "1", "/", "ratio", ")", "\n", "\n", "#if verbose > 0:", "\n", "#    print totalcomps", "\n", "#    print \"ratio:\", ratio", "\n", "\n", "", "", "self", ".", "_score", "=", "bleus", "\n", "return", "self", ".", "_score", ",", "bleu_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.precook": [[11, 22], ["s.split", "collections.defaultdict", "range", "range", "len", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "    ", "\"\"\"Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "(", "len", "(", "words", ")", ",", "counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.cook_refs": [[23, 47], ["bleu_scorer.precook", "min.append", "counts.items", "min", "max", "maxcounts.get", "float", "len", "sum"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.precook"], ["", "def", "cook_refs", "(", "refs", ",", "eff", "=", "None", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.'''", "\n", "\n", "reflen", "=", "[", "]", "\n", "maxcounts", "=", "{", "}", "\n", "for", "ref", "in", "refs", ":", "\n", "        ", "rl", ",", "counts", "=", "precook", "(", "ref", ",", "n", ")", "\n", "reflen", ".", "append", "(", "rl", ")", "\n", "for", "(", "ngram", ",", "count", ")", "in", "counts", ".", "items", "(", ")", ":", "\n", "            ", "maxcounts", "[", "ngram", "]", "=", "max", "(", "maxcounts", ".", "get", "(", "ngram", ",", "0", ")", ",", "count", ")", "\n", "\n", "# Calculate effective reference sentence length.", "\n", "", "", "if", "eff", "==", "\"shortest\"", ":", "\n", "        ", "reflen", "=", "min", "(", "reflen", ")", "\n", "", "elif", "eff", "==", "\"average\"", ":", "\n", "        ", "reflen", "=", "float", "(", "sum", "(", "reflen", ")", ")", "/", "len", "(", "reflen", ")", "\n", "\n", "## lhuang: N.B.: leave reflen computaiton to the very end!!", "\n", "\n", "## lhuang: N.B.: in case of \"closest\", keep a list of reflens!! (bad design)", "\n", "\n", "", "return", "(", "reflen", ",", "maxcounts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.bleu.bleu_scorer.cook_test": [[48, 72], ["bleu_scorer.precook", "counts.items", "max", "min", "min", "range", "refmaxcounts.get", "len", "abs"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.precook"], ["", "def", "cook_test", "(", "test", ",", "refs", ",", "eff", "=", "None", ",", "n", "=", "4", ")", ":", "\n", "    ", "'''Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.'''", "\n", "(", "reflen", ",", "refmaxcounts", ")", "=", "refs", "\n", "testlen", ",", "counts", "=", "precook", "(", "test", ",", "n", ",", "True", ")", "\n", "\n", "result", "=", "{", "}", "\n", "\n", "# Calculate effective reference sentence length.", "\n", "\n", "if", "eff", "==", "\"closest\"", ":", "\n", "        ", "result", "[", "\"reflen\"", "]", "=", "min", "(", "(", "abs", "(", "l", "-", "testlen", ")", ",", "l", ")", "for", "l", "in", "reflen", ")", "[", "1", "]", "\n", "", "else", ":", "## i.e., \"average\" or \"shortest\" or None", "\n", "        ", "result", "[", "\"reflen\"", "]", "=", "reflen", "\n", "\n", "", "result", "[", "\"testlen\"", "]", "=", "testlen", "\n", "\n", "result", "[", "\"guess\"", "]", "=", "[", "max", "(", "0", ",", "testlen", "-", "k", "+", "1", ")", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", "]", "\n", "\n", "result", "[", "'correct'", "]", "=", "[", "0", "]", "*", "n", "\n", "for", "(", "ngram", ",", "count", ")", "in", "counts", ".", "items", "(", ")", ":", "\n", "        ", "result", "[", "\"correct\"", "]", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "min", "(", "refmaxcounts", ".", "get", "(", "ngram", ",", "0", ")", ",", "count", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.rouge.rouge.Rouge.__init__": [[33, 36], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# vrama91: updated the value below based on discussion with Hovey", "\n", "        ", "self", ".", "beta", "=", "1.2", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.rouge.rouge.Rouge.calc_score": [[37, 68], ["candidate[].split", "max", "max", "len", "len", "reference.split", "rouge.my_lcs", "prec.append", "rec.append", "float", "float", "float", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.rouge.rouge.my_lcs"], ["", "def", "calc_score", "(", "self", ",", "candidate", ",", "refs", ")", ":", "\n", "        ", "\"\"\"\n        Compute ROUGE-L score given one candidate and references for an image\n        :param candidate: str : candidate sentence to be evaluated\n        :param refs: list of str : COCO reference sentences for the particular image to be evaluated\n        :returns score: int (ROUGE-L score for the candidate evaluated against references)\n        \"\"\"", "\n", "assert", "(", "len", "(", "candidate", ")", "==", "1", ")", "\n", "assert", "(", "len", "(", "refs", ")", ">", "0", ")", "\n", "prec", "=", "[", "]", "\n", "rec", "=", "[", "]", "\n", "\n", "# split into tokens", "\n", "token_c", "=", "candidate", "[", "0", "]", ".", "split", "(", "\" \"", ")", "\n", "\n", "for", "reference", "in", "refs", ":", "\n", "# split into tokens", "\n", "            ", "token_r", "=", "reference", ".", "split", "(", "\" \"", ")", "\n", "# compute the longest common subsequence", "\n", "lcs", "=", "my_lcs", "(", "token_r", ",", "token_c", ")", "\n", "prec", ".", "append", "(", "lcs", "/", "float", "(", "len", "(", "token_c", ")", ")", ")", "\n", "rec", ".", "append", "(", "lcs", "/", "float", "(", "len", "(", "token_r", ")", ")", ")", "\n", "\n", "", "prec_max", "=", "max", "(", "prec", ")", "\n", "rec_max", "=", "max", "(", "rec", ")", "\n", "\n", "if", "(", "prec_max", "!=", "0", "and", "rec_max", "!=", "0", ")", ":", "\n", "            ", "score", "=", "(", "(", "1", "+", "self", ".", "beta", "**", "2", ")", "*", "prec_max", "*", "rec_max", ")", "/", "float", "(", "rec_max", "+", "self", ".", "beta", "**", "2", "*", "prec_max", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "0.0", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.rouge.rouge.Rouge.compute_score": [[69, 95], ["gts.keys", "numpy.mean", "gts.keys", "res.keys", "score.append", "numpy.array", "numpy.array", "rouge.Rouge.calc_score", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.rouge.rouge.Rouge.calc_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Computes Rouge-L score given a set of reference and candidate sentences for the dataset\n        Invoked by evaluate_captions.py \n        :param hypo_for_image: dict : candidate / test sentences with \"image name\" key and \"tokenized sentences\" as values \n        :param ref_for_image: dict : reference MS-COCO sentences with \"image name\" key and \"tokenized sentences\" as values\n        :returns: average_score: float (mean ROUGE-L score computed by averaging scores for all the images)\n        \"\"\"", "\n", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "score", "=", "[", "]", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "score", ".", "append", "(", "self", ".", "calc_score", "(", "hypo", ",", "ref", ")", ")", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "\n", "", "average_score", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", "\n", "return", "average_score", ",", "np", ".", "array", "(", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.rouge.rouge.Rouge.method": [[96, 98], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"Rouge\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.rouge.rouge.my_lcs": [[5, 27], ["range", "len", "len", "range", "range", "len", "len", "range", "len", "max", "len", "len", "len"], "function", ["None"], ["def", "my_lcs", "(", "string", ",", "sub", ")", ":", "\n", "    ", "\"\"\"\n    Calculates longest common subsequence for a pair of tokenized strings\n    :param string : list of str : tokens from a string split using whitespace\n    :param sub : list of str : shorter string, also split using whitespace\n    :returns: length (list of int): length of the longest common subsequence between the two strings\n\n    Note: my_lcs only gives length of the longest common subsequence, not the actual LCS\n    \"\"\"", "\n", "if", "(", "len", "(", "string", ")", "<", "len", "(", "sub", ")", ")", ":", "\n", "        ", "sub", ",", "string", "=", "string", ",", "sub", "\n", "\n", "", "lengths", "=", "[", "[", "0", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sub", ")", "+", "1", ")", "]", "for", "j", "in", "range", "(", "0", ",", "len", "(", "string", ")", "+", "1", ")", "]", "\n", "\n", "for", "j", "in", "range", "(", "1", ",", "len", "(", "sub", ")", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "string", ")", "+", "1", ")", ":", "\n", "            ", "if", "(", "string", "[", "i", "-", "1", "]", "==", "sub", "[", "j", "-", "1", "]", ")", ":", "\n", "                ", "lengths", "[", "i", "]", "[", "j", "]", "=", "lengths", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "", "else", ":", "\n", "                ", "lengths", "[", "i", "]", "[", "j", "]", "=", "max", "(", "lengths", "[", "i", "-", "1", "]", "[", "j", "]", ",", "lengths", "[", "i", "]", "[", "j", "-", "1", "]", ")", "\n", "\n", "", "", "", "return", "lengths", "[", "len", "(", "string", ")", "]", "[", "len", "(", "sub", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.meteor.meteor.Meteor.__init__": [[11, 21], ["subprocess.Popen", "threading.Lock", "os.path.dirname", "os.path.abspath"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "meteor_cmd", "=", "[", "'java'", ",", "'-jar'", ",", "'-Xmx2G'", ",", "METEOR_JAR", ",", "'-'", ",", "'-'", ",", "'-stdio'", ",", "'-l'", ",", "'en'", ",", "'-norm'", "]", "\n", "self", ".", "meteor_p", "=", "subprocess", ".", "Popen", "(", "self", ".", "meteor_cmd", ",", "cwd", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "# Used to guarantee thread safety", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.meteor.meteor.Meteor.compute_score": [[22, 41], ["gts.keys", "meteor.Meteor.lock.acquire", "meteor.Meteor.meteor_p.stdin.write", "range", "float", "meteor.Meteor.lock.release", "gts.keys", "res.keys", "meteor.Meteor._stat", "len", "scores.append", "meteor.Meteor.meteor_p.stdout.readline().strip", "len", "float", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.meteor.meteor.Meteor._stat"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "scores", "=", "[", "]", "\n", "\n", "eval_line", "=", "'EVAL'", "\n", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "for", "i", "in", "imgIds", ":", "\n", "            ", "assert", "(", "len", "(", "res", "[", "i", "]", ")", "==", "1", ")", "\n", "stat", "=", "self", ".", "_stat", "(", "res", "[", "i", "]", "[", "0", "]", ",", "gts", "[", "i", "]", ")", "\n", "eval_line", "+=", "' ||| {}'", ".", "format", "(", "stat", ")", "\n", "\n", "", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "eval_line", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "imgIds", ")", ")", ":", "\n", "            ", "scores", ".", "append", "(", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", ")", "\n", "", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.meteor.meteor.Meteor.method": [[42, 44], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"METEOR\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.meteor.meteor.Meteor._stat": [[45, 51], ["hypothesis_str.replace().replace.replace().replace.replace().replace", "meteor.Meteor.meteor_p.stdin.write", "meteor.Meteor.meteor_p.stdout.readline().strip", "hypothesis_str.replace().replace.replace().replace.replace", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["None"], ["", "def", "_stat", "(", "self", ",", "hypothesis_str", ",", "reference_list", ")", ":", "\n", "# SCORE ||| reference 1 words ||| reference n words ||| hypothesis words", "\n", "        ", "hypothesis_str", "=", "hypothesis_str", ".", "replace", "(", "'|||'", ",", "''", ")", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "score_line", "=", "' ||| '", ".", "join", "(", "(", "'SCORE'", ",", "' ||| '", ".", "join", "(", "reference_list", ")", ",", "hypothesis_str", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score_line", ")", ")", "\n", "return", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.meteor.meteor.Meteor._score": [[52, 68], ["meteor.Meteor.lock.acquire", "hypothesis_str.replace().replace.replace().replace.replace().replace", "meteor.Meteor.meteor_p.stdin.write", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdin.write", "float", "float", "meteor.Meteor.lock.release", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdout.readline().strip", "hypothesis_str.replace().replace.replace().replace.replace", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["None"], ["", "def", "_score", "(", "self", ",", "hypothesis_str", ",", "reference_list", ")", ":", "\n", "        ", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "# SCORE ||| reference 1 words ||| reference n words ||| hypothesis words", "\n", "hypothesis_str", "=", "hypothesis_str", ".", "replace", "(", "'|||'", ",", "''", ")", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "score_line", "=", "' ||| '", ".", "join", "(", "(", "'SCORE'", ",", "' ||| '", ".", "join", "(", "reference_list", ")", ",", "hypothesis_str", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score_line", ")", ")", "\n", "stats", "=", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "eval_line", "=", "'EVAL ||| {}'", ".", "format", "(", "stats", ")", "\n", "# EVAL ||| stats ", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "eval_line", ")", ")", "\n", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "# bug fix: there are two values returned by the jar file, one average, and one all, so do it twice", "\n", "# thanks for Andrej for pointing this out", "\n", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.meteor.meteor.Meteor.__exit__": [[69, 75], ["meteor.Meteor.lock.acquire", "meteor.Meteor.meteor_p.stdin.close", "meteor.Meteor.meteor_p.kill", "meteor.Meteor.meteor_p.wait", "meteor.Meteor.lock.release"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ")", ":", "\n", "        ", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "close", "(", ")", "\n", "self", ".", "meteor_p", ".", "kill", "(", ")", "\n", "self", ".", "meteor_p", ".", "wait", "(", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.tokenizer.ptbtokenizer.PTBTokenizer.tokenize": [[16, 58], ["os.path.dirname", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.close", "cmd.append", "subprocess.Popen", "token_lines.split", "os.remove", "zip", "os.path.abspath", "os.path.basename", "subprocess.Popen.communicate", "final_tokenized_captions_for_image[].append", "captions_for_image.items", "range", "c[].replace", "len", "captions_for_image.items", "sentences.rstrip", "line.rstrip().split", "line.rstrip"], "methods", ["None"], ["def", "tokenize", "(", "self", ",", "captions_for_image", ")", ":", "\n", "        ", "cmd", "=", "[", "'java'", ",", "'-cp'", ",", "STANFORD_CORENLP_3_4_1_JAR", ",", "'edu.stanford.nlp.process.PTBTokenizer'", ",", "'-preserveLines'", ",", "'-lowerCase'", "]", "\n", "\n", "# ======================================================", "\n", "# prepare data for PTB Tokenizer", "\n", "# ======================================================", "\n", "final_tokenized_captions_for_image", "=", "{", "}", "\n", "image_id", "=", "[", "k", "for", "k", ",", "v", "in", "captions_for_image", ".", "items", "(", ")", "for", "_", "in", "range", "(", "len", "(", "v", ")", ")", "]", "\n", "sentences", "=", "'\\n'", ".", "join", "(", "[", "c", "[", "'caption'", "]", ".", "replace", "(", "'\\n'", ",", "' '", ")", "for", "k", ",", "v", "in", "captions_for_image", ".", "items", "(", ")", "for", "c", "in", "v", "]", ")", "\n", "\n", "# ======================================================", "\n", "# save sentences to temporary file", "\n", "# ======================================================", "\n", "path_to_jar_dirname", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "tmp_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ",", "dir", "=", "path_to_jar_dirname", ")", "\n", "tmp_file", ".", "write", "(", "sentences", ")", "\n", "tmp_file", ".", "close", "(", ")", "\n", "\n", "# ======================================================", "\n", "# tokenize sentence", "\n", "# ======================================================", "\n", "cmd", ".", "append", "(", "os", ".", "path", ".", "basename", "(", "tmp_file", ".", "name", ")", ")", "\n", "p_tokenizer", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "cwd", "=", "path_to_jar_dirname", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "token_lines", "=", "p_tokenizer", ".", "communicate", "(", "input", "=", "sentences", ".", "rstrip", "(", ")", ")", "[", "0", "]", "\n", "lines", "=", "token_lines", ".", "split", "(", "'\\n'", ")", "\n", "# remove temp file", "\n", "os", ".", "remove", "(", "tmp_file", ".", "name", ")", "\n", "\n", "# ======================================================", "\n", "# create dictionary for tokenized captions", "\n", "# ======================================================", "\n", "for", "k", ",", "line", "in", "zip", "(", "image_id", ",", "lines", ")", ":", "\n", "            ", "if", "not", "k", "in", "final_tokenized_captions_for_image", ":", "\n", "                ", "final_tokenized_captions_for_image", "[", "k", "]", "=", "[", "]", "\n", "", "tokenized_caption", "=", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "if", "w", "not", "in", "PUNCTUATIONS", "]", ")", "\n", "final_tokenized_captions_for_image", "[", "k", "]", ".", "append", "(", "tokenized_caption", ")", "\n", "\n", "", "return", "final_tokenized_captions_for_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy": [[48, 54], ["cider_scorer.CiderScorer", "copy.copy", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy"], ["def", "copy", "(", "self", ")", ":", "\n", "        ", "''' copy the refs.'''", "\n", "new", "=", "CiderScorer", "(", "n", "=", "self", ".", "n", ")", "\n", "new", ".", "ctest", "=", "copy", ".", "copy", "(", "self", ".", "ctest", ")", "\n", "new", ".", "crefs", "=", "copy", ".", "copy", "(", "self", ".", "crefs", ")", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.__init__": [[55, 64], ["collections.defaultdict", "cider_scorer.CiderScorer.cook_append"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "        ", "''' singular instance '''", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "self", ".", "document_frequency", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "cook_append", "(", "test", ",", "refs", ")", "\n", "self", ".", "ref_len", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.cook_append": [[65, 74], ["cider_scorer.CiderScorer.crefs.append", "cider_scorer.cook_refs", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.cook_test"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.cook_refs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.cook_test"], ["", "def", "cook_append", "(", "self", ",", "test", ",", "refs", ")", ":", "\n", "        ", "'''called by constructor and __iadd__ to avoid creating new instances.'''", "\n", "\n", "if", "refs", "is", "not", "None", ":", "\n", "            ", "self", ".", "crefs", ".", "append", "(", "cook_refs", "(", "refs", ")", ")", "\n", "if", "test", "is", "not", "None", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "cook_test", "(", "test", ")", ")", "## N.B.: -1", "\n", "", "else", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "None", ")", "# lens of crefs and ctest have to match", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size": [[75, 78], ["len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "crefs", ")", "==", "len", "(", "self", ".", "ctest", ")", ",", "\"refs/test mismatch! %d<>%d\"", "%", "(", "len", "(", "self", ".", "crefs", ")", ",", "len", "(", "self", ".", "ctest", ")", ")", "\n", "return", "len", "(", "self", ".", "crefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.__iadd__": [[79, 90], ["type", "cider_scorer.CiderScorer.cook_append", "cider_scorer.CiderScorer.ctest.extend", "cider_scorer.CiderScorer.crefs.extend"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "'''add an instance (e.g., from another sentence).'''", "\n", "\n", "if", "type", "(", "other", ")", "is", "tuple", ":", "\n", "## avoid creating new CiderScorer instances", "\n", "            ", "self", ".", "cook_append", "(", "other", "[", "0", "]", ",", "other", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ctest", ".", "extend", "(", "other", ".", "ctest", ")", "\n", "self", ".", "crefs", ".", "extend", "(", "other", ".", "crefs", ")", "\n", "\n", "", "return", "self", "\n", "", "def", "compute_doc_freq", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.compute_doc_freq": [[90, 101], ["set", "ref.items"], "methods", ["None"], ["", "def", "compute_doc_freq", "(", "self", ")", ":", "\n", "        ", "'''\n        Compute term frequency for reference data.\n        This will be used to compute idf (inverse document frequency later)\n        The term frequency is stored in the object\n        :return: None\n        '''", "\n", "for", "refs", "in", "self", ".", "crefs", ":", "\n", "# refs, k ref captions of one image", "\n", "            ", "for", "ngram", "in", "set", "(", "[", "ngram", "for", "ref", "in", "refs", "for", "(", "ngram", ",", "count", ")", "in", "ref", ".", "items", "(", ")", "]", ")", ":", "\n", "                ", "self", ".", "document_frequency", "[", "ngram", "]", "+=", "1", "\n", "# maxcounts[ngram] = max(maxcounts.get(ngram,0), count)", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.compute_cider": [[103, 179], ["numpy.log", "zip", "cnts.items", "float", "numpy.array", "range", "float", "cider_scorer.CiderScorer.compute_cider.counts2vec"], "methods", ["None"], ["", "", "", "def", "compute_cider", "(", "self", ")", ":", "\n", "        ", "def", "counts2vec", "(", "cnts", ")", ":", "\n", "            ", "\"\"\"\n            Function maps counts of ngram to vector of tfidf weights.\n            The function returns vec, an array of dictionary that store mapping of n-gram and tf-idf weights.\n            The n-th entry of array denotes length of n-grams.\n            :param cnts:\n            :return: vec (array of dict), norm (array of float), length (int)\n            \"\"\"", "\n", "vec", "=", "[", "defaultdict", "(", "float", ")", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "length", "=", "0", "\n", "norm", "=", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "for", "(", "ngram", ",", "term_freq", ")", "in", "cnts", ".", "items", "(", ")", ":", "\n", "# give word count 1 if it doesn't appear in reference corpus", "\n", "                ", "df", "=", "np", ".", "log", "(", "max", "(", "1.0", ",", "self", ".", "document_frequency", "[", "ngram", "]", ")", ")", "\n", "# ngram index", "\n", "n", "=", "len", "(", "ngram", ")", "-", "1", "\n", "# tf (term_freq) * idf (precomputed idf) for n-grams", "\n", "vec", "[", "n", "]", "[", "ngram", "]", "=", "float", "(", "term_freq", ")", "*", "(", "self", ".", "ref_len", "-", "df", ")", "\n", "# compute norm for the vector.  the norm will be used for computing similarity", "\n", "norm", "[", "n", "]", "+=", "pow", "(", "vec", "[", "n", "]", "[", "ngram", "]", ",", "2", ")", "\n", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "length", "+=", "term_freq", "\n", "", "", "norm", "=", "[", "np", ".", "sqrt", "(", "n", ")", "for", "n", "in", "norm", "]", "\n", "return", "vec", ",", "norm", ",", "length", "\n", "\n", "", "def", "sim", "(", "vec_hyp", ",", "vec_ref", ",", "norm_hyp", ",", "norm_ref", ",", "length_hyp", ",", "length_ref", ")", ":", "\n", "            ", "'''\n            Compute the cosine similarity of two vectors.\n            :param vec_hyp: array of dictionary for vector corresponding to hypothesis\n            :param vec_ref: array of dictionary for vector corresponding to reference\n            :param norm_hyp: array of float for vector corresponding to hypothesis\n            :param norm_ref: array of float for vector corresponding to reference\n            :param length_hyp: int containing length of hypothesis\n            :param length_ref: int containing length of reference\n            :return: array of score for each n-grams cosine similarity\n            '''", "\n", "delta", "=", "float", "(", "length_hyp", "-", "length_ref", ")", "\n", "# measure consine similarity", "\n", "val", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "# ngram", "\n", "                ", "for", "(", "ngram", ",", "count", ")", "in", "vec_hyp", "[", "n", "]", ".", "items", "(", ")", ":", "\n", "# vrama91 : added clipping", "\n", "                    ", "val", "[", "n", "]", "+=", "min", "(", "vec_hyp", "[", "n", "]", "[", "ngram", "]", ",", "vec_ref", "[", "n", "]", "[", "ngram", "]", ")", "*", "vec_ref", "[", "n", "]", "[", "ngram", "]", "\n", "\n", "", "if", "(", "norm_hyp", "[", "n", "]", "!=", "0", ")", "and", "(", "norm_ref", "[", "n", "]", "!=", "0", ")", ":", "\n", "                    ", "val", "[", "n", "]", "/=", "(", "norm_hyp", "[", "n", "]", "*", "norm_ref", "[", "n", "]", ")", "\n", "\n", "", "assert", "(", "not", "math", ".", "isnan", "(", "val", "[", "n", "]", ")", ")", "\n", "# vrama91: added a length based gaussian penalty", "\n", "val", "[", "n", "]", "*=", "np", ".", "e", "**", "(", "-", "(", "delta", "**", "2", ")", "/", "(", "2", "*", "self", ".", "sigma", "**", "2", ")", ")", "\n", "", "return", "val", "\n", "\n", "# compute log reference length", "\n", "", "self", ".", "ref_len", "=", "np", ".", "log", "(", "float", "(", "len", "(", "self", ".", "crefs", ")", ")", ")", "\n", "\n", "scores", "=", "[", "]", "\n", "for", "test", ",", "refs", "in", "zip", "(", "self", ".", "ctest", ",", "self", ".", "crefs", ")", ":", "\n", "# compute vector for test captions", "\n", "            ", "vec", ",", "norm", ",", "length", "=", "counts2vec", "(", "test", ")", "\n", "# compute vector for ref captions", "\n", "score", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "ref", "in", "refs", ":", "\n", "                ", "vec_ref", ",", "norm_ref", ",", "length_ref", "=", "counts2vec", "(", "ref", ")", "\n", "score", "+=", "sim", "(", "vec", ",", "vec_ref", ",", "norm", ",", "norm_ref", ",", "length", ",", "length_ref", ")", "\n", "# change by vrama91 - mean of ngram scores, instead of sum", "\n", "", "score_avg", "=", "np", ".", "mean", "(", "score", ")", "\n", "# divide by number of references", "\n", "score_avg", "/=", "len", "(", "refs", ")", "\n", "# multiply score by 10", "\n", "score_avg", "*=", "10.0", "\n", "# append score of an image to the score list", "\n", "scores", ".", "append", "(", "score_avg", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.compute_score": [[180, 190], ["cider_scorer.CiderScorer.compute_doc_freq", "cider_scorer.CiderScorer.compute_cider", "len", "max", "numpy.mean", "numpy.array", "cider_scorer.CiderScorer.document_frequency.values", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.compute_doc_freq", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.compute_cider"], ["", "def", "compute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "# compute idf", "\n", "        ", "self", ".", "compute_doc_freq", "(", ")", "\n", "# assert to check document frequency", "\n", "assert", "(", "len", "(", "self", ".", "ctest", ")", ">=", "max", "(", "self", ".", "document_frequency", ".", "values", "(", ")", ")", ")", "\n", "# compute cider score", "\n", "score", "=", "self", ".", "compute_cider", "(", ")", "\n", "# debug", "\n", "# print score", "\n", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", ",", "np", ".", "array", "(", "score", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.precook": [[8, 24], ["s.split", "collections.defaultdict", "range", "range", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\n    :param s: string : sentence to be converted into ngrams\n    :param n: int    : number of ngrams for which representation is calculated\n    :return: term frequency vector for occuring ngrams\n    \"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.cook_refs": [[25, 34], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.precook"], ["", "def", "cook_refs", "(", "refs", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    '''", "\n", "return", "[", "precook", "(", "ref", ",", "n", ")", "for", "ref", "in", "refs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.cook_test": [[35, 43], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.precook"], ["", "def", "cook_test", "(", "test", ",", "n", "=", "4", ")", ":", "\n", "    ", "'''Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.\n    :param test: list of string : hypothesis sentence for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (dict)\n    '''", "\n", "return", "precook", "(", "test", ",", "n", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.__init__": [[10, 15], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "# set cider to sum over 1 to 4-grams", "\n", "        ", "self", ".", "_n", "=", "n", "\n", "# set the standard deviation parameter for gaussian penalty", "\n", "self", ".", "_sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score": [[16, 44], ["gts.keys", "cider_scorer.CiderScorer.CiderScorer", "cider_scorer.CiderScorer.CiderScorer.compute_score", "gts.keys", "res.keys", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Main function to compute CIDEr score\n        :param  hypo_for_image (dict) : dictionary with key <image> and value <tokenized hypothesis / candidate sentence>\n                ref_for_image (dict)  : dictionary with key <image> and value <tokenized reference sentence>\n        :return: cider (float) : computed CIDEr score for the corpus \n        \"\"\"", "\n", "\n", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "cider_scorer", "=", "CiderScorer", "(", "n", "=", "self", ".", "_n", ",", "sigma", "=", "self", ".", "_sigma", ")", "\n", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "\n", "cider_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "", "(", "score", ",", "scores", ")", "=", "cider_scorer", ".", "compute_score", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.method": [[45, 47], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"CIDEr\"", "", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.distributed.is_master": [[13, 15], ["None"], "function", ["None"], ["def", "is_master", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "return", "opt", ".", "gpu_ranks", "[", "device_id", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.distributed.multi_init": [[16, 29], ["torch.distributed.init_process_group", "torch.distributed.get_rank", "distributed.is_master"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_rank", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.distributed.is_master"], ["", "def", "multi_init", "(", "opt", ",", "device_id", ",", "logger", "=", "None", ")", ":", "\n", "    ", "dist_init_method", "=", "'tcp://{master_ip}:{master_port}'", ".", "format", "(", "\n", "master_ip", "=", "opt", ".", "master_ip", ",", "\n", "master_port", "=", "opt", ".", "master_port", ")", "\n", "dist_world_size", "=", "opt", ".", "world_size", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "opt", ".", "gpu_backend", ",", "init_method", "=", "dist_init_method", ",", "\n", "world_size", "=", "dist_world_size", ",", "rank", "=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ")", "\n", "gpu_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "if", "not", "is_master", "(", "opt", ",", "device_id", ")", "and", "logger", "is", "not", "None", ":", "\n", "        ", "logger", ".", "disabled", "=", "True", "\n", "\n", "", "return", "gpu_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.distributed.all_reduce_and_rescale_tensors": [[30, 82], ["tensors[].new().zero_", "torch.distributed.all_reduce", "tensors[].new().zero_.div_", "len", "distributed.all_reduce_and_rescale_tensors.all_reduce_buffer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_reduce"], ["", "def", "all_reduce_and_rescale_tensors", "(", "tensors", ",", "rescale_denom", ",", "\n", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n        buffer_size: all-reduce chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "all_reduce_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "torch", ".", "distributed", ".", "all_reduce", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, all-reduce and rescale directly", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "t", ")", "\n", "t", ".", "div_", "(", "rescale_denom", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, all-reduce and replace buffer with grad", "\n", "            ", "all_reduce_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "all_reduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.distributed.all_gather_list": [[83, 117], ["torch.distributed.get_world_size", "pickle.dumps", "len", "torch.ByteTensor", "torch.distributed.all_gather", "range", "torch.cuda.ByteTensor", "ValueError", "list", "in_buffer.cuda", "bytes", "pickle.loads", "results.append", "hasattr", "all_gather_list._in_buffer.size", "torch.cuda.ByteTensor", "out_buffer[].item", "out_buffer[].tolist", "range", "out_buffer[].item"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "def", "all_gather_list", "(", "data", ",", "max_size", "=", "9128", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\"\"\"", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_in_buffer'", ")", "or", "max_size", "!=", "all_gather_list", ".", "_in_buffer", ".", "size", "(", ")", ":", "\n", "        ", "all_gather_list", ".", "_in_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "all_gather_list", ".", "_out_buffers", "=", "[", "\n", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "", "in_buffer", "=", "all_gather_list", ".", "_in_buffer", "\n", "out_buffers", "=", "all_gather_list", ".", "_out_buffers", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "if", "enc_size", "+", "2", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'encoded data exceeds max_size: {}'", ".", "format", "(", "enc_size", "+", "2", ")", ")", "\n", "", "assert", "max_size", "<", "255", "*", "256", "\n", "in_buffer", "[", "0", "]", "=", "enc_size", "//", "255", "# this encoding works for max_size < 65k", "\n", "in_buffer", "[", "1", "]", "=", "enc_size", "%", "255", "\n", "in_buffer", "[", "2", ":", "enc_size", "+", "2", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "out_buffers", ",", "in_buffer", ".", "cuda", "(", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "out_buffer", "=", "out_buffers", "[", "i", "]", "\n", "size", "=", "(", "255", "*", "out_buffer", "[", "0", "]", ".", "item", "(", ")", ")", "+", "out_buffer", "[", "1", "]", ".", "item", "(", ")", "\n", "\n", "bytes_list", "=", "bytes", "(", "out_buffer", "[", "2", ":", "size", "+", "2", "]", ".", "tolist", "(", ")", ")", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.top_k_top_p_filtering": [[18, 51], ["float", "min", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_indices_to_remove.scatter", "max", "logits.size", "torch.softmax", "torch.topk", "torch.topk"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["def", "top_k_top_p_filtering", "(", "logits", ",", "top_k", "=", "0", ",", "top_p", "=", "1.0", ",", "filter_value", "=", "-", "float", "(", "\"Inf\"", ")", ",", "min_tokens_to_keep", "=", "1", ")", ":", "\n", "    ", "\"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n        Args:\n            logits: logits distribution shape (batch size, vocabulary size)\n            if top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n            if top_p < 1.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n            Make sure we keep at least min_tokens_to_keep per batch example in the output\n        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n    \"\"\"", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "top_k", "=", "min", "(", "max", "(", "top_k", ",", "min_tokens_to_keep", ")", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "# Safety check", "\n", "# Remove all tokens with a probability less than the last token of the top-k", "\n", "indices_to_remove", "=", "logits", "<", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "\n", "", "if", "top_p", "<", "1.0", ":", "\n", "        ", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold (token with 0 are kept)", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "top_p", "\n", "if", "min_tokens_to_keep", ">", "1", ":", "\n", "# Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)", "\n", "            ", "sorted_indices_to_remove", "[", "...", ",", ":", "min_tokens_to_keep", "]", "=", "0", "\n", "# Shift the indices to the right to keep also the first token above the threshold", "\n", "", "sorted_indices_to_remove", "[", "...", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "\n", "# scatter sorted tensors to original indexing", "\n", "indices_to_remove", "=", "sorted_indices_to_remove", ".", "scatter", "(", "1", ",", "sorted_indices", ",", "sorted_indices_to_remove", ")", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.generate_next_token": [[53, 95], ["isinstance", "sample.lower", "torch.no_grad", "torch.no_grad", "model.lm_head", "torch.softmax", "model.transformer", "model.transformer", "sample.lower", "torch.multinomial", "torch.multinomial", "sample.lower", "len", "generation.top_k_top_p_filtering", "generation.top_k_logits", "sample.lower", "torch.topk", "torch.topk", "sample.lower", "torch.topk", "torch.topk", "numpy.setdiff1d", "torch.multinomial.cpu", "len", "torch.tensor", "torch.tensor", "sample.lower", "torch.topk", "torch.topk", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.top_k_top_p_filtering", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.top_k_logits"], ["", "def", "generate_next_token", "(", "model", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "prev", "=", "None", ",", "temperature", "=", "1", ",", "top_k", "=", "0", ",", "top_p", "=", "1.0", ",", "sample", "=", "'greedy'", ",", "past", "=", "None", ",", "protected_idx", "=", "[", "]", ")", ":", "\n", "    ", "assert", "sample", ".", "lower", "(", ")", "in", "[", "'sample'", ",", "'greedy'", ",", "'topk'", ",", "'protected_topk'", "]", ",", "f'{sample} should be one of [sample, greedy, topk, constrained_topk]'", "\n", "\n", "if", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "not", "past", ":", "\n", "            ", "hidden_states", ",", "past", "=", "model", ".", "transformer", "(", "prev", ",", "position_ids", ",", "token_type_ids", ",", "past", "=", "past", ")", "\n", "", "else", ":", "\n", "            ", "hidden_states", ",", "past", "=", "model", ".", "transformer", "(", "prev", ",", "position_ids", ",", "token_type_ids", ",", "past", "=", "past", ")", "\n", "", "logits", "=", "model", ".", "lm_head", "(", "hidden_states", ")", "\n", "logits", "=", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", "\n", "if", "sample", ".", "lower", "(", ")", "!=", "'protected_topk'", "or", "len", "(", "protected_idx", ")", "==", "0", ":", "\n", "            ", "if", "top_p", "<", "1.0", ":", "\n", "                ", "top_k_top_p_filtering", "(", "logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "", "else", ":", "\n", "                ", "logits", "=", "top_k_logits", "(", "logits", ",", "k", "=", "top_k", ")", "\n", "", "", "probs", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "if", "sample", ".", "lower", "(", ")", "==", "'sample'", ":", "\n", "            ", "prev", "=", "torch", ".", "multinomial", "(", "probs", ",", "num_samples", "=", "1", ")", "\n", "return", "prev", ",", "probs", "[", "0", "]", "[", "prev", "]", ",", "past", "\n", "", "elif", "sample", ".", "lower", "(", ")", "==", "'topk'", ":", "\n", "            ", "probs_sel", ",", "prev", "=", "torch", ".", "topk", "(", "probs", ",", "k", "=", "top_k", ",", "dim", "=", "-", "1", ")", "\n", "return", "prev", ",", "probs_sel", ",", "past", "\n", "", "elif", "sample", ".", "lower", "(", ")", "==", "'protected_topk'", ":", "\n", "            ", "probs_sel", ",", "prev", "=", "torch", ".", "topk", "(", "probs", ",", "k", "=", "top_k", "+", "len", "(", "protected_idx", ")", ",", "dim", "=", "-", "1", ")", "\n", "missing_idx", "=", "np", ".", "setdiff1d", "(", "protected_idx", ",", "prev", ".", "cpu", "(", ")", ")", "\n", "if", "len", "(", "missing_idx", ")", ">", "0", ":", "\n", "# If any protected word is missing, add them back by truncating probs_sel, prev:", "\n", "                ", "missing_probs", "=", "probs", "[", "0", ",", "missing_idx", "]", "\n", "L", "=", "len", "(", "probs_sel", "[", "0", "]", ")", "-", "len", "(", "missing_probs", ")", "\n", "reorder", "=", "(", "-", "missing_probs", ")", ".", "argsort", "(", ")", ".", "cpu", "(", ")", "\n", "missing_probs", "=", "missing_probs", "[", "reorder", "]", "\n", "missing_idx", "=", "missing_idx", "[", "reorder", "]", "\n", "probs_sel", "[", "0", ",", "L", ":", "]", "=", "missing_probs", "\n", "prev", "[", "0", ",", "L", ":", "]", "=", "torch", ".", "tensor", "(", "missing_idx", ")", "\n", "", "return", "prev", ",", "probs_sel", ",", "past", "\n", "", "elif", "sample", ".", "lower", "(", ")", "==", "'greedy'", ":", "\n", "            ", "assert", "top_k", "==", "1", ",", "f'just a sanity check, top_k needs to be 1 in greedy mode, instead of {top_k}'", "\n", "probs_sel", ",", "prev", "=", "torch", ".", "topk", "(", "probs", ",", "k", "=", "1", ",", "dim", "=", "-", "1", ")", "\n", "return", "prev", ",", "probs_sel", ",", "past", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.generate_sequence": [[98, 110], ["input_ids.new_zeros", "isinstance", "range", "generation.generate_next_token", "torch.cat", "torch.cat", "input_ids.size", "token_type_ids[].view", "position_ids[].view"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.generate_next_token", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "", "", "def", "generate_sequence", "(", "model", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "start_token", "=", "None", ",", "temperature", "=", "1", ",", "top_k", "=", "0", ",", "top_p", "=", "1.0", ",", "length", "=", "20", ",", "sample", "=", "'greedy'", ",", "past", "=", "None", ",", "device", "=", "'cuda'", ",", "no_token_id", "=", "False", ")", ":", "\n", "    ", "output", "=", "input_ids", ".", "new_zeros", "(", "[", "input_ids", ".", "size", "(", "0", ")", ",", "0", "]", ")", "\n", "if", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "prev", "=", "input_ids", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "        ", "prev", ",", "probs", ",", "past", "=", "generate_next_token", "(", "model", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "prev", ",", "temperature", ",", "top_k", ",", "top_p", ",", "sample", ",", "past", ")", "\n", "if", "not", "no_token_id", ":", "\n", "            ", "position_ids", "=", "position_ids", "[", ":", ",", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "+", "1", "\n", "token_type_ids", "=", "token_type_ids", "[", ":", ",", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "prev", ")", ",", "dim", "=", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.top_k_logits": [[112, 124], ["values[].view().expand_as", "torch.where", "torch.where", "torch.topk", "torch.topk", "values[].view", "torch.ones_like", "torch.ones_like"], "function", ["None"], ["", "def", "top_k_logits", "(", "logits", ",", "k", ")", ":", "\n", "    ", "\"\"\"\n    Masks everything but the k top entries as -infinity (1e10).\n    Used to mask logits such that e^-infinity -> 0 won't contribute to the\n    sum of the denominator.\n    \"\"\"", "\n", "if", "k", "==", "0", ":", "\n", "        ", "return", "logits", "\n", "", "else", ":", "\n", "        ", "values", "=", "torch", ".", "topk", "(", "logits", ",", "k", ")", "[", "0", "]", "\n", "batch_mins", "=", "values", "[", ":", ",", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "logits", ")", "\n", "return", "torch", ".", "where", "(", "logits", "<", "batch_mins", ",", "torch", ".", "ones_like", "(", "logits", ")", "*", "-", "1e10", ",", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.cut_seq_to_eos": [[126, 136], ["sent.append"], "function", ["None"], ["", "", "def", "cut_seq_to_eos", "(", "sentence", ",", "remove_id", "=", "[", "-", "1", "]", ")", ":", "\n", "    ", "sent", "=", "[", "]", "\n", "for", "s", "in", "sentence", ":", "\n", "        ", "if", "s", "in", "remove_id", ":", "\n", "            ", "continue", "\n", "", "if", "s", "!=", "EOS_ID", ":", "\n", "            ", "sent", ".", "append", "(", "s", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.torch_vec_to_str": [[138, 142], ["x.cpu().numpy", "tokenizer.decode().encode().decode", "x.cpu", "tokenizer.decode().encode", "tokenizer.decode", "generation.cut_seq_to_eos"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.cut_seq_to_eos"], ["", "def", "torch_vec_to_str", "(", "x", ",", "tokenizer", ")", ":", "\n", "    ", "xx", "=", "x", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "decode_str", "=", "[", "tokenizer", ".", "decode", "(", "cut_seq_to_eos", "(", "s", ")", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", "for", "s", "in", "xx", "]", "\n", "return", "decode_str", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.InputFeatures.__init__": [[73, 85], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "conv_id", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "\n", "lm_labels", ",", "doc_len", ",", "context_len", ",", "response_len", ")", ":", "\n", "        ", "self", ".", "conv_id", "=", "conv_id", "\n", "self", ".", "choices_features", "=", "{", "\n", "'input_ids'", ":", "input_ids", ",", "\n", "'position_ids'", ":", "position_ids", ",", "\n", "'token_type_ids'", ":", "token_type_ids", "\n", "}", "\n", "self", ".", "lm_labels", "=", "lm_labels", "\n", "self", ".", "doc_len", "=", "doc_len", "\n", "self", ".", "context_len", "=", "context_len", "\n", "self", ".", "response_len", "=", "response_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.InputFeatures_train.__init__": [[87, 99], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "conv_id", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "\n", "lm_labels", ",", "weights", ",", "input_len", "=", "None", ")", ":", "\n", "        ", "self", ".", "conv_id", "=", "conv_id", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "position_ids", "=", "position_ids", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "lm_labels", "=", "lm_labels", "\n", "self", ".", "weights", "=", "weights", "\n", "if", "input_len", "is", "None", ":", "\n", "            ", "self", ".", "input_len", "=", "len", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_len", "=", "input_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.RedditExample.__init__": [[101, 106], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "conv_id", ",", "doc", ",", "context", ",", "response", ")", ":", "\n", "        ", "self", ".", "conv_id", "=", "conv_id", "\n", "self", ".", "doc", "=", "doc", "\n", "self", ".", "context", "=", "context", "\n", "self", ".", "response", "=", "response", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.RedditExample.__repr__": [[107, 110], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'conv_id = {}\\ndoc = {}\\ncontext = {}\\nresponse = {}'", ".", "format", "(", "\n", "self", ".", "conv_id", ",", "self", ".", "doc", ",", "self", ".", "context", ",", "self", ".", "response", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.RedditExample.__str__": [[111, 113], ["train_utils.RedditExample.__repr__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.RedditExample.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.load_model": [[16, 56], ["model.to", "torch.load", "train_utils.fix_state_dict_namespace", "start_model.load_state_dict", "logger.info", "os.path.exists", "ValueError", "logger.info", "args.init_checkpoint.endswith", "hasattr", "all", "logger.info", "model_state_dict[].type", "model._get_name", "s.startswith", "fix_state_dict_namespace.keys"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.fix_state_dict_namespace"], ["def", "load_model", "(", "model", ",", "checkpoint", ",", "args", ",", "verbose", "=", "False", ",", "set_type_embedding_to_zero", "=", "False", ")", ":", "\n", "    ", "n_gpu", "=", "args", ".", "n_gpu", "\n", "device", "=", "args", ".", "device", "\n", "if", "checkpoint", "is", "None", "or", "checkpoint", "==", "\"None\"", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "'no checkpoint provided for %s!'", "%", "model", ".", "_get_name", "(", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'checkpoint %s not exist'", "%", "checkpoint", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "'loading finetuned model from %s'", "%", "checkpoint", ")", "\n", "", "model_state_dict", "=", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model_state_dict", "=", "fix_state_dict_namespace", "(", "model_state_dict", ")", "\n", "\n", "if", "set_type_embedding_to_zero", ":", "\n", "            ", "if", "args", ".", "init_checkpoint", ".", "endswith", "(", "'pkl'", ")", ":", "\n", "\n", "                ", "tmp", "=", "model_state_dict", "[", "'transformer.wte.weight'", "]", ".", "type", "(", "'torch.FloatTensor'", ")", "\n", "tmp", "=", "tmp", "[", "TOKEN_TYPE_CXT", ",", ":", "]", "\n", "\n", "model_state_dict", "[", "'transformer.wte.weight'", "]", "[", "TOKEN_TYPE_CXT", ",", ":", "]", "=", "tmp", "*", "0", "\n", "model_state_dict", "[", "'transformer.wte.weight'", "]", "[", "TOKEN_TYPE_DOC", ",", ":", "]", "=", "tmp", "*", "0", "\n", "model_state_dict", "[", "'lm_head.decoder.weight'", "]", "[", "TOKEN_TYPE_CXT", ",", ":", "]", "=", "tmp", "*", "0", "\n", "model_state_dict", "[", "'lm_head.decoder.weight'", "]", "[", "TOKEN_TYPE_DOC", ",", ":", "]", "=", "tmp", "*", "0", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "model_state_dict", "[", "'wte.weight'", "]", "[", "TOKEN_TYPE_CXT", ",", ":", "]", "\n", "model_state_dict", "[", "'wte.weight'", "]", "[", "TOKEN_TYPE_CXT", ",", ":", "]", "=", "tmp", "*", "0", "\n", "model_state_dict", "[", "'wte.weight'", "]", "[", "TOKEN_TYPE_DOC", ",", ":", "]", "=", "tmp", "*", "0", "\n", "model_state_dict", "[", "'lm_head.decoder.weight'", "]", "[", "TOKEN_TYPE_CXT", ",", ":", "]", "=", "tmp", "*", "0", "\n", "model_state_dict", "[", "'lm_head.decoder.weight'", "]", "[", "TOKEN_TYPE_DOC", ",", ":", "]", "=", "tmp", "*", "0", "\n", "", "", "start_model", "=", "model", "\n", "if", "(", "hasattr", "(", "model", ",", "\"transformer\"", ")", "\n", "and", "all", "(", "not", "s", ".", "startswith", "(", "'transformer.'", ")", "\n", "for", "s", "in", "model_state_dict", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'loading transfomer only'", ")", "\n", "start_model", "=", "model", ".", "transformer", "\n", "", "start_model", ".", "load_state_dict", "(", "model_state_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.fix_state_dict_namespace": [[57, 71], ["zip", "t.startswith", "old_keys.append", "new_keys.append", "model_state_dict.pop", "t.replace"], "function", ["None"], ["", "def", "fix_state_dict_namespace", "(", "model_state_dict", ")", ":", "\n", "    ", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "t", "in", "model_state_dict", ":", "\n", "        ", "new_key", "=", "t", "\n", "if", "t", ".", "startswith", "(", "'module.'", ")", ":", "\n", "            ", "new_key", "=", "t", ".", "replace", "(", "'module.'", ",", "''", ")", "\n", "", "old_keys", ".", "append", "(", "t", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "\n", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "        ", "model_state_dict", "[", "new_key", "]", "=", "model_state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "return", "model_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.boolean_string": [[114, 118], ["s.lower", "ValueError", "s.lower"], "function", ["None"], ["", "", "def", "boolean_string", "(", "s", ")", ":", "\n", "    ", "if", "s", ".", "lower", "(", ")", "not", "in", "{", "'false'", ",", "'true'", "}", ":", "\n", "        ", "raise", "ValueError", "(", "'Not a valid boolean string'", ")", "\n", "", "return", "s", ".", "lower", "(", ")", "==", "'true'", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.get_eval_list_same_length": [[119, 210], ["zip", "collections.defaultdict", "sorted", "open", "tokenizer.encode", "tokenizer.encode", "train_utils.InputFeatures", "torch.stack", "torch.stack", "torch.stack", "torch.nn.utils.rnn.pad_sequence", "torch.tensor", "torch.tensor", "torch.tensor", "train_utils.get_eval_list_same_length.featurize"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "def", "get_eval_list_same_length", "(", "input_file", ",", "tokenizer", ",", "max_batch_size", ",", "\n", "norm", "=", "True", ",", "for_eval", "=", "False", ")", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "with", "open", "(", "input_file", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "content", "=", "[", "l", ".", "split", "(", "'\\t'", ")", "for", "l", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", "\n", "", "docs", ",", "context", ",", "response", "=", "[", "c", "[", "0", "]", "for", "c", "in", "content", "]", ",", "[", "c", "[", "1", "]", "for", "c", "in", "content", "]", ",", "[", "c", "[", "2", ":", "]", "for", "c", "in", "content", "]", "\n", "i", "=", "0", "\n", "for", "doc", ",", "src", ",", "tgt_all", "in", "zip", "(", "docs", ",", "context", ",", "response", ")", ":", "\n", "        ", "for", "tgt", "in", "tgt_all", ":", "\n", "            ", "if", "norm", ":", "\n", "                ", "doc_line", "=", "' '", ".", "join", "(", "doc", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "src_line", "=", "' '", ".", "join", "(", "src", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "tgt_line", "=", "' '", ".", "join", "(", "tgt", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "doc_line", "=", "doc", ".", "strip", "(", ")", "\n", "src_line", "=", "src", ".", "strip", "(", ")", "\n", "tgt_line", "=", "tgt", ".", "strip", "(", ")", "\n", "", "examples", ".", "append", "(", "RedditExample", "(", "i", ",", "doc_line", ",", "src_line", ",", "tgt_line", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "def", "featurize", "(", "example", ",", "doc_limit", "=", "256", ",", "cxt_limit", "=", "128", ",", "rsp_limit", "=", "128", ",", "doc_start_pos", "=", "400", ")", ":", "\n", "        ", "conv_id", "=", "example", ".", "conv_id", "\n", "end_of_text_id", "=", "tokenizer", ".", "encoder", "[", "END_OF_TEXT_TOKEN", "]", "\n", "context_id", "=", "[", "tokenizer", ".", "encode", "(", "x", ")", "+", "[", "end_of_text_id", "]", "for", "x", "in", "example", ".", "context", ".", "split", "(", "' EOS '", ")", "]", "\n", "context_id", "=", "[", "x", "for", "sublist", "in", "context_id", "for", "x", "in", "sublist", "]", "\n", "context_id", "=", "context_id", "[", ":", "-", "1", "]", "\n", "doc_id", "=", "tokenizer", ".", "encode", "(", "example", ".", "doc", ")", "\n", "\n", "response_id", "=", "tokenizer", ".", "encode", "(", "example", ".", "response", ")", "\n", "\n", "doc_id", "=", "doc_id", "[", ":", "doc_limit", "]", "if", "len", "(", "doc_id", ")", ">", "doc_limit", "else", "doc_id", "\n", "context_id", "=", "context_id", "[", "-", "cxt_limit", ":", "]", "if", "len", "(", "context_id", ")", ">", "cxt_limit", "else", "context_id", "\n", "response_id", "=", "response_id", "[", ":", "rsp_limit", "]", "if", "len", "(", "response_id", ")", ">", "rsp_limit", "else", "response_id", "\n", "\n", "input_ids", "=", "doc_id", "+", "[", "end_of_text_id", "]", "+", "context_id", "+", "[", "end_of_text_id", "]", "\n", "\n", "lm_labels", "=", "response_id", "\n", "\n", "doc_len", "=", "len", "(", "doc_id", ")", "+", "1", "\n", "\n", "position_ids", "=", "list", "(", "range", "(", "doc_start_pos", ",", "doc_start_pos", "+", "doc_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "len", "(", "input_ids", ")", "-", "doc_len", ")", ")", "\n", "\n", "token_type_ids", "=", "[", "TOKEN_TYPE_DOC", "]", "*", "doc_len", "+", "[", "TOKEN_TYPE_CXT", "]", "*", "(", "len", "(", "input_ids", ")", "-", "doc_len", ")", "\n", "\n", "assert", "(", "len", "(", "input_ids", ")", "==", "len", "(", "position_ids", ")", "==", "len", "(", "token_type_ids", ")", ")", "\n", "return", "InputFeatures", "(", "conv_id", ",", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "\n", "lm_labels", ",", "len", "(", "doc_id", ")", ",", "len", "(", "input_ids", ")", ",", "len", "(", "response_id", ")", ")", "\n", "\n", "", "def", "batch_feature_same_len", "(", "features", ")", ":", "\n", "\n", "        ", "input_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'input_ids'", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ")", "\n", "position_ids", "=", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'position_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ")", "\n", "token_type_ids", "=", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'token_type_ids'", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "f", "in", "features", "]", ")", "\n", "labels", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "\n", "[", "torch", ".", "tensor", "(", "f", ".", "lm_labels", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "doc_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "doc_len", "for", "f", "in", "features", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "context_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "context_len", "for", "f", "in", "features", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "response_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "response_len", "for", "f", "in", "features", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "labels", ",", "\n", "context_len", ",", "response_len", ")", "\n", "\n", "", "features", "=", "[", "featurize", "(", "e", ")", "for", "e", "in", "examples", "]", "\n", "dataloader_pre", "=", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "features", ":", "\n", "        ", "dataloader_pre", "[", "f", ".", "context_len", "+", "f", ".", "response_len", "if", "for_eval", "else", "f", ".", "context_len", "]", ".", "append", "(", "f", ")", "\n", "\n", "", "dataloader", "=", "[", "]", "\n", "for", "l", "in", "sorted", "(", "dataloader_pre", ")", ":", "\n", "        ", "f", "=", "batch_feature_same_len", "(", "dataloader_pre", "[", "l", "]", ")", "\n", "if", "len", "(", "f", "[", "0", "]", ")", "<=", "max_batch_size", ":", "\n", "            ", "dataloader", ".", "append", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "start_index", "=", "0", "\n", "while", "True", ":", "\n", "                ", "dataloader", ".", "append", "(", "[", "ff", "[", "start_index", ":", "start_index", "+", "max_batch_size", "]", "\n", "for", "ff", "in", "f", "]", ")", "\n", "start_index", "+=", "max_batch_size", "\n", "if", "start_index", ">=", "len", "(", "f", "[", "0", "]", ")", ":", "\n", "                    ", "break", "\n", "", "", "", "", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.get_eval_list_same_length_with_order": [[211, 304], ["zip", "collections.defaultdict", "open", "examples.append", "re.split", "list", "tokenizer.encode", "train_utils.InputFeatures", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "train_utils.get_eval_list_same_length.featurize"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "def", "get_eval_list_same_length_with_order", "(", "input_file", ",", "tokenizer", ",", "max_batch_size", ",", "norm", "=", "True", ",", "for_eval", "=", "False", ",", "sort_data", "=", "True", ")", ":", "\n", "\n", "    ", "examples", "=", "[", "]", "\n", "with", "open", "(", "input_file", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "content", "=", "[", "l", ".", "split", "(", "'\\t'", ")", "for", "l", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", "\n", "\n", "", "docs", ",", "context", ",", "response", "=", "[", "c", "[", "0", "]", "for", "c", "in", "content", "]", ",", "[", "c", "[", "1", "]", "for", "c", "in", "content", "]", ",", "[", "c", "[", "2", ":", "]", "for", "c", "in", "content", "]", "\n", "i", "=", "0", "\n", "for", "doc", ",", "src", ",", "tgt_all", "in", "zip", "(", "docs", ",", "context", ",", "response", ")", ":", "\n", "        ", "if", "norm", ":", "\n", "            ", "doc_line", "=", "' '", ".", "join", "(", "doc", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "src_line", "=", "' '", ".", "join", "(", "src", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "tgt_line", "=", "[", "' '", ".", "join", "(", "tgt", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "for", "tgt", "in", "tgt_all", "]", "\n", "", "else", ":", "\n", "            ", "doc_line", "=", "doc", ".", "strip", "(", ")", "\n", "src_line", "=", "src", ".", "strip", "(", ")", "\n", "tgt_line", "=", "[", "tgt", ".", "strip", "(", ")", "for", "tgt", "in", "tgt_all", "]", "\n", "", "examples", ".", "append", "(", "RedditExample", "(", "i", ",", "doc_line", ",", "src_line", ",", "tgt_line", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "def", "multi_turn_enc", "(", "sent", ")", ":", "\n", "        ", "sent", "=", "re", ".", "split", "(", "'<\\|endoftext\\|>|EOS'", ",", "sent", ")", "\n", "return", "list", "(", "np", ".", "concatenate", "(", "[", "tokenizer", ".", "encode", "(", "s", ".", "strip", "(", ")", ")", "+", "[", "tokenizer", ".", "encoder", "[", "END_OF_TEXT_TOKEN", "]", "]", "for", "s", "in", "sent", "]", ")", ")", "\n", "\n", "", "def", "featurize", "(", "example", ",", "doc_limit", "=", "256", ",", "cxt_limit", "=", "128", ",", "rsp_limit", "=", "128", ",", "doc_start_pos", "=", "400", ")", ":", "\n", "        ", "conv_id", "=", "example", ".", "conv_id", "\n", "end_of_text_id", "=", "tokenizer", ".", "encoder", "[", "END_OF_TEXT_TOKEN", "]", "\n", "context_id", "=", "[", "tokenizer", ".", "encode", "(", "x", ")", "+", "[", "end_of_text_id", "]", "for", "x", "in", "example", ".", "context", ".", "split", "(", "' EOS '", ")", "]", "\n", "context_id", "=", "[", "x", "for", "sublist", "in", "context_id", "for", "x", "in", "sublist", "]", "\n", "context_id", "=", "context_id", "[", ":", "-", "1", "]", "\n", "doc_id", "=", "tokenizer", ".", "encode", "(", "example", ".", "doc", ")", "\n", "\n", "response_id", "=", "multi_turn_enc", "(", "example", ".", "response", "[", "0", "]", ")", "if", "for_eval", "else", "None", "\n", "\n", "doc_id", "=", "doc_id", "[", ":", "doc_limit", "]", "if", "len", "(", "doc_id", ")", ">", "doc_limit", "else", "doc_id", "\n", "context_id", "=", "context_id", "[", "-", "cxt_limit", ":", "]", "if", "len", "(", "context_id", ")", ">", "cxt_limit", "else", "context_id", "\n", "if", "response_id", ":", "\n", "            ", "response_id", "=", "response_id", "[", ":", "rsp_limit", "]", "if", "len", "(", "response_id", ")", ">", "rsp_limit", "else", "response_id", "\n", "\n", "", "input_ids", "=", "doc_id", "+", "[", "end_of_text_id", "]", "+", "context_id", "+", "[", "end_of_text_id", "]", "\n", "\n", "lm_labels", "=", "response_ids", "if", "for_eval", "else", "example", ".", "response", "\n", "\n", "doc_len", "=", "len", "(", "doc_id", ")", "+", "1", "\n", "\n", "position_ids", "=", "list", "(", "range", "(", "doc_start_pos", ",", "doc_start_pos", "+", "doc_len", ",", "1", ")", ")", "+", "list", "(", "range", "(", "len", "(", "input_ids", ")", "-", "doc_len", ")", ")", "\n", "\n", "token_type_id", "=", "[", "TOKEN_TYPE_DOC", "]", "*", "doc_len", "+", "[", "TOKEN_TYPE_CXT", "]", "*", "(", "len", "(", "input_ids", ")", "-", "doc_len", ")", "\n", "assert", "(", "len", "(", "input_ids", ")", "==", "len", "(", "position_ids", ")", "==", "len", "(", "token_type_id", ")", ")", "\n", "\n", "return", "InputFeatures", "(", "conv_id", ",", "input_ids", ",", "position_ids", ",", "token_type_id", ",", "\n", "lm_labels", ",", "len", "(", "doc_id", ")", ",", "len", "(", "input_ids", ")", "-", "1", ",", "len", "(", "response_ids", ")", "-", "1", "if", "for_eval", "else", "-", "1", ")", "\n", "\n", "", "def", "batch_feature_same_len", "(", "features", ")", ":", "\n", "        ", "if", "for_eval", ":", "\n", "            ", "input_ids", "=", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'input_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", "\n", "position_ids", "=", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'position_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", "\n", "token_type_ids", "=", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'token_type_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", "\n", "labels", "=", "[", "torch", ".", "tensor", "(", "f", ".", "lm_labels", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'input_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", ")", "\n", "position_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'position_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", ")", "\n", "token_type_ids", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "f", ".", "choices_features", "[", "'token_type_ids'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", ")", "\n", "labels", "=", "[", "f", ".", "lm_labels", "for", "f", "in", "features", "]", "\n", "", "doc_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "doc_len", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "context_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "context_len", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "response_len", "=", "torch", ".", "tensor", "(", "[", "f", ".", "response_len", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "conv_ids", "=", "torch", ".", "tensor", "(", "[", "torch", ".", "tensor", "(", "f", ".", "conv_id", ",", "dtype", "=", "torch", ".", "long", ")", "for", "f", "in", "features", "]", ")", "\n", "\n", "return", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "labels", ",", "doc_len", ",", "context_len", ",", "response_len", ",", "conv_ids", "\n", "\n", "", "features", "=", "[", "featurize", "(", "e", ")", "for", "e", "in", "examples", "]", "\n", "dataloader_pre", "=", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "features", ":", "\n", "        ", "dataloader_pre", "[", "f", ".", "context_len", "+", "f", ".", "response_len", "if", "for_eval", "else", "f", ".", "context_len", "]", ".", "append", "(", "f", ")", "\n", "\n", "", "dataloader", "=", "[", "]", "\n", "if", "sort_data", ":", "\n", "        ", "sorted_data", "=", "sorted", "(", "dataloader_pre", ")", "\n", "", "else", ":", "\n", "        ", "sorted_data", "=", "dataloader_pre", "\n", "", "for", "l", "in", "sorted_data", ":", "\n", "        ", "f", "=", "batch_feature_same_len", "(", "dataloader_pre", "[", "l", "]", ")", "\n", "if", "len", "(", "f", "[", "0", "]", ")", "<=", "max_batch_size", ":", "\n", "            ", "dataloader", ".", "append", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "start_index", "=", "0", "\n", "while", "True", ":", "\n", "                ", "dataloader", ".", "append", "(", "[", "ff", "[", "start_index", ":", "start_index", "+", "max_batch_size", "]", "for", "ff", "in", "f", "]", ")", "\n", "start_index", "+=", "max_batch_size", "\n", "if", "start_index", ">=", "len", "(", "f", "[", "0", "]", ")", ":", "\n", "                    ", "break", "\n", "", "", "", "", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.train_utils.set_lr": [[305, 318], ["lsp_model.optim.noam_decay", "lsp_model.optim.noamwd_decay", "lsp_model.optim.warmup_linear"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.noam_decay", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.noamwd_decay", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.optimization_openai.warmup_linear"], ["", "def", "set_lr", "(", "optimizer", ",", "step", ",", "schedule", ",", "lr", ",", "\n", "warmup_steps", ",", "warmup_proportion", ",", "n_embd", ",", "tot_steps", ")", ":", "\n", "    ", "if", "schedule", "==", "'None'", ":", "\n", "        ", "lr_this_step", "=", "lr", "\n", "", "elif", "schedule", "==", "'noam'", ":", "\n", "        ", "lr_this_step", "=", "lr", "*", "1e4", "*", "noam_decay", "(", "step", "+", "1", ",", "warmup_steps", ",", "n_embd", ")", "\n", "", "elif", "schedule", "==", "'noamwd'", ":", "\n", "        ", "lr_this_step", "=", "lr", "*", "1e4", "*", "noamwd_decay", "(", "step", "+", "1", ",", "warmup_steps", ",", "n_embd", ")", "\n", "", "else", ":", "\n", "        ", "lr_this_step", "=", "lr", "*", "warmup_linear", "(", "step", "/", "tot_steps", ",", "\n", "warmup_proportion", ")", "\n", "", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.cal_BLEU_4": [[27, 41], ["enumerate", "zip", "len", "len", "len", "len", "pycocoevalcap.bleu.bleu.Bleu().compute_score", "pycocoevalcap.bleu.bleu.Bleu().compute_score", "pycocoevalcap.bleu.bleu.Bleu", "pycocoevalcap.bleu.bleu.Bleu"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider.Cider.compute_score"], ["def", "cal_BLEU_4", "(", "generated", ",", "reference", ",", "is_corpus", "=", "False", ")", ":", "\n", "    ", "BLEUscore", "=", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "\n", "for", "idx", ",", "g", "in", "enumerate", "(", "generated", ")", ":", "\n", "        ", "if", "is_corpus", ":", "\n", "            ", "score", ",", "scores", "=", "Bleu", "(", "4", ")", ".", "compute_score", "(", "reference", ",", "{", "0", ":", "[", "g", "]", "}", ")", "\n", "", "else", ":", "\n", "            ", "score", ",", "scores", "=", "Bleu", "(", "4", ")", ".", "compute_score", "(", "{", "0", ":", "[", "reference", "[", "0", "]", "[", "idx", "]", "]", "}", ",", "{", "0", ":", "[", "g", "]", "}", ")", "\n", "", "for", "i", ",", "s", "in", "zip", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ",", "score", ")", ":", "\n", "            ", "BLEUscore", "[", "i", "]", "+=", "s", "\n", "", "", "BLEUscore", "[", "0", "]", "=", "BLEUscore", "[", "0", "]", "/", "len", "(", "generated", ")", "\n", "BLEUscore", "[", "1", "]", "=", "BLEUscore", "[", "1", "]", "/", "len", "(", "generated", ")", "\n", "BLEUscore", "[", "2", "]", "=", "BLEUscore", "[", "2", "]", "/", "len", "(", "generated", ")", "\n", "BLEUscore", "[", "3", "]", "=", "BLEUscore", "[", "3", "]", "/", "len", "(", "generated", ")", "\n", "return", "BLEUscore", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.cal_entropy": [[42, 58], ["range", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "gg.rstrip().split", "range", "counter[].values", "range", "sum", "gg.rstrip", "counter[].values", "len", "len", "numpy.log", "numpy.log", "counter[].values"], "function", ["None"], ["", "def", "cal_entropy", "(", "generated", ")", ":", "\n", "    ", "etp_score", "=", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "\n", "div_score", "=", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "\n", "counter", "=", "[", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", "]", "\n", "for", "gg", "in", "generated", ":", "\n", "        ", "g", "=", "gg", ".", "rstrip", "(", ")", ".", "split", "(", ")", "\n", "for", "n", "in", "range", "(", "4", ")", ":", "\n", "            ", "for", "idx", "in", "range", "(", "len", "(", "g", ")", "-", "n", ")", ":", "\n", "                ", "ngram", "=", "' '", ".", "join", "(", "g", "[", "idx", ":", "idx", "+", "n", "+", "1", "]", ")", "\n", "counter", "[", "n", "]", "[", "ngram", "]", "+=", "1", "\n", "", "", "", "for", "n", "in", "range", "(", "4", ")", ":", "\n", "        ", "total", "=", "sum", "(", "counter", "[", "n", "]", ".", "values", "(", ")", ")", "+", "1e-10", "\n", "for", "v", "in", "counter", "[", "n", "]", ".", "values", "(", ")", ":", "\n", "            ", "etp_score", "[", "n", "]", "+=", "-", "(", "v", "+", "0.0", ")", "/", "total", "*", "(", "np", ".", "log", "(", "v", "+", "0.0", ")", "-", "np", ".", "log", "(", "total", ")", ")", "\n", "", "div_score", "[", "n", "]", "=", "(", "len", "(", "counter", "[", "n", "]", ".", "values", "(", ")", ")", "+", "0.0", ")", "/", "total", "\n", "", "return", "etp_score", ",", "div_score", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.eval_model_generation": [[59, 119], ["model.eval", "torch.no_grad", "tqdm.tqdm", "enumerate", "eval_utils.cal_BLEU_4", "eval_utils.cal_entropy", "print", "print", "print", "print", "print", "range", "sys.stdout.flush", "torch.cuda.empty_cache", "gpt2_training.generation.generate_sequence", "sources.extend", "out.tolist.tolist", "outs.extend", "isinstance", "targets.extend", "tokenizer.decode().encode().decode().strip", "tokenizer.decode().encode().decode().strip", "tokenizer.decode().encode().decode().strip", "print", "print", "print", "print", "len", "int", "isinstance", "input_ids.size", "torch.stack", "input_ids.cpu().numpy", "new_batch.append", "new_batch.append", "new_token_ids.append", "x.cpu().numpy", "tokenizer.decode().encode().decode", "tokenizer.decode().encode().decode", "tokenizer.decode().encode().decode", "len", "t.to", "torch.cat", "input_ids.cpu", "t.item", "str", "str", "str", "str", "x.cpu", "tokenizer.decode().encode", "tokenizer.decode().encode", "tokenizer.decode().encode", "round", "round", "round", "torch.zeros", "torch.ones", "tokenizer.decode", "tokenizer.decode", "tokenizer.decode", "gpt2_training.generation.cut_seq_to_eos", "gpt2_training.generation.cut_seq_to_eos", "gpt2_training.generation.cut_seq_to_eos"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.cal_BLEU_4", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.cal_entropy", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.generate_sequence", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.cut_seq_to_eos", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.cut_seq_to_eos", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.generation.cut_seq_to_eos"], ["", "def", "eval_model_generation", "(", "model", ",", "tokenizer", ",", "eval_dataloader", ",", "epoch_id", ",", "args", ",", "use_beam_search", "=", "False", ",", "beam_width", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "outs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "sources", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "eval_dataloader", ")", ",", "desc", "=", "f\"Epoch {epoch_id-1} dev set\"", ",", "miniters", "=", "int", "(", "len", "(", "eval_dataloader", ")", "/", "10", ")", ")", "as", "pbar", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "eval_dataloader", ")", ":", "\n", "                ", "new_batch", "=", "[", "]", "\n", "for", "t", "in", "batch", ":", "\n", "                    ", "if", "isinstance", "(", "t", ",", "list", ")", ":", "\n", "                        ", "new_batch", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "                        ", "new_batch", ".", "append", "(", "t", ".", "to", "(", "args", ".", "device", ")", ")", "\n", "", "", "input_ids", ",", "position_ids", ",", "token_ids", ",", "label_ids", ",", "src_len", ",", "_", "=", "new_batch", "\n", "if", "not", "args", ".", "no_token_id", ":", "\n", "                    ", "new_token_ids", "=", "[", "]", "\n", "tot_len", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "for", "s", "in", "src_len", ":", "\n", "                        ", "new_token_ids", ".", "append", "(", "torch", ".", "cat", "(", "(", "torch", ".", "zeros", "(", "[", "1", ",", "s", "]", ",", "dtype", "=", "token_ids", ".", "dtype", ",", "device", "=", "token_ids", ".", "device", ")", ",", "torch", ".", "ones", "(", "[", "1", ",", "tot_len", "-", "s", "]", ",", "dtype", "=", "token_ids", ".", "dtype", ",", "device", "=", "token_ids", ".", "device", ")", ")", ",", "1", ")", ")", "\n", "", "token_ids", "=", "torch", ".", "stack", "(", "new_token_ids", ",", "dim", "=", "1", ")", "\n", "", "if", "args", ".", "no_token_id", ":", "\n", "                    ", "token_ids", "=", "None", "\n", "\n", "\n", "", "out", "=", "generate_sequence", "(", "model", ",", "input_ids", ",", "position_ids", ",", "token_ids", ",", "\n", "length", "=", "args", ".", "generation_length", ",", "\n", "start_token", "=", "None", ",", "\n", "temperature", "=", "args", ".", "temperature", ",", "top_k", "=", "args", ".", "top_k", ",", "\n", "sample", "=", "args", ".", "is_sampling", ")", "\n", "sources", ".", "extend", "(", "input_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "out", "=", "out", ".", "tolist", "(", ")", "\n", "outs", ".", "extend", "(", "out", ")", "\n", "target", "=", "[", "[", "x", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "x", "in", "l", "if", "x", "!=", "-", "1", "]", "for", "l", "in", "label_ids", "]", "\n", "if", "isinstance", "(", "target", "[", "0", "]", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "                    ", "target", "=", "[", "[", "t", ".", "item", "(", ")", "for", "t", "in", "tt", "]", "for", "tt", "in", "target", "]", "\n", "", "targets", ".", "extend", "(", "target", ")", "\n", "", "val_src", "=", "[", "tokenizer", ".", "decode", "(", "cut_seq_to_eos", "(", "s", ")", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", ".", "strip", "(", ")", "for", "s", "in", "sources", "]", "\n", "val_set", "=", "[", "tokenizer", ".", "decode", "(", "cut_seq_to_eos", "(", "s", ")", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", ".", "strip", "(", ")", "for", "s", "in", "targets", "]", "\n", "gen", "=", "[", "tokenizer", ".", "decode", "(", "cut_seq_to_eos", "(", "s", ")", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", ".", "strip", "(", ")", "for", "s", "in", "outs", "]", "\n", "[", "bleu1s", ",", "bleu2s", ",", "bleu3s", ",", "bleu4s", "]", "=", "cal_BLEU_4", "(", "gen", ",", "{", "0", ":", "val_set", "}", ",", "is_corpus", "=", "False", ")", "\n", "etp_score", ",", "dist_score", "=", "cal_entropy", "(", "gen", ")", "\n", "\n", "print", "(", "\"=\"", "*", "80", ")", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "'Val BLEU: '", "+", "' '", ".", "join", "(", "[", "str", "(", "round", "(", "it", ",", "3", ")", ")", "for", "it", "in", "(", "bleu1s", ",", "bleu2s", ",", "bleu3s", ",", "bleu4s", ")", "]", ")", ")", "\n", "print", "(", "'Val Entropy: '", "+", "' '", ".", "join", "(", "[", "str", "(", "round", "(", "it", ",", "3", ")", ")", "for", "it", "in", "(", "etp_score", "[", "0", "]", ",", "etp_score", "[", "1", "]", ",", "etp_score", "[", "2", "]", ",", "etp_score", "[", "3", "]", ")", "]", ")", ")", "\n", "print", "(", "'Val Diversity: '", "+", "' '", ".", "join", "(", "[", "str", "(", "round", "(", "it", ",", "3", ")", ")", "for", "it", "in", "(", "dist_score", "[", "0", "]", ",", "dist_score", "[", "1", "]", ",", "dist_score", "[", "2", "]", ",", "dist_score", "[", "3", "]", ")", "]", ")", ")", "\n", "for", "n_s", "in", "range", "(", "2", ",", "args", ".", "nsamples", ")", ":", "\n", "                ", "print", "(", "\"=\"", "*", "40", "+", "\" SAMPLE \"", "+", "str", "(", "n_s", ")", "+", "\"=\"", "*", "40", ")", "\n", "src", "=", "val_src", "[", "-", "1", "-", "n_s", "*", "50", "]", "\n", "gt", "=", "val_set", "[", "-", "1", "-", "n_s", "*", "50", "]", "\n", "resp", "=", "gen", "[", "-", "1", "-", "n_s", "*", "50", "]", "\n", "print", "(", "f\"Source: \\t {src} \\n Oracle: \\t {gt} \\n Resp: \\t {resp}\\n\"", ")", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "\"=\"", "*", "80", ")", "\n", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "gen", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.eval_model_loss": [[120, 143], ["logger.info", "model.eval", "print", "hasattr", "torch.no_grad", "enumerate", "tuple", "model_", "tot_loss.append", "tot_ppl.append", "tot_sample.append", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "t.to", "loss.mean().item", "ppl.mean().item", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "loss.mean", "ppl.mean"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["", "", "", "def", "eval_model_loss", "(", "model", ",", "tokenizer", ",", "eval_dataloader", ",", "epoch_id", ",", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'compute eval model loss, using eval mode, please change it back to train after calling this function'", ")", "\n", "model", ".", "eval", "(", ")", "\n", "tot_loss", "=", "[", "]", "\n", "tot_ppl", "=", "[", "]", "\n", "tot_sample", "=", "[", "]", "\n", "model_", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "eval_dataloader", ")", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "input_ids", ",", "position_ids", ",", "token_ids", ",", "label_ids", ",", "doc_len", ",", "src_len", ",", "_", "=", "batch", "\n", "\n", "\n", "if", "args", ".", "no_token_id", ":", "\n", "                ", "token_ids", "=", "None", "\n", "", "n_sample", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "\n", "loss", ",", "ppl", "=", "model_", "(", "input_ids", ",", "position_ids", ",", "token_ids", ",", "label_ids", ")", "\n", "tot_loss", ".", "append", "(", "loss", ".", "mean", "(", ")", ".", "item", "(", ")", "*", "n_sample", ")", "\n", "tot_ppl", ".", "append", "(", "ppl", ".", "mean", "(", ")", ".", "item", "(", ")", "*", "n_sample", ")", "\n", "tot_sample", ".", "append", "(", "n_sample", ")", "\n", "", "", "print", "(", "f\"\\n Epoch {epoch_id}: Val loss {np.sum(tot_loss) / np.sum(tot_sample)} Val ppl {np.sum(tot_ppl) / np.sum(tot_sample)} \"", ")", "\n", "return", "np", ".", "sum", "(", "tot_loss", ")", "/", "np", ".", "sum", "(", "tot_sample", ")", ",", "np", ".", "sum", "(", "tot_ppl", ")", "/", "np", ".", "sum", "(", "tot_sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.eval_model_loss_joint_training": [[144, 191], ["logger.info", "model.eval", "print", "hasattr", "torch.no_grad", "enumerate", "tuple", "eval_utils.retrieve_top_docs", "range", "torch.softmax", "torch.exp", "tot_loss.append", "tot_ppl.append", "tot_reward.append", "tot_sample.append", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "data_loader.convert_examples_to_features_dynamic", "eval_dataloader._batch_feature", "tuple", "model_.forward_pointwise", "loss_ret_topK.append", "torch.tensor().to", "torch.mean", "t.to", "gpt2_training.train_utils.RedditExample", "torch.mean", "torch.sum", "torch.mean.mean().item", "torch.exp.mean().item", "torch.exp().mean().item", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "doc.strip().split", "enumerate", "t.to", "torch.tensor", "torch.logsumexp", "zip", "torch.stack", "torch.mean.mean", "torch.exp.mean", "torch.exp().mean", "doc.strip", "torch.log_softmax", "torch.stack", "torch.tensor().to", "torch.exp", "torch.tensor", "torch.stack"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dstc.batch_eval.eval", "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.retrieve_top_docs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.convert_examples_to_features_dynamic", "home.repos.pwc.inspect_result.dreasysnail_RetGen.dialogpt.data_loader.DynamicBatchingLoader._batch_feature", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.forward_pointwise", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["", "def", "eval_model_loss_joint_training", "(", "model", ",", "retriever", ",", "all_passages", ",", "enc", ",", "eval_dataloader", ",", "epoch_id", ",", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'compute eval model loss, using eval mode, please change it back to train after calling this function'", ")", "\n", "model", ".", "eval", "(", ")", "\n", "tot_loss", "=", "[", "]", "\n", "tot_ppl", "=", "[", "]", "\n", "tot_sample", "=", "[", "]", "\n", "tot_reward", "=", "[", "]", "\n", "model_", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "eval_dataloader", ")", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "input_ids", ",", "position_ids", ",", "token_ids", ",", "label_ids", ",", "doc_len", ",", "src_len", ",", "_", "=", "batch", "\n", "\n", "ret_passages", ",", "ret_scores", ",", "cxt_str", ",", "rsp_str", "=", "retrieve_top_docs", "(", "input_ids", ",", "enc", ",", "retriever", ",", "all_passages", ",", "args", ")", "\n", "loss_ret_topK", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "args", ".", "n_docs", ")", ":", "\n", "\n", "                ", "doc_lines", "=", "[", "' '", ".", "join", "(", "doc", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "for", "doc", "in", "ret_passages", "[", "t", "]", "]", "\n", "examples", "=", "[", "RedditExample", "(", "i", ",", "doc_line", ",", "src_line", ",", "tgt_line", ")", "for", "i", ",", "(", "doc_line", ",", "src_line", ",", "tgt_line", ")", "in", "enumerate", "(", "zip", "(", "doc_lines", ",", "cxt_str", ",", "rsp_str", ")", ")", "]", "\n", "features", "=", "convert_examples_to_features_dynamic", "(", "examples", ",", "enc", ",", "args", ".", "max_seq_length", ")", "\n", "batch_ret", "=", "eval_dataloader", ".", "_batch_feature", "(", "features", ")", "\n", "batch_ret", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch_ret", ")", "\n", "input_ids_ret", ",", "position_ids_ret", ",", "token_ids_ret", ",", "label_ids_ret", ",", "*", "_", "=", "batch_ret", "\n", "loss_ret", ",", "_", "=", "model_", ".", "forward_pointwise", "(", "input_ids_ret", ",", "position_ids_ret", ",", "token_ids_ret", ",", "label_ids_ret", ")", "\n", "loss_ret_topK", ".", "append", "(", "loss_ret", ")", "\n", "\n", "", "normalized_score", "=", "torch", ".", "softmax", "(", "torch", ".", "tensor", "(", "ret_scores", ")", ".", "to", "(", "args", ".", "device", ")", ",", "dim", "=", "0", ")", "\n", "if", "args", ".", "avg_by_prob", ":", "\n", "                ", "loss", "=", "-", "torch", ".", "mean", "(", "torch", ".", "logsumexp", "(", "-", "torch", ".", "stack", "(", "loss_ret_topK", ",", "dim", "=", "0", ")", "+", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "ret_scores", ")", ".", "to", "(", "device", ")", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "normalized_score", "*", "torch", ".", "stack", "(", "loss_ret_topK", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", ")", "\n", "\n", "", "ppl", "=", "torch", ".", "exp", "(", "loss", ")", "\n", "n_sample", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "\n", "\n", "\n", "tot_loss", ".", "append", "(", "loss", ".", "mean", "(", ")", ".", "item", "(", ")", "*", "n_sample", ")", "\n", "tot_ppl", ".", "append", "(", "ppl", ".", "mean", "(", ")", ".", "item", "(", ")", "*", "n_sample", ")", "\n", "tot_reward", ".", "append", "(", "torch", ".", "exp", "(", "-", "torch", ".", "stack", "(", "loss_ret_topK", ")", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "*", "n_sample", ")", "\n", "\n", "tot_sample", ".", "append", "(", "n_sample", ")", "\n", "\n", "\n", "", "", "print", "(", "f\"\\n Epoch {epoch_id}: Val loss {np.sum(tot_loss) / np.sum(tot_sample):.3f} Val ppl {np.sum(tot_ppl) / np.sum(tot_sample):.3f} Val reward {np.sum(tot_reward) / np.sum(tot_sample):.3f}\"", ")", "\n", "\n", "return", "np", ".", "sum", "(", "tot_loss", ")", "/", "np", ".", "sum", "(", "tot_sample", ")", ",", "np", ".", "sum", "(", "tot_ppl", ")", "/", "np", ".", "sum", "(", "tot_sample", ")", ",", "np", ".", "sum", "(", "tot_reward", ")", "/", "np", ".", "sum", "(", "tot_sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.retrieve_top_docs": [[192, 232], ["torch.no_grad", "input_ids.cpu().numpy", "eval_utils.retrieve_top_docs.find_pad_start"], "function", ["None"], ["", "def", "retrieve_top_docs", "(", "input_ids", ",", "enc", ",", "retriever", ",", "all_passages", ",", "args", ")", ":", "\n", "    ", "\"\"\"\n    docstring\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "input_ids_cpu", "=", "input_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "start_idx", "=", "[", "np", ".", "where", "(", "o", "==", "EOS_ID", ")", "[", "0", "]", "[", "0", "]", "for", "o", "in", "input_ids_cpu", "]", "\n", "end_idx", "=", "[", "np", ".", "where", "(", "o", "==", "EOS_ID", ")", "[", "0", "]", "[", "-", "1", "]", "for", "o", "in", "input_ids_cpu", "]", "\n", "def", "find_pad_start", "(", "input_ids_cpu", ")", ":", "\n", "            ", "pad_idx", "=", "[", "None", "]", "*", "len", "(", "input_ids_cpu", ")", "\n", "i", "=", "len", "(", "input_ids_cpu", "[", "0", "]", ")", "-", "1", "\n", "rows", "=", "set", "(", "[", "idx", "for", "idx", ",", "x", "in", "enumerate", "(", "input_ids_cpu", "[", ":", ",", "i", "]", ")", "if", "x", "!=", "0", "]", ")", "\n", "all_rows", "=", "set", "(", "list", "(", "range", "(", "len", "(", "input_ids_cpu", ")", ")", ")", ")", "\n", "while", "i", ">=", "-", "1", ":", "\n", "                ", "remain_rows", "=", "all_rows", "-", "rows", "\n", "if", "len", "(", "remain_rows", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "for", "r", "in", "remain_rows", ".", "copy", "(", ")", ":", "\n", "                    ", "if", "input_ids_cpu", "[", "r", ",", "i", "]", "!=", "0", "or", "i", "==", "-", "1", ":", "\n", "                        ", "rows", ".", "add", "(", "r", ")", "\n", "pad_idx", "[", "r", "]", "=", "i", "+", "1", "\n", "", "", "i", "-=", "1", "\n", "", "return", "pad_idx", "\n", "\n", "", "pad_idx", "=", "find_pad_start", "(", "input_ids_cpu", ")", "\n", "\n", "cxt", "=", "[", "o", "[", "s", "+", "1", ":", "e", "]", "for", "o", ",", "s", ",", "e", "in", "zip", "(", "list", "(", "input_ids_cpu", ")", ",", "start_idx", ",", "end_idx", ")", "]", "\n", "cxt_str", "=", "[", "enc", ".", "decode", "(", "c", ")", ".", "encode", "(", "'ascii'", ",", "'ignore'", ")", ".", "decode", "(", "'ascii'", ")", "for", "c", "in", "cxt", "]", "\n", "cxt_str", "=", "[", "re", ".", "sub", "(", "'<\\|endoftext\\|>'", ",", "' EOS '", ",", "c", ")", "for", "c", "in", "cxt_str", "]", "\n", "\n", "rsp", "=", "[", "o", "[", "s", "+", "1", ":", "e", "]", "for", "o", ",", "s", ",", "e", "in", "zip", "(", "list", "(", "input_ids_cpu", ")", ",", "end_idx", ",", "pad_idx", ")", "]", "\n", "rsp_str", "=", "[", "enc", ".", "decode", "(", "r", ")", ".", "encode", "(", "'ascii'", ",", "'ignore'", ")", ".", "decode", "(", "'ascii'", ")", "for", "r", "in", "rsp", "]", "\n", "\n", "qry_str", "=", "[", "\" \"", "+", "c", "for", "c", "in", "cxt_str", "]", "\n", "questions_tensor", "=", "retriever", ".", "generate_question_vectors", "(", "qry_str", ")", "\n", "top_ids_and_scores", "=", "retriever", ".", "get_top_docs", "(", "questions_tensor", ".", "numpy", "(", ")", ",", "args", ".", "n_docs", ",", "is_hnsw", "=", "args", ".", "hnsw_index", ")", "\n", "# save top docs and scores", "\n", "ret_passages", "=", "list", "(", "zip", "(", "*", "[", "[", "all_passages", "[", "str", "(", "idx", ")", ".", "strip", "(", ")", "]", "[", "0", "]", "for", "idx", "in", "it", "[", "0", "]", "]", "for", "it", "in", "top_ids_and_scores", "]", ")", ")", "\n", "ret_scores", "=", "list", "(", "zip", "(", "*", "[", "[", "float", "(", "s", ")", "for", "s", "in", "it", "[", "1", "]", "]", "for", "it", "in", "top_ids_and_scores", "]", ")", ")", "\n", "", "return", "ret_passages", ",", "ret_scores", ",", "qry_str", ",", "rsp_str", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.gpt2_training.eval_utils.compare_models": [[233, 246], ["zip", "model_1.state_dict().items", "model_2.state_dict().items", "torch.equal", "print", "model_1.state_dict", "model_2.state_dict", "print"], "function", ["None"], ["", "def", "compare_models", "(", "model_1", ",", "model_2", ")", ":", "\n", "    ", "models_differ", "=", "0", "\n", "for", "key_item_1", ",", "key_item_2", "in", "zip", "(", "model_1", ".", "state_dict", "(", ")", ".", "items", "(", ")", ",", "model_2", ".", "state_dict", "(", ")", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "torch", ".", "equal", "(", "key_item_1", "[", "1", "]", ",", "key_item_2", "[", "1", "]", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "models_differ", "+=", "1", "\n", "if", "(", "key_item_1", "[", "0", "]", "==", "key_item_2", "[", "0", "]", ")", ":", "\n", "                ", "print", "(", "'Mismtach found at'", ",", "key_item_1", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "\n", "", "", "", "if", "models_differ", "==", "0", ":", "\n", "        ", "print", "(", "'Models match perfectly! :)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs": [[20, 23], ["os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs"], ["def", "makedirs", "(", "fld", ")", ":", "\n", "\t", "if", "not", "os", ".", "path", ".", "exists", "(", "fld", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "fld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_submission_id": [[68, 70], ["None"], "function", ["None"], ["def", "get_submission_id", "(", "submission", ")", ":", "\n", "\t", "return", "TAG_SUBMISSION", "+", "submission", "[", "\"id\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_comment_id": [[71, 73], ["None"], "function", ["None"], ["", "def", "get_comment_id", "(", "comment", ")", ":", "\n", "\t", "return", "TAG_COMMENT", "+", "comment", "[", "\"id\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.norm_sentence": [[74, 79], ["reddit.minimal_norm_sentence", "reddit.gpt_norm_sentence"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.minimal_norm_sentence", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.gpt_norm_sentence"], ["", "def", "norm_sentence", "(", "txt", ",", "is_extract", ")", ":", "\n", "\t", "if", "is_extract", ":", "\n", "\t\t", "return", "minimal_norm_sentence", "(", "txt", ")", "\n", "", "else", ":", "\n", "\t\t", "return", "gpt_norm_sentence", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.minimal_norm_sentence": [[80, 87], ["txt.replace.replace", "txt.replace.replace", "txt.replace.replace", "txt.replace.replace", "chr"], "function", ["None"], ["", "", "def", "minimal_norm_sentence", "(", "txt", ")", ":", "\n", "\t", "txt", "=", "txt", ".", "replace", "(", "chr", "(", "92", ")", ",", "''", ")", "# chr(92) = '\\'. as twitter has 'b\\/c' rather than 'b/c'", "\n", "txt", "=", "txt", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "'\\r'", ",", "' '", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "#print (\"Tokenized: [%s]\" % txt, file=sys.stderr)", "\n", "return", "txt", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.gpt_norm_sentence": [[88, 114], ["re.sub.split", "re.sub.replace", "re.sub.replace().replace().replace().replace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "nltk.tokenize.TweetTokenizer", "word.lower().find", "words.append", "chr", "re.sub.split", "word.strip", "re.sub.replace().replace().replace", "word.lower", "nltk.tokenize.TweetTokenizer.tokenize", "re.sub.replace().replace", "re.sub.replace"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize"], ["", "def", "gpt_norm_sentence", "(", "txt", ")", ":", "\n", "# url and tag", "\n", "\t", "words", "=", "[", "]", "\n", "for", "word", "in", "txt", ".", "split", "(", ")", ":", "\n", "\t\t", "if", "word", "[", "0", "]", "==", "'#'", ":", "# don't allow tag", "\n", "\t\t\t", "continue", "\n", "", "i", "=", "word", ".", "lower", "(", ")", ".", "find", "(", "'http'", ")", "\n", "if", "i", ">=", "0", ":", "\n", "\t\t\t", "word", "=", "word", "[", ":", "i", "]", "+", "' '", "+", "'__url__'", "\n", "", "words", ".", "append", "(", "word", ".", "strip", "(", ")", ")", "\n", "", "txt", "=", "' '", ".", "join", "(", "words", ")", "\n", "\n", "# remove illegal char", "\n", "txt", "=", "txt", ".", "replace", "(", "chr", "(", "92", ")", ",", "''", ")", "# chr(92) = '\\'. as twitter has 'b\\/c' rather than 'b/c'", "\n", "txt", "=", "txt", ".", "replace", "(", "\"b/c\"", ",", "\"because\"", ")", ".", "replace", "(", "'j/k'", ",", "'just kidding'", ")", ".", "replace", "(", "'w/o'", ",", "'without'", ")", ".", "replace", "(", "'w/'", ",", "'with'", ")", "\n", "txt", "=", "re", ".", "sub", "(", "'__mention__'", ",", "'MENTION'", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "'__url__'", ",", "'URL'", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "r\"[^A-Za-z0-9()\\[\\]:,.!?'\u201c\u201d ]\"", ",", "\" \"", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "'MENTION'", ",", "'__mention__'", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "'URL'", ",", "'__url__'", ",", "txt", ")", "\n", "\n", "tokenizer", "=", "TweetTokenizer", "(", "preserve_case", "=", "True", ")", "\n", "txt", "=", "' '", "+", "' '", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "txt", ")", ")", "+", "' '", "\n", "\n", "# remove un-necessary space", "\n", "return", "' '", ".", "join", "(", "txt", ".", "split", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.extract_submissions": [[115, 157], ["print", "sids.append", "print", "bz2.open", "set", "open", "f.write", "print", "json.loads", "reddit.norm_sentence", "lines.append", "sid.append", "len", "print", "sids.append", "int", "reddit.get_submission_id", "traceback.print_exc", "set", "open", "f.write", "str"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.norm_sentence", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_submission_id"], ["", "def", "extract_submissions", "(", "fld_bz2", ",", "fld_split", ",", "size", "=", "2e5", ")", ":", "\n", "\t", "path_in", "=", "fld_bz2", "+", "'/RS_%s.bz2'", "%", "args", ".", "dump_name", "\n", "n", "=", "0", "\n", "m", "=", "0", "\n", "sub", "=", "0", "\n", "sid", "=", "[", "]", "\n", "sids", "=", "[", "]", "\n", "lines", "=", "[", "]", "\n", "with", "bz2", ".", "open", "(", "path_in", ",", "'rt'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "n", "+=", "1", "\n", "if", "n", "%", "1e4", "==", "0", ":", "\n", "\t\t\t\t", "print", "(", "'[%s] selected %.3fM from %.2fM submissions'", "%", "(", "\n", "args", ".", "dump_name", ",", "m", "/", "1e6", ",", "n", "/", "1e6", ")", ")", "\n", "", "try", ":", "\n", "\t\t\t\t", "submission", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "int", "(", "submission", "[", "'num_comments'", "]", ")", "<", "2", ":", "# filter 1", "\n", "\t\t\t\t\t", "continue", "\n", "", "submission", "[", "'title'", "]", "=", "norm_sentence", "(", "submission", "[", "'title'", "]", ",", "True", ")", "\n", "lines", ".", "append", "(", "'\\t'", ".", "join", "(", "[", "str", "(", "submission", "[", "k", "]", ")", "for", "k", "in", "fields_subm", "]", ")", ")", "\n", "m", "+=", "1", "\n", "sid", ".", "append", "(", "get_submission_id", "(", "submission", ")", ")", "\n", "\n", "", "except", "Exception", ":", "\n", "\t\t\t\t", "traceback", ".", "print_exc", "(", ")", "\n", "continue", "\n", "\n", "", "if", "len", "(", "sid", ")", "==", "size", ":", "\n", "\t\t\t\t", "print", "(", "'writing submissions_sub%i'", "%", "sub", ")", "\n", "sids", ".", "append", "(", "set", "(", "sid", ")", ")", "\n", "with", "open", "(", "fld_split", "+", "'/rs_sub%i.tsv'", "%", "sub", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", ")", "\n", "", "sid", "=", "[", "]", "\n", "lines", "=", "[", "]", "\n", "sub", "+=", "1", "\n", "\n", "", "", "", "print", "(", "'writing submissions_sub%i'", "%", "sub", ")", "\n", "sids", ".", "append", "(", "set", "(", "sid", ")", ")", "\n", "with", "open", "(", "fld_split", "+", "'/rs_sub%i.tsv'", "%", "sub", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", ")", "\n", "", "print", "(", "'extract_submissions done.\\n'", ")", "\n", "return", "sids", ",", "m", ",", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.extract_comments": [[158, 212], ["len", "range", "print", "range", "print", "open", "bz2.open", "print", "range", "open", "f.write", "print", "range", "json.loads", "range", "print", "traceback.print_exc", "len", "len", "keys.keys", "len", "reddit.norm_sentence", "lines[].append", "open", "f.write", "reddit.get_comment_id", "len", "len", "comment[].split", "str"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.norm_sentence", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_comment_id"], ["", "def", "extract_comments", "(", "fld_bz2", ",", "fld_split", ",", "sids", ")", ":", "\n", "\t", "path_in", "=", "fld_bz2", "+", "'/RC_%s.bz2'", "%", "args", ".", "dump_name", "\n", "n", "=", "0", "\n", "m", "=", "0", "\n", "n_sub", "=", "len", "(", "sids", ")", "\n", "lines", "=", "[", "[", "]", "for", "i", "in", "range", "(", "n_sub", ")", "]", "\n", "for", "sub", "in", "range", "(", "n_sub", ")", ":", "\n", "\t\t", "open", "(", "fld_split", "+", "'/rc_sub%i.tsv'", "%", "sub", ",", "'w'", ")", "\n", "\n", "", "with", "bz2", ".", "open", "(", "path_in", ",", "'rt'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "n", "+=", "1", "\n", "if", "n", "%", "1e4", "==", "0", ":", "\n", "\t\t\t\t", "print", "(", "'[%s] selected %.3fM from %.2fM comments'", "%", "(", "\n", "args", ".", "dump_name", ",", "m", "/", "1e6", ",", "n", "/", "1e6", ")", ")", "\n", "\n", "for", "sub", "in", "range", "(", "n_sub", ")", ":", "\n", "\t\t\t\t\t", "print", "(", "'    sub %i: %i'", "%", "(", "sub", ",", "len", "(", "lines", "[", "sub", "]", ")", ")", ")", "\n", "if", "len", "(", "lines", "[", "sub", "]", ")", ">", "0", ":", "\n", "\t\t\t\t\t\t", "with", "open", "(", "fld_split", "+", "'/rc_sub%i.tsv'", "%", "sub", ",", "'a'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", "[", "sub", "]", ")", "+", "'\\n'", ")", "\n", "", "lines", "[", "sub", "]", "=", "[", "]", "\n", "", "", "", "try", ":", "\n", "\t\t\t\t", "comment", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "args", ".", "keep_keys", ":", "\n", "\t\t\t\t\t", "k", "=", "'\\t'", ".", "join", "(", "[", "comment", "[", "'link_id'", "]", ",", "get_comment_id", "(", "comment", ")", ",", "'dep'", "]", ")", "\n", "if", "k", "not", "in", "keys", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t", "continue", "\n", "", "", "if", "comment", "[", "'body'", "]", "==", "'[deleted]'", ":", "# filter 1", "\n", "\t\t\t\t\t", "continue", "\n", "", "if", "'>'", "in", "comment", "[", "'body'", "]", "or", "'&gt;'", "in", "comment", "[", "'body'", "]", ":", "# filter 3: '&gt;' means '>'", "\n", "\t\t\t\t\t", "continue", "\n", "", "sid", "=", "comment", "[", "'link_id'", "]", "\n", "for", "sub", "in", "range", "(", "n_sub", ")", ":", "\n", "\t\t\t\t\t", "if", "sid", "in", "sids", "[", "sub", "]", ":", "\n", "\t\t\t\t\t\t", "comment", "[", "'n_char'", "]", "=", "len", "(", "comment", "[", "'body'", "]", ")", "\n", "comment", "[", "'body'", "]", "=", "norm_sentence", "(", "comment", "[", "'body'", "]", ",", "True", ")", "\n", "if", "len", "(", "comment", "[", "'body'", "]", ".", "split", "(", ")", ")", "<", "2", ":", "# filter 2", "\n", "\t\t\t\t\t\t\t", "break", "\n", "", "lines", "[", "sub", "]", ".", "append", "(", "'\\t'", ".", "join", "(", "[", "str", "(", "comment", "[", "k", "]", ")", "for", "k", "in", "fields_comm", "]", ")", ")", "\n", "m", "+=", "1", "\n", "break", "\n", "\n", "", "", "", "except", "Exception", ":", "\n", "\t\t\t\t", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "", "", "print", "(", "'the rest...'", ")", "\n", "for", "sub", "in", "range", "(", "n_sub", ")", ":", "\n", "\t\t", "print", "(", "'    sub %i: %i'", "%", "(", "sub", ",", "len", "(", "lines", "[", "sub", "]", ")", ")", ")", "\n", "with", "open", "(", "fld_split", "+", "'/rc_sub%i.tsv'", "%", "sub", ",", "'a'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", "[", "sub", "]", ")", ")", "\n", "\n", "", "", "print", "(", "'extract_comments done.\\n'", ")", "\n", "return", "m", ",", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_convo": [[213, 231], ["get_convo.append", "pid.startswith", "len", "int", "reddit.get_convo", "c[].split"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_convo"], ["", "def", "get_convo", "(", "sid", ",", "rootid", ",", "cid", ",", "submissions", ",", "comments", ",", "depth", "=", "args", ".", "max_depth", ")", ":", "\n", "\t", "if", "depth", "==", "0", ":", "\n", "\t\t", "return", "[", "]", "\n", "", "c", "=", "comments", "[", "cid", "]", "\n", "if", "args", ".", "max_len_type", "==", "'w'", "and", "len", "(", "c", "[", "'body'", "]", ".", "split", "(", ")", ")", ">", "args", ".", "max_len", ":", "# len filter", "\n", "\t\t", "return", "[", "]", "\n", "", "if", "args", ".", "max_len_type", "==", "'c'", "and", "int", "(", "c", "[", "'n_char'", "]", ")", ">", "args", ".", "max_len", ":", "\n", "\t\t", "return", "[", "]", "\n", "\n", "", "pid", "=", "c", "[", "'parent_id'", "]", "\n", "if", "args", ".", "use_title", "and", "pid", ".", "startswith", "(", "TAG_SUBMISSION", ")", ":", "\n", "\t\t", "txts", "=", "[", "\"title: \"", "+", "submissions", "[", "c", "[", "'link_id'", "]", "]", "[", "'title'", "]", "]", "\n", "", "elif", "pid", "in", "comments", ":", "\n", "\t\t", "txts", "=", "get_convo", "(", "sid", ",", "rootid", ",", "pid", ",", "submissions", ",", "comments", ",", "depth", "-", "1", ")", "\n", "", "else", ":", "\n", "\t\t", "txts", "=", "[", "]", "\n", "", "txts", ".", "append", "(", "c", "[", "'body'", "]", ")", "\n", "return", "txts", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.filter_instance": [[232, 295], ["tgt.split", "src.split", "range", "bl_words.extract_keywords", "len", "print", "print", "len", "len", "print", "print", "re.search", "print", "re.search", "print", "len", "print", "print", "len"], "function", ["None"], ["", "def", "filter_instance", "(", "src", ",", "tgt", ",", "info", ")", ":", "\n", "# Remove offensive words:", "\n", "\t", "if", "args", ".", "bl_words", "and", "not", "args", ".", "leaves_only", ":", "\n", "\t\t", "bad_words", "=", "bl_words", ".", "extract_keywords", "(", "tgt", ")", "\n", "if", "bad_words", ":", "\n", "\t\t\t", "print", "(", "\"skip\\toffensive\\t%s\\t%s\\tbad word(s): %s\"", "%", "(", "info", ",", "tgt", ",", "bad_words", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "# Remove empty targets:", "\n", "", "", "tgttoks", "=", "tgt", ".", "split", "(", ")", "\n", "if", "len", "(", "tgttoks", ")", "<=", "1", ":", "# 1 means there is only a weight, and 0 means there's a bug..", "\n", "\t\t", "print", "(", "\"skip\\temptytarget\\t%s\\t%s\"", "%", "(", "info", ",", "tgt", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "# Skip if word too long:", "\n", "", "toolong", "=", "False", "\n", "for", "w", "in", "tgttoks", ":", "\n", "\t\t", "if", "len", "(", "w", ")", ">", "30", ":", "\n", "\t\t\t", "toolong", "=", "True", "\n", "break", "\n", "", "", "if", "toolong", ":", "\n", "\t\t", "print", "(", "\"skip\\tlongword\\t%s\\t%s\\tword too long\"", "%", "(", "info", ",", "tgt", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "", "srctoks", "=", "src", ".", "split", "(", ")", "\n", "# Remove empty sources: (should probably uncomment, but left for reproducibility)", "\n", "#if len(srctoks) <= 1: # 1 means there is only a weight, and 0 means there's a bug..", "\n", "#\tprint(\"skip\\temptysource\\t%s\\t%s\" % (info, src), file=sys.stderr)", "\n", "#\treturn True", "\n", "\n", "# Remove too long turns:", "\n", "nsrctgt", "=", "len", "(", "srctoks", ")", "+", "len", "(", "tgttoks", ")", "\n", "if", "nsrctgt", ">", "200", ":", "\n", "\t\t", "print", "(", "\"skip\\ttoolong\\t%s\\t%s\\tsrc+tgt too long, src=[%s]\"", "%", "(", "info", ",", "tgt", ",", "src", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "# Skip turns with URLs:", "\n", "", "srctgt", "=", "src", "+", "\" \"", "+", "tgt", "\n", "if", "\"__url__\"", "in", "srctgt", ":", "\n", "\t\t", "print", "(", "\"skip\\turl\\t%s\\t%s\\turl in tgt, or src =[%s]\"", "%", "(", "info", ",", "tgt", ",", "src", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "# Skip responses with meta data:", "\n", "", "if", "re", ".", "search", "(", "\"[\\[\\]\\(\\)]\"", ",", "srctgt", ")", "!=", "None", ":", "\n", "\t\t", "print", "(", "\"skip\\ttags\\t%s\\t%s\\ttag in tgt (or src: [%s])\"", "%", "(", "info", ",", "tgt", ",", "src", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "# Skip yelling:", "\n", "", "if", "re", ".", "search", "(", "\"[A-Z]{5,}\"", ",", "srctgt", ")", "!=", "None", ":", "\n", "\t\t", "print", "(", "\"skip\\tallcaps\\t%s\\t%s\\tall caps in tgt (or src: [%s])\"", "%", "(", "info", ",", "tgt", ",", "src", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "# Skip word repetitions:", "\n", "", "reps", "=", "False", "\n", "for", "i", "in", "range", "(", "2", ",", "len", "(", "tgttoks", ")", ")", ":", "\n", "\t\t", "if", "tgttoks", "[", "i", "-", "2", "]", "==", "tgttoks", "[", "i", "]", "and", "tgttoks", "[", "i", "-", "1", "]", "==", "tgttoks", "[", "i", "]", ":", "\n", "\t\t\t", "reps", "=", "True", "\n", "break", "\n", "", "", "if", "reps", ":", "\n", "\t\t", "print", "(", "\"skip\\trepetitions\\t%s\\t%s\\ttoo many repetitions\"", "%", "(", "info", ",", "tgt", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.save_convo": [[296, 417], ["print", "dict", "print", "dict", "sorted", "len", "print", "print", "gzip.open", "gzip.open", "print", "range", "lines.append", "len", "open", "f.write", "line.strip().strip().split", "line.strip().strip().split", "print", "dict.keys", "[].lower", "[].lower", "int", "print", "reddit.get_convo", "len", "print", "len", "reddit.norm_sentence", "reddit.filter_instance", "tgt.split", "dict", "dict", "keys.keys", "len", "print", "print", "print", "line.strip().strip", "reddit.get_submission_id", "line.strip().strip", "traceback.print_exc", "reddit.get_comment_id", "len", "len", "open", "f.write", "hashlib.sha224().hexdigest", "bl_words.extract_keywords", "[].split", "len", "keys_rm.keys", "line.strip", "range", "line.strip", "range", "hashlib.sha224", "len", "len", "txts[].encode"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_convo", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.norm_sentence", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.filter_instance", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_submission_id", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.get_comment_id", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "def", "save_convo", "(", "path_rs", ",", "path_rc", ",", "path_out", ")", ":", "\n", "\t", "print", "(", "'reading submissions...'", ")", "\n", "submissions", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "path_rs", ",", "mode", "=", "'rt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "cells", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "try", ":", "\n", "\t\t\t\t", "submission", "=", "dict", "(", "[", "(", "fields_subm", "[", "i", "]", ",", "cells", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "fields_subm", ")", ")", "]", ")", "\n", "", "except", "Exception", ":", "\n", "#traceback.print_exc()", "\n", "\t\t\t\t", "continue", "\n", "", "submissions", "[", "get_submission_id", "(", "submission", ")", "]", "=", "submission", "\n", "\n", "", "", "print", "(", "'reading comments...'", ")", "\n", "comments", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "path_rc", ",", "mode", "=", "'rt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "cells", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "try", ":", "\n", "\t\t\t\t", "comment", "=", "dict", "(", "[", "(", "fields_comm", "[", "i", "]", ",", "cells", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "fields_comm", ")", ")", "]", ")", "\n", "", "except", "Exception", ":", "\n", "\t\t\t\t", "traceback", ".", "print_exc", "(", ")", "\n", "continue", "\n", "", "comments", "[", "get_comment_id", "(", "comment", ")", "]", "=", "comment", "\n", "\n", "", "", "sorted_id", "=", "sorted", "(", "[", "(", "\n", "comments", "[", "cid", "]", "[", "'link_id'", "]", ",", "\n", "comments", "[", "cid", "]", "[", "'parent_id'", "]", ",", "\n", "cid", "\n", ")", "for", "cid", "in", "comments", "]", ")", "\n", "\n", "n", "=", "len", "(", "comments", ")", "\n", "print", "(", "'total comments: %i'", "%", "n", ")", "\n", "\n", "i", "=", "0", "\n", "m", "=", "0", "\n", "lines", "=", "[", "]", "\n", "sum_resp_len", "=", "0", "\n", "\n", "skip_id", "=", "{", "}", "\n", "if", "args", ".", "leaves_only", ":", "\n", "\t\t", "for", "_", ",", "pid", ",", "_", "in", "sorted_id", ":", "\n", "\t\t\t", "skip_id", "[", "pid", "]", "=", "1", "\n", "", "print", "(", "\"leaves ratio : %f\"", "%", "(", "len", "(", "skip_id", ")", "/", "len", "(", "sorted_id", ")", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "for", "sid", ",", "pid", ",", "cid", "in", "sorted_id", ":", "\n", "\t\t", "if", "args", ".", "keep_keys", ":", "\n", "\t\t\t", "k", "=", "'\\t'", ".", "join", "(", "[", "sid", ",", "cid", ",", "'keep'", "]", ")", "\n", "if", "k", "not", "in", "keys", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "continue", "\n", "", "", "if", "cid", "in", "skip_id", ":", "\n", "\t\t\t", "continue", "\n", "", "i", "+=", "1", "\n", "if", "i", "%", "1e5", "==", "0", ":", "\n", "\t\t\t", "print", "(", "'selected %.2fM from %.1f/%.1fM comments'", "%", "(", "m", "/", "1e6", ",", "i", "/", "1e6", ",", "n", "/", "1e6", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "if", "len", "(", "lines", ")", ">", "0", ":", "\n", "\t\t\t\t", "with", "open", "(", "path_out", ",", "'a'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", "+", "'\\n'", ")", "\n", "", "", "lines", "=", "[", "]", "\n", "\n", "", "subreddit", "=", "''", "\n", "domain", "=", "''", "\n", "if", "sid", "in", "submissions", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "subreddit", "=", "submissions", "[", "sid", "]", "[", "'permalink'", "]", ".", "split", "(", "'/'", ")", "[", "2", "]", ".", "lower", "(", ")", "\n", "domain", "=", "submissions", "[", "sid", "]", "[", "'domain'", "]", ".", "lower", "(", ")", "\n", "", "info", "=", "subreddit", "+", "'\\t'", "+", "domain", "\n", "\n", "if", "args", ".", "bl_subreddits", ":", "\n", "\t\t\t", "if", "not", "subreddit", ":", "\n", "\t\t\t\t", "print", "(", "\"skip\\tmissing\\t%s\\tN/A\\tmissing submission: %s\"", "%", "(", "info", ",", "sid", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "", "if", "subreddit", "in", "bl_subreddits", ":", "\n", "\t\t\t\t", "print", "(", "\"skip\\tbad_subreddit\\t%s\\tN/A\\toffensive subreddit: %s\"", "%", "(", "info", ",", "subreddit", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "\n", "", "", "comment", "=", "comments", "[", "cid", "]", "\n", "if", "comment", "[", "'score'", "]", "==", "'None'", ":", "\n", "\t\t\t", "score", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t", "score", "=", "int", "(", "comment", "[", "'score'", "]", ")", "\n", "", "if", "score", "<", "args", ".", "min_score", ":", "# filter 1", "\n", "\t\t\t", "print", "(", "\"skip\\tlow_score\\t%s\\t%s\\tscore %d < %d\"", "%", "(", "info", ",", "comment", "[", "'body'", "]", ",", "score", ",", "args", ".", "min_score", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "", "try", ":", "\n", "\t\t\t", "txts", "=", "get_convo", "(", "sid", ",", "cid", ",", "cid", ",", "submissions", ",", "comments", ")", "# filter 2", "\n", "", "except", "Exception", ":", "\n", "\t\t\t", "print", "(", "\"skip\\texception\\t%s\\t%s\\texception\"", "%", "(", "info", ",", "comment", "[", "'body'", "]", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "", "if", "len", "(", "txts", ")", "<", "args", ".", "min_depth", ":", "# filter 3", "\n", "\t\t\t", "print", "(", "\"skip\\tmin_depth\\t%s\\t%s\\tdepth %d < %d: %s\"", "%", "(", "info", ",", "comment", "[", "'body'", "]", ",", "len", "(", "txts", ")", ",", "args", ".", "min_depth", ",", "\"|\"", ".", "join", "(", "txts", ")", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "txts", ")", ")", ":", "\n", "\t\t\t", "txts", "[", "i", "]", "=", "norm_sentence", "(", "txts", "[", "i", "]", ",", "False", ")", "\n", "if", "args", ".", "leaves_only", "and", "args", ".", "clean", ":", "\n", "\t\t\t\t", "sc", "=", "'1.0'", "\n", "skip_target", "=", "False", "\n", "if", "args", ".", "discard_tgt_keys", ":", "\n", "\t\t\t\t\t", "tgt_h", "=", "hashlib", ".", "sha224", "(", "txts", "[", "i", "]", ".", "encode", "(", "\"utf-8\"", ")", ")", ".", "hexdigest", "(", ")", "\n", "if", "tgt_h", "in", "keys_rm", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t", "skip_target", "=", "True", "\n", "", "", "if", "bl_words", ".", "extract_keywords", "(", "txts", "[", "i", "]", ")", "or", "skip_target", ":", "\n", "\t\t\t\t\t", "sc", "=", "'0.0'", "\n", "", "txts", "[", "i", "]", "=", "sc", "+", "' '", "+", "txts", "[", "i", "]", "\n", "\n", "", "", "src", "=", "' EOS '", ".", "join", "(", "txts", "[", ":", "-", "1", "]", ")", "\n", "tgt", "=", "txts", "[", "-", "1", "]", "\n", "\n", "if", "args", ".", "clean", "and", "filter_instance", "(", "src", ",", "tgt", ",", "info", ")", ":", "\n", "\t\t\t", "continue", "\n", "\n", "", "header", "=", "','", ".", "join", "(", "[", "sid", ",", "pid", ",", "cid", "]", ")", "\n", "lines", ".", "append", "(", "header", "+", "'\\t'", "+", "src", "+", "'\\t'", "+", "tgt", ")", "\n", "sum_resp_len", "+=", "len", "(", "tgt", ".", "split", "(", ")", ")", "\n", "m", "+=", "1", "\n", "\n", "", "avg_len", "=", "sum_resp_len", "/", "m", "\n", "with", "open", "(", "path_out", ",", "'a'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", "+", "'\\n'", ")", "\n", "", "print", "(", "'finally selected %i/%i, avg len = %.2f'", "%", "(", "m", ",", "n", ",", "avg_len", ")", ")", "\n", "return", "m", ",", "n", ",", "avg_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.extract": [[418, 424], ["reddit.makedirs", "reddit.extract_submissions", "reddit.extract_comments", "open", "f.write", "map"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.extract_submissions", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.extract_comments"], ["", "def", "extract", "(", ")", ":", "\n", "\t", "makedirs", "(", "fld_split", ")", "\n", "sids", ",", "ms", ",", "ns", "=", "extract_submissions", "(", "fld_root_in", ",", "fld_split", ",", "size", "=", "args", ".", "split_size", ")", "\n", "mc", ",", "nc", "=", "extract_comments", "(", "fld_root_in", ",", "fld_split", ",", "sids", ")", "\n", "with", "open", "(", "fld_split", "+", "'/stat.tsv'", ",", "'a'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "map", "(", "str", ",", "[", "args", ".", "dump_name", ",", "mc", ",", "nc", ",", "ms", ",", "ns", "]", ")", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.build_conv": [[425, 454], ["reddit.makedirs", "print", "open.write", "open.close", "open", "open", "print", "path_rs.replace", "reddit.save_convo", "open.write", "os.path.exists", "print", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.makedirs", "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.save_convo"], ["", "", "def", "build_conv", "(", "fld_out", ")", ":", "\n", "\t", "makedirs", "(", "fld_out", ")", "\n", "path_out", "=", "fld_out", "+", "'/%s.tsv'", "%", "args", ".", "dump_name", "\n", "print", "(", "path_out", ")", "\n", "\n", "if", "args", ".", "parallel", ":", "\n", "\t\t", "fs", "=", "open", "(", "fld_out", "+", "'/'", "+", "args", ".", "dump_name", "+", "'.stat.tsv'", ",", "'w'", ")", "\n", "", "else", ":", "\n", "\t\t", "fs", "=", "open", "(", "fld_out", "+", "'/stat.tsv'", ",", "'a'", ")", "\n", "\n", "", "sub", "=", "0", "\n", "sum_m", "=", "0", "\n", "sum_n", "=", "0", "\n", "while", "True", ":", "\n", "\t\t", "path_rs", "=", "fld_split", "+", "'/rs_sub%i.tsv.gz'", "%", "sub", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path_rs", ")", ":", "\n", "\t\t\t", "if", "sub", "==", "0", ":", "\n", "\t\t\t\t", "print", "(", "'no such file: '", "+", "path_rs", ")", "\n", "", "break", "\n", "", "print", "(", "'-'", "*", "10", "+", "' sub%i '", "%", "sub", "+", "'-'", "*", "10", ")", "\n", "path_rc", "=", "path_rs", ".", "replace", "(", "'/rs_'", ",", "'/rc_'", ")", "\n", "m", ",", "n", ",", "avg_len", "=", "save_convo", "(", "path_rs", ",", "path_rc", ",", "path_out", ")", "\n", "fs", ".", "write", "(", "'\\t'", ".", "join", "(", "[", "args", ".", "dump_name", ",", "str", "(", "sub", ")", ",", "str", "(", "m", ")", ",", "str", "(", "n", ")", ",", "'%.2f'", "%", "avg_len", "]", ")", "+", "'\\n'", ")", "\n", "sum_m", "+=", "m", "\n", "sum_n", "+=", "n", "\n", "sub", "+=", "1", "\n", "\n", "", "fs", ".", "write", "(", "'\\t'", ".", "join", "(", "[", "args", ".", "dump_name", ",", "'all'", ",", "str", "(", "sum_m", ")", ",", "str", "(", "sum_n", ")", ",", "''", "]", ")", "+", "'\\n'", ")", "\n", "fs", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.src.reddit.load_keys": [[455, 464], ["gzip.open", "line.rstrip", "line.rstrip.endswith"], "function", ["None"], ["", "def", "load_keys", "(", "key_file", ")", ":", "\n", "\t", "d", "=", "{", "}", "\n", "with", "gzip", ".", "open", "(", "key_file", ",", "'rt'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "k", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "args", ".", "task", "==", "'conv'", "and", "k", ".", "endswith", "(", "'\\tdep'", ")", ":", "\n", "\t\t\t\t", "continue", "\n", "", "d", "[", "k", "]", "=", "1", "\n", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_tokenizer_params": [[23, 26], ["parser.add_argument"], "function", ["None"], ["def", "add_tokenizer_params", "(", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to lower case the input text. True for uncased models, False for cased models.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_encoder_params": [[27, 40], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "add_encoder_params", "(", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"\n        Common parameters to initialize an encoder-based model\n    \"\"\"", "\n", "parser", ".", "add_argument", "(", "\"--pretrained_model_cfg\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"config name for model initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--encoder_model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"model type. One of [hf_bert, pytext_bert, fairseq_roberta]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained_file'", ",", "type", "=", "str", ",", "help", "=", "\"Some encoders need to be initialized from a file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Saved bi-encoder checkpoint file to initialize the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--projection_dim\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Extra linear layer on top of standard bert/roberta encoder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sequence_length\"", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "\"Max length of the encoder input sequence\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_training_params": [[41, 70], ["options.add_cuda_params", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_cuda_params"], ["", "def", "add_training_params", "(", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"\n        Common parameters for training\n    \"\"\"", "\n", "add_cuda_params", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"File pattern for the train set\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"Amount of questions per batch\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_batch_size\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "\"amount of questions per batch for dev set validation\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"random seed for initialization and dataset shuffling\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--adam_eps\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_betas\"", ",", "default", "=", "'(0.9, 0.999)'", ",", "type", "=", "str", ",", "help", "=", "\"Betas for Adam optimizer.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_batch_step\"", ",", "default", "=", "100", ",", "type", "=", "int", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_rolling_loss_step\"", ",", "default", "=", "100", ",", "type", "=", "int", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "1e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "100", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_cuda_params": [[71, 82], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "add_cuda_params", "(", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "# args, leftovers = parser.parse_known_args()", "\n", "# if args.local_rank is None:", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "# if args.fp16 is None:", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit float precision instead of 32-bit\"", ")", "\n", "# if args.fp16_opt_level is None:", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.add_reader_preprocessing_params": [[84, 91], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "add_reader_preprocessing_params", "(", "parser", ":", "argparse", ".", "ArgumentParser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--gold_passages_src\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"File with the original dataset passages (json format). Required for train set\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gold_passages_src_dev\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"File with the original dataset passages (json format). Required for dev set\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "\"number of parallel processes to binarize reader data\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.get_encoder_checkpoint_params_names": [[92, 96], ["None"], "function", ["None"], ["", "def", "get_encoder_checkpoint_params_names", "(", ")", ":", "\n", "    ", "return", "[", "'do_lower_case'", ",", "'pretrained_model_cfg'", ",", "'encoder_model_type'", ",", "\n", "'pretrained_file'", ",", "\n", "'projection_dim'", ",", "'sequence_length'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.get_encoder_params_state": [[97, 109], ["options.get_encoder_checkpoint_params_names", "getattr"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.get_encoder_checkpoint_params_names"], ["", "def", "get_encoder_params_state", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n     Selects the param values to be saved in a checkpoint, so that a trained model faile can be used for downstream\n     tasks without the need to specify these parameter again\n    :return: Dict of params to memorize in a checkpoint\n    \"\"\"", "\n", "params_to_save", "=", "get_encoder_checkpoint_params_names", "(", ")", "\n", "\n", "r", "=", "{", "}", "\n", "for", "param", "in", "params_to_save", ":", "\n", "        ", "r", "[", "param", "]", "=", "getattr", "(", "args", ",", "param", ")", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_encoder_params_from_state": [[110, 122], ["options.get_encoder_checkpoint_params_names", "hasattr", "setattr", "logger.warning"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.get_encoder_checkpoint_params_names"], ["", "def", "set_encoder_params_from_state", "(", "state", ",", "args", ")", ":", "\n", "    ", "if", "not", "state", ":", "\n", "        ", "return", "\n", "", "params_to_save", "=", "get_encoder_checkpoint_params_names", "(", ")", "\n", "\n", "override_params", "=", "[", "(", "param", ",", "state", "[", "param", "]", ")", "for", "param", "in", "params_to_save", "if", "param", "in", "state", "and", "state", "[", "param", "]", "]", "\n", "for", "param", ",", "value", "in", "override_params", ":", "\n", "        ", "if", "hasattr", "(", "args", ",", "param", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "'Overriding args parameter value from checkpoint state. Param = %s, value = %s'", ",", "param", ",", "\n", "value", ")", "\n", "", "setattr", "(", "args", ",", "param", ",", "value", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.set_seed": [[123, 130], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "seed", "=", "args", ".", "seed", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.setup_args_gpu": [[131, 156], ["os.environ.get", "logger.info", "logger.info", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "int", "socket.gethostname", "torch.distributed.init_process_group", "torch.cuda.is_available"], "function", ["None"], ["", "", "def", "setup_args_gpu", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n     Setup arguments CUDA, GPU & distributed training\n    \"\"\"", "\n", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "# single-node multi-gpu (or cpu) mode", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# distributed mode", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "if", "not", "torch", ".", "distributed", ".", "is_initialized", ":", "\n", "            ", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "ws", "=", "os", ".", "environ", ".", "get", "(", "'WORLD_SIZE'", ")", "\n", "\n", "args", ".", "distributed_world_size", "=", "int", "(", "ws", ")", "if", "ws", "else", "1", "\n", "\n", "logger", ".", "info", "(", "\n", "'Initialized host %s as d.rank %d on device=%s, n_gpu=%d, world size=%d'", ",", "socket", ".", "gethostname", "(", ")", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "args", ".", "distributed_world_size", ")", "\n", "logger", ".", "info", "(", "\"16-bits training: %s \"", ",", "args", ".", "fp16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.dpr.options.print_args": [[157, 163], ["logger.info", "sorted", "logger.info", "vars().items", "logger.info", "vars", "len"], "function", ["None"], ["", "def", "print_args", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\" **************** CONFIGURATION **************** \"", ")", "\n", "for", "key", ",", "val", "in", "sorted", "(", "vars", "(", "args", ")", ".", "items", "(", ")", ")", ":", "\n", "        ", "keystr", "=", "\"{}\"", ".", "format", "(", "key", ")", "+", "(", "\" \"", "*", "(", "30", "-", "len", "(", "key", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"%s -->   %s\"", ",", "keystr", ",", "val", ")", "\n", "", "logger", ".", "info", "(", "\" **************** CONFIGURATION **************** \"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_rank": [[17, 23], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_rank"], ["def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "-", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "-", "1", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.is_main_process": [[24, 26], ["dist_utils.get_rank"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "in", "[", "-", "1", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size": [[27, 29], ["torch.get_world_size"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_default_group": [[30, 32], ["None"], "function", ["None"], ["", "def", "get_default_group", "(", ")", ":", "\n", "    ", "return", "dist", ".", "group", ".", "WORLD", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_reduce": [[33, 37], ["torch.all_reduce", "dist_utils.get_default_group"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_reduce", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_default_group"], ["", "def", "all_reduce", "(", "tensor", ",", "group", "=", "None", ")", ":", "\n", "    ", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "get_default_group", "(", ")", "\n", "", "return", "dist", ".", "all_reduce", "(", "tensor", ",", "group", "=", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_gather_list": [[38, 93], ["pickle.dumps", "len", "dist_utils.get_rank", "dist_utils.get_world_size", "buffer.zero_", "len.to_bytes", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "buffer[].copy_", "dist_utils.all_reduce", "ValueError", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.ByteTensor().pin_memory", "torch.ByteTensor().pin_memory", "list", "list", "range", "hasattr", "all_gather_list._buffer.numel", "int.from_bytes", "Exception", "torch.ByteTensor", "torch.ByteTensor", "result.append", "pickle.loads", "bytes", "out_buffer[].tolist"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_rank", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.get_world_size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.dist_utils.all_reduce"], ["", "def", "all_gather_list", "(", "data", ",", "group", "=", "None", ",", "max_size", "=", "16384", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\n    Similar to :func:`~torch.distributed.all_gather` but for arbitrary Python\n    data. Note that *data* must be picklable.\n    Args:\n        data (Any): data from the local worker to be gathered on other workers\n        group (optional): group of the collective\n    \"\"\"", "\n", "SIZE_STORAGE_BYTES", "=", "4", "# int32 to encode the payload size", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "\n", "if", "enc_size", "+", "SIZE_STORAGE_BYTES", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'encoded data exceeds max_size, this can be fixed by increasing buffer size: {}'", ".", "format", "(", "enc_size", ")", ")", "\n", "\n", "", "rank", "=", "get_rank", "(", ")", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "buffer_size", "=", "max_size", "*", "world_size", "\n", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_buffer'", ")", "or", "all_gather_list", ".", "_buffer", ".", "numel", "(", ")", "<", "buffer_size", ":", "\n", "        ", "all_gather_list", ".", "_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "buffer_size", ")", "\n", "all_gather_list", ".", "_cpu_buffer", "=", "torch", ".", "ByteTensor", "(", "max_size", ")", ".", "pin_memory", "(", ")", "\n", "\n", "", "buffer", "=", "all_gather_list", ".", "_buffer", "\n", "buffer", ".", "zero_", "(", ")", "\n", "cpu_buffer", "=", "all_gather_list", ".", "_cpu_buffer", "\n", "\n", "assert", "enc_size", "<", "256", "**", "SIZE_STORAGE_BYTES", ",", "'Encoded object size should be less than {} bytes'", ".", "format", "(", "\n", "256", "**", "SIZE_STORAGE_BYTES", ")", "\n", "\n", "size_bytes", "=", "enc_size", ".", "to_bytes", "(", "SIZE_STORAGE_BYTES", ",", "byteorder", "=", "'big'", ")", "\n", "\n", "cpu_buffer", "[", "0", ":", "SIZE_STORAGE_BYTES", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "size_bytes", ")", ")", "\n", "cpu_buffer", "[", "SIZE_STORAGE_BYTES", ":", "enc_size", "+", "SIZE_STORAGE_BYTES", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "\n", "start", "=", "rank", "*", "max_size", "\n", "size", "=", "enc_size", "+", "SIZE_STORAGE_BYTES", "\n", "buffer", "[", "start", ":", "start", "+", "size", "]", ".", "copy_", "(", "cpu_buffer", "[", ":", "size", "]", ")", "\n", "\n", "all_reduce", "(", "buffer", ",", "group", "=", "group", ")", "\n", "\n", "try", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "            ", "out_buffer", "=", "buffer", "[", "i", "*", "max_size", ":", "(", "i", "+", "1", ")", "*", "max_size", "]", "\n", "size", "=", "int", ".", "from_bytes", "(", "out_buffer", "[", "0", ":", "SIZE_STORAGE_BYTES", "]", ",", "byteorder", "=", "'big'", ")", "\n", "if", "size", ">", "0", ":", "\n", "                ", "result", ".", "append", "(", "pickle", ".", "loads", "(", "bytes", "(", "out_buffer", "[", "SIZE_STORAGE_BYTES", ":", "size", "+", "SIZE_STORAGE_BYTES", "]", ".", "tolist", "(", ")", ")", ")", ")", "\n", "", "", "return", "result", "\n", "", "except", "pickle", ".", "UnpicklingError", ":", "\n", "        ", "raise", "Exception", "(", "\n", "'Unable to unpickle data from other workers. all_gather_list requires all '", "\n", "'workers to enter the function together, so this error usually indicates '", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.setup_for_distributed_mode": [[25, 51], ["amp.initialize.to", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "apex.amp.register_half_function", "amp.initialize", "amp.initialize", "ImportError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["def", "setup_for_distributed_mode", "(", "model", ":", "nn", ".", "Module", ",", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "device", ":", "object", ",", "n_gpu", ":", "int", "=", "1", ",", "\n", "local_rank", ":", "int", "=", "-", "1", ",", "\n", "fp16", ":", "bool", "=", "False", ",", "\n", "fp16_opt_level", ":", "str", "=", "\"O1\"", ")", "->", "(", "nn", ".", "Module", ",", "torch", ".", "optim", ".", "Optimizer", ")", ":", "\n", "    ", "model", ".", "to", "(", "device", ")", "\n", "if", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "apex", "\n", "from", "apex", "import", "amp", "\n", "apex", ".", "amp", ".", "register_half_function", "(", "torch", ",", "\"einsum\"", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "", "if", "optimizer", "is", "None", ":", "\n", "            ", "model", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "fp16_opt_level", ")", "\n", "", "else", ":", "\n", "            ", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "fp16_opt_level", ")", "\n", "\n", "", "", "if", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "if", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "\n", "output_device", "=", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "", "return", "model", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.move_to_cuda": [[52, 72], ["model_utils.move_to_cuda._move_to_cuda"], "function", ["None"], ["", "def", "move_to_cuda", "(", "sample", ")", ":", "\n", "    ", "if", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_move_to_cuda", "(", "maybe_tensor", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "maybe_tensor", ")", ":", "\n", "            ", "return", "maybe_tensor", ".", "cuda", "(", ")", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "dict", ")", ":", "\n", "            ", "return", "{", "\n", "key", ":", "_move_to_cuda", "(", "value", ")", "\n", "for", "key", ",", "value", "in", "maybe_tensor", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "list", ")", ":", "\n", "            ", "return", "[", "_move_to_cuda", "(", "x", ")", "for", "x", "in", "maybe_tensor", "]", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "tuple", ")", ":", "\n", "            ", "return", "[", "_move_to_cuda", "(", "x", ")", "for", "x", "in", "maybe_tensor", "]", "\n", "", "else", ":", "\n", "            ", "return", "maybe_tensor", "\n", "\n", "", "", "return", "_move_to_cuda", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.move_to_device": [[73, 93], ["model_utils.move_to_device._move_to_device"], "function", ["None"], ["", "def", "move_to_device", "(", "sample", ",", "device", ")", ":", "\n", "    ", "if", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_move_to_device", "(", "maybe_tensor", ",", "device", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "maybe_tensor", ")", ":", "\n", "            ", "return", "maybe_tensor", ".", "to", "(", "device", ")", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "dict", ")", ":", "\n", "            ", "return", "{", "\n", "key", ":", "_move_to_device", "(", "value", ",", "device", ")", "\n", "for", "key", ",", "value", "in", "maybe_tensor", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "list", ")", ":", "\n", "            ", "return", "[", "_move_to_device", "(", "x", ",", "device", ")", "for", "x", "in", "maybe_tensor", "]", "\n", "", "elif", "isinstance", "(", "maybe_tensor", ",", "tuple", ")", ":", "\n", "            ", "return", "[", "_move_to_device", "(", "x", ",", "device", ")", "for", "x", "in", "maybe_tensor", "]", "\n", "", "else", ":", "\n", "            ", "return", "maybe_tensor", "\n", "\n", "", "", "return", "_move_to_device", "(", "sample", ",", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_schedule_linear": [[94, 107], ["torch.optim.lr_scheduler.LambdaLR", "max", "float", "float", "float", "float", "max", "max"], "function", ["None"], ["", "def", "get_schedule_linear", "(", "optimizer", ",", "warmup_steps", ",", "training_steps", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\" Create a schedule with a learning rate that decreases linearly after\n    linearly increasing during a warmup period.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "current_step", ")", ":", "\n", "        ", "if", "current_step", "<", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "warmup_steps", ")", ")", "\n", "", "return", "max", "(", "\n", "0.0", ",", "float", "(", "training_steps", "-", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "training_steps", "-", "warmup_steps", ")", ")", "\n", ")", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.init_weights": [[108, 117], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "function", ["None"], ["", "def", "init_weights", "(", "modules", ":", "List", ")", ":", "\n", "    ", "for", "module", "in", "modules", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_obj": [[118, 120], ["hasattr"], "function", ["None"], ["", "", "", "def", "get_model_obj", "(", "model", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "return", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.get_model_file": [[121, 131], ["logger.info", "glob.glob", "os.path.exists", "os.path.join", "len", "max"], "function", ["None"], ["", "def", "get_model_file", "(", "args", ",", "file_prefix", ")", "->", "str", ":", "\n", "    ", "out_cp_files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "file_prefix", "+", "'*'", ")", ")", "if", "args", ".", "output_dir", "else", "[", "]", "\n", "logger", ".", "info", "(", "'Checkpoint files %s'", ",", "out_cp_files", ")", "\n", "model_file", "=", "None", "\n", "\n", "if", "args", ".", "model_file", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_file", ")", ":", "\n", "        ", "model_file", "=", "args", ".", "model_file", "\n", "", "elif", "len", "(", "out_cp_files", ")", ">", "0", ":", "\n", "        ", "model_file", "=", "max", "(", "out_cp_files", ",", "key", "=", "os", ".", "path", ".", "getctime", ")", "\n", "", "return", "model_file", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint": [[132, 138], ["logger.info", "torch.load", "logger.info", "CheckpointState", "torch.load.keys", "torch.serialization.default_restore_location"], "function", ["None"], ["", "def", "load_states_from_checkpoint", "(", "model_file", ":", "str", ")", "->", "CheckpointState", ":", "\n", "    ", "logger", ".", "info", "(", "'Reading saved model from %s'", ",", "model_file", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "model_file", ",", "map_location", "=", "lambda", "s", ",", "l", ":", "default_restore_location", "(", "s", ",", "'cpu'", ")", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "logger", ".", "info", "(", "'model_state_dict keys %s'", ",", "state_dict", ".", "keys", "(", ")", ")", "\n", "return", "CheckpointState", "(", "**", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.load_states_from_checkpoint_only_model": [[139, 156], ["logger.info", "torch.load", "CheckpointState", "k.replace", "torch.load.pop", "torch.load.keys", "torch.serialization.default_restore_location"], "function", ["None"], ["", "def", "load_states_from_checkpoint_only_model", "(", "model_file", ":", "str", ")", "->", "CheckpointState", ":", "\n", "    ", "logger", ".", "info", "(", "'Reading saved model from %s'", ",", "model_file", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "model_file", ",", "map_location", "=", "lambda", "s", ",", "l", ":", "default_restore_location", "(", "s", ",", "'cpu'", ")", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "\n", "### delete after running the wrong vesion of code ###", "\n", "# state_dict = state_dict.model_dict", "\n", "### delete end ###", "\n", "\n", "all_keys", "=", "[", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "]", "\n", "for", "k", "in", "all_keys", ":", "\n", "        ", "new_key", "=", "k", ".", "replace", "(", "'module.'", ",", "''", ")", "\n", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "k", ")", "\n", "# import pdb;pdb.set_trace()", "\n", "", "meta_params", "=", "None", "\n", "# logger.info('model_state_dict keys %s', state_dict.keys())", "\n", "return", "CheckpointState", "(", "state_dict", ",", "None", ",", "None", ",", "None", ",", "None", ",", "meta_params", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.__init__": [[138, 171], ["len", "max", "max", "math.ceil", "min", "logger.debug", "math.ceil", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ":", "list", ",", "shard_id", ":", "int", "=", "0", ",", "num_shards", ":", "int", "=", "1", ",", "batch_size", ":", "int", "=", "1", ",", "shuffle", "=", "True", ",", "\n", "shuffle_seed", ":", "int", "=", "0", ",", "offset", ":", "int", "=", "0", ",", "\n", "strict_batch_size", ":", "bool", "=", "False", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "data", "=", "data", "\n", "total_size", "=", "len", "(", "data", ")", "\n", "\n", "self", ".", "shards_num", "=", "max", "(", "num_shards", ",", "1", ")", "\n", "self", ".", "shard_id", "=", "max", "(", "shard_id", ",", "0", ")", "\n", "\n", "samples_per_shard", "=", "math", ".", "ceil", "(", "total_size", "/", "self", ".", "shards_num", ")", "\n", "\n", "self", ".", "shard_start_idx", "=", "self", ".", "shard_id", "*", "samples_per_shard", "\n", "\n", "self", ".", "shard_end_idx", "=", "min", "(", "self", ".", "shard_start_idx", "+", "samples_per_shard", ",", "total_size", ")", "\n", "\n", "if", "strict_batch_size", ":", "\n", "            ", "self", ".", "max_iterations", "=", "math", ".", "ceil", "(", "samples_per_shard", "/", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "max_iterations", "=", "int", "(", "samples_per_shard", "/", "batch_size", ")", "\n", "\n", "", "logger", ".", "debug", "(", "\n", "'samples_per_shard=%d, shard_start_idx=%d, shard_end_idx=%d, max_iterations=%d'", ",", "samples_per_shard", ",", "\n", "self", ".", "shard_start_idx", ",", "\n", "self", ".", "shard_end_idx", ",", "\n", "self", ".", "max_iterations", ")", "\n", "\n", "self", ".", "iteration", "=", "offset", "# to track in-shard iteration status", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "shuffle_seed", "=", "shuffle_seed", "\n", "self", ".", "strict_batch_size", "=", "strict_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.total_data_len": [[172, 174], ["len"], "methods", ["None"], ["", "def", "total_data_len", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.iterate_data": [[175, 204], ["range", "logger.debug", "random.Random", "random.Random.shuffle", "len", "logger.debug", "logger.debug", "items.extend", "len", "len"], "methods", ["None"], ["", "def", "iterate_data", "(", "self", ",", "epoch", ":", "int", "=", "0", ")", "->", "Iterator", "[", "List", "]", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "# to be able to resume, same shuffling should be used when starting from a failed/stopped iteration", "\n", "            ", "epoch_rnd", "=", "random", ".", "Random", "(", "self", ".", "shuffle_seed", "+", "epoch", ")", "\n", "epoch_rnd", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "\n", "# if resuming iteration somewhere in the middle of epoch, one needs to adjust max_iterations", "\n", "\n", "", "max_iterations", "=", "self", ".", "max_iterations", "-", "self", ".", "iteration", "\n", "\n", "shard_samples", "=", "self", ".", "data", "[", "self", ".", "shard_start_idx", ":", "self", ".", "shard_end_idx", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "iteration", "*", "self", ".", "batch_size", ",", "len", "(", "shard_samples", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "            ", "items", "=", "shard_samples", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "if", "self", ".", "strict_batch_size", "and", "len", "(", "items", ")", "<", "self", ".", "batch_size", ":", "\n", "                ", "logger", ".", "debug", "(", "'Extending batch to max size'", ")", "\n", "items", ".", "extend", "(", "shard_samples", "[", "0", ":", "self", ".", "batch_size", "-", "len", "(", "items", ")", "]", ")", "\n", "", "self", ".", "iteration", "+=", "1", "\n", "yield", "items", "\n", "\n", "# some shards may done iterating while the others are at the last batch. Just return the first batch", "\n", "", "while", "self", ".", "iteration", "<", "max_iterations", ":", "\n", "            ", "logger", ".", "debug", "(", "'Fulfilling non complete shard='", ".", "format", "(", "self", ".", "shard_id", ")", ")", "\n", "self", ".", "iteration", "+=", "1", "\n", "batch", "=", "shard_samples", "[", "0", ":", "self", ".", "batch_size", "]", "\n", "yield", "batch", "\n", "\n", "", "logger", ".", "debug", "(", "'Finished iterating, iteration={}, shard={}'", ".", "format", "(", "self", ".", "iteration", ",", "self", ".", "shard_id", ")", ")", "\n", "# reset the iteration status", "\n", "self", ".", "iteration", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.get_iteration": [[205, 207], ["None"], "methods", ["None"], ["", "def", "get_iteration", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "iteration", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply": [[208, 211], ["visitor_func"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "visitor_func", ":", "Callable", ")", ":", "\n", "        ", "for", "sample", "in", "self", ".", "data", "[", "self", ".", "shard_start_idx", ":", "self", ".", "shard_end_idx", "]", ":", "\n", "            ", "visitor_func", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.Tensorizer.text_to_tensor": [[223, 225], ["None"], "methods", ["None"], ["def", "text_to_tensor", "(", "self", ",", "text", ":", "str", ",", "title", ":", "str", "=", "None", ",", "add_special_tokens", ":", "bool", "=", "True", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.Tensorizer.get_pair_separator_ids": [[226, 228], ["None"], "methods", ["None"], ["", "def", "get_pair_separator_ids", "(", "self", ")", "->", "T", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.Tensorizer.get_pad_id": [[229, 231], ["None"], "methods", ["None"], ["", "def", "get_pad_id", "(", "self", ")", "->", "int", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.Tensorizer.get_attn_mask": [[232, 234], ["None"], "methods", ["None"], ["", "def", "get_attn_mask", "(", "self", ",", "tokens_tensor", ":", "T", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.Tensorizer.is_sub_word_id": [[235, 237], ["None"], "methods", ["None"], ["", "def", "is_sub_word_id", "(", "self", ",", "token_id", ":", "int", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.Tensorizer.to_string": [[238, 240], ["None"], "methods", ["None"], ["", "def", "to_string", "(", "self", ",", "token_ids", ",", "skip_special_tokens", "=", "True", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.Tensorizer.set_pad_to_max": [[241, 243], ["None"], "methods", ["None"], ["", "def", "set_pad_to_max", "(", "self", ",", "pad", ":", "bool", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.read_serialized_data_from_files": [[26, 36], ["enumerate", "logger.info", "open", "logger.info", "pickle.load", "results.extend", "logger.info", "len", "len"], "function", ["None"], ["def", "read_serialized_data_from_files", "(", "paths", ":", "List", "[", "str", "]", ")", "->", "List", ":", "\n", "    ", "results", "=", "[", "]", "\n", "for", "i", ",", "path", "in", "enumerate", "(", "paths", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "reader", ":", "\n", "            ", "logger", ".", "info", "(", "'Reading file %s'", ",", "path", ")", "\n", "data", "=", "pickle", ".", "load", "(", "reader", ")", "\n", "results", ".", "extend", "(", "data", ")", "\n", "logger", ".", "info", "(", "'Aggregated data size: {}'", ".", "format", "(", "len", "(", "results", ")", ")", ")", "\n", "", "", "logger", ".", "info", "(", "'Total data size: {}'", ".", "format", "(", "len", "(", "results", ")", ")", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.read_data_from_json_files": [[37, 53], ["enumerate", "len", "len", "len", "open", "logger.info", "json.load", "int", "results.extend", "logger.info", "len"], "function", ["None"], ["", "def", "read_data_from_json_files", "(", "paths", ":", "List", "[", "str", "]", ",", "upsample_rates", ":", "List", "=", "None", ")", "->", "List", ":", "\n", "    ", "results", "=", "[", "]", "\n", "if", "upsample_rates", "is", "None", ":", "\n", "        ", "upsample_rates", "=", "[", "1", "]", "*", "len", "(", "paths", ")", "\n", "\n", "", "assert", "len", "(", "upsample_rates", ")", "==", "len", "(", "paths", ")", ",", "'up-sample rates parameter doesn\\'t match input files amount'", "\n", "\n", "for", "i", ",", "path", "in", "enumerate", "(", "paths", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "logger", ".", "info", "(", "'Reading file %s'", "%", "path", ")", "\n", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "upsample_factor", "=", "int", "(", "upsample_rates", "[", "i", "]", ")", "\n", "data", "=", "data", "*", "upsample_factor", "\n", "results", ".", "extend", "(", "data", ")", "\n", "logger", ".", "info", "(", "'Aggregated data size: {}'", ".", "format", "(", "len", "(", "results", ")", ")", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.read_data_from_wiki_to_json": [[54, 129], ["random.seed", "enumerate", "len", "len", "open", "open", "open.readlines", "enumerate", "len", "open.readlines", "str", "doc_lines[].strip().split", "open", "logger.info", "csv.reader", "len", "int", "results.extend", "logger.info", "len", "random.choice", "it[].append", "doc_lines[].strip", "row.split", "int", "re.split", "data.append", "sys.exit", "range", "len", "row[].strip", "random.choice", "row.split", "len", "len", "len", "len", "len", "len", "range", "len", "hard_negative_dict.keys", "row[].split", "len", "list", "range", "len"], "function", ["None"], ["", "def", "read_data_from_wiki_to_json", "(", "data_files", ":", "List", "[", "str", "]", ",", "sample_seed", ":", "int", "=", "0", ",", "upsample_rates", ":", "list", "=", "None", ",", "is_dialog", ":", "bool", "=", "False", ",", "hard_negative_path", ":", "str", "=", "None", ")", ":", "\n", "    ", "random", ".", "seed", "(", "sample_seed", ")", "\n", "results", "=", "[", "]", "\n", "if", "upsample_rates", "is", "None", ":", "\n", "        ", "upsample_rates", "=", "[", "1", "]", "*", "len", "(", "data_files", ")", "\n", "", "assert", "len", "(", "upsample_rates", ")", "==", "len", "(", "data_files", ")", ",", "'up-sample rates parameter doesn\\'t match input files amount'", "\n", "if", "hard_negative_path", ":", "\n", "        ", "hard_negative_dict", "=", "{", "}", "\n", "hard_negative_id_file", "=", "open", "(", "hard_negative_path", ",", "'r'", ")", "\n", "hard_negative_doc_file", "=", "open", "(", "hard_negative_path", "[", ":", "-", "6", "]", "+", "\"doc.txt\"", ",", "'rU'", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "doc_lines", "=", "hard_negative_doc_file", ".", "readlines", "(", ")", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "hard_negative_id_file", ".", "readlines", "(", ")", ")", ":", "\n", "            ", "doc_id", "=", "str", "(", "idx", "+", "1", ")", "\n", "# [doc_id, doc_context]", "\n", "docs", "=", "doc_lines", "[", "idx", "]", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "row", ".", "split", "(", ")", ")", "==", "0", ":", "\n", "                ", "assert", "(", "docs", "==", "[", "''", "]", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                ", "hard_negative_dict", "[", "doc_id", "]", "=", "[", "int", "(", "row", ".", "split", "(", ")", "[", "0", "]", ")", ",", "docs", "[", "0", "]", "]", "\n", "\n", "", "", "", "for", "i", ",", "path", "in", "enumerate", "(", "data_files", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'rU'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "# with open(path, 'rb') as f:", "\n", "            ", "logger", ".", "info", "(", "'Reading file %s'", "%", "path", ")", "\n", "\n", "# data = f.read()", "\n", "# with open(path[:-4]+\".fixed.txt\", 'wb') as fo:", "\n", "#     fo.write(data.replace(b'\\x00', b''))", "\n", "# exit()sss", "\n", "\n", "full_file", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "data", "=", "[", "]", "\n", "try", ":", "\n", "                ", "for", "row", "in", "full_file", ":", "\n", "                    ", "if", "len", "(", "row", "[", "1", "]", ")", ">", "1024", "or", "len", "(", "row", "[", "1", "]", ")", "<", "20", "or", "len", "(", "row", "[", "2", "]", ")", ">", "1024", ":", "\n", "                        ", "continue", "\n", "", "parag", "=", "re", ".", "split", "(", "r'\\.|!|\\?'", ",", "row", "[", "1", "]", ")", "\n", "if", "len", "(", "parag", ")", "<", "4", "or", "len", "(", "row", "[", "1", "]", ".", "split", "(", ")", ")", ">", "256", ":", "\n", "                        ", "continue", "\n", "", "if", "is_dialog", ":", "\n", "                        ", "query", "=", "row", "[", "2", "]", ".", "strip", "(", ")", "\n", "context", "=", "row", "[", "1", "]", "\n", "if", "len", "(", "query", ")", "<", "2", ":", "continue", "\n", "ctxs", "=", "{", "'title'", ":", "'na'", ",", "'text'", ":", "context", ",", "'score'", ":", "0", ",", "'title_score'", ":", "0", ",", "'psg_id'", ":", "row", "[", "0", "]", "}", "\n", "", "else", ":", "\n", "                        ", "rnd", "=", "random", ".", "choice", "(", "range", "(", "len", "(", "parag", ")", ")", ")", "\n", "query", "=", "parag", "[", "rnd", "]", "\n", "context", "=", "\".\"", ".", "join", "(", "parag", "[", "i", "]", "for", "i", "in", "list", "(", "range", "(", "len", "(", "parag", ")", ")", ")", "if", "i", "!=", "rnd", ")", "\n", "if", "len", "(", "query", ")", "<", "2", ":", "continue", "\n", "ctxs", "=", "{", "'title'", ":", "row", "[", "2", "]", ",", "'text'", ":", "context", ",", "'score'", ":", "0", ",", "'title_score'", ":", "0", ",", "'psg_id'", ":", "row", "[", "0", "]", "}", "\n", "\n", "", "if", "hard_negative_path", "and", "(", "row", "[", "0", "]", "in", "hard_negative_dict", ".", "keys", "(", ")", ")", ":", "\n", "                        ", "hard_negative_id", ",", "hard_negative_doc", "=", "hard_negative_dict", "[", "row", "[", "0", "]", "]", "\n", "hard_negative_ctxs", "=", "{", "'title'", ":", "'na'", ",", "'text'", ":", "hard_negative_doc", ",", "'score'", ":", "0", ",", "'title_score'", ":", "0", ",", "'psg_id'", ":", "hard_negative_id", "}", "\n", "# print(ctxs)", "\n", "# print(hard_negative_ctxs)", "\n", "\n", "", "data", ".", "append", "(", "\n", "{", "'dataset'", ":", "\"\"", ",", "'question'", ":", "query", ",", "'answers'", ":", "[", "]", ",", "'positive_ctxs'", ":", "[", "ctxs", "]", ",", "'negative_ctxs'", ":", "[", "]", ",", "\n", "'hard_negative_ctxs'", ":", "(", "[", "hard_negative_ctxs", "]", "if", "hard_negative_path", "else", "[", "]", ")", "}", ")", "\n", "#except csv.Error:", "\n", "", "", "except", "csv", ".", "Error", "as", "e", ":", "\n", "                ", "sys", ".", "exit", "(", "'file %s, line %d: %s'", "%", "(", "path", ",", "full_file", ".", "line_num", ",", "e", ")", ")", "\n", "# pass", "\n", "", "data_size", "=", "len", "(", "data", ")", "\n", "for", "it", "in", "data", ":", "\n", "                ", "rnd", "=", "random", ".", "choice", "(", "range", "(", "data_size", ")", ")", "\n", "it", "[", "'hard_negative_ctxs'", "]", ".", "append", "(", "data", "[", "rnd", "]", "[", "'positive_ctxs'", "]", "[", "0", "]", ")", "\n", "", "upsample_factor", "=", "int", "(", "upsample_rates", "[", "i", "]", ")", "\n", "data", "=", "data", "*", "upsample_factor", "\n", "results", ".", "extend", "(", "data", ")", "\n", "logger", ".", "info", "(", "'Aggregated data size: {}'", ".", "format", "(", "len", "(", "results", ")", ")", ")", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.normalize_question": [[212, 216], ["None"], "function", ["None"], ["", "", "", "def", "normalize_question", "(", "question", ":", "str", ")", "->", "str", ":", "\n", "    ", "if", "question", "[", "-", "1", "]", "==", "'?'", ":", "\n", "        ", "question", "=", "question", "[", ":", "-", "1", "]", "\n", "", "return", "question", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.__init__": [[29, 33], ["None"], "methods", ["None"], ["# contraction", "\n", "add_space", "=", "[", "\"'s\"", ",", "\"'m\"", ",", "\"'re\"", ",", "\"n't\"", ",", "\"'ll\"", ",", "\"'ve\"", ",", "\"'d\"", ",", "\"'em\"", "]", "\n", "tokenizer", "=", "TweetTokenizer", "(", "preserve_case", "=", "False", ")", "\n", "txt", "=", "' '", "+", "' '", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "txt", ")", ")", "+", "' '", "\n", "txt", "=", "txt", ".", "replace", "(", "\" won't \"", ",", "\" will n't \"", ")", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.__len__": [[34, 37], ["len"], "methods", ["None"], ["txt", "=", "txt", ".", "replace", "(", "\" can't \"", ",", "\" can n't \"", ")", "\n", "for", "a", "in", "add_space", ":", "\n", "\t\t", "txt", "=", "txt", ".", "replace", "(", "a", "+", "' '", ",", "' '", "+", "a", "+", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.slice": [[38, 43], ["copy.copy"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.copy"], ["", "txt", "=", "re", ".", "sub", "(", "r'^\\s+'", ",", "''", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "r'\\s+$'", ",", "''", ",", "txt", ")", "\n", "txt", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "txt", ")", "# remove extra spaces", "\n", "\n", "#print(\"out=[%s]\" % txt)", "\n", "return", "txt", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.untokenize": [[44, 47], ["None"], "methods", ["None"], ["\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "\t", "ss", "=", "[", "\n", "\" I don't know:). how about this?https://github.com/golsun/deep-RL-time-series\"", ",", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.words": [[48, 58], ["t[].lower"], "methods", ["None"], ["\"please try [ GitHub ] ( https://github.com )\"", ",", "\n", "]", "\n", "for", "s", "in", "ss", ":", "\n", "\t\t", "print", "(", "s", ")", "\n", "print", "(", "clean_str", "(", "s", ")", ")", "\n", "print", "(", ")", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.offsets": [[59, 62], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.pos": [[63, 70], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.lemmas": [[71, 78], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.entities": [[79, 86], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.ngrams": [[87, 114], ["tokenizers.Tokens.words", "filter_fn", "range", "range", "len", "min", "tokenizers.Tokens.ngrams._skip"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.words"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.entity_groups": [[115, 135], ["tokenizers.Tokens.entities", "tokenizers.Tokens.opts.get", "len", "groups.append", "len", "tokenizers.Tokens.slice().untokenize", "tokenizers.Tokens.slice"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.entities", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.untokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.slice"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokenizer.tokenize": [[141, 143], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokenizer.shutdown": [[144, 146], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokenizer.__del__": [[147, 149], ["tokenizers.Tokenizer.shutdown"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokenizer.shutdown"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SimpleTokenizer.__init__": [[154, 167], ["regex.compile", "set", "len", "logger.warning", "kwargs.get", "kwargs.get", "type"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SimpleTokenizer.tokenize": [[168, 190], ["range", "tokenizers.Tokens", "len", "matches[].group", "matches[].span", "data.append", "tokenizers.SimpleTokenizer._regexp.finditer", "len", "matches[].span"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.__init__": [[193, 207], ["kwargs.get", "copy.deepcopy", "spacy.load", "kwargs.get", "any", "set"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize": [[208, 237], ["text.replace", "tokenizers.SpacyTokenizer.nlp.tokenizer", "any", "range", "tokenizers.Tokens", "tokenizers.SpacyTokenizer.nlp.tagger", "tokenizers.SpacyTokenizer.nlp.entity", "len", "data.append", "len", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.__init__": [[42, 45], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "fairseq_roberta_hub", ":", "RobertaHubInterface", ")", ":", "\n", "        ", "super", "(", "RobertaEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fairseq_roberta", "=", "fairseq_roberta_hub", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained": [[46, 50], ["fairseq.models.roberta.model.RobertaModel.from_pretrained", "cls"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_dir_path", ":", "str", ")", ":", "\n", "        ", "model", "=", "FaiseqRobertaModel", ".", "from_pretrained", "(", "pretrained_dir_path", ")", "\n", "return", "cls", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.forward": [[51, 55], ["fairseq_models.RobertaEncoder.fairseq_roberta.extract_features"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ":", "T", ",", "token_type_ids", ":", "T", ",", "attention_mask", ":", "T", ")", "->", "Tuple", "[", "T", ",", "...", "]", ":", "\n", "        ", "roberta_out", "=", "self", ".", "fairseq_roberta", ".", "extract_features", "(", "input_ids", ")", "\n", "cls_out", "=", "roberta_out", "[", ":", ",", "0", ",", ":", "]", "\n", "return", "roberta_out", ",", "cls_out", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.get_out_size": [[56, 58], ["None"], "methods", ["None"], ["", "def", "get_out_size", "(", "self", ")", ":", "\n", "        ", "return", "768", "\n", "# return self.config.hidden_size", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.get_roberta_biencoder_components": [[26, 35], ["fairseq_models.RobertaEncoder.from_pretrained", "fairseq_models.RobertaEncoder.from_pretrained", "biencoder.BiEncoder", "dpr.models.hf_models.get_roberta_tensorizer", "fairseq_models.get_fairseq_adamw_optimizer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tensorizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.get_fairseq_adamw_optimizer"], ["def", "get_roberta_biencoder_components", "(", "args", ",", "inference_only", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "question_encoder", "=", "RobertaEncoder", ".", "from_pretrained", "(", "args", ".", "pretrained_file", ")", "\n", "ctx_encoder", "=", "RobertaEncoder", ".", "from_pretrained", "(", "args", ".", "pretrained_file", ")", "\n", "biencoder", "=", "BiEncoder", "(", "question_encoder", ",", "ctx_encoder", ")", "\n", "optimizer", "=", "get_fairseq_adamw_optimizer", "(", "biencoder", ",", "args", ")", "if", "not", "inference_only", "else", "None", "\n", "\n", "tensorizer", "=", "get_roberta_tensorizer", "(", "args", ")", "\n", "\n", "return", "tensorizer", ",", "biencoder", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.get_fairseq_adamw_optimizer": [[36, 39], ["setattr", "fairseq.optim.adam.FairseqAdam", "model.parameters"], "function", ["None"], ["", "def", "get_fairseq_adamw_optimizer", "(", "model", ":", "nn", ".", "Module", ",", "args", ")", ":", "\n", "    ", "setattr", "(", "args", ",", "'lr'", ",", "[", "args", ".", "learning_rate", "]", ")", "\n", "return", "FairseqAdam", "(", "args", ",", "model", ".", "parameters", "(", ")", ")", ".", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.__init__": [[16, 22], ["print"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_argobj", ")", ":", "\n", "        ", "if", "model_argobj", "is", "None", ":", "\n", "            ", "self", ".", "use_mean", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "use_mean", "=", "model_argobj", ".", "use_mean", "\n", "", "print", "(", "\"Using mean:\"", ",", "self", ".", "use_mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin._init_weights": [[23, 29], ["isinstance", "module.weight.data.normal_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "nn", ".", "Conv1d", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.masked_mean": [[30, 34], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "mask.sum().float", "mask.unsqueeze().float", "mask.sum", "mask.unsqueeze"], "methods", ["None"], ["", "", "def", "masked_mean", "(", "self", ",", "t", ",", "mask", ")", ":", "\n", "        ", "s", "=", "torch", ".", "sum", "(", "t", "*", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "float", "(", ")", ",", "axis", "=", "1", ")", "\n", "d", "=", "mask", ".", "sum", "(", "axis", "=", "1", ",", "keepdim", "=", "True", ")", ".", "float", "(", ")", "\n", "return", "s", "/", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.masked_mean_or_first": [[35, 42], ["isinstance", "ance_models.EmbeddingMixin.masked_mean"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.masked_mean"], ["", "def", "masked_mean_or_first", "(", "self", ",", "emb_all", ",", "mask", ")", ":", "\n", "# emb_all is a tuple from bert - sequence output, pooler", "\n", "        ", "assert", "isinstance", "(", "emb_all", ",", "tuple", ")", "\n", "if", "self", ".", "use_mean", ":", "\n", "            ", "return", "self", ".", "masked_mean", "(", "emb_all", "[", "0", "]", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "return", "emb_all", "[", "0", "]", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.query_emb": [[43, 45], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "query_emb", "(", "self", ",", "input_ids", ",", "attention_mask", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Please Implement this method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.body_emb": [[46, 48], ["NotImplementedError"], "methods", ["None"], ["", "def", "body_emb", "(", "self", ",", "input_ids", ",", "attention_mask", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Please Implement this method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.NLL.forward": [[50, 73], ["ance_models.NLL.query_emb", "ance_models.NLL.body_emb", "ance_models.NLL.body_emb", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log_softmax", "torch.log_softmax", "ance_models.NLL.query_emb", "loss.mean", "ance_models.NLL.body_emb"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.query_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.body_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.body_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.query_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.body_emb"], ["    ", "def", "forward", "(", "\n", "self", ",", "\n", "query_ids", ",", "\n", "attention_mask_q", ",", "\n", "input_ids_a", "=", "None", ",", "\n", "attention_mask_a", "=", "None", ",", "\n", "input_ids_b", "=", "None", ",", "\n", "attention_mask_b", "=", "None", ",", "\n", "is_query", "=", "True", ")", ":", "\n", "        ", "if", "input_ids_b", "is", "None", "and", "is_query", ":", "\n", "            ", "return", "self", ".", "query_emb", "(", "query_ids", ",", "attention_mask_q", ")", "\n", "", "elif", "input_ids_b", "is", "None", ":", "\n", "            ", "return", "self", ".", "body_emb", "(", "query_ids", ",", "attention_mask_q", ")", "\n", "\n", "", "q_embs", "=", "self", ".", "query_emb", "(", "query_ids", ",", "attention_mask_q", ")", "\n", "a_embs", "=", "self", ".", "body_emb", "(", "input_ids_a", ",", "attention_mask_a", ")", "\n", "b_embs", "=", "self", ".", "body_emb", "(", "input_ids_b", ",", "attention_mask_b", ")", "\n", "\n", "logit_matrix", "=", "torch", ".", "cat", "(", "[", "(", "q_embs", "*", "a_embs", ")", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "(", "q_embs", "*", "b_embs", ")", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "# [B, 2]", "\n", "lsm", "=", "F", ".", "log_softmax", "(", "logit_matrix", ",", "dim", "=", "1", ")", "\n", "loss", "=", "-", "1.0", "*", "lsm", "[", ":", ",", "0", "]", "\n", "return", "(", "loss", ".", "mean", "(", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.NLL_MultiChunk.forward": [[75, 125], ["ance_models.NLL_MultiChunk.query_emb", "ance_models.NLL_MultiChunk.body_emb", "ance_models.NLL_MultiChunk.body_emb", "input_ids_a.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log_softmax", "torch.log_softmax", "ance_models.NLL_MultiChunk.query_emb", "attention_mask_a.reshape", "ance_models.NLL_MultiChunk.unsqueeze", "ance_models.NLL_MultiChunk.transpose", "attention_mask_b.reshape", "ance_models.NLL_MultiChunk.unsqueeze", "ance_models.NLL_MultiChunk.transpose", "loss.mean", "ance_models.NLL_MultiChunk.body_emb", "logits_a.unsqueeze", "logits_b.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.query_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.body_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.body_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.query_emb", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.body_emb"], ["    ", "def", "forward", "(", "\n", "self", ",", "\n", "query_ids", ",", "\n", "attention_mask_q", ",", "\n", "input_ids_a", "=", "None", ",", "\n", "attention_mask_a", "=", "None", ",", "\n", "input_ids_b", "=", "None", ",", "\n", "attention_mask_b", "=", "None", ",", "\n", "is_query", "=", "True", ")", ":", "\n", "        ", "if", "input_ids_b", "is", "None", "and", "is_query", ":", "\n", "            ", "return", "self", ".", "query_emb", "(", "query_ids", ",", "attention_mask_q", ")", "\n", "", "elif", "input_ids_b", "is", "None", ":", "\n", "            ", "return", "self", ".", "body_emb", "(", "query_ids", ",", "attention_mask_q", ")", "\n", "\n", "", "q_embs", "=", "self", ".", "query_emb", "(", "query_ids", ",", "attention_mask_q", ")", "\n", "a_embs", "=", "self", ".", "body_emb", "(", "input_ids_a", ",", "attention_mask_a", ")", "\n", "b_embs", "=", "self", ".", "body_emb", "(", "input_ids_b", ",", "attention_mask_b", ")", "\n", "\n", "[", "batchS", ",", "full_length", "]", "=", "input_ids_a", ".", "size", "(", ")", "\n", "chunk_factor", "=", "full_length", "//", "self", ".", "base_len", "\n", "\n", "# special handle of attention mask -----", "\n", "attention_mask_body", "=", "attention_mask_a", ".", "reshape", "(", "\n", "batchS", ",", "chunk_factor", ",", "-", "1", ")", "[", ":", ",", ":", ",", "0", "]", "# [batchS, chunk_factor]", "\n", "inverted_bias", "=", "(", "(", "1", "-", "attention_mask_body", ")", "*", "(", "-", "9999", ")", ")", ".", "float", "(", ")", "\n", "\n", "a12", "=", "torch", ".", "matmul", "(", "\n", "q_embs", ".", "unsqueeze", "(", "1", ")", ",", "a_embs", ".", "transpose", "(", "\n", "1", ",", "2", ")", ")", "# [batch, 1, chunk_factor]", "\n", "logits_a", "=", "(", "a12", "[", ":", ",", "0", ",", ":", "]", "+", "inverted_bias", ")", ".", "max", "(", "dim", "=", "-", "\n", "1", ",", "keepdim", "=", "False", ")", ".", "values", "# [batch]", "\n", "# -------------------------------------", "\n", "\n", "# special handle of attention mask -----", "\n", "attention_mask_body", "=", "attention_mask_b", ".", "reshape", "(", "\n", "batchS", ",", "chunk_factor", ",", "-", "1", ")", "[", ":", ",", ":", ",", "0", "]", "# [batchS, chunk_factor]", "\n", "inverted_bias", "=", "(", "(", "1", "-", "attention_mask_body", ")", "*", "(", "-", "9999", ")", ")", ".", "float", "(", ")", "\n", "\n", "a12", "=", "torch", ".", "matmul", "(", "\n", "q_embs", ".", "unsqueeze", "(", "1", ")", ",", "b_embs", ".", "transpose", "(", "\n", "1", ",", "2", ")", ")", "# [batch, 1, chunk_factor]", "\n", "logits_b", "=", "(", "a12", "[", ":", ",", "0", ",", ":", "]", "+", "inverted_bias", ")", ".", "max", "(", "dim", "=", "-", "\n", "1", ",", "keepdim", "=", "False", ")", ".", "values", "# [batch]", "\n", "# -------------------------------------", "\n", "\n", "logit_matrix", "=", "torch", ".", "cat", "(", "\n", "[", "logits_a", ".", "unsqueeze", "(", "1", ")", ",", "logits_b", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "# [B, 2]", "\n", "lsm", "=", "F", ".", "log_softmax", "(", "logit_matrix", ",", "dim", "=", "1", ")", "\n", "loss", "=", "-", "1.0", "*", "lsm", "[", ":", ",", "0", "]", "\n", "return", "(", "loss", ".", "mean", "(", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.__init__": [[131, 137], ["ance_models.EmbeddingMixin.__init__", "transformers.RobertaForSequenceClassification.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "ance_models.RobertaDot_NLL_LN.apply"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.ShardedDataIterator.apply"], ["def", "__init__", "(", "self", ",", "config", ",", "model_argobj", "=", "None", ")", ":", "\n", "        ", "NLL", ".", "__init__", "(", "self", ",", "model_argobj", ")", "\n", "RobertaForSequenceClassification", ".", "__init__", "(", "self", ",", "config", ")", "\n", "self", ".", "embeddingHead", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "768", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "768", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.query_emb": [[138, 144], ["ance_models.RobertaDot_NLL_LN.roberta", "ance_models.RobertaDot_NLL_LN.masked_mean_or_first", "ance_models.RobertaDot_NLL_LN.norm", "ance_models.RobertaDot_NLL_LN.embeddingHead"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.masked_mean_or_first"], ["", "def", "query_emb", "(", "self", ",", "input_ids", ",", "attention_mask", ")", ":", "\n", "        ", "outputs1", "=", "self", ".", "roberta", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "full_emb", "=", "self", ".", "masked_mean_or_first", "(", "outputs1", ",", "attention_mask", ")", "\n", "query1", "=", "self", ".", "norm", "(", "self", ".", "embeddingHead", "(", "full_emb", ")", ")", "\n", "return", "query1", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.body_emb": [[145, 147], ["ance_models.RobertaDot_NLL_LN.query_emb"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_NLL_LN.query_emb"], ["", "def", "body_emb", "(", "self", ",", "input_ids", ",", "attention_mask", ")", ":", "\n", "        ", "return", "self", ".", "query_emb", "(", "input_ids", ",", "attention_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.__init__": [[149, 152], ["ance_models.RobertaDot_NLL_LN.__init__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "RobertaDot_NLL_LN", ".", "__init__", "(", "self", ",", "config", ")", "\n", "self", ".", "base_len", "=", "512", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.body_emb": [[153, 188], ["input_ids.size", "input_ids.reshape().reshape", "attention_mask.reshape().reshape", "ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.roberta", "ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.embeddingHead", "ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.norm", "ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.size", "ance_models.RobertaDot_CLF_ANN_NLL_MultiChunk.reshape", "input_ids.reshape", "attention_mask.reshape"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "body_emb", "(", "self", ",", "input_ids", ",", "attention_mask", ")", ":", "\n", "        ", "[", "batchS", ",", "full_length", "]", "=", "input_ids", ".", "size", "(", ")", "\n", "chunk_factor", "=", "full_length", "//", "self", ".", "base_len", "\n", "\n", "input_seq", "=", "input_ids", ".", "reshape", "(", "\n", "batchS", ",", "\n", "chunk_factor", ",", "\n", "full_length", "//", "\n", "chunk_factor", ")", ".", "reshape", "(", "\n", "batchS", "*", "\n", "chunk_factor", ",", "\n", "full_length", "//", "\n", "chunk_factor", ")", "\n", "attention_mask_seq", "=", "attention_mask", ".", "reshape", "(", "\n", "batchS", ",", "\n", "chunk_factor", ",", "\n", "full_length", "//", "\n", "chunk_factor", ")", ".", "reshape", "(", "\n", "batchS", "*", "\n", "chunk_factor", ",", "\n", "full_length", "//", "\n", "chunk_factor", ")", "\n", "\n", "outputs_k", "=", "self", ".", "roberta", "(", "input_ids", "=", "input_seq", ",", "\n", "attention_mask", "=", "attention_mask_seq", ")", "\n", "\n", "compressed_output_k", "=", "self", ".", "embeddingHead", "(", "\n", "outputs_k", "[", "0", "]", ")", "# [batch, len, dim]", "\n", "compressed_output_k", "=", "self", ".", "norm", "(", "compressed_output_k", "[", ":", ",", "0", ",", ":", "]", ")", "\n", "\n", "[", "batch_expand", ",", "embeddingS", "]", "=", "compressed_output_k", ".", "size", "(", ")", "\n", "complex_emb_k", "=", "compressed_output_k", ".", "reshape", "(", "\n", "batchS", ",", "chunk_factor", ",", "embeddingS", ")", "\n", "\n", "return", "complex_emb_k", "# size [batchS, chunk_factor, embeddingS]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.__init__": [[51, 58], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "question_model", ":", "nn", ".", "Module", ",", "ctx_model", ":", "nn", ".", "Module", ",", "fix_q_encoder", ":", "bool", "=", "False", ",", "\n", "fix_ctx_encoder", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "BiEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "question_model", "=", "question_model", "\n", "self", ".", "ctx_model", "=", "ctx_model", "\n", "self", ".", "fix_q_encoder", "=", "fix_q_encoder", "\n", "self", ".", "fix_ctx_encoder", "=", "fix_ctx_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.get_representation": [[59, 77], ["sub_model", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sub_model", "sequence_output.requires_grad_", "pooled_output.requires_grad_"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_representation", "(", "sub_model", ":", "nn", ".", "Module", ",", "ids", ":", "T", ",", "segments", ":", "T", ",", "attn_mask", ":", "T", ",", "fix_encoder", ":", "bool", "=", "False", ")", "->", "(", "\n", "T", ",", "T", ",", "T", ")", ":", "\n", "        ", "sequence_output", "=", "None", "\n", "pooled_output", "=", "None", "\n", "hidden_states", "=", "None", "\n", "if", "ids", "is", "not", "None", ":", "\n", "            ", "if", "fix_encoder", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "sequence_output", ",", "pooled_output", ",", "hidden_states", "=", "sub_model", "(", "ids", ",", "segments", ",", "attn_mask", ")", "\n", "\n", "", "if", "sub_model", ".", "training", ":", "\n", "                    ", "sequence_output", ".", "requires_grad_", "(", "requires_grad", "=", "True", ")", "\n", "pooled_output", ".", "requires_grad_", "(", "requires_grad", "=", "True", ")", "\n", "", "", "else", ":", "\n", "                ", "sequence_output", ",", "pooled_output", ",", "hidden_states", "=", "sub_model", "(", "ids", ",", "segments", ",", "attn_mask", ")", "\n", "\n", "", "", "return", "sequence_output", ",", "pooled_output", ",", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.forward": [[78, 87], ["biencoder.BiEncoder.get_representation", "biencoder.BiEncoder.get_representation"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.get_representation", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.get_representation"], ["", "def", "forward", "(", "self", ",", "question_ids", ":", "T", ",", "question_segments", ":", "T", ",", "question_attn_mask", ":", "T", ",", "context_ids", ":", "T", ",", "ctx_segments", ":", "T", ",", "\n", "ctx_attn_mask", ":", "T", ")", "->", "Tuple", "[", "T", ",", "T", "]", ":", "\n", "\n", "        ", "_q_seq", ",", "q_pooled_out", ",", "_q_hidden", "=", "self", ".", "get_representation", "(", "self", ".", "question_model", ",", "question_ids", ",", "question_segments", ",", "\n", "question_attn_mask", ",", "self", ".", "fix_q_encoder", ")", "\n", "_ctx_seq", ",", "ctx_pooled_out", ",", "_ctx_hidden", "=", "self", ".", "get_representation", "(", "self", ".", "ctx_model", ",", "context_ids", ",", "ctx_segments", ",", "\n", "ctx_attn_mask", ",", "self", ".", "fix_ctx_encoder", ")", "\n", "\n", "return", "q_pooled_out", ",", "ctx_pooled_out", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoder.create_biencoder_input": [[88, 159], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "BiEncoderBatch", "dpr.utils.data_utils.normalize_question", "len", "ctx_tensors.extend", "positive_ctx_indices.append", "hard_neg_ctx_indices.append", "question_tensors.append", "random.shuffle", "random.shuffle", "len", "tensorizer.text_to_tensor", "tensorizer.text_to_tensor", "ctx.view", "q.view", "numpy.random.choice", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.data_utils.normalize_question", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor"], ["", "@", "classmethod", "\n", "def", "create_biencoder_input", "(", "cls", ",", "\n", "samples", ":", "List", ",", "\n", "tensorizer", ":", "Tensorizer", ",", "\n", "insert_title", ":", "bool", ",", "\n", "num_hard_negatives", ":", "int", "=", "0", ",", "\n", "num_other_negatives", ":", "int", "=", "0", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "shuffle_positives", ":", "bool", "=", "False", ",", "\n", ")", "->", "BiEncoderBatch", ":", "\n", "        ", "\"\"\"\n        Creates a batch of the biencoder training tuple.\n        :param samples: list of data items (from json) to create the batch for\n        :param tensorizer: components to create model input tensors from a text sequence\n        :param insert_title: enables title insertion at the beginning of the context sequences\n        :param num_hard_negatives: amount of hard negatives per question (taken from samples' pools)\n        :param num_other_negatives: amount of other negatives per question (taken from samples' pools)\n        :param shuffle: shuffles negative passages pools\n        :param shuffle_positives: shuffles positive passages pools\n        :return: BiEncoderBatch tuple\n        \"\"\"", "\n", "question_tensors", "=", "[", "]", "\n", "ctx_tensors", "=", "[", "]", "\n", "positive_ctx_indices", "=", "[", "]", "\n", "hard_neg_ctx_indices", "=", "[", "]", "\n", "\n", "for", "sample", "in", "samples", ":", "\n", "# ctx+ & [ctx-] composition", "\n", "# as of now, take the first(gold) ctx+ only", "\n", "            ", "if", "shuffle", "and", "shuffle_positives", ":", "\n", "                ", "positive_ctxs", "=", "sample", "[", "'positive_ctxs'", "]", "\n", "positive_ctx", "=", "positive_ctxs", "[", "np", ".", "random", ".", "choice", "(", "len", "(", "positive_ctxs", ")", ")", "]", "\n", "", "else", ":", "\n", "                ", "positive_ctx", "=", "sample", "[", "'positive_ctxs'", "]", "[", "0", "]", "\n", "\n", "", "neg_ctxs", "=", "sample", "[", "'negative_ctxs'", "]", "\n", "hard_neg_ctxs", "=", "sample", "[", "'hard_negative_ctxs'", "]", "\n", "question", "=", "normalize_question", "(", "sample", "[", "'question'", "]", ")", "\n", "\n", "if", "shuffle", ":", "\n", "                ", "random", ".", "shuffle", "(", "neg_ctxs", ")", "\n", "random", ".", "shuffle", "(", "hard_neg_ctxs", ")", "\n", "\n", "", "neg_ctxs", "=", "neg_ctxs", "[", "0", ":", "num_other_negatives", "]", "\n", "hard_neg_ctxs", "=", "hard_neg_ctxs", "[", "0", ":", "num_hard_negatives", "]", "\n", "\n", "all_ctxs", "=", "[", "positive_ctx", "]", "+", "neg_ctxs", "+", "hard_neg_ctxs", "\n", "hard_negatives_start_idx", "=", "1", "\n", "hard_negatives_end_idx", "=", "1", "+", "len", "(", "hard_neg_ctxs", ")", "\n", "\n", "current_ctxs_len", "=", "len", "(", "ctx_tensors", ")", "\n", "sample_ctxs_tensors", "=", "[", "tensorizer", ".", "text_to_tensor", "(", "ctx", "[", "'text'", "]", ",", "title", "=", "ctx", "[", "'title'", "]", "if", "insert_title", "else", "None", ")", "\n", "for", "\n", "ctx", "in", "all_ctxs", "]", "\n", "\n", "ctx_tensors", ".", "extend", "(", "sample_ctxs_tensors", ")", "\n", "positive_ctx_indices", ".", "append", "(", "current_ctxs_len", ")", "\n", "hard_neg_ctx_indices", ".", "append", "(", "\n", "[", "i", "for", "i", "in", "\n", "range", "(", "current_ctxs_len", "+", "hard_negatives_start_idx", ",", "current_ctxs_len", "+", "hard_negatives_end_idx", ")", "]", ")", "\n", "\n", "question_tensors", ".", "append", "(", "tensorizer", ".", "text_to_tensor", "(", "question", ")", ")", "\n", "\n", "", "ctxs_tensor", "=", "torch", ".", "cat", "(", "[", "ctx", ".", "view", "(", "1", ",", "-", "1", ")", "for", "ctx", "in", "ctx_tensors", "]", ",", "dim", "=", "0", ")", "\n", "questions_tensor", "=", "torch", ".", "cat", "(", "[", "q", ".", "view", "(", "1", ",", "-", "1", ")", "for", "q", "in", "question_tensors", "]", ",", "dim", "=", "0", ")", "\n", "\n", "ctx_segments", "=", "torch", ".", "zeros_like", "(", "ctxs_tensor", ")", "\n", "question_segments", "=", "torch", ".", "zeros_like", "(", "questions_tensor", ")", "\n", "\n", "return", "BiEncoderBatch", "(", "questions_tensor", ",", "question_segments", ",", "ctxs_tensor", ",", "ctx_segments", ",", "positive_ctx_indices", ",", "\n", "hard_neg_ctx_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.calc": [[162, 184], ["biencoder.BiEncoderNllLoss.get_scores", "torch.log_softmax", "torch.log_softmax", "torch.nll_loss", "torch.nll_loss", "torch.max", "torch.max", "torch.max", "torch.max", "len", "q_vectors.size", "scores.view.view.view", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "q_vectors.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.get_scores", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to", "home.repos.pwc.inspect_result.dreasysnail_RetGen.lsp_model.optim.Adamax.to"], ["    ", "def", "calc", "(", "self", ",", "q_vectors", ":", "T", ",", "ctx_vectors", ":", "T", ",", "positive_idx_per_question", ":", "list", ",", "\n", "hard_negatice_idx_per_question", ":", "list", "=", "None", ")", "->", "Tuple", "[", "T", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Computes nll loss for the given lists of question and ctx vectors.\n        Note that although hard_negatice_idx_per_question in not currently in use, one can use it for the\n        loss modifications. For example - weighted NLL with different factors for hard vs regular negatives.\n        :return: a tuple of loss value and amount of correct predictions per batch\n        \"\"\"", "\n", "scores", "=", "self", ".", "get_scores", "(", "q_vectors", ",", "ctx_vectors", ")", "\n", "\n", "if", "len", "(", "q_vectors", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "            ", "q_num", "=", "q_vectors", ".", "size", "(", "0", ")", "\n", "scores", "=", "scores", ".", "view", "(", "q_num", ",", "-", "1", ")", "\n", "\n", "", "softmax_scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "1", ")", "\n", "\n", "loss", "=", "F", ".", "nll_loss", "(", "softmax_scores", ",", "torch", ".", "tensor", "(", "positive_idx_per_question", ")", ".", "to", "(", "softmax_scores", ".", "device", ")", ",", "\n", "reduction", "=", "'mean'", ")", "\n", "\n", "max_score", ",", "max_idxs", "=", "torch", ".", "max", "(", "softmax_scores", ",", "1", ")", "\n", "correct_predictions_count", "=", "(", "max_idxs", "==", "torch", ".", "tensor", "(", "positive_idx_per_question", ")", ".", "to", "(", "max_idxs", ".", "device", ")", ")", ".", "sum", "(", ")", "\n", "return", "loss", ",", "correct_predictions_count", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.get_scores": [[185, 189], ["biencoder.BiEncoderNllLoss.get_similarity_function", "biencoder.BiEncoderNllLoss.get_similarity_function"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.get_similarity_function", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.get_similarity_function"], ["", "@", "staticmethod", "\n", "def", "get_scores", "(", "q_vector", ":", "T", ",", "ctx_vectors", ":", "T", ")", "->", "T", ":", "\n", "        ", "f", "=", "BiEncoderNllLoss", ".", "get_similarity_function", "(", ")", "\n", "return", "f", "(", "q_vector", ",", "ctx_vectors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.BiEncoderNllLoss.get_similarity_function": [[190, 193], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_similarity_function", "(", ")", ":", "\n", "        ", "return", "dot_product_scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.dot_product_scores": [[32, 42], ["torch.matmul", "torch.matmul", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "dot_product_scores", "(", "q_vectors", ":", "T", ",", "ctx_vectors", ":", "T", ")", "->", "T", ":", "\n", "    ", "\"\"\"\n    calculates q->ctx scores for every row in ctx_vector\n    :param q_vector:\n    :param ctx_vector:\n    :return:\n    \"\"\"", "\n", "# q_vector: n1 x D, ctx_vectors: n2 x D, result n1 x n2", "\n", "r", "=", "torch", ".", "matmul", "(", "q_vectors", ",", "torch", ".", "transpose", "(", "ctx_vectors", ",", "0", ",", "1", ")", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.biencoder.cosine_scores": [[43, 46], ["torch.cosine_similarity"], "function", ["None"], ["", "def", "cosine_scores", "(", "q_vector", ":", "T", ",", "ctx_vectors", ":", "T", ")", ":", "\n", "# q_vector: n1 x D, ctx_vectors: n2 x D, result n1 x n2", "\n", "    ", "return", "F", ".", "cosine_similarity", "(", "q_vector", ",", "ctx_vectors", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFBertEncoder.__init__": [[132, 137], ["transformers.modeling_bert.BertModel.__init__", "hf_models.HFBertEncoder.init_weights", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "project_dim", ":", "int", "=", "0", ")", ":", "\n", "        ", "BertModel", ".", "__init__", "(", "self", ",", "config", ")", "\n", "assert", "config", ".", "hidden_size", ">", "0", ",", "'Encoder hidden_size can\\'t be zero'", "\n", "self", ".", "encode_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "project_dim", ")", "if", "project_dim", "!=", "0", "else", "None", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFBertEncoder.init_encoder": [[138, 145], ["transformers.modeling_bert.BertConfig.from_pretrained", "cls.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained"], ["", "@", "classmethod", "\n", "def", "init_encoder", "(", "cls", ",", "cfg_name", ":", "str", ",", "projection_dim", ":", "int", "=", "0", ",", "dropout", ":", "float", "=", "0.1", ",", "**", "kwargs", ")", "->", "BertModel", ":", "\n", "        ", "cfg", "=", "BertConfig", ".", "from_pretrained", "(", "cfg_name", "if", "cfg_name", "else", "'bert-base-uncased'", ")", "\n", "if", "dropout", "!=", "0", ":", "\n", "            ", "cfg", ".", "attention_probs_dropout_prob", "=", "dropout", "\n", "cfg", ".", "hidden_dropout_prob", "=", "dropout", "\n", "", "return", "cls", ".", "from_pretrained", "(", "cfg_name", ",", "config", "=", "cfg", ",", "project_dim", "=", "projection_dim", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFBertEncoder.forward": [[146, 160], ["super().forward", "super().forward", "hf_models.HFBertEncoder.encode_proj"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader.forward", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ":", "T", ",", "token_type_ids", ":", "T", ",", "attention_mask", ":", "T", ")", "->", "Tuple", "[", "T", ",", "...", "]", ":", "\n", "        ", "if", "self", ".", "config", ".", "output_hidden_states", ":", "\n", "            ", "sequence_output", ",", "pooled_output", ",", "hidden_states", "=", "super", "(", ")", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "hidden_states", "=", "None", "\n", "sequence_output", ",", "pooled_output", "=", "super", "(", ")", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "", "pooled_output", "=", "sequence_output", "[", ":", ",", "0", ",", ":", "]", "\n", "if", "self", ".", "encode_proj", ":", "\n", "            ", "pooled_output", "=", "self", ".", "encode_proj", "(", "pooled_output", ")", "\n", "", "return", "sequence_output", ",", "pooled_output", ",", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFBertEncoder.get_out_size": [[161, 165], ["None"], "methods", ["None"], ["", "def", "get_out_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "encode_proj", ":", "\n", "            ", "return", "self", ".", "encode_proj", ".", "out_features", "\n", "", "return", "self", ".", "config", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFRoBERTaEncoder.__init__": [[168, 173], ["transformers.modeling_roberta.RobertaModel.__init__", "hf_models.HFRoBERTaEncoder.init_weights", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "project_dim", ":", "int", "=", "0", ")", ":", "\n", "        ", "RobertaModel", ".", "__init__", "(", "self", ",", "config", ")", "\n", "assert", "config", ".", "hidden_size", ">", "0", ",", "'Encoder hidden_size can\\'t be zero'", "\n", "self", ".", "encode_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "project_dim", ")", "if", "project_dim", "!=", "0", "else", "None", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFRoBERTaEncoder.init_encoder": [[174, 181], ["transformers.modeling_roberta.RobertaConfig.from_pretrained", "cls.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained"], ["", "@", "classmethod", "\n", "def", "init_encoder", "(", "cls", ",", "cfg_name", ":", "str", ",", "projection_dim", ":", "int", "=", "0", ",", "dropout", ":", "float", "=", "0.1", ",", "**", "kwargs", ")", "->", "RobertaModel", ":", "\n", "        ", "cfg", "=", "RobertaConfig", ".", "from_pretrained", "(", "cfg_name", "if", "cfg_name", "else", "'roberta-base'", ")", "\n", "if", "dropout", "!=", "0", ":", "\n", "            ", "cfg", ".", "attention_probs_dropout_prob", "=", "dropout", "\n", "cfg", ".", "hidden_dropout_prob", "=", "dropout", "\n", "", "return", "cls", ".", "from_pretrained", "(", "cfg_name", ",", "config", "=", "cfg", ",", "project_dim", "=", "projection_dim", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFRoBERTaEncoder.forward": [[182, 196], ["super().forward", "super().forward", "hf_models.HFRoBERTaEncoder.encode_proj"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader.forward", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ":", "T", ",", "token_type_ids", ":", "T", ",", "attention_mask", ":", "T", ")", "->", "Tuple", "[", "T", ",", "...", "]", ":", "\n", "        ", "if", "self", ".", "config", ".", "output_hidden_states", ":", "\n", "            ", "sequence_output", ",", "pooled_output", ",", "hidden_states", "=", "super", "(", ")", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "hidden_states", "=", "None", "\n", "sequence_output", ",", "pooled_output", "=", "super", "(", ")", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "", "pooled_output", "=", "sequence_output", "[", ":", ",", "0", ",", ":", "]", "\n", "if", "self", ".", "encode_proj", ":", "\n", "            ", "pooled_output", "=", "self", ".", "encode_proj", "(", "pooled_output", ")", "\n", "", "return", "sequence_output", ",", "pooled_output", ",", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.HFRoBERTaEncoder.get_out_size": [[197, 201], ["None"], "methods", ["None"], ["", "def", "get_out_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "encode_proj", ":", "\n", "            ", "return", "self", ".", "encode_proj", ".", "out_features", "\n", "", "return", "self", ".", "config", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.ANCERoBERTaEncoder.__init__": [[204, 211], ["dpr.models.ance_models.NLL.__init__", "transformers.modeling_roberta.RobertaForSequenceClassification.__init__", "torch.nn.Linear", "torch.nn.LayerNorm", "hf_models.ANCERoBERTaEncoder.init_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "project_dim", ":", "int", "=", "0", ")", ":", "\n", "        ", "NLL", ".", "__init__", "(", "self", ",", "None", ")", "\n", "RobertaForSequenceClassification", ".", "__init__", "(", "self", ",", "config", ")", "\n", "assert", "config", ".", "hidden_size", ">", "0", ",", "'Encoder hidden_size can\\'t be zero'", "\n", "self", ".", "embeddingHead", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "768", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "768", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.ANCERoBERTaEncoder.init_encoder": [[212, 219], ["transformers.modeling_roberta.RobertaConfig.from_pretrained", "cls.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained"], ["", "@", "classmethod", "\n", "def", "init_encoder", "(", "cls", ",", "cfg_name", ":", "str", ",", "projection_dim", ":", "int", "=", "0", ",", "dropout", ":", "float", "=", "0.1", ",", "**", "kwargs", ")", "->", "RobertaModel", ":", "\n", "        ", "cfg", "=", "RobertaConfig", ".", "from_pretrained", "(", "cfg_name", "if", "cfg_name", "else", "'bert-base-uncased'", ")", "\n", "if", "dropout", "!=", "0", ":", "\n", "            ", "cfg", ".", "attention_probs_dropout_prob", "=", "dropout", "\n", "cfg", ".", "hidden_dropout_prob", "=", "dropout", "\n", "", "return", "cls", ".", "from_pretrained", "(", "cfg_name", ",", "config", "=", "cfg", ",", "project_dim", "=", "projection_dim", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.ANCERoBERTaEncoder.forward": [[220, 225], ["hf_models.ANCERoBERTaEncoder.roberta", "hf_models.ANCERoBERTaEncoder.masked_mean_or_first", "hf_models.ANCERoBERTaEncoder.norm", "hf_models.ANCERoBERTaEncoder.embeddingHead"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.ance_models.EmbeddingMixin.masked_mean_or_first"], ["", "def", "forward", "(", "self", ",", "input_ids", ":", "T", ",", "token_type_ids", ":", "T", ",", "attention_mask", ":", "T", ")", "->", "Tuple", "[", "T", ",", "...", "]", ":", "\n", "        ", "outputs1", "=", "self", ".", "roberta", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "full_emb", "=", "self", ".", "masked_mean_or_first", "(", "outputs1", ",", "attention_mask", ")", "\n", "pooled_output", "=", "self", ".", "norm", "(", "self", ".", "embeddingHead", "(", "full_emb", ")", ")", "\n", "return", "None", ",", "pooled_output", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.ANCERoBERTaEncoder.get_out_size": [[226, 230], ["None"], "methods", ["None"], ["", "def", "get_out_size", "(", "self", ")", ":", "\n", "# if self.encode_proj:", "\n", "#    return self.encode_proj.out_features", "\n", "        ", "return", "self", ".", "config", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.__init__": [[232, 241], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "BertTokenizer", ",", "max_length", ":", "int", ",", "pad_to_max", ":", "bool", "=", "True", ",", "pad_token_id", ":", "int", "=", "None", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "pad_to_max", "=", "pad_to_max", "\n", "\n", "if", "pad_token_id", "is", "not", "None", ":", "\n", "            ", "self", ".", "pad_token_id", "=", "pad_token_id", "\n", "", "else", ":", "\n", "            ", "self", ".", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor": [[242, 262], ["text.strip.strip.strip", "torch.tensor", "hf_models.BertTensorizer.tokenizer.encode", "hf_models.BertTensorizer.tokenizer.encode", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode", "home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode"], ["", "", "def", "text_to_tensor", "(", "self", ",", "text", ":", "str", ",", "title", ":", "str", "=", "None", ",", "add_special_tokens", ":", "bool", "=", "True", ")", ":", "\n", "        ", "text", "=", "text", ".", "strip", "(", ")", "\n", "\n", "# tokenizer automatic padding is explicitly disabled since its inconsistent behavior", "\n", "if", "title", ":", "\n", "            ", "token_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "title", ",", "text_pair", "=", "text", ",", "add_special_tokens", "=", "add_special_tokens", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "pad_to_max_length", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "token_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "text", ",", "add_special_tokens", "=", "add_special_tokens", ",", "max_length", "=", "self", ".", "max_length", ",", "\n", "pad_to_max_length", "=", "False", ")", "\n", "\n", "", "seq_len", "=", "self", ".", "max_length", "\n", "if", "self", ".", "pad_to_max", "and", "len", "(", "token_ids", ")", "<", "seq_len", ":", "\n", "            ", "token_ids", "=", "token_ids", "+", "[", "self", ".", "pad_token_id", "]", "*", "(", "seq_len", "-", "len", "(", "token_ids", ")", ")", "\n", "", "if", "len", "(", "token_ids", ")", ">", "seq_len", ":", "\n", "            ", "token_ids", "=", "token_ids", "[", "0", ":", "seq_len", "]", "\n", "token_ids", "[", "-", "1", "]", "=", "self", ".", "tokenizer", ".", "sep_token_id", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "token_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_pair_separator_ids": [[263, 265], ["torch.tensor"], "methods", ["None"], ["", "def", "get_pair_separator_ids", "(", "self", ")", "->", "T", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_pad_id": [[266, 268], ["None"], "methods", ["None"], ["", "def", "get_pad_id", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "pad_token_id", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_attn_mask": [[269, 273], ["None"], "methods", ["None"], ["", "def", "get_attn_mask", "(", "self", ",", "tokens_tensor", ":", "T", ")", "->", "T", ":", "\n", "        ", "output", "=", "tokens_tensor", "!=", "self", ".", "pad_token_id", "\n", "output", "[", ":", ",", "0", "]", "=", "True", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.is_sub_word_id": [[274, 277], ["hf_models.BertTensorizer.tokenizer.convert_ids_to_tokens", "token.startswith", "token.startswith"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.convert_ids_to_tokens"], ["", "def", "is_sub_word_id", "(", "self", ",", "token_id", ":", "int", ")", ":", "\n", "        ", "token", "=", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "[", "token_id", "]", ")", "[", "0", "]", "\n", "return", "token", ".", "startswith", "(", "\"##\"", ")", "or", "token", ".", "startswith", "(", "\" ##\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.to_string": [[278, 280], ["hf_models.BertTensorizer.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode"], ["", "def", "to_string", "(", "self", ",", "token_ids", ",", "skip_special_tokens", "=", "True", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "decode", "(", "token_ids", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.set_pad_to_max": [[281, 283], ["None"], "methods", ["None"], ["", "def", "set_pad_to_max", "(", "self", ",", "do_pad", ":", "bool", ")", ":", "\n", "        ", "self", ".", "pad_to_max", "=", "do_pad", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.RobertaTensorizer.__init__": [[285, 287], ["hf_models.BertTensorizer.__init__"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "max_length", ":", "int", ",", "pad_to_max", ":", "bool", "=", "True", ",", "pad_token_id", ":", "int", "=", "None", ")", ":", "\n", "        ", "super", "(", "RobertaTensorizer", ",", "self", ")", ".", "__init__", "(", "tokenizer", ",", "max_length", ",", "pad_to_max", "=", "pad_to_max", ",", "pad_token_id", "=", "pad_token_id", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_biencoder_components": [[31, 68], ["biencoder.BiEncoder", "hasattr", "hf_models.get_ance_tensorizer", "hasattr", "hf_models.get_optimizer", "hf_models.HFBertEncoder.init_encoder", "hf_models.HFBertEncoder.init_encoder", "hf_models.ANCERoBERTaEncoder.init_encoder", "hf_models.ANCERoBERTaEncoder.init_encoder", "hf_models.HFRoBERTaEncoder.init_encoder", "hf_models.HFRoBERTaEncoder.init_encoder", "hf_models.get_roberta_tensorizer", "hf_models.HFBertEncoder.init_encoder", "hf_models.HFBertEncoder.init_encoder", "hf_models.get_bert_tensorizer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_ance_tensorizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_optimizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tensorizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_tensorizer"], ["def", "get_bert_biencoder_components", "(", "args", ",", "inference_only", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "dropout", "=", "args", ".", "dropout", "if", "hasattr", "(", "args", ",", "'dropout'", ")", "else", "0.0", "\n", "\n", "# modify based on cfg so it could load both bert and roberta models", "\n", "if", "'ance'", "in", "args", ".", "encoder_model_type", ":", "\n", "        ", "if", "args", ".", "pretrained_model_cfg", "and", "'bert-'", "in", "args", ".", "pretrained_model_cfg", ":", "\n", "            ", "question_encoder", "=", "HFBertEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "ctx_encoder", "=", "HFBertEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "question_encoder", "=", "ANCERoBERTaEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "ctx_encoder", "=", "ANCERoBERTaEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "", "tensorizer", "=", "get_ance_tensorizer", "(", "args", ")", "\n", "", "elif", "'roberta'", "in", "args", ".", "pretrained_model_cfg", ":", "\n", "        ", "question_encoder", "=", "HFRoBERTaEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "ctx_encoder", "=", "HFRoBERTaEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "tensorizer", "=", "get_roberta_tensorizer", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "question_encoder", "=", "HFBertEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "ctx_encoder", "=", "HFBertEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ",", "**", "kwargs", ")", "\n", "tensorizer", "=", "get_bert_tensorizer", "(", "args", ")", "\n", "\n", "", "fix_ctx_encoder", "=", "args", ".", "fix_ctx_encoder", "if", "hasattr", "(", "args", ",", "'fix_ctx_encoder'", ")", "else", "False", "\n", "biencoder", "=", "BiEncoder", "(", "question_encoder", ",", "ctx_encoder", ",", "fix_ctx_encoder", "=", "fix_ctx_encoder", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "biencoder", ",", "\n", "learning_rate", "=", "args", ".", "learning_rate", ",", "\n", "adam_eps", "=", "args", ".", "adam_eps", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "\n", ")", "if", "not", "inference_only", "else", "None", "\n", "return", "tensorizer", ",", "biencoder", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_reader_components": [[69, 88], ["hf_models.HFBertEncoder.init_encoder", "reader.Reader", "hasattr", "hf_models.get_optimizer", "hf_models.get_roberta_tensorizer", "hf_models.get_bert_tensorizer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_optimizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tensorizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_tensorizer"], ["", "def", "get_bert_reader_components", "(", "args", ",", "inference_only", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "dropout", "=", "args", ".", "dropout", "if", "hasattr", "(", "args", ",", "'dropout'", ")", "else", "0.0", "\n", "encoder", "=", "HFBertEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_model_cfg", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "dropout", ")", "\n", "\n", "hidden_size", "=", "encoder", ".", "config", ".", "hidden_size", "\n", "reader", "=", "Reader", "(", "encoder", ",", "hidden_size", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "reader", ",", "\n", "learning_rate", "=", "args", ".", "learning_rate", ",", "\n", "adam_eps", "=", "args", ".", "adam_eps", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "\n", ")", "if", "not", "inference_only", "else", "None", "\n", "\n", "if", "'roberta'", "in", "args", ".", "pretrained_model_cfg", ":", "\n", "        ", "tensorizer", "=", "get_roberta_tensorizer", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "tensorizer", "=", "get_bert_tensorizer", "(", "args", ")", "\n", "\n", "", "return", "tensorizer", ",", "reader", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_ance_tensorizer": [[89, 100], ["hf_models.BertTensorizer", "hf_models.RobertaTensorizer", "hf_models.get_bert_tokenizer", "hf_models.get_roberta_tokenizer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_tokenizer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tokenizer"], ["", "def", "get_ance_tensorizer", "(", "args", ",", "tokenizer", "=", "None", ")", ":", "\n", "    ", "if", "not", "tokenizer", ":", "\n", "        ", "if", "args", ".", "pretrained_model_cfg", "and", "'bert-'", "in", "args", ".", "pretrained_model_cfg", ":", "\n", "            ", "tokenizer", "=", "get_bert_tokenizer", "(", "args", ".", "pretrained_model_cfg", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "            ", "tokenizer", "=", "get_roberta_tokenizer", "(", "args", ".", "pretrained_model_cfg", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "", "", "if", "args", ".", "pretrained_model_cfg", "and", "'bert-'", "in", "args", ".", "pretrained_model_cfg", ":", "\n", "        ", "return", "BertTensorizer", "(", "tokenizer", ",", "args", ".", "sequence_length", ",", "pad_token_id", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "RobertaTensorizer", "(", "tokenizer", ",", "args", ".", "sequence_length", ",", "pad_token_id", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_tensorizer": [[101, 105], ["hf_models.BertTensorizer", "hf_models.get_bert_tokenizer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_tokenizer"], ["", "", "def", "get_bert_tensorizer", "(", "args", ",", "tokenizer", "=", "None", ")", ":", "\n", "    ", "if", "not", "tokenizer", ":", "\n", "        ", "tokenizer", "=", "get_bert_tokenizer", "(", "args", ".", "pretrained_model_cfg", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "return", "BertTensorizer", "(", "tokenizer", ",", "args", ".", "sequence_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tensorizer": [[106, 110], ["hf_models.RobertaTensorizer", "hf_models.get_roberta_tokenizer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tokenizer"], ["", "def", "get_roberta_tensorizer", "(", "args", ",", "tokenizer", "=", "None", ")", ":", "\n", "    ", "if", "not", "tokenizer", ":", "\n", "        ", "tokenizer", "=", "get_roberta_tokenizer", "(", "args", ".", "pretrained_model_cfg", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "return", "RobertaTensorizer", "(", "tokenizer", ",", "args", ".", "sequence_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_optimizer": [[111, 122], ["transformers.optimization.AdamW", "model.named_parameters", "model.named_parameters", "any", "any"], "function", ["None"], ["", "def", "get_optimizer", "(", "model", ":", "nn", ".", "Module", ",", "learning_rate", ":", "float", "=", "1e-5", ",", "adam_eps", ":", "float", "=", "1e-8", ",", "\n", "weight_decay", ":", "float", "=", "0.0", ",", ")", "->", "torch", ".", "optim", ".", "Optimizer", ":", "\n", "    ", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "learning_rate", ",", "eps", "=", "adam_eps", ",", "correct_bias", "=", "False", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_tokenizer": [[123, 125], ["transformers.tokenization_bert.BertTokenizer.from_pretrained"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained"], ["", "def", "get_bert_tokenizer", "(", "pretrained_cfg_name", ":", "str", ",", "do_lower_case", ":", "bool", "=", "True", ")", ":", "\n", "    ", "return", "BertTokenizer", ".", "from_pretrained", "(", "pretrained_cfg_name", ",", "do_lower_case", "=", "do_lower_case", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tokenizer": [[126, 129], ["transformers.tokenization_roberta.RobertaTokenizer.from_pretrained"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.RobertaEncoder.from_pretrained"], ["", "def", "get_roberta_tokenizer", "(", "pretrained_cfg_name", ":", "str", ",", "do_lower_case", ":", "bool", "=", "True", ")", ":", "\n", "# still uses HF code for tokenizer since they are the same", "\n", "    ", "return", "RobertaTokenizer", ".", "from_pretrained", "(", "pretrained_cfg_name", ",", "do_lower_case", "=", "do_lower_case", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.__init__": [[84, 96], ["pytext.models.representations.transformer_sentence_encoder.TransformerSentenceEncoder.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "TransformerSentenceEncoder", ".", "Config", ",", "\n", "padding_idx", ":", "int", ",", "\n", "vocab_size", ":", "int", ",", "\n", "projection_dim", ":", "int", "=", "0", ",", "\n", "*", "args", ",", "\n", "**", "kwarg", "\n", ")", ":", "\n", "\n", "        ", "TransformerSentenceEncoder", ".", "__init__", "(", "self", ",", "config", ",", "False", ",", "padding_idx", ",", "vocab_size", ",", "*", "args", ",", "**", "kwarg", ")", "\n", "\n", "assert", "config", ".", "embedding_dim", ">", "0", ",", "'Encoder hidden_size can\\'t be zero'", "\n", "self", ".", "encode_proj", "=", "nn", ".", "Linear", "(", "config", ".", "embedding_dim", ",", "projection_dim", ")", "if", "projection_dim", "!=", "0", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder": [[97, 115], ["pytext_models.get_pytext_bert_base_cfg", "cls", "logger.info", "torch.load", "cls.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_pytext_bert_base_cfg"], ["", "@", "classmethod", "\n", "def", "init_encoder", "(", "cls", ",", "pretrained_file", ":", "str", "=", "None", ",", "projection_dim", ":", "int", "=", "0", ",", "dropout", ":", "float", "=", "0.1", ",", "\n", "vocab_size", ":", "int", "=", "0", ",", "\n", "padding_idx", ":", "int", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "        ", "cfg", "=", "get_pytext_bert_base_cfg", "(", ")", "\n", "\n", "if", "dropout", "!=", "0", ":", "\n", "            ", "cfg", ".", "dropout", "=", "dropout", "\n", "cfg", ".", "attention_dropout", "=", "dropout", "\n", "cfg", ".", "activation_dropout", "=", "dropout", "\n", "\n", "", "encoder", "=", "cls", "(", "cfg", ",", "padding_idx", ",", "vocab_size", ",", "projection_dim", ",", "**", "kwargs", ")", "\n", "\n", "if", "pretrained_file", ":", "\n", "            ", "logger", ".", "info", "(", "'Loading pre-trained pytext encoder state from %s'", ",", "pretrained_file", ")", "\n", "state", "=", "torch", ".", "load", "(", "pretrained_file", ")", "\n", "encoder", ".", "load_state_dict", "(", "state", ")", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.forward": [[116, 122], ["super().forward", "pytext_models.PytextBertEncoder.encode_proj"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ":", "T", ",", "token_type_ids", ":", "T", ",", "attention_mask", ":", "T", ")", "->", "Tuple", "[", "T", ",", "...", "]", ":", "\n", "        ", "pooled_output", "=", "super", "(", ")", ".", "forward", "(", "(", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "None", ")", ")", "[", "0", "]", "\n", "if", "self", ".", "encode_proj", ":", "\n", "            ", "pooled_output", "=", "self", ".", "encode_proj", "(", "pooled_output", ")", "\n", "\n", "", "return", "None", ",", "pooled_output", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.get_out_size": [[123, 127], ["None"], "methods", ["None"], ["", "def", "get_out_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "encode_proj", ":", "\n", "            ", "return", "self", ".", "encode_proj", ".", "out_features", "\n", "", "return", "self", ".", "representation_dim", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_bert_biencoder_components": [[25, 52], ["get_tokenizer", "pytext_models.PytextBertEncoder.init_encoder", "pytext_models.PytextBertEncoder.init_encoder", "biencoder.BiEncoder", "BertTensorizer", "pytext_models.get_optimizer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.PytextBertEncoder.init_encoder", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_optimizer"], ["def", "get_bert_biencoder_components", "(", "args", ",", "inference_only", ":", "bool", "=", "False", ")", ":", "\n", "# since bert tokenizer is the same in HF and pytext/fairseq, just use HF's implementation here for now", "\n", "    ", "from", ".", "hf_models", "import", "get_tokenizer", ",", "BertTensorizer", "\n", "\n", "tokenizer", "=", "get_tokenizer", "(", "args", ".", "pretrained_model_cfg", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "question_encoder", "=", "PytextBertEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_file", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "args", ".", "dropout", ",", "\n", "vocab_size", "=", "tokenizer", ".", "vocab_size", ",", "\n", "padding_idx", "=", "tokenizer", ".", "pad_token_type_id", "\n", ")", "\n", "\n", "ctx_encoder", "=", "PytextBertEncoder", ".", "init_encoder", "(", "args", ".", "pretrained_file", ",", "\n", "projection_dim", "=", "args", ".", "projection_dim", ",", "dropout", "=", "args", ".", "dropout", ",", "\n", "vocab_size", "=", "tokenizer", ".", "vocab_size", ",", "\n", "padding_idx", "=", "tokenizer", ".", "pad_token_type_id", "\n", ")", "\n", "\n", "biencoder", "=", "BiEncoder", "(", "question_encoder", ",", "ctx_encoder", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "biencoder", ",", "\n", "learning_rate", "=", "args", ".", "learning_rate", ",", "\n", "adam_eps", "=", "args", ".", "adam_eps", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "\n", ")", "if", "not", "inference_only", "else", "None", "\n", "\n", "tensorizer", "=", "BertTensorizer", "(", "tokenizer", ",", "args", ".", "sequence_length", ")", "\n", "return", "tensorizer", ",", "biencoder", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_optimizer": [[53, 61], ["pytext.optimizer.optimizers.AdamW.Config", "pytext.optimizer.optimizers.AdamW.from_config"], "function", ["None"], ["", "def", "get_optimizer", "(", "model", ":", "nn", ".", "Module", ",", "learning_rate", ":", "float", "=", "1e-5", ",", "adam_eps", ":", "float", "=", "1e-8", ",", "\n", "weight_decay", ":", "float", "=", "0.0", ")", "->", "torch", ".", "optim", ".", "Optimizer", ":", "\n", "    ", "cfg", "=", "AdamW", ".", "Config", "(", ")", "\n", "cfg", ".", "lr", "=", "learning_rate", "\n", "cfg", ".", "weight_decay", "=", "weight_decay", "\n", "cfg", ".", "eps", "=", "adam_eps", "\n", "optimizer", "=", "AdamW", ".", "from_config", "(", "cfg", ",", "model", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_pytext_bert_base_cfg": [[62, 81], ["pytext.models.representations.transformer_sentence_encoder.TransformerSentenceEncoder.Config"], "function", ["None"], ["", "def", "get_pytext_bert_base_cfg", "(", ")", ":", "\n", "    ", "cfg", "=", "TransformerSentenceEncoder", ".", "Config", "(", ")", "\n", "cfg", ".", "embedding_dim", "=", "768", "\n", "cfg", ".", "ffn_embedding_dim", "=", "3072", "\n", "cfg", ".", "num_encoder_layers", "=", "12", "\n", "cfg", ".", "num_attention_heads", "=", "12", "\n", "cfg", ".", "num_segments", "=", "2", "\n", "cfg", ".", "use_position_embeddings", "=", "True", "\n", "cfg", ".", "offset_positions_by_padding", "=", "True", "\n", "cfg", ".", "apply_bert_init", "=", "True", "\n", "cfg", ".", "encoder_normalize_before", "=", "True", "\n", "cfg", ".", "activation_fn", "=", "\"gelu\"", "\n", "cfg", ".", "projection_dim", "=", "0", "\n", "cfg", ".", "max_seq_len", "=", "512", "\n", "cfg", ".", "multilingual", "=", "False", "\n", "cfg", ".", "freeze_embeddings", "=", "False", "\n", "cfg", ".", "n_trans_layers_to_freeze", "=", "0", "\n", "cfg", ".", "use_torchscript", "=", "False", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_hf_bert_biencoder": [[14, 19], ["get_bert_biencoder_components", "importlib.util.find_spec", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_bert_biencoder_components"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_hf_bert_reader": [[20, 25], ["get_bert_reader_components", "importlib.util.find_spec", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_reader_components"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_pytext_bert_biencoder": [[26, 31], ["get_bert_biencoder_components", "importlib.util.find_spec", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.pytext_models.get_bert_biencoder_components"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_fairseq_roberta_biencoder": [[32, 37], ["get_roberta_biencoder_components", "importlib.util.find_spec", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.fairseq_models.get_roberta_biencoder_components"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_hf_bert_tenzorizer": [[38, 43], ["get_bert_tensorizer", "importlib.util.find_spec", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_bert_tensorizer"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_hf_roberta_tenzorizer": [[44, 49], ["get_roberta_tensorizer", "importlib.util.find_spec", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.get_roberta_tensorizer"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_comp": [[70, 75], ["RuntimeError"], "function", ["None"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_biencoder_components": [[76, 78], ["__init__.init_comp"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_comp"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_reader_components": [[79, 81], ["__init__.init_comp"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_comp"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_tenzorizer": [[82, 84], ["__init__.init_comp"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.__init__.init_comp"], []], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader.__init__": [[31, 37], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "dpr.utils.model_utils.init_weights"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.model_utils.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ":", "nn", ".", "Module", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "Reader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "2", ")", "\n", "self", ".", "qa_classifier", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "init_weights", "(", "[", "self", ".", "qa_outputs", ",", "self", ".", "qa_classifier", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader.forward": [[38, 48], ["input_ids.size", "reader.Reader._forward", "input_ids.view", "attention_mask.view", "reader.compute_loss", "start_logits.view", "end_logits.view", "relevance_logits.view"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader._forward", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.compute_loss"], ["", "def", "forward", "(", "self", ",", "input_ids", ":", "T", ",", "attention_mask", ":", "T", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "answer_mask", "=", "None", ")", ":", "\n", "# notations: N - number of questions in a batch, M - number of passages per questions, L - sequence length", "\n", "        ", "N", ",", "M", ",", "L", "=", "input_ids", ".", "size", "(", ")", "\n", "start_logits", ",", "end_logits", ",", "relevance_logits", "=", "self", ".", "_forward", "(", "input_ids", ".", "view", "(", "N", "*", "M", ",", "L", ")", ",", "\n", "attention_mask", ".", "view", "(", "N", "*", "M", ",", "L", ")", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "compute_loss", "(", "start_positions", ",", "end_positions", ",", "answer_mask", ",", "start_logits", ",", "end_logits", ",", "relevance_logits", ",", "\n", "N", ",", "M", ")", "\n", "\n", "", "return", "start_logits", ".", "view", "(", "N", ",", "M", ",", "L", ")", ",", "end_logits", ".", "view", "(", "N", ",", "M", ",", "L", ")", ",", "relevance_logits", ".", "view", "(", "N", ",", "M", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.Reader._forward": [[49, 58], ["reader.Reader.encoder", "reader.Reader.qa_outputs", "reader.Reader.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "reader.Reader.qa_classifier"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "input_ids", ",", "attention_mask", ")", ":", "\n", "# TODO: provide segment values", "\n", "        ", "sequence_output", ",", "_pooled_output", ",", "_hidden_states", "=", "self", ".", "encoder", "(", "input_ids", ",", "None", ",", "attention_mask", ")", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "rank_logits", "=", "self", ".", "qa_classifier", "(", "sequence_output", "[", ":", ",", "0", ",", ":", "]", ")", "\n", "return", "start_logits", ",", "end_logits", ",", "rank_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.compute_loss": [[59, 94], ["start_positions.view.view", "end_positions.view.view", "answer_mask.type().cuda.view", "start_logits.view.view", "end_logits.view.view", "relevance_logits.view.view", "answer_mask.type().cuda.type().cuda", "start_logits.view.size", "start_positions.view.clamp_", "end_positions.view.clamp_", "torch.nn.CrossEntropyLoss", "relevance_logits.view.view", "torch.zeros().cuda", "torch.zeros().cuda", "torch.sum", "torch.sum", "reader._calc_mml", "torch.nn.CrossEntropyLoss.", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "loss_tensor.view().max", "answer_mask.type().cuda.type", "torch.zeros", "torch.zeros", "torch.nn.CrossEntropyLoss.", "zip", "torch.nn.CrossEntropyLoss.", "zip", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "t.unsqueeze", "t.unsqueeze", "loss_tensor.view"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._calc_mml"], ["", "", "def", "compute_loss", "(", "start_positions", ",", "end_positions", ",", "answer_mask", ",", "start_logits", ",", "end_logits", ",", "relevance_logits", ",", "N", ",", "M", ")", ":", "\n", "    ", "start_positions", "=", "start_positions", ".", "view", "(", "N", "*", "M", ",", "-", "1", ")", "\n", "end_positions", "=", "end_positions", ".", "view", "(", "N", "*", "M", ",", "-", "1", ")", "\n", "answer_mask", "=", "answer_mask", ".", "view", "(", "N", "*", "M", ",", "-", "1", ")", "\n", "\n", "start_logits", "=", "start_logits", ".", "view", "(", "N", "*", "M", ",", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "view", "(", "N", "*", "M", ",", "-", "1", ")", "\n", "relevance_logits", "=", "relevance_logits", ".", "view", "(", "N", "*", "M", ")", "\n", "\n", "answer_mask", "=", "answer_mask", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", ")", "\n", "\n", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "reduce", "=", "False", ",", "ignore_index", "=", "ignored_index", ")", "\n", "\n", "# compute switch loss", "\n", "relevance_logits", "=", "relevance_logits", ".", "view", "(", "N", ",", "M", ")", "\n", "switch_labels", "=", "torch", ".", "zeros", "(", "N", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "\n", "switch_loss", "=", "torch", ".", "sum", "(", "loss_fct", "(", "relevance_logits", ",", "switch_labels", ")", ")", "\n", "\n", "# compute span loss", "\n", "start_losses", "=", "[", "(", "loss_fct", "(", "start_logits", ",", "_start_positions", ")", "*", "_span_mask", ")", "\n", "for", "(", "_start_positions", ",", "_span_mask", ")", "\n", "in", "zip", "(", "torch", ".", "unbind", "(", "start_positions", ",", "dim", "=", "1", ")", ",", "torch", ".", "unbind", "(", "answer_mask", ",", "dim", "=", "1", ")", ")", "]", "\n", "\n", "end_losses", "=", "[", "(", "loss_fct", "(", "end_logits", ",", "_end_positions", ")", "*", "_span_mask", ")", "\n", "for", "(", "_end_positions", ",", "_span_mask", ")", "\n", "in", "zip", "(", "torch", ".", "unbind", "(", "end_positions", ",", "dim", "=", "1", ")", ",", "torch", ".", "unbind", "(", "answer_mask", ",", "dim", "=", "1", ")", ")", "]", "\n", "loss_tensor", "=", "torch", ".", "cat", "(", "[", "t", ".", "unsqueeze", "(", "1", ")", "for", "t", "in", "start_losses", "]", ",", "dim", "=", "1", ")", "+", "torch", ".", "cat", "(", "[", "t", ".", "unsqueeze", "(", "1", ")", "for", "t", "in", "end_losses", "]", ",", "dim", "=", "1", ")", "\n", "\n", "loss_tensor", "=", "loss_tensor", ".", "view", "(", "N", ",", "M", ",", "-", "1", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "span_loss", "=", "_calc_mml", "(", "loss_tensor", ")", "\n", "return", "span_loss", "+", "switch_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader.create_reader_input": [[95, 149], ["torch.Tensor().new_full", "torch.Tensor().new_full", "torch.cat", "torch.cat", "ReaderBatch", "reader._create_question_passages_tensors", "torch.cat.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.Tensor", "torch.Tensor", "logger.warning", "torch.stack.append", "torch.stack.append", "torch.stack.append", "ids.unsqueeze"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._create_question_passages_tensors"], ["", "def", "create_reader_input", "(", "pad_token_id", ":", "int", ",", "\n", "samples", ":", "List", "[", "ReaderSample", "]", ",", "\n", "passages_per_question", ":", "int", ",", "\n", "max_length", ":", "int", ",", "\n", "max_n_answers", ":", "int", ",", "\n", "is_train", ":", "bool", ",", "\n", "shuffle", ":", "bool", ",", "\n", ")", "->", "ReaderBatch", ":", "\n", "    ", "\"\"\"\n    Creates a reader batch instance out of a list of ReaderSample-s\n    :param pad_token_id: id of the padding token\n    :param samples: list of samples to create the batch for\n    :param passages_per_question: amount of passages for every question in a batch\n    :param max_length: max model input sequence length\n    :param max_n_answers: max num of answers per single question\n    :param is_train: if the samples are for a train set\n    :param shuffle: should passages selection be randomized\n    :return: ReaderBatch instance\n    \"\"\"", "\n", "input_ids", "=", "[", "]", "\n", "start_positions", "=", "[", "]", "\n", "end_positions", "=", "[", "]", "\n", "answers_masks", "=", "[", "]", "\n", "empty_sequence", "=", "torch", ".", "Tensor", "(", ")", ".", "new_full", "(", "(", "max_length", ",", ")", ",", "pad_token_id", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "for", "sample", "in", "samples", ":", "\n", "        ", "positive_ctxs", "=", "sample", ".", "positive_passages", "\n", "negative_ctxs", "=", "sample", ".", "negative_passages", "if", "is_train", "else", "sample", ".", "passages", "\n", "\n", "sample_tensors", "=", "_create_question_passages_tensors", "(", "positive_ctxs", ",", "\n", "negative_ctxs", ",", "\n", "passages_per_question", ",", "\n", "empty_sequence", ",", "\n", "max_n_answers", ",", "\n", "pad_token_id", ",", "\n", "is_train", ",", "\n", "is_random", "=", "shuffle", ")", "\n", "if", "not", "sample_tensors", ":", "\n", "            ", "logger", ".", "warning", "(", "'No valid passages combination for question=%s '", ",", "sample", ".", "question", ")", "\n", "continue", "\n", "", "sample_input_ids", ",", "starts_tensor", ",", "ends_tensor", ",", "answer_mask", "=", "sample_tensors", "\n", "input_ids", ".", "append", "(", "sample_input_ids", ")", "\n", "if", "is_train", ":", "\n", "            ", "start_positions", ".", "append", "(", "starts_tensor", ")", "\n", "end_positions", ".", "append", "(", "ends_tensor", ")", "\n", "answers_masks", ".", "append", "(", "answer_mask", ")", "\n", "", "", "input_ids", "=", "torch", ".", "cat", "(", "[", "ids", ".", "unsqueeze", "(", "0", ")", "for", "ids", "in", "input_ids", "]", ",", "dim", "=", "0", ")", "\n", "\n", "if", "is_train", ":", "\n", "        ", "start_positions", "=", "torch", ".", "stack", "(", "start_positions", ",", "dim", "=", "0", ")", "\n", "end_positions", "=", "torch", ".", "stack", "(", "end_positions", ",", "dim", "=", "0", ")", "\n", "answers_masks", "=", "torch", ".", "stack", "(", "answers_masks", ",", "dim", "=", "0", ")", "\n", "\n", "", "return", "ReaderBatch", "(", "input_ids", ",", "start_positions", ",", "end_positions", ",", "answers_masks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._calc_mml": [[150, 155], ["torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.ones().cuda", "torch.ones().cuda", "torch.ones", "torch.ones", "loss_tensor.size"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_calc_mml", "(", "loss_tensor", ")", ":", "\n", "    ", "marginal_likelihood", "=", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "\n", "-", "loss_tensor", "-", "1e10", "*", "(", "loss_tensor", "==", "0", ")", ".", "float", "(", ")", ")", ",", "1", ")", "\n", "return", "-", "torch", ".", "sum", "(", "torch", ".", "log", "(", "marginal_likelihood", "+", "\n", "torch", ".", "ones", "(", "loss_tensor", ".", "size", "(", "0", ")", ")", ".", "cuda", "(", ")", "*", "(", "marginal_likelihood", "==", "0", ")", ".", "float", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._pad_to_len": [[156, 161], ["seq.size", "torch.cat", "torch.cat", "torch.Tensor().new_full", "torch.Tensor().new_full", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_pad_to_len", "(", "seq", ":", "T", ",", "pad_id", ":", "int", ",", "max_len", ":", "int", ")", ":", "\n", "    ", "s_len", "=", "seq", ".", "size", "(", "0", ")", "\n", "if", "s_len", ">", "max_len", ":", "\n", "        ", "return", "seq", "[", "0", ":", "max_len", "]", "\n", "", "return", "torch", ".", "cat", "(", "[", "seq", ",", "torch", ".", "Tensor", "(", ")", ".", "new_full", "(", "(", "max_len", "-", "s_len", ",", ")", ",", "pad_id", ",", "dtype", "=", "torch", ".", "long", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._get_answer_spans": [[162, 165], ["None"], "function", ["None"], ["", "def", "_get_answer_spans", "(", "idx", ",", "positives", ":", "List", "[", "ReaderPassage", "]", ",", "max_len", ":", "int", ")", ":", "\n", "    ", "positive_a_spans", "=", "positives", "[", "idx", "]", ".", "answers_spans", "\n", "return", "[", "span", "for", "span", "in", "positive_a_spans", "if", "(", "span", "[", "0", "]", "<", "max_len", "and", "span", "[", "1", "]", "<", "max_len", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._get_positive_idx": [[166, 175], ["numpy.random.choice", "reader._get_answer_spans", "next", "len", "range", "reader._get_answer_spans", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._get_answer_spans", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._get_answer_spans"], ["", "def", "_get_positive_idx", "(", "positives", ":", "List", "[", "ReaderPassage", "]", ",", "max_len", ":", "int", ",", "is_random", ":", "bool", ")", ":", "\n", "# select just one positive", "\n", "    ", "positive_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "positives", ")", ")", "if", "is_random", "else", "0", "\n", "\n", "if", "not", "_get_answer_spans", "(", "positive_idx", ",", "positives", ",", "max_len", ")", ":", "\n", "# question may be too long, find the first positive with at least one valid span", "\n", "        ", "positive_idx", "=", "next", "(", "(", "i", "for", "i", "in", "range", "(", "len", "(", "positives", ")", ")", "if", "_get_answer_spans", "(", "i", ",", "positives", ",", "max_len", ")", ")", ",", "\n", "None", ")", "\n", "", "return", "positive_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._create_question_passages_tensors": [[176, 229], ["empty_ids.size", "len", "torch.stack", "torch.stack", "reader._get_positive_idx", "all", "all", "reader._pad_to_len", "torch.zeros().long", "torch.zeros().long", "torch.tensor", "torch.tensor", "torch.zeros().long", "torch.zeros().long", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "numpy.random.permutation", "range", "reader._pad_to_len", "len", "negatives_selected.append", "reader._get_answer_spans", "range", "empty_ids.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "len", "len", "len", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._get_positive_idx", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._pad_to_len", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._pad_to_len", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.reader._get_answer_spans"], ["", "def", "_create_question_passages_tensors", "(", "positives", ":", "List", "[", "ReaderPassage", "]", ",", "negatives", ":", "List", "[", "ReaderPassage", "]", ",", "total_size", ":", "int", ",", "\n", "empty_ids", ":", "T", ",", "\n", "max_n_answers", ":", "int", ",", "\n", "pad_token_id", ":", "int", ",", "\n", "is_train", ":", "bool", ",", "\n", "is_random", ":", "bool", "=", "True", ")", ":", "\n", "    ", "max_len", "=", "empty_ids", ".", "size", "(", "0", ")", "\n", "if", "is_train", ":", "\n", "# select just one positive", "\n", "        ", "positive_idx", "=", "_get_positive_idx", "(", "positives", ",", "max_len", ",", "is_random", ")", "\n", "if", "positive_idx", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "positive_a_spans", "=", "_get_answer_spans", "(", "positive_idx", ",", "positives", ",", "max_len", ")", "[", "0", ":", "max_n_answers", "]", "\n", "\n", "answer_starts", "=", "[", "span", "[", "0", "]", "for", "span", "in", "positive_a_spans", "]", "\n", "answer_ends", "=", "[", "span", "[", "1", "]", "for", "span", "in", "positive_a_spans", "]", "\n", "\n", "assert", "all", "(", "s", "<", "max_len", "for", "s", "in", "answer_starts", ")", "\n", "assert", "all", "(", "e", "<", "max_len", "for", "e", "in", "answer_ends", ")", "\n", "\n", "positive_input_ids", "=", "_pad_to_len", "(", "positives", "[", "positive_idx", "]", ".", "sequence_ids", ",", "pad_token_id", ",", "max_len", ")", "\n", "\n", "answer_starts_tensor", "=", "torch", ".", "zeros", "(", "(", "total_size", ",", "max_n_answers", ")", ")", ".", "long", "(", ")", "\n", "answer_starts_tensor", "[", "0", ",", "0", ":", "len", "(", "answer_starts", ")", "]", "=", "torch", ".", "tensor", "(", "answer_starts", ")", "\n", "\n", "answer_ends_tensor", "=", "torch", ".", "zeros", "(", "(", "total_size", ",", "max_n_answers", ")", ")", ".", "long", "(", ")", "\n", "answer_ends_tensor", "[", "0", ",", "0", ":", "len", "(", "answer_ends", ")", "]", "=", "torch", ".", "tensor", "(", "answer_ends", ")", "\n", "\n", "answer_mask", "=", "torch", ".", "zeros", "(", "(", "total_size", ",", "max_n_answers", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "answer_mask", "[", "0", ",", "0", ":", "len", "(", "answer_starts", ")", "]", "=", "torch", ".", "tensor", "(", "[", "1", "for", "_", "in", "range", "(", "len", "(", "answer_starts", ")", ")", "]", ")", "\n", "\n", "positives_selected", "=", "[", "positive_input_ids", "]", "\n", "\n", "", "else", ":", "\n", "        ", "positives_selected", "=", "[", "]", "\n", "answer_starts_tensor", "=", "None", "\n", "answer_ends_tensor", "=", "None", "\n", "answer_mask", "=", "None", "\n", "\n", "", "positives_num", "=", "len", "(", "positives_selected", ")", "\n", "negative_idxs", "=", "np", ".", "random", ".", "permutation", "(", "range", "(", "len", "(", "negatives", ")", ")", ")", "if", "is_random", "else", "range", "(", "\n", "len", "(", "negatives", ")", "-", "positives_num", ")", "\n", "\n", "negative_idxs", "=", "negative_idxs", "[", ":", "total_size", "-", "positives_num", "]", "\n", "\n", "negatives_selected", "=", "[", "_pad_to_len", "(", "negatives", "[", "i", "]", ".", "sequence_ids", ",", "pad_token_id", ",", "max_len", ")", "for", "i", "in", "negative_idxs", "]", "\n", "\n", "while", "len", "(", "negatives_selected", ")", "<", "total_size", "-", "positives_num", ":", "\n", "        ", "negatives_selected", ".", "append", "(", "empty_ids", ".", "clone", "(", ")", ")", "\n", "\n", "", "input_ids", "=", "torch", ".", "stack", "(", "[", "t", "for", "t", "in", "positives_selected", "+", "negatives_selected", "]", ",", "dim", "=", "0", ")", "\n", "return", "input_ids", ",", "answer_starts_tensor", ",", "answer_ends_tensor", ",", "answer_mask", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.calculate_matches": [[28, 72], ["dpr.utils.tokenizers.SimpleTokenizer", "multiprocessing.Pool", "logger.info", "functools.partial", "zip", "multiprocessing.Pool.map", "logger.info", "len", "QAMatchStats", "len", "next", "enumerate"], "function", ["None"], ["def", "calculate_matches", "(", "all_docs", ":", "Dict", "[", "object", ",", "Tuple", "[", "str", ",", "str", "]", "]", ",", "answers", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "closest_docs", ":", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ",", "workers_num", ":", "int", ",", "\n", "match_type", ":", "str", ")", "->", "QAMatchStats", ":", "\n", "    ", "\"\"\"\n    Evaluates answers presence in the set of documents. This function is supposed to be used with a large collection of\n    documents and results. It internally forks multiple sub-processes for evaluation and then merges results\n    :param all_docs: dictionary of the entire documents database. doc_id -> (doc_text, title)\n    :param answers: list of answers's list. One list per question\n    :param closest_docs: document ids of the top results along with their scores\n    :param workers_num: amount of parallel threads to process data\n    :param match_type: type of answer matching. Refer to has_answer code for available options\n    :return: matching information tuple.\n    top_k_hits - a list where the index is the amount of top documents retrieved and the value is the total amount of\n    valid matches across an entire dataset.\n    questions_doc_hits - more detailed info with answer matches for every question and every retrieved document\n    \"\"\"", "\n", "global", "dpr_all_documents", "\n", "dpr_all_documents", "=", "all_docs", "\n", "\n", "tok_opts", "=", "{", "}", "\n", "tokenizer", "=", "SimpleTokenizer", "(", "**", "tok_opts", ")", "\n", "\n", "processes", "=", "ProcessPool", "(", "\n", "processes", "=", "workers_num", ",", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "'Matching answers in top docs...'", ")", "\n", "\n", "get_score_partial", "=", "partial", "(", "check_answer", ",", "match_type", "=", "match_type", ",", "tokenizer", "=", "tokenizer", ")", "\n", "\n", "questions_answers_docs", "=", "zip", "(", "answers", ",", "closest_docs", ")", "\n", "\n", "scores", "=", "processes", ".", "map", "(", "get_score_partial", ",", "questions_answers_docs", ")", "\n", "\n", "logger", ".", "info", "(", "'Per question validation results len=%d'", ",", "len", "(", "scores", ")", ")", "\n", "\n", "n_docs", "=", "len", "(", "closest_docs", "[", "0", "]", "[", "0", "]", ")", "\n", "top_k_hits", "=", "[", "0", "]", "*", "n_docs", "\n", "for", "question_hits", "in", "scores", ":", "\n", "        ", "best_hit", "=", "next", "(", "(", "i", "for", "i", ",", "x", "in", "enumerate", "(", "question_hits", ")", "if", "x", ")", ",", "None", ")", "\n", "if", "best_hit", "is", "not", "None", ":", "\n", "            ", "top_k_hits", "[", "best_hit", ":", "]", "=", "[", "v", "+", "1", "for", "v", "in", "top_k_hits", "[", "best_hit", ":", "]", "]", "\n", "\n", "", "", "return", "QAMatchStats", "(", "top_k_hits", ",", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.check_answer": [[73, 94], ["enumerate", "qa_validation.has_answer", "hits.append", "logger.warning", "hits.append"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.has_answer"], ["", "def", "check_answer", "(", "questions_answers_docs", ",", "tokenizer", ",", "match_type", ")", "->", "List", "[", "bool", "]", ":", "\n", "    ", "\"\"\"Search through all the top docs to see if they have any of the answers.\"\"\"", "\n", "answers", ",", "(", "doc_ids", ",", "doc_scores", ")", "=", "questions_answers_docs", "\n", "\n", "global", "dpr_all_documents", "\n", "hits", "=", "[", "]", "\n", "\n", "for", "i", ",", "doc_id", "in", "enumerate", "(", "doc_ids", ")", ":", "\n", "        ", "doc", "=", "dpr_all_documents", "[", "doc_id", "]", "\n", "text", "=", "doc", "[", "0", "]", "\n", "\n", "answer_found", "=", "False", "\n", "if", "text", "is", "None", ":", "# cannot find the document for some reason", "\n", "            ", "logger", ".", "warning", "(", "\"no doc in db\"", ")", "\n", "hits", ".", "append", "(", "False", ")", "\n", "continue", "\n", "\n", "", "if", "has_answer", "(", "answers", ",", "text", ",", "tokenizer", ",", "match_type", ")", ":", "\n", "            ", "answer_found", "=", "True", "\n", "", "hits", ".", "append", "(", "answer_found", ")", "\n", "", "return", "hits", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.has_answer": [[95, 122], ["qa_validation._normalize", "tokenizer.tokenize().words", "qa_validation._normalize", "tokenizer.tokenize", "_normalize.words", "range", "tokenizer.tokenize", "qa_validation._normalize", "qa_validation.regex_match", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation._normalize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.words", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation._normalize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.Tokens.words", "home.repos.pwc.inspect_result.dreasysnail_RetGen.utils.tokenizers.SpacyTokenizer.tokenize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation._normalize", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.regex_match"], ["", "def", "has_answer", "(", "answers", ",", "text", ",", "tokenizer", ",", "match_type", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Check if a document contains an answer string.\n    If `match_type` is string, token matching is done between the text and answer.\n    If `match_type` is regex, we search the whole text with the regex.\n    \"\"\"", "\n", "text", "=", "_normalize", "(", "text", ")", "\n", "\n", "if", "match_type", "==", "'string'", ":", "\n", "# Answer is a list of possible strings", "\n", "        ", "text", "=", "tokenizer", ".", "tokenize", "(", "text", ")", ".", "words", "(", "uncased", "=", "True", ")", "\n", "\n", "for", "single_answer", "in", "answers", ":", "\n", "            ", "single_answer", "=", "_normalize", "(", "single_answer", ")", "\n", "single_answer", "=", "tokenizer", ".", "tokenize", "(", "single_answer", ")", "\n", "single_answer", "=", "single_answer", ".", "words", "(", "uncased", "=", "True", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "text", ")", "-", "len", "(", "single_answer", ")", "+", "1", ")", ":", "\n", "                ", "if", "single_answer", "==", "text", "[", "i", ":", "i", "+", "len", "(", "single_answer", ")", "]", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "", "elif", "match_type", "==", "'regex'", ":", "\n", "# Answer is a regex", "\n", "        ", "for", "single_answer", "in", "answers", ":", "\n", "            ", "single_answer", "=", "_normalize", "(", "single_answer", ")", "\n", "if", "regex_match", "(", "text", ",", "single_answer", ")", ":", "\n", "                ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.regex_match": [[123, 133], ["regex.compile", "re.compile.search"], "function", ["None"], ["", "def", "regex_match", "(", "text", ",", "pattern", ")", ":", "\n", "    ", "\"\"\"Test if a regex pattern is contained within a text.\"\"\"", "\n", "try", ":", "\n", "        ", "pattern", "=", "re", ".", "compile", "(", "\n", "pattern", ",", "\n", "flags", "=", "re", ".", "IGNORECASE", "+", "re", ".", "UNICODE", "+", "re", ".", "MULTILINE", ",", "\n", ")", "\n", "", "except", "BaseException", ":", "\n", "        ", "return", "False", "\n", "", "return", "pattern", ".", "search", "(", "text", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation.exact_match_score": [[135, 137], ["qa_validation._normalize_answer", "qa_validation._normalize_answer"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation._normalize_answer", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation._normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "_normalize_answer", "(", "prediction", ")", "==", "_normalize_answer", "(", "ground_truth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation._normalize_answer": [[138, 153], ["qa_validation._normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "_normalize_answer", "(", "s", ")", ":", "\n", "    ", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.qa_validation._normalize": [[154, 156], ["unicodedata.normalize"], "function", ["None"], ["", "def", "_normalize", "(", "text", ")", ":", "\n", "    ", "return", "unicodedata", ".", "normalize", "(", "'NFD'", ",", "text", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderPassage.__init__": [[34, 48], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "id", "=", "None", ",", "text", ":", "str", "=", "None", ",", "title", ":", "str", "=", "None", ",", "score", "=", "None", ",", "\n", "has_answer", ":", "bool", "=", "None", ")", ":", "\n", "        ", "self", ".", "id", "=", "id", "\n", "# string passage representations", "\n", "self", ".", "passage_text", "=", "text", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "score", "=", "score", "\n", "self", ".", "has_answer", "=", "has_answer", "\n", "self", ".", "passage_token_ids", "=", "None", "\n", "# offset of the actual passage (i.e. not a question or may be title) in the sequence_ids", "\n", "self", ".", "passage_offset", "=", "None", "\n", "self", ".", "answers_spans", "=", "None", "\n", "# passage token ids", "\n", "self", ".", "sequence_ids", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderPassage.on_serialize": [[49, 55], ["reader_data.ReaderPassage.sequence_ids.numpy"], "methods", ["None"], ["", "def", "on_serialize", "(", "self", ")", ":", "\n", "# store only final sequence_ids and the ctx offset", "\n", "        ", "self", ".", "sequence_ids", "=", "self", ".", "sequence_ids", ".", "numpy", "(", ")", "\n", "self", ".", "passage_text", "=", "None", "\n", "self", ".", "title", "=", "None", "\n", "self", ".", "passage_token_ids", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderPassage.on_deserialize": [[56, 58], ["torch.tensor"], "methods", ["None"], ["", "def", "on_deserialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "sequence_ids", "=", "torch", ".", "tensor", "(", "self", ".", "sequence_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderSample.__init__": [[64, 73], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "question", ":", "str", ",", "answers", ":", "List", ",", "positive_passages", ":", "List", "[", "ReaderPassage", "]", "=", "[", "]", ",", "\n", "negative_passages", ":", "List", "[", "ReaderPassage", "]", "=", "[", "]", ",", "\n", "passages", ":", "List", "[", "ReaderPassage", "]", "=", "[", "]", ",", "\n", ")", ":", "\n", "        ", "self", ".", "question", "=", "question", "\n", "self", ".", "answers", "=", "answers", "\n", "self", ".", "positive_passages", "=", "positive_passages", "\n", "self", ".", "negative_passages", "=", "negative_passages", "\n", "self", ".", "passages", "=", "passages", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderSample.on_serialize": [[74, 77], ["passage.on_serialize"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderSample.on_serialize"], ["", "def", "on_serialize", "(", "self", ")", ":", "\n", "        ", "for", "passage", "in", "self", ".", "passages", "+", "self", ".", "positive_passages", "+", "self", ".", "negative_passages", ":", "\n", "            ", "passage", ".", "on_serialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderSample.on_deserialize": [[78, 81], ["passage.on_deserialize"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderSample.on_deserialize"], ["", "", "def", "on_deserialize", "(", "self", ")", ":", "\n", "        ", "for", "passage", "in", "self", ".", "passages", "+", "self", ".", "positive_passages", "+", "self", ".", "negative_passages", ":", "\n", "            ", "passage", ".", "on_deserialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.preprocess_retriever_data": [[99, 170], ["tensorizer.get_pair_separator_ids", "logger.info", "logger.info", "reader_data._get_gold_ctx_dict", "tensorizer.text_to_tensor", "reader_data._concat_pair", "reader_data._select_reader_passages", "next", "tensorizer.text_to_tensor", "reader_data.preprocess_retriever_data.create_reader_sample_ids"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.get_pair_separator_ids", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._get_gold_ctx_dict", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._concat_pair", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._select_reader_passages", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor"], ["def", "preprocess_retriever_data", "(", "samples", ":", "List", "[", "Dict", "]", ",", "gold_info_file", ":", "Optional", "[", "str", "]", ",", "tensorizer", ":", "Tensorizer", ",", "\n", "cfg", ":", "ReaderPreprocessingCfg", "=", "DEFAULT_PREPROCESSING_CFG_TRAIN", ",", "\n", "is_train_set", ":", "bool", "=", "True", ",", "\n", ")", "->", "Iterable", "[", "ReaderSample", "]", ":", "\n", "    ", "\"\"\"\n    Converts retriever results into reader training data.\n    :param samples: samples from the retriever's json file results\n    :param gold_info_file: optional path for the 'gold passages & questions' file. Required to get best results for NQ\n    :param tensorizer: Tensorizer object for text to model input tensors conversions\n    :param cfg: ReaderPreprocessingCfg object with positive and negative passage selection parameters\n    :param is_train_set: if the data should be processed as a train set\n    :return: iterable of ReaderSample objects which can be consumed by the reader model\n    \"\"\"", "\n", "sep_tensor", "=", "tensorizer", ".", "get_pair_separator_ids", "(", ")", "# separator can be a multi token", "\n", "\n", "gold_passage_map", ",", "canonical_questions", "=", "_get_gold_ctx_dict", "(", "gold_info_file", ")", "if", "gold_info_file", "else", "(", "{", "}", ",", "{", "}", ")", "\n", "\n", "no_positive_passages", "=", "0", "\n", "positives_from_gold", "=", "0", "\n", "\n", "def", "create_reader_sample_ids", "(", "sample", ":", "ReaderPassage", ",", "question", ":", "str", ")", ":", "\n", "        ", "question_and_title", "=", "tensorizer", ".", "text_to_tensor", "(", "sample", ".", "title", ",", "title", "=", "question", ",", "add_special_tokens", "=", "True", ")", "\n", "if", "sample", ".", "passage_token_ids", "is", "None", ":", "\n", "            ", "sample", ".", "passage_token_ids", "=", "tensorizer", ".", "text_to_tensor", "(", "sample", ".", "passage_text", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "all_concatenated", ",", "shift", "=", "_concat_pair", "(", "question_and_title", ",", "sample", ".", "passage_token_ids", ",", "\n", "tailing_sep", "=", "sep_tensor", "if", "cfg", ".", "use_tailing_sep", "else", "None", ")", "\n", "\n", "sample", ".", "sequence_ids", "=", "all_concatenated", "\n", "sample", ".", "passage_offset", "=", "shift", "\n", "assert", "shift", ">", "1", "\n", "if", "sample", ".", "has_answer", "and", "is_train_set", ":", "\n", "            ", "sample", ".", "answers_spans", "=", "[", "(", "span", "[", "0", "]", "+", "shift", ",", "span", "[", "1", "]", "+", "shift", ")", "for", "span", "in", "sample", ".", "answers_spans", "]", "\n", "", "return", "sample", "\n", "\n", "", "for", "sample", "in", "samples", ":", "\n", "        ", "question", "=", "sample", "[", "'question'", "]", "\n", "\n", "if", "question", "in", "canonical_questions", ":", "\n", "            ", "question", "=", "canonical_questions", "[", "question", "]", "\n", "\n", "", "positive_passages", ",", "negative_passages", "=", "_select_reader_passages", "(", "sample", ",", "question", ",", "\n", "tensorizer", ",", "\n", "gold_passage_map", ",", "\n", "cfg", ".", "gold_page_only_positives", ",", "\n", "cfg", ".", "max_positives", ",", "cfg", ".", "max_negatives", ",", "\n", "cfg", ".", "min_negatives", ",", "\n", "cfg", ".", "max_retriever_passages", ",", "\n", "cfg", ".", "include_gold_passage", ",", "\n", "is_train_set", ",", "\n", ")", "\n", "# create concatenated sequence ids for each passage and adjust answer spans", "\n", "positive_passages", "=", "[", "create_reader_sample_ids", "(", "s", ",", "question", ")", "for", "s", "in", "positive_passages", "]", "\n", "negative_passages", "=", "[", "create_reader_sample_ids", "(", "s", ",", "question", ")", "for", "s", "in", "negative_passages", "]", "\n", "\n", "if", "is_train_set", "and", "len", "(", "positive_passages", ")", "==", "0", ":", "\n", "            ", "no_positive_passages", "+=", "1", "\n", "if", "cfg", ".", "skip_no_positves", ":", "\n", "                ", "continue", "\n", "\n", "", "", "if", "next", "(", "iter", "(", "ctx", "for", "ctx", "in", "positive_passages", "if", "ctx", ".", "score", "==", "-", "1", ")", ",", "None", ")", ":", "\n", "            ", "positives_from_gold", "+=", "1", "\n", "\n", "", "if", "is_train_set", ":", "\n", "            ", "yield", "ReaderSample", "(", "question", ",", "sample", "[", "'answers'", "]", ",", "positive_passages", "=", "positive_passages", ",", "\n", "negative_passages", "=", "negative_passages", ")", "\n", "", "else", ":", "\n", "            ", "yield", "ReaderSample", "(", "question", ",", "sample", "[", "'answers'", "]", ",", "passages", "=", "negative_passages", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "'no positive passages samples: %d'", ",", "no_positive_passages", ")", "\n", "logger", ".", "info", "(", "'positive passages from gold samples: %d'", ",", "positives_from_gold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.convert_retriever_results": [[171, 211], ["logger.info", "multiprocessing.Pool", "len", "max", "logger.info", "functools.partial", "multiprocessing.Pool.map", "logger.info", "open", "json.loads", "len", "math.ceil", "len", "serialized_files.append", "logger.info", "logger.info", "range", "range", "f.readlines", "len"], "function", ["None"], ["", "def", "convert_retriever_results", "(", "is_train_set", ":", "bool", ",", "input_file", ":", "str", ",", "out_file_prefix", ":", "str", ",", "\n", "gold_passages_file", ":", "str", ",", "\n", "tensorizer", ":", "Tensorizer", ",", "\n", "num_workers", ":", "int", "=", "8", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Converts the file with dense retriever(or any compatible file format) results into the reader input data and\n    serializes them into a set of files.\n    Conversion splits the input data into multiple chunks and processes them in parallel. Each chunk results are stored\n    in a separate file with name out_file_prefix.{number}.pkl\n    :param is_train_set: if the data should be processed for a train set (i.e. with answer span detection)\n    :param input_file: path to a json file with data to convert\n    :param out_file_prefix: output path prefix.\n    :param gold_passages_file: optional path for the 'gold passages & questions' file. Required to get best results for NQ\n    :param tensorizer: Tensorizer object for text to model input tensors conversions\n    :param num_workers: the number of parallel processes for conversion\n    :return: names of files with serialized results\n    \"\"\"", "\n", "with", "open", "(", "input_file", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "samples", "=", "json", ".", "loads", "(", "\"\"", ".", "join", "(", "f", ".", "readlines", "(", ")", ")", ")", "\n", "", "logger", ".", "info", "(", "\"Loaded %d questions + retrieval results from %s\"", ",", "len", "(", "samples", ")", ",", "input_file", ")", "\n", "workers", "=", "multiprocessing", ".", "Pool", "(", "num_workers", ")", "\n", "ds_size", "=", "len", "(", "samples", ")", "\n", "step", "=", "max", "(", "math", ".", "ceil", "(", "ds_size", "/", "num_workers", ")", ",", "1", ")", "\n", "chunks", "=", "[", "samples", "[", "i", ":", "i", "+", "step", "]", "for", "i", "in", "range", "(", "0", ",", "ds_size", ",", "step", ")", "]", "\n", "chunks", "=", "[", "(", "i", ",", "chunks", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "chunks", ")", ")", "]", "\n", "\n", "logger", ".", "info", "(", "\"Split data into %d chunks\"", ",", "len", "(", "chunks", ")", ")", "\n", "\n", "processed", "=", "0", "\n", "_parse_batch", "=", "partial", "(", "_preprocess_reader_samples_chunk", ",", "out_file_prefix", "=", "out_file_prefix", ",", "\n", "gold_passages_file", "=", "gold_passages_file", ",", "tensorizer", "=", "tensorizer", ",", "\n", "is_train_set", "=", "is_train_set", ")", "\n", "serialized_files", "=", "[", "]", "\n", "for", "file_name", "in", "workers", ".", "map", "(", "_parse_batch", ",", "chunks", ")", ":", "\n", "        ", "processed", "+=", "1", "\n", "serialized_files", ".", "append", "(", "file_name", ")", "\n", "logger", ".", "info", "(", "'Chunks processed %d'", ",", "processed", ")", "\n", "logger", ".", "info", "(", "'Data saved to %s'", ",", "file_name", ")", "\n", "", "logger", ".", "info", "(", "'Preprocessed data stored in %s'", ",", "serialized_files", ")", "\n", "return", "serialized_files", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.get_best_spans": [[212, 248], ["enumerate", "sorted", "enumerate", "any", "reader_data._extend_span_to_full_words", "tensorizer.to_string", "best_spans.append", "chosen_span_intervals.append", "sorted.append", "SpanPrediction", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._extend_span_to_full_words", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.to_string"], ["", "def", "get_best_spans", "(", "tensorizer", ":", "Tensorizer", ",", "start_logits", ":", "List", ",", "end_logits", ":", "List", ",", "ctx_ids", ":", "List", ",", "max_answer_length", ":", "int", ",", "\n", "passage_idx", ":", "int", ",", "relevance_score", ":", "float", ",", "top_spans", ":", "int", "=", "1", ")", "->", "List", "[", "SpanPrediction", "]", ":", "\n", "    ", "\"\"\"\n    Finds the best answer span for the extractive Q&A model\n    \"\"\"", "\n", "scores", "=", "[", "]", "\n", "for", "(", "i", ",", "s", ")", "in", "enumerate", "(", "start_logits", ")", ":", "\n", "        ", "for", "(", "j", ",", "e", ")", "in", "enumerate", "(", "end_logits", "[", "i", ":", "i", "+", "max_answer_length", "]", ")", ":", "\n", "            ", "scores", ".", "append", "(", "(", "(", "i", ",", "i", "+", "j", ")", ",", "s", "+", "e", ")", ")", "\n", "\n", "", "", "scores", "=", "sorted", "(", "scores", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "chosen_span_intervals", "=", "[", "]", "\n", "best_spans", "=", "[", "]", "\n", "\n", "for", "(", "start_index", ",", "end_index", ")", ",", "score", "in", "scores", ":", "\n", "        ", "assert", "start_index", "<=", "end_index", "\n", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "assert", "length", "<=", "max_answer_length", "\n", "\n", "if", "any", "(", "[", "start_index", "<=", "prev_start_index", "<=", "prev_end_index", "<=", "end_index", "or", "\n", "prev_start_index", "<=", "start_index", "<=", "end_index", "<=", "prev_end_index", "\n", "for", "(", "prev_start_index", ",", "prev_end_index", ")", "in", "chosen_span_intervals", "]", ")", ":", "\n", "            ", "continue", "\n", "\n", "# extend bpe subtokens to full tokens", "\n", "", "start_index", ",", "end_index", "=", "_extend_span_to_full_words", "(", "tensorizer", ",", "ctx_ids", ",", "\n", "(", "start_index", ",", "end_index", ")", ")", "\n", "\n", "predicted_answer", "=", "tensorizer", ".", "to_string", "(", "ctx_ids", "[", "start_index", ":", "end_index", "+", "1", "]", ")", "\n", "best_spans", ".", "append", "(", "SpanPrediction", "(", "predicted_answer", ",", "score", ",", "relevance_score", ",", "passage_idx", ",", "ctx_ids", ")", ")", "\n", "chosen_span_intervals", ".", "append", "(", "(", "start_index", ",", "end_index", ")", ")", "\n", "\n", "if", "len", "(", "chosen_span_intervals", ")", "==", "top_spans", ":", "\n", "            ", "break", "\n", "", "", "return", "best_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._select_reader_passages": [[249, 322], ["list", "tensorizer.text_to_tensor", "list", "list", "list", "filter", "next", "min", "reader_data.ReaderPassage", "filter", "filter", "filter", "list", "bool", "list", "iter", "reader_data._select_reader_passages.find_answer_spans"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.text_to_tensor"], ["", "def", "_select_reader_passages", "(", "sample", ":", "Dict", ",", "\n", "question", ":", "str", ",", "\n", "tensorizer", ":", "Tensorizer", ",", "gold_passage_map", ":", "Dict", "[", "str", ",", "ReaderPassage", "]", ",", "\n", "gold_page_only_positives", ":", "bool", ",", "\n", "max_positives", ":", "int", ",", "\n", "max1_negatives", ":", "int", ",", "\n", "max2_negatives", ":", "int", ",", "\n", "max_retriever_passages", ":", "int", ",", "\n", "include_gold_passage", ":", "bool", ",", "\n", "is_train_set", ":", "bool", "\n", ")", "->", "Tuple", "[", "List", "[", "ReaderPassage", "]", ",", "List", "[", "ReaderPassage", "]", "]", ":", "\n", "    ", "answers", "=", "sample", "[", "'answers'", "]", "\n", "\n", "ctxs", "=", "[", "ReaderPassage", "(", "**", "ctx", ")", "for", "ctx", "in", "sample", "[", "'ctxs'", "]", "]", "[", "0", ":", "max_retriever_passages", "]", "\n", "answers_token_ids", "=", "[", "tensorizer", ".", "text_to_tensor", "(", "a", ",", "add_special_tokens", "=", "False", ")", "for", "a", "in", "answers", "]", "\n", "\n", "if", "is_train_set", ":", "\n", "        ", "positive_samples", "=", "list", "(", "filter", "(", "lambda", "ctx", ":", "ctx", ".", "has_answer", ",", "ctxs", ")", ")", "\n", "negative_samples", "=", "list", "(", "filter", "(", "lambda", "ctx", ":", "not", "ctx", ".", "has_answer", ",", "ctxs", ")", ")", "\n", "", "else", ":", "\n", "        ", "positive_samples", "=", "[", "]", "\n", "negative_samples", "=", "ctxs", "\n", "\n", "", "positive_ctxs_from_gold_page", "=", "list", "(", "\n", "filter", "(", "lambda", "ctx", ":", "_is_from_gold_wiki_page", "(", "gold_passage_map", ",", "ctx", ".", "title", ",", "question", ")", ",", "\n", "positive_samples", ")", ")", "if", "gold_page_only_positives", "else", "[", "]", "\n", "\n", "def", "find_answer_spans", "(", "ctx", ":", "ReaderPassage", ")", ":", "\n", "        ", "if", "ctx", ".", "has_answer", ":", "\n", "            ", "if", "ctx", ".", "passage_token_ids", "is", "None", ":", "\n", "                ", "ctx", ".", "passage_token_ids", "=", "tensorizer", ".", "text_to_tensor", "(", "ctx", ".", "passage_text", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "answer_spans", "=", "[", "_find_answer_positions", "(", "ctx", ".", "passage_token_ids", ",", "answers_token_ids", "[", "i", "]", ")", "for", "i", "in", "\n", "range", "(", "len", "(", "answers", ")", ")", "]", "\n", "\n", "# flatten spans list", "\n", "answer_spans", "=", "[", "item", "for", "sublist", "in", "answer_spans", "for", "item", "in", "sublist", "]", "\n", "answers_spans", "=", "list", "(", "filter", "(", "None", ",", "answer_spans", ")", ")", "\n", "ctx", ".", "answers_spans", "=", "answers_spans", "\n", "\n", "if", "not", "answers_spans", ":", "\n", "                ", "logger", ".", "warning", "(", "'No answer found in passage id=%s text=%s, answers=%s, question=%s'", ",", "ctx", ".", "id", ",", "\n", "ctx", ".", "passage_text", ",", "\n", "answers", ",", "question", ")", "\n", "\n", "", "ctx", ".", "has_answer", "=", "bool", "(", "answers_spans", ")", "\n", "\n", "", "return", "ctx", "\n", "\n", "# check if any of the selected ctx+ has answer spans", "\n", "", "selected_positive_ctxs", "=", "list", "(", "\n", "filter", "(", "lambda", "ctx", ":", "ctx", ".", "has_answer", ",", "[", "find_answer_spans", "(", "ctx", ")", "for", "ctx", "in", "positive_ctxs_from_gold_page", "]", ")", ")", "\n", "\n", "if", "not", "selected_positive_ctxs", ":", "# fallback to positive ctx not from gold pages", "\n", "        ", "selected_positive_ctxs", "=", "list", "(", "\n", "filter", "(", "lambda", "ctx", ":", "ctx", ".", "has_answer", ",", "[", "find_answer_spans", "(", "ctx", ")", "for", "ctx", "in", "positive_samples", "]", ")", "\n", ")", "[", "0", ":", "max_positives", "]", "\n", "\n", "# optionally include gold passage itself if it is still not in the positives list", "\n", "", "if", "include_gold_passage", "and", "question", "in", "gold_passage_map", ":", "\n", "        ", "gold_passage", "=", "gold_passage_map", "[", "question", "]", "\n", "included_gold_passage", "=", "next", "(", "iter", "(", "ctx", "for", "ctx", "in", "selected_positive_ctxs", "if", "ctx", ".", "id", "==", "gold_passage", ".", "id", ")", ",", "None", ")", "\n", "if", "not", "included_gold_passage", ":", "\n", "            ", "gold_passage", "=", "find_answer_spans", "(", "gold_passage", ")", "\n", "if", "not", "gold_passage", ".", "has_answer", ":", "\n", "                ", "logger", ".", "warning", "(", "'No answer found in gold passage %s'", ",", "gold_passage", ")", "\n", "", "else", ":", "\n", "                ", "selected_positive_ctxs", ".", "append", "(", "gold_passage", ")", "\n", "\n", "", "", "", "max_negatives", "=", "min", "(", "max", "(", "10", "*", "len", "(", "selected_positive_ctxs", ")", ",", "max1_negatives", ")", ",", "\n", "max2_negatives", ")", "if", "is_train_set", "else", "DEFAULT_EVAL_PASSAGES", "\n", "negative_samples", "=", "negative_samples", "[", "0", ":", "max_negatives", "]", "\n", "return", "selected_positive_ctxs", ",", "negative_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._find_answer_positions": [[323, 331], ["ctx_ids.size", "answer.size", "range", "answer_occurences.append"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_find_answer_positions", "(", "ctx_ids", ":", "T", ",", "answer", ":", "T", ")", "->", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ":", "\n", "    ", "c_len", "=", "ctx_ids", ".", "size", "(", "0", ")", "\n", "a_len", "=", "answer", ".", "size", "(", "0", ")", "\n", "answer_occurences", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "c_len", "-", "a_len", "+", "1", ")", ":", "\n", "        ", "if", "(", "answer", "==", "ctx_ids", "[", "i", ":", "i", "+", "a_len", "]", ")", ".", "all", "(", ")", ":", "\n", "            ", "answer_occurences", ".", "append", "(", "(", "i", ",", "i", "+", "a_len", "-", "1", ")", ")", "\n", "", "", "return", "answer_occurences", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._concat_pair": [[332, 336], ["torch.cat", "t1.size", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.cider.cider_scorer.CiderScorer.size"], ["", "def", "_concat_pair", "(", "t1", ":", "T", ",", "t2", ":", "T", ",", "middle_sep", ":", "T", "=", "None", ",", "tailing_sep", ":", "T", "=", "None", ")", ":", "\n", "    ", "middle", "=", "(", "[", "middle_sep", "]", "if", "middle_sep", "else", "[", "]", ")", "\n", "r", "=", "[", "t1", "]", "+", "middle", "+", "[", "t2", "]", "+", "(", "[", "tailing_sep", "]", "if", "tailing_sep", "else", "[", "]", ")", "\n", "return", "torch", ".", "cat", "(", "r", ",", "dim", "=", "0", ")", ",", "t1", ".", "size", "(", "0", ")", "+", "len", "(", "middle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._get_gold_ctx_dict": [[337, 368], ["open", "logger.info", "sample[].lower", "reader_data.ReaderPassage", "json.load", "logger.info", "logger.info", "logger.info", "logger.info"], "function", ["None"], ["", "def", "_get_gold_ctx_dict", "(", "file", ":", "str", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "ReaderPassage", "]", ",", "Dict", "[", "str", ",", "str", "]", "]", ":", "\n", "    ", "gold_passage_infos", "=", "{", "}", "# question|question_tokens -> ReaderPassage (with title and gold ctx)", "\n", "\n", "# original NQ dataset has 2 forms of same question - original, and tokenized.", "\n", "# Tokenized form is not fully consisted with the original question if tokenized by some encoder tokenizers", "\n", "# Specifically, this is the case for the BERT tokenizer.", "\n", "# Depending of which form was used for retriever training and results generation, it may be useful to convert", "\n", "# all questions to the canonical original representation.", "\n", "original_questions", "=", "{", "}", "# question from tokens -> original question (NQ only)", "\n", "\n", "with", "open", "(", "file", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "logger", ".", "info", "(", "'Reading file %s'", "%", "file", ")", "\n", "data", "=", "json", ".", "load", "(", "f", ")", "[", "'data'", "]", "\n", "\n", "", "for", "sample", "in", "data", ":", "\n", "        ", "question", "=", "sample", "[", "'question'", "]", "\n", "question_from_tokens", "=", "sample", "[", "'question_tokens'", "]", "if", "'question_tokens'", "in", "sample", "else", "question", "\n", "original_questions", "[", "question_from_tokens", "]", "=", "question", "\n", "title", "=", "sample", "[", "'title'", "]", ".", "lower", "(", ")", "\n", "context", "=", "sample", "[", "'context'", "]", "# Note: This one is cased", "\n", "rp", "=", "ReaderPassage", "(", "sample", "[", "'example_id'", "]", ",", "text", "=", "context", ",", "title", "=", "title", ")", "\n", "if", "question", "in", "gold_passage_infos", ":", "\n", "            ", "logger", ".", "info", "(", "'Duplicate question %s'", ",", "question", ")", "\n", "rp_exist", "=", "gold_passage_infos", "[", "question", "]", "\n", "logger", ".", "info", "(", "'Duplicate question gold info: title new =%s | old title=%s'", ",", "title", ",", "rp_exist", ".", "title", ")", "\n", "logger", ".", "info", "(", "'Duplicate question gold info: new ctx =%s '", ",", "context", ")", "\n", "logger", ".", "info", "(", "'Duplicate question gold info: old ctx =%s '", ",", "rp_exist", ".", "passage_text", ")", "\n", "\n", "", "gold_passage_infos", "[", "question", "]", "=", "rp", "\n", "gold_passage_infos", "[", "question_from_tokens", "]", "=", "rp", "\n", "", "return", "gold_passage_infos", ",", "original_questions", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._is_from_gold_wiki_page": [[369, 374], ["gold_passage_map.get", "passage_title.lower", "gold_passage_map.get.title.lower"], "function", ["None"], ["", "def", "_is_from_gold_wiki_page", "(", "gold_passage_map", ":", "Dict", "[", "str", ",", "ReaderPassage", "]", ",", "passage_title", ":", "str", ",", "question", ":", "str", ")", ":", "\n", "    ", "gold_info", "=", "gold_passage_map", ".", "get", "(", "question", ",", "None", ")", "\n", "if", "gold_info", ":", "\n", "        ", "return", "passage_title", ".", "lower", "(", ")", "==", "gold_info", ".", "title", ".", "lower", "(", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._extend_span_to_full_words": [[375, 385], ["len", "tensorizer.is_sub_word_id", "tensorizer.is_sub_word_id"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.is_sub_word_id", "home.repos.pwc.inspect_result.dreasysnail_RetGen.models.hf_models.BertTensorizer.is_sub_word_id"], ["", "def", "_extend_span_to_full_words", "(", "tensorizer", ":", "Tensorizer", ",", "tokens", ":", "List", "[", "int", "]", ",", "span", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "    ", "start_index", ",", "end_index", "=", "span", "\n", "max_len", "=", "len", "(", "tokens", ")", "\n", "while", "start_index", ">", "0", "and", "tensorizer", ".", "is_sub_word_id", "(", "tokens", "[", "start_index", "]", ")", ":", "\n", "        ", "start_index", "-=", "1", "\n", "\n", "", "while", "end_index", "<", "max_len", "-", "1", "and", "tensorizer", ".", "is_sub_word_id", "(", "tokens", "[", "end_index", "+", "1", "]", ")", ":", "\n", "        ", "end_index", "+=", "1", "\n", "\n", "", "return", "start_index", ",", "end_index", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data._preprocess_reader_samples_chunk": [[386, 410], ["logger.info", "reader_data.preprocess_retriever_data", "tqdm.tqdm", "enumerate", "len", "r.on_serialize", "results.append", "open", "logger.info", "pickle.dump", "str", "len"], "function", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.preprocess_retriever_data", "home.repos.pwc.inspect_result.dreasysnail_RetGen.data.reader_data.ReaderSample.on_serialize"], ["", "def", "_preprocess_reader_samples_chunk", "(", "samples", ":", "List", ",", "out_file_prefix", ":", "str", ",", "gold_passages_file", ":", "str", ",", "\n", "tensorizer", ":", "Tensorizer", ",", "\n", "is_train_set", ":", "bool", ")", "->", "str", ":", "\n", "    ", "chunk_id", ",", "samples", "=", "samples", "\n", "logger", ".", "info", "(", "'Start batch %d'", ",", "len", "(", "samples", ")", ")", "\n", "iterator", "=", "preprocess_retriever_data", "(", "\n", "samples", ",", "\n", "gold_passages_file", ",", "\n", "tensorizer", ",", "\n", "is_train_set", "=", "is_train_set", ",", "\n", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "iterator", "=", "tqdm", "(", "iterator", ")", "\n", "for", "i", ",", "r", "in", "enumerate", "(", "iterator", ")", ":", "\n", "        ", "r", ".", "on_serialize", "(", ")", "\n", "results", ".", "append", "(", "r", ")", "\n", "\n", "", "out_file", "=", "out_file_prefix", "+", "'.'", "+", "str", "(", "chunk_id", ")", "+", "'.pkl'", "\n", "with", "open", "(", "out_file", ",", "mode", "=", "'wb'", ")", "as", "f", ":", "\n", "        ", "logger", ".", "info", "(", "'Serialize %d results to %s'", ",", "len", "(", "results", ")", ",", "out_file", ")", "\n", "pickle", ".", "dump", "(", "results", ",", "f", ")", "\n", "", "return", "out_file", "\n", "", ""]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer.__init__": [[23, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "buffer_size", ":", "int", "=", "50000", ")", ":", "\n", "        ", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "index_id_to_db_id", "=", "[", "]", "\n", "self", ".", "index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer.index_data": [[28, 30], ["None"], "methods", ["None"], ["", "def", "index_data", "(", "self", ",", "data", ":", "List", "[", "Tuple", "[", "object", ",", "np", ".", "array", "]", "]", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer.search_knn": [[31, 33], ["None"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ":", "np", ".", "array", ",", "top_docs", ":", "int", ")", "->", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer.serialize": [[34, 43], ["logger.info", "faiss.write_index", "open", "pickle.dump"], "methods", ["None"], ["", "def", "serialize", "(", "self", ",", "file", ":", "str", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Serializing index to %s'", ",", "file", ")", "\n", "\n", "index_file", "=", "file", "+", "'.index.dpr'", "\n", "meta_file", "=", "file", "+", "'.index_meta.dpr'", "\n", "\n", "faiss", ".", "write_index", "(", "self", ".", "index", ",", "index_file", ")", "\n", "with", "open", "(", "meta_file", ",", "mode", "=", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "index_id_to_db_id", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer.deserialize_from": [[44, 57], ["logger.info", "faiss.read_index", "logger.info", "type", "open", "pickle.load", "len"], "methods", ["None"], ["", "", "def", "deserialize_from", "(", "self", ",", "file", ":", "str", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading index from %s'", ",", "file", ")", "\n", "\n", "index_file", "=", "file", "+", "'.index.dpr'", "\n", "meta_file", "=", "file", "+", "'.index_meta.dpr'", "\n", "\n", "self", ".", "index", "=", "faiss", ".", "read_index", "(", "index_file", ")", "\n", "logger", ".", "info", "(", "'Loaded index of type %s and size %d'", ",", "type", "(", "self", ".", "index", ")", ",", "self", ".", "index", ".", "ntotal", ")", "\n", "\n", "with", "open", "(", "meta_file", ",", "\"rb\"", ")", "as", "reader", ":", "\n", "            ", "self", ".", "index_id_to_db_id", "=", "pickle", ".", "load", "(", "reader", ")", "\n", "", "assert", "len", "(", "\n", "self", ".", "index_id_to_db_id", ")", "==", "self", ".", "index", ".", "ntotal", ",", "'Deserialized index_id_to_db_id should match faiss index size'", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer._update_id_mapping": [[58, 60], ["faiss_indexers.DenseIndexer.index_id_to_db_id.extend"], "methods", ["None"], ["", "def", "_update_id_mapping", "(", "self", ",", "db_ids", ":", "List", ")", ":", "\n", "        ", "self", ".", "index_id_to_db_id", ".", "extend", "(", "db_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseFlatIndexer.__init__": [[63, 66], ["faiss_indexers.DenseIndexer.__init__", "faiss.IndexFlatIP"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vector_sz", ":", "int", ",", "buffer_size", ":", "int", "=", "50000", ")", ":", "\n", "        ", "super", "(", "DenseFlatIndexer", ",", "self", ")", ".", "__init__", "(", "buffer_size", "=", "buffer_size", ")", "\n", "self", ".", "index", "=", "faiss", ".", "IndexFlatIP", "(", "vector_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseFlatIndexer.index_data": [[67, 79], ["len", "range", "len", "logger.info", "numpy.concatenate", "faiss_indexers.DenseFlatIndexer._update_id_mapping", "faiss_indexers.DenseFlatIndexer.index.add", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer._update_id_mapping"], ["", "def", "index_data", "(", "self", ",", "data", ":", "List", "[", "Tuple", "[", "object", ",", "np", ".", "array", "]", "]", ")", ":", "\n", "        ", "n", "=", "len", "(", "data", ")", "\n", "# indexing in batches is beneficial for many faiss index types", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "self", ".", "buffer_size", ")", ":", "\n", "            ", "db_ids", "=", "[", "t", "[", "0", "]", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "vectors", "=", "[", "np", ".", "reshape", "(", "t", "[", "1", "]", ",", "(", "1", ",", "-", "1", ")", ")", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "vectors", "=", "np", ".", "concatenate", "(", "vectors", ",", "axis", "=", "0", ")", "\n", "self", ".", "_update_id_mapping", "(", "db_ids", ")", "\n", "self", ".", "index", ".", "add", "(", "vectors", ")", "\n", "\n", "", "indexed_cnt", "=", "len", "(", "self", ".", "index_id_to_db_id", ")", "\n", "logger", ".", "info", "(", "'Total data indexed %d'", ",", "indexed_cnt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseFlatIndexer.search_knn": [[80, 86], ["faiss_indexers.DenseFlatIndexer.index.search", "range", "len"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ":", "np", ".", "array", ",", "top_docs", ":", "int", ")", "->", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ":", "\n", "        ", "scores", ",", "indexes", "=", "self", ".", "index", ".", "search", "(", "query_vectors", ",", "top_docs", ")", "\n", "# convert to external ids", "\n", "db_ids", "=", "[", "[", "self", ".", "index_id_to_db_id", "[", "i", "]", "for", "i", "in", "query_top_idxs", "]", "for", "query_top_idxs", "in", "indexes", "]", "\n", "result", "=", "[", "(", "db_ids", "[", "i", "]", ",", "scores", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "db_ids", ")", ")", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__": [[92, 103], ["faiss_indexers.DenseIndexer.__init__", "faiss.IndexHNSWFlat"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.__init__"], ["def", "__init__", "(", "self", ",", "vector_sz", ":", "int", ",", "buffer_size", ":", "int", "=", "50000", ",", "store_n", ":", "int", "=", "512", "\n", ",", "ef_search", ":", "int", "=", "128", ",", "ef_construction", ":", "int", "=", "200", ")", ":", "\n", "        ", "super", "(", "DenseHNSWFlatIndexer", ",", "self", ")", ".", "__init__", "(", "buffer_size", "=", "buffer_size", ")", "\n", "\n", "# IndexHNSWFlat supports L2 similarity only", "\n", "# so we have to apply DOT -> L2 similairy space conversion with the help of an extra dimension", "\n", "index", "=", "faiss", ".", "IndexHNSWFlat", "(", "vector_sz", "+", "1", ",", "store_n", ")", "\n", "index", ".", "hnsw", ".", "efSearch", "=", "ef_search", "\n", "index", ".", "hnsw", ".", "efConstruction", "=", "ef_construction", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "phi", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.index_data": [[104, 136], ["len", "enumerate", "logger.info", "range", "len", "logger.info", "RuntimeError", "max", "numpy.concatenate", "faiss_indexers.DenseHNSWFlatIndexer._update_id_mapping", "faiss_indexers.DenseHNSWFlatIndexer.index.add", "logger.info", "numpy.reshape", "numpy.sqrt", "numpy.hstack", "len", "enumerate", "aux_dims[].reshape"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseIndexer._update_id_mapping"], ["", "def", "index_data", "(", "self", ",", "data", ":", "List", "[", "Tuple", "[", "object", ",", "np", ".", "array", "]", "]", ")", ":", "\n", "        ", "n", "=", "len", "(", "data", ")", "\n", "\n", "# max norm is required before putting all vectors in the index to convert inner product similarity to L2", "\n", "if", "self", ".", "phi", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'DPR HNSWF index needs to index all data at once,'", "\n", "'results will be unpredictable otherwise.'", ")", "\n", "", "phi", "=", "0", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "id", ",", "doc_vector", "=", "item", "\n", "norms", "=", "(", "doc_vector", "**", "2", ")", ".", "sum", "(", ")", "\n", "phi", "=", "max", "(", "phi", ",", "norms", ")", "\n", "", "logger", ".", "info", "(", "'HNSWF DotProduct -> L2 space phi={}'", ".", "format", "(", "phi", ")", ")", "\n", "self", ".", "phi", "=", "0", "\n", "\n", "# indexing in batches is beneficial for many faiss index types", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "self", ".", "buffer_size", ")", ":", "\n", "            ", "db_ids", "=", "[", "t", "[", "0", "]", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "vectors", "=", "[", "np", ".", "reshape", "(", "t", "[", "1", "]", ",", "(", "1", ",", "-", "1", ")", ")", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "\n", "norms", "=", "[", "(", "doc_vector", "**", "2", ")", ".", "sum", "(", ")", "for", "doc_vector", "in", "vectors", "]", "\n", "aux_dims", "=", "[", "np", ".", "sqrt", "(", "phi", "-", "norm", ")", "for", "norm", "in", "norms", "]", "\n", "hnsw_vectors", "=", "[", "np", ".", "hstack", "(", "(", "doc_vector", ",", "aux_dims", "[", "i", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ")", "for", "i", ",", "doc_vector", "in", "\n", "enumerate", "(", "vectors", ")", "]", "\n", "hnsw_vectors", "=", "np", ".", "concatenate", "(", "hnsw_vectors", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "_update_id_mapping", "(", "db_ids", ")", "\n", "self", ".", "index", ".", "add", "(", "hnsw_vectors", ")", "\n", "logger", ".", "info", "(", "'data indexed %d'", ",", "len", "(", "self", ".", "index_id_to_db_id", ")", ")", "\n", "\n", "", "indexed_cnt", "=", "len", "(", "self", ".", "index_id_to_db_id", ")", "\n", "logger", ".", "info", "(", "'Total data indexed %d'", ",", "indexed_cnt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.search_knn": [[137, 147], ["numpy.zeros", "numpy.hstack", "faiss_indexers.DenseHNSWFlatIndexer.index.search", "len", "numpy.zeros.reshape", "range", "len"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ":", "np", ".", "array", ",", "top_docs", ":", "int", ")", "->", "List", "[", "Tuple", "[", "List", "[", "object", "]", ",", "List", "[", "float", "]", "]", "]", ":", "\n", "\n", "        ", "aux_dim", "=", "np", ".", "zeros", "(", "len", "(", "query_vectors", ")", ",", "dtype", "=", "'float32'", ")", "\n", "query_nhsw_vectors", "=", "np", ".", "hstack", "(", "(", "query_vectors", ",", "aux_dim", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ")", "\n", "# logger.info('query_hnsw_vectors %s', query_nhsw_vectors.shape)", "\n", "scores", ",", "indexes", "=", "self", ".", "index", ".", "search", "(", "query_nhsw_vectors", ",", "top_docs", ")", "\n", "# convert to external ids", "\n", "db_ids", "=", "[", "[", "self", ".", "index_id_to_db_id", "[", "i", "]", "for", "i", "in", "query_top_idxs", "]", "for", "query_top_idxs", "in", "indexes", "]", "\n", "result", "=", "[", "(", "db_ids", "[", "i", "]", ",", "scores", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "db_ids", ")", ")", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.deserialize_from": [[148, 152], ["faiss_indexers.DenseIndexer.deserialize_from"], "methods", ["home.repos.pwc.inspect_result.dreasysnail_RetGen.indexer.faiss_indexers.DenseHNSWFlatIndexer.deserialize_from"], ["", "def", "deserialize_from", "(", "self", ",", "file", ":", "str", ")", ":", "\n", "        ", "super", "(", "DenseHNSWFlatIndexer", ",", "self", ")", ".", "deserialize_from", "(", "file", ")", "\n", "# to trigger warning on subsequent indexing", "\n", "self", ".", "phi", "=", "1", "\n", "", "", ""]]}