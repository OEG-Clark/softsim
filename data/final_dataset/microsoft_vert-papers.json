{"home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF.__init__": [[24, 44], ["torch.Module.__init__", "torch.zeros.to", "torch.zeros.to", "torch.Parameter", "torch.Parameter", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "crfb.CRF.reset_trans_matrix", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF.reset_trans_matrix"], ["    ", "def", "__init__", "(", "self", ",", "tagset_size", ",", "model_name", ",", "reset", "=", "False", ")", ":", "\n", "        ", "super", "(", "CRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Matrix of transition parameters.  Entry i,j is the score of transitioning *to* i *from* j.", "\n", "self", ".", "average_batch", "=", "False", "\n", "self", ".", "tagset_size", "=", "tagset_size", "\n", "# # We add 2 here, because of START_TAG and STOP_TAG", "\n", "# # transitions (f_tag_size, t_tag_size), transition value from f_tag to t_tag", "\n", "if", "reset", ":", "\n", "            ", "init_transitions", "=", "torch", ".", "Tensor", "(", "self", ".", "tagset_size", "+", "2", ",", "self", ".", "tagset_size", "+", "2", ")", ".", "fill_", "(", "-", "1000.0", ")", "\n", "self", ".", "reset_trans_matrix", "(", "init_transitions", ",", "model_name", ")", "\n", "", "else", ":", "\n", "            ", "init_transitions", "=", "torch", ".", "zeros", "(", "self", ".", "tagset_size", "+", "2", ",", "self", ".", "tagset_size", "+", "2", ")", "\n", "# init_transitions = torch.zeros(self.tagset_size+2, self.tagset_size+2)", "\n", "# init_transitions[:,START_TAG] = -1000.0", "\n", "# init_transitions[STOP_TAG,:] = -1000.0", "\n", "# init_transitions[:,0] = -1000.0", "\n", "# init_transitions[0,:] = -1000.0", "\n", "", "init_transitions", ".", "to", "(", "device", ")", "\n", "self", ".", "transitions", "=", "nn", ".", "Parameter", "(", "init_transitions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF.reset_trans_matrix": [[48, 89], ["Exception"], "methods", ["None"], ["", "def", "reset_trans_matrix", "(", "self", ",", "init_transitions", ",", "model_name", ")", ":", "\n", "        ", "init_transitions", "[", ":", ",", "STOP_TAG", "]", "=", "0.0", "\n", "init_transitions", "[", "START_TAG", ",", ":", "]", "=", "0.0", "\n", "init_transitions", "[", "0", ",", "0", "]", "=", "0.0", "# O to O", "\n", "if", "model_name", "==", "\"weibo.model\"", "or", "model_name", "==", "\"resume.model\"", ":", "\n", "            ", "B_index", "=", "[", "1", ",", "5", ",", "9", ",", "13", ",", "17", ",", "21", ",", "25", ",", "29", "]", "\n", "M_index", "=", "[", "2", ",", "6", ",", "10", ",", "14", ",", "18", ",", "22", ",", "26", ",", "30", "]", "\n", "S_index", "=", "[", "3", ",", "7", ",", "11", ",", "15", ",", "19", ",", "23", ",", "27", ",", "31", "]", "\n", "E_index", "=", "[", "4", ",", "8", ",", "12", ",", "16", ",", "20", ",", "24", ",", "28", ",", "32", "]", "\n", "init_transitions", "[", "3", ":", "32", ":", "4", ",", "1", ":", "30", ":", "4", "]", "=", "0.0", "# S to all B", "\n", "init_transitions", "[", "3", ":", "32", ":", "4", ",", "3", ":", "32", ":", "4", "]", "=", "0.0", "# S to all S", "\n", "init_transitions", "[", "4", ":", "33", ":", "4", ",", "1", ":", "30", ":", "4", "]", "=", "0.0", "# E to all B", "\n", "init_transitions", "[", "4", ":", "33", ":", "3", ",", "3", ":", "32", ":", "4", "]", "=", "0.0", "# E to all S", "\n", "", "elif", "model_name", "==", "\"msra.model\"", ":", "\n", "            ", "B_index", "=", "[", "1", ",", "5", ",", "9", "]", "\n", "M_index", "=", "[", "2", ",", "6", ",", "10", "]", "\n", "S_index", "=", "[", "3", ",", "7", ",", "11", "]", "\n", "E_index", "=", "[", "4", ",", "8", ",", "12", "]", "\n", "init_transitions", "[", "3", ":", "12", ":", "4", ",", "1", ":", "10", ":", "4", "]", "=", "0.0", "# S to all B", "\n", "init_transitions", "[", "3", ":", "12", ":", "4", ",", "3", ":", "12", ":", "4", "]", "=", "0.0", "# S to all S", "\n", "init_transitions", "[", "4", ":", "13", ":", "4", ",", "1", ":", "10", ":", "4", "]", "=", "0.0", "# E to all B", "\n", "init_transitions", "[", "4", ":", "13", ":", "4", ",", "3", ":", "12", ":", "4", "]", "=", "0.0", "# E to all S", "\n", "", "elif", "model_name", "==", "\"onto4.model\"", "or", "model_name", "==", "\"conll2003.model\"", ":", "\n", "            ", "B_index", "=", "[", "1", ",", "5", ",", "9", ",", "13", "]", "\n", "M_index", "=", "[", "2", ",", "6", ",", "10", ",", "14", "]", "\n", "S_index", "=", "[", "3", ",", "7", ",", "11", ",", "15", "]", "\n", "E_index", "=", "[", "4", ",", "8", ",", "12", ",", "16", "]", "\n", "init_transitions", "[", "3", ":", "16", ":", "4", ",", "1", ":", "14", ":", "4", "]", "=", "0.0", "# S to all B", "\n", "init_transitions", "[", "3", ":", "16", ":", "4", ",", "3", ":", "16", ":", "4", "]", "=", "0.0", "# S to all S", "\n", "init_transitions", "[", "4", ":", "17", ":", "4", ",", "1", ":", "14", ":", "4", "]", "=", "0.0", "# E to all B", "\n", "init_transitions", "[", "4", ":", "17", ":", "4", ",", "3", ":", "16", ":", "4", "]", "=", "0.0", "# E to all S", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "model_name", "+", "\"doesn't exists!\"", ")", "\n", "", "init_transitions", "[", "0", ",", "B_index", "]", "=", "0.0", "# O to all B", "\n", "init_transitions", "[", "0", ",", "S_index", "]", "=", "0.0", "# O to all S", "\n", "init_transitions", "[", "B_index", ",", "M_index", "]", "=", "0.0", "# B to self M", "\n", "init_transitions", "[", "B_index", ",", "E_index", "]", "=", "0.0", "# B to self E", "\n", "init_transitions", "[", "M_index", ",", "M_index", "]", "=", "0.0", "# M to self M", "\n", "init_transitions", "[", "M_index", ",", "E_index", "]", "=", "0.0", "# M to self E", "\n", "init_transitions", "[", "S_index", ",", "0", "]", "=", "0.0", "# S to O", "\n", "init_transitions", "[", "E_index", ",", "0", "]", "=", "0.0", "# E to O", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF._calculate_PZ": [[90, 145], ["feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "mask.transpose().contiguous.transpose().contiguous.transpose().contiguous", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view().expand", "scores.view.view.view", "enumerate", "enumerate.__next__", "inivalues[].clone().view", "crfb.log_sum_exp", "crfb.CRF.transitions.view().expand", "crfb.log_sum_exp", "mask[].view().expand", "log_sum_exp.masked_select", "mask_idx.contiguous().view.contiguous().view.contiguous().view", "inivalues[].clone().view.masked_scatter_", "crfb.CRF.transitions.view().expand", "inivalues[].clone().view.contiguous().view().expand", "final_partition.sum", "mask.transpose().contiguous.transpose().contiguous.transpose", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view", "inivalues[].clone", "inivalues[].clone().view.contiguous().view().expand", "crfb.CRF.transitions.view", "mask[].view", "mask_idx.contiguous().view.contiguous().view.contiguous", "crfb.CRF.transitions.view", "inivalues[].clone().view.contiguous().view", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous", "inivalues[].clone().view.contiguous().view", "inivalues[].clone().view.contiguous", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose", "inivalues[].clone().view.contiguous"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.function_util.log_sum_exp", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.function_util.log_sum_exp"], ["", "def", "_calculate_PZ", "(", "self", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, self.tag_size+2)\n                masks: (batch, seq_len)\n        \"\"\"", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "# print feats.view(seq_len, tag_size)", "\n", "assert", "(", "tag_size", "==", "self", ".", "tagset_size", "+", "2", ")", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "ins_num", "=", "seq_len", "*", "batch_size", "\n", "## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)", "\n", "feats", "=", "feats", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "ins_num", ",", "1", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "## need to consider start", "\n", "scores", "=", "feats", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "scores", "=", "scores", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "# build iter", "\n", "seq_iter", "=", "enumerate", "(", "scores", ")", "\n", "_", ",", "inivalues", "=", "seq_iter", ".", "__next__", "(", ")", "# bat_size * from_target_size * to_target_size", "\n", "# only need start from start_tag", "\n", "partition", "=", "inivalues", "[", ":", ",", "START_TAG", ",", ":", "]", ".", "clone", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "# bat_size * to_target_size", "\n", "\n", "## add start score (from start to all tag, duplicate to batch_size)", "\n", "# partition = partition + self.transitions[START_TAG,:].view(1, tag_size, 1).expand(batch_size, tag_size, 1)", "\n", "# iter over last scores", "\n", "for", "idx", ",", "cur_values", "in", "seq_iter", ":", "\n", "# previous to_target is current from_target", "\n", "# partition: previous results log(exp(from_target)), #(batch_size * from_target)", "\n", "# cur_values: bat_size * from_target * to_target", "\n", "\n", "            ", "cur_values", "=", "cur_values", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "\n", "tag_size", ")", "\n", "cur_partition", "=", "log_sum_exp", "(", "cur_values", ",", "tag_size", ")", "\n", "# print cur_partition.data", "\n", "\n", "# (bat_size * from_target * to_target) -> (bat_size * to_target)", "\n", "# partition = utils.switch(partition, cur_partition, mask[idx].view(bat_size, 1).expand(bat_size, self.tagset_size)).view(bat_size, -1)", "\n", "mask_idx", "=", "mask", "[", "idx", ",", ":", "]", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ")", "\n", "\n", "## effective updated partition part, only keep the partition value of mask value = 1", "\n", "masked_cur_partition", "=", "cur_partition", ".", "masked_select", "(", "mask_idx", ")", "\n", "## let mask_idx broadcastable, to disable warning", "\n", "mask_idx", "=", "mask_idx", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "\n", "\n", "## replace the partition where the maskvalue=1, other partition value keeps the same", "\n", "partition", ".", "masked_scatter_", "(", "mask_idx", ",", "masked_cur_partition", ")", "\n", "# until the last state, add transition score for all partition (and do log_sum_exp) then select the value in STOP_TAG", "\n", "", "cur_values", "=", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "\n", "tag_size", ")", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "cur_partition", "=", "log_sum_exp", "(", "cur_values", ",", "tag_size", ")", "\n", "final_partition", "=", "cur_partition", "[", ":", ",", "STOP_TAG", "]", "\n", "return", "final_partition", ".", "sum", "(", ")", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF._viterbi_decode": [[146, 240], ["feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "mask.transpose().contiguous.transpose().contiguous.transpose().contiguous", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view().expand", "scores.view.view.view", "enumerate", "list", "list", "mask.transpose().contiguous.transpose().contiguous.to", "enumerate.__next__", "inivalues[].clone().view", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "last_position.to", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long.to", "torch.zeros().long.to", "back_points.transpose().contiguous.transpose().contiguous.append", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.gather.contiguous().view().expand", "torch.gather.contiguous().view().expand", "back_points.transpose().contiguous.transpose().contiguous.transpose().contiguous", "back_points.transpose().contiguous.transpose().contiguous.scatter_", "back_points.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "decode_idx.transpose.transpose.to", "range", "decode_idx.transpose.transpose.transpose", "crfb.CRF.transitions.view().expand", "torch.max", "torch.max", "torch.max", "torch.max", "partition.view.view.view", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "cur_bp.masked_fill_", "back_points.transpose().contiguous.transpose().contiguous.append", "torch.sum().view().long.view().expand", "torch.sum().view().long.view().expand", "torch.gather().view.expand", "torch.gather().view.expand", "crfb.CRF.transitions.view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "mask.transpose().contiguous.transpose().contiguous.transpose", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view", "inivalues[].clone", "partition.view.view.contiguous().view().expand", "mask[].view().expand", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather.contiguous().view", "torch.gather.contiguous().view", "back_points.transpose().contiguous.transpose().contiguous.transpose", "back_points.transpose().contiguous.transpose().contiguous.transpose", "len", "torch.gather.contiguous().view", "torch.gather.contiguous().view", "crfb.CRF.transitions.view", "mask.transpose().contiguous.transpose().contiguous.long", "torch.sum().view().long.view", "torch.sum().view().long.view", "crfb.CRF.transitions.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous", "partition.view.view.contiguous().view", "mask[].view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.gather.contiguous", "torch.gather.contiguous", "torch.gather.contiguous", "torch.gather.contiguous", "mask.transpose().contiguous.transpose().contiguous.long", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose", "partition.view.view.contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "_viterbi_decode", "(", "self", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, self.tag_size+2)\n                mask: (batch, seq_len)\n            output:\n                decode_idx: (batch, seq_len) decoded sequence\n                path_score: (batch, 1) corresponding score for each sequence (to be implementated)\n        \"\"\"", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "assert", "(", "tag_size", "==", "self", ".", "tagset_size", "+", "2", ")", "\n", "## calculate sentence length for each sentence", "\n", "length_mask", "=", "torch", ".", "sum", "(", "mask", ".", "long", "(", ")", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "long", "(", ")", "\n", "## mask to (seq_len, batch_size)", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "ins_num", "=", "seq_len", "*", "batch_size", "\n", "## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)", "\n", "feats", "=", "feats", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "ins_num", ",", "1", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "## need to consider start", "\n", "scores", "=", "feats", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "scores", "=", "scores", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "\n", "# build iter", "\n", "seq_iter", "=", "enumerate", "(", "scores", ")", "\n", "## record the position of best score", "\n", "back_points", "=", "list", "(", ")", "\n", "partition_history", "=", "list", "(", ")", "\n", "\n", "##  reverse mask (bug for mask = 1- mask, use this as alternative choice)", "\n", "# mask = 1 + (-1)*mask", "\n", "mask", "=", "(", "1", "-", "mask", ".", "long", "(", ")", ")", ".", "byte", "(", ")", "\n", "mask", ".", "to", "(", "device", ")", "\n", "_", ",", "inivalues", "=", "seq_iter", ".", "__next__", "(", ")", "# bat_size * from_target_size * to_target_size", "\n", "# only need start from start_tag", "\n", "partition", "=", "inivalues", "[", ":", ",", "START_TAG", ",", ":", "]", ".", "clone", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "# bat_size * to_target_size", "\n", "partition_history", ".", "append", "(", "partition", ")", "\n", "# print (partition.size())", "\n", "# iter over last scores", "\n", "for", "idx", ",", "cur_values", "in", "seq_iter", ":", "\n", "# previous to_target is current from_target", "\n", "# partition: previous results log(exp(from_target)), #(batch_size * from_target)", "\n", "# cur_values: batch_size * from_target * to_target", "\n", "            ", "cur_values", "=", "cur_values", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "\n", "tag_size", ")", "\n", "## forscores, cur_bp = torch.max(cur_values[:,:-2,:], 1) # do not consider START_TAG/STOP_TAG", "\n", "partition", ",", "cur_bp", "=", "torch", ".", "max", "(", "cur_values", ",", "1", ")", "\n", "partition", "=", "partition", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "\n", "partition_history", ".", "append", "(", "partition", ")", "\n", "\n", "## cur_bp: (batch_size, tag_size) max source score position in current tag", "\n", "## set padded label as 0, which will be filtered in post processing", "\n", "cur_bp", ".", "masked_fill_", "(", "mask", "[", "idx", "]", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ")", ",", "0", ")", "\n", "back_points", ".", "append", "(", "cur_bp", ")", "\n", "### add score to final STOP_TAG", "\n", "\n", "", "partition_history", "=", "torch", ".", "cat", "(", "partition_history", ",", "0", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "\n", "0", ")", ".", "contiguous", "(", ")", "## (batch_size, seq_len. tag_size)", "\n", "### get the last position for each setences, and select the last partitions using gather()", "\n", "last_position", "=", "length_mask", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ")", "-", "1", "\n", "last_position", ".", "to", "(", "device", ")", "\n", "last_partition", "=", "torch", ".", "gather", "(", "partition_history", ",", "1", ",", "last_position", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "\n", "### calculate the score from last partition to end state (and then select the STOP_TAG from it)", "\n", "last_values", "=", "last_partition", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "\n", "tag_size", ")", ".", "expand", "(", "\n", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "_", ",", "last_bp", "=", "torch", ".", "max", "(", "last_values", ",", "1", ")", "\n", "pad_zero", "=", "torch", ".", "zeros", "(", "batch_size", ",", "tag_size", ")", ".", "long", "(", ")", "\n", "pad_zero", ".", "to", "(", "device", ")", "\n", "back_points", ".", "append", "(", "pad_zero", ")", "\n", "back_points", "=", "torch", ".", "cat", "(", "back_points", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ")", "\n", "\n", "## select end ids in STOP_TAG", "\n", "pointer", "=", "last_bp", "[", ":", ",", "STOP_TAG", "]", "\n", "insert_last", "=", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ")", "\n", "back_points", "=", "back_points", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "## move the end ids(expand to tag_size) to the corresponding position of back_points to replace the 0 values", "\n", "# print \"lp:\",last_position", "\n", "# print \"il:\",insert_last", "\n", "back_points", ".", "scatter_", "(", "1", ",", "last_position", ",", "insert_last", ")", "\n", "# print \"bp:\",back_points", "\n", "# exit(0)", "\n", "back_points", "=", "back_points", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "## decode from the end, padded position ids are 0, which will be filtered if following evaluation", "\n", "decode_idx", "=", "torch", ".", "LongTensor", "(", "seq_len", ",", "batch_size", ")", "\n", "decode_idx", ".", "to", "(", "device", ")", "\n", "decode_idx", "[", "-", "1", "]", "=", "pointer", ".", "data", "\n", "for", "idx", "in", "range", "(", "len", "(", "back_points", ")", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "pointer", "=", "torch", ".", "gather", "(", "back_points", "[", "idx", "]", ",", "1", ",", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ")", ")", "\n", "decode_idx", "[", "idx", "]", "=", "pointer", ".", "data", "\n", "", "path_score", "=", "None", "\n", "decode_idx", "=", "decode_idx", ".", "transpose", "(", "1", ",", "0", ")", "\n", "return", "path_score", ",", "decode_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF.forward": [[241, 244], ["crfb.CRF._viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF._viterbi_decode"], ["", "def", "forward", "(", "self", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "path_score", ",", "best_path", "=", "self", ".", "_viterbi_decode", "(", "feats", ",", "mask", ")", "\n", "return", "path_score", ",", "best_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF._score_sentence": [[245, 297], ["scores.size", "scores.size", "scores.size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "new_tags.transpose().contiguous().view.transpose().contiguous().view.to", "range", "crfb.CRF.transitions[].contiguous().view().expand", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "new_tags.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "tg_energy.masked_select.masked_select.masked_select", "mask.transpose", "tg_energy.masked_select.masked_select.sum", "torch.gather.sum", "torch.gather.sum", "crfb.CRF.transitions[].contiguous().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "new_tags.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "scores.view", "crfb.CRF.transitions[].contiguous", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "new_tags.transpose().contiguous().view.transpose().contiguous().view.transpose", "mask.long"], "methods", ["None"], ["", "def", "_score_sentence", "(", "self", ",", "scores", ",", "mask", ",", "tags", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                scores: variable (seq_len, batch, tag_size, tag_size)\n                mask: (batch, seq_len)\n                tags: tensor  (batch, seq_len)\n            output:\n                score: sum of score for gold sequences within whole batch\n        \"\"\"", "\n", "# Gives the score of a provided tag sequence", "\n", "batch_size", "=", "scores", ".", "size", "(", "1", ")", "\n", "seq_len", "=", "scores", ".", "size", "(", "0", ")", "\n", "tag_size", "=", "scores", ".", "size", "(", "2", ")", "\n", "## convert tag value into a new format, recorded label bigram information to index  ", "\n", "new_tags", "=", "torch", ".", "LongTensor", "(", "batch_size", ",", "seq_len", ")", "\n", "# print (tags.size())", "\n", "# exit()", "\n", "new_tags", "=", "new_tags", ".", "to", "(", "device", ")", "\n", "for", "idx", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "## start -> first score", "\n", "                ", "new_tags", "[", ":", ",", "0", "]", "=", "(", "tag_size", "-", "2", ")", "*", "tag_size", "+", "tags", "[", ":", ",", "0", "]", "\n", "\n", "", "else", ":", "\n", "                ", "new_tags", "[", ":", ",", "idx", "]", "=", "tags", "[", ":", ",", "idx", "-", "1", "]", "*", "tag_size", "+", "tags", "[", ":", ",", "idx", "]", "\n", "\n", "## transition for label to STOP_TAG", "\n", "", "", "end_transition", "=", "self", ".", "transitions", "[", ":", ",", "STOP_TAG", "]", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "tag_size", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ")", "\n", "## length for batch,  last word position = length - 1", "\n", "length_mask", "=", "torch", ".", "sum", "(", "mask", ".", "long", "(", ")", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "long", "(", ")", "\n", "## index the label id of last word", "\n", "end_ids", "=", "torch", ".", "gather", "(", "tags", ",", "1", ",", "length_mask", "-", "1", ")", "\n", "\n", "## index the transition score for end_id to STOP_TAG", "\n", "end_energy", "=", "torch", ".", "gather", "(", "end_transition", ",", "1", ",", "end_ids", ")", "\n", "\n", "## convert tag as (seq_len, batch_size, 1)", "\n", "new_tags", "=", "new_tags", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "1", ")", "\n", "### need convert tags id to search from 400 positions of scores", "\n", "tg_energy", "=", "torch", ".", "gather", "(", "scores", ".", "view", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ",", "2", ",", "new_tags", ")", ".", "view", "(", "seq_len", ",", "\n", "batch_size", ")", "# seq_len * bat_size", "\n", "## mask transpose to (seq_len, batch_size)", "\n", "tg_energy", "=", "tg_energy", ".", "masked_select", "(", "mask", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "\n", "# ## calculate the score from START_TAG to first label", "\n", "# start_transition = self.transitions[START_TAG,:].view(1, tag_size).expand(batch_size, tag_size)", "\n", "# start_energy = torch.gather(start_transition, 1, tags[0,:])", "\n", "\n", "## add all score together", "\n", "# gold_score = start_energy.sum() + tg_energy.sum() + end_energy.sum()", "\n", "gold_score", "=", "tg_energy", ".", "sum", "(", ")", "+", "end_energy", ".", "sum", "(", ")", "\n", "return", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF.batch_loss": [[298, 309], ["feats.size", "crfb.CRF._calculate_PZ", "crfb.CRF._score_sentence"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.CRF._calculate_PZ", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._score_sentence"], ["", "def", "batch_loss", "(", "self", ",", "feats", ",", "mask", ",", "tags", ")", ":", "\n", "# nonegative log likelihood", "\n", "        ", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "forward_score", ",", "scores", "=", "self", ".", "_calculate_PZ", "(", "feats", ",", "mask", ")", "\n", "gold_score", "=", "self", ".", "_score_sentence", "(", "scores", ",", "mask", ",", "tags", ")", "\n", "# print \"batch, f:\", forward_score.data[0], \" g:\", gold_score.data[0], \" dis:\", forward_score.data[0] - gold_score.data[0]", "\n", "# exit(0)", "\n", "if", "self", ".", "average_batch", ":", "\n", "            ", "return", "(", "forward_score", "-", "gold_score", ")", "/", "batch_size", "\n", "", "else", ":", "\n", "            ", "return", "forward_score", "-", "gold_score", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.crfb.log_sum_exp": [[8, 21], ["torch.max", "torch.max", "torch.gather().view", "torch.gather().view", "torch.gather().view.view", "torch.log().view", "torch.log().view", "torch.gather", "torch.gather", "idx.view", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.gather().view.expand_as"], "function", ["None"], ["def", "log_sum_exp", "(", "vec", ",", "m_size", ")", ":", "\n", "    ", "\"\"\"\n    calculate log of exp sum\n    args:\n        vec (batch_size, vanishing_dim, hidden_dim) : input tensor\n        m_size : hidden_dim\n    return:\n        batch_size, hidden_dim\n    \"\"\"", "\n", "_", ",", "idx", "=", "torch", ".", "max", "(", "vec", ",", "1", ")", "# B * 1 * M", "\n", "max_score", "=", "torch", ".", "gather", "(", "vec", ",", "1", ",", "idx", ".", "view", "(", "-", "1", ",", "1", ",", "m_size", ")", ")", ".", "view", "(", "-", "1", ",", "1", ",", "m_size", ")", "# B * M", "\n", "return", "max_score", ".", "view", "(", "-", "1", ",", "m_size", ")", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "vec", "-", "max_score", ".", "expand_as", "(", "vec", ")", ")", ",", "1", ")", ")", ".", "view", "(", "-", "1", ",", "\n", "m_size", ")", "# B * M", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.nner_with_seg_info.CANNERModel.__init__": [[10, 55], ["torch.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "nner_with_seg_info.CANNERModel.add_module", "nner_with_seg_info.CANNERModel.add_module", "nner_with_seg_info.CANNERModel.features_embeds.append", "nner_with_seg_info.CANNERModel.features_embeds.append", "acnn.ACNN", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "nner_with_seg_info.CANNERModel.SelfAttentionComponent", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "crfb.CRF", "torch.Linear", "torch.Linear", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "util.init_embedding_", "attr.to", "util.init_lstm_", "util.init_linear_"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_embedding_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_lstm_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "tag2id", ",", "dropout", ",", "seg_dim", "=", "300", ",", "embed_dim", "=", "300", ",", "pretrain_embed", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# make sure this tag2id do not contains start and stop", "\n", "self", ".", "tag_to_ix", "=", "tag2id", "\n", "self", ".", "target_size", "=", "len", "(", "tag2id", ")", "+", "2", "\n", "\n", "self", ".", "reset_para", "=", "False", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "seg_dim", "=", "seg_dim", "\n", "\n", "self", ".", "model_name", "=", "config", ".", "model_name", "\n", "self", ".", "hidden_dim", "=", "config", ".", "hidden_dim", "\n", "self", ".", "window_size", "=", "config", ".", "window_size", "\n", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "self", ".", "features_embeds", "=", "[", "]", "\n", "embeds", "=", "torch", ".", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "pretrain_embed", ")", ",", "freeze", "=", "False", ")", "\n", "soft_seg", "=", "torch", ".", "nn", ".", "Embedding", "(", "5", ",", "self", ".", "seg_dim", ")", "# OBMES 01234", "\n", "if", "self", ".", "reset_para", ":", "\n", "            ", "util", ".", "init_embedding_", "(", "soft_seg", ")", "\n", "", "self", ".", "add_module", "(", "'feature_embeds_{}'", ".", "format", "(", "0", ")", ",", "embeds", ")", "\n", "self", ".", "add_module", "(", "'feature_embeds_{}'", ".", "format", "(", "1", ")", ",", "soft_seg", ")", "\n", "self", ".", "features_embeds", ".", "append", "(", "embeds", ")", "\n", "self", ".", "features_embeds", ".", "append", "(", "soft_seg", ")", "\n", "\n", "\n", "self", ".", "features_embeds", "=", "[", "attr", ".", "to", "(", "device", ")", "for", "attr", "in", "self", ".", "features_embeds", "]", "\n", "self", ".", "cnn", "=", "acnn", ".", "ACNN", "(", "self", ".", "embed_dim", "+", "self", ".", "seg_dim", ",", "self", ".", "hidden_dim", ",", "self", ".", "window_size", ")", "\n", "\n", "self", ".", "rnn", "=", "torch", ".", "nn", ".", "GRU", "(", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", "//", "2", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "conv_activation", "=", "torch", ".", "nn", ".", "LeakyReLU", "(", "0.01", ")", "\n", "self", ".", "attc", "=", "SelfAttentionComponent", "(", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", ")", "\n", "self", ".", "hidden2tag", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", "*", "2", ",", "self", ".", "target_size", ")", "\n", "\n", "self", ".", "crf", "=", "crfb", ".", "CRF", "(", "self", ".", "target_size", "-", "2", ",", "self", ".", "model_name", ")", "\n", "self", ".", "hidden2tag", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", "*", "2", ",", "self", ".", "target_size", ")", "\n", "\n", "if", "self", ".", "reset_para", ":", "\n", "            ", "util", ".", "init_lstm_", "(", "self", ".", "rnn", ")", "\n", "util", ".", "init_linear_", "(", "self", ".", "hidden2tag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.nner_with_seg_info.CANNERModel.forward": [[57, 79], ["batch_x.size", "range", "nner_with_seg_info.CANNERModel.cnn", "nner_with_seg_info.CANNERModel.conv_activation", "nner_with_seg_info.CANNERModel.dropout", "nner_with_seg_info.CANNERModel.attc", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nner_with_seg_info.CANNERModel.dropout", "nner_with_seg_info.CANNERModel.hidden2tag", "getattr", "getattr.", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "getattr."], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "batch_x", ",", "mask", ")", ":", "\n", "        ", "batch_n", ",", "seq_len", ",", "feature_num", "=", "batch_x", ".", "size", "(", ")", "\n", "for", "i", "in", "range", "(", "feature_num", ")", ":", "\n", "            ", "feature_embed_data", "=", "batch_x", "[", ":", ",", ":", ",", "i", "]", "\n", "feature_embeds", "=", "getattr", "(", "self", ",", "'feature_embeds_{}'", ".", "format", "(", "i", ")", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "embeds_output", "=", "feature_embeds", "(", "feature_embed_data", ")", "\n", "", "else", ":", "\n", "                ", "embeds_output", "=", "torch", ".", "cat", "(", "(", "embeds_output", ",", "feature_embeds", "(", "feature_embed_data", ")", ")", ",", "2", ")", "\n", "\n", "# batch, seq_len, hidden_dim", "\n", "", "", "cnn_out", "=", "self", ".", "cnn", "(", "embeds_output", ")", "\n", "cnn_out", "=", "self", ".", "conv_activation", "(", "cnn_out", ")", "\n", "cnn_out", "=", "self", ".", "dropout", "(", "cnn_out", ")", "\n", "\n", "att_contexts", "=", "self", ".", "attc", "(", "cnn_out", ")", "\n", "cat_out", "=", "torch", ".", "cat", "(", "(", "cnn_out", ",", "att_contexts", ")", ",", "2", ")", "\n", "cat_out", "=", "self", ".", "dropout", "(", "cat_out", ")", "\n", "\n", "out", "=", "self", ".", "hidden2tag", "(", "cat_out", ")", "\n", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.self_attention_layer.SelfAttentionComponent.__init__": [[9, 27], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "util.init_linear_", "util.init_linear_", "util.init_linear_", "torch.Linear", "torch.Linear", "torch.Linear", "util.init_linear_"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_"], ["    ", "def", "__init__", "(", "self", ",", "dec_units", ",", "input_dim", ",", "score_type", "=", "'bahdanau'", ",", "use_bias", "=", "True", ",", "reset_para", "=", "False", ")", ":", "\n", "        ", "super", "(", "SelfAttentionComponent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "score_type", "=", "score_type", "\n", "self", ".", "dec_units", "=", "dec_units", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "\n", "if", "self", ".", "score_type", "==", "'bahdanau'", ":", "\n", "            ", "self", ".", "W1", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "dec_units", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "dec_units", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "V", "=", "nn", ".", "Linear", "(", "self", ".", "dec_units", ",", "1", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                ", "util", ".", "init_linear_", "(", "self", ".", "W1", ")", "\n", "util", ".", "init_linear_", "(", "self", ".", "W2", ")", "\n", "util", ".", "init_linear_", "(", "self", ".", "V", ")", "\n", "", "", "elif", "self", ".", "score_type", "==", "'luong'", ":", "\n", "            ", "self", ".", "W", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "input_dim", ")", "\n", "if", "reset_para", ":", "\n", "                ", "util", ".", "init_linear_", "(", "self", ".", "W", ")", "\n", "# elif self.score_type == 'dot':", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.self_attention_layer.SelfAttentionComponent.forward": [[34, 47], ["contexts.size", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "contexts[].unsqueeze", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.get_att_weights", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.get_att_vectors", "torch.stack.append", "torch.stack.append", "torch.stack.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.get_att_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.get_att_vectors"], ["def", "forward", "(", "self", ",", "contexts", ")", ":", "\n", "        ", "batch_n", ",", "seq_len", ",", "feature_n", "=", "contexts", ".", "size", "(", ")", "\n", "att_weights", ",", "att_vectors", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "entity", "=", "contexts", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "weights", "=", "self", ".", "get_att_weights", "(", "entity", ",", "contexts", ")", "# batch_n, seq_len,", "\n", "vectors", "=", "self", ".", "get_att_vectors", "(", "weights", ",", "contexts", ")", "# batch_n, feature_dim", "\n", "# print (weigths.size(), vectors.size())", "\n", "# att_weights.append(weights)", "\n", "att_vectors", ".", "append", "(", "vectors", ")", "\n", "# att_weights = torch.stack(att_weights, 1)", "\n", "", "att_vectors", "=", "torch", ".", "stack", "(", "att_vectors", ",", "1", ")", "\n", "return", "att_vectors", "\n", "# return att_vectors, att_weights", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.self_attention_layer.SelfAttentionComponent.get_att_vectors": [[73, 77], ["torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "get_att_vectors", "(", "self", ",", "att_weights", ",", "contexts", ")", ":", "\n", "        ", "rets", "=", "torch", ".", "mul", "(", "contexts", ",", "att_weights", ")", "\n", "att_vectors", "=", "torch", ".", "sum", "(", "rets", ",", "1", ")", "\n", "return", "att_vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.self_attention_layer.SelfAttentionComponent.get_att_weights": [[82, 92], ["entities.size", "contexts.size", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.score_func", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.score_func"], ["def", "get_att_weights", "(", "self", ",", "entities", ",", "contexts", ")", ":", "\n", "        ", "batch_n", ",", "token_n", ",", "feature_n", "=", "entities", ".", "size", "(", ")", "\n", "batch_n_c", ",", "token_n_c", ",", "feature_n_c", "=", "contexts", ".", "size", "(", ")", "\n", "assert", "(", "batch_n", "==", "batch_n_c", "and", "feature_n", "==", "feature_n_c", ")", "\n", "assert", "(", "token_n", "==", "1", "or", "token_n", "==", "token_n_c", ")", "\n", "assert", "(", "feature_n", "==", "self", ".", "input_dim", ")", "\n", "# self_att = token_n == token_n_c", "\n", "scores", "=", "self", ".", "score_func", "(", "entities", ",", "contexts", ")", "# (bn * tn) * dec_units", "\n", "att_weights", "=", "F", ".", "softmax", "(", "scores", ",", "1", ")", "\n", "return", "att_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.self_attention_layer.SelfAttentionComponent.score_func": [[93, 120], ["hs.size", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.W1", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.W2", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.V().view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "Exception", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.W", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "ht.size", "ht.size", "hs.size", "self_attention_layer.SelfAttentionComponent.SelfAttentionComponent.V", "ht.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Exception", "ht.transpose"], "methods", ["None"], ["", "def", "score_func", "(", "self", ",", "ht", ",", "hs", ")", ":", "\n", "        ", "if", "self", ".", "score_type", "==", "'bahdanau'", ":", "\n", "            ", "batch_n_c", ",", "token_n_c", ",", "feature_n_c", "=", "hs", ".", "size", "(", ")", "\n", "rc", "=", "self", ".", "W1", "(", "hs", ")", "\n", "re", "=", "self", ".", "W2", "(", "ht", ")", "\n", "if", "ht", ".", "size", "(", "1", ")", "==", "1", "or", "ht", ".", "size", "(", "1", ")", "==", "hs", ".", "size", "(", "1", ")", ":", "\n", "                ", "score", "=", "torch", ".", "tanh", "(", "rc", "+", "re", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"score func else\"", ")", "\n", "# batch_n = hs.size(0)", "\n", "# scores = []", "\n", "# for i in range(batch_n):", "\n", "#     score = torch.tanh(rc[i] + re[i])", "\n", "#     scores.append(score)", "\n", "# score = torch.cat(scores)", "\n", "", "score", "=", "self", ".", "V", "(", "score", ")", ".", "view", "(", "batch_n_c", ",", "token_n_c", ",", "1", ")", "\n", "# score = self.V(score)", "\n", "", "elif", "self", ".", "score_type", "==", "'luong'", ":", "\n", "# Todo:fix", "\n", "            ", "score", "=", "self", ".", "W", "(", "hs", ")", "\n", "score", "=", "torch", ".", "matmul", "(", "score", ",", "ht", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "# score = torch.mul(ht.view(1, -1), self.W1(hs))", "\n", "", "elif", "self", ".", "score_type", "==", "'dot'", ":", "\n", "            ", "score", "=", "torch", ".", "matmul", "(", "hs", ",", "ht", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'not support score function type'", ")", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.train.evaluate": [[18, 60], ["model.eval", "len", "len", "torch.no_grad", "torch.no_grad", "len", "open", "range", "open.close", "print", "metric.fmeasure_from_singlefile", "torch.tensor().to", "torch.tensor().to", "sentence.unsqueeze.unsqueeze", "torch.ones().byte().cuda", "torch.ones().byte().cuda", "model", "isinstance", "py.append", "len", "len", "len", "range", "open.write", "os.remove", "model.module.crf.forward", "model.crf.forward", "tag.item", "len", "len", "open.write", "torch.tensor", "torch.tensor", "torch.ones().byte", "torch.ones().byte", "torch.ones", "torch.ones", "sentence.unsqueeze.size"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.fmeasure_from_singlefile", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], ["def", "evaluate", "(", "model", ",", "tx", ",", "ty", ",", "id2tag", ",", "name", "=", "''", ",", "base_path", "=", "None", ",", "is_test", "=", "False", ",", "type", "=", "\"test\"", ",", "is_weibo", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "assert", "len", "(", "tx", ")", "==", "len", "(", "ty", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "py", "=", "[", "]", "\n", "for", "sentence", "in", "tx", ":", "\n", "# sentence = torch.tensor(sentence, dtype=torch.long, requires_grad=False).cuda()", "\n", "            ", "sentence", "=", "torch", ".", "tensor", "(", "sentence", ",", "dtype", "=", "torch", ".", "long", ",", "requires_grad", "=", "False", ")", ".", "to", "(", "device", ")", "\n", "sentence", "=", "sentence", ".", "unsqueeze", "(", "0", ")", "\n", "mask", "=", "torch", ".", "ones", "(", "(", "1", ",", "sentence", ".", "size", "(", "1", ")", ")", ")", ".", "byte", "(", ")", ".", "cuda", "(", ")", "\n", "feats", "=", "model", "(", "sentence", ",", "mask", ")", "\n", "if", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "parallel", ".", "DataParallel", ")", ":", "\n", "                ", "ret", "=", "model", ".", "module", ".", "crf", ".", "forward", "(", "feats", ",", "mask", ")", "\n", "", "else", ":", "\n", "                ", "ret", "=", "model", ".", "crf", ".", "forward", "(", "feats", ",", "mask", ")", "\n", "\n", "", "tags", "=", "[", "tag", ".", "item", "(", ")", "for", "tag", "in", "ret", "[", "1", "]", "[", "0", "]", "]", "\n", "py", ".", "append", "(", "tags", ")", "\n", "\n", "", "assert", "len", "(", "py", ")", "==", "len", "(", "ty", ")", "\n", "n", "=", "len", "(", "py", ")", "\n", "evalname", "=", "name", "+", "'.'", "+", "type", "+", "'.eval'", "\n", "fout", "=", "open", "(", "base_path", "+", "\"/\"", "+", "evalname", ",", "'w'", ",", "encoding", "=", "'utf8'", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "pi", "=", "py", "[", "i", "]", "\n", "ti", "=", "ty", "[", "i", "]", "\n", "assert", "len", "(", "pi", ")", "==", "len", "(", "ti", ")", "\n", "k", "=", "len", "(", "pi", ")", "\n", "for", "j", "in", "range", "(", "k", ")", ":", "\n", "                ", "idx", "=", "pi", "[", "j", "]", "\n", "if", "idx", "not", "in", "id2tag", ":", "\n", "                    ", "idx", "=", "0", "\n", "", "fout", ".", "write", "(", "id2tag", "[", "idx", "]", "+", "' '", "+", "id2tag", "[", "ti", "[", "j", "]", "]", "+", "'\\n'", ")", "\n", "", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n", "", "fout", ".", "close", "(", ")", "\n", "print", "(", "'eval '", "+", "evalname", ")", "\n", "F", "=", "fmeasure_from_singlefile", "(", "base_path", "+", "\"/\"", "+", "evalname", ",", "\"BMES\"", ",", "base_path", "=", "base_path", ",", "is_test", "=", "is_test", ",", "type", "=", "type", ",", "is_weibo", "=", "is_weibo", ")", "\n", "# \u4e2d\u95f4\u7ed3\u679c", "\n", "if", "is_test", ":", "\n", "            ", "os", ".", "remove", "(", "base_path", "+", "\"/\"", "+", "evalname", ")", "\n", "", "return", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.acnn.ACNN.__init__": [[10, 61], ["torch.Module.__init__", "attention_layer.AttentionComponent", "attention_layer.AttentionComponent", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "util.init_linear_", "util.init_linear_", "util.init_linear_", "util.init_linear_", "util.init_linear_", "util.init_linear_"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_"], ["    ", "def", "__init__", "(", "self", ",", "feature_dim", ",", "hidden_dim", ",", "window_size", "=", "5", ",", "use_cnn", "=", "True", ",", "use_bias", "=", "True", ",", "\n", "cat_self", "=", "False", ",", "pos_info", "=", "False", ",", "att_type", "=", "'bahdanau'", ",", "reset_para", "=", "False", ")", ":", "\n", "        ", "super", "(", "ACNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "window_size", "=", "window_size", "\n", "assert", "window_size", "%", "2", "==", "1", "\n", "self", ".", "padding", "=", "self", ".", "window_size", "//", "2", "\n", "self", ".", "feature_dim", "=", "feature_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "use_cnn", "=", "use_cnn", "\n", "self", ".", "cat_self", "=", "cat_self", "\n", "self", ".", "pos_info", "=", "pos_info", "\n", "\n", "if", "pos_info", ":", "\n", "            ", "new_feature_dim", "=", "self", ".", "feature_dim", "+", "self", ".", "window_size", "\n", "self", ".", "attc", "=", "AttentionComponent", "(", "self", ".", "hidden_dim", ",", "new_feature_dim", ",", "att_type", ",", "use_bias", ",", "reset_para", ")", "\n", "if", "use_cnn", ":", "\n", "                ", "self", ".", "cnn", "=", "nn", ".", "Linear", "(", "new_feature_dim", "*", "self", ".", "window_size", ",", "self", ".", "hidden_dim", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                    ", "util", ".", "init_linear_", "(", "self", ".", "cnn", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "new_feature_dim", ",", "self", ".", "hidden_dim", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                    ", "util", ".", "init_linear_", "(", "self", ".", "linear", ")", "\n", "\n", "", "", "if", "self", ".", "cat_self", ":", "\n", "                ", "if", "self", ".", "use_cnn", ":", "\n", "                    ", "int_features", "=", "new_feature_dim", "+", "self", ".", "hidden_dim", "\n", "", "else", ":", "\n", "                    ", "int_features", "=", "new_feature_dim", "*", "2", "\n", "", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "int_features", ",", "self", ".", "hidden_dim", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                    ", "util", ".", "init_linear_", "(", "self", ".", "linear", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "attc", "=", "AttentionComponent", "(", "self", ".", "hidden_dim", ",", "self", ".", "feature_dim", ")", "\n", "if", "use_cnn", ":", "\n", "                ", "self", ".", "cnn", "=", "nn", ".", "Linear", "(", "self", ".", "feature_dim", "*", "self", ".", "window_size", ",", "self", ".", "hidden_dim", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                    ", "util", ".", "init_linear_", "(", "self", ".", "cnn", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "hidden_dim", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                    ", "util", ".", "init_linear_", "(", "self", ".", "cnn", ")", "\n", "", "", "if", "self", ".", "cat_self", ":", "\n", "                ", "if", "self", ".", "use_cnn", ":", "\n", "                    ", "int_features", "=", "self", ".", "feature_dim", "+", "self", ".", "hidden_dim", "\n", "", "else", ":", "\n", "                    ", "int_features", "=", "self", ".", "feature_dim", "*", "2", "\n", "", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "int_features", ",", "self", ".", "hidden_dim", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                    ", "util", ".", "init_linear_", "(", "self", ".", "cnn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.acnn.ACNN.forward": [[62, 96], ["embeds_output.size", "acnn.ACNN.getConvEmbeds().transpose", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "acnn.ACNN.view", "contexts[].unsqueeze", "embeds_output.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "acnn.ACNN.linear", "acnn.ACNN.getConvEmbeds", "acnn.ACNN.attc.get_att_weights", "torch.mul().reshape", "torch.mul().reshape", "torch.mul().reshape", "torch.mul().reshape", "acnn.ACNN.cnn", "torch.cat.append", "torch.cat.append", "acnn.ACNN.attc.forward", "torch.cat.append", "torch.cat.append", "embeds_output.contiguous", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.acnn.ACNN.getConvEmbeds", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.get_att_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], ["", "", "", "", "def", "forward", "(", "self", ",", "embeds_output", ")", ":", "\n", "        ", "batch_n", ",", "seq_len", ",", "feature_dim", "=", "embeds_output", ".", "size", "(", ")", "\n", "\n", "conv_embeds", "=", "self", ".", "getConvEmbeds", "(", "embeds_output", "[", ":", "]", ")", ".", "transpose", "(", "3", ",", "2", ")", "\n", "\n", "# batch, seq_len, features, windows", "\n", "context_cnn_out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "contexts", "=", "conv_embeds", "[", ":", ",", "i", ",", ":", ",", ":", "]", "\n", "entity", "=", "contexts", "[", ":", ",", "self", ".", "padding", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "if", "self", ".", "use_cnn", ":", "\n", "                ", "att_weigths", "=", "self", ".", "attc", ".", "get_att_weights", "(", "entity", ",", "contexts", ")", "\n", "att_context", "=", "torch", ".", "mul", "(", "att_weigths", ",", "contexts", ")", ".", "reshape", "(", "batch_n", ",", "-", "1", ")", "\n", "# att_context = torch.mul(att_weigths, contexts).view(batch_n, -1)", "\n", "\n", "# .view(batch_n, self.feature_dim * self.window_size)", "\n", "cnn_out", "=", "self", ".", "cnn", "(", "att_context", ")", "\n", "context_cnn_out", ".", "append", "(", "cnn_out", ")", "\n", "", "else", ":", "\n", "                ", "att_context", ",", "_", "=", "self", ".", "attc", ".", "forward", "(", "entity", ",", "contexts", ")", "\n", "context_cnn_out", ".", "append", "(", "att_context", ")", "\n", "", "", "context_cnn_out", "=", "torch", ".", "stack", "(", "context_cnn_out", ",", "1", ")", "# batch_n, seq_len,", "\n", "\n", "if", "self", ".", "cat_self", ":", "\n", "            ", "entities", "=", "embeds_output", ".", "contiguous", "(", ")", ".", "view", "(", "batch_n", ",", "seq_len", ",", "feature_dim", ")", "\n", "context_cnn_out", "=", "torch", ".", "cat", "(", "(", "context_cnn_out", ",", "entities", ")", ",", "2", ")", "\n", "\n", "", "if", "self", ".", "use_cnn", "and", "not", "self", ".", "cat_self", ":", "\n", "            ", "att_out", "=", "context_cnn_out", "\n", "", "else", ":", "\n", "            ", "att_out", "=", "self", ".", "linear", "(", "context_cnn_out", ")", "# batch * seq_len, hidden_dim", "\n", "\n", "", "att_out", "=", "att_out", ".", "view", "(", "batch_n", ",", "seq_len", ",", "self", ".", "hidden_dim", ")", "\n", "return", "att_out", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.acnn.ACNN.getConvEmbeds": [[97, 121], ["torch.cat.size", "torch.cat.size", "range", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "acnn.ACNN.padding_vector", "pad.expand.expand.view", "pad.expand.expand.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack.append", "torch.stack.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "pos.expand.expand.expand", "pos.expand.expand.to", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.acnn.ACNN.padding_vector"], ["", "def", "getConvEmbeds", "(", "self", ",", "embeds_output", ")", ":", "\n", "        ", "batch_n", ",", "seq_len", ",", "feature_dim", "=", "embeds_output", ".", "size", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "padding", ")", ":", "\n", "            ", "pad", "=", "self", ".", "padding_vector", "(", "self", ".", "feature_dim", ")", "\n", "pad", "=", "pad", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "pad", "=", "pad", ".", "expand", "(", "batch_n", ",", "1", ",", "self", ".", "feature_dim", ")", "\n", "embeds_output", "=", "torch", ".", "cat", "(", "[", "pad", ",", "embeds_output", ",", "pad", "]", ",", "1", ")", "\n", "\n", "", "conv_out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "window_size", ")", ":", "\n", "            ", "ed", "=", "i", "+", "seq_len", "\n", "out", "=", "embeds_output", "[", ":", ",", "i", ":", "ed", ",", ":", "]", "\n", "if", "self", ".", "pos_info", ":", "\n", "                ", "pos", "=", "torch", ".", "zeros", "(", "seq_len", ",", "self", ".", "window_size", ")", "\n", "pos", "[", ":", ",", "i", "]", "=", "1", "\n", "# for i in range(self.window_size):", "\n", "#     pos[i][i] = 1", "\n", "pos", "=", "pos", ".", "expand", "(", "batch_n", ",", "seq_len", ",", "self", ".", "window_size", ")", "\n", "pos", ".", "to", "(", "device", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "out", ",", "pos", ")", ",", "2", ")", "\n", "\n", "", "conv_out", ".", "append", "(", "out", ")", "\n", "", "conv_out", "=", "torch", ".", "stack", "(", "conv_out", ",", "3", ")", "\n", "return", "conv_out", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.acnn.ACNN.padding_vector": [[122, 126], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros.to", "torch.zeros.to"], "methods", ["None"], ["", "def", "padding_vector", "(", "self", ",", "dim", ")", ":", "\n", "        ", "v", "=", "torch", ".", "zeros", "(", "dim", ")", "\n", "v", ".", "to", "(", "device", ")", "\n", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.__init__": [[9, 28], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "util.init_linear_", "util.init_linear_", "util.init_linear_", "torch.Linear", "torch.Linear", "torch.Linear", "util.init_linear_"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_"], ["    ", "def", "__init__", "(", "self", ",", "dec_units", ",", "input_dim", ",", "score_type", "=", "'bahdanau'", ",", "use_bias", "=", "True", ",", "reset_para", "=", "False", ")", ":", "\n", "        ", "super", "(", "AttentionComponent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "score_type", "=", "score_type", "\n", "self", ".", "dec_units", "=", "dec_units", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "\n", "if", "self", ".", "score_type", "==", "'bahdanau'", ":", "\n", "            ", "self", ".", "W1", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "dec_units", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "dec_units", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "V", "=", "nn", ".", "Linear", "(", "self", ".", "dec_units", ",", "1", ",", "bias", "=", "use_bias", ")", "\n", "if", "reset_para", ":", "\n", "                ", "util", ".", "init_linear_", "(", "self", ".", "W1", ")", "\n", "util", ".", "init_linear_", "(", "self", ".", "W2", ")", "\n", "util", ".", "init_linear_", "(", "self", ".", "V", ")", "\n", "\n", "", "", "elif", "self", ".", "score_type", "==", "'luong'", ":", "\n", "            ", "self", ".", "W", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "input_dim", ")", "\n", "if", "reset_para", ":", "\n", "                ", "util", ".", "init_linear_", "(", "self", ".", "W", ")", "\n", "# self.W = nn.Linear(self.input_dim,self.input_dim)", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.forward": [[36, 41], ["entities.size", "attention_layer.AttentionComponent.get_att_weights", "attention_layer.AttentionComponent.get_att_vectors"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.get_att_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.get_att_vectors"], ["def", "forward", "(", "self", ",", "entities", ",", "contexts", ")", ":", "\n", "        ", "batch_n", ",", "token_n", ",", "feature_n", "=", "entities", ".", "size", "(", ")", "\n", "att_weights", "=", "self", ".", "get_att_weights", "(", "entities", ",", "contexts", ")", "\n", "att_vectors", "=", "self", ".", "get_att_vectors", "(", "att_weights", ",", "contexts", ")", "\n", "return", "att_vectors", ",", "att_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.get_att_vectors": [[42, 46], ["torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "get_att_vectors", "(", "self", ",", "att_weights", ",", "contexts", ")", ":", "\n", "        ", "rets", "=", "torch", ".", "mul", "(", "contexts", ",", "att_weights", ")", "\n", "att_vectors", "=", "torch", ".", "sum", "(", "rets", ",", "1", ")", "\n", "return", "att_vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.get_att_weights": [[47, 58], ["entities.size", "contexts.size", "attention_layer.AttentionComponent.score_func", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.score_func"], ["", "def", "get_att_weights", "(", "self", ",", "entities", ",", "contexts", ")", ":", "\n", "        ", "batch_n", ",", "token_n", ",", "feature_n", "=", "entities", ".", "size", "(", ")", "\n", "batch_n_c", ",", "token_n_c", ",", "feature_n_c", "=", "contexts", ".", "size", "(", ")", "\n", "assert", "(", "batch_n", "==", "batch_n_c", "and", "feature_n", "==", "feature_n_c", ")", "\n", "assert", "(", "token_n", "==", "1", "or", "token_n", "==", "token_n_c", ")", "\n", "assert", "(", "feature_n", "==", "self", ".", "input_dim", ")", "\n", "self_att", "=", "token_n", "==", "token_n_c", "\n", "\n", "scores", "=", "self", ".", "score_func", "(", "entities", ",", "contexts", ")", "# (bn * tn) * dec_units", "\n", "att_weights", "=", "F", ".", "softmax", "(", "scores", ",", "1", ")", "\n", "return", "att_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.attention_layer.AttentionComponent.score_func": [[59, 87], ["hs.size", "attention_layer.AttentionComponent.W1", "attention_layer.AttentionComponent.W2", "attention_layer.AttentionComponent.V().view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "Exception", "attention_layer.AttentionComponent.W", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "ht.size", "ht.size", "hs.size", "attention_layer.AttentionComponent.V", "ht.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Exception", "ht.transpose"], "methods", ["None"], ["", "def", "score_func", "(", "self", ",", "ht", ",", "hs", ")", ":", "\n", "        ", "if", "self", ".", "score_type", "==", "'bahdanau'", ":", "\n", "            ", "batch_n_c", ",", "token_n_c", ",", "feature_n_c", "=", "hs", ".", "size", "(", ")", "\n", "rc", "=", "self", ".", "W1", "(", "hs", ")", "\n", "re", "=", "self", ".", "W2", "(", "ht", ")", "\n", "if", "ht", ".", "size", "(", "1", ")", "==", "1", "or", "ht", ".", "size", "(", "1", ")", "==", "hs", ".", "size", "(", "1", ")", ":", "\n", "                ", "score", "=", "torch", ".", "tanh", "(", "rc", "+", "re", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"score func else\"", ")", "\n", "# batch_n = hs.size(0)", "\n", "# scores = []", "\n", "# for i in range(batch_n):", "\n", "#     score = torch.tanh(rc[i] + re[i])", "\n", "#     scores.append(score)", "\n", "# score = torch.cat(scores)", "\n", "", "score", "=", "self", ".", "V", "(", "score", ")", ".", "view", "(", "batch_n_c", ",", "token_n_c", ",", "1", ")", "\n", "# score = self.V(score)", "\n", "", "elif", "self", ".", "score_type", "==", "'luong'", ":", "\n", "# Todo:fix", "\n", "            ", "score", "=", "self", ".", "W", "(", "hs", ")", "\n", "score", "=", "torch", ".", "matmul", "(", "score", ",", "ht", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "# score = torch.mul(ht.view(1, -1), self.W1(hs))", "\n", "", "elif", "self", ".", "score_type", "==", "'dot'", ":", "\n", "            ", "score", "=", "torch", ".", "matmul", "(", "hs", ",", "ht", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'not support score function type'", ")", "\n", "\n", "", "return", "score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure": [[8, 54], ["len", "range", "len", "len", "len", "print", "range", "len", "list", "len", "metric.get_ner_BMES", "metric.get_ner_BMES", "metric.get_ner_BIO", "metric.get_ner_BIO", "set().intersection", "set", "set"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BMES", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BMES", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BIO", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BIO"], ["def", "get_ner_fmeasure", "(", "golden_lists", ",", "predict_lists", ",", "label_type", "=", "\"BMES\"", ")", ":", "\n", "    ", "sent_num", "=", "len", "(", "golden_lists", ")", "\n", "golden_full", "=", "[", "]", "\n", "predict_full", "=", "[", "]", "\n", "right_full", "=", "[", "]", "\n", "right_tag", "=", "0", "\n", "all_tag", "=", "0", "\n", "for", "idx", "in", "range", "(", "0", ",", "sent_num", ")", ":", "\n", "# word_list = sentence_lists[idx]", "\n", "        ", "golden_list", "=", "golden_lists", "[", "idx", "]", "\n", "predict_list", "=", "predict_lists", "[", "idx", "]", "\n", "for", "idy", "in", "range", "(", "len", "(", "golden_list", ")", ")", ":", "\n", "            ", "if", "golden_list", "[", "idy", "]", "==", "predict_list", "[", "idy", "]", ":", "\n", "                ", "right_tag", "+=", "1", "\n", "", "", "all_tag", "+=", "len", "(", "golden_list", ")", "\n", "if", "label_type", "==", "\"BMES\"", ":", "\n", "            ", "gold_matrix", "=", "get_ner_BMES", "(", "golden_list", ")", "\n", "pred_matrix", "=", "get_ner_BMES", "(", "predict_list", ")", "\n", "", "else", ":", "\n", "            ", "gold_matrix", "=", "get_ner_BIO", "(", "golden_list", ")", "\n", "pred_matrix", "=", "get_ner_BIO", "(", "predict_list", ")", "\n", "# print \"gold\", gold_matrix", "\n", "# print \"pred\", pred_matrix", "\n", "", "right_ner", "=", "list", "(", "set", "(", "gold_matrix", ")", ".", "intersection", "(", "set", "(", "pred_matrix", ")", ")", ")", "\n", "golden_full", "+=", "gold_matrix", "\n", "predict_full", "+=", "pred_matrix", "\n", "right_full", "+=", "right_ner", "\n", "", "right_num", "=", "len", "(", "right_full", ")", "\n", "golden_num", "=", "len", "(", "golden_full", ")", "\n", "predict_num", "=", "len", "(", "predict_full", ")", "\n", "if", "predict_num", "==", "0", ":", "\n", "        ", "precision", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "precision", "=", "(", "right_num", "+", "0.0", ")", "/", "predict_num", "\n", "", "if", "golden_num", "==", "0", ":", "\n", "        ", "recall", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "recall", "=", "(", "right_num", "+", "0.0", ")", "/", "golden_num", "\n", "", "if", "(", "precision", "==", "-", "1", ")", "or", "(", "recall", "==", "-", "1", ")", "or", "(", "precision", "+", "recall", ")", "<=", "0.", ":", "\n", "        ", "f_measure", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "f_measure", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "", "accuracy", "=", "(", "right_tag", "+", "0.0", ")", "/", "all_tag", "\n", "# print \"Accuracy: \", right_tag,\"/\",all_tag,\"=\",accuracy", "\n", "print", "(", "\"gold_num = \"", ",", "golden_num", ",", "\" pred_num = \"", ",", "predict_num", ",", "\" right_num = \"", ",", "right_num", ")", "\n", "return", "accuracy", ",", "precision", ",", "recall", ",", "f_measure", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.reverse_style": [[56, 61], ["input_string.index", "len"], "function", ["None"], ["", "def", "reverse_style", "(", "input_string", ")", ":", "\n", "    ", "target_position", "=", "input_string", ".", "index", "(", "'['", ")", "\n", "input_len", "=", "len", "(", "input_string", ")", "\n", "output_string", "=", "input_string", "[", "target_position", ":", "input_len", "]", "+", "input_string", "[", "0", ":", "target_position", "]", "\n", "return", "output_string", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BMES": [[63, 108], ["len", "range", "len", "range", "label_list[].upper", "tag_list.append", "label_list[].upper.replace", "len", "metric.reverse_style", "stand_matrix.append", "tag_list.append", "str", "tag_list.append", "label_list[].upper.replace", "tag_list.append", "str", "str", "label_list[].upper.replace", "tag_list.append", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.reverse_style"], ["", "def", "get_ner_BMES", "(", "label_list", ")", ":", "\n", "# list_len = len(word_list)", "\n", "# assert(list_len == len(label_list)), \"word list size unmatch with label list\"", "\n", "    ", "list_len", "=", "len", "(", "label_list", ")", "\n", "begin_label", "=", "'B-'", "\n", "end_label", "=", "'E-'", "\n", "single_label", "=", "'S-'", "\n", "whole_tag", "=", "''", "\n", "index_tag", "=", "''", "\n", "tag_list", "=", "[", "]", "\n", "stand_matrix", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "list_len", ")", ":", "\n", "# wordlabel = word_list[i]", "\n", "        ", "current_label", "=", "label_list", "[", "i", "]", ".", "upper", "(", ")", "\n", "if", "begin_label", "in", "current_label", ":", "\n", "            ", "if", "index_tag", "!=", "''", ":", "\n", "                ", "tag_list", ".", "append", "(", "whole_tag", "+", "','", "+", "str", "(", "i", "-", "1", ")", ")", "\n", "", "whole_tag", "=", "current_label", ".", "replace", "(", "begin_label", ",", "\"\"", ",", "1", ")", "+", "'['", "+", "str", "(", "i", ")", "\n", "index_tag", "=", "current_label", ".", "replace", "(", "begin_label", ",", "\"\"", ",", "1", ")", "\n", "\n", "", "elif", "single_label", "in", "current_label", ":", "\n", "            ", "if", "index_tag", "!=", "''", ":", "\n", "                ", "tag_list", ".", "append", "(", "whole_tag", "+", "','", "+", "str", "(", "i", "-", "1", ")", ")", "\n", "", "whole_tag", "=", "current_label", ".", "replace", "(", "single_label", ",", "\"\"", ",", "1", ")", "+", "'['", "+", "str", "(", "i", ")", "\n", "tag_list", ".", "append", "(", "whole_tag", ")", "\n", "whole_tag", "=", "\"\"", "\n", "index_tag", "=", "\"\"", "\n", "", "elif", "end_label", "in", "current_label", ":", "\n", "            ", "if", "index_tag", "!=", "''", ":", "\n", "                ", "tag_list", ".", "append", "(", "whole_tag", "+", "','", "+", "str", "(", "i", ")", ")", "\n", "", "whole_tag", "=", "''", "\n", "index_tag", "=", "''", "\n", "", "else", ":", "\n", "            ", "continue", "\n", "", "", "if", "(", "whole_tag", "!=", "''", ")", "&", "(", "index_tag", "!=", "''", ")", ":", "\n", "        ", "tag_list", ".", "append", "(", "whole_tag", ")", "\n", "", "tag_list_len", "=", "len", "(", "tag_list", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "tag_list_len", ")", ":", "\n", "        ", "if", "len", "(", "tag_list", "[", "i", "]", ")", ">", "0", ":", "\n", "            ", "tag_list", "[", "i", "]", "=", "tag_list", "[", "i", "]", "+", "']'", "\n", "insert_list", "=", "reverse_style", "(", "tag_list", "[", "i", "]", ")", "\n", "stand_matrix", ".", "append", "(", "insert_list", ")", "\n", "# print stand_matrix", "\n", "", "", "return", "stand_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BIO": [[110, 156], ["len", "range", "len", "range", "label_list[].upper", "tag_list.append", "len", "metric.reverse_style", "stand_matrix.append", "label_list[].upper.replace", "tag_list.append", "label_list[].upper.replace", "str", "str", "label_list[].upper.replace", "tag_list.append", "label_list[].upper.replace", "str", "label_list[].upper.replace", "tag_list.append", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.reverse_style"], ["", "def", "get_ner_BIO", "(", "label_list", ")", ":", "\n", "# list_len = len(word_list)", "\n", "# assert(list_len == len(label_list)), \"word list size unmatch with label list\"", "\n", "    ", "list_len", "=", "len", "(", "label_list", ")", "\n", "begin_label", "=", "'B-'", "\n", "inside_label", "=", "'I-'", "\n", "whole_tag", "=", "''", "\n", "index_tag", "=", "''", "\n", "tag_list", "=", "[", "]", "\n", "stand_matrix", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "list_len", ")", ":", "\n", "# wordlabel = word_list[i]", "\n", "        ", "current_label", "=", "label_list", "[", "i", "]", ".", "upper", "(", ")", "\n", "if", "begin_label", "in", "current_label", ":", "\n", "            ", "if", "index_tag", "==", "''", ":", "\n", "                ", "whole_tag", "=", "current_label", ".", "replace", "(", "begin_label", ",", "\"\"", ",", "1", ")", "+", "'['", "+", "str", "(", "i", ")", "\n", "index_tag", "=", "current_label", ".", "replace", "(", "begin_label", ",", "\"\"", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "tag_list", ".", "append", "(", "whole_tag", "+", "','", "+", "str", "(", "i", "-", "1", ")", ")", "\n", "whole_tag", "=", "current_label", ".", "replace", "(", "begin_label", ",", "\"\"", ",", "1", ")", "+", "'['", "+", "str", "(", "i", ")", "\n", "index_tag", "=", "current_label", ".", "replace", "(", "begin_label", ",", "\"\"", ",", "1", ")", "\n", "\n", "", "", "elif", "inside_label", "in", "current_label", ":", "\n", "            ", "if", "current_label", ".", "replace", "(", "inside_label", ",", "\"\"", ",", "1", ")", "==", "index_tag", ":", "\n", "                ", "whole_tag", "=", "whole_tag", "\n", "", "else", ":", "\n", "                ", "if", "(", "whole_tag", "!=", "''", ")", "&", "(", "index_tag", "!=", "''", ")", ":", "\n", "                    ", "tag_list", ".", "append", "(", "whole_tag", "+", "','", "+", "str", "(", "i", "-", "1", ")", ")", "\n", "", "whole_tag", "=", "''", "\n", "index_tag", "=", "''", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "whole_tag", "!=", "''", ")", "&", "(", "index_tag", "!=", "''", ")", ":", "\n", "                ", "tag_list", ".", "append", "(", "whole_tag", "+", "','", "+", "str", "(", "i", "-", "1", ")", ")", "\n", "", "whole_tag", "=", "''", "\n", "index_tag", "=", "''", "\n", "\n", "", "", "if", "(", "whole_tag", "!=", "''", ")", "&", "(", "index_tag", "!=", "''", ")", ":", "\n", "        ", "tag_list", ".", "append", "(", "whole_tag", ")", "\n", "", "tag_list_len", "=", "len", "(", "tag_list", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "tag_list_len", ")", ":", "\n", "        ", "if", "len", "(", "tag_list", "[", "i", "]", ")", ">", "0", ":", "\n", "            ", "tag_list", "[", "i", "]", "=", "tag_list", "[", "i", "]", "+", "']'", "\n", "insert_list", "=", "reverse_style", "(", "tag_list", "[", "i", "]", ")", "\n", "stand_matrix", ".", "append", "(", "insert_list", ")", "\n", "", "", "return", "stand_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.readSentence": [[158, 175], ["open().readlines", "open", "len", "sentences.append", "labels.append", "line.strip().split", "sentence.append", "label.append", "line.strip"], "function", ["None"], ["", "def", "readSentence", "(", "input_file", ")", ":", "\n", "    ", "in_lines", "=", "open", "(", "input_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "sentences", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "for", "line", "in", "in_lines", ":", "\n", "        ", "if", "len", "(", "line", ")", "<", "2", ":", "\n", "            ", "sentences", ".", "append", "(", "sentence", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "pair", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "' '", ")", "\n", "sentence", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "label", ".", "append", "(", "pair", "[", "-", "1", "]", ")", "\n", "", "", "return", "sentences", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.readTwoLabelSentence": [[177, 202], ["open().readlines", "open", "len", "sentences.append", "golden_labels.append", "predict_labels.append", "line.strip().split", "sentence.append", "golden_label.append", "predict_label.append", "line.strip"], "function", ["None"], ["", "def", "readTwoLabelSentence", "(", "input_file", ",", "truth_col", "=", "-", "1", ")", ":", "\n", "    ", "in_lines", "=", "open", "(", "input_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "sentences", "=", "[", "]", "\n", "predict_labels", "=", "[", "]", "\n", "golden_labels", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "predict_label", "=", "[", "]", "\n", "golden_label", "=", "[", "]", "\n", "for", "line", "in", "in_lines", ":", "\n", "        ", "if", "\"##score##\"", "in", "line", ":", "\n", "            ", "continue", "\n", "", "if", "len", "(", "line", ")", "<", "2", ":", "\n", "            ", "sentences", ".", "append", "(", "sentence", ")", "\n", "golden_labels", ".", "append", "(", "golden_label", ")", "\n", "predict_labels", ".", "append", "(", "predict_label", ")", "\n", "sentence", "=", "[", "]", "\n", "golden_label", "=", "[", "]", "\n", "predict_label", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "pair", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "' '", ")", "\n", "sentence", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "golden_label", ".", "append", "(", "pair", "[", "truth_col", "]", ")", "\n", "predict_label", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "\n", "", "", "return", "sentences", ",", "golden_labels", ",", "predict_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.weibo_readTwoLabelSentence": [[204, 241], ["open().readlines", "open", "len", "sentences.append", "golden_labels.append", "predict_labels.append", "line.strip().split", "sentence.append", "golden_label.append", "predict_label.append", "line.strip", "sentence.append", "predict_label.append", "sentence.append", "predict_label.append", "golden_label.append", "golden_label.append"], "function", ["None"], ["", "def", "weibo_readTwoLabelSentence", "(", "input_file", ",", "truth_col", "=", "-", "1", ",", "type", "=", "None", ")", ":", "\n", "    ", "in_lines", "=", "open", "(", "input_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "sentences", "=", "[", "]", "\n", "predict_labels", "=", "[", "]", "\n", "golden_labels", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "predict_label", "=", "[", "]", "\n", "golden_label", "=", "[", "]", "\n", "for", "line", "in", "in_lines", ":", "\n", "        ", "if", "\"##score##\"", "in", "line", ":", "\n", "            ", "continue", "\n", "", "if", "len", "(", "line", ")", "<", "2", ":", "\n", "            ", "sentences", ".", "append", "(", "sentence", ")", "\n", "golden_labels", ".", "append", "(", "golden_label", ")", "\n", "predict_labels", ".", "append", "(", "predict_label", ")", "\n", "sentence", "=", "[", "]", "\n", "golden_label", "=", "[", "]", "\n", "predict_label", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "pair", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "' '", ")", "\n", "if", "type", "!=", "None", ":", "\n", "                ", "if", "type", "in", "pair", "[", "0", "]", ":", "\n", "                    ", "sentence", ".", "append", "(", "'O'", ")", "\n", "predict_label", ".", "append", "(", "'O'", ")", "\n", "", "else", ":", "\n", "                    ", "sentence", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "predict_label", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "", "if", "type", "in", "pair", "[", "truth_col", "]", ":", "\n", "                    ", "golden_label", ".", "append", "(", "'O'", ")", "\n", "", "else", ":", "\n", "                    ", "golden_label", ".", "append", "(", "pair", "[", "truth_col", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "sentence", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "golden_label", ".", "append", "(", "pair", "[", "truth_col", "]", ")", "\n", "predict_label", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "\n", "", "", "", "return", "sentences", ",", "golden_labels", ",", "predict_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.fmeasure_from_file": [[243, 250], ["print", "print", "metric.readSentence", "metric.readSentence", "metric.get_ner_fmeasure", "print"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.readSentence", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.readSentence", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure"], ["", "def", "fmeasure_from_file", "(", "golden_file", ",", "predict_file", ",", "label_type", "=", "\"BMES\"", ")", ":", "\n", "    ", "print", "(", "\"Get f measure from file:\"", ",", "golden_file", ",", "predict_file", ")", "\n", "print", "(", "\"Label format:\"", ",", "label_type", ")", "\n", "golden_sent", ",", "golden_labels", "=", "readSentence", "(", "golden_file", ")", "\n", "predict_sent", ",", "predict_labels", "=", "readSentence", "(", "predict_file", ")", "\n", "acc", ",", "P", ",", "R", ",", "F", "=", "get_ner_fmeasure", "(", "golden_labels", ",", "predict_labels", ",", "label_type", ")", "\n", "print", "(", "\"Acc:%s, P:%s R:%s, F:%s\"", "%", "(", "acc", ",", "P", ",", "R", ",", "F", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.fmeasure_from_singlefile": [[252, 279], ["metric.weibo_readTwoLabelSentence", "metric.get_ner_fmeasure", "metric.print_helper", "print", "metric.weibo_readTwoLabelSentence", "metric.get_ner_fmeasure", "metric.print_helper", "print", "metric.weibo_readTwoLabelSentence", "metric.get_ner_fmeasure", "metric.print_helper", "print", "metric.readTwoLabelSentence", "metric.get_ner_fmeasure", "metric.print_helper", "print"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.weibo_readTwoLabelSentence", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.print_helper", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.weibo_readTwoLabelSentence", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.print_helper", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.weibo_readTwoLabelSentence", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.print_helper", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.readTwoLabelSentence", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.print_helper"], ["", "def", "fmeasure_from_singlefile", "(", "twolabel_file", ",", "label_type", "=", "\"BMES\"", ",", "truth_col", "=", "-", "1", ",", "base_path", "=", "None", ",", "is_test", "=", "False", ",", "type", "=", "\"test\"", ",", "\n", "is_weibo", "=", "False", ")", ":", "\n", "    ", "if", "is_weibo", ":", "\n", "        ", "sent", ",", "golden_labels", ",", "predict_labels", "=", "weibo_readTwoLabelSentence", "(", "twolabel_file", ",", "truth_col", ",", "\"NOM\"", ")", "\n", "acc", ",", "P", ",", "R", ",", "F", "=", "get_ner_fmeasure", "(", "golden_labels", ",", "predict_labels", ",", "label_type", ")", "\n", "print_helper", "(", "base_path", ",", "is_test", ",", "type", ",", "acc", ",", "P", ",", "R", ",", "F", ",", "suffix", "=", "\".NOM\"", ")", "\n", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ")", "\n", "\n", "sent", ",", "golden_labels", ",", "predict_labels", "=", "weibo_readTwoLabelSentence", "(", "twolabel_file", ",", "truth_col", ",", "\"NAM\"", ")", "\n", "acc", ",", "P", ",", "R", ",", "F", "=", "get_ner_fmeasure", "(", "golden_labels", ",", "predict_labels", ",", "label_type", ")", "\n", "print_helper", "(", "base_path", ",", "is_test", ",", "type", ",", "acc", ",", "P", ",", "R", ",", "F", ",", "suffix", "=", "\".NAM\"", ")", "\n", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ")", "\n", "\n", "sent", ",", "golden_labels", ",", "predict_labels", "=", "weibo_readTwoLabelSentence", "(", "twolabel_file", ",", "truth_col", ")", "\n", "acc", ",", "P", ",", "R", ",", "F", "=", "get_ner_fmeasure", "(", "golden_labels", ",", "predict_labels", ",", "label_type", ")", "\n", "print_helper", "(", "base_path", ",", "is_test", ",", "type", ",", "acc", ",", "P", ",", "R", ",", "F", ",", "suffix", "=", "\".all\"", ")", "\n", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ")", "\n", "\n", "return", "F", "\n", "", "else", ":", "\n", "        ", "sent", ",", "golden_labels", ",", "predict_labels", "=", "readTwoLabelSentence", "(", "twolabel_file", ",", "truth_col", ")", "\n", "\n", "acc", ",", "P", ",", "R", ",", "F", "=", "get_ner_fmeasure", "(", "golden_labels", ",", "predict_labels", ",", "label_type", ")", "\n", "print_helper", "(", "base_path", ",", "is_test", ",", "type", ",", "acc", ",", "P", ",", "R", ",", "F", ")", "\n", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ")", "\n", "\n", "return", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.print_helper": [[281, 294], ["print", "print", "print", "open", "open", "print", "open", "open"], "function", ["None"], ["", "", "def", "print_helper", "(", "base_path", ",", "is_test", ",", "type", ",", "acc", ",", "P", ",", "R", ",", "F", ",", "suffix", "=", "\"\"", ")", ":", "\n", "    ", "if", "is_test", ":", "\n", "        ", "if", "type", "==", "\"test\"", ":", "\n", "            ", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ",", "\n", "file", "=", "open", "(", "base_path", "+", "\"/test_eval_in_training\"", "+", "suffix", ",", "'a'", ")", ")", "\n", "", "elif", "type", "==", "\"dev\"", ":", "\n", "            ", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ",", "\n", "file", "=", "open", "(", "base_path", "+", "\"/dev_eval_in_training\"", "+", "suffix", ",", "'a'", ")", ")", "\n", "", "elif", "type", "==", "\"train\"", ":", "\n", "            ", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ",", "\n", "file", "=", "open", "(", "base_path", "+", "\"/train_eval_in_training\"", "+", "suffix", ",", "'a'", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"P:%s, R:%s, F:%s, ACC:%s\"", "%", "(", "P", ",", "R", ",", "F", ",", "acc", ")", ",", "file", "=", "open", "(", "base_path", "+", "\"/eval_results\"", "+", "suffix", ",", "'w+'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.fmeasure_from_singlefile_lengths": [[295, 302], ["metric.readTwoLabelSentence", "metric.get_ner_fmeasure_length", "print"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.readTwoLabelSentence", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure_length"], ["", "", "def", "fmeasure_from_singlefile_lengths", "(", "file", ",", "lengths", ",", "label_type", "=", "\"BMES\"", ",", "truth_col", "=", "-", "1", ")", ":", "\n", "    ", "sent", ",", "golden_labels", ",", "predict_labels", "=", "readTwoLabelSentence", "(", "file", ",", "truth_col", ")", "\n", "for", "length", "in", "lengths", ":", "\n", "# print(\"Length:%s\" % length)", "\n", "        ", "P", ",", "R", ",", "F", "=", "get_ner_fmeasure_length", "(", "golden_labels", ",", "predict_labels", ",", "length", ",", "label_type", ")", "\n", "# print_helper(base_path, is_test, type, acc, P, R, F)", "\n", "print", "(", "\"P:%s, R:%s, F:%s\"", "%", "(", "P", ",", "R", ",", "F", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_fmeasure_length": [[304, 354], ["len", "range", "len", "len", "len", "print", "list", "metric.get_ner_BMES", "metric.get_ner_BMES", "metric.get_ner_BIO", "metric.get_ner_BIO", "set().intersection", "metric.filter_length", "metric.filter_length", "set", "set"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BMES", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BMES", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BIO", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.get_ner_BIO", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.filter_length", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.filter_length"], ["", "", "def", "get_ner_fmeasure_length", "(", "golden_lists", ",", "predict_lists", ",", "length", ",", "label_type", "=", "\"BMES\"", ")", ":", "\n", "    ", "sent_num", "=", "len", "(", "golden_lists", ")", "\n", "golden_full", "=", "[", "]", "\n", "predict_full", "=", "[", "]", "\n", "right_full", "=", "[", "]", "\n", "right_tag", "=", "0", "\n", "all_tag", "=", "0", "\n", "for", "idx", "in", "range", "(", "0", ",", "sent_num", ")", ":", "\n", "# word_list = sentence_lists[idx]", "\n", "        ", "golden_list", "=", "golden_lists", "[", "idx", "]", "\n", "predict_list", "=", "predict_lists", "[", "idx", "]", "\n", "# for idy in range(len(golden_list)):", "\n", "#     if golden_list[idy] == predict_list[idy]:", "\n", "#         right_tag += 1", "\n", "# all_tag += len(golden_list)", "\n", "if", "label_type", "==", "\"BMES\"", ":", "\n", "            ", "gold_matrix", "=", "get_ner_BMES", "(", "golden_list", ")", "\n", "pred_matrix", "=", "get_ner_BMES", "(", "predict_list", ")", "\n", "", "else", ":", "\n", "            ", "gold_matrix", "=", "get_ner_BIO", "(", "golden_list", ")", "\n", "pred_matrix", "=", "get_ner_BIO", "(", "predict_list", ")", "\n", "# print \"gold\", gold_matrix", "\n", "# print \"pred\", pred_matrix", "\n", "", "gold_matrix", "=", "[", "x", "for", "x", "in", "gold_matrix", "if", "filter_length", "(", "x", ",", "length", ")", "]", "\n", "pred_matrix", "=", "[", "x", "for", "x", "in", "pred_matrix", "if", "filter_length", "(", "x", ",", "length", ")", "]", "\n", "\n", "right_ner", "=", "list", "(", "set", "(", "gold_matrix", ")", ".", "intersection", "(", "set", "(", "pred_matrix", ")", ")", ")", "\n", "golden_full", "+=", "gold_matrix", "\n", "predict_full", "+=", "pred_matrix", "\n", "right_full", "+=", "right_ner", "\n", "", "right_num", "=", "len", "(", "right_full", ")", "\n", "golden_num", "=", "len", "(", "golden_full", ")", "\n", "predict_num", "=", "len", "(", "predict_full", ")", "\n", "if", "predict_num", "==", "0", ":", "\n", "        ", "precision", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "precision", "=", "(", "right_num", "+", "0.0", ")", "/", "predict_num", "\n", "", "if", "golden_num", "==", "0", ":", "\n", "        ", "recall", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "recall", "=", "(", "right_num", "+", "0.0", ")", "/", "golden_num", "\n", "", "if", "(", "precision", "==", "-", "1", ")", "or", "(", "recall", "==", "-", "1", ")", "or", "(", "precision", "+", "recall", ")", "<=", "0.", ":", "\n", "        ", "f_measure", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "f_measure", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "# accuracy = (right_tag + 0.0) / all_tag", "\n", "# print \"Accuracy: \", right_tag,\"/\",all_tag,\"=\",accuracy", "\n", "", "print", "(", "\"Length:\"", ",", "length", ",", "\"gold_num = \"", ",", "golden_num", ",", "\" pred_num = \"", ",", "predict_num", ",", "\" right_num = \"", ",", "right_num", ")", "\n", "# return accuracy, precision, recall, f_measure", "\n", "return", "precision", ",", "recall", ",", "f_measure", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.metric.filter_length": [[355, 382], ["isinstance", "matrix.index", "matrix.index", "matrix.index", "matrix.index", "matrix.index", "matrix.index", "int", "int", "int", "int"], "function", ["None"], ["", "def", "filter_length", "(", "matrix", ",", "length", ")", ":", "\n", "    ", "if", "isinstance", "(", "length", ",", "tuple", ")", ":", "\n", "        ", "range_s", "=", "length", "[", "0", "]", "\n", "range_e", "=", "length", "[", "1", "]", "\n", "start", "=", "matrix", ".", "index", "(", "\"[\"", ")", "\n", "if", "\",\"", "not", "in", "matrix", ":", "\n", "            ", "pred_len", "=", "1", "\n", "", "else", ":", "\n", "            ", "middle", "=", "matrix", ".", "index", "(", "\",\"", ")", "\n", "end", "=", "matrix", ".", "index", "(", "\"]\"", ")", "\n", "pred_len", "=", "int", "(", "matrix", "[", "middle", "+", "1", ":", "end", "]", ")", "-", "int", "(", "matrix", "[", "start", "+", "1", ":", "middle", "]", ")", "+", "1", "\n", "", "if", "pred_len", ">=", "range_s", "and", "pred_len", "<=", "range_e", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "", "", "else", ":", "\n", "        ", "start", "=", "matrix", ".", "index", "(", "\"[\"", ")", "\n", "if", "\",\"", "not", "in", "matrix", ":", "\n", "            ", "if", "length", "==", "1", ":", "\n", "                ", "return", "True", "\n", "", "", "else", ":", "\n", "            ", "middle", "=", "matrix", ".", "index", "(", "\",\"", ")", "\n", "end", "=", "matrix", ".", "index", "(", "\"]\"", ")", "\n", "if", "length", "!=", "int", "(", "matrix", "[", "middle", "+", "1", ":", "end", "]", ")", "-", "int", "(", "matrix", "[", "start", "+", "1", ":", "middle", "]", ")", "+", "1", ":", "\n", "                ", "return", "False", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.Token.__init__": [[23, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "start", ",", "end", ",", "text", ")", ":", "\n", "        ", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "self", ".", "length", "=", "end", "-", "start", "\n", "self", ".", "text", "=", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.MyDataset.__init__": [[131, 134], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "X", ",", "Y", ")", ":", "\n", "        ", "self", ".", "X", "=", "X", "\n", "self", ".", "Y", "=", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.MyDataset.__len__": [[135, 137], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.MyDataset.__getitem__": [[138, 142], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "X", "=", "self", ".", "X", "[", "index", "]", "\n", "Y", "=", "self", ".", "Y", "[", "index", "]", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.print_para": [[10, 15], ["model.named_children", "print", "module.named_parameters", "print"], "function", ["None"], ["def", "print_para", "(", "model", ")", ":", "\n", "    ", "for", "name", ",", "module", "in", "model", ".", "named_children", "(", ")", ":", "\n", "        ", "print", "(", "name", ")", "\n", "for", "name", ",", "param", "in", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "print", "(", "name", ",", "param", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.reset_seeds": [[16, 21], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "", "", "def", "reset_seeds", "(", "seed", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.print_tensor": [[29, 51], ["_tensor.size", "open", "mf.write", "mf.write", "len", "mf.write", "len", "mf.write", "len", "mf.write", "str", "c.item", "str", "b.item", "str", "a.item"], "function", ["None"], ["", "", "def", "print_tensor", "(", "_tensor", ",", "path", ")", ":", "\n", "    ", "shape", "=", "_tensor", ".", "size", "(", ")", "\n", "# print(\"[\", end=\"\", file=open(path, \"a\"))", "\n", "# if len(shape)==3:", "\n", "#     for a in _tensor:", "\n", "#         for b in a:", "\n", "#             for c in b:", "\n", "#                 print(c.item(),\",\",end=\"\",file=open(path,\"a\"))", "\n", "# elif len(shape)==2:", "\n", "#     for a in _tensor:", "\n", "#         for b in a:", "\n", "#             print(b.item(),\",\",end=\"\",file=open(path,\"a\"))", "\n", "# print(\"]\", file=open(path, \"a\"))", "\n", "with", "open", "(", "path", ",", "\"a\"", ")", "as", "mf", ":", "\n", "        ", "mf", ".", "write", "(", "\"[\"", ")", "\n", "if", "len", "(", "shape", ")", "==", "3", ":", "\n", "            ", "mf", ".", "write", "(", "\", \"", ".", "join", "(", "[", "str", "(", "c", ".", "item", "(", ")", ")", "for", "a", "in", "_tensor", "for", "b", "in", "a", "for", "c", "in", "b", "]", ")", ")", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "mf", ".", "write", "(", "\", \"", ".", "join", "(", "[", "str", "(", "b", ".", "item", "(", ")", ")", "for", "a", "in", "_tensor", "for", "b", "in", "a", "]", ")", ")", "\n", "", "elif", "len", "(", "shape", ")", "==", "1", ":", "\n", "            ", "mf", ".", "write", "(", "\", \"", ".", "join", "(", "[", "str", "(", "a", ".", "item", "(", ")", ")", "for", "a", "in", "_tensor", "]", ")", ")", "\n", "", "mf", ".", "write", "(", "\"]\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.init_weight_": [[52, 54], ["torch.kaiming_uniform_"], "function", ["None"], ["", "", "def", "init_weight_", "(", "weight", ")", ":", "\n", "    ", "init", ".", "kaiming_uniform_", "(", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.init_embedding_": [[55, 60], ["util.init_weight_"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["", "def", "init_embedding_", "(", "input_embedding", ")", ":", "\n", "    ", "\"\"\"\n    Initialize embedding\n    \"\"\"", "\n", "init_weight_", "(", "input_embedding", ".", "weight", ")", "\n", "# init.normal_(input_embedding.weight, 0, 0.1)", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.init_linear_": [[62, 76], ["util.init_weight_", "input_linear.bias.data.zero_"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["", "def", "init_linear_", "(", "input_linear", ")", ":", "\n", "    ", "\"\"\"\n    Initialize linear transformation\n    \"\"\"", "\n", "# init.normal_(input_linear.weight, mean=0, std=math.sqrt((1 - dropout) / in_features))", "\n", "# # init_weight_(input_linear.weight)", "\n", "# if input_linear.bias is not None:", "\n", "#     # input_linear.bias.data.zero_()", "\n", "#     init.constant_(input_linear.bias, 0)", "\n", "# # weight_norm(input_linear)", "\n", "\n", "init_weight_", "(", "input_linear", ".", "weight", ")", "\n", "if", "input_linear", ".", "bias", "is", "not", "None", ":", "\n", "        ", "input_linear", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.init_lstm_": [[77, 111], ["range", "eval", "util.init_weight_", "eval", "util.init_weight_", "range", "range", "eval", "util.init_weight_", "eval", "util.init_weight_", "eval", "eval.data.zero_", "eval", "eval.data.zero_", "range", "str", "str", "eval", "eval.data.zero_", "eval", "eval.data.zero_", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["", "", "def", "init_lstm_", "(", "input_lstm", ")", ":", "\n", "    ", "\"\"\"\n    Initialize lstm\n    \"\"\"", "\n", "for", "ind", "in", "range", "(", "0", ",", "input_lstm", ".", "num_layers", ")", ":", "\n", "        ", "weight", "=", "eval", "(", "'input_lstm.weight_ih_l'", "+", "str", "(", "ind", ")", ")", "\n", "init_weight_", "(", "weight", ")", "\n", "\n", "weight", "=", "eval", "(", "'input_lstm.weight_hh_l'", "+", "str", "(", "ind", ")", ")", "\n", "init_weight_", "(", "weight", ")", "\n", "", "if", "input_lstm", ".", "bidirectional", ":", "\n", "        ", "for", "ind", "in", "range", "(", "0", ",", "input_lstm", ".", "num_layers", ")", ":", "\n", "            ", "weight", "=", "eval", "(", "'input_lstm.weight_ih_l'", "+", "str", "(", "ind", ")", "+", "'_reverse'", ")", "\n", "init_weight_", "(", "weight", ")", "\n", "\n", "weight", "=", "eval", "(", "'input_lstm.weight_hh_l'", "+", "str", "(", "ind", ")", "+", "'_reverse'", ")", "\n", "init_weight_", "(", "weight", ")", "\n", "\n", "", "", "if", "input_lstm", ".", "bias", ":", "\n", "        ", "for", "ind", "in", "range", "(", "0", ",", "input_lstm", ".", "num_layers", ")", ":", "\n", "            ", "weight", "=", "eval", "(", "'input_lstm.bias_ih_l'", "+", "str", "(", "ind", ")", ")", "\n", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "weight", ".", "data", "[", "input_lstm", ".", "hidden_size", ":", "2", "*", "input_lstm", ".", "hidden_size", "]", "=", "1", "\n", "weight", "=", "eval", "(", "'input_lstm.bias_hh_l'", "+", "str", "(", "ind", ")", ")", "\n", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "weight", ".", "data", "[", "input_lstm", ".", "hidden_size", ":", "2", "*", "input_lstm", ".", "hidden_size", "]", "=", "1", "\n", "", "if", "input_lstm", ".", "bidirectional", ":", "\n", "            ", "for", "ind", "in", "range", "(", "0", ",", "input_lstm", ".", "num_layers", ")", ":", "\n", "                ", "weight", "=", "eval", "(", "'input_lstm.bias_ih_l'", "+", "str", "(", "ind", ")", "+", "'_reverse'", ")", "\n", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "weight", ".", "data", "[", "input_lstm", ".", "hidden_size", ":", "2", "*", "input_lstm", ".", "hidden_size", "]", "=", "1", "\n", "weight", "=", "eval", "(", "'input_lstm.bias_hh_l'", "+", "str", "(", "ind", ")", "+", "'_reverse'", ")", "\n", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "weight", ".", "data", "[", "input_lstm", ".", "hidden_size", ":", "2", "*", "input_lstm", ".", "hidden_size", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.init_cnn_": [[113, 120], ["util.init_weight_", "input_cnn.bias.data.zero_"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["", "", "", "", "def", "init_cnn_", "(", "input_cnn", ")", ":", "\n", "    ", "\"\"\"\n    Initialize cnn\n    \"\"\"", "\n", "init_weight_", "(", "input_cnn", ".", "weight", ")", "\n", "if", "input_cnn", ".", "bias", "is", "not", "None", ":", "\n", "        ", "input_cnn", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "# std = math.sqrt((4 * (1.0 - dropout)) / (kernel_size * in_channels))", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.util.collate_fn": [[143, 175], ["zip", "max", "len", "len", "torch.ones().bool", "torch.ones().bool", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.tensor.to", "torch.ones().bool.to", "len", "len", "range", "batches.append", "torch.tensor.append", "torch.ones", "torch.ones", "dt.append", "tags.append", "range", "dt[].append"], "function", ["None"], ["", "", "def", "collate_fn", "(", "seq_list", ")", ":", "\n", "    ", "batch_x", ",", "batch_y", "=", "zip", "(", "*", "seq_list", ")", "\n", "# (batch, tokens, features)", "\n", "batch_lens", "=", "[", "len", "(", "item", ")", "for", "item", "in", "batch_x", "]", "\n", "max_tokens", "=", "max", "(", "batch_lens", ")", "\n", "batch_n", "=", "len", "(", "batch_lens", ")", "\n", "feature_num", "=", "len", "(", "batch_x", "[", "0", "]", "[", "0", "]", ")", "\n", "\n", "# mask = torch.ones((batch_n, max_tokens)).byte()", "\n", "mask", "=", "torch", ".", "ones", "(", "(", "batch_n", ",", "max_tokens", ")", ")", ".", "bool", "(", ")", "\n", "batches", "=", "[", "]", "\n", "batch_tags", "=", "[", "]", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "batch_x", ")", ":", "\n", "        ", "dt", "=", "batch_x", "[", "i", "]", "[", ":", "]", "\n", "l", "=", "len", "(", "dt", ")", "\n", "tags", "=", "batch_y", "[", "i", "]", "[", ":", "]", "\n", "for", "j", "in", "range", "(", "max_tokens", "-", "l", ")", ":", "\n", "            ", "dt", ".", "append", "(", "[", "]", ")", "\n", "mask", "[", "i", ",", "j", "+", "l", "]", "=", "0", "\n", "tags", ".", "append", "(", "0", ")", "\n", "for", "k", "in", "range", "(", "feature_num", ")", ":", "\n", "                ", "dt", "[", "j", "+", "l", "]", ".", "append", "(", "0", ")", "\n", "", "", "batches", ".", "append", "(", "dt", ")", "\n", "batch_tags", ".", "append", "(", "tags", ")", "\n", "\n", "", "batch_data", "=", "torch", ".", "tensor", "(", "batches", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "batch_tags", "=", "torch", ".", "tensor", "(", "batch_tags", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "batch_data", ".", "to", "(", "device", ")", "\n", "batch_tags", ".", "to", "(", "device", ")", "\n", "mask", ".", "to", "(", "device", ")", "\n", "return", "batch_data", ",", "batch_tags", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.normalize_word": [[5, 13], ["char.isdigit"], "function", ["None"], ["def", "normalize_word", "(", "word", ")", ":", "\n", "    ", "new_word", "=", "\"\"", "\n", "for", "char", "in", "word", ":", "\n", "        ", "if", "char", ".", "isdigit", "(", ")", ":", "\n", "            ", "new_word", "+=", "'0'", "\n", "", "else", ":", "\n", "            ", "new_word", "+=", "char", "\n", "", "", "return", "new_word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.load_trainset_BIO": [[15, 63], ["f.read().rstrip.split", "open", "f.read().rstrip", "data_process.getTagIx", "r.split", "enumerate", "line.strip().split", "data_process.normalize_word", "f.read", "print", "len", "sent.append", "data_process.getDataFromSent_with_seg_test", "rs.append", "sent.append", "line.strip", "len", "lines[].split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.getTagIx", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.normalize_word", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.getDataFromSent_with_seg_test"], ["", "def", "load_trainset_BIO", "(", "name", ",", "word2id", ",", "corpusname", "=", "'onto4'", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "        ", "datas", "=", "f", ".", "read", "(", ")", ".", "rstrip", "(", ")", "\n", "", "sentences", "=", "datas", ".", "split", "(", "'\\n\\n'", ")", "\n", "\n", "rs", "=", "[", "]", "\n", "sent", "=", "[", "]", "\n", "tag2id", "=", "getTagIx", "(", "corpusname", ")", "[", "0", "]", "\n", "\n", "for", "r", "in", "sentences", ":", "\n", "        ", "lines", "=", "r", ".", "split", "(", "'\\n'", ")", "\n", "for", "index", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "word", "=", "text", "[", "0", "]", "[", "0", "]", "\n", "seg", "=", "text", "[", "0", "]", "[", "1", "]", "\n", "tag", "=", "text", "[", "1", "]", "\n", "word", "=", "normalize_word", "(", "word", ")", "\n", "if", "word", "not", "in", "word2id", ":", "\n", "                ", "word2id", "[", "word", "]", "=", "1", "\n", "", "if", "tag", "not", "in", "tag2id", ":", "\n", "                ", "print", "(", "tag", ")", "\n", "tag2id", "[", "tag", "]", "=", "len", "(", "tag2id", ")", "\n", "\n", "", "if", "index", "==", "len", "(", "lines", ")", "-", "1", ":", "\n", "                ", "if", "seg", "==", "\"0\"", ":", "\n", "                    ", "seg", "=", "4", "\n", "", "else", ":", "\n", "                    ", "seg", "=", "3", "\n", "", "sent", ".", "append", "(", "[", "word2id", "[", "word", "]", ",", "tag2id", "[", "tag", "]", ",", "seg", "]", ")", "\n", "ret", "=", "getDataFromSent_with_seg_test", "(", "sent", ")", "\n", "rs", ".", "append", "(", "ret", ")", "\n", "sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                ", "next_seg", "=", "lines", "[", "index", "+", "1", "]", ".", "split", "(", "\" \"", ")", "[", "0", "]", "[", "1", "]", "\n", "if", "seg", "==", "\"0\"", ":", "\n", "                    ", "if", "next_seg", "==", "\"0\"", ":", "\n", "                        ", "seg", "=", "4", "\n", "", "else", ":", "\n", "                        ", "seg", "=", "1", "\n", "", "", "else", ":", "\n", "                    ", "if", "next_seg", "==", "\"0\"", ":", "\n", "                        ", "seg", "=", "3", "\n", "", "else", ":", "\n", "                        ", "seg", "=", "2", "\n", "", "", "sent", ".", "append", "(", "[", "word2id", "[", "word", "]", ",", "tag2id", "[", "tag", "]", ",", "seg", "]", ")", "\n", "\n", "", "", "", "return", "rs", ",", "tag2id", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.load_embed": [[65, 132], ["enumerate", "print", "embs.append", "embs.append", "print", "embs.append", "open", "line.strip().split", "len", "embs.append", "numpy.array", "numpy.sqrt", "numpy.random.uniform", "numpy.random.uniform", "numpy.sqrt", "numpy.random.uniform", "numpy.random.uniform", "numpy.sqrt", "numpy.random.uniform", "print", "len", "word2id.keys", "print", "numpy.array", "numpy.sqrt", "numpy.random.uniform", "numpy.sqrt", "numpy.random.uniform", "line.strip", "len", "int", "int", "len", "len", "list", "map"], "function", ["None"], ["", "def", "load_embed", "(", "filename", ")", ":", "\n", "    ", "word2id", ",", "id2word", "=", "{", "}", ",", "{", "}", "\n", "\n", "embs", "=", "[", "]", "\n", "file_names", "=", "[", "\n", "\"./data/embeds\"", ",", "\n", "\"./data/embedding/embeds\"", ",", "\n", "\"./data/embedding/word2vec.sgns.weibo.onlychar\"", ",", "\n", "\"./data/embedding/fasttext.cc.zh.300.vec.onlychar\"", ",", "\n", "\"./data/embedding/glove.6B.100d.english.txt\"", ",", "\n", "\"./data/embedding/glove.6B.300d.english.txt\"", "]", "\n", "\n", "if", "filename", "in", "file_names", ":", "\n", "        ", "print", "(", "\"ADD UNK and PAD.....\"", ")", "\n", "word2id", "=", "{", "'<PAD>'", ":", "0", ",", "'<UNK>'", ":", "1", "}", "\n", "id2word", "=", "{", "0", ":", "'<PAD>'", ",", "1", ":", "'<UNK>'", "}", "\n", "# UNK not in vocab, we need to random a unk embedding", "\n", "# range(-1,1)", "\n", "if", "\"glove.6B.100d.english.txt\"", "in", "filename", ":", "\n", "# rand = (2 * np.random.random(100) - 1).astype(np.float32)", "\n", "            ", "scale", "=", "np", ".", "sqrt", "(", "6.0", "/", "100", ")", "\n", "UNK", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "100", ")", "\n", "PAD", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "100", ")", "\n", "", "else", ":", "\n", "            ", "scale", "=", "np", ".", "sqrt", "(", "6.0", "/", "300", ")", "\n", "UNK", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "300", ")", "\n", "PAD", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "300", ")", "\n", "\n", "", "embs", ".", "append", "(", "PAD", ")", "\n", "embs", ".", "append", "(", "UNK", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"ADD PAD.....\"", ")", "\n", "word2id", "=", "{", "'<PAD>'", ":", "0", "}", "\n", "id2word", "=", "{", "0", ":", "'<PAD>'", "}", "\n", "if", "filename", "==", "\"./data/embedding/ctb.50d.vec\"", ":", "\n", "            ", "scale", "=", "np", ".", "sqrt", "(", "6.0", "/", "50", ")", "\n", "PAD", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "50", ")", "\n", "", "elif", "filename", "==", "\"./data/embedding/word2vec.continuous.skipgram\"", ":", "\n", "            ", "scale", "=", "np", ".", "sqrt", "(", "6.0", "/", "50", ")", "\n", "PAD", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "100", ")", "\n", "", "else", ":", "\n", "            ", "scale", "=", "np", ".", "sqrt", "(", "6.0", "/", "300", ")", "\n", "PAD", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "300", ")", "\n", "", "embs", ".", "append", "(", "PAD", ")", "\n", "\n", "", "V", ",", "D", "=", "-", "1", ",", "-", "1", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "open", "(", "filename", ",", "encoding", "=", "'utf8'", ")", ")", ":", "\n", "        ", "if", "idx", "!=", "0", "and", "idx", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "'{} embs loaded'", ".", "format", "(", "idx", ")", ")", "\n", "\n", "", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "idx", "==", "0", "and", "len", "(", "line_split", ")", "==", "2", ":", "\n", "            ", "V", ",", "D", "=", "int", "(", "line_split", "[", "0", "]", ")", ",", "int", "(", "line_split", "[", "1", "]", ")", "\n", "continue", "\n", "", "if", "D", "==", "-", "1", ":", "\n", "            ", "D", "=", "len", "(", "line_split", ")", "-", "1", "\n", "", "if", "len", "(", "line_split", ")", "!=", "D", "+", "1", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "line_split", "[", "0", "]", "in", "word2id", ".", "keys", "(", ")", ":", "\n", "            ", "print", "(", "'line {}: {} already in vocab'", ".", "format", "(", "idx", "+", "1", ",", "line_split", "[", "0", "]", ")", ")", "\n", "continue", "\n", "", "word2id", "[", "line_split", "[", "0", "]", "]", "=", "len", "(", "word2id", ")", "\n", "id2word", "[", "len", "(", "id2word", ")", "]", "=", "line_split", "[", "0", "]", "\n", "embs", ".", "append", "(", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "line_split", "[", "1", ":", "]", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "", "return", "word2id", ",", "id2word", ",", "np", ".", "array", "(", "embs", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.load_testset_BIO": [[134, 182], ["f.read().rstrip.split", "open", "f.read().rstrip", "data_process.getTagIx", "r.split", "enumerate", "line.strip().split", "data_process.normalize_word", "f.read", "print", "len", "sent.append", "data_process.getDataFromSent_with_seg_test", "rs.append", "sent.append", "line.strip", "len", "lines[].split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.getTagIx", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.normalize_word", "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.getDataFromSent_with_seg_test"], ["", "def", "load_testset_BIO", "(", "name", ",", "word2id", ",", "corpusname", "=", "'onto4'", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "        ", "datas", "=", "f", ".", "read", "(", ")", ".", "rstrip", "(", ")", "\n", "", "sentences", "=", "datas", ".", "split", "(", "'\\n\\n'", ")", "\n", "\n", "rs", "=", "[", "]", "\n", "sent", "=", "[", "]", "\n", "tag2id", "=", "getTagIx", "(", "corpusname", ")", "[", "0", "]", "\n", "\n", "for", "r", "in", "sentences", ":", "\n", "        ", "lines", "=", "r", ".", "split", "(", "'\\n'", ")", "\n", "for", "index", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "word", "=", "text", "[", "0", "]", "[", "0", "]", "\n", "seg", "=", "text", "[", "0", "]", "[", "1", "]", "\n", "tag", "=", "text", "[", "1", "]", "\n", "word", "=", "normalize_word", "(", "word", ")", "\n", "if", "word", "not", "in", "word2id", ":", "\n", "                ", "word2id", "[", "word", "]", "=", "1", "\n", "", "if", "tag", "not", "in", "tag2id", ":", "\n", "                ", "print", "(", "tag", ")", "\n", "tag2id", "[", "tag", "]", "=", "len", "(", "tag2id", ")", "\n", "\n", "", "if", "index", "==", "len", "(", "lines", ")", "-", "1", ":", "\n", "                ", "if", "seg", "==", "\"0\"", ":", "\n", "                    ", "seg", "=", "4", "\n", "", "else", ":", "\n", "                    ", "seg", "=", "3", "\n", "", "sent", ".", "append", "(", "[", "word2id", "[", "word", "]", ",", "tag2id", "[", "tag", "]", ",", "seg", "]", ")", "\n", "ret", "=", "getDataFromSent_with_seg_test", "(", "sent", ")", "\n", "rs", ".", "append", "(", "ret", ")", "\n", "sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                ", "next_seg", "=", "lines", "[", "index", "+", "1", "]", ".", "split", "(", "\" \"", ")", "[", "0", "]", "[", "1", "]", "\n", "if", "seg", "==", "\"0\"", ":", "\n", "                    ", "if", "next_seg", "==", "\"0\"", ":", "\n", "                        ", "seg", "=", "4", "\n", "", "else", ":", "\n", "                        ", "seg", "=", "1", "\n", "", "", "else", ":", "\n", "                    ", "if", "next_seg", "==", "\"0\"", ":", "\n", "                        ", "seg", "=", "3", "\n", "", "else", ":", "\n", "                        ", "seg", "=", "2", "\n", "", "", "sent", ".", "append", "(", "[", "word2id", "[", "word", "]", ",", "tag2id", "[", "tag", "]", ",", "seg", "]", ")", "\n", "\n", "", "", "", "return", "rs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.getDataFromSent_with_seg_test": [[184, 194], ["words.append", "tags.append"], "function", ["None"], ["", "def", "getDataFromSent_with_seg_test", "(", "sent", ")", ":", "\n", "    ", "words", "=", "[", "]", "\n", "tags", "=", "[", "]", "\n", "# segs = []", "\n", "for", "i", "in", "sent", ":", "\n", "# segs.append([i[2]])", "\n", "        ", "words", ".", "append", "(", "[", "i", "[", "0", "]", ",", "i", "[", "2", "]", "]", ")", "\n", "tags", ".", "append", "(", "i", "[", "1", "]", ")", "\n", "# return words, tags, segs", "\n", "", "return", "words", ",", "tags", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.model.data_process.getTagIx": [[196, 274], ["data_process.getTagIx.getTagDict"], "function", ["None"], ["", "def", "getTagIx", "(", "name", ",", ")", ":", "\n", "    ", "tag_to_ix", "=", "{", "}", "\n", "\n", "def", "getTagDict", "(", "tags", ")", ":", "\n", "        ", "if", "'O'", "not", "in", "tags", ":", "\n", "            ", "tags", ".", "insert", "(", "0", ",", "\"O\"", ")", "\n", "", "d", "=", "{", "}", "\n", "for", "t", "in", "tags", ":", "\n", "            ", "d", "[", "t", "]", "=", "len", "(", "d", ")", "\n", "", "return", "d", "\n", "\n", "", "if", "name", "==", "'conll2003'", ":", "\n", "        ", "tags", "=", "[", "\"O\"", ",", "\"B-PER\"", ",", "\"M-PER\"", ",", "\"S-PER\"", ",", "\"E-PER\"", ",", "\n", "\"B-ORG\"", ",", "\"M-ORG\"", ",", "\"S-ORG\"", ",", "\"E-ORG\"", ",", "\n", "\"B-LOC\"", ",", "\"M-LOC\"", ",", "\"S-LOC\"", ",", "\"E-LOC\"", ",", "\n", "\"B-MISC\"", ",", "\"M-MISC\"", ",", "\"S-MISC\"", ",", "\"E-MISC\"", ",", "]", "\n", "tag_to_ix", "=", "getTagDict", "(", "tags", ")", "\n", "", "elif", "name", "==", "'onto4'", ":", "\n", "        ", "tags", "=", "[", "\n", "\"O\"", ",", "\"B-PER\"", ",", "\"M-PER\"", ",", "\"S-PER\"", ",", "\"E-PER\"", ",", "\n", "\"B-ORG\"", ",", "\"M-ORG\"", ",", "\"S-ORG\"", ",", "\"E-ORG\"", ",", "\n", "\"B-LOC\"", ",", "\"M-LOC\"", ",", "\"S-LOC\"", ",", "\"E-LOC\"", ",", "\n", "\"B-GPE\"", ",", "\"M-GPE\"", ",", "\"S-GPE\"", ",", "\"E-GPE\"", ",", "\n", "]", "\n", "tag_to_ix", "=", "getTagDict", "(", "tags", ")", "\n", "", "elif", "name", "==", "'resume'", ":", "\n", "        ", "tags", "=", "[", "\n", "\"O\"", ",", "\"B-CONT\"", ",", "\"M-CONT\"", ",", "\"S-CONT\"", ",", "\"E-CONT\"", ",", "\n", "\"B-EDU\"", ",", "\"M-EDU\"", ",", "\"S-EDU\"", ",", "\"E-EDU\"", ",", "\n", "\"B-LOC\"", ",", "\"M-LOC\"", ",", "\"S-LOC\"", ",", "\"E-LOC\"", ",", "\n", "\"B-NAME\"", ",", "\"M-NAME\"", ",", "\"S-NAME\"", ",", "\"E-NAME\"", ",", "\n", "\"B-ORG\"", ",", "\"M-ORG\"", ",", "\"S-ORG\"", ",", "\"E-ORG\"", ",", "\n", "\"B-PRO\"", ",", "\"M-PRO\"", ",", "\"S-PRO\"", ",", "\"E-PRO\"", ",", "\n", "\"B-RACE\"", ",", "\"M-RACE\"", ",", "\"S-RACE\"", ",", "\"E-RACE\"", ",", "\n", "\"B-TITLE\"", ",", "\"M-TITLE\"", ",", "\"S-TITLE\"", ",", "\"E-TITLE\"", ",", "\n", "]", "\n", "tag_to_ix", "=", "getTagDict", "(", "tags", ")", "\n", "", "elif", "name", "==", "'weibo.nom'", ":", "\n", "        ", "tags", "=", "[", "\n", "\"B-PER\"", ",", "\"M-PER\"", ",", "\"S-PER\"", ",", "\"E-PER\"", ",", "\n", "\"B-ORG\"", ",", "\"M-ORG\"", ",", "\"S-ORG\"", ",", "\"E-ORG\"", ",", "\n", "\"B-LOC\"", ",", "\"M-LOC\"", ",", "\"S-LOC\"", ",", "\"E-LOC\"", ",", "\n", "\"B-GPE\"", ",", "\"M-GPE\"", ",", "\"S-GPE\"", ",", "\"E-GPE\"", "\n", "]", "\n", "wtags", "=", "[", "w", "+", "'.NOM'", "for", "w", "in", "tags", "]", "\n", "\n", "tag_to_ix", "=", "getTagDict", "(", "wtags", ")", "\n", "", "elif", "name", "==", "'weibo.nam'", ":", "\n", "        ", "tags", "=", "[", "\n", "\"B-PER\"", ",", "\"M-PER\"", ",", "\"S-PER\"", ",", "\"E-PER\"", ",", "\n", "\"B-ORG\"", ",", "\"M-ORG\"", ",", "\"S-ORG\"", ",", "\"E-ORG\"", ",", "\n", "\"B-LOC\"", ",", "\"M-LOC\"", ",", "\"S-LOC\"", ",", "\"E-LOC\"", ",", "\n", "\"B-GPE\"", ",", "\"M-GPE\"", ",", "\"S-GPE\"", ",", "\"E-GPE\"", "\n", "]", "\n", "wtags", "=", "[", "w", "+", "'.NAM'", "for", "w", "in", "tags", "]", "\n", "\n", "tag_to_ix", "=", "getTagDict", "(", "wtags", ")", "\n", "", "elif", "name", "==", "'weibo.all'", ":", "\n", "        ", "tags", "=", "[", "\n", "\"B-PER\"", ",", "\"M-PER\"", ",", "\"S-PER\"", ",", "\"E-PER\"", ",", "\n", "\"B-ORG\"", ",", "\"M-ORG\"", ",", "\"S-ORG\"", ",", "\"E-ORG\"", ",", "\n", "\"B-LOC\"", ",", "\"M-LOC\"", ",", "\"S-LOC\"", ",", "\"E-LOC\"", ",", "\n", "\"B-GPE\"", ",", "\"M-GPE\"", ",", "\"S-GPE\"", ",", "\"E-GPE\"", "\n", "]", "\n", "wtags", "=", "[", "w", "+", "'.NOM'", "for", "w", "in", "tags", "]", "\n", "wtags", "+=", "[", "w", "+", "'.NAM'", "for", "w", "in", "tags", "]", "\n", "\n", "tag_to_ix", "=", "getTagDict", "(", "wtags", ")", "\n", "", "elif", "name", "==", "'MSRA'", ":", "\n", "        ", "tags", "=", "[", "\n", "\"O\"", ",", "\"B-PER\"", ",", "\"M-PER\"", ",", "\"S-PER\"", ",", "\"E-PER\"", ",", "\n", "\"B-ORG\"", ",", "\"M-ORG\"", ",", "\"S-ORG\"", ",", "\"E-ORG\"", ",", "\n", "\"B-LOC\"", ",", "\"M-LOC\"", ",", "\"S-LOC\"", ",", "\"E-LOC\"", ",", "\n", "]", "\n", "tag_to_ix", "=", "getTagDict", "(", "tags", ")", "\n", "\n", "", "ix_to_tag", "=", "{", "val", ":", "key", "for", "(", "key", ",", "val", ")", "in", "tag_to_ix", ".", "items", "(", ")", "}", "\n", "return", "tag_to_ix", ",", "ix_to_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.modeling.BertForTokenClassification_.forward_wuqh": [[8, 66], ["modeling.BertForTokenClassification_.bert", "modeling.BertForTokenClassification_.dropout", "modeling.BertForTokenClassification_.classifier", "modeling.BertForTokenClassification_.size", "modeling.BertForTokenClassification_.size", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.mean", "active_loss.view.view.view", "range", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling.BertForTokenClassification_.view", "labels.view", "torch.sum", "torch.mean", "torch.cat", "modeling.BertForTokenClassification_.view", "labels.view", "torch.cat.append", "active_max.append", "torch.stack", "sum", "torch.max", "torch.sum", "sum"], "methods", ["None"], ["    ", "def", "forward_wuqh", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "lambda_max_loss", "=", "0.0", ",", "lambda_mask_loss", "=", "0.0", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "batch_size", "=", "logits", ".", "size", "(", "0", ")", "\n", "max_seq_len", "=", "logits", ".", "size", "(", "1", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "# modified by wuqh, 2019/5/21", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "\n", "loss_crossEntropy", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "\n", "if", "lambda_max_loss", "==", "0.0", "and", "lambda_mask_loss", "==", "0.0", ":", "\n", "                    ", "return", "loss_crossEntropy", "\n", "\n", "", "active_loss", "=", "active_loss", ".", "view", "(", "batch_size", ",", "max_seq_len", ")", "\n", "\n", "active_max", "=", "[", "]", "\n", "active_mask", "=", "[", "]", "\n", "start_id", "=", "0", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "sent_len", "=", "torch", ".", "sum", "(", "active_loss", "[", "i", "]", ")", "\n", "# mask-loss", "\n", "if", "lambda_mask_loss", "!=", "0.0", ":", "\n", "                        ", "active_mask", ".", "append", "(", "(", "input_ids", "[", "i", "]", "==", "103", ")", "[", ":", "sent_len", "]", ")", "# id of [MASK] is 103, according to the bertTokenizer", "\n", "# max-loss", "\n", "", "if", "lambda_max_loss", "!=", "0.0", ":", "\n", "                        ", "end_id", "=", "start_id", "+", "sent_len", "\n", "active_max", ".", "append", "(", "torch", ".", "max", "(", "loss", "[", "start_id", ":", "end_id", "]", ")", ")", "\n", "start_id", "=", "end_id", "\n", "\n", "# max-loss", "\n", "", "", "if", "lambda_max_loss", "!=", "0.0", ":", "\n", "                    ", "loss_max", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "active_max", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss_max", "=", "0.0", "\n", "\n", "# mask-loss", "\n", "", "if", "lambda_mask_loss", "!=", "0.0", ":", "\n", "                    ", "active_mask", "=", "torch", ".", "cat", "(", "active_mask", ")", "\n", "if", "sum", "(", "active_mask", ")", "!=", "0", ":", "\n", "                        ", "loss_mask", "=", "torch", ".", "sum", "(", "loss", "[", "active_mask", "]", ")", "/", "sum", "(", "active_mask", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss_mask", "=", "0.0", "\n", "\n", "", "return", "loss_crossEntropy", "+", "lambda_max_loss", "*", "loss_max", "+", "lambda_mask_loss", "*", "loss_mask", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "assert", "False", "\n", "", "", "else", ":", "\n", "            ", "return", "logits", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.main.train_NOmeta": [[14, 55], ["logger.info", "preprocessor.Corpus", "preprocessor.Corpus", "learner.Learner().to", "time.time", "range", "logger.info", "preprocessor.Corpus.get_batch_NOmeta", "Learner().to.forward_NOmeta", "learner.Learner", "logger.info", "logger.info", "Learner().to.evaluate_NOmeta", "logger.info", "logger.info", "Learner().to.save_model", "logger.info", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_NOmeta", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.forward_NOmeta", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_NOmeta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model"], ["def", "train_NOmeta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: NO Meta Learning **********\"", ")", "\n", "\n", "# prepare dataset, here we take English as the source language.", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_en_valid", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'valid'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_en_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "\n", "        ", "batch_data", "=", "corpus_en_train", ".", "get_batch_NOmeta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "\n", "loss", "=", "learner", ".", "forward_NOmeta", "(", "batch_data", ",", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [en] - [valid] **********\"", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_en_valid", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Valid F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.main.train_meta": [[56, 99], ["logger.info", "preprocessor.Corpus", "preprocessor.Corpus", "learner.Learner().to", "time.time", "range", "logger.info", "preprocessor.Corpus.get_batch_meta", "Learner().to.forward_meta", "learner.Learner", "logger.info", "logger.info", "Learner().to.evaluate_NOmeta", "logger.info", "logger.info", "Learner().to.save_model", "logger.info", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_meta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.forward_meta", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_NOmeta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model"], ["", "def", "train_meta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: Meta Learning **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "True", ",", "support_size", "=", "args", ".", "support_size", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "True", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_en_valid", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'valid'", ",", "\n", "load_data", "=", "True", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_en_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "        ", "progress", "=", "1.0", "*", "step", "/", "args", ".", "max_meta_steps", "\n", "\n", "batch_query", ",", "batch_support", "=", "corpus_en_train", ".", "get_batch_meta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "#(batch_size=32)", "\n", "loss", "=", "learner", ".", "forward_meta", "(", "batch_query", ",", "batch_support", ",", "progress", "=", "progress", ",", "inner_steps", "=", "args", ".", "inner_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [en] - [valid] **********\"", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_en_valid", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Valid F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.main.zero_shot_NOmeta": [[105, 135], ["os.path.exists", "logger.info", "learner.Learner().to", "preprocessor.Corpus", "logger.info", "Learner().to.evaluate_NOmeta", "F1s[].append", "logger.info", "logger.info", "pathlib.Path().open", "json.dump", "learner.Learner", "pathlib.Path", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_NOmeta"], ["", "def", "zero_shot_NOmeta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-NOmeta-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot NO meta learning **********\"", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.main.zero_shot_meta": [[136, 174], ["os.path.exists", "logger.info", "preprocessor.Reprer", "preprocessor.Corpus", "learner.Learner().to", "preprocessor.Corpus", "logger.info", "Learner().to.evaluate_meta", "F1s[].append", "logger.info", "logger.info", "pathlib.Path().open", "json.dump", "learner.Learner", "pathlib.Path", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_meta"], ["", "", "def", "zero_shot_meta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot with meta learning (separate support set) **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "reprer", "=", "Reprer", "(", "args", ".", "bert_model", ")", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "\n", "args", ".", "lr_inner", ",", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "args", ".", "support_size", ",", "base_features", "=", "corpus_en_train", ".", "original_features", ",", "\n", "mask_rate", "=", "-", "1.0", ",", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] - support on [en] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_meta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lr", "=", "args", ".", "lr_finetune", ",", "steps", "=", "args", ".", "max_ft_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ",", "\n", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.main.k_shot": [[175, 222], ["os.path.exists", "logger.info", "learner.Learner().to", "enumerate", "preprocessor.Corpus", "preprocessor.Corpus", "copy.deepcopy", "time.time", "range", "logger.info", "pathlib.Path().open", "json.dump", "learner.Learner", "preprocessor.Corpus.get_batches", "copy.deepcopy.inner_update", "logger.info", "logger.info", "copy.deepcopy.evaluate_NOmeta", "F1s[].append", "logger.info", "pathlib.Path", "str", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batches", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.inner_update", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_NOmeta"], ["", "", "def", "k_shot", "(", "args", ")", ":", "\n", "# to define: k_shot, max_ft_steps, lr_finetune, lambda_max_loss", "\n", "    ", "res_filename", "=", "'{}/res-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: {}-shot fine-tuning **********\"", ".", "format", "(", "args", ".", "k_shot", ")", ")", "\n", "\n", "learner_pretrained", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ",", "k_shot_prop", "=", "args", ".", "k_shot", ")", "# add k_shot_prop", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "deepcopy", "(", "learner_pretrained", ")", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "for", "ft_step", "in", "range", "(", "args", ".", "max_ft_steps", ")", ":", "\n", "            ", "data_batches", "=", "corpus_train", ".", "get_batches", "(", "args", ".", "inner_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", "\n", "\n", "for", "batch_data", "in", "data_batches", ":", "\n", "                ", "loss", "=", "learner", ".", "inner_update", "(", "batch_data", ",", "lr_curr", "=", "args", ".", "lr_finetune", ",", "inner_steps", "=", "1", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "", "if", "ft_step", "in", "[", "0", ",", "4", ",", "9", ",", "14", "]", ":", "\n", "                ", "logger", ".", "info", "(", "'Fine-tune Step: {}/{}, loss = {:8f}, time = {:2f}s.'", ".", "format", "(", "ft_step", ",", "args", ".", "max_ft_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test], Finetune step = {} **********\"", ".", "format", "(", "lang", ",", "ft_step", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "", "", "for", "i", ",", "lang", "in", "enumerate", "(", "languages", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.main.supervised_NOmeta": [[223, 266], ["logger.info", "logger.info", "preprocessor.Corpus", "preprocessor.Corpus", "learner.Learner().to", "time.time", "range", "logger.info", "preprocessor.Corpus.get_batch_NOmeta", "Learner().to.forward_NOmeta", "learner.Learner", "logger.info", "logger.info", "Learner().to.evaluate_NOmeta", "logger.info", "logger.info", "Learner().to.save_model", "logger.info", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_NOmeta", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.forward_NOmeta", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_NOmeta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model"], ["", "", "def", "supervised_NOmeta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: Supervised & NO Meta Learning **********\"", ")", "\n", "lang", "=", "args", ".", "test_langs", "[", "0", "]", "\n", "logger", ".", "info", "(", "\"language: {}\"", ".", "format", "(", "lang", ")", ")", "\n", "\n", "# prepare dataset", "\n", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "\n", "        ", "batch_data", "=", "corpus_train", ".", "get_batch_NOmeta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "\n", "loss", "=", "learner", ".", "forward_NOmeta", "(", "batch_data", ",", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Test F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.split_tag": [[34, 44], ["chunk_tag.split"], "function", ["None"], ["def", "split_tag", "(", "chunk_tag", ")", ":", "\n", "    ", "\"\"\"\n    split chunk tag into IOBES prefix and chunk_type\n    e.g.\n    B-PER -> (B, PER)\n    O -> (O, None)\n    \"\"\"", "\n", "if", "chunk_tag", "in", "[", "'O'", ",", "'X'", ",", "'[CLS]'", ",", "'[SEP]'", "]", ":", "# == 'O'", "\n", "        ", "return", "(", "'O'", ",", "None", ")", "\n", "", "return", "chunk_tag", ".", "split", "(", "'-'", ",", "maxsplit", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.is_chunk_end": [[46, 68], ["conlleval.split_tag", "conlleval.split_tag"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.split_tag", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.split_tag"], ["", "def", "is_chunk_end", "(", "prev_tag", ",", "tag", ")", ":", "\n", "    ", "\"\"\"\n    check if the previous chunk ended between the previous and current word\n    e.g.\n    (B-PER, I-PER) -> False\n    (B-LOC, O)  -> True\n\n    Note: in case of contradicting tags, e.g. (B-PER, I-LOC)\n    this is considered as (B-PER, B-LOC)\n    \"\"\"", "\n", "prefix1", ",", "chunk_type1", "=", "split_tag", "(", "prev_tag", ")", "\n", "prefix2", ",", "chunk_type2", "=", "split_tag", "(", "tag", ")", "\n", "\n", "if", "prefix1", "==", "'O'", ":", "\n", "        ", "return", "False", "\n", "", "if", "prefix2", "==", "'O'", ":", "\n", "        ", "return", "prefix1", "!=", "'O'", "\n", "\n", "", "if", "chunk_type1", "!=", "chunk_type2", ":", "\n", "        ", "return", "True", "\n", "\n", "", "return", "prefix2", "in", "[", "'B'", ",", "'S'", "]", "or", "prefix1", "in", "[", "'E'", ",", "'S'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.is_chunk_start": [[70, 86], ["conlleval.split_tag", "conlleval.split_tag"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.split_tag", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.split_tag"], ["", "def", "is_chunk_start", "(", "prev_tag", ",", "tag", ")", ":", "\n", "    ", "\"\"\"\n    check if a new chunk started between the previous and current word\n    \"\"\"", "\n", "prefix1", ",", "chunk_type1", "=", "split_tag", "(", "prev_tag", ")", "\n", "prefix2", ",", "chunk_type2", "=", "split_tag", "(", "tag", ")", "\n", "\n", "if", "prefix2", "==", "'O'", ":", "\n", "        ", "return", "False", "\n", "", "if", "prefix1", "==", "'O'", ":", "\n", "        ", "return", "prefix2", "!=", "'O'", "\n", "\n", "", "if", "chunk_type1", "!=", "chunk_type2", ":", "\n", "        ", "return", "True", "\n", "\n", "", "return", "prefix2", "in", "[", "'B'", ",", "'S'", "]", "or", "prefix1", "in", "[", "'E'", ",", "'S'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.calc_metrics": [[88, 100], ["None"], "function", ["None"], ["", "def", "calc_metrics", "(", "tp", ",", "p", ",", "t", ",", "percent", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    compute overall precision, recall and FB1 (default values are 0.0)\n    if percent is True, return 100 * original decimal value\n    \"\"\"", "\n", "precision", "=", "tp", "/", "p", "if", "p", "else", "0", "\n", "recall", "=", "tp", "/", "t", "if", "t", "else", "0", "\n", "fb1", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "if", "precision", "+", "recall", "else", "0", "\n", "if", "percent", ":", "\n", "        ", "return", "100", "*", "precision", ",", "100", "*", "recall", ",", "100", "*", "fb1", "\n", "", "else", ":", "\n", "        ", "return", "precision", ",", "recall", ",", "fb1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.count_chunks": [[102, 162], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "zip", "conlleval.split_tag", "conlleval.split_tag", "conlleval.is_chunk_start", "conlleval.is_chunk_start", "conlleval.is_chunk_end", "conlleval.is_chunk_end"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.split_tag", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.split_tag", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.is_chunk_start", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.is_chunk_start", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.is_chunk_end", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.is_chunk_end"], ["", "", "def", "count_chunks", "(", "true_seqs", ",", "pred_seqs", ")", ":", "\n", "    ", "\"\"\"\n    true_seqs: a list of true tags\n    pred_seqs: a list of predicted tags\n\n    return:\n    correct_chunks: a dict (counter),\n                    key = chunk types,\n                    value = number of correctly identified chunks per type\n    true_chunks:    a dict, number of true chunks per type\n    pred_chunks:    a dict, number of identified chunks per type\n\n    correct_counts, true_counts, pred_counts: similar to above, but for tags\n    \"\"\"", "\n", "correct_chunks", "=", "defaultdict", "(", "int", ")", "\n", "true_chunks", "=", "defaultdict", "(", "int", ")", "\n", "pred_chunks", "=", "defaultdict", "(", "int", ")", "\n", "\n", "correct_counts", "=", "defaultdict", "(", "int", ")", "\n", "true_counts", "=", "defaultdict", "(", "int", ")", "\n", "pred_counts", "=", "defaultdict", "(", "int", ")", "\n", "\n", "prev_true_tag", ",", "prev_pred_tag", "=", "'O'", ",", "'O'", "\n", "correct_chunk", "=", "None", "\n", "\n", "for", "true_tag", ",", "pred_tag", "in", "zip", "(", "true_seqs", ",", "pred_seqs", ")", ":", "\n", "        ", "if", "true_tag", "==", "pred_tag", ":", "\n", "            ", "correct_counts", "[", "true_tag", "]", "+=", "1", "\n", "", "true_counts", "[", "true_tag", "]", "+=", "1", "\n", "pred_counts", "[", "pred_tag", "]", "+=", "1", "\n", "\n", "_", ",", "true_type", "=", "split_tag", "(", "true_tag", ")", "\n", "_", ",", "pred_type", "=", "split_tag", "(", "pred_tag", ")", "\n", "\n", "if", "correct_chunk", "is", "not", "None", ":", "\n", "            ", "true_end", "=", "is_chunk_end", "(", "prev_true_tag", ",", "true_tag", ")", "\n", "pred_end", "=", "is_chunk_end", "(", "prev_pred_tag", ",", "pred_tag", ")", "\n", "\n", "if", "pred_end", "and", "true_end", ":", "\n", "                ", "correct_chunks", "[", "correct_chunk", "]", "+=", "1", "\n", "correct_chunk", "=", "None", "\n", "", "elif", "pred_end", "!=", "true_end", "or", "true_type", "!=", "pred_type", ":", "\n", "                ", "correct_chunk", "=", "None", "\n", "\n", "", "", "true_start", "=", "is_chunk_start", "(", "prev_true_tag", ",", "true_tag", ")", "\n", "pred_start", "=", "is_chunk_start", "(", "prev_pred_tag", ",", "pred_tag", ")", "\n", "\n", "if", "true_start", "and", "pred_start", "and", "true_type", "==", "pred_type", ":", "\n", "            ", "correct_chunk", "=", "true_type", "\n", "", "if", "true_start", ":", "\n", "            ", "true_chunks", "[", "true_type", "]", "+=", "1", "\n", "", "if", "pred_start", ":", "\n", "            ", "pred_chunks", "[", "pred_type", "]", "+=", "1", "\n", "\n", "", "prev_true_tag", ",", "prev_pred_tag", "=", "true_tag", ",", "pred_tag", "\n", "", "if", "correct_chunk", "is", "not", "None", ":", "\n", "        ", "correct_chunks", "[", "correct_chunk", "]", "+=", "1", "\n", "\n", "", "return", "(", "correct_chunks", ",", "true_chunks", ",", "pred_chunks", ",", "\n", "correct_counts", ",", "true_counts", ",", "pred_counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.get_result": [[164, 207], ["sum", "sum", "sum", "sum", "sum", "sum", "sum", "sorted", "conlleval.calc_metrics", "print", "print", "print", "print", "correct_chunks.values", "true_chunks.values", "pred_chunks.values", "correct_counts.values", "true_counts.values", "list", "conlleval.calc_metrics", "print", "print", "print", "set", "correct_counts.items", "true_counts.items", "list", "list"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.calc_metrics", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.calc_metrics"], ["", "def", "get_result", "(", "correct_chunks", ",", "true_chunks", ",", "pred_chunks", ",", "\n", "correct_counts", ",", "true_counts", ",", "pred_counts", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    if verbose, print overall performance, as well as preformance per chunk type;\n    otherwise, simply return overall prec, rec, f1 scores\n    \"\"\"", "\n", "# sum counts", "\n", "sum_correct_chunks", "=", "sum", "(", "correct_chunks", ".", "values", "(", ")", ")", "\n", "sum_true_chunks", "=", "sum", "(", "true_chunks", ".", "values", "(", ")", ")", "\n", "sum_pred_chunks", "=", "sum", "(", "pred_chunks", ".", "values", "(", ")", ")", "\n", "\n", "sum_correct_counts", "=", "sum", "(", "correct_counts", ".", "values", "(", ")", ")", "\n", "sum_true_counts", "=", "sum", "(", "true_counts", ".", "values", "(", ")", ")", "\n", "\n", "nonO_correct_counts", "=", "sum", "(", "v", "for", "k", ",", "v", "in", "correct_counts", ".", "items", "(", ")", "if", "k", "!=", "'O'", ")", "\n", "nonO_true_counts", "=", "sum", "(", "v", "for", "k", ",", "v", "in", "true_counts", ".", "items", "(", ")", "if", "k", "!=", "'O'", ")", "\n", "\n", "chunk_types", "=", "sorted", "(", "list", "(", "set", "(", "list", "(", "true_chunks", ")", "+", "list", "(", "pred_chunks", ")", ")", ")", ")", "\n", "\n", "# compute overall precision, recall and FB1 (default values are 0.0)", "\n", "prec", ",", "rec", ",", "f1", "=", "calc_metrics", "(", "sum_correct_chunks", ",", "sum_pred_chunks", ",", "sum_true_chunks", ")", "\n", "res", "=", "(", "prec", ",", "rec", ",", "f1", ")", "\n", "if", "not", "verbose", ":", "\n", "        ", "return", "res", "\n", "\n", "# print overall performance, and performance per chunk type", "\n", "\n", "", "print", "(", "\"processed %i tokens with %i phrases; \"", "%", "(", "sum_true_counts", ",", "sum_true_chunks", ")", ",", "end", "=", "''", ")", "\n", "print", "(", "\"found: %i phrases; correct: %i.\\n\"", "%", "(", "sum_pred_chunks", ",", "sum_correct_chunks", ")", ",", "end", "=", "''", ")", "\n", "\n", "# print(\"accuracy: %6.2f%%; (non-O)\" % (100 * nonO_correct_counts / nonO_true_counts))", "\n", "print", "(", "\"accuracy: %6.2f%%; \"", "%", "(", "100", "*", "sum_correct_counts", "/", "sum_true_counts", ")", ",", "end", "=", "''", ")", "\n", "print", "(", "\"precision: %6.2f%%; recall: %6.2f%%; FB1: %6.2f\"", "%", "(", "prec", ",", "rec", ",", "f1", ")", ")", "\n", "\n", "# for each chunk type, compute precision, recall and FB1 (default values are 0.0)", "\n", "for", "t", "in", "chunk_types", ":", "\n", "        ", "prec", ",", "rec", ",", "f1", "=", "calc_metrics", "(", "correct_chunks", "[", "t", "]", ",", "pred_chunks", "[", "t", "]", ",", "true_chunks", "[", "t", "]", ")", "\n", "print", "(", "\"%17s: \"", "%", "t", ",", "end", "=", "''", ")", "\n", "print", "(", "\"precision: %6.2f%%; recall: %6.2f%%; FB1: %6.2f\"", "%", "\n", "(", "prec", ",", "rec", ",", "f1", ")", ",", "end", "=", "''", ")", "\n", "print", "(", "\"  %d\"", "%", "pred_chunks", "[", "t", "]", ")", "\n", "\n", "", "return", "res", "\n", "# you can generate LaTeX output for tables like in", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.evaluate": [[212, 218], ["conlleval.count_chunks", "conlleval.get_result"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.count_chunks", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.get_result"], ["", "def", "evaluate", "(", "true_seqs", ",", "pred_seqs", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "(", "correct_chunks", ",", "true_chunks", ",", "pred_chunks", ",", "\n", "correct_counts", ",", "true_counts", ",", "pred_counts", ")", "=", "count_chunks", "(", "true_seqs", ",", "pred_seqs", ")", "\n", "result", "=", "get_result", "(", "correct_chunks", ",", "true_chunks", ",", "pred_chunks", ",", "\n", "correct_counts", ",", "true_counts", ",", "pred_counts", ",", "verbose", "=", "verbose", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.conlleval.evaluate_conll_file": [[220, 236], ["conlleval.evaluate", "line.strip().split", "true_seqs.append", "pred_seqs.append", "line.strip", "len", "IOError", "true_seqs.append", "pred_seqs.append"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate"], ["", "def", "evaluate_conll_file", "(", "fileIterator", ")", ":", "\n", "    ", "true_seqs", ",", "pred_seqs", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "line", "in", "fileIterator", ":", "\n", "        ", "cols", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "# each non-empty line must contain >= 3 columns", "\n", "if", "not", "cols", ":", "\n", "            ", "true_seqs", ".", "append", "(", "'O'", ")", "\n", "pred_seqs", ".", "append", "(", "'O'", ")", "\n", "", "elif", "len", "(", "cols", ")", "<", "3", ":", "\n", "            ", "raise", "IOError", "(", "\"conlleval: too few columns in line %s\\n\"", "%", "line", ")", "\n", "", "else", ":", "\n", "# extract tags from last 2 columns", "\n", "            ", "true_seqs", ".", "append", "(", "cols", "[", "-", "2", "]", ")", "\n", "pred_seqs", ".", "append", "(", "cols", "[", "-", "1", "]", ")", "\n", "", "", "return", "evaluate", "(", "true_seqs", ",", "pred_seqs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.InputExample.__init__": [[14, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.InputFeatures.__init__": [[34, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_id", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "self", ".", "representation", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.NerProcessor.get_examples": [[44, 50], ["preprocessor.NerProcessor._read_tsv", "preprocessor.NerProcessor._create_examples", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples"], ["def", "get_examples", "(", "self", ",", "language", ",", "mode", ")", ":", "\n", "        ", "\"\"\"\n        :param mode: one element in ['train', 'valid', 'test']\n        \"\"\"", "\n", "sentences", "=", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "\"data\"", ",", "language", ",", "\"{}.txt\"", ".", "format", "(", "mode", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "sentences", ",", "mode", ")", "# [list of labels, list of words(no split)]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.NerProcessor._create_examples": [[51, 57], ["enumerate", "examples.append", "preprocessor.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "for", "i", ",", "(", "sentence", ",", "label", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "sentence", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.NerProcessor._read_tsv": [[58, 85], ["open", "enumerate", "line.split", "sentence.append", "label.append", "len", "data.append", "line.startswith", "len", "len", "data.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "## read file", "\n", "# return format :", "\n", "# [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]", "\n", "f", "=", "open", "(", "input_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "data", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "sentence_id", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "if", "len", "(", "line", ")", "==", "0", "or", "line", ".", "startswith", "(", "'-DOCSTART'", ")", "or", "line", "[", "0", "]", "==", "\"\\n\"", ":", "\n", "                ", "if", "len", "(", "sentence", ")", ">", "0", ":", "\n", "                    ", "data", ".", "append", "(", "(", "sentence", ",", "label", ")", ")", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "sentence_id", "+=", "1", "\n", "", "continue", "\n", "", "splits", "=", "line", ".", "split", "(", "' '", ")", "\n", "sentence", ".", "append", "(", "splits", "[", "0", "]", ")", "\n", "label", ".", "append", "(", "splits", "[", "-", "1", "]", "[", ":", "-", "1", "]", ")", "\n", "\n", "", "if", "len", "(", "sentence", ")", ">", "0", ":", "\n", "            ", "data", ".", "append", "(", "(", "sentence", ",", "label", ")", ")", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "", "return", "data", "#, type_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Reprer.__init__": [[109, 112], ["pytorch_pretrained_bert.modeling.BertModel.from_pretrained().to", "pytorch_pretrained_bert.modeling.BertModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "bert_model", ",", "device", "=", "\"cuda\"", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "model", "=", "BertModel", ".", "from_pretrained", "(", "bert_model", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.__init__": [[114, 159], ["preprocessor.NerProcessor", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "preprocessor.Corpus.build_original_features", "isinstance", "len", "len", "len", "logger.info", "preprocessor.compute_represenation", "preprocessor.Corpus.build_query_features_with_mask", "numpy.random.permutation", "numpy.array", "preprocessor.Corpus.build_support_features_", "preprocessor.Corpus.build_support_features_", "numpy.random.permutation().tolist", "numpy.random.permutation().tolist", "int", "int", "range", "numpy.random.permutation", "numpy.random.permutation", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_original_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.compute_represenation", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_query_features_with_mask", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_support_features_", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_support_features_"], ["    ", "def", "__init__", "(", "self", ",", "bert_model", ",", "max_seq_length", ",", "logger", ",", "language", ",", "mode", ",", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "\n", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ",", "k_shot_prop", "=", "-", "1.0", ",", "reprer", "=", "None", ")", ":", "\n", "        ", "self", ".", "processor", "=", "NerProcessor", "(", ")", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "label_list", "=", "LABEL_LIST", "\n", "self", ".", "num_labels", "=", "len", "(", "self", ".", "label_list", ")", "+", "1", "# if not +1, then the loss returned may be `nan`", "\n", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "language", "=", "language", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "load_data", "=", "load_data", "\n", "self", ".", "mask_rate", "=", "mask_rate", "\n", "\n", "# get original feature list (do not consider [MASK] scheme)", "\n", "self", ".", "original_features", "=", "self", ".", "build_original_features", "(", "language", ",", "mode", ",", "load_data", "=", "load_data", ")", "\n", "\n", "if", "k_shot_prop", ">", "0", ":", "\n", "            ", "n_tmp", "=", "len", "(", "self", ".", "original_features", ")", "\n", "kept_idxs", "=", "np", ".", "random", ".", "permutation", "(", "n_tmp", ")", ".", "tolist", "(", ")", "[", ":", "int", "(", "n_tmp", "*", "k_shot_prop", ")", "]", "if", "k_shot_prop", "<", "1.0", "else", "np", ".", "random", ".", "permutation", "(", "n_tmp", ")", ".", "tolist", "(", ")", "[", ":", "int", "(", "k_shot_prop", ")", "]", "\n", "logger", ".", "info", "(", "'  The kept {}-shot-prop idxs are: {}'", ".", "format", "(", "k_shot_prop", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "kept_idxs", "]", ")", ")", ")", "\n", "self", ".", "original_features", "=", "[", "self", ".", "original_features", "[", "i", "]", "for", "i", "in", "kept_idxs", "]", "\n", "\n", "# compute representations for original features (in-place operation)", "\n", "", "if", "compute_repr", ":", "\n", "            ", "compute_represenation", "(", "self", ".", "original_features", ",", "bert_model", ",", "logger", ",", "reprer", "=", "reprer", ")", "\n", "\n", "# build query set", "\n", "", "if", "mask_rate", "<", "0", ":", "# NO [MASK] scheme", "\n", "            ", "self", ".", "query_features", "=", "self", ".", "original_features", "\n", "", "else", ":", "\n", "            ", "self", ".", "query_features", "=", "self", ".", "build_query_features_with_mask", "(", "mask_rate", ")", "# (masked)", "\n", "\n", "# build support set", "\n", "", "assert", "isinstance", "(", "support_size", ",", "int", ")", "\n", "if", "support_size", ">", "0", ":", "# build support set (NOT masked)", "\n", "            ", "if", "base_features", "is", "None", ":", "\n", "                ", "self", ".", "support_features", "=", "self", ".", "build_support_features_", "(", "self", ".", "original_features", ",", "support_size", "=", "support_size", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "support_features", "=", "self", ".", "build_support_features_", "(", "base_features", ",", "support_size", "=", "support_size", ")", "\n", "\n", "", "", "self", ".", "n_total", "=", "len", "(", "self", ".", "query_features", ")", "\n", "self", ".", "batch_start_idx", "=", "0", "\n", "self", ".", "batch_idxs", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n_total", ")", "if", "shuffle", "else", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "self", ".", "n_total", ")", "]", ")", "# for batch sampling in training", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.reset_batch_info": [[161, 164], ["numpy.random.permutation", "numpy.array", "range"], "methods", ["None"], ["", "def", "reset_batch_info", "(", "self", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "self", ".", "batch_start_idx", "=", "0", "\n", "self", ".", "batch_idxs", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n_total", ")", "if", "shuffle", "else", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "self", ".", "n_total", ")", "]", ")", "# for batch sampling in training", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_original_features": [[166, 201], ["preprocessor.Corpus.logger.info", "preprocessor.Corpus.processor.get_examples", "preprocessor.Corpus.logger.info", "preprocessor.Corpus._prepare_data", "preprocessor.Corpus._load_data", "item.split", "tokens.strip().split.strip().split.strip().split", "labels.strip().split.strip().split.strip().split", "preprocessor.Corpus.tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "len", "len", "preprocessor.InputFeatures", "len", "len", "tokens.strip().split.strip().split.strip", "labels.strip().split.strip().split.strip", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.NerProcessor.get_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus._prepare_data", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus._load_data", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "build_original_features", "(", "self", ",", "lang", ",", "mode", ",", "load_data", "=", "True", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Build original features for [{}-{}]...\"", ".", "format", "(", "lang", ",", "mode", ")", ")", "\n", "\n", "# examples: a list of sentences. each item is a tuple of a list of words and a list of tags > (['words'], ['tags'])", "\n", "examples", "=", "self", ".", "processor", ".", "get_examples", "(", "lang", ",", "mode", ")", "# 'en', 'train'", "\n", "\n", "# prepare data (max length limitation...)", "\n", "if", "not", "load_data", ":", "\n", "            ", "tokens_labels", "=", "self", ".", "_prepare_data", "(", "examples", ",", "'data/{}-{}-processed.txt'", ".", "format", "(", "lang", ",", "mode", ")", ")", "\n", "", "else", ":", "\n", "            ", "tokens_labels", "=", "self", ".", "_load_data", "(", "'data/{}-{}-processed.txt'", ".", "format", "(", "lang", ",", "mode", ")", ")", "\n", "\n", "# convert texts and labels to ids, add segments and mask", "\n", "", "features", "=", "[", "]", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "\n", "for", "item", "in", "tokens_labels", ":", "\n", "            ", "tokens", ",", "labels", "=", "item", ".", "split", "(", "'\\t|\\t'", ")", "\n", "tokens", "=", "tokens", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "labels", "=", "labels", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "label_ids", "=", "[", "label_map", "[", "label", "]", "for", "label", "in", "labels", "]", "\n", "\n", "if", "len", "(", "label_ids", ")", "!=", "len", "(", "input_ids", ")", ":", "\n", "                ", "assert", "False", "\n", "", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "input_ids", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "label_ids", "+=", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "\n", "features", ".", "append", "(", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "input_mask", "=", "input_mask", ",", "segment_ids", "=", "segment_ids", ",", "label_id", "=", "label_ids", ")", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'  Num examples: {}, Num examples after split: {}'", ".", "format", "(", "len", "(", "examples", ")", ",", "len", "(", "features", ")", ")", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_query_features_with_mask": [[202, 225], ["preprocessor.Corpus.logger.info", "copy.deepcopy", "preprocessor.Corpus.logger.info", "enumerate", "len", "numpy.random.random"], "methods", ["None"], ["", "def", "build_query_features_with_mask", "(", "self", ",", "mask_rate", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Build query features with MASK for [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "\n", "assert", "mask_rate", ">", "0", "\n", "features", "=", "deepcopy", "(", "self", ".", "original_features", ")", "\n", "mask_id", "=", "self", ".", "tokenizer", ".", "vocab", "[", "'[MASK]'", "]", "\n", "\n", "n_BIs", "=", "0", "\n", "n_masked", "=", "0", "\n", "for", "item", "in", "features", ":", "\n", "            ", "for", "i", ",", "label_id", "in", "enumerate", "(", "item", ".", "label_id", ")", ":", "\n", "                ", "if", "label_id", "==", "0", ":", "# [PAD] token", "\n", "                    ", "break", "\n", "", "label", "=", "self", ".", "label_list", "[", "label_id", "-", "1", "]", "\n", "if", "len", "(", "label", ")", ">", "1", "and", "label", "[", "1", "]", "==", "'-'", ":", "# -: both B-XXX and I-XXX have a '-'", "\n", "                    ", "n_BIs", "+=", "1", "\n", "if", "np", ".", "random", ".", "random", "(", ")", "<", "mask_rate", ":", "\n", "                        ", "item", ".", "input_ids", "[", "i", "]", "=", "mask_id", "\n", "n_masked", "+=", "1", "\n", "\n", "", "", "", "", "self", ".", "logger", ".", "info", "(", "'  Masked {}/{} tokens in total.'", ".", "format", "(", "n_masked", ",", "n_BIs", ")", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus._prepare_data": [[226, 269], ["open", "enumerate", "res_list.append", "open.write", "enumerate", "preprocessor.Corpus.tokenizer.tokenize", "tokens.extend", "labels.extend", "len", "preprocessor.Corpus._prepare_data.output_item"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "_prepare_data", "(", "self", ",", "examples", ",", "fn", ")", ":", "\n", "\n", "        ", "def", "output_item", "(", "tokens", ",", "labels", ",", "res_list", ",", "fw", ")", ":", "\n", "            ", "item", "=", "' '", ".", "join", "(", "[", "'[CLS]'", "]", "+", "tokens", "+", "[", "'[SEP]'", "]", ")", "+", "'\\t|\\t'", "+", "' '", ".", "join", "(", "[", "'[CLS]'", "]", "+", "labels", "+", "[", "'[SEP]'", "]", ")", "\n", "res_list", ".", "append", "(", "item", ")", "\n", "fw", ".", "write", "(", "item", "+", "'\\n'", ")", "\n", "\n", "", "fw", "=", "open", "(", "fn", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "res", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "            ", "textList", "=", "example", ".", "text_a", "\n", "labelList", "=", "example", ".", "label", "\n", "tokens", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "textList", ")", ":", "\n", "                ", "token", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "label", "=", "[", "labelList", "[", "i", "]", "]", "+", "[", "'X'", "]", "*", "(", "len", "(", "token", ")", "-", "1", ")", "\n", "if", "len", "(", "token", ")", "!=", "len", "(", "label", ")", ":", "\n", "                    ", "assert", "False", "\n", "", "tokens", ".", "extend", "(", "token", ")", "\n", "labels", ".", "extend", "(", "label", ")", "\n", "\n", "", "if", "len", "(", "tokens", ")", ">=", "self", ".", "max_seq_length", "-", "1", ":", "\n", "                ", "tokens_", "=", "tokens", "[", "0", ":", "(", "self", ".", "max_seq_length", "-", "2", ")", "]", "\n", "labels_", "=", "labels", "[", "0", ":", "(", "self", ".", "max_seq_length", "-", "2", ")", "]", "\n", "output_item", "(", "tokens_", ",", "labels_", ",", "res", ",", "fw", ")", "\n", "\n", "curr_idx", "=", "self", ".", "max_seq_length", "-", "2", "\n", "while", "len", "(", "tokens", ")", ">=", "curr_idx", "+", "self", ".", "max_seq_length", "//", "2", "-", "2", ":", "\n", "                    ", "tokens_", "=", "tokens", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "curr_idx", "+", "self", ".", "max_seq_length", "//", "2", "-", "2", "]", "\n", "labels_", "=", "labels", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "curr_idx", "+", "self", ".", "max_seq_length", "//", "2", "-", "2", "]", "\n", "output_item", "(", "tokens_", ",", "labels_", ",", "res", ",", "fw", ")", "\n", "curr_idx", "+=", "self", ".", "max_seq_length", "//", "2", "-", "2", "\n", "\n", "", "tokens_", "=", "tokens", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "]", "\n", "labels_", "=", "labels", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "]", "\n", "output_item", "(", "tokens_", ",", "labels_", ",", "res", ",", "fw", ")", "\n", "\n", "", "else", ":", "\n", "                ", "output_item", "(", "tokens", ",", "labels", ",", "res", ",", "fw", ")", "\n", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus._load_data": [[270, 277], ["open", "line.strip.strip.strip", "res.append"], "methods", ["None"], ["", "def", "_load_data", "(", "self", ",", "fn", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "with", "open", "(", "fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "res", ".", "append", "(", "line", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.get_support_ids": [[279, 306], ["preprocessor.Corpus.logger.info", "numpy.stack", "numpy.stack", "numpy.matmul", "numpy.linalg.norm", "numpy.stack", "numpy.argsort", "enumerate", "set", "preprocessor.Corpus.logger.info", "list", "set.extend", "len", "preprocessor.Corpus.logger.info", "len", "str"], "methods", ["None"], ["", "def", "get_support_ids", "(", "self", ",", "base_features", ",", "support_size", "=", "2", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Getting support feature ids for [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "target_features", "=", "self", ".", "query_features", "\n", "\n", "target_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "target_features", "]", ")", "\n", "base_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "base_features", "]", ")", "# sample_num x feature_dim", "\n", "\n", "# compute pairwise cosine distance", "\n", "dis", "=", "np", ".", "matmul", "(", "target_reprs", ",", "base_reprs", ".", "T", ")", "# target_num x base_num", "\n", "\n", "base_norm", "=", "np", ".", "linalg", ".", "norm", "(", "base_reprs", ",", "axis", "=", "1", ")", "# base_num", "\n", "base_norm", "=", "np", ".", "stack", "(", "[", "base_norm", "]", "*", "len", "(", "target_features", ")", ",", "axis", "=", "0", ")", "# target_num x base_num", "\n", "\n", "dis", "=", "dis", "/", "base_norm", "# target_num x base_num", "\n", "relevance", "=", "np", ".", "argsort", "(", "dis", ",", "axis", "=", "1", ")", "\n", "\n", "support_id_set", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "target_features", ")", ":", "\n", "            ", "chosen_ids", "=", "relevance", "[", "i", "]", "[", "-", "1", "*", "(", "support_size", "+", "1", ")", ":", "-", "1", "]", "\n", "if", "i", "<=", "9", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'  Support set info: {}: {}'", ".", "format", "(", "i", ",", "', '", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "chosen_ids", "]", ")", ")", ")", "\n", "", "support_id_set", ".", "extend", "(", "chosen_ids", ")", "\n", "\n", "", "support_id_set", "=", "set", "(", "support_id_set", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'  size of support ids: {}'", ".", "format", "(", "len", "(", "support_id_set", ")", ")", ")", "\n", "return", "list", "(", "support_id_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.reset_query_features": [[307, 315], ["preprocessor.Corpus.logger.info", "len", "preprocessor.Corpus.reset_batch_info", "preprocessor.Corpus.logger.info"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.reset_batch_info"], ["", "def", "reset_query_features", "(", "self", ",", "feature_ids", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Reset query features of [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "self", ".", "query_features", "=", "[", "self", ".", "original_features", "[", "i", "]", "for", "i", "in", "feature_ids", "]", "\n", "\n", "self", ".", "n_total", "=", "len", "(", "self", ".", "query_features", ")", "\n", "self", ".", "reset_batch_info", "(", "shuffle", "=", "shuffle", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'  size of current query features: {}'", ".", "format", "(", "self", ".", "n_total", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_support_features_": [[316, 340], ["preprocessor.Corpus.logger.info", "numpy.stack", "numpy.stack", "numpy.matmul", "numpy.linalg.norm", "numpy.stack", "numpy.argsort", "enumerate", "preprocessor.Corpus.logger.info", "support_set.append", "len", "str"], "methods", ["None"], ["", "def", "build_support_features_", "(", "self", ",", "base_features", ",", "support_size", "=", "2", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Build support features for [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "target_features", "=", "self", ".", "query_features", "\n", "\n", "target_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "target_features", "]", ")", "\n", "base_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "base_features", "]", ")", "# sample_num x feature_dim", "\n", "\n", "# compute pairwise cosine distance", "\n", "dis", "=", "np", ".", "matmul", "(", "target_reprs", ",", "base_reprs", ".", "T", ")", "# target_num x base_num", "\n", "\n", "base_norm", "=", "np", ".", "linalg", ".", "norm", "(", "base_reprs", ",", "axis", "=", "1", ")", "# base_num", "\n", "base_norm", "=", "np", ".", "stack", "(", "[", "base_norm", "]", "*", "len", "(", "target_features", ")", ",", "axis", "=", "0", ")", "# target_num x base_num", "\n", "\n", "dis", "=", "dis", "/", "base_norm", "# target_num x base_num", "\n", "relevance", "=", "np", ".", "argsort", "(", "dis", ",", "axis", "=", "1", ")", "\n", "\n", "support_set", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "target_features", ")", ":", "\n", "            ", "chosen_ids", "=", "relevance", "[", "i", "]", "[", "-", "1", "*", "(", "support_size", "+", "1", ")", ":", "-", "1", "]", "\n", "self", ".", "logger", ".", "info", "(", "'  Support set info: {}: {}'", ".", "format", "(", "i", ",", "', '", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "chosen_ids", "]", ")", ")", ")", "\n", "support", "=", "[", "base_features", "[", "id", "]", "for", "id", "in", "chosen_ids", "]", "\n", "support_set", ".", "append", "(", "support", ")", "\n", "\n", "", "return", "support_set", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.get_batch_meta": [[342, 378], ["range", "preprocessor.Corpus.reset_batch_info", "query_batch.append", "support_batch.append", "preprocessor.Corpus.build_query_features_with_mask", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.reset_batch_info", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_query_features_with_mask"], ["", "def", "get_batch_meta", "(", "self", ",", "batch_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "batch_start_idx", "+", "batch_size", ">=", "self", ".", "n_total", ":", "\n", "            ", "self", ".", "reset_batch_info", "(", "shuffle", "=", "shuffle", ")", "\n", "if", "self", ".", "mask_rate", ">=", "0", ":", "\n", "                ", "self", ".", "query_features", "=", "self", ".", "build_query_features_with_mask", "(", "mask_rate", "=", "self", ".", "mask_rate", ")", "\n", "\n", "\n", "", "", "query_batch", "=", "[", "]", "\n", "support_batch", "=", "[", "]", "\n", "start_id", "=", "self", ".", "batch_start_idx", "\n", "\n", "for", "i", "in", "range", "(", "start_id", ",", "start_id", "+", "batch_size", ")", ":", "\n", "            ", "idx", "=", "self", ".", "batch_idxs", "[", "i", "]", "\n", "query_i", "=", "self", ".", "query_features", "[", "idx", "]", "\n", "query_item", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "input_ids", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "# 1 x max_seq_len", "\n", "'input_mask'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "input_mask", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "segment_ids", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "label_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([query_i.flag], dtype=torch.long).to(device)", "\n", "}", "\n", "query_batch", ".", "append", "(", "query_item", ")", "\n", "\n", "support_i", "=", "self", ".", "support_features", "[", "idx", "]", "\n", "support_item", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'input_mask'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([f.flag for f in support_i], dtype=torch.long).to(device)", "\n", "}", "\n", "support_batch", ".", "append", "(", "support_item", ")", "\n", "\n", "", "self", ".", "batch_start_idx", "+=", "batch_size", "\n", "\n", "return", "query_batch", ",", "support_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.get_batch_NOmeta": [[379, 400], ["preprocessor.Corpus.reset_batch_info", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "preprocessor.Corpus.build_query_features_with_mask", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.reset_batch_info", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_query_features_with_mask"], ["", "def", "get_batch_NOmeta", "(", "self", ",", "batch_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "batch_start_idx", "+", "batch_size", ">=", "self", ".", "n_total", ":", "\n", "            ", "self", ".", "reset_batch_info", "(", "shuffle", "=", "shuffle", ")", "\n", "if", "self", ".", "mask_rate", ">=", "0", ":", "\n", "                ", "self", ".", "query_features", "=", "self", ".", "build_query_features_with_mask", "(", "mask_rate", "=", "self", ".", "mask_rate", ")", "\n", "\n", "", "", "idxs", "=", "self", ".", "batch_idxs", "[", "self", ".", "batch_start_idx", ":", "self", ".", "batch_start_idx", "+", "batch_size", "]", "\n", "batch_features", "=", "[", "self", ".", "query_features", "[", "idx", "]", "for", "idx", "in", "idxs", "]", "\n", "# batch_features = self.query_features[self.batch_start_idx : self.batch_start_idx + batch_size]", "\n", "\n", "batch", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'input_mask'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([f.flag for f in batch_features], dtype=torch.long).to(device)", "\n", "}", "\n", "\n", "self", ".", "batch_start_idx", "+=", "batch_size", "\n", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.get_batches": [[401, 424], ["range", "numpy.random.permutation", "batches.append", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "min", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "get_batches", "(", "self", ",", "batch_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "batches", "=", "[", "]", "\n", "\n", "if", "shuffle", ":", "\n", "            ", "idxs", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n_total", ")", "\n", "features", "=", "[", "self", ".", "query_features", "[", "i", "]", "for", "i", "in", "idxs", "]", "\n", "", "else", ":", "\n", "            ", "features", "=", "self", ".", "query_features", "\n", "\n", "", "for", "i", "in", "range", "(", "0", ",", "self", ".", "n_total", ",", "batch_size", ")", ":", "\n", "            ", "batch_features", "=", "features", "[", "i", ":", "min", "(", "self", ".", "n_total", ",", "i", "+", "batch_size", ")", "]", "\n", "\n", "batch", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'input_mask'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([f.flag for f in batch_features], dtype=torch.long).to(device)", "\n", "}", "\n", "\n", "batches", ".", "append", "(", "batch", ")", "\n", "\n", "", "return", "batches", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.compute_represenation": [[86, 107], ["BertModel.from_pretrained().to.eval", "range", "logger.info", "pytorch_pretrained_bert.modeling.BertModel.from_pretrained().to", "len", "all_encoder_layers[].detach().cpu().numpy", "enumerate", "torch.no_grad", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "BertModel.from_pretrained().to.", "logger.info", "pytorch_pretrained_bert.modeling.BertModel.from_pretrained", "min", "all_encoder_layers[].detach().cpu", "len", "torch.tensor", "torch.tensor", "torch.tensor", "all_encoder_layers[].detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "compute_represenation", "(", "sents", ",", "bert_model", ",", "logger", ",", "device", "=", "\"cuda\"", ",", "reprer", "=", "None", ")", ":", "\n", "    ", "if", "reprer", "is", "None", ":", "\n", "        ", "model", "=", "BertModel", ".", "from_pretrained", "(", "bert_model", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "reprer", ".", "model", "\n", "", "model", ".", "eval", "(", ")", "\n", "batch_size", "=", "100", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sents", ")", ",", "batch_size", ")", ":", "\n", "        ", "items", "=", "sents", "[", "i", ":", "min", "(", "len", "(", "sents", ")", ",", "i", "+", "batch_size", ")", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "torch", ".", "tensor", "(", "[", "item", ".", "input_ids", "for", "item", "in", "items", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "[", "item", ".", "segment_ids", "for", "item", "in", "items", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "item", ".", "input_mask", "for", "item", "in", "items", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "all_encoder_layers", ",", "_", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "# batch_size x seq_len x target_size", "\n", "", "layer_output", "=", "all_encoder_layers", "[", "-", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# batch_size x seq_len x target_size", "\n", "for", "j", ",", "item", "in", "enumerate", "(", "items", ")", ":", "\n", "            ", "item", ".", "representation", "=", "layer_output", "[", "j", "]", "[", "0", "]", "\n", "# item.representation = layer_output", "\n", "", "if", "i", "%", "(", "10", "*", "batch_size", ")", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'  Compute sentence representation. To {}...'", ".", "format", "(", "i", ")", ")", "\n", "", "", "logger", ".", "info", "(", "'  Finish.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.__init__": [[14, 57], ["torch.nn.Module.__init__", "logger.info", "learner.Learner.model.named_parameters", "pytorch_pretrained_bert.optimization.BertAdam", "len", "logger.info", "os.path.join", "os.path.join", "pytorch_pretrained_bert.modeling.BertConfig", "modeling.BertForTokenClassification_", "learner.Learner.model.load_state_dict", "logger.info", "modeling.BertForTokenClassification_.from_pretrained", "any", "learner.Learner.get_optimizer_grouped_parameters", "torch.load", "str", "logger.info", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters"], ["    ", "def", "__init__", "(", "self", ",", "bert_model", ",", "label_list", ",", "freeze_layer", ",", "logger", ",", "lr_meta", ",", "lr_inner", ",", "\n", "warmup_prop_meta", ",", "warmup_prop_inner", ",", "max_meta_steps", ",", "model_dir", "=", "''", ",", "cache_dir", "=", "''", ",", "gpu_no", "=", "0", ",", "py_alias", "=", "\"python\"", ")", ":", "\n", "\n", "        ", "super", "(", "Learner", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lr_meta", "=", "lr_meta", "\n", "self", ".", "lr_inner", "=", "lr_inner", "\n", "self", ".", "warmup_prop_meta", "=", "warmup_prop_meta", "\n", "self", ".", "warmup_prop_inner", "=", "warmup_prop_inner", "\n", "self", ".", "max_meta_steps", "=", "max_meta_steps", "\n", "\n", "self", ".", "bert_model", "=", "bert_model", "\n", "self", ".", "label_list", "=", "label_list", "\n", "self", ".", "py_alias", "=", "py_alias", "\n", "\n", "num_labels", "=", "len", "(", "label_list", ")", "+", "1", "\n", "\n", "## load model", "\n", "if", "model_dir", "!=", "''", ":", "\n", "            ", "logger", ".", "info", "(", "'********** Loading saved model **********'", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "CONFIG_NAME", ")", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'en_{}'", ".", "format", "(", "WEIGHTS_NAME", ")", ")", "\n", "config", "=", "BertConfig", "(", "output_config_file", ")", "\n", "self", ".", "model", "=", "BertForTokenClassification_", "(", "config", ",", "num_labels", "=", "num_labels", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_model_file", ",", "map_location", "=", "\"cuda:{}\"", ".", "format", "(", "gpu_no", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'********** Loading pre-trained model **********'", ")", "\n", "cache_dir", "=", "cache_dir", "if", "cache_dir", "else", "str", "(", "PYTORCH_PRETRAINED_BERT_CACHE", ")", "\n", "self", ".", "model", "=", "BertForTokenClassification_", ".", "from_pretrained", "(", "bert_model", ",", "cache_dir", "=", "cache_dir", ",", "num_labels", "=", "num_labels", ")", "\n", "\n", "## layer freezing", "\n", "", "if", "freeze_layer", "==", "0", ":", "\n", "            ", "no_grad_param_names", "=", "[", "'embeddings'", "]", "# layer.0", "\n", "", "else", ":", "\n", "            ", "no_grad_param_names", "=", "[", "'embeddings'", ",", "'pooler'", "]", "+", "[", "'layer.{}.'", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "freeze_layer", "+", "1", ")", "]", "\n", "", "logger", ".", "info", "(", "\"The frozen parameters are:\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "any", "(", "no_grad_pn", "in", "name", "for", "no_grad_pn", "in", "no_grad_param_names", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "logger", ".", "info", "(", "\"  {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "", "self", ".", "opt", "=", "BertAdam", "(", "self", ".", "get_optimizer_grouped_parameters", "(", ")", ",", "lr", "=", "lr_meta", ",", "\n", "warmup", "=", "warmup_prop_meta", ",", "t_total", "=", "max_meta_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.get_optimizer_grouped_parameters": [[59, 67], ["list", "learner.Learner.model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "get_optimizer_grouped_parameters", "(", "self", ")", ":", "\n", "        ", "param_optimizer", "=", "list", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "return", "optimizer_grouped_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.get_names": [[69, 72], ["learner.Learner.model.named_parameters"], "methods", ["None"], ["", "def", "get_names", "(", "self", ")", ":", "\n", "        ", "names", "=", "[", "n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.get_params": [[73, 76], ["learner.Learner.model.parameters"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "        ", "params", "=", "[", "p", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.load_weights": [[78, 82], ["learner.Learner.model.state_dict", "zip", "model_params[].data.copy_"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ",", "names", ",", "params", ")", ":", "\n", "        ", "model_params", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "for", "n", ",", "p", "in", "zip", "(", "names", ",", "params", ")", ":", "\n", "            ", "model_params", "[", "n", "]", ".", "data", ".", "copy_", "(", "p", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.load_gradients": [[83, 87], ["learner.Learner.model.state_dict", "zip", "model_params[].grad.data.add_"], "methods", ["None"], ["", "", "def", "load_gradients", "(", "self", ",", "names", ",", "grads", ")", ":", "\n", "        ", "model_params", "=", "self", ".", "model", ".", "state_dict", "(", "keep_vars", "=", "True", ")", "\n", "for", "n", ",", "g", "in", "zip", "(", "names", ",", "grads", ")", ":", "\n", "            ", "model_params", "[", "n", "]", ".", "grad", ".", "data", ".", "add_", "(", "g", ".", "data", ")", "# accumulate", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.get_learning_rate": [[89, 97], ["max"], "methods", ["None"], ["", "", "def", "get_learning_rate", "(", "self", ",", "lr", ",", "progress", ",", "warmup", ",", "schedule", "=", "'linear'", ")", ":", "\n", "        ", "if", "schedule", "==", "'linear'", ":", "\n", "            ", "if", "progress", "<", "warmup", ":", "\n", "                ", "lr", "*=", "progress", "/", "warmup", "\n", "", "else", ":", "\n", "                ", "lr", "*=", "max", "(", "(", "progress", "-", "1.", ")", "/", "(", "warmup", "-", "1.", ")", ",", "0.", ")", "\n", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.inner_update": [[99, 116], ["pytorch_pretrained_bert.optimization.BertAdam", "learner.Learner.model.train", "range", "learner.Learner.item", "learner.Learner.get_optimizer_grouped_parameters", "pytorch_pretrained_bert.optimization.BertAdam.zero_grad", "learner.Learner.model.forward_wuqh", "learner.Learner.backward", "pytorch_pretrained_bert.optimization.BertAdam.step"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["", "def", "inner_update", "(", "self", ",", "data_support", ",", "lr_curr", ",", "inner_steps", ",", "lambda_max_loss", ",", "lambda_mask_loss", ")", ":", "\n", "        ", "inner_opt", "=", "BertAdam", "(", "self", ".", "get_optimizer_grouped_parameters", "(", ")", ",", "lr", "=", "self", ".", "lr_inner", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "inner_steps", ")", ":", "\n", "            ", "inner_opt", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr_curr", "\n", "inner_opt", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", "=", "lr_curr", "\n", "\n", "inner_opt", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "model", ".", "forward_wuqh", "(", "data_support", "[", "'input_ids'", "]", ",", "data_support", "[", "'segment_ids'", "]", ",", "\n", "data_support", "[", "'input_mask'", "]", ",", "data_support", "[", "'label_ids'", "]", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "inner_opt", ".", "step", "(", ")", "\n", "\n", "", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.forward_meta": [[118, 154], ["learner.Learner.get_names", "learner.Learner.get_params", "copy.deepcopy", "len", "learner.Learner.get_learning_rate", "range", "learner.Learner.opt.zero_grad", "learner.Learner.opt.step", "numpy.mean", "learner.Learner.inner_update", "learner.Learner.model.forward_wuqh", "torch.autograd.grad", "meta_grad.append", "meta_loss.append", "learner.Learner.load_weights", "learner.Learner.load_gradients", "numpy.array", "learner.Learner.item"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_names", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_params", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_learning_rate", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.inner_update", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_gradients"], ["", "def", "forward_meta", "(", "self", ",", "batch_query", ",", "batch_support", ",", "progress", ",", "inner_steps", ",", "lambda_max_loss", ",", "lambda_mask_loss", ")", ":", "# for one task", "\n", "        ", "names", "=", "self", ".", "get_names", "(", ")", "\n", "params", "=", "self", ".", "get_params", "(", ")", "\n", "weights", "=", "deepcopy", "(", "params", ")", "\n", "\n", "meta_grad", "=", "[", "]", "\n", "meta_loss", "=", "[", "]", "\n", "\n", "task_num", "=", "len", "(", "batch_query", ")", "\n", "lr_inner", "=", "self", ".", "get_learning_rate", "(", "self", ".", "lr_inner", ",", "progress", ",", "self", ".", "warmup_prop_inner", ")", "\n", "\n", "# compute meta_grad of each task", "\n", "for", "task_id", "in", "range", "(", "task_num", ")", ":", "\n", "            ", "self", ".", "inner_update", "(", "batch_support", "[", "task_id", "]", ",", "lr_inner", ",", "inner_steps", "=", "inner_steps", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n", "loss", "=", "self", ".", "model", ".", "forward_wuqh", "(", "batch_query", "[", "task_id", "]", "[", "'input_ids'", "]", ",", "batch_query", "[", "task_id", "]", "[", "'segment_ids'", "]", ",", "\n", "batch_query", "[", "task_id", "]", "[", "'input_mask'", "]", ",", "batch_query", "[", "task_id", "]", "[", "'label_ids'", "]", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "params", ")", "\n", "meta_grad", ".", "append", "(", "grad", ")", "\n", "meta_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "load_weights", "(", "names", ",", "weights", ")", "\n", "\n", "# accumulate grads of all tasks to param.grad", "\n", "", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "# similar to backward()", "\n", "for", "g", "in", "meta_grad", ":", "\n", "            ", "self", ".", "load_gradients", "(", "names", ",", "g", ")", "\n", "", "self", ".", "opt", ".", "step", "(", ")", "\n", "\n", "ave_loss", "=", "numpy", ".", "mean", "(", "numpy", ".", "array", "(", "meta_loss", ")", ")", "\n", "\n", "return", "ave_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.forward_NOmeta": [[156, 168], ["learner.Learner.model.train", "learner.Learner.opt.zero_grad", "learner.Learner.model.forward_wuqh", "learner.Learner.backward", "learner.Learner.opt.step", "learner.Learner.item"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["", "def", "forward_NOmeta", "(", "self", ",", "batch_data", ",", "lambda_max_loss", ",", "lambda_mask_loss", ")", ":", "#, lambda_flag=-1.0):", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "loss", "=", "self", ".", "model", ".", "forward_wuqh", "(", "batch_data", "[", "'input_ids'", "]", ",", "batch_data", "[", "'segment_ids'", "]", ",", "\n", "batch_data", "[", "'input_mask'", "]", ",", "batch_data", "[", "'label_ids'", "]", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "\n", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "#, lambda_flag=lambda_flag)", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.write_result": [[171, 178], ["len", "len", "open", "enumerate", "fw.write", "enumerate", "fw.write"], "methods", ["None"], ["", "def", "write_result", "(", "self", ",", "words", ",", "y_true", ",", "y_pred", ",", "tmp_fn", ")", ":", "\n", "        ", "assert", "len", "(", "y_pred", ")", "==", "len", "(", "y_true", ")", "\n", "with", "open", "(", "tmp_fn", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "for", "i", ",", "sent", "in", "enumerate", "(", "y_true", ")", ":", "\n", "                ", "for", "j", ",", "word", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "fw", ".", "write", "(", "'{} {} {}\\n'", ".", "format", "(", "words", "[", "i", "]", "[", "j", "]", ",", "word", ",", "y_pred", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "", "fw", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_meta": [[179, 252], ["pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "learner.Learner.get_names", "learner.Learner.get_params", "copy.deepcopy", "time.time", "range", "learner.Learner.write_result", "os.system", "corpus.get_batch_meta", "learner.Learner.inner_update", "learner.Learner.model.eval", "torch.argmax", "learner.Learner.detach().cpu().numpy", "[].to().numpy", "[].to().numpy", "[].to().numpy", "enumerate", "learner.Learner.load_weights", "open", "enumerate", "enumerate", "torch.no_grad", "learner.Learner.model", "torch.nn.functional.log_softmax", "enumerate", "y_true.append", "y_pred.append", "words.append", "logger.info", "logger.info", "learner.Learner.detach().cpu", "[].to", "[].to", "[].to", "float", "line.strip", "temp_1.pop", "temp_2.pop", "temp_word.pop", "learner.Learner.detach", "temp_1.append", "temp_2.append", "temp_word.append", "time.time", "line.strip().split", "len", "len", "line.strip", "max"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_names", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_params", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.write_result", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_meta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.inner_update", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights"], ["", "", "def", "evaluate_meta", "(", "self", ",", "corpus", ",", "result_dir", ",", "logger", ",", "lr", ",", "steps", ",", "lambda_max_loss", ",", "lambda_mask_loss", ",", "lang", "=", "'en'", ",", "mode", "=", "'valid'", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "bert_model", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "names", "=", "self", ".", "get_names", "(", ")", "\n", "params", "=", "self", ".", "get_params", "(", ")", "\n", "weights", "=", "deepcopy", "(", "params", ")", "\n", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "\n", "t_tmp", "=", "time", ".", "time", "(", ")", "\n", "for", "item_id", "in", "range", "(", "corpus", ".", "n_total", ")", ":", "\n", "            ", "eval_query", ",", "eval_support", "=", "corpus", ".", "get_batch_meta", "(", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "\n", "# train on support examples", "\n", "self", ".", "inner_update", "(", "eval_support", "[", "0", "]", ",", "lr_curr", "=", "lr", ",", "inner_steps", "=", "steps", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n", "\n", "# eval on pseudo query examples (test example)", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "logits", "=", "self", ".", "model", "(", "eval_query", "[", "0", "]", "[", "'input_ids'", "]", ",", "eval_query", "[", "0", "]", "[", "'segment_ids'", "]", ",", "\n", "eval_query", "[", "0", "]", "[", "'input_mask'", "]", ")", "# batch_size x seq_len x target_size", "\n", "\n", "", "logits", "=", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "2", ")", ",", "dim", "=", "2", ")", "\n", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "input_ids", "=", "eval_query", "[", "0", "]", "[", "'input_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "label_ids", "=", "eval_query", "[", "0", "]", "[", "'label_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "input_mask", "=", "eval_query", "[", "0", "]", "[", "'input_mask'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "for", "i", ",", "mask", "in", "enumerate", "(", "input_mask", ")", ":", "\n", "                ", "temp_1", "=", "[", "]", "\n", "temp_2", "=", "[", "]", "\n", "temp_word", "=", "[", "]", "\n", "for", "j", ",", "m", "in", "enumerate", "(", "mask", ")", ":", "\n", "                    ", "if", "j", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "if", "m", ":", "\n", "                        ", "if", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", "!=", "\"X\"", ":", "\n", "                            ", "temp_1", ".", "append", "(", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "temp_2", ".", "append", "(", "label_map", "[", "max", "(", "logits", "[", "i", "]", "[", "j", "]", ",", "1", ")", "]", ")", "\n", "temp_word", ".", "append", "(", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "", "else", ":", "\n", "                            ", "tmp", "=", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", "\n", "if", "len", "(", "tmp", ")", ">", "2", "and", "len", "(", "temp_word", ")", ">", "0", ":", "\n", "                                ", "temp_word", "[", "-", "1", "]", "=", "temp_word", "[", "-", "1", "]", "+", "tmp", "[", "2", ":", "]", "\n", "", "", "", "else", ":", "\n", "                        ", "temp_1", ".", "pop", "(", ")", "\n", "temp_2", ".", "pop", "(", ")", "\n", "temp_word", ".", "pop", "(", ")", "\n", "break", "\n", "", "", "y_true", ".", "append", "(", "temp_1", ")", "\n", "y_pred", ".", "append", "(", "temp_2", ")", "\n", "words", ".", "append", "(", "temp_word", ")", "\n", "\n", "", "self", ".", "load_weights", "(", "names", ",", "weights", ")", "\n", "if", "item_id", "%", "50", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'  To sentence {}/{}. Time: {}sec'", ".", "format", "(", "item_id", ",", "corpus", ".", "n_total", ",", "time", ".", "time", "(", ")", "-", "t_tmp", ")", ")", "\n", "\n", "", "", "tmp_fn", "=", "'{}/{}-{}_pred.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "score_fn", "=", "'{}/{}-{}_score.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "self", ".", "write_result", "(", "words", ",", "y_true", ",", "y_pred", ",", "tmp_fn", ")", "\n", "os", ".", "system", "(", "'%s %s < %s > %s'", "%", "(", "self", ".", "py_alias", ",", "'conlleval.py'", ",", "tmp_fn", ",", "score_fn", ")", ")", "\n", "\n", "F1", "=", "-", "1", "\n", "with", "open", "(", "score_fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "            ", "for", "id", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "if", "id", "==", "1", ":", "\n", "                    ", "F1", "=", "float", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "", "logger", ".", "info", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "return", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.evaluate_NOmeta": [[253, 311], ["pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "corpus.get_batches", "learner.Learner.model.eval", "enumerate", "learner.Learner.write_result", "os.system", "torch.argmax", "learner.Learner.detach().cpu().numpy", "data_batch[].to().numpy", "data_batch[].to().numpy", "data_batch[].to().numpy", "enumerate", "open", "enumerate", "enumerate", "torch.no_grad", "learner.Learner.model", "torch.nn.functional.log_softmax", "enumerate", "y_true.append", "y_pred.append", "words.append", "logger.info", "learner.Learner.detach().cpu", "data_batch[].to", "data_batch[].to", "data_batch[].to", "float", "line.strip", "temp_1.pop", "temp_2.pop", "temp_word.pop", "learner.Learner.detach", "temp_1.append", "temp_2.append", "temp_word.append", "line.strip().split", "len", "len", "line.strip", "max"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batches", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.write_result"], ["", "def", "evaluate_NOmeta", "(", "self", ",", "corpus", ",", "result_dir", ",", "logger", ",", "lang", "=", "'en'", ",", "mode", "=", "'valid'", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "bert_model", ",", "do_lower_case", "=", "False", ")", "\n", "data_batches", "=", "corpus", ".", "get_batches", "(", "batch_size", "=", "64", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "for", "batch_id", ",", "data_batch", "in", "enumerate", "(", "data_batches", ")", ":", "\n", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "logits", "=", "self", ".", "model", "(", "data_batch", "[", "'input_ids'", "]", ",", "data_batch", "[", "'segment_ids'", "]", ",", "\n", "data_batch", "[", "'input_mask'", "]", ")", "# batch_size x seq_len x target_size", "\n", "\n", "", "logits", "=", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "2", ")", ",", "dim", "=", "2", ")", "\n", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "input_ids", "=", "data_batch", "[", "'input_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "label_ids", "=", "data_batch", "[", "'label_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "input_mask", "=", "data_batch", "[", "'input_mask'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "for", "i", ",", "mask", "in", "enumerate", "(", "input_mask", ")", ":", "\n", "                ", "temp_1", "=", "[", "]", "\n", "temp_2", "=", "[", "]", "\n", "temp_word", "=", "[", "]", "\n", "for", "j", ",", "m", "in", "enumerate", "(", "mask", ")", ":", "\n", "                    ", "if", "j", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "if", "m", ":", "\n", "                        ", "if", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", "!=", "\"X\"", ":", "\n", "                            ", "temp_1", ".", "append", "(", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "temp_2", ".", "append", "(", "label_map", "[", "max", "(", "logits", "[", "i", "]", "[", "j", "]", ",", "1", ")", "]", ")", "\n", "temp_word", ".", "append", "(", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "", "else", ":", "\n", "                            ", "tmp", "=", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", "\n", "if", "len", "(", "tmp", ")", ">", "2", "and", "len", "(", "temp_word", ")", ">", "0", ":", "\n", "                                ", "temp_word", "[", "-", "1", "]", "=", "temp_word", "[", "-", "1", "]", "+", "tmp", "[", "2", ":", "]", "\n", "", "", "", "else", ":", "\n", "                        ", "temp_1", ".", "pop", "(", ")", "# pop [SEP]", "\n", "temp_2", ".", "pop", "(", ")", "\n", "temp_word", ".", "pop", "(", ")", "\n", "break", "\n", "", "", "y_true", ".", "append", "(", "temp_1", ")", "\n", "y_pred", ".", "append", "(", "temp_2", ")", "\n", "words", ".", "append", "(", "temp_word", ")", "\n", "\n", "", "", "tmp_fn", "=", "'{}/{}-{}_pred.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "score_fn", "=", "'{}/{}-{}_score.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "self", ".", "write_result", "(", "words", ",", "y_true", ",", "y_pred", ",", "tmp_fn", ")", "\n", "os", ".", "system", "(", "'%s %s < %s > %s'", "%", "(", "self", ".", "py_alias", ",", "'conlleval.py'", ",", "tmp_fn", ",", "score_fn", ")", ")", "\n", "\n", "F1", "=", "-", "1", "\n", "with", "open", "(", "score_fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "            ", "for", "id", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "if", "id", "==", "1", ":", "\n", "                    ", "F1", "=", "float", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "", "logger", ".", "info", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "return", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.learner.Learner.save_model": [[312, 325], ["os.path.join", "torch.save", "os.path.join", "json.dump", "hasattr", "model_to_save.state_dict", "open", "f.write", "open", "model_to_save.config.to_json_string", "enumerate", "len", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["", "def", "save_model", "(", "self", ",", "result_dir", ",", "fn_prefix", ",", "max_seq_len", ")", ":", "\n", "# Save a trained model and the associated configuration", "\n", "        ", "model_to_save", "=", "self", ".", "model", ".", "module", "if", "hasattr", "(", "self", ".", "model", ",", "'module'", ")", "else", "self", ".", "model", "# Only save the model it-self", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "'{}_{}'", ".", "format", "(", "fn_prefix", ",", "WEIGHTS_NAME", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "CONFIG_NAME", ")", "\n", "with", "open", "(", "output_config_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "model_to_save", ".", "config", ".", "to_json_string", "(", ")", ")", "\n", "", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "model_config", "=", "{", "\"bert_model\"", ":", "self", ".", "bert_model", ",", "\"do_lower\"", ":", "False", ",", "\n", "\"max_seq_length\"", ":", "max_seq_len", ",", "\"num_labels\"", ":", "len", "(", "self", ".", "label_list", ")", "+", "1", ",", "\n", "\"label_map\"", ":", "label_map", "}", "\n", "json", ".", "dump", "(", "model_config", ",", "open", "(", "os", ".", "path", ".", "join", "(", "result_dir", ",", "\"model_config.json\"", ")", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.__init__": [[12, 55], ["torch.Module.__init__", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Embedding", "torch.Embedding", "torch.Embedding", "hscrf_layer_SoftDict.HSCRF.init_embedding", "torch.Linear", "torch.Linear", "torch.Linear", "hscrf_layer_SoftDict.HSCRF.init_linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "hscrf_layer_SoftDict.HSCRF.init_linear", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "ix_to_tag.items", "hscrf_layer_SoftDict.HSCRF.ix_to_tag.items"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.init_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.init_linear", "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.init_linear"], ["    ", "def", "__init__", "(", "self", ",", "ix_to_tag", ",", "word_rep_dim", "=", "300", ",", "SCRF_feature_dim", "=", "100", ",", "index_embeds_dim", "=", "10", ",", "ALLOWED_SPANLEN", "=", "7", ",", "\n", "softdict_text_field_embedder", "=", "None", ",", "\n", "length_embedder", "=", "None", ",", "\n", "encoder", "=", "None", ",", "\n", "BILOU_tag_projection_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "HSCRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ix_to_tag", "=", "ix_to_tag", "\n", "self", ".", "entity_tag_ids", "=", "[", "ky", "for", "ky", ",", "val", "in", "ix_to_tag", ".", "items", "(", ")", "if", "val", "!=", "\"O\"", "]", "\n", "self", ".", "tag_to_ix", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "ix_to_tag", ".", "items", "(", ")", "}", "\n", "self", ".", "tagset_size", "=", "len", "(", "ix_to_tag", ")", "+", "2", "# including <start, end>", "\n", "self", ".", "index_embeds_dim", "=", "index_embeds_dim", "\n", "self", ".", "SCRF_feature_dim", "=", "SCRF_feature_dim", "\n", "self", ".", "ALLOWED_SPANLEN", "=", "ALLOWED_SPANLEN", "\n", "\n", "self", ".", "softdict_text_field_embedder", "=", "softdict_text_field_embedder", "\n", "self", ".", "length_embedder", "=", "length_embedder", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "BILOU_tag_projection_layer", "=", "BILOU_tag_projection_layer", "\n", "\n", "self", ".", "start_id", "=", "self", ".", "tagset_size", "-", "1", "\n", "self", ".", "stop_id", "=", "self", ".", "tagset_size", "-", "2", "\n", "\n", "self", ".", "tanher", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "self", ".", "ix_to_tag", "[", "self", ".", "start_id", "]", "=", "'START'", "\n", "self", ".", "ix_to_tag", "[", "self", ".", "stop_id", "]", "=", "'STOP'", "\n", "\n", "\n", "self", ".", "index_embeds", "=", "nn", ".", "Embedding", "(", "self", ".", "ALLOWED_SPANLEN", ",", "self", ".", "index_embeds_dim", ")", "\n", "self", ".", "init_embedding", "(", "self", ".", "index_embeds", ".", "weight", ")", "\n", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "word_rep_dim", ",", "self", ".", "SCRF_feature_dim", ")", "\n", "self", ".", "init_linear", "(", "self", ".", "dense", ")", "\n", "\n", "# 4 for SBIE, 3 for START, STOP, O and 2 for START and O", "\n", "self", ".", "CRF_tagset_size", "=", "4", "*", "(", "self", ".", "tagset_size", "-", "3", ")", "+", "2", "\n", "\n", "self", ".", "transition", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "tagset_size", ",", "self", ".", "tagset_size", ")", ")", "\n", "\n", "span_word_embedding_dim", "=", "2", "*", "self", ".", "SCRF_feature_dim", "+", "self", ".", "index_embeds_dim", "+", "4", "*", "4", "\n", "self", ".", "new_hidden2CRFtag", "=", "nn", ".", "Linear", "(", "span_word_embedding_dim", ",", "self", ".", "CRF_tagset_size", ")", "\n", "self", ".", "init_linear", "(", "self", ".", "new_hidden2CRFtag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.init_embedding": [[57, 63], ["numpy.sqrt", "torch.init.uniform", "torch.init.uniform", "torch.init.uniform", "input_embedding.size"], "methods", ["None"], ["", "def", "init_embedding", "(", "self", ",", "input_embedding", ")", ":", "\n", "        ", "\"\"\"\n        Initialize embedding\n        \"\"\"", "\n", "bias", "=", "np", ".", "sqrt", "(", "3.0", "/", "input_embedding", ".", "size", "(", "1", ")", ")", "\n", "nn", ".", "init", ".", "uniform", "(", "input_embedding", ",", "-", "bias", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.init_linear": [[64, 72], ["numpy.sqrt", "torch.init.uniform", "torch.init.uniform", "torch.init.uniform", "input_linear.bias.data.zero_", "input_linear.weight.size", "input_linear.weight.size"], "methods", ["None"], ["", "def", "init_linear", "(", "self", ",", "input_linear", ")", ":", "\n", "        ", "\"\"\"\n        Initialize linear transformation\n        \"\"\"", "\n", "bias", "=", "np", ".", "sqrt", "(", "6.0", "/", "(", "input_linear", ".", "weight", ".", "size", "(", "0", ")", "+", "input_linear", ".", "weight", ".", "size", "(", "1", ")", ")", ")", "\n", "nn", ".", "init", ".", "uniform", "(", "input_linear", ".", "weight", ",", "-", "bias", ",", "bias", ")", "\n", "if", "input_linear", ".", "bias", "is", "not", "None", ":", "\n", "            ", "input_linear", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_logloss_denominator": [[73, 95], ["torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "mask.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "alpha[].sum", "allennlp.get_device_of", "list", "tmp.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "range", "logalpha[].unsqueeze().expand", "max_tmp.view", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "mask.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "tmp.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "logalpha[].unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "mask.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "tmp.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "", "def", "get_logloss_denominator", "(", "self", ",", "scores", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        calculate all path scores of SCRF with dynamic programming\n        args:\n            scores (batch_size, sent_len, sent_len, self.tagset_size, self.tagset_size) : features for SCRF\n            mask   (batch_size) : mask for words\n        \"\"\"", "\n", "\n", "logalpha", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "self", ".", "batch_size", ",", "self", ".", "sent_len", "+", "1", ",", "self", ".", "tagset_size", ")", ".", "fill_", "(", "-", "10000.", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "mask", ")", ")", "\n", "logalpha", "[", ":", ",", "0", ",", "self", ".", "start_id", "]", "=", "0.", "\n", "istarts", "=", "[", "0", "]", "*", "self", ".", "ALLOWED_SPANLEN", "+", "list", "(", "range", "(", "self", ".", "sent_len", "-", "self", ".", "ALLOWED_SPANLEN", "+", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "sent_len", "+", "1", ")", ":", "\n", "            ", "tmp", "=", "scores", "[", ":", ",", "istarts", "[", "i", "]", ":", "i", ",", "i", "-", "1", "]", "+", "logalpha", "[", ":", ",", "istarts", "[", "i", "]", ":", "i", "]", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "self", ".", "batch_size", ",", "i", "-", "istarts", "[", "i", "]", ",", "self", ".", "tagset_size", ",", "self", ".", "tagset_size", ")", "\n", "tmp", "=", "tmp", ".", "transpose", "(", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "batch_size", ",", "self", ".", "tagset_size", ",", "(", "i", "-", "istarts", "[", "i", "]", ")", "*", "self", ".", "tagset_size", ")", "\n", "max_tmp", ",", "_", "=", "torch", ".", "max", "(", "tmp", ",", "dim", "=", "2", ")", "\n", "tmp", "=", "tmp", "-", "max_tmp", ".", "view", "(", "self", ".", "batch_size", ",", "self", ".", "tagset_size", ",", "1", ")", "\n", "logalpha", "[", ":", ",", "i", "]", "=", "max_tmp", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "tmp", ")", ",", "dim", "=", "2", ")", ")", "\n", "\n", "", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "self", ".", "batch_size", ",", "1", ",", "self", ".", "tagset_size", ")", "\n", "alpha", "=", "torch", ".", "gather", "(", "logalpha", ",", "1", ",", "mask", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "alpha", "[", ":", ",", "self", ".", "stop_id", "]", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.decode": [[96, 139], ["factexprscalars.size", "factexprscalars.size", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.FloatTensor().fill_().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "range", "allennlp.get_device_of", "allennlp.get_device_of", "allennlp.get_device_of", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "batch_scores.append", "batch_spans.append", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "max", "factexprscalars[].permute().contiguous().view", "logalpha[].contiguous().view().expand", "max", "int", "int", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "factexprscalars[].permute().contiguous", "logalpha[].contiguous().view", "int", "int", "factexprscalars[].permute", "logalpha[].contiguous", "int", "int"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "factexprscalars", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        decode SCRF labels with dynamic programming\n        args:\n            factexprscalars (batch_size, sent_len, sent_len, self.tagset_size, self.tagset_size) : features for SCRF\n            mask            (batch_size) : mask for words\n        \"\"\"", "\n", "\n", "batch_size", "=", "factexprscalars", ".", "size", "(", "0", ")", "\n", "sentlen", "=", "factexprscalars", ".", "size", "(", "1", ")", "\n", "factexprscalars", "=", "factexprscalars", ".", "data", "\n", "logalpha", "=", "torch", ".", "FloatTensor", "(", "batch_size", ",", "sentlen", "+", "1", ",", "self", ".", "tagset_size", ")", ".", "fill_", "(", "-", "10000.", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "mask", ")", ")", "\n", "logalpha", "[", ":", ",", "0", ",", "self", ".", "start_id", "]", "=", "0.", "\n", "starts", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "sentlen", ",", "self", ".", "tagset_size", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "mask", ")", ")", "\n", "ys", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "sentlen", ",", "self", ".", "tagset_size", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "mask", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "1", ",", "sentlen", "+", "1", ")", ":", "\n", "            ", "istart", "=", "0", "\n", "if", "j", ">", "self", ".", "ALLOWED_SPANLEN", ":", "\n", "                ", "istart", "=", "max", "(", "0", ",", "j", "-", "self", ".", "ALLOWED_SPANLEN", ")", "\n", "", "f", "=", "factexprscalars", "[", ":", ",", "istart", ":", "j", ",", "j", "-", "1", "]", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "self", ".", "tagset_size", ",", "-", "1", ")", "+", "logalpha", "[", ":", ",", "istart", ":", "j", "]", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "tagset_size", ",", "(", "j", "-", "istart", ")", "*", "self", ".", "tagset_size", ")", "\n", "logalpha", "[", ":", ",", "j", ",", ":", "]", ",", "argm", "=", "torch", ".", "max", "(", "f", ",", "dim", "=", "2", ")", "\n", "starts", "[", ":", ",", "j", "-", "1", ",", ":", "]", "=", "(", "argm", "/", "self", ".", "tagset_size", "+", "istart", ")", "\n", "ys", "[", ":", ",", "j", "-", "1", ",", ":", "]", "=", "(", "argm", "%", "self", ".", "tagset_size", ")", "\n", "\n", "", "batch_scores", "=", "[", "]", "\n", "batch_spans", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "spans", "=", "{", "}", "\n", "batch_scores", ".", "append", "(", "max", "(", "logalpha", "[", "i", ",", "mask", "[", "i", "]", "-", "1", "]", ")", ")", "\n", "end", "=", "mask", "[", "i", "]", "-", "1", "\n", "y", "=", "self", ".", "stop_id", "\n", "while", "end", ">=", "0", ":", "\n", "                ", "start", "=", "int", "(", "starts", "[", "i", ",", "end", ",", "y", "]", ")", "\n", "y_1", "=", "int", "(", "ys", "[", "i", ",", "end", ",", "y", "]", ")", "\n", "if", "self", ".", "ix_to_tag", "[", "int", "(", "y", ")", "]", "not", "in", "(", "'START'", ",", "'STOP'", ")", ":", "\n", "                    ", "spans", "[", "(", "int", "(", "start", ")", ",", "int", "(", "end", ")", ")", "]", "=", "self", ".", "ix_to_tag", "[", "int", "(", "y", ")", "]", "\n", "", "y", "=", "y_1", "\n", "end", "=", "start", "-", "1", "\n", "", "batch_spans", ".", "append", "(", "spans", ")", "\n", "pass", "\n", "", "return", "batch_spans", ",", "batch_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_logloss_numerator": [[140, 156], ["scores.size", "scores.size", "scores.size", "scores.view", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather.masked_select", "torch.gather.masked_select", "torch.gather.masked_select", "mask.byte"], "methods", ["None"], ["", "def", "get_logloss_numerator", "(", "self", ",", "goldfactors", ",", "scores", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        get scores of best path\n        args:\n            goldfactors (batch_size, tag_len, 4) : path labels\n            scores      (batch_size, sent_len, sent_len, self.tagset_size, self.tagset_size) : all tag scores\n            mask        (batch_size, tag_len) : mask for goldfactors\n        \"\"\"", "\n", "batch_size", "=", "scores", ".", "size", "(", "0", ")", "\n", "sent_len", "=", "scores", ".", "size", "(", "1", ")", "\n", "tagset_size", "=", "scores", ".", "size", "(", "3", ")", "\n", "goldfactors", "=", "goldfactors", "[", ":", ",", ":", ",", "0", "]", "*", "sent_len", "*", "tagset_size", "*", "tagset_size", "+", "goldfactors", "[", ":", ",", ":", ",", "1", "]", "*", "tagset_size", "*", "tagset_size", "+", "goldfactors", "[", ":", ",", ":", ",", "2", "]", "*", "tagset_size", "+", "goldfactors", "[", ":", ",", ":", ",", "3", "]", "\n", "factorexprs", "=", "scores", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "val", "=", "torch", ".", "gather", "(", "factorexprs", ",", "1", ",", "goldfactors", ")", "\n", "numerator", "=", "val", ".", "masked_select", "(", "mask", ".", "byte", "(", ")", ")", "\n", "return", "numerator", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.HSCRF_scores": [[158, 202], ["torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "allennlp.get_device_of", "allennlp.get_device_of", "allennlp.get_device_of", "allennlp.get_device_of", "min", "hscrf_layer_SoftDict.HSCRF.concat_features", "hscrf_layer_SoftDict.HSCRF.new_hidden2CRFtag", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.FloatTensor().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze", "emb_x[].unsqueeze", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze", "emb_x[].unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze().expand", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze().expand", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze().expand", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze().unsqueeze", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze", "emb_x[].sum", "hscrf_layer_SoftDict.HSCRF.transition[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.concat_features"], ["", "def", "HSCRF_scores", "(", "self", ",", "global_feats", ",", "token_indices", ")", ":", "\n", "        ", "\"\"\"\n        calculate SCRF scores with HSCRF\n        args:\n            global_feats (batch_size, sentence_len, featsdim) : word representations\n        \"\"\"", "\n", "\n", "# 3 for O, STOP, START", "\n", "validtag_size", "=", "self", ".", "tagset_size", "-", "3", "\n", "scores", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "batch_size", ",", "self", ".", "sent_len", ",", "self", ".", "sent_len", ",", "self", ".", "tagset_size", ",", "self", ".", "tagset_size", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "global_feats", ")", ")", "\n", "diag0", "=", "torch", ".", "LongTensor", "(", "range", "(", "self", ".", "sent_len", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "global_feats", ")", ")", "\n", "# m10000 for STOP", "\n", "m10000", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "[", "-", "10000.", "]", ")", ".", "expand", "(", "self", ".", "batch_size", ",", "self", ".", "sent_len", ",", "self", ".", "tagset_size", ",", "1", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "global_feats", ")", ")", "\n", "# m30000 for O, START, STOP", "\n", "m30000", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "[", "-", "10000.", "]", ")", ".", "expand", "(", "self", ".", "batch_size", ",", "self", ".", "sent_len", ",", "self", ".", "tagset_size", ",", "3", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "global_feats", ")", ")", "\n", "for", "span_len", "in", "range", "(", "min", "(", "self", ".", "ALLOWED_SPANLEN", ",", "self", ".", "sent_len", "-", "1", ")", ")", ":", "\n", "            ", "emb_x", "=", "self", ".", "concat_features", "(", "global_feats", ",", "token_indices", ",", "span_len", ")", "\n", "emb_x", "=", "self", ".", "new_hidden2CRFtag", "(", "emb_x", ")", "\n", "if", "span_len", "==", "0", ":", "\n", "                ", "tmp", "=", "torch", ".", "cat", "(", "(", "self", ".", "transition", "[", ":", ",", ":", "validtag_size", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "+", "emb_x", "[", ":", ",", "0", ",", ":", ",", ":", "validtag_size", "]", ".", "unsqueeze", "(", "2", ")", ",", "\n", "self", ".", "transition", "[", ":", ",", "-", "2", ":", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "+", "emb_x", "[", ":", ",", "0", ",", ":", ",", "-", "2", ":", "]", ".", "unsqueeze", "(", "2", ")", ",", "\n", "m10000", ")", ",", "3", ")", "\n", "scores", "[", ":", ",", "diag0", ",", "diag0", "]", "=", "tmp", "\n", "", "elif", "span_len", "==", "1", ":", "\n", "                ", "tmp", "=", "torch", ".", "cat", "(", "(", "self", ".", "transition", "[", ":", ",", ":", "validtag_size", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "self", ".", "batch_size", ",", "self", ".", "sent_len", "-", "1", ",", "self", ".", "tagset_size", ",", "validtag_size", ")", "+", "(", "emb_x", "[", ":", ",", "0", ",", ":", ",", "validtag_size", ":", "2", "*", "validtag_size", "]", "+", "\n", "emb_x", "[", ":", ",", "1", ",", ":", ",", "3", "*", "validtag_size", ":", "4", "*", "validtag_size", "]", ")", ".", "unsqueeze", "(", "2", ")", ",", "m30000", "[", ":", ",", "1", ":", "]", ")", ",", "3", ")", "\n", "scores", "[", ":", ",", "diag0", "[", ":", "-", "1", "]", ",", "diag0", "[", "1", ":", "]", "]", "=", "tmp", "\n", "\n", "", "elif", "span_len", "==", "2", ":", "\n", "                ", "tmp", "=", "torch", ".", "cat", "(", "(", "self", ".", "transition", "[", ":", ",", ":", "validtag_size", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "self", ".", "batch_size", ",", "self", ".", "sent_len", "-", "2", ",", "self", ".", "tagset_size", ",", "validtag_size", ")", "+", "(", "emb_x", "[", ":", ",", "0", ",", ":", ",", "validtag_size", ":", "2", "*", "validtag_size", "]", "+", "\n", "emb_x", "[", ":", ",", "1", ",", ":", ",", "2", "*", "validtag_size", ":", "3", "*", "validtag_size", "]", "+", "\n", "emb_x", "[", ":", ",", "2", ",", ":", ",", "3", "*", "validtag_size", ":", "4", "*", "validtag_size", "]", ")", ".", "unsqueeze", "(", "2", ")", ",", "m30000", "[", ":", ",", "2", ":", "]", ")", ",", "3", ")", "\n", "scores", "[", ":", ",", "diag0", "[", ":", "-", "2", "]", ",", "diag0", "[", "2", ":", "]", "]", "=", "tmp", "\n", "\n", "", "elif", "span_len", ">=", "3", ":", "\n", "                ", "tmp0", "=", "self", ".", "transition", "[", ":", ",", ":", "validtag_size", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "self", ".", "batch_size", ",", "self", ".", "sent_len", "-", "span_len", ",", "self", ".", "tagset_size", ",", "validtag_size", ")", "+", "(", "emb_x", "[", ":", ",", "0", ",", ":", ",", "validtag_size", ":", "2", "*", "validtag_size", "]", "+", "\n", "emb_x", "[", ":", ",", "1", ":", "span_len", ",", ":", ",", "2", "*", "validtag_size", ":", "3", "*", "validtag_size", "]", ".", "sum", "(", "1", ")", "+", "\n", "emb_x", "[", ":", ",", "span_len", ",", ":", ",", "3", "*", "validtag_size", ":", "4", "*", "validtag_size", "]", ")", ".", "unsqueeze", "(", "2", ")", "\n", "tmp", "=", "torch", ".", "cat", "(", "(", "tmp0", ",", "m30000", "[", ":", ",", "span_len", ":", "]", ")", ",", "3", ")", "\n", "scores", "[", ":", ",", "diag0", "[", ":", "-", "span_len", "]", ",", "diag0", "[", "span_len", ":", "]", "]", "=", "tmp", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.concat_features": [[203, 230], ["emb_z.unsqueeze().expand.unsqueeze().expand.size", "emb_z.unsqueeze().expand.unsqueeze().expand.size", "emb_z.unsqueeze().expand.unsqueeze().expand.size", "emb_z.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "hscrf_layer_SoftDict.HSCRF.index_embeds().unsqueeze().unsqueeze().expand", "hscrf_layer_SoftDict.HSCRF.get_BILOU_features", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.transpose().contiguous", "torch.cat.transpose().contiguous", "torch.cat.transpose().contiguous", "allennlp.get_device_of", "emb_z.unsqueeze().expand.unsqueeze().expand.unsqueeze", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "hscrf_layer_SoftDict.HSCRF.index_embeds().unsqueeze().unsqueeze", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "hscrf_layer_SoftDict.HSCRF.index_embeds().unsqueeze", "hscrf_layer_SoftDict.HSCRF.index_embeds"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_BILOU_features"], ["", "def", "concat_features", "(", "self", ",", "emb_z", ",", "token_indices", ",", "span_len", ")", ":", "\n", "        ", "\"\"\"\n        concatenate two features\n        args:\n            emb_z (batch_size, sentence_len, featsdim) : contextualized word representations\n            token_indices: Dict[str, LongTensor], indices of different fields\n            span_len: a number (from 0)\n        \"\"\"", "\n", "batch_size", "=", "emb_z", ".", "size", "(", "0", ")", "\n", "sent_len", "=", "emb_z", ".", "size", "(", "1", ")", "\n", "hidden_dim", "=", "emb_z", ".", "size", "(", "2", ")", "\n", "emb_z", "=", "emb_z", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "sent_len", ",", "hidden_dim", ")", "\n", "\n", "span_exprs", "=", "[", "emb_z", "[", ":", ",", ":", ",", "i", ":", "i", "+", "span_len", "+", "1", "]", "for", "i", "in", "range", "(", "sent_len", "-", "span_len", ")", "]", "\n", "span_exprs", "=", "torch", ".", "cat", "(", "span_exprs", ",", "1", ")", "\n", "\n", "endpoint_vec", "=", "(", "span_exprs", "[", ":", ",", ":", ",", "0", "]", "-", "span_exprs", "[", ":", ",", ":", ",", "span_len", "]", ")", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "batch_size", ",", "sent_len", "-", "span_len", ",", "span_len", "+", "1", ",", "hidden_dim", ")", "\n", "\n", "index", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "range", "(", "span_len", "+", "1", ")", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "emb_z", ")", ")", "\n", "index", "=", "self", ".", "index_embeds", "(", "index", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "sent_len", "-", "span_len", ",", "span_len", "+", "1", ",", "self", ".", "index_embeds_dim", ")", "\n", "\n", "\n", "BILOU_features", "=", "self", ".", "get_BILOU_features", "(", "token_indices", ",", "sent_len", ",", "span_len", ")", "\n", "\n", "new_emb", "=", "torch", ".", "cat", "(", "(", "span_exprs", ",", "BILOU_features", ",", "endpoint_vec", ",", "index", ")", ",", "3", ")", "\n", "\n", "return", "new_emb", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_BILOU_features": [[232, 265], ["list", "hscrf_layer_SoftDict.HSCRF.softdict_text_field_embedder", "allennlp.get_text_field_mask", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad.size", "torch.pad.size", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "hscrf_layer_SoftDict.HSCRF.length_embedder().unsqueeze().unsqueeze().expand", "hscrf_layer_SoftDict.HSCRF.encoder", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "hscrf_layer_SoftDict.HSCRF.BILOU_tag_projection_layer", "hscrf_layer_SoftDict.HSCRF.tanher", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "span_logits[].detach", "token_indices.items", "val.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.pad.size", "allennlp.get_device_of", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "hscrf_layer_SoftDict.HSCRF.length_embedder().unsqueeze().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "range", "range", "hscrf_layer_SoftDict.HSCRF.length_embedder().unsqueeze", "hscrf_layer_SoftDict.HSCRF.length_embedder"], "methods", ["None"], ["", "def", "get_BILOU_features", "(", "self", ",", "token_indices", ",", "sent_len", ",", "span_len", ")", ":", "\n", "\n", "        ", "span_level_token_indices", "=", "{", "}", "\n", "for", "ky", ",", "val", "in", "list", "(", "token_indices", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "ky", "==", "'elmo'", ":", "\n", "                ", "continue", "\n", "", "val", "=", "val", ".", "unsqueeze", "(", "1", ")", "\n", "span_level_token_indices", "[", "ky", "]", "=", "torch", ".", "cat", "(", "[", "val", "[", ":", ",", ":", ",", "i", ":", "i", "+", "span_len", "+", "1", "]", "for", "i", "in", "range", "(", "sent_len", "-", "1", "-", "span_len", ")", "]", ",", "1", ")", "\n", "\n", "", "spans_embedded", "=", "self", ".", "softdict_text_field_embedder", "(", "span_level_token_indices", ",", "num_wrapping_dims", "=", "1", ")", "\n", "spans_mask", "=", "util", ".", "get_text_field_mask", "(", "span_level_token_indices", ",", "num_wrapping_dims", "=", "1", ")", "\n", "\n", "dim_2_pad", "=", "self", ".", "ALLOWED_SPANLEN", "-", "spans_embedded", ".", "size", "(", "2", ")", "\n", "p2d", "=", "(", "0", ",", "0", ",", "0", ",", "dim_2_pad", ")", "\n", "# now shape (batch_size, num_span, max_span_width, dim)", "\n", "spans_embedded", "=", "F", ".", "pad", "(", "spans_embedded", ",", "p2d", ",", "\"constant\"", ",", "0.", ")", "\n", "spans_mask", "=", "F", ".", "pad", "(", "spans_mask", ",", "(", "0", ",", "dim_2_pad", ")", ",", "\"constant\"", ",", "0.", ")", "\n", "\n", "batch_size", "=", "spans_mask", ".", "size", "(", "0", ")", "\n", "num_spans", "=", "spans_mask", ".", "size", "(", "1", ")", "\n", "length_vec", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "range", "(", "self", ".", "ALLOWED_SPANLEN", ")", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "spans_mask", ")", ")", "\n", "length_vec", "=", "self", ".", "length_embedder", "(", "length_vec", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "num_spans", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "spans_encoded", "=", "self", ".", "encoder", "(", "spans_embedded", ",", "spans_mask", ")", "\n", "\n", "spans_encoded", "=", "torch", ".", "cat", "(", "(", "spans_encoded", ",", "length_vec", ")", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "\n", "# shape (batch_size, num_spans, max_span_wid, 4* span_tags) BILU", "\n", "span_logits", "=", "self", ".", "BILOU_tag_projection_layer", "(", "spans_encoded", ")", "\n", "span_logits", "=", "self", ".", "tanher", "(", "span_logits", ")", "\n", "span_logits", "=", "torch", ".", "cat", "(", "[", "span_logits", ",", "span_logits", ".", "new_zeros", "(", "batch_size", ",", "1", ",", "span_logits", ".", "size", "(", "2", ")", ",", "span_logits", ".", "size", "(", "3", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "return", "span_logits", "[", ":", ",", ":", ",", ":", "span_len", "+", "1", ",", ":", "]", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.forward": [[267, 285], ["hscrf_layer_SoftDict.HSCRF.size", "hscrf_layer_SoftDict.HSCRF.size", "hscrf_layer_SoftDict.HSCRF.dense", "hscrf_layer_SoftDict.HSCRF.HSCRF_scores", "hscrf_layer_SoftDict.HSCRF.get_logloss_denominator", "hscrf_layer_SoftDict.HSCRF.get_logloss_numerator", "hscrf_layer_SoftDict.HSCRF.sum"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.HSCRF_scores", "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_logloss_denominator", "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_logloss_numerator"], ["", "def", "forward", "(", "self", ",", "feats", ",", "token_indices", ",", "mask_word", ",", "tags", ",", "mask_tag", ")", ":", "\n", "        ", "\"\"\"\n        calculate loss\n        args:\n            feats (batch_size, sent_len, featsdim) : word representations\n            mask_word (batch_size) : sentence lengths\n            tags (batch_size, tag_len, 4) : target\n            mask_tag (batch_size, tag_len) : tag_len <= sentence_len\n        \"\"\"", "\n", "self", ".", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "self", ".", "sent_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "feats", "=", "self", ".", "dense", "(", "feats", ")", "\n", "\n", "self", ".", "SCRF_scores", "=", "self", ".", "HSCRF_scores", "(", "feats", ",", "token_indices", ")", "\n", "forward_score", "=", "self", ".", "get_logloss_denominator", "(", "self", ".", "SCRF_scores", ",", "mask_word", ")", "\n", "numerator", "=", "self", ".", "get_logloss_numerator", "(", "tags", ",", "self", ".", "SCRF_scores", ",", "mask_tag", ")", "\n", "\n", "return", "(", "forward_score", "-", "numerator", ".", "sum", "(", ")", ")", "/", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_scrf_decode": [[286, 295], ["hscrf_layer_SoftDict.HSCRF.decode"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "get_scrf_decode", "(", "self", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        decode with SCRF\n        args:\n            feats (batch_size, sent_len, featsdim) : word representations\n            mask  (batch_size) : mask for words\n        \"\"\"", "\n", "batch_spans", ",", "batch_scores", "=", "self", ".", "decode", "(", "self", ".", "SCRF_scores", ",", "mask", ")", "\n", "return", "batch_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.span_based_chunker.SpanBasedChunker.__init__": [[24, 28], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SpanBasedChunker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# nothing...", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.span_based_chunker.SpanBasedChunker.forward": [[29, 41], ["span_based_chunker.SpanBasedChunker._input_likelihood", "span_based_chunker.SpanBasedChunker._joint_likelihood", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.modules.span_based_chunker.SpanBasedChunker._input_likelihood", "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.span_based_chunker.SpanBasedChunker._joint_likelihood"], ["", "def", "forward", "(", "self", ",", "spans", ":", "torch", ".", "Tensor", ",", "\n", "span_scores", ":", "torch", ".", "Tensor", ",", "\n", "gold_spans", ":", "torch", ".", "Tensor", ",", "\n", "gold_span_labels", ":", "torch", ".", "Tensor", ",", "\n", "span_mask", ":", "torch", ".", "Tensor", ",", "\n", "gold_span_mask", ":", "torch", ".", "Tensor", ",", "\n", "token_mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "\n", "        ", "log_denominator", "=", "self", ".", "_input_likelihood", "(", "token_mask", ",", "spans", ",", "span_scores", ",", "span_mask", ")", "\n", "log_numerator", "=", "self", ".", "_joint_likelihood", "(", "token_mask", ",", "spans", ",", "gold_spans", ",", "gold_span_labels", ",", "span_scores", ",", "gold_span_mask", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "log_numerator", "-", "log_denominator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.span_based_chunker.SpanBasedChunker._input_likelihood": [[43, 95], ["token_mask.size", "spans.transpose().contiguous.transpose().contiguous.transpose().contiguous", "span_mask.float().transpose().contiguous.float().transpose().contiguous.float().transpose().contiguous", "span_scores.transpose().contiguous.transpose().contiguous.transpose().contiguous", "span_scores.transpose().contiguous.transpose().contiguous.new_zeros", "span_based_chunker.SpanBasedChunker._input_likelihood._select_span_score"], "methods", ["None"], ["", "def", "_input_likelihood", "(", "self", ",", "token_mask", ":", "torch", ".", "Tensor", ",", "spans", ":", "torch", ".", "Tensor", ",", "span_scores", ":", "torch", ".", "Tensor", ",", "span_mask", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the (batch_size,) denominator term for the log-likelihood, which is the\n        sum of the likelihoods across all possible segmentation sequences. Using Dynamic programming.\n        Dp matrix: Shape (batch_size, sequence_length, sequence_length+1)\n                          batch_size, current_index  , last segment starting index\n        \"\"\"", "\n", "\n", "def", "_select_span_score", "(", "_span_scores", ",", "_spans", ",", "_start", ",", "_end", ",", "keepdim", ")", ":", "\n", "            ", "return", "_span_scores", ".", "where", "(", "(", "_spans", "[", ":", ",", ":", ",", "0", "]", "==", "_start", ")", "*", "(", "_spans", "[", ":", ",", ":", ",", "1", "]", "==", "_end", ")", ",", "torch", ".", "zeros_like", "(", "_span_scores", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "keepdim", ")", "\n", "\n", "", "batch_size", ",", "sequence_length", "=", "token_mask", ".", "size", "(", ")", "\n", "\n", "# Transpose batch size and sequence dimensions", "\n", "\n", "# Shape: (num_spans, batch_size, 2)", "\n", "spans", "=", "spans", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Shape: (num_spans, batch_size)", "\n", "span_mask", "=", "span_mask", ".", "float", "(", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Shape: (num_spans, batch_size, 1)", "\n", "span_scores", "=", "span_scores", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Initial alpha is the (batch_size, sequence_length, sequence_length+1) tensor of likelihoods combining the", "\n", "# transitions to the initial states and the logits for the first timestep.", "\n", "\n", "alpha", "=", "span_scores", ".", "new_zeros", "(", "sequence_length", "+", "1", ",", "batch_size", ",", "sequence_length", "+", "1", ")", "\n", "# Shape: need to add one when indexing in alpha", "\n", "alpha", "[", "1", ",", ":", ",", "0", "]", "=", "-", "_select_span_score", "(", "span_scores", ".", "transpose", "(", "0", ",", "1", ")", ",", "spans", ".", "transpose", "(", "0", ",", "1", ")", ",", "0", ",", "0", ",", "False", ")", "# negative logit --  non-entity score", "\n", "alpha", "[", "1", ",", ":", ",", "1", "]", "=", "_select_span_score", "(", "span_scores", ".", "transpose", "(", "0", ",", "1", ")", ",", "spans", ".", "transpose", "(", "0", ",", "1", ")", ",", "0", ",", "0", ",", "False", ")", "\n", "\n", "# For each i we compute logits for the transitions from timestep 0:i-1 to timestep i.", "\n", "# We do so in a (batch_size, num_tags, num_tags) tensor where the axes are", "\n", "# (instance, current_tag, next_tag)", "\n", "for", "i", "in", "range", "(", "2", ",", "sequence_length", "+", "1", ")", ":", "\n", "            ", "alpha", "[", "i", ",", ":", ",", "0", "]", "=", "util", ".", "logsumexp", "(", "alpha", "[", "i", "-", "1", ",", ":", ",", ":", "i", "]", "-", "_select_span_score", "(", "span_scores", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "spans", ".", "transpose", "(", "0", ",", "1", ")", ",", "i", "-", "1", ",", "i", "-", "1", ",", "True", ")", ",", "1", ")", "\n", "for", "j", "in", "range", "(", "1", ",", "i", "+", "1", ")", ":", "\n", "# j is the start index of the current span", "\n", "# j = 0: current word_i is not an entity", "\n", "                ", "alpha", "[", "i", ",", ":", ",", "j", "]", "=", "util", ".", "logsumexp", "(", "alpha", "[", "j", "-", "1", ",", ":", ",", ":", "j", "]", "+", "_select_span_score", "(", "span_scores", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "spans", ".", "transpose", "(", "0", ",", "1", ")", ",", "j", "-", "1", ",", "i", "-", "1", ",", "True", ")", ",", "1", ")", "\n", "\n", "# We don't have to apply mask to alpha because we only select the indices of the scores of each sample", "\n", "# that we need", "\n", "\n", "", "", "total_score", "=", "util", ".", "batched_index_select", "(", "alpha", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "token_mask", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "total_score", "=", "torch", ".", "squeeze", "(", "total_score", ")", "\n", "\n", "total_score", "[", ":", ",", "1", ":", "]", "+=", "token_mask", ".", "log", "(", ")", "\n", "return", "util", ".", "logsumexp", "(", "total_score", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.span_based_chunker.SpanBasedChunker._joint_likelihood": [[98, 137], ["token_mask.size", "gold_spans.transpose().contiguous.transpose().contiguous.transpose().contiguous", "gold_span_labels.transpose().contiguous.transpose().contiguous.transpose().contiguous", "gold_span_mask.float().transpose().contiguous.float().transpose().contiguous.float().transpose().contiguous", "span_scores.transpose().contiguous.transpose().contiguous.transpose().contiguous", "span_scores.transpose().contiguous.transpose().contiguous.new_zeros", "range", "_span_scores.where().sum", "gold_spans.transpose().contiguous.transpose().contiguous.transpose", "gold_span_labels.transpose().contiguous.transpose().contiguous.transpose", "gold_span_mask.float().transpose().contiguous.float().transpose().contiguous.float().transpose", "span_scores.transpose().contiguous.transpose().contiguous.transpose", "_span_scores.where", "span_based_chunker.SpanBasedChunker._joint_likelihood._batch_select_span_score"], "methods", ["None"], ["", "def", "_joint_likelihood", "(", "self", ",", "token_mask", ":", "torch", ".", "Tensor", ",", "spans", ":", "torch", ".", "Tensor", ",", "gold_spans", ":", "torch", ".", "Tensor", ",", "gold_span_labels", ":", "torch", ".", "Tensor", ",", "span_scores", ":", "torch", ".", "Tensor", ",", "gold_span_mask", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "def", "_batch_select_span_score", "(", "_span_scores", ",", "_spans", ",", "_batch_gold_spans", ",", "keepdim", ")", ":", "\n", "# _span_scores: shape(batch_size, num_spans)", "\n", "# _spans      : shape(batch_size, num_spans, 2)", "\n", "#_batch_gold_spans : shape(batch_size, 2)", "\n", "# return: shape(batch_size, 1)(if keepdim)", "\n", "            ", "return", "_span_scores", ".", "where", "(", "(", "(", "_spans", "[", ":", ",", ":", ",", "0", "]", "==", "_batch_gold_spans", "[", ":", ",", "0", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "*", "(", "_spans", "[", ":", ",", ":", ",", "1", "]", "==", "_batch_gold_spans", "[", ":", ",", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", ",", "\n", "torch", ".", "zeros_like", "(", "_span_scores", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "keepdim", ")", "\n", "\n", "", "batch_size", ",", "sequence_length", "=", "token_mask", ".", "size", "(", ")", "\n", "num_gold_spans", "=", "gold_spans", ".", "data", ".", "shape", "[", "1", "]", "\n", "\n", "# Transpose batch size and sequence dimensions", "\n", "\n", "# Shape: (num_gold_spans, batch_size, 2)", "\n", "gold_spans", "=", "gold_spans", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Shape: (num_gold_spans, batch_size, 1), 0 for 'O', 1 for 'I'", "\n", "gold_span_labels", "=", "gold_span_labels", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Shape: (num_gold_spans, batch_size)", "\n", "gold_span_mask", "=", "gold_span_mask", ".", "float", "(", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Shape: (num_spans, batch_size, 1)", "\n", "span_scores", "=", "span_scores", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Initial alpha is the (batch_size, sequence_length, sequence_length+1) tensor of likelihoods combining the", "\n", "# transitions to the initial states and the logits for the first timestep.", "\n", "\n", "alpha", "=", "span_scores", ".", "new_zeros", "(", "batch_size", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_gold_spans", ")", ":", "\n", "\n", "            ", "alpha", "+=", "_batch_select_span_score", "(", "span_scores", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "spans", ".", "long", "(", ")", ",", "\n", "gold_spans", "[", "i", "]", ".", "long", "(", ")", ",", "keepdim", "=", "False", ")", "*", "gold_span_mask", "[", "i", "]", "*", "(", "2", "*", "gold_span_labels", "[", "i", "]", "-", "1", ")", "\n", "\n", "", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.modules.span_based_chunker.SpanBasedChunker._best_chunking": [[139, 227], ["token_mask.size", "enumerate", "torch.tensor", "torch.tensor.max", "torch.stack", "torch.stack", "torch.Tensor", "_span_scores.where().sum", "zip", "_one_token_mask.long().sum", "span_scores.new_zeros", "span_based_chunker.SpanBasedChunker._input_likelihood._select_span_score"], "methods", ["None"], ["", "def", "_best_chunking", "(", "self", ",", "token_mask", ":", "torch", ".", "Tensor", ",", "spans", ":", "torch", ".", "Tensor", ",", "span_scores", ":", "torch", ".", "Tensor", ",", "span_mask", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "'''\n            maximize the chunking score\n            return:\n                gold_spans\n                gold_span_labels\n                max_score\n                gold_spans_masks\n        '''", "\n", "def", "_select_span_score", "(", "_span_scores", ",", "_spans", ",", "_start", ",", "_end", ",", "keepdim", ")", ":", "\n", "            ", "return", "_span_scores", ".", "where", "(", "(", "_spans", "[", ":", ",", "0", "]", "==", "_start", ")", "*", "(", "_spans", "[", ":", ",", "1", "]", "==", "_end", ")", ",", "torch", ".", "zeros_like", "(", "_span_scores", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "keepdim", ")", "\n", "\n", "", "batch_size", ",", "sequence_length", "=", "token_mask", ".", "size", "(", ")", "\n", "# Initial alpha is the (batch_size, sequence_length, sequence_length+1) tensor of likelihoods combining the", "\n", "# transitions to the initial states and the logits for the first timestep.", "\n", "\n", "# For each i we compute logits for the transitions from timestep 0:i-1 to timestep i.", "\n", "# We do so in a (batch_size, num_tags, num_tags) tensor where the axes are", "\n", "# (instance, current_tag, next_tag)", "\n", "\n", "batch_best_scores", "=", "[", "]", "\n", "batch_best_chunkings", "=", "[", "]", "\n", "batch_best_chunking_labels", "=", "[", "]", "\n", "for", "_batch_id", ",", "(", "_one_spans", ",", "_one_span_scores", ",", "_one_span_mask", ",", "_one_token_mask", ")", "in", "enumerate", "(", "zip", "(", "spans", ",", "span_scores", ",", "span_mask", ",", "token_mask", ")", ")", ":", "\n", "            ", "best_chunkings", "=", "[", "]", "\n", "best_chunking_labels", "=", "[", "]", "\n", "\n", "seq_length", "=", "_one_token_mask", ".", "long", "(", ")", ".", "sum", "(", ")", "# one scalar", "\n", "# chunks = [[None for _id in range(seq_length+1)] for _jd in range(seq_length+1)]", "\n", "alpha", "=", "span_scores", ".", "new_zeros", "(", "seq_length", "+", "1", ",", "seq_length", "+", "1", ")", "\n", "# Shape: need to add one when indexing in alpha", "\n", "alpha", "[", "1", ",", "0", "]", "=", "-", "_select_span_score", "(", "_one_span_scores", ",", "_one_spans", ",", "0", ",", "0", ",", "False", ")", "# negative logit --  non-entity score", "\n", "alpha", "[", "1", ",", "1", "]", "=", "_select_span_score", "(", "_one_span_scores", ",", "_one_spans", ",", "0", ",", "0", ",", "False", ")", "\n", "\n", "for", "i", "in", "range", "(", "2", ",", "int", "(", "seq_length", ")", "+", "1", ")", ":", "\n", "# TODO:", "\n", "# make it parallel", "\n", "                ", "alpha", "[", "i", ",", "0", "]", ",", "prev_start_index", "=", "(", "alpha", "[", "i", "-", "1", ",", ":", "i", "]", "-", "_select_span_score", "(", "_one_span_scores", ",", "\n", "_one_spans", ",", "i", "-", "1", ",", "i", "-", "1", ",", "False", ")", ")", ".", "max", "(", "-", "1", ")", "\n", "# chunks[i][0] = int(prev_start_index)", "\n", "# j = 0: current word_i is not an entity", "\n", "for", "j", "in", "range", "(", "1", ",", "i", "+", "1", ")", ":", "\n", "# j is the start index of the current span", "\n", "                    ", "alpha", "[", "i", ",", "j", "]", ",", "prev_start_index", "=", "(", "alpha", "[", "j", "-", "1", ",", ":", "j", "]", "+", "_select_span_score", "(", "_one_span_scores", ",", "\n", "_one_spans", ",", "j", "-", "1", ",", "i", "-", "1", ",", "False", ")", ")", ".", "max", "(", "-", "1", ")", "\n", "# chunks[i][j] = int(prev_start_index)", "\n", "# We don't have to apply mask to alpha because we only select the indices of the scores of each sample", "\n", "# that we need", "\n", "\n", "", "", "best_score", ",", "last_state", "=", "alpha", "[", "seq_length", ",", ":", "]", ".", "max", "(", "-", "1", ")", "\n", "batch_best_scores", ".", "append", "(", "best_score", ")", "\n", "\n", "last_state", "=", "int", "(", "last_state", ")", "\n", "cur_ptr", "=", "int", "(", "seq_length", ")", "\n", "while", "(", "cur_ptr", ">=", "1", ")", ":", "\n", "                ", "if", "last_state", "==", "0", ":", "\n", "                    ", "best_chunkings", ".", "append", "(", "(", "cur_ptr", "-", "1", ",", "cur_ptr", "-", "1", ")", ")", "# current word does not belong to an entity", "\n", "best_chunking_labels", ".", "append", "(", "0", ")", "\n", "cur_ptr", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "best_chunkings", ".", "append", "(", "(", "last_state", "-", "1", ",", "cur_ptr", "-", "1", ")", ")", "\n", "best_chunking_labels", ".", "append", "(", "1", ")", "\n", "cur_ptr", "=", "last_state", "-", "1", "\n", "\n", "# ALERT...", "\n", "", "_", ",", "last_state", "=", "alpha", "[", "cur_ptr", ",", ":", "]", ".", "max", "(", "-", "1", ")", "# ??? shouldn't it be alpha[cur_ptr, :cur_ptr+1].max(-1)", "\n", "last_state", "=", "int", "(", "last_state", ")", "\n", "\n", "", "batch_best_chunkings", ".", "append", "(", "torch", ".", "Tensor", "(", "best_chunkings", ")", ")", "\n", "batch_best_chunking_labels", ".", "append", "(", "torch", ".", "Tensor", "(", "best_chunking_labels", ")", ")", "\n", "\n", "", "num_spans", "=", "torch", ".", "tensor", "(", "[", "len", "(", "x", ")", "for", "x", "in", "batch_best_chunkings", "]", ")", "\n", "max_num_spans", "=", "num_spans", ".", "max", "(", ")", "\n", "chunking_masks", "=", "torch", ".", "arange", "(", "max_num_spans", ")", ".", "expand", "(", "len", "(", "num_spans", ")", ",", "max_num_spans", ")", "<", "num_spans", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "batch_best_chunkings", "=", "[", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "max_num_spans", "-", "x", ".", "shape", "[", "0", "]", ")", ",", "value", "=", "0", ")", "for", "x", "in", "batch_best_chunkings", "]", "\n", "batch_best_chunkings", "=", "torch", ".", "stack", "(", "batch_best_chunkings", ")", "\n", "\n", "batch_best_chunking_labels", "=", "[", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "x", ",", "(", "0", ",", "max_num_spans", "-", "x", ".", "shape", "[", "0", "]", ")", ",", "value", "=", "0", ")", "for", "x", "in", "batch_best_chunking_labels", "]", "\n", "batch_best_chunking_labels", "=", "torch", ".", "stack", "(", "batch_best_chunking_labels", ")", "\n", "\n", "batch_best_scores", "=", "torch", ".", "Tensor", "(", "batch_best_scores", ")", "\n", "\n", "\n", "return", "{", "'best_score'", ":", "batch_best_scores", ",", "\n", "'best_chunkings'", ":", "batch_best_chunkings", ",", "\n", "'best_chunking_labels'", ":", "batch_best_chunking_labels", ",", "\n", "'chunking_masks'", ":", "chunking_masks", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.span_conll2003_dataset_reader.SpanConll2003DatasetReader.__init__": [[114, 139], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "set", "allennlp.common.checks.ConfigurationError", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.common.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "tag_label", ":", "str", "=", "\"ner\"", ",", "\n", "feature_labels", ":", "Sequence", "[", "str", "]", "=", "(", ")", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "coding_scheme", ":", "str", "=", "\"BIOUL\"", ",", "\n", "max_span_width", ":", "int", "=", "-", "1", ",", "\n", "label_namespace", ":", "str", "=", "\"labels\"", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "'tokens'", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "if", "tag_label", "is", "not", "None", "and", "tag_label", "not", "in", "self", ".", "_VALID_LABELS", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"unknown tag label type: {}\"", ".", "format", "(", "tag_label", ")", ")", "\n", "", "for", "label", "in", "feature_labels", ":", "\n", "            ", "if", "label", "not", "in", "self", ".", "_VALID_LABELS", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"unknown feature label type: {}\"", ".", "format", "(", "label", ")", ")", "\n", "\n", "", "", "self", ".", "tag_label", "=", "tag_label", "\n", "self", ".", "feature_labels", "=", "set", "(", "feature_labels", ")", "\n", "self", ".", "label_namespace", "=", "label_namespace", "\n", "self", ".", "coding_scheme", "=", "coding_scheme", "\n", "self", ".", "_original_coding_scheme", "=", "\"IOB1\"", "\n", "if", "max_span_width", "!=", "-", "1", ":", "\n", "            ", "self", ".", "_max_span_width", "=", "max_span_width", "\n", "", "else", ":", "\n", "            ", "self", ".", "_max_span_width", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.span_conll2003_dataset_reader.SpanConll2003DatasetReader._read": [[141, 161], ["allennlp.common.file_utils.cached_path", "open", "logger.info", "itertools.groupby", "line.strip().split", "list", "allennlp.data.tokenizers.Token", "span_conll2003_dataset_reader.SpanConll2003DatasetReader.text_to_instance", "zip", "line.strip"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader.BC5CDRDatasetReader.text_to_instance"], ["", "", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", "->", "Iterable", "[", "Instance", "]", ":", "\n", "# if `file_path` is a URL, redirect to the cache", "\n", "        ", "file_path", "=", "cached_path", "(", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"Reading instances from lines in file at: %s\"", ",", "file_path", ")", "\n", "\n", "# Group into alternative divider / sentence chunks.", "\n", "for", "is_divider", ",", "lines", "in", "itertools", ".", "groupby", "(", "data_file", ",", "_is_divider", ")", ":", "\n", "# Ignore the divider chunks, so that `lines` corresponds to the words", "\n", "# of a single sentence.", "\n", "                ", "if", "not", "is_divider", ":", "\n", "                    ", "fields", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "line", "in", "lines", "]", "\n", "# unzipping trick returns tuples, but our Fields need lists", "\n", "fields", "=", "[", "list", "(", "field", ")", "for", "field", "in", "zip", "(", "*", "fields", ")", "]", "\n", "tokens_", ",", "pos_tags", ",", "chunk_tags", ",", "ner_tags", "=", "fields", "\n", "# TextField requires ``Token`` objects", "\n", "tokens", "=", "[", "Token", "(", "token", ")", "for", "token", "in", "tokens_", "]", "\n", "yield", "self", ".", "text_to_instance", "(", "tokens", ",", "pos_tags", ",", "chunk_tags", ",", "ner_tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.span_conll2003_dataset_reader.SpanConll2003DatasetReader.text_to_instance": [[162, 259], ["allennlp.data.fields.TextField", "span_conll2003_dataset_reader._extract_spans", "allennlp.data.dataset_readers.dataset_utils.enumerate_spans", "_extract_spans.items", "allennlp.data.fields.MetadataField", "allennlp.data.fields.ListField", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.ListField", "allennlp.data.fields.SequenceLabelField", "allennlp.data.instance.Instance", "len", "len", "span_labels.append", "spans.append", "gold_span_labels.append", "gold_spans.append", "len", "len", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.SequenceLabelField", "allennlp.data.dataset_readers.dataset_utils.to_bioul", "allennlp.data.dataset_readers.dataset_utils.to_bioul", "str", "str", "_extract_spans.get", "allennlp.data.fields.SpanField", "allennlp.data.fields.SpanField", "allennlp.common.checks.ConfigurationError", "allennlp.common.checks.ConfigurationError", "allennlp.common.checks.ConfigurationError", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.SequenceLabelField"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader._extract_spans"], ["", "", "", "", "def", "text_to_instance", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "pos_tags", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "chunk_tags", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "ner_tags", ":", "List", "[", "str", "]", "=", "None", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        We take `pre-tokenized` input here, because we don't have a tokenizer in this class.\n        \"\"\"", "\n", "sequence", "=", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "instance_fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "'tokens'", ":", "sequence", "}", "\n", "\n", "def", "_remove_BI", "(", "_one_tag", ")", ":", "\n", "            ", "if", "_one_tag", "==", "'O'", ":", "\n", "                ", "return", "_one_tag", "\n", "", "else", ":", "\n", "                ", "return", "_one_tag", "[", "2", ":", "]", "\n", "\n", "", "", "if", "self", ".", "coding_scheme", "==", "\"BIOUL\"", ":", "\n", "            ", "coded_chunks", "=", "to_bioul", "(", "chunk_tags", ",", "\n", "encoding", "=", "self", ".", "_original_coding_scheme", ")", "if", "chunk_tags", "is", "not", "None", "else", "None", "\n", "coded_ner", "=", "to_bioul", "(", "ner_tags", ",", "\n", "encoding", "=", "self", ".", "_original_coding_scheme", ")", "if", "ner_tags", "is", "not", "None", "else", "None", "\n", "", "else", ":", "\n", "# the default IOB1", "\n", "            ", "coded_chunks", "=", "chunk_tags", "\n", "coded_ner", "=", "ner_tags", "\n", "\n", "# TODO:", "\n", "# ner_tags -> spans of NE", "\n", "# return something like spans, span_labels (\"O\" if span not in golden_spans, \"PER\", \"LOC\"... otherwise)", "\n", "", "spans", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "span_labels", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\n", "gold_spans", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "gold_span_labels", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\n", "assert", "len", "(", "ner_tags", ")", "==", "len", "(", "tokens", ")", ",", "\"sentence:%s but ner_tags:%s\"", "%", "(", "str", "(", "tokens", ")", ",", "str", "(", "ner_tags", ")", ")", "\n", "ner_gold_spans", "=", "_extract_spans", "(", "ner_tags", ")", "# ner_gold_spans: Dict[tuple(startid, endid), str(entity_type)]", "\n", "for", "start", ",", "end", "in", "enumerate_spans", "(", "ner_tags", ",", "offset", "=", "0", ",", "max_span_width", "=", "self", ".", "_max_span_width", ")", ":", "\n", "            ", "span_labels", ".", "append", "(", "ner_gold_spans", ".", "get", "(", "(", "start", ",", "end", ")", ",", "'O'", ")", ")", "\n", "spans", ".", "append", "(", "SpanField", "(", "start", ",", "end", ",", "sequence", ")", ")", "\n", "pass", "\n", "\n", "", "_dict_gold_spans", "=", "{", "}", "\n", "for", "ky", ",", "val", "in", "ner_gold_spans", ".", "items", "(", ")", ":", "\n", "            ", "gold_span_labels", ".", "append", "(", "val", ")", "\n", "gold_spans", ".", "append", "(", "SpanField", "(", "ky", "[", "0", "]", ",", "ky", "[", "1", "]", ",", "sequence", ")", ")", "\n", "if", "val", "!=", "'O'", ":", "\n", "                ", "_dict_gold_spans", "[", "ky", "]", "=", "val", "\n", "", "pass", "\n", "\n", "", "instance_fields", "[", "\"metadata\"", "]", "=", "MetadataField", "(", "{", "\"words\"", ":", "[", "x", ".", "text", "for", "x", "in", "tokens", "]", ",", "\n", "\"gold_spans\"", ":", "_dict_gold_spans", "}", ")", "\n", "\n", "assert", "len", "(", "spans", ")", "==", "len", "(", "span_labels", ")", ",", "\"span length not equal to span label length...\"", "\n", "span_field", "=", "ListField", "(", "spans", ")", "# a list of (start, end) tuples...", "\n", "\n", "# contains all possible spans and there tags", "\n", "instance_fields", "[", "'spans'", "]", "=", "span_field", "\n", "instance_fields", "[", "'span_labels'", "]", "=", "SequenceLabelField", "(", "span_labels", ",", "span_field", ",", "\"span_tags\"", ")", "\n", "\n", "# only contain gold_spans and there tags", "\n", "# e.g. (0,0,O), (1,1,O), (2,3,PER), (4,4,O) for 'I am Donald Trump .'", "\n", "gold_span_field", "=", "ListField", "(", "gold_spans", ")", "\n", "instance_fields", "[", "'gold_spans'", "]", "=", "gold_span_field", "\n", "instance_fields", "[", "'gold_span_labels'", "]", "=", "SequenceLabelField", "(", "gold_span_labels", ",", "\n", "gold_span_field", ",", "\"span_tags\"", ")", "\n", "\n", "# Add \"feature labels\" to instance", "\n", "if", "'pos'", "in", "self", ".", "feature_labels", ":", "\n", "            ", "if", "pos_tags", "is", "None", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"Dataset reader was specified to use pos_tags as \"", "\n", "\"features. Pass them to text_to_instance.\"", ")", "\n", "", "instance_fields", "[", "'pos_tags'", "]", "=", "SequenceLabelField", "(", "pos_tags", ",", "sequence", ",", "\"pos_tags\"", ")", "\n", "", "if", "'chunk'", "in", "self", ".", "feature_labels", ":", "\n", "            ", "if", "coded_chunks", "is", "None", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"Dataset reader was specified to use chunk tags as \"", "\n", "\"features. Pass them to text_to_instance.\"", ")", "\n", "", "instance_fields", "[", "'chunk_tags'", "]", "=", "SequenceLabelField", "(", "coded_chunks", ",", "sequence", ",", "\"chunk_tags\"", ")", "\n", "", "if", "'ner'", "in", "self", ".", "feature_labels", ":", "\n", "            ", "if", "coded_ner", "is", "None", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"Dataset reader was specified to use NER tags as \"", "\n", "\" features. Pass them to text_to_instance.\"", ")", "\n", "", "instance_fields", "[", "'ner_tags'", "]", "=", "SequenceLabelField", "(", "coded_ner", ",", "sequence", ",", "\"token_tags\"", ")", "\n", "\n", "# Add \"tag label\" to instance", "\n", "", "if", "self", ".", "tag_label", "==", "'ner'", "and", "coded_ner", "is", "not", "None", ":", "\n", "            ", "instance_fields", "[", "'tags'", "]", "=", "SequenceLabelField", "(", "coded_ner", ",", "sequence", ",", "\n", "'token_tags'", ")", "\n", "", "elif", "self", ".", "tag_label", "==", "'pos'", "and", "pos_tags", "is", "not", "None", ":", "\n", "            ", "instance_fields", "[", "'tags'", "]", "=", "SequenceLabelField", "(", "pos_tags", ",", "sequence", ",", "\n", "'token_tags'", ")", "\n", "", "elif", "self", ".", "tag_label", "==", "'chunk'", "and", "coded_chunks", "is", "not", "None", ":", "\n", "            ", "instance_fields", "[", "'tags'", "]", "=", "SequenceLabelField", "(", "coded_chunks", ",", "sequence", ",", "\n", "'token_tags'", ")", "\n", "\n", "", "return", "Instance", "(", "instance_fields", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.span_conll2003_dataset_reader._is_divider": [[19, 29], ["line.strip", "line.split"], "function", ["None"], ["def", "_is_divider", "(", "line", ":", "str", ")", "->", "bool", ":", "\n", "    ", "empty_line", "=", "line", ".", "strip", "(", ")", "==", "''", "\n", "if", "empty_line", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "first_token", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "first_token", "==", "\"-DOCSTART-\"", ":", "# pylint: disable=simplifiable-if-statement", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.span_conll2003_dataset_reader._extract_spans": [[31, 60], ["enumerate", "span_conll2003_dataset_reader._extract_spans._save_span"], "function", ["None"], ["", "", "", "def", "_extract_spans", "(", "tags", ":", "List", "[", "str", "]", ")", "->", "Dict", "[", "Tuple", "[", "int", ",", "int", "]", ",", "str", "]", ":", "\n", "    ", "cur_tag", "=", "None", "\n", "cur_start", "=", "None", "\n", "gold_spans", "=", "{", "}", "\n", "def", "_save_span", "(", "_cur_tag", ",", "_cur_start", ",", "_cur_id", ",", "_gold_spans", ")", ":", "\n", "        ", "if", "_cur_start", "is", "None", ":", "\n", "            ", "return", "_gold_spans", "\n", "", "_gold_spans", "[", "(", "_cur_start", ",", "_cur_id", "-", "1", ")", "]", "=", "_cur_tag", "# inclusive start & end, accord with conll-coref settings", "\n", "return", "_gold_spans", "\n", "\n", "# iterate over the tags", "\n", "# (BIO1 scheme)", "\n", "", "for", "_id", ",", "nt", "in", "enumerate", "(", "tags", ")", ":", "\n", "        ", "indicator", "=", "nt", "[", "0", "]", "\n", "if", "indicator", "==", "'B'", ":", "\n", "            ", "gold_spans", "=", "_save_span", "(", "cur_tag", ",", "cur_start", ",", "_id", ",", "gold_spans", ")", "\n", "cur_start", "=", "_id", "\n", "cur_tag", "=", "nt", "[", "2", ":", "]", "\n", "pass", "\n", "", "elif", "indicator", "==", "'I'", ":", "\n", "# do nothing ", "\n", "            ", "pass", "\n", "", "elif", "indicator", "==", "'O'", ":", "\n", "            ", "gold_spans", "=", "_save_span", "(", "cur_tag", ",", "cur_start", ",", "_id", ",", "gold_spans", ")", "\n", "cur_tag", "=", "'O'", "\n", "cur_start", "=", "_id", "\n", "pass", "\n", "", "", "_save_span", "(", "cur_tag", ",", "cur_start", ",", "_id", "+", "1", ",", "gold_spans", ")", "\n", "return", "gold_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader.BC5CDRDatasetReader.__init__": [[63, 79], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "coding_scheme", ":", "str", "=", "\"BIOUL\"", ",", "\n", "max_span_width", ":", "int", "=", "-", "1", ",", "\n", "label_namespace", ":", "str", "=", "\"labels\"", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "'tokens'", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "\n", "self", ".", "label_namespace", "=", "label_namespace", "\n", "self", ".", "coding_scheme", "=", "coding_scheme", "\n", "self", ".", "_original_coding_scheme", "=", "\"IOB1\"", "\n", "if", "max_span_width", "!=", "-", "1", ":", "\n", "            ", "self", ".", "_max_span_width", "=", "max_span_width", "\n", "", "else", ":", "\n", "            ", "self", ".", "_max_span_width", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader.BC5CDRDatasetReader._read": [[80, 124], ["allennlp.common.file_utils.cached_path", "enumerate", "open", "logger.info", "itertools.groupby", "zip", "range", "range", "len", "spans.append", "line.strip().split", "list", "allennlp.data.tokenizers.Token", "BC5CDR_dataset_reader.BC5CDRDatasetReader.text_to_instance", "zip", "BC5CDR_dataset_reader.BC5CDRDatasetReader._read._to_IOB1"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader.BC5CDRDatasetReader.text_to_instance"], ["", "", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", "->", "Iterable", "[", "Instance", "]", ":", "\n", "\n", "        ", "def", "_to_IOB1", "(", "_io_s", ",", "_ner_tags", ")", ":", "\n", "            ", "ans", "=", "[", "\"O\"", "for", "i", "in", "range", "(", "len", "(", "_io_s", ")", ")", "]", "\n", "spans", "=", "[", "]", "\n", "left_end", ",", "right_end", "=", "None", ",", "None", "\n", "current_type", "=", "\"None\"", "\n", "\n", "for", "i", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "zip", "(", "_io_s", ",", "_ner_tags", ")", ")", ":", "\n", "                ", "if", "x", "==", "\"I\"", ":", "\n", "                    ", "if", "current_type", "!=", "\"None\"", "and", "i", ">", "0", ":", "\n", "                        ", "spans", ".", "append", "(", "(", "left_end", ",", "i", "-", "1", ",", "current_type", ")", ")", "\n", "", "left_end", "=", "i", "\n", "current_type", "=", "y", "\n", "\n", "", "", "for", "(", "_lend", ",", "_rend", ",", "_type", ")", "in", "spans", ":", "\n", "                ", "if", "_rend", "-", "_lend", "+", "1", "==", "1", ":", "\n", "                    ", "ans", "[", "_lend", "]", "=", "\"B-\"", "+", "_type", "\n", "", "else", ":", "\n", "                    ", "ans", "[", "_lend", "]", "=", "\"B-\"", "+", "_type", "\n", "for", "i", "in", "range", "(", "_lend", "+", "1", ",", "_rend", "+", "1", ")", ":", "\n", "                        ", "ans", "[", "i", "]", "=", "\"I-\"", "+", "_type", "\n", "", "", "", "return", "ans", "\n", "\n", "\n", "# if `file_path` is a URL, redirect to the cache", "\n", "", "file_path", "=", "cached_path", "(", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"Reading instances from lines in file at: %s\"", ",", "file_path", ")", "\n", "\n", "# Group into alternative divider / sentence chunks.", "\n", "for", "is_divider", ",", "lines", "in", "itertools", ".", "groupby", "(", "data_file", ",", "_is_divider", ")", ":", "\n", "# Ignore the divider chunks, so that `lines` corresponds to the words", "\n", "# of a single sentence.", "\n", "                ", "if", "not", "is_divider", ":", "\n", "                    ", "fields", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "line", "in", "lines", "]", "\n", "# unzipping trick returns tuples, but our Fields need lists", "\n", "fields", "=", "[", "list", "(", "field", ")", "for", "field", "in", "zip", "(", "*", "fields", ")", "]", "\n", "tokens_", ",", "io_s", ",", "ner_tags", "=", "fields", "\n", "# TextField requires ``Token`` objects", "\n", "tokens", "=", "[", "Token", "(", "token", ")", "for", "token", "in", "tokens_", "]", "\n", "yield", "self", ".", "text_to_instance", "(", "tokens", ",", "_to_IOB1", "(", "io_s", ",", "ner_tags", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader.BC5CDRDatasetReader.text_to_instance": [[125, 194], ["allennlp.data.fields.TextField", "BC5CDR_dataset_reader._extract_spans", "allennlp.data.dataset_readers.dataset_utils.enumerate_spans", "_extract_spans.items", "allennlp.data.fields.MetadataField", "allennlp.data.fields.ListField", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.ListField", "allennlp.data.fields.SequenceLabelField", "allennlp.data.instance.Instance", "len", "len", "span_labels.append", "spans.append", "gold_span_labels.append", "gold_spans.append", "len", "len", "allennlp.data.fields.SequenceLabelField", "allennlp.data.dataset_readers.dataset_utils.to_bioul", "str", "str", "_extract_spans.get", "allennlp.data.fields.SpanField", "allennlp.data.fields.SpanField"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader._extract_spans"], ["", "", "", "", "def", "text_to_instance", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "ner_tags", ":", "List", "[", "str", "]", "=", "None", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        We take `pre-tokenized` input here, because we don't have a tokenizer in this class.\n        \"\"\"", "\n", "sequence", "=", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "instance_fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "'tokens'", ":", "sequence", "}", "\n", "\n", "def", "_remove_BI", "(", "_one_tag", ")", ":", "\n", "            ", "if", "_one_tag", "==", "'O'", ":", "\n", "                ", "return", "_one_tag", "\n", "", "else", ":", "\n", "                ", "return", "_one_tag", "[", "2", ":", "]", "\n", "\n", "", "", "if", "self", ".", "coding_scheme", "==", "\"BIOUL\"", ":", "\n", "            ", "coded_ner", "=", "to_bioul", "(", "ner_tags", ",", "\n", "encoding", "=", "self", ".", "_original_coding_scheme", ")", "if", "ner_tags", "is", "not", "None", "else", "None", "\n", "", "else", ":", "\n", "# the default IOB1", "\n", "            ", "coded_ner", "=", "ner_tags", "\n", "\n", "# TODO:", "\n", "# ner_tags -> spans of NE", "\n", "# return something like spans, span_labels (\"O\" if span not in golden_spans, \"PER\", \"LOC\"... otherwise)", "\n", "", "spans", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "span_labels", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\n", "gold_spans", ":", "List", "[", "Field", "]", "=", "[", "]", "\n", "gold_span_labels", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\n", "assert", "len", "(", "ner_tags", ")", "==", "len", "(", "tokens", ")", ",", "\"sentence:%s but ner_tags:%s\"", "%", "(", "str", "(", "tokens", ")", ",", "str", "(", "ner_tags", ")", ")", "\n", "ner_gold_spans", "=", "_extract_spans", "(", "ner_tags", ")", "# ner_gold_spans: Dict[tuple(startid, endid), str(entity_type)]", "\n", "for", "start", ",", "end", "in", "enumerate_spans", "(", "ner_tags", ",", "offset", "=", "0", ",", "max_span_width", "=", "self", ".", "_max_span_width", ")", ":", "\n", "            ", "span_labels", ".", "append", "(", "ner_gold_spans", ".", "get", "(", "(", "start", ",", "end", ")", ",", "'O'", ")", ")", "\n", "spans", ".", "append", "(", "SpanField", "(", "start", ",", "end", ",", "sequence", ")", ")", "\n", "pass", "\n", "\n", "", "_dict_gold_spans", "=", "{", "}", "\n", "for", "ky", ",", "val", "in", "ner_gold_spans", ".", "items", "(", ")", ":", "\n", "            ", "gold_span_labels", ".", "append", "(", "val", ")", "\n", "gold_spans", ".", "append", "(", "SpanField", "(", "ky", "[", "0", "]", ",", "ky", "[", "1", "]", ",", "sequence", ")", ")", "\n", "if", "val", "!=", "'O'", ":", "\n", "                ", "_dict_gold_spans", "[", "ky", "]", "=", "val", "\n", "", "pass", "\n", "\n", "", "instance_fields", "[", "\"metadata\"", "]", "=", "MetadataField", "(", "{", "\"words\"", ":", "[", "x", ".", "text", "for", "x", "in", "tokens", "]", ",", "\n", "\"gold_spans\"", ":", "_dict_gold_spans", "}", ")", "\n", "\n", "assert", "len", "(", "spans", ")", "==", "len", "(", "span_labels", ")", ",", "\"span length not equal to span label length...\"", "\n", "span_field", "=", "ListField", "(", "spans", ")", "# a list of (start, end) tuples...", "\n", "\n", "# contains all possible spans and their tags", "\n", "instance_fields", "[", "'spans'", "]", "=", "span_field", "\n", "instance_fields", "[", "'span_labels'", "]", "=", "SequenceLabelField", "(", "span_labels", ",", "span_field", ",", "\"span_tags\"", ")", "\n", "\n", "# only contain gold_spans and their tags", "\n", "# e.g. (0,0,O), (1,1,O), (2,3,PER), (4,4,O) for 'I am Donald Trump .'", "\n", "gold_span_field", "=", "ListField", "(", "gold_spans", ")", "\n", "instance_fields", "[", "'gold_spans'", "]", "=", "gold_span_field", "\n", "instance_fields", "[", "'gold_span_labels'", "]", "=", "SequenceLabelField", "(", "gold_span_labels", ",", "\n", "gold_span_field", ",", "\"span_tags\"", ")", "\n", "\n", "\n", "# Add \"tag label\" to instance", "\n", "if", "self", ".", "tag_label", "==", "'ner'", "and", "coded_ner", "is", "not", "None", ":", "\n", "            ", "instance_fields", "[", "'tags'", "]", "=", "SequenceLabelField", "(", "coded_ner", ",", "sequence", ",", "\n", "'token_tags'", ")", "\n", "", "return", "Instance", "(", "instance_fields", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader._is_divider": [[19, 26], ["line.strip", "line.split"], "function", ["None"], ["def", "_is_divider", "(", "line", ":", "str", ")", "->", "bool", ":", "\n", "    ", "empty_line", "=", "line", ".", "strip", "(", ")", "==", "''", "\n", "if", "empty_line", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "first_token", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.dataset_readers.BC5CDR_dataset_reader._extract_spans": [[28, 57], ["enumerate", "BC5CDR_dataset_reader._extract_spans._save_span"], "function", ["None"], ["", "", "def", "_extract_spans", "(", "tags", ":", "List", "[", "str", "]", ")", "->", "Dict", "[", "Tuple", "[", "int", ",", "int", "]", ",", "str", "]", ":", "\n", "    ", "cur_tag", "=", "None", "\n", "cur_start", "=", "None", "\n", "gold_spans", "=", "{", "}", "\n", "def", "_save_span", "(", "_cur_tag", ",", "_cur_start", ",", "_cur_id", ",", "_gold_spans", ")", ":", "\n", "        ", "if", "_cur_start", "is", "None", ":", "\n", "            ", "return", "_gold_spans", "\n", "", "_gold_spans", "[", "(", "_cur_start", ",", "_cur_id", "-", "1", ")", "]", "=", "_cur_tag", "# inclusive start & end, accord with conll-coref settings", "\n", "return", "_gold_spans", "\n", "\n", "# iterate over the tags", "\n", "# (BIO1 scheme)", "\n", "", "for", "_id", ",", "nt", "in", "enumerate", "(", "tags", ")", ":", "\n", "        ", "indicator", "=", "nt", "[", "0", "]", "\n", "if", "indicator", "==", "'B'", ":", "\n", "            ", "gold_spans", "=", "_save_span", "(", "cur_tag", ",", "cur_start", ",", "_id", ",", "gold_spans", ")", "\n", "cur_start", "=", "_id", "\n", "cur_tag", "=", "nt", "[", "2", ":", "]", "\n", "pass", "\n", "", "elif", "indicator", "==", "'I'", ":", "\n", "# do nothing ", "\n", "            ", "pass", "\n", "", "elif", "indicator", "==", "'O'", ":", "\n", "            ", "gold_spans", "=", "_save_span", "(", "cur_tag", ",", "cur_start", ",", "_id", ",", "gold_spans", ")", "\n", "cur_tag", "=", "'O'", "\n", "cur_start", "=", "_id", "\n", "pass", "\n", "", "", "_save_span", "(", "cur_tag", ",", "cur_start", ",", "_id", "+", "1", ",", "gold_spans", ")", "\n", "return", "gold_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.HSCRF_SoftDict.HSCRF_SoftDict.__init__": [[32, 135], ["allennlp.nn.InitializerApplicator", "allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "HSCRF_SoftDict.HSCRF_SoftDict.vocab.get_vocab_size", "HSCRF_SoftDict.HSCRF_SoftDict.vocab.get_vocab_size", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "numpy.sqrt", "torch.nn.init.uniform", "torch.nn.init.uniform", "torch.nn.init.uniform", "torch.nn.init.uniform", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "HSCRF_SoftDict.HSCRF_SoftDict.load_weights", "modules.hscrf_layer_SoftDict.HSCRF", "metrics.span_f1.MySpanF1", "allennlp.common.checks.check_dimensions_match", "allennlp.common.checks.check_dimensions_match", "initializer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "feedforward.get_output_dim", "HSCRF_SoftDict.HSCRF_SoftDict.encoder.get_output_dim", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "HSCRF_SoftDict.HSCRF_SoftDict.vocab.get_index_to_token_vocabulary", "allennlp.modules.conditional_random_field.allowed_transitions", "allennlp.modules.conditional_random_field.allowed_transitions", "text_field_embedder.get_output_dim", "encoder.get_input_dim", "allennlp.common.checks.check_dimensions_match", "allennlp.common.checks.check_dimensions_match", "text_field_embedder.get_output_dim", "text_field_embedder.get_output_dim", "torch.nn.modules.linear.Linear", "torch.nn.modules.linear.Linear", "copy.copy", "encoder.get_output_dim", "feedforward.get_input_dim", "softdict_feedforward.get_output_dim", "HSCRF_SoftDict.HSCRF_SoftDict.vocab.get_index_to_token_vocabulary"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "softdict_text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "softdict_encoder", ":", "Seq2SeqEncoder", ",", "\n", "softdict_feedforward", ":", "FeedForward", ",", "\n", "softdict_pretrained_path", ":", "str", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "feature_size", ":", "int", ",", "\n", "max_span_width", ":", "int", ",", "\n", "span_label_namespace", ":", "str", "=", "\"span_tags\"", ",", "\n", "token_label_namespace", ":", "str", "=", "\"token_tags\"", ",", "\n", "feedforward", ":", "Optional", "[", "FeedForward", "]", "=", "None", ",", "\n", "token_label_encoding", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "constraint_type", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "include_start_end_transitions", ":", "bool", "=", "True", ",", "\n", "constrain_crf_decoding", ":", "bool", "=", "None", ",", "\n", "calculate_span_f1", ":", "bool", "=", "None", ",", "\n", "dropout", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "verbose_metrics", ":", "bool", "=", "True", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "self", ".", "span_label_namespace", "=", "span_label_namespace", "\n", "self", ".", "token_label_namespace", "=", "token_label_namespace", "\n", "\n", "self", ".", "num_span_tags", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "span_label_namespace", ")", "\n", "self", ".", "num_token_tags", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "token_label_namespace", ")", "\n", "\n", "self", ".", "text_field_embedder", "=", "text_field_embedder", "\n", "\n", "self", ".", "max_span_width", "=", "max_span_width", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "_verbose_metrics", "=", "verbose_metrics", "\n", "\n", "self", ".", "end_token_embedding", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "text_field_embedder", ".", "get_output_dim", "(", ")", ")", ")", "\n", "\n", "bias", "=", "np", ".", "sqrt", "(", "3.0", "/", "text_field_embedder", ".", "get_output_dim", "(", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "uniform", "(", "self", ".", "end_token_embedding", ",", "-", "bias", ",", "bias", ")", "\n", "\n", "if", "dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "_feedforward", "=", "feedforward", "\n", "\n", "if", "feedforward", "is", "not", "None", ":", "\n", "            ", "output_dim", "=", "feedforward", ".", "get_output_dim", "(", ")", "\n", "", "else", ":", "\n", "            ", "output_dim", "=", "self", ".", "encoder", ".", "get_output_dim", "(", ")", "\n", "\n", "", "softdict_length_embedder", "=", "torch", ".", "nn", ".", "Embedding", "(", "max_span_width", ",", "feature_size", ")", "\n", "softdict_encoder", "=", "TimeDistributed", "(", "softdict_encoder", ")", "\n", "softdict_BILOU_tag_projection_layer", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "softdict_feedforward", ")", ",", "\n", "TimeDistributed", "(", "Linear", "(", "softdict_feedforward", ".", "get_output_dim", "(", ")", ",", "4", "*", "4", ")", ")", "\n", ")", "\n", "\n", "self", ".", "load_weights", "(", "softdict_text_field_embedder", ",", "\n", "softdict_length_embedder", ",", "\n", "softdict_encoder", ",", "\n", "softdict_BILOU_tag_projection_layer", ",", "\n", "softdict_pretrained_path", ")", "\n", "\n", "self", ".", "hscrf_layer", "=", "hscrf_layer_SoftDict", ".", "HSCRF", "(", "\n", "ix_to_tag", "=", "copy", ".", "copy", "(", "self", ".", "vocab", ".", "get_index_to_token_vocabulary", "(", "span_label_namespace", ")", ")", ",", "\n", "word_rep_dim", "=", "output_dim", ",", "\n", "ALLOWED_SPANLEN", "=", "self", ".", "max_span_width", ",", "\n", "softdict_text_field_embedder", "=", "softdict_text_field_embedder", ",", "\n", "length_embedder", "=", "softdict_length_embedder", ",", "\n", "encoder", "=", "softdict_encoder", ",", "\n", "BILOU_tag_projection_layer", "=", "softdict_BILOU_tag_projection_layer", "\n", ")", "\n", "\n", "if", "constraint_type", "is", "not", "None", ":", "\n", "            ", "token_label_encoding", "=", "constraint_type", "\n", "# if  constrain_crf_decoding and calculate_span_f1 are not", "\n", "# provided, (i.e., they're None), set them to True", "\n", "# if label_encoding is provided and False if it isn't.", "\n", "", "if", "constrain_crf_decoding", "is", "None", ":", "\n", "            ", "constrain_crf_decoding", "=", "token_label_encoding", "is", "not", "None", "\n", "", "if", "calculate_span_f1", "is", "None", ":", "\n", "            ", "calculate_span_f1", "=", "token_label_encoding", "is", "not", "None", "\n", "\n", "", "self", ".", "token_label_encoding", "=", "token_label_encoding", "# BILOU/BIO/BI", "\n", "\n", "if", "constrain_crf_decoding", ":", "\n", "            ", "token_labels", "=", "self", ".", "vocab", ".", "get_index_to_token_vocabulary", "(", "token_label_namespace", ")", "\n", "constraints", "=", "allowed_transitions", "(", "token_label_encoding", ",", "token_labels", ")", "\n", "", "else", ":", "\n", "            ", "constraints", "=", "None", "\n", "\n", "", "self", ".", "metrics", "=", "{", "}", "\n", "self", ".", "calculate_span_f1", "=", "calculate_span_f1", "\n", "self", ".", "_span_f1_metric", "=", "MySpanF1", "(", ")", "\n", "\n", "check_dimensions_match", "(", "text_field_embedder", ".", "get_output_dim", "(", ")", ",", "encoder", ".", "get_input_dim", "(", ")", ",", "\n", "\"text field embedding dim\"", ",", "\"encoder input dim\"", ")", "\n", "\n", "if", "feedforward", "is", "not", "None", ":", "\n", "            ", "check_dimensions_match", "(", "encoder", ".", "get_output_dim", "(", ")", ",", "feedforward", ".", "get_input_dim", "(", ")", ",", "\n", "\"encoder output dim\"", ",", "\"feedforward input dim\"", ")", "\n", "", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.HSCRF_SoftDict.HSCRF_SoftDict.load_weights": [[136, 181], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "softdict_text_field_embedder.load_state_dict", "softdict_text_field_embedder.eval", "softdict_text_field_embedder.parameters", "softdict_length_embedder.load_state_dict", "softdict_length_embedder.eval", "softdict_length_embedder.parameters", "softdict_encoder.load_state_dict", "softdict_encoder.eval", "softdict_encoder.parameters", "softdict_BILOU_tag_projection_layer.load_state_dict", "softdict_BILOU_tag_projection_layer.eval", "softdict_BILOU_tag_projection_layer.parameters", "torch.load.items", "torch.load.items", "ky.startswith", "tmp[].expand", "tmp[].expand", "torch.load.items", "torch.load.items", "ky.startswith", "torch.load.items", "torch.load.items", "ky.startswith", "torch.load.items", "torch.load.items", "ky.startswith", "len", "HSCRF_SoftDict.HSCRF_SoftDict.vocab.get_vocab_size", "tmp.size", "HSCRF_SoftDict.HSCRF_SoftDict.vocab.get_vocab_size", "tmp.size", "len", "len", "len"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ",", "\n", "softdict_text_field_embedder", ",", "\n", "softdict_length_embedder", ",", "\n", "softdict_encoder", ",", "\n", "softdict_BILOU_tag_projection_layer", ",", "\n", "pretrained_path", ")", ":", "\n", "        ", "pretrained_model_state", "=", "torch", ".", "load", "(", "pretrained_path", ")", "\n", "\n", "softdict_text_field_embedder_statedict", "=", "{", "ky", "[", "len", "(", "'text_field_embedder'", ")", "+", "1", ":", "]", ":", "val", "for", "ky", ",", "val", "in", "pretrained_model_state", ".", "items", "(", ")", "if", "ky", ".", "startswith", "(", "'text_field_embedder'", ")", "}", "\n", "tmp", "=", "softdict_text_field_embedder_statedict", "[", "'token_embedder_tokens.weight'", "]", "\n", "\n", "\n", "softdict_text_field_embedder_statedict", "[", "'token_embedder_tokens.weight'", "]", "=", "torch", ".", "cat", "(", "[", "tmp", ",", "tmp", "[", "0", ":", "1", "]", ".", "expand", "(", "self", ".", "vocab", ".", "get_vocab_size", "(", "'tokens'", ")", "-", "tmp", ".", "size", "(", "0", ")", ",", "-", "1", ")", "]", ",", "dim", "=", "0", ")", "\n", "tmp", "=", "softdict_text_field_embedder_statedict", "[", "'token_embedder_token_characters._embedding._module.weight'", "]", "\n", "softdict_text_field_embedder_statedict", "[", "'token_embedder_token_characters._embedding._module.weight'", "]", "=", "torch", ".", "cat", "(", "[", "tmp", ",", "\n", "tmp", "[", "0", ":", "1", "]", ".", "expand", "(", "self", ".", "vocab", ".", "get_vocab_size", "(", "'token_characters'", ")", "-", "tmp", ".", "size", "(", "0", ")", ",", "\n", "-", "1", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "softdict_text_field_embedder", ".", "load_state_dict", "(", "softdict_text_field_embedder_statedict", ")", "\n", "softdict_text_field_embedder", ".", "eval", "(", ")", "\n", "\n", "for", "param", "in", "softdict_text_field_embedder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "softdict_length_embedder_statedict", "=", "{", "ky", "[", "len", "(", "'length_embedder'", ")", "+", "1", ":", "]", ":", "val", "for", "ky", ",", "val", "in", "pretrained_model_state", ".", "items", "(", ")", "if", "ky", ".", "startswith", "(", "'length_embedder'", ")", "}", "\n", "softdict_length_embedder", ".", "load_state_dict", "(", "softdict_length_embedder_statedict", ")", "\n", "softdict_length_embedder", ".", "eval", "(", ")", "\n", "for", "param", "in", "softdict_length_embedder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "softdict_encoder_statedict", "=", "{", "ky", "[", "len", "(", "'encoder'", ")", "+", "1", ":", "]", ":", "val", "for", "ky", ",", "val", "in", "pretrained_model_state", ".", "items", "(", ")", "if", "ky", ".", "startswith", "(", "'encoder'", ")", "}", "\n", "softdict_encoder", ".", "load_state_dict", "(", "softdict_encoder_statedict", ")", "\n", "softdict_encoder", ".", "eval", "(", ")", "\n", "\n", "for", "param", "in", "softdict_encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "softdict_BILOU_tag_projection_layer_statedict", "=", "{", "ky", "[", "len", "(", "'BILOU_tag_projection_layer'", ")", "+", "1", ":", "]", ":", "val", "for", "ky", ",", "val", "in", "pretrained_model_state", ".", "items", "(", ")", "if", "ky", ".", "startswith", "(", "'BILOU_tag_projection_layer'", ")", "}", "\n", "softdict_BILOU_tag_projection_layer", ".", "load_state_dict", "(", "softdict_BILOU_tag_projection_layer_statedict", ")", "\n", "softdict_BILOU_tag_projection_layer", ".", "eval", "(", ")", "\n", "\n", "for", "param", "in", "softdict_BILOU_tag_projection_layer", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.HSCRF_SoftDict.HSCRF_SoftDict.forward": [[182, 315], ["torch.relu().long.size", "allennlp.get_text_field_mask", "allennlp.get_text_field_mask", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HSCRF_SoftDict.HSCRF_SoftDict.text_field_embedder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.sum().long", "torch.cat.sum().long", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "allennlp.move_to_device", "allennlp.move_to_device", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HSCRF_SoftDict.HSCRF_SoftDict.end_token_embedding.cuda", "torch.relu().long", "torch.relu().long", "torch.relu().long", "torch.relu().long", "torch.relu().long.size", "torch.relu().long.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gold_span_labels.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu().long", "torch.relu().long", "torch.relu().long.size", "HSCRF_SoftDict.HSCRF_SoftDict.encoder", "HSCRF_SoftDict.HSCRF_SoftDict.hscrf_layer", "HSCRF_SoftDict.HSCRF_SoftDict.hscrf_layer.get_scrf_decode", "HSCRF_SoftDict.HSCRF_SoftDict._span_f1_metric", "allennlp.get_device_of", "allennlp.get_device_of", "allennlp.get_device_of", "allennlp.get_device_of", "HSCRF_SoftDict.HSCRF_SoftDict.dropout", "HSCRF_SoftDict.HSCRF_SoftDict.dropout", "HSCRF_SoftDict.HSCRF_SoftDict._feedforward", "torch.cat.sum().squeeze", "torch.cat.sum().squeeze", "torch.cat.sum().squeeze", "torch.cat.sum().squeeze", "allennlp.get_text_field_mask.new_zeros", "HSCRF_SoftDict.HSCRF_SoftDict.new_zeros", "torch.cat.sum", "torch.cat.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu().long.new_zeros", "torch.relu().long.new_zeros", "torch.cat.float", "torch.cat.float", "torch.cat.new_zeros().float", "torch.cat.new_zeros().float", "torch.relu", "torch.relu", "HSCRF_SoftDict.HSCRF_SoftDict.size", "torch.relu().long.float", "torch.relu().long.float", "gold_span_labels.squeeze", "torch.relu().long.float", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.relu().long.size", "torch.cat.new_zeros", "torch.cat.new_zeros", "gold_span_labels.new_zeros"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.modules.hscrf_layer_SoftDict.HSCRF.get_scrf_decode"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "spans", ":", "torch", ".", "LongTensor", ",", "\n", "gold_spans", ":", "torch", ".", "LongTensor", ",", "\n", "tags", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "span_labels", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "gold_span_labels", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "'''\n            tags: Shape(batch_size, seq_len)\n                bilou scheme tags for crf modelling\n        '''", "\n", "\n", "batch_size", "=", "spans", ".", "size", "(", "0", ")", "\n", "# Adding mask", "\n", "mask", "=", "util", ".", "get_text_field_mask", "(", "tokens", ")", "\n", "\n", "token_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "\n", "mask", ".", "new_zeros", "(", "batch_size", ",", "1", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "\n", "embedded_text_input", "=", "self", ".", "text_field_embedder", "(", "tokens", ")", "\n", "\n", "embedded_text_input", "=", "torch", ".", "cat", "(", "[", "embedded_text_input", ",", "\n", "embedded_text_input", ".", "new_zeros", "(", "batch_size", ",", "1", ",", "embedded_text_input", ".", "size", "(", "2", ")", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "\n", "# span_mask Shape: (batch_size, num_spans), 1 or 0", "\n", "span_mask", "=", "(", "spans", "[", ":", ",", ":", ",", "0", "]", ">=", "0", ")", ".", "squeeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "gold_span_mask", "=", "(", "gold_spans", "[", ":", ",", ":", ",", "0", "]", ">=", "0", ")", ".", "squeeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "last_span_indices", "=", "gold_span_mask", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", ".", "long", "(", ")", "\n", "\n", "batch_indices", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "batch_indices", "=", "util", ".", "move_to_device", "(", "batch_indices", ",", "\n", "util", ".", "get_device_of", "(", "embedded_text_input", ")", ")", "\n", "last_span_indices", "=", "torch", ".", "cat", "(", "[", "batch_indices", ",", "last_span_indices", "]", ",", "dim", "=", "-", "1", ")", "\n", "embedded_text_input", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", "]", "+=", "self", ".", "end_token_embedding", ".", "cuda", "(", "util", ".", "get_device_of", "(", "spans", ")", ")", "\n", "\n", "token_mask", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", "]", "+=", "1.", "\n", "# SpanFields return -1 when they are used as padding. As we do", "\n", "# some comparisons based on span widths when we attend over the", "\n", "# span representations that we generate from these indices, we", "\n", "# need them to be <= 0. This is only relevant in edge cases where", "\n", "# the number of spans we consider after the pruning stage is >= the", "\n", "# total number of spans, because in this case, it is possible we might", "\n", "# consider a masked span.", "\n", "\n", "# spans Shape: (batch_size, num_spans, 2)", "\n", "spans", "=", "F", ".", "relu", "(", "spans", ".", "float", "(", ")", ")", ".", "long", "(", ")", "\n", "gold_spans", "=", "F", ".", "relu", "(", "gold_spans", ".", "float", "(", ")", ")", ".", "long", "(", ")", "\n", "num_spans", "=", "spans", ".", "size", "(", "1", ")", "\n", "num_gold_spans", "=", "gold_spans", ".", "size", "(", "1", ")", "\n", "\n", "# Shape (batch_size, num_gold_spans, 4)", "\n", "hscrf_target", "=", "torch", ".", "cat", "(", "[", "gold_spans", ",", "gold_spans", ".", "new_zeros", "(", "*", "gold_spans", ".", "size", "(", ")", ")", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "hscrf_target", "[", ":", ",", ":", ",", "2", "]", "=", "torch", ".", "cat", "(", "[", "\n", "(", "gold_span_labels", ".", "new_zeros", "(", "batch_size", ",", "1", ")", "+", "self", ".", "hscrf_layer", ".", "start_id", ")", ".", "long", "(", ")", ",", "# start tags in the front", "\n", "gold_span_labels", ".", "squeeze", "(", ")", "[", ":", ",", "0", ":", "-", "1", "]", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "hscrf_target", "[", ":", ",", ":", ",", "3", "]", "=", "gold_span_labels", ".", "squeeze", "(", ")", "\n", "# Shape (batch_size, num_gold_spans+1, 4)  including an <end> singular-span", "\n", "hscrf_target", "=", "torch", ".", "cat", "(", "[", "hscrf_target", ",", "gold_spans", ".", "new_zeros", "(", "batch_size", ",", "1", ",", "4", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "\n", "hscrf_target", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", ",", "0", ":", "2", "]", "=", "hscrf_target", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", "-", "1", "]", "[", ":", ",", "1", ":", "2", "]", "+", "1", "\n", "\n", "hscrf_target", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", ",", "2", "]", "=", "hscrf_target", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", "-", "1", "]", "[", ":", ",", "3", "]", "\n", "\n", "hscrf_target", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", ",", "3", "]", "=", "self", ".", "hscrf_layer", ".", "stop_id", "\n", "\n", "\n", "\n", "# span_mask Shape: (batch_size, num_spans), 1 or 0", "\n", "span_mask", "=", "(", "spans", "[", ":", ",", ":", ",", "0", "]", ">=", "0", ")", ".", "squeeze", "(", "-", "1", ")", ".", "float", "(", ")", "\n", "\n", "gold_span_mask", "=", "torch", ".", "cat", "(", "[", "gold_span_mask", ".", "float", "(", ")", ",", "\n", "gold_span_mask", ".", "new_zeros", "(", "batch_size", ",", "1", ")", ".", "float", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "gold_span_mask", "[", "last_span_indices", "[", ":", ",", "0", "]", ",", "last_span_indices", "[", ":", ",", "1", "]", "]", "=", "1.", "\n", "\n", "\n", "# SpanFields return -1 when they are used as padding. As we do", "\n", "# some comparisons based on span widths when we attend over the", "\n", "# span representations that we generate from these indices, we", "\n", "# need them to be <= 0. This is only relevant in edge cases where", "\n", "# the number of spans we consider after the pruning stage is >= the", "\n", "# total number of spans, because in this case, it is possible we might", "\n", "# consider a masked span.", "\n", "\n", "# spans Shape: (batch_size, num_spans, 2)", "\n", "spans", "=", "F", ".", "relu", "(", "spans", ".", "float", "(", ")", ")", ".", "long", "(", ")", "\n", "num_spans", "=", "spans", ".", "size", "(", "1", ")", "\n", "\n", "if", "self", ".", "dropout", ":", "\n", "            ", "embedded_text_input", "=", "self", ".", "dropout", "(", "embedded_text_input", ")", "\n", "\n", "", "encoded_text", "=", "self", ".", "encoder", "(", "embedded_text_input", ",", "token_mask", ")", "\n", "\n", "if", "self", ".", "dropout", ":", "\n", "            ", "encoded_text", "=", "self", ".", "dropout", "(", "encoded_text", ")", "\n", "\n", "", "if", "self", ".", "_feedforward", "is", "not", "None", ":", "\n", "            ", "encoded_text", "=", "self", ".", "_feedforward", "(", "encoded_text", ")", "\n", "\n", "", "hscrf_neg_log_likelihood", "=", "self", ".", "hscrf_layer", "(", "\n", "encoded_text", ",", "\n", "tokens", ",", "\n", "token_mask", ".", "sum", "(", "-", "1", ")", ".", "squeeze", "(", ")", ",", "\n", "hscrf_target", ",", "\n", "gold_span_mask", "\n", ")", "\n", "\n", "pred_results", "=", "self", ".", "hscrf_layer", ".", "get_scrf_decode", "(", "\n", "token_mask", ".", "sum", "(", "-", "1", ")", ".", "squeeze", "(", ")", "\n", ")", "\n", "self", ".", "_span_f1_metric", "(", "\n", "pred_results", ",", "\n", "[", "dic", "[", "'gold_spans'", "]", "for", "dic", "in", "metadata", "]", ",", "\n", "sentences", "=", "[", "x", "[", "\"words\"", "]", "for", "x", "in", "metadata", "]", ")", "\n", "output", "=", "{", "\n", "\"mask\"", ":", "token_mask", ",", "\n", "\"loss\"", ":", "hscrf_neg_log_likelihood", ",", "\n", "\"results\"", ":", "pred_results", "\n", "}", "\n", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "output", "[", "\"words\"", "]", "=", "[", "x", "[", "\"words\"", "]", "for", "x", "in", "metadata", "]", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.HSCRF_SoftDict.HSCRF_SoftDict.decode": [[317, 331], ["HSCRF_SoftDict.HSCRF_SoftDict.vocab.get_token_from_index"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Converts the tag ids to the actual tags.\n        ``output_dict[\"tags\"]`` is a list of lists of tag_ids,\n        so we use an ugly nested list comprehension.\n        \"\"\"", "\n", "output_dict", "[", "\"tags\"", "]", "=", "[", "\n", "[", "self", ".", "vocab", ".", "get_token_from_index", "(", "tag", ",", "namespace", "=", "self", ".", "label_namespace", ")", "\n", "for", "tag", "in", "instance_tags", "]", "\n", "for", "instance_tags", "in", "output_dict", "[", "\"tags\"", "]", "\n", "]", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.HSCRF_SoftDict.HSCRF_SoftDict.get_metrics": [[332, 347], ["HSCRF_SoftDict.HSCRF_SoftDict._span_f1_metric.get_metric", "list", "HSCRF_SoftDict.HSCRF_SoftDict.keys", "HSCRF_SoftDict.HSCRF_SoftDict.pop", "metrics_to_return.update", "metrics_to_return.update", "HSCRF_SoftDict.HSCRF_SoftDict.items"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics_to_return", "=", "{", "}", "\n", "if", "self", ".", "calculate_span_f1", ":", "\n", "            ", "span_f1_dict", "=", "self", ".", "_span_f1_metric", ".", "get_metric", "(", "reset", "=", "reset", ")", "\n", "span_kys", "=", "list", "(", "span_f1_dict", ".", "keys", "(", ")", ")", "\n", "for", "ky", "in", "span_kys", ":", "\n", "                ", "span_f1_dict", "[", "ky", "]", "=", "span_f1_dict", ".", "pop", "(", "ky", ")", "\n", "", "if", "self", ".", "_verbose_metrics", ":", "\n", "                ", "metrics_to_return", ".", "update", "(", "span_f1_dict", ")", "\n", "", "else", ":", "\n", "                ", "metrics_to_return", ".", "update", "(", "{", "\n", "x", ":", "y", "for", "x", ",", "y", "in", "span_f1_dict", ".", "items", "(", ")", "if", "\n", "\"overall\"", "in", "x", "}", ")", "\n", "", "", "return", "metrics_to_return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.__init__": [[33, 100], ["allennlp.nn.InitializerApplicator", "allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.vocab.get_vocab_size", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.vocab.get_vocab_size", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.label_to_mask_for_loss.weight.data.copy_", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.HSCRF_scoring_mask.weight.data.copy_", "metrics.span_f1.MySpanF1", "initializer", "numpy.array", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._get_label_to_category_mask", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._get_HSCRF_scoring_mask().reshape", "torch.nn.modules.linear.Linear", "torch.nn.modules.linear.Linear", "torch.nn.modules.linear.Linear", "torch.nn.modules.linear.Linear", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.feedforward.get_output_dim", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._get_HSCRF_scoring_mask", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.encoder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.models.soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._get_label_to_category_mask", "home.repos.pwc.inspect_result.microsoft_vert-papers.models.soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._get_HSCRF_scoring_mask"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "feature_size", ":", "int", ",", "\n", "max_span_width", ":", "int", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "span_label_namespace", ":", "str", "=", "\"span_tags\"", ",", "\n", "token_label_namespace", ":", "str", "=", "\"token_tags\"", ",", "\n", "calculate_span_f1", ":", "bool", "=", "None", ",", "\n", "verbose_metrics", ":", "bool", "=", "True", ",", "\n", "feedforward", ":", "Optional", "[", "FeedForward", "]", "=", "None", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ",", "\n", "class_weight", "=", "None", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "span_label_namespace", "=", "span_label_namespace", "\n", "self", ".", "token_label_namespace", "=", "token_label_namespace", "\n", "self", ".", "num_span_tags", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "span_label_namespace", ")", "\n", "self", ".", "num_token_tags", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "token_label_namespace", ")", "\n", "self", ".", "text_field_embedder", "=", "text_field_embedder", "\n", "\n", "self", ".", "encoder", "=", "TimeDistributed", "(", "encoder", ")", "\n", "\n", "self", ".", "length_embedder", "=", "torch", ".", "nn", ".", "Embedding", "(", "max_span_width", ",", "feature_size", ")", "\n", "\n", "self", ".", "max_span_width", "=", "max_span_width", "\n", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "soft_maxer", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "3", ")", "\n", "\n", "self", ".", "_verbose_metrics", "=", "verbose_metrics", "\n", "self", ".", "BILOU_const", "=", "4", "\n", "\n", "if", "class_weight", "is", "not", "None", ":", "\n", "# assert len(class_weight) == self.num_span_tags - 1, \"size of class_weight has to be equal to num_class\"", "\n", "            ", "self", ".", "class_weight", "=", "numpy", ".", "array", "(", "class_weight", ",", "dtype", "=", "numpy", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "class_weight", "=", "None", "\n", "\n", "\n", "", "if", "not", "feedforward", ":", "\n", "            ", "self", ".", "BILOU_tag_projection_layer", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "Linear", "(", "self", ".", "encoder", ".", "get_output_dim", "(", ")", "+", "feature_size", ",", "self", ".", "BILOU_const", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "feedforward", "=", "feedforward", "\n", "self", ".", "BILOU_tag_projection_layer", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "self", ".", "feedforward", ")", ",", "\n", "TimeDistributed", "(", "Linear", "(", "self", ".", "feedforward", ".", "get_output_dim", "(", ")", ",", "self", ".", "BILOU_const", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", ")", ")", "\n", ")", "\n", "\n", "", "self", ".", "metrics", "=", "{", "}", "\n", "self", ".", "calculate_span_f1", "=", "True", "\n", "\n", "# get mask for loss calculation", "\n", "self", ".", "label_to_mask_for_loss", "=", "torch", ".", "nn", ".", "Embedding", "(", "self", ".", "num_span_tags", ",", "2", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", ")", "\n", "# e.g. PER: [1,0,0,0,| 0,1,1,1], LOC: [0,1,0,0, | ,1,0,1,1], O[0,0,0,0, | ,1,1,1,1]", "\n", "self", ".", "label_to_mask_for_loss", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "_get_label_to_category_mask", "(", ")", ")", ")", "\n", "\n", "# get mask for loss calculation", "\n", "self", ".", "HSCRF_scoring_mask", "=", "torch", ".", "nn", ".", "Embedding", "(", "self", ".", "max_span_width", ",", "\n", "self", ".", "max_span_width", "*", "self", ".", "BILOU_const", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", ")", "\n", "# e.g. PER: [1,0,0,0,| 0,1,1,1], LOC: [0,1,0,0, | ,1,0,1,1], O[0,0,0,0, | ,1,1,1,1]", "\n", "self", ".", "HSCRF_scoring_mask", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "_get_HSCRF_scoring_mask", "(", ")", ".", "reshape", "(", "self", ".", "max_span_width", ",", "-", "1", ")", ")", ")", "\n", "\n", "self", ".", "_span_f1_metric", "=", "MySpanF1", "(", ")", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._get_label_to_category_mask": [[101, 116], ["numpy.zeros", "range", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.vocab.get_token_from_index", "range", "range"], "methods", ["None"], ["", "def", "_get_label_to_category_mask", "(", "self", ")", ":", "\n", "        ", "tag_cnter", "=", "0", "\n", "label_to_mask", "=", "numpy", ".", "zeros", "(", "[", "self", ".", "num_span_tags", ",", "2", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", "]", ",", "dtype", "=", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_span_tags", ")", ":", "\n", "            ", "i_tag", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "i", ",", "namespace", "=", "'span_tags'", ")", "\n", "if", "i_tag", "==", "'O'", ":", "\n", "                ", "for", "j", "in", "range", "(", "1", ",", "2", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", ",", "2", ")", ":", "\n", "                    ", "label_to_mask", "[", "i", ",", "j", "]", "=", "1.0", "\n", "", "", "else", ":", "\n", "                ", "label_to_mask", "[", "i", ",", "2", "*", "tag_cnter", "]", "=", "1.0", "\n", "for", "j", "in", "range", "(", "1", ",", "2", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", ",", "2", ")", ":", "\n", "                    ", "if", "j", "!=", "2", "*", "tag_cnter", "+", "1", ":", "\n", "                        ", "label_to_mask", "[", "i", ",", "j", "]", "=", "1.0", "\n", "", "", "tag_cnter", "+=", "1", "\n", "", "", "return", "label_to_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._get_HSCRF_scoring_mask": [[117, 134], ["numpy.zeros", "range", "range", "range"], "methods", ["None"], ["", "def", "_get_HSCRF_scoring_mask", "(", "self", ")", ":", "\n", "        ", "HSCRF_mask", "=", "numpy", ".", "zeros", "(", "[", "self", ".", "max_span_width", ",", "\n", "self", ".", "max_span_width", ",", "\n", "self", ".", "BILOU_const", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", "]", ",", "\n", "dtype", "=", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "max_span_width", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ")", ":", "\n", "                ", "for", "k", "in", "range", "(", "0", ",", "(", "self", ".", "num_span_tags", "-", "1", ")", "*", "self", ".", "BILOU_const", ",", "self", ".", "BILOU_const", ")", ":", "\n", "                    ", "if", "i", "==", "j", "==", "0", ":", "\n", "                        ", "HSCRF_mask", "[", "i", ",", "j", ",", "k", "]", "=", "1.0", "# U", "\n", "", "elif", "j", "==", "0", ":", "\n", "                        ", "HSCRF_mask", "[", "i", ",", "j", ",", "k", "+", "1", "]", "=", "1.0", "# B", "\n", "", "elif", "j", "==", "i", ":", "\n", "                        ", "HSCRF_mask", "[", "i", ",", "j", ",", "k", "+", "3", "]", "=", "1.0", "# L", "\n", "", "else", ":", "\n", "                        ", "HSCRF_mask", "[", "i", ",", "j", ",", "k", "+", "2", "]", "=", "1.0", "# I", "\n", "", "", "", "", "return", "HSCRF_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.forward": [[135, 235], ["allennlp.get_text_field_mask", "allennlp.get_text_field_mask", "torch.pad.size", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.text_field_embedder().unsqueeze", "torch.pad.unsqueeze", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.length_embedder().unsqueeze().unsqueeze().expand", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.encoder", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.HSCRF_scoring_mask().detach", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.BILOU_tag_projection_layer", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.sum().sum", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu().long().view", "torch.relu().long().view", "torch.relu().long().view.size", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.soft_maxer().view", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.label_to_mask_for_loss().detach().float", "[].max", "range", "ce_loss.view", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.view", "torch.pad.size", "allennlp.get_device_of", "allennlp.get_device_of", "torch.pad.size", "torch.pad.sum().long", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.view", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.view", "len", "pred_results.append", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.text_field_embedder", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.length_embedder().unsqueeze().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.HSCRF_scoring_mask", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.sum", "torch.stack.new_zeros", "torch.stack.new_zeros", "torch.relu().long", "torch.relu().long", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.soft_maxer", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.label_to_mask_for_loss().detach", "ce_loss.sum", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.pad.sum", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.view", "range", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.length_embedder().unsqueeze", "torch.stack.size", "torch.stack.size", "torch.relu", "torch.relu", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.label_to_mask_for_loss", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.vocab.get_index_to_token_vocabulary", "torch.relu().long().view.float", "int", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.length_embedder"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "spans", ":", "torch", ".", "LongTensor", ",", "\n", "gold_spans", ":", "torch", ".", "LongTensor", ",", "\n", "tags", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "span_labels", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "gold_span_labels", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "'''\n            tags: Shape(batch_size, seq_len)\n                bilou scheme tags for crf modelling\n        '''", "\n", "# Adding mask", "\n", "token_mask", "=", "util", ".", "get_text_field_mask", "(", "tokens", ")", "\n", "batch_size", ",", "max_seq_length", "=", "token_mask", ".", "shape", "\n", "len_in_token", "=", "token_mask", ".", "size", "(", "1", ")", "\n", "\n", "#shape (batch_size, num_span, span_width, dim)", "\n", "token_embedded", "=", "self", ".", "text_field_embedder", "(", "tokens", ")", ".", "unsqueeze", "(", "1", ")", "\n", "token_mask", "=", "token_mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "dim_2_pad", "=", "self", ".", "max_span_width", "-", "token_embedded", ".", "size", "(", "2", ")", "\n", "p2d", "=", "(", "0", ",", "0", ",", "0", ",", "dim_2_pad", ")", "\n", "# now shape (batch_size, num_span, max_span_width, dim)", "\n", "token_embedded", "=", "F", ".", "pad", "(", "token_embedded", ",", "p2d", ",", "\"constant\"", ",", "0.", ")", "\n", "token_mask", "=", "F", ".", "pad", "(", "token_mask", ",", "(", "0", ",", "dim_2_pad", ")", ",", "\"constant\"", ",", "0.", ")", "\n", "\n", "length_vec", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "LongTensor", "(", "range", "(", "self", ".", "max_span_width", ")", ")", ")", ".", "cuda", "(", "util", ".", "get_device_of", "(", "spans", ")", ")", "\n", "length_vec", "=", "self", ".", "length_embedder", "(", "length_vec", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "token_embedded", ".", "size", "(", "1", ")", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "token_encoded", "=", "self", ".", "encoder", "(", "token_embedded", ",", "token_mask", ")", "\n", "token_encoded", "=", "torch", ".", "cat", "(", "(", "token_encoded", ",", "length_vec", ")", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Shape (batch_size, 1)", "\n", "lengths", "=", "token_mask", ".", "sum", "(", "-", "1", ")", ".", "long", "(", ")", "-", "1", "\n", "HSCRF_scoring_mask", "=", "self", ".", "HSCRF_scoring_mask", "(", "lengths", ")", ".", "detach", "(", ")", "\n", "\n", "# shape (batch_size, 1 (only 1 span), max_span_wid, 4* span_tags)", "\n", "span_logits", "=", "self", ".", "BILOU_tag_projection_layer", "(", "token_encoded", ")", "\n", "span_logits", "=", "span_logits", ".", "view", "(", "batch_size", ",", "\n", "1", ",", "\n", "self", ".", "max_span_width", ",", "\n", "(", "self", ".", "num_span_tags", "-", "1", ")", ",", "\n", "self", ".", "BILOU_const", "\n", ")", "*", "HSCRF_scoring_mask", ".", "view", "(", "batch_size", ",", "\n", "1", ",", "\n", "self", ".", "max_span_width", ",", "\n", "(", "self", ".", "num_span_tags", "-", "1", ")", ",", "\n", "self", ".", "BILOU_const", ")", "\n", "\n", "final_logits", "=", "span_logits", ".", "sum", "(", "-", "1", ")", ".", "sum", "(", "2", ")", "\n", "# add dummy zero for O", "\n", "final_logits", "=", "torch", ".", "stack", "(", "[", "final_logits", ",", "final_logits", ".", "new_zeros", "(", "*", "final_logits", ".", "size", "(", ")", ")", "]", ",", "-", "1", ")", "\n", "\n", "spans", "=", "gold_spans", "\n", "span_labels", "=", "gold_span_labels", "\n", "# spans Shape: (batch_size, num_spans, 2)", "\n", "spans", "=", "F", ".", "relu", "(", "spans", ".", "float", "(", ")", ")", ".", "long", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "2", ")", "\n", "num_spans", "=", "spans", ".", "size", "(", "1", ")", "\n", "\n", "# shape (batch_size, 1 (only 1 span), span_tags, 2)   is PER / not PER , is LOC / not LOC ...", "\n", "span_probs", "=", "self", ".", "soft_maxer", "(", "final_logits", ")", ".", "view", "(", "batch_size", ",", "1", ",", "2", "*", "(", "self", ".", "num_span_tags", "-", "1", ")", ")", "\n", "# shape (batch_size, 1 (only 1 span), 2*(self.num_span_tags-1)) ", "\n", "span_probs_mask", "=", "self", ".", "label_to_mask_for_loss", "(", "span_labels", ")", ".", "detach", "(", ")", ".", "float", "(", ")", "\n", "\n", "\n", "# TODO:", "\n", "# Predict results", "\n", "pred_results", "=", "[", "]", "\n", "mx_prob", ",", "mx_ind", "=", "span_probs", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ",", "2", ")", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "max", "(", "2", ")", "\n", "larger_than_half", "=", "mx_prob", ">", "0.5", "\n", "# Shape: mx_prob:(batch_size, 1), mx_ind:(batch_size,1)", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "pred_span", "=", "{", "}", "\n", "phrase_len", "=", "len", "(", "metadata", "[", "i", "]", "[", "\"words\"", "]", ")", "\n", "if", "mx_prob", "[", "i", ",", "0", "]", ">", "0.5", ":", "\n", "                ", "pred_span", "=", "{", "(", "0", ",", "phrase_len", "-", "1", ")", ":", "self", ".", "vocab", ".", "get_index_to_token_vocabulary", "(", "self", ".", "span_label_namespace", ")", "[", "int", "(", "mx_ind", "[", "i", ",", "0", "]", ")", "]", "}", "\n", "pass", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "", "pred_results", ".", "append", "(", "pred_span", ")", "\n", "\n", "", "output", "=", "{", "}", "\n", "output", "[", "'span_logits'", "]", "=", "span_logits", "\n", "\n", "ce_loss", "=", "span_probs_mask", "*", "(", "1e-6", "+", "span_probs", ")", ".", "log", "(", ")", "# may cause NaN error..., possibly use (eps + span_probs).log ?", "\n", "output", "[", "'span_probs_mask'", "]", "=", "span_probs_mask", "\n", "output", "[", "'ce_loss'", "]", "=", "ce_loss", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ",", "2", ")", "\n", "if", "self", ".", "class_weight", "is", "not", "None", ":", "\n", "# re-weight classes during training", "\n", "            ", "pass", "#ce_loss = ce_loss.view(batch_size,1,-1,2) * torch.cuda.FloatTensor(self.class_weight).view(-1,1)  ", "\n", "", "ce_loss", "=", "-", "ce_loss", ".", "sum", "(", ")", "/", "(", "batch_size", "*", "num_spans", ")", "\n", "output", "[", "'loss'", "]", "=", "ce_loss", "\n", "output", "[", "'span_probs'", "]", "=", "span_probs", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ",", "2", ")", "\n", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "output", "[", "\"words\"", "]", "=", "[", "x", "[", "\"words\"", "]", "for", "x", "in", "metadata", "]", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.models.soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.get_metrics": [[237, 250], ["soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF._span_f1_metric.get_metric", "list", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.keys", "metrics_to_return.update", "metrics_to_return.update", "soft_dictionary_span_classifier_HSCRF.soft_dictionary_span_classifier_HSCRF.items"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics_to_return", "=", "{", "}", "\n", "if", "self", ".", "calculate_span_f1", ":", "\n", "            ", "span_f1_dict", "=", "self", ".", "_span_f1_metric", ".", "get_metric", "(", "reset", "=", "reset", ")", "\n", "span_kys", "=", "list", "(", "span_f1_dict", ".", "keys", "(", ")", ")", "\n", "if", "self", ".", "_verbose_metrics", ":", "\n", "                ", "metrics_to_return", ".", "update", "(", "span_f1_dict", ")", "\n", "", "else", ":", "\n", "                ", "metrics_to_return", ".", "update", "(", "{", "\n", "x", ":", "y", "for", "x", ",", "y", "in", "span_f1_dict", ".", "items", "(", ")", "if", "\n", "\"overall\"", "in", "x", "}", ")", "\n", "", "", "return", "metrics_to_return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1.__init__": [[11, 20], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "set"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "non_entity_labels", "=", "[", "'O'", "]", ")", "->", "None", ":", "\n", "        ", "self", ".", "_num_gold_mentions", "=", "0", "\n", "self", ".", "_num_recalled_mentions", "=", "0", "\n", "self", ".", "_num_predicted_mentions", "=", "0", "\n", "self", ".", "_TP", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_FP", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_TN", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_FN", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "non_entity_labels", "=", "set", "(", "non_entity_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1.__call__": [[22, 45], ["zip", "len", "len", "len", "predicted_spans.items", "gold_spans.items", "set", "set", "predicted_spans.items", "predicted_spans.items"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "__call__", "(", "self", ",", "# type: ignore", "\n", "batched_predicted_spans", ",", "\n", "batched_gold_spans", ",", "\n", "sentences", "=", "None", ")", ":", "\n", "\n", "        ", "non_entity_labels", "=", "self", ".", "non_entity_labels", "\n", "for", "predicted_spans", ",", "gold_spans", ",", "sent", "in", "zip", "(", "batched_predicted_spans", ",", "batched_gold_spans", ",", "sentences", ")", ":", "\n", "            ", "self", ".", "_num_gold_mentions", "+=", "len", "(", "gold_spans", ")", "\n", "self", ".", "_num_recalled_mentions", "+=", "len", "(", "set", "(", "gold_spans", ")", "&", "set", "(", "[", "x", "for", "x", ",", "y", "in", "predicted_spans", ".", "items", "(", ")", "if", "y", "not", "in", "non_entity_labels", "]", ")", ")", "\n", "self", ".", "_num_predicted_mentions", "+=", "len", "(", "[", "x", "for", "x", ",", "y", "in", "predicted_spans", ".", "items", "(", ")", "if", "y", "not", "in", "non_entity_labels", "]", ")", "\n", "mem_dict", "=", "{", "}", "\n", "for", "ky", ",", "val", "in", "predicted_spans", ".", "items", "(", ")", ":", "\n", "                ", "if", "val", "in", "non_entity_labels", ":", "\n", "                    ", "continue", "\n", "", "if", "ky", "in", "gold_spans", "and", "val", "==", "gold_spans", "[", "ky", "]", ":", "\n", "                    ", "self", ".", "_TP", "[", "val", "]", "+=", "1", "\n", "mem_dict", "[", "ky", "]", "=", "True", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_FP", "[", "val", "]", "+=", "1", "\n", "", "", "for", "ky", ",", "val", "in", "gold_spans", ".", "items", "(", ")", ":", "\n", "                ", "if", "ky", "not", "in", "mem_dict", ":", "\n", "                    ", "self", ".", "_FN", "[", "val", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1.get_metric": [[48, 96], ["set", "all_tags.update", "all_tags.update", "all_tags.update", "span_f1.MySpanF1._compute_metrics", "span_f1.MySpanF1._TP.keys", "span_f1.MySpanF1._FP.keys", "span_f1.MySpanF1._FN.keys", "span_f1.MySpanF1._compute_metrics", "sum", "sum", "sum", "span_f1.MySpanF1.reset", "span_f1.MySpanF1._TP.values", "span_f1.MySpanF1._FP.values", "span_f1.MySpanF1._FN.values", "float", "float"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1._compute_metrics", "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1._compute_metrics", "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1.reset"], ["", "", "", "", "@", "overrides", "\n", "def", "get_metric", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "float", ":", "\n", "\n", "        ", "all_tags", ":", "Set", "[", "str", "]", "=", "set", "(", ")", "\n", "all_tags", ".", "update", "(", "self", ".", "_TP", ".", "keys", "(", ")", ")", "\n", "all_tags", ".", "update", "(", "self", ".", "_FP", ".", "keys", "(", ")", ")", "\n", "all_tags", ".", "update", "(", "self", ".", "_FN", ".", "keys", "(", ")", ")", "\n", "all_metrics", "=", "{", "}", "\n", "\n", "for", "tag", "in", "all_tags", ":", "\n", "            ", "precision", ",", "recall", ",", "f1_measure", "=", "self", ".", "_compute_metrics", "(", "self", ".", "_TP", "[", "tag", "]", ",", "\n", "self", ".", "_FP", "[", "tag", "]", ",", "\n", "self", ".", "_FN", "[", "tag", "]", ")", "\n", "precision_key", "=", "\"precision\"", "+", "\"-\"", "+", "tag", "\n", "recall_key", "=", "\"recall\"", "+", "\"-\"", "+", "tag", "\n", "f1_key", "=", "\"f1-measure\"", "+", "\"-\"", "+", "tag", "\n", "all_metrics", "[", "precision_key", "]", "=", "precision", "\n", "all_metrics", "[", "recall_key", "]", "=", "recall", "\n", "all_metrics", "[", "f1_key", "]", "=", "f1_measure", "\n", "\n", "# Compute the precision, recall and f1 for all spans jointly.", "\n", "", "precision", ",", "recall", ",", "f1_measure", "=", "self", ".", "_compute_metrics", "(", "sum", "(", "self", ".", "_TP", ".", "values", "(", ")", ")", ",", "\n", "sum", "(", "self", ".", "_FP", ".", "values", "(", ")", ")", ",", "\n", "sum", "(", "self", ".", "_FN", ".", "values", "(", ")", ")", ")", "\n", "all_metrics", "[", "\"precision-overall\"", "]", "=", "precision", "\n", "all_metrics", "[", "\"recall-overall\"", "]", "=", "recall", "\n", "all_metrics", "[", "\"f1-measure-overall\"", "]", "=", "f1_measure", "\n", "\n", "\n", "if", "self", ".", "_num_gold_mentions", "==", "0", ":", "\n", "            ", "entity_recall", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "entity_recall", "=", "self", ".", "_num_recalled_mentions", "/", "float", "(", "self", ".", "_num_gold_mentions", ")", "\n", "\n", "", "if", "self", ".", "_num_predicted_mentions", "==", "0", ":", "\n", "            ", "entity_precision", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "entity_precision", "=", "self", ".", "_num_recalled_mentions", "/", "float", "(", "self", ".", "_num_predicted_mentions", ")", "\n", "\n", "", "all_metrics", "[", "'entity_recall'", "]", "=", "entity_recall", "\n", "all_metrics", "[", "'entity_precision'", "]", "=", "entity_precision", "\n", "all_metrics", "[", "'entity_f1'", "]", "=", "2.", "*", "(", "(", "entity_precision", "*", "entity_recall", ")", "/", "(", "entity_precision", "+", "entity_recall", "+", "1e-13", ")", ")", "\n", "all_metrics", "[", "'entity_ALLTRUE'", "]", "=", "self", ".", "_num_gold_mentions", "\n", "all_metrics", "[", "'entity_ALLRECALLED'", "]", "=", "self", ".", "_num_recalled_mentions", "\n", "all_metrics", "[", "'entity_ALLPRED'", "]", "=", "self", ".", "_num_predicted_mentions", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "all_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1._compute_metrics": [[98, 104], ["float", "float", "float", "float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_metrics", "(", "true_positives", ":", "int", ",", "false_positives", ":", "int", ",", "false_negatives", ":", "int", ")", ":", "\n", "        ", "precision", "=", "float", "(", "true_positives", ")", "/", "float", "(", "true_positives", "+", "false_positives", "+", "1e-13", ")", "\n", "recall", "=", "float", "(", "true_positives", ")", "/", "float", "(", "true_positives", "+", "false_negatives", "+", "1e-13", ")", "\n", "f1_measure", "=", "2.", "*", "(", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", "+", "1e-13", ")", ")", "\n", "return", "precision", ",", "recall", ",", "f1_measure", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.span_f1.MySpanF1.reset": [[105, 114], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_num_gold_mentions", "=", "0", "\n", "self", ".", "_num_recalled_mentions", "=", "0", "\n", "self", ".", "_num_predicted_mentions", "=", "0", "\n", "self", ".", "_TP", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_FP", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_TN", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_FN", "=", "defaultdict", "(", "int", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.metrics.__init__.is_sklearn_available": [[31, 33], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling.BertForTokenClassification_.forward": [[44, 131], ["modeling.BertForTokenClassification_.bert", "modeling.BertForTokenClassification_.dropout", "modeling.BertForTokenClassification_.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.nn.functional.softmax", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "attention_mask.view", "modeling.BertForTokenClassification_.view", "labels.view", "modeling.BertForTokenClassification_.view", "labels.view", "attention_mask.view", "labels.view", "torch.nn.functional.softmax.view", "src_probs.view", "torch.nn.functional.softmax.view", "hard_labels.view", "hard_labels_mask.view"], "methods", ["None"], ["start_id", "=", "end_id", "\n", "\n", "# max-loss", "\n", "", "", "if", "lambda_max_loss", "!=", "0.0", ":", "\n", "                    ", "loss_max", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "active_max", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss_max", "=", "0.0", "\n", "\n", "# mask-loss", "\n", "", "if", "lambda_mask_loss", "!=", "0.0", ":", "\n", "                    ", "active_mask", "=", "torch", ".", "cat", "(", "active_mask", ")", "\n", "if", "sum", "(", "active_mask", ")", "!=", "0", ":", "\n", "                        ", "loss_mask", "=", "torch", ".", "sum", "(", "loss", "[", "active_mask", "]", ")", "/", "sum", "(", "active_mask", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss_mask", "=", "0.0", "\n", "\n", "", "return", "loss_crossEntropy", "+", "lambda_max_loss", "*", "loss_max", "+", "lambda_mask_loss", "*", "loss_mask", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "assert", "False", "\n", "", "", "else", ":", "\n", "            ", "return", "logits", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling.BaseModel.__init__": [[134, 141], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Dropout", "modeling.BaseModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling.BaseModel.forward": [[142, 154], ["modeling.BaseModel.bert"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling.DomainLearner.__init__": [[157, 170], ["super().__init__", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "modeling.DomainLearner.domain_embed.data.copy_"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling.DomainLearner.forward": [[171, 195], ["modeling.DomainLearner.simU", "modeling.DomainLearner.simV().transpose", "torch.mm", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.DomainLearner.simV", "torch.sum", "torch.mm", "torch.eye().to", "torch.mm", "torch.eye().to", "modeling.DomainLearner.domain_embed.transpose", "modeling.DomainLearner.domain_embed.t", "torch.eye", "torch.eye", "modeling.DomainLearner.domain_embed.size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling.DomainLearner.get_domain_embeds": [[196, 198], ["modeling.DomainLearner.domain_embed.detach"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling.DomainLearner.get_domain_similarity": [[199, 214], ["modeling.DomainLearner.simU", "modeling.DomainLearner.simV", "torch.sum().detach().item", "torch.nn.functional.cosine_similarity", "torch.sum().detach", "torch.norm", "torch.sum"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.set_seed": [[41, 48], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [en] - [valid] **********\"", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_en_valid", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_optimizer_grouped_parameters": [[49, 70], ["logger.info", "model.named_parameters", "model.named_parameters", "any", "logger.info", "model.named_parameters", "model.named_parameters", "any", "any"], "function", ["None"], ["best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Valid F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "", "def", "train_meta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: Meta Learning **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "True", ",", "support_size", "=", "args", ".", "support_size", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "True", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_en_valid", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'valid'", ",", "\n", "load_data", "=", "True", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_en_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.train": [[71, 238], ["tensorboardX.SummaryWriter", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "main.get_optimizer_grouped_parameters", "transformers.AdamW", "transformers.WarmupLinearSchedule", "main.set_seed", "range", "tensorboardX.SummaryWriter.close", "max", "len", "torch.nn.DataParallel", "enumerate", "len", "src_probs.size", "src_probs.size", "torch.cat().to", "torch.nn.functional.embedding().detach", "torch.ones_like.detach", "len", "int", "model.train", "model.zero_grad", "model", "loss_KD.mean.backward", "loss.mean.item", "loss_KD.mean.item", "torch.nn.utils.clip_grad_norm_", "transformers.WarmupLinearSchedule.step", "transformers.AdamW.step", "torch.argmax", "len", "str", "range", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "loss.mean.mean", "loss_KD.mean.mean", "model.parameters", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "torch.ones_like", "torch.cat", "torch.nn.functional.embedding", "str", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.WarmupLinearSchedule.get_lr", "torch.eye", "torch.zeros", "transformers.WarmupLinearSchedule.get_lr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "        ", "progress", "=", "1.0", "*", "step", "/", "args", ".", "max_meta_steps", "\n", "\n", "batch_query", ",", "batch_support", "=", "corpus_en_train", ".", "get_batch_meta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "#(batch_size=32)", "\n", "loss", "=", "learner", ".", "forward_meta", "(", "batch_query", ",", "batch_support", ",", "progress", "=", "progress", ",", "inner_steps", "=", "args", ".", "inner_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [en] - [valid] **********\"", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_en_valid", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Valid F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "\n", "#########################################################", "\n", "# Transfer the source-trained model to target languages", "\n", "#########################################################", "\n", "\n", "", "def", "zero_shot_NOmeta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-NOmeta-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot NO meta learning **********\"", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "zero_shot_meta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot with meta learning (separate support set) **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "reprer", "=", "Reprer", "(", "args", ".", "bert_model", ")", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "\n", "args", ".", "lr_inner", ",", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "args", ".", "support_size", ",", "base_features", "=", "corpus_en_train", ".", "original_features", ",", "\n", "mask_rate", "=", "-", "1.0", ",", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] - support on [en] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_meta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lr", "=", "args", ".", "lr_finetune", ",", "steps", "=", "args", ".", "max_ft_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ",", "\n", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "k_shot", "(", "args", ")", ":", "\n", "# to define: k_shot, max_ft_steps, lr_finetune, lambda_max_loss", "\n", "    ", "res_filename", "=", "'{}/res-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: {}-shot fine-tuning **********\"", ".", "format", "(", "args", ".", "k_shot", ")", ")", "\n", "\n", "learner_pretrained", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ",", "k_shot_prop", "=", "args", ".", "k_shot", ")", "# add k_shot_prop", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "deepcopy", "(", "learner_pretrained", ")", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "for", "ft_step", "in", "range", "(", "args", ".", "max_ft_steps", ")", ":", "\n", "            ", "data_batches", "=", "corpus_train", ".", "get_batches", "(", "args", ".", "inner_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", "\n", "\n", "for", "batch_data", "in", "data_batches", ":", "\n", "                ", "loss", "=", "learner", ".", "inner_update", "(", "batch_data", ",", "lr_curr", "=", "args", ".", "lr_finetune", ",", "inner_steps", "=", "1", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "", "if", "ft_step", "in", "[", "0", ",", "4", ",", "9", ",", "14", "]", ":", "\n", "                ", "logger", ".", "info", "(", "'Fine-tune Step: {}/{}, loss = {:8f}, time = {:2f}s.'", ".", "format", "(", "ft_step", ",", "args", ".", "max_ft_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test], Finetune step = {} **********\"", ".", "format", "(", "lang", ",", "ft_step", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "", "", "for", "i", ",", "lang", "in", "enumerate", "(", "languages", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "supervised_NOmeta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: Supervised & NO Meta Learning **********\"", ")", "\n", "lang", "=", "args", ".", "test_langs", "[", "0", "]", "\n", "logger", ".", "info", "(", "\"language: {}\"", ".", "format", "(", "lang", ")", ")", "\n", "\n", "# prepare dataset", "\n", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.evaluate": [[239, 304], ["main.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "numpy.argmax", "range", "logger.info", "sorted", "max", "len", "tuple", "range", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "results.keys", "logger.info", "torch.no_grad", "model", "tmp_eval_loss.item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "enumerate", "range", "range", "str", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "out_label_list[].append", "preds_list[].append", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples"], ["\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "\n", "        ", "batch_data", "=", "corpus_train", ".", "get_batch_NOmeta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "\n", "loss", "=", "learner", ".", "forward_NOmeta", "(", "batch_data", ",", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Test F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# dataset settings", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "help", "=", "'where to save the result.'", ",", "default", "=", "'test'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_langs'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'languages to test'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "type", "=", "str", ",", "help", "=", "'dir name of a trained model'", ",", "default", "=", "''", ")", "\n", "\n", "# activate zero_shot only", "\n", "parser", ".", "add_argument", "(", "'--zero_shot'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run 0-shot procedure only.'", ")", "\n", "# activate fine-tune only", "\n", "parser", ".", "add_argument", "(", "'--k_shot'", ",", "type", "=", "float", ",", "default", "=", "-", "1", ",", "help", "=", "'size of k-shot data: k, if >0,  will run fine-ture procedure'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_finetune'", ",", "type", "=", "float", ",", "help", "=", "'finetune learning rate, used in [test_meta]. and [k_shot setting]'", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--max_ft_steps'", ",", "type", "=", "int", ",", "help", "=", "'maximal steps token for fine-tune.'", ",", "default", "=", "1", ")", "# ===>", "\n", "\n", "# activate mBERT only", "\n", "parser", ".", "add_argument", "(", "'--no_meta_learning'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run mBERT only.'", ")", "\n", "parser", ".", "add_argument", "(", "'--supervised'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run mBERT only.'", ")", "\n", "\n", "# meta-learning", "\n", "parser", ".", "add_argument", "(", "'--inner_steps'", ",", "type", "=", "int", ",", "help", "=", "'every ** inner update for one meta-update'", ",", "default", "=", "2", ")", "# ===>", "\n", "parser", ".", "add_argument", "(", "'--inner_size'", ",", "type", "=", "int", ",", "help", "=", "'[number of tasks] for one meta-update'", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--support_size'", ",", "type", "=", "int", ",", "help", "=", "'support size (batch_size) for inner update'", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_inner'", ",", "type", "=", "float", ",", "help", "=", "'inner loop learning rate'", ",", "default", "=", "3e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_meta'", ",", "type", "=", "float", ",", "help", "=", "'meta learning rate'", ",", "default", "=", "3e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--max_meta_steps'", ",", "type", "=", "int", ",", "help", "=", "'maximal steps token for meta training.'", ",", "default", "=", "3001", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every_meta_steps'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_prop_inner'", ",", "type", "=", "int", ",", "help", "=", "'warm up proportion for inner update'", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_prop_meta'", ",", "type", "=", "int", ",", "help", "=", "'warm up proportion for meta update'", ",", "default", "=", "0.1", ")", "\n", "# parser.add_argument('--cross_meta_rate', type=float, help='when > 0, randomly flipping cross objective or normal objective', default=1.0)", "\n", "\n", "\n", "# training paramters", "\n", "parser", ".", "add_argument", "(", "'--mask_rate'", ",", "type", "=", "float", ",", "help", "=", "'the probability to [mask] a token with a B/I-XXX label.'", ",", "default", "=", "-", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_max_loss'", ",", "type", "=", "float", ",", "help", "=", "'the weight of the max-loss.'", ",", "default", "=", "0.0", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.weighted_voting": [[306, 340], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "numpy.argmax", "range", "logger.info", "sorted", "max", "src_probs.cpu().numpy", "range", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "os.path.basename", "results.keys", "logger.info", "numpy.append", "enumerate", "range", "range", "str", "src_probs.cpu", "out_label_list[].append", "preds_list[].append"], "function", ["None"], ["\n", "\n", "# permanent params", "\n", "parser", ".", "add_argument", "(", "'--freeze_layer'", ",", "type", "=", "int", ",", "help", "=", "'the layer of mBERT to be frozen'", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seq_len'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_model'", ",", "type", "=", "str", ",", "default", "=", "'bert-base-multilingual-cased'", ",", "#required=True,", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"", "\n", "\"bert-base-multilingual-cased, bert-base-chinese.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "help", "=", "'Where do you want to store the pre-trained models downloaded from s3'", ",", "default", "=", "''", ")", "\n", "# expt setting", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "help", "=", "'random seed to reproduce the result.'", ",", "default", "=", "667", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_device'", ",", "type", "=", "int", ",", "help", "=", "'GPU device num'", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--py_alias'", ",", "type", "=", "str", ",", "help", "=", "'python alias'", ",", "default", "=", "'python'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "# setup random seed", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "\n", "# set up GPU device", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu_device", ")", "\n", "\n", "# setup logger settings", "\n", "if", "args", ".", "zero_shot", ":", "\n", "        ", "assert", "args", ".", "model_dir", "!=", "''", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_dir", ")", "and", "len", "(", "args", ".", "test_langs", ")", ">", "0", "\n", "if", "args", ".", "no_meta_learning", ":", "\n", "            ", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-0shot-NOmeta-{}.txt'", ".", "format", "(", "args", ".", "model_dir", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.load_and_cache_examples": [[342, 380], ["os.path.join", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_ner.read_examples_from_file", "utils_ner.convert_examples_to_features", "logger.info", "torch.save", "list().pop", "str", "list", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.read_examples_from_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["            ", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.txt'", ".", "format", "(", "\n", "args", ".", "model_dir", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "\n", "# dump args", "\n", "", "with", "Path", "(", "'{}/args-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "\n", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "args", ".", "result_dir", "=", "args", ".", "model_dir", "\n", "\n", "", "elif", "args", ".", "k_shot", ">", "0", ":", "\n", "        ", "assert", "args", ".", "model_dir", "!=", "''", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_dir", ")", "and", "len", "(", "args", ".", "test_langs", ")", ">", "0", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.txt'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "\n", "\n", "# dump args", "\n", "with", "Path", "(", "'{}/args-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "args", ".", "result_dir", "=", "args", ".", "model_dir", "\n", "", "elif", "args", ".", "supervised", ":", "\n", "        ", "assert", "args", ".", "model_dir", "==", "''", "\n", "# top_dir = 'models\\\\result-{}'.format(args.expt_comment)", "\n", "top_dir", "=", "'models'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "top_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "top_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", ")", "\n", "", "elif", "args", ".", "result_dir", "!=", "'test'", ":", "\n", "            ", "assert", "False", ",", "'Existing result directory!'", "\n", "\n", "", "args", ".", "result_dir", "=", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", "\n", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-training.txt'", ".", "format", "(", "args", ".", "result_dir", ")", ")", "\n", "\n", "# dump args", "\n", "with", "Path", "(", "'{}/args.json'", ".", "format", "(", "args", ".", "result_dir", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "assert", "args", ".", "model_dir", "==", "''", "\n", "# top_dir = 'models\\\\result-{}'.format(args.expt_comment)", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_src_probs": [[382, 419], ["os.path.join", "modeling.BertForTokenClassification_.from_pretrained", "BertForTokenClassification_.from_pretrained.to", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "BertForTokenClassification_.from_pretrained.eval", "torch.nn.functional.softmax", "max", "len", "tuple", "torch.no_grad", "BertForTokenClassification_.from_pretrained.", "logits.detach", "torch.cat", "t.to", "logits.detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["if", "not", "os", ".", "path", ".", "exists", "(", "top_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "top_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'{}/{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "'{}/{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ")", ")", "\n", "", "elif", "args", ".", "result_dir", "!=", "'test'", ":", "\n", "            ", "assert", "False", ",", "'Existing result directory!'", "\n", "\n", "", "args", ".", "result_dir", "=", "'{}/{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ")", "\n", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-training.txt'", ".", "format", "(", "args", ".", "result_dir", ")", ")", "\n", "\n", "# dump args", "\n", "with", "Path", "(", "'{}/args-train.json'", ".", "format", "(", "args", ".", "result_dir", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s %(levelname)s: - %(message)s'", ",", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "\n", "if", "args", ".", "zero_shot", ":", "\n", "        ", "if", "args", ".", "no_meta_learning", ":", "\n", "            ", "zero_shot_NOmeta", "(", "args", ")", "\n", "", "else", ":", "\n", "            ", "zero_shot_meta", "(", "args", ")", "\n", "", "", "elif", "args", ".", "k_shot", ">", "0", ":", "\n", "        ", "k_shot", "(", "args", ")", "\n", "", "elif", "args", ".", "supervised", ":", "\n", "        ", "supervised_NOmeta", "(", "args", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_st_embeds": [[420, 448], ["logger.info", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "BaseModel.from_pretrained.eval", "modeling.BaseModel.from_pretrained", "BaseModel.from_pretrained.to", "max", "len", "tuple", "torch.no_grad", "BaseModel.from_pretrained.", "pooled_outputs.detach", "torch.cat", "bool", "t.to", "pooled_outputs.detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["        ", "if", "args", ".", "no_meta_learning", ":", "\n", "            ", "train_NOmeta", "(", "args", ")", "\n", "", "else", ":", "\n", "            ", "train_meta", "(", "args", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_st_sims": [[449, 492], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.eval", "torch.reciprocal", "logger.info", "torch.nn.functional.softmax", "torch.mean", "main.print_sim_info", "max", "len", "torch.var", "torch.no_grad", "model", "logits_batch.detach", "torch.cat", "torch.std", "str", "logits_batch.detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.print_sim_info"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_unlearn_st_sims": [[494, 530], ["range", "torch.cat", "torch.reciprocal", "logger.info", "torch.nn.functional.softmax", "torch.mean", "main.print_sim_info", "len", "torch.var", "torch.nn.functional.cosine_similarity", "sims.append", "torch.std", "torch.nn.functional.cosine_similarity.unsqueeze", "sims.append", "torch.sum", "sims.append", "ValueError", "torch.abs", "torch.sqrt", "torch.sum", "res.mul"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.print_sim_info"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.print_sim_info": [[532, 541], ["logger.info", "logger.info", "range", "logger.info", "logger.info", "logger.info", "logger.info", "str", "str", "round", "round", "v.item", "v.item"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_src_weighted_probs": [[543, 625], ["logger.info", "os.path.join", "os.path.exists", "enumerate", "logger.info", "torch.load", "logger.info", "logger.info", "torch.save", "main.get_src_probs", "src_predictions.append", "enumerate", "ValueError", "os.path.join", "os.path.join", "len", "ValueError", "main.print_sim_info", "torch.load", "main.get_st_embeds", "torch.utils.data.TensorDataset", "modeling.DomainLearner", "modeling.DomainLearner.load_state_dict", "modeling.DomainLearner.to", "main.get_st_sims", "main.get_st_embeds", "enumerate", "main.get_unlearn_st_sims", "main.get_src_probs", "src_predictions.append", "os.path.join", "langs.index", "len", "torch.load", "main.get_st_embeds", "torch.mean", "src_ebds.append", "os.path.join", "len", "len", "st_sims[].unsqueeze().unsqueeze", "st_sims[].unsqueeze().unsqueeze", "len", "len", "st_sims[].unsqueeze", "st_sims[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.print_sim_info", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_st_embeds", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_st_sims", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_st_embeds", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_unlearn_st_sims", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_st_embeds"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.setup": [[626, 798], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "str", "torch.device", "os.path.join", "logging.Formatter", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logger.addHandler", "logger.addHandler", "logger.warning", "main.set_seed", "logger.info", "parser.parse_args.src_langs.remove", "ValueError", "ValueError", "os.path.exists", "os.listdir", "os.path.exists", "ValueError", "os.path.exists", "os.listdir", "os.listdir", "os.path.exists", "os.listdir", "os.makedirs", "os.path.exists", "os.makedirs", "time.strftime", "os.path.join", "os.path.join", "os.path.basename", "os.path.basename", "ValueError", "ValueError", "os.path.exists", "time.localtime"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.main": [[799, 914], ["utils_ner.get_labels", "len", "transformers.BertTokenizer.from_pretrained", "transformers.BertConfig.from_pretrained", "torch.nn.CrossEntropyLoss", "main.load_and_cache_examples", "src_datasets.append", "logger.info", "main.load_and_cache_examples", "main.get_src_weighted_probs", "modeling.BertForTokenClassification_.from_pretrained", "BertForTokenClassification_.from_pretrained.to", "main.load_and_cache_examples", "main.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "BertTokenizer.from_pretrained.save_pretrained", "torch.save", "logger.info", "main.load_and_cache_examples", "main.get_src_weighted_probs", "main.weighted_voting", "os.path.join", "os.path.join", "logger.info", "modeling.BertForTokenClassification_.from_pretrained", "BertForTokenClassification_.from_pretrained.to", "main.evaluate", "os.path.join", "os.path.join", "torch.argmax().cpu", "torch.utils.data.TensorDataset", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "open", "sorted", "open", "open", "sorted", "open", "bool", "time.strftime", "os.path.basename", "result.keys", "writer.write", "time.strftime", "os.path.basename", "open", "time.strftime", "result.keys", "writer.write", "time.strftime", "open", "torch.argmax", "time.localtime", "time.localtime", "os.path.join", "time.localtime", "time.localtime", "os.path.join", "str", "line.startswith", "writer.write", "str", "line.startswith", "writer.write", "writer.write", "logger.warning", "writer.write", "logger.warning", "predictions[].pop", "line.split", "predictions[].pop", "line.split", "[].replace", "[].replace", "line.split", "line.split", "line.split", "line.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_labels", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_src_weighted_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.get_src_weighted_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main.weighted_voting", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.utils_ner.InputExample.__init__": [[30, 42], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "words", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            words: list. The words of the sequence.\n            labels: (Optional) list. The labels for each word of the sequence. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "words", "=", "words", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.utils_ner.InputFeatures.__init__": [[47, 52], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_ids", "=", "label_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.utils_ner.read_examples_from_file": [[54, 84], ["os.path.join", "io.open", "examples.append", "line.startswith", "line.split", "words.append", "utils_ner.InputExample", "examples.append", "len", "labels.append", "labels.append", "utils_ner.InputExample", "splits[].replace"], "function", ["None"], ["", "", "def", "read_examples_from_file", "(", "data_dir", ",", "mode", ")", ":", "\n", "    ", "file_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.txt\"", ".", "format", "(", "mode", ")", ")", "\n", "# file_path = os.path.join(data_dir, \"{}.part.txt\".format(mode)) # for debug", "\n", "guid_index", "=", "1", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", "or", "line", "==", "\"\"", "or", "line", "==", "\"\\n\"", ":", "\n", "                ", "if", "words", ":", "\n", "                    ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "\"{}-{}\"", ".", "format", "(", "mode", ",", "guid_index", ")", ",", "\n", "words", "=", "words", ",", "\n", "labels", "=", "labels", ")", ")", "\n", "guid_index", "+=", "1", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                ", "splits", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "words", ".", "append", "(", "splits", "[", "0", "]", ")", "\n", "if", "len", "(", "splits", ")", ">", "1", ":", "\n", "                    ", "labels", ".", "append", "(", "splits", "[", "-", "1", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "", "else", ":", "\n", "# Examples could have no label for mode = \"test\"", "\n", "                    ", "labels", ".", "append", "(", "\"O\"", ")", "\n", "", "", "", "if", "words", ":", "\n", "            ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "\"%s-%d\"", ".", "format", "(", "mode", ",", "guid_index", ")", ",", "\n", "words", "=", "words", ",", "\n", "labels", "=", "labels", ")", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.utils_ner.convert_examples_to_features": [[86, 205], ["enumerate", "zip", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "logger.info", "tokenizer.tokenize", "tokens.extend", "label_ids.extend", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_ner.InputFeatures", "len", "len", "str", "str", "str", "str", "str", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "convert_examples_to_features", "(", "examples", ",", "\n", "label_list", ",", "\n", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "cls_token_segment_id", "=", "1", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "sep_token_extra", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_token_label_id", "=", "-", "1", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", ",", "ex_index", ",", "len", "(", "examples", ")", ")", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "for", "word", ",", "label", "in", "zip", "(", "example", ".", "words", ",", "example", ".", "labels", ")", ":", "\n", "            ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "if", "len", "(", "word_tokens", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "# Use the real label id for the first token of the word, and padding ids for the remaining tokens", "\n", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "pad_token_label_id", "]", "*", "(", "len", "(", "word_tokens", ")", "-", "1", ")", ")", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.", "\n", "", "special_tokens_count", "=", "3", "if", "sep_token_extra", "else", "2", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_length", "-", "special_tokens_count", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "label_ids", "=", "label_ids", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "if", "sep_token_extra", ":", "\n", "# roberta uses an extra separator b/w pairs of sentences", "\n", "            ", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "+=", "[", "cls_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "segment_ids", "+=", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "label_ids", "=", "[", "pad_token_label_id", "]", "+", "label_ids", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "label_ids", "=", "(", "[", "pad_token_label_id", "]", "*", "padding_length", ")", "+", "label_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "+=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "+=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "+=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "label_ids", "+=", "(", "[", "pad_token_label_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "label_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", ",", "example", ".", "guid", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "label_ids", "]", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_ids", "=", "label_ids", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.utils_ner.get_labels": [[207, 218], ["io.open", "f.read().splitlines", "f.read().splitlines.remove", "f.read"], "function", ["None"], ["", "def", "get_labels", "(", "path", ")", ":", "\n", "    ", "if", "path", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "if", "\"O\"", "not", "in", "labels", ":", "\n", "            ", "labels", "=", "[", "\"O\"", "]", "+", "labels", "\n", "", "while", "(", "''", "in", "labels", ")", ":", "\n", "            ", "labels", ".", "remove", "(", "''", ")", "\n", "", "return", "labels", "\n", "", "else", ":", "\n", "        ", "return", "[", "\"O\"", ",", "\"B-MISC\"", ",", "\"I-MISC\"", ",", "\"B-PER\"", ",", "\"I-PER\"", ",", "\"B-ORG\"", ",", "\"I-ORG\"", ",", "\"B-LOC\"", ",", "\"I-LOC\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.utils_ner.endless_get_next_pt_batch": [[220, 231], ["next", "iter", "next"], "function", ["None"], ["", "", "def", "endless_get_next_pt_batch", "(", "pt_loader", ",", "pt_iter", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "pt_batch", "=", "next", "(", "pt_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "        ", "pt_iter", "=", "iter", "(", "pt_loader", ")", "\n", "pt_batch", "=", "next", "(", "pt_iter", ")", "\n", "# In PyTorch 0.3, Batch Norm no longer works for size 1 batch,", "\n", "# so we will skip leftover batch of size == 1", "\n", "# if opt.skip_leftover_batch and len(targets) < opt.batch_size:", "\n", "#     return endless_get_next_batch(loaders, iters, lang)", "\n", "", "return", "pt_batch", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.BertForTokenClassification_.forward": [[44, 114], ["modeling_single.BertForTokenClassification_.bert", "modeling_single.BertForTokenClassification_.dropout", "modeling_single.BertForTokenClassification_.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.nn.functional.softmax", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "attention_mask.view", "modeling_single.BertForTokenClassification_.view", "labels.view", "modeling_single.BertForTokenClassification_.view", "labels.view", "attention_mask.view", "labels.view", "torch.nn.functional.softmax.view", "src_probs.view"], "methods", ["None"], ["def", "forward", "(", "self", ",", "input_ids", ",", "src_probs", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ",", "loss_ignore_index", "=", "-", "100", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "if", "src_probs", "is", "not", "None", ":", "\n", "# ## KL Divergence", "\n", "# loss_KD_fct = KLDivLoss(reduction=\"mean\")", "\n", "# log_probs = torch.nn.functional.log_softmax(logits, dim=-1)", "\n", "# if attention_mask is not None:", "\n", "#     active_loss = attention_mask.view(-1) == 1", "\n", "#     active_log_probs = log_probs.view(-1, self.num_labels)[active_loss]", "\n", "#     active_src_probs = src_probs.view(-1, self.num_labels)[active_loss]", "\n", "#", "\n", "#     loss_KD = loss_KD_fct(active_log_probs, active_src_probs)", "\n", "# else:", "\n", "#     loss_KD = loss_KD_fct(log_probs, src_probs)", "\n", "\n", "# ## CrossEntropy", "\n", "# loss_KD_fct = CrossEntropyLoss()", "\n", "# src_labels = torch.argmax(src_probs.view(-1, self.num_labels), dim=-1)", "\n", "# if attention_mask is not None:", "\n", "#     active_loss = attention_mask.view(-1) == 1", "\n", "#     active_logits = logits.view(-1, self.num_labels)[active_loss]", "\n", "#     active_src_labels = src_labels[active_loss]", "\n", "#", "\n", "#     loss_KD = loss_KD_fct(active_logits, active_src_labels)", "\n", "# else:", "\n", "#     loss_KD = loss_KD_fct(logits.view(-1, self.num_labels), src_labels)", "\n", "\n", "## L2 Norm", "\n", "            ", "loss_KD_fct", "=", "MSELoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "inactive_subword", "=", "labels", ".", "view", "(", "-", "1", ")", "==", "loss_ignore_index", "\n", "active_loss", "[", "inactive_subword", "]", "=", "0", "\n", "active_probs", "=", "probs", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_src_probs", "=", "src_probs", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "\n", "loss_KD", "=", "loss_KD_fct", "(", "active_probs", ",", "active_src_probs", ")", "\n", "", "else", ":", "\n", "                ", "loss_KD", "=", "loss_KD_fct", "(", "probs", ",", "src_probs", ")", "\n", "\n", "", "outputs", "=", "(", "loss_KD", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss_KD), (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.BaseModel.__init__": [[117, 124], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Dropout", "modeling_single.BaseModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BaseModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.BaseModel.forward": [[125, 137], ["modeling_single.BaseModel.bert"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "# sequence_output = outputs[0]", "\n", "# pooled_output = outputs[1]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.LIOutputLayer.__init__": [[140, 149], ["super().__init__", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Dropout", "modeling_single.GradientReversal", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "hidden_dropout_prob", ",", "n_langs", ",", "gr_lambda", "=", "-", "1.0", ")", ":", "\n", "        ", "super", "(", "LIOutputLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_langs", "=", "n_langs", "\n", "\n", "if", "gr_lambda", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Sequential", "(", "GradientReversal", "(", "lambda_", "=", "gr_lambda", ")", ",", "torch", ".", "nn", ".", "Dropout", "(", "hidden_dropout_prob", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "hidden_dropout_prob", ")", "\n", "", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "n_langs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.LIOutputLayer.forward": [[150, 166], ["modeling_single.LIOutputLayer.dropout", "modeling_single.LIOutputLayer.classifier", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_single.LIOutputLayer.view", "labels.view", "modeling_single.LIOutputLayer.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ",", "labels", "=", "None", ")", ":", "\n", "        ", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "outputs", "=", "(", "logits", ",", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "n_langs", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "n_langs", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.TaskOutputLayer.__init__": [[169, 175], ["super().__init__", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "hidden_dropout_prob", ",", "n_labels", ")", ":", "\n", "        ", "super", "(", "TaskOutputLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_labels", "=", "n_labels", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "n_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.TaskOutputLayer.forward": [[176, 211], ["modeling_single.TaskOutputLayer.dropout", "modeling_single.TaskOutputLayer.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.nn.functional.softmax", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "attention_mask.view", "modeling_single.TaskOutputLayer.view", "labels.view", "modeling_single.TaskOutputLayer.view", "labels.view", "attention_mask.view", "torch.nn.functional.softmax.view", "src_probs.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "src_probs", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "# src_probs: batch_size x n_src_langs x n_labels", "\n", "        ", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "# logits: batch_size x seq_len x n_labels", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "\n", "\n", "# compute the supervised loss", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "n_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "n_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "# compute the li_probs weighted KD loss (L2 norm)", "\n", "", "if", "src_probs", "is", "not", "None", ":", "\n", "            ", "loss_KD_fct", "=", "MSELoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_probs", "=", "probs", ".", "view", "(", "-", "1", ",", "self", ".", "n_labels", ")", "[", "active_loss", "]", "\n", "active_src_probs", "=", "src_probs", ".", "view", "(", "-", "1", ",", "self", ".", "n_labels", ")", "[", "active_loss", "]", "\n", "\n", "loss_KD", "=", "loss_KD_fct", "(", "active_probs", ",", "active_src_probs", ")", "\n", "", "else", ":", "\n", "                ", "loss_KD", "=", "loss_KD_fct", "(", "probs", ",", "src_probs", ")", "\n", "\n", "", "outputs", "=", "(", "loss_KD", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss_KD), (loss), logits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.forward": [[236, 240], ["x.clone"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "lambda_", ")", ":", "\n", "        ", "ctx", ".", "lambda_", "=", "lambda_", "\n", "return", "x", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward": [[241, 247], ["grads.new_tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grads", ")", ":", "\n", "        ", "lambda_", "=", "ctx", ".", "lambda_", "\n", "lambda_", "=", "grads", ".", "new_tensor", "(", "lambda_", ")", "\n", "dx", "=", "-", "lambda_", "*", "grads", "\n", "return", "dx", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GradientReversal.__init__": [[250, 253], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lambda_", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "GradientReversal", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_", "=", "lambda_", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GradientReversal.forward": [[254, 256], ["GRFunction.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "GRFunction", ".", "apply", "(", "x", ",", "self", ".", "lambda_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.DomainLearner.__init__": [[268, 279], ["super().__init__", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "modeling_single.DomainLearner.domain_embed.data.copy_"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "domain_vocab_size", ",", "hidden_size", ",", "low_rank_size", ",", "weights_init", "=", "None", ",", "gamma", "=", "0.00001", ")", ":", "\n", "        ", "super", "(", "DomainLearner", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "self", ".", "domain_embed", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "domain_vocab_size", ",", "hidden_size", ")", ")", "\n", "if", "weights_init", "is", "not", "None", ":", "\n", "            ", "self", ".", "domain_embed", ".", "data", ".", "copy_", "(", "weights_init", ")", "\n", "\n", "", "self", ".", "simU", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "low_rank_size", ")", "\n", "self", ".", "simV", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "low_rank_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.DomainLearner.forward": [[280, 301], ["modeling_single.DomainLearner.simU", "modeling_single.DomainLearner.simV().transpose", "torch.mm", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_single.DomainLearner.simV", "torch.mm", "torch.eye().to", "torch.sum", "modeling_single.DomainLearner.domain_embed.transpose", "torch.eye"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "labels", "=", "None", ",", "device", "=", "\"cuda\"", ")", ":", "\n", "\n", "        ", "U_fi", "=", "self", ".", "simU", "(", "features", ")", "# batch_size x low_rank_size", "\n", "V_mu_all", "=", "self", ".", "simV", "(", "self", ".", "domain_embed", ")", ".", "transpose", "(", "0", ",", "1", ")", "# vocab_size x low_rank_size = > low_rank_size x vocab_size", "\n", "\n", "logits", "=", "torch", ".", "mm", "(", "U_fi", ",", "V_mu_all", ")", "# batch_size x vocab_size", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "# nn.LogSoftmax() + nn.NLLLoss()", "\n", "loss_f", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "\n", "R", "=", "torch", ".", "mm", "(", "self", ".", "domain_embed", ".", "transpose", "(", "0", ",", "1", ")", ",", "self", ".", "domain_embed", ")", "-", "torch", ".", "eye", "(", "self", ".", "hidden_size", ")", ".", "to", "(", "device", ")", "\n", "loss_R", "=", "self", ".", "gamma", "*", "torch", ".", "sum", "(", "R", "*", "R", ")", "\n", "\n", "loss", "=", "loss_f", "+", "loss_R", "\n", "\n", "outputs", "=", "(", "loss", ",", "loss_f", ",", "loss_R", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.DomainLearner.get_domain_embeds": [[302, 304], ["modeling_single.DomainLearner.domain_embed.detach"], "methods", ["None"], ["", "def", "get_domain_embeds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "domain_embed", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.DomainLearner.get_domain_similarity": [[305, 320], ["modeling_single.DomainLearner.simU", "modeling_single.DomainLearner.simV", "torch.sum().detach().item", "torch.nn.functional.cosine_similarity", "torch.sum().detach", "torch.norm", "torch.sum"], "methods", ["None"], ["", "def", "get_domain_similarity", "(", "self", ",", "domain_idx", ",", "domain_idy", ",", "method", "=", "\"default\"", ")", ":", "\n", "        ", "if", "method", "==", "\"default\"", ":", "\n", "            ", "f_x", "=", "self", ".", "simU", "(", "self", ".", "domain_embed", "[", "domain_idx", "]", ")", "# low_rank_size", "\n", "f_y", "=", "self", ".", "simV", "(", "self", ".", "domain_embed", "[", "domain_idy", "]", ")", "# low_rank_size", "\n", "\n", "sim", "=", "torch", ".", "sum", "(", "f_x", "*", "f_y", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "elif", "method", "==", "\"cosine\"", ":", "\n", "            ", "sim", "=", "torch", ".", "nn", ".", "functional", ".", "cosine_similarity", "(", "self", ".", "domain_embed", "[", "domain_idx", "]", ",", "self", ".", "domain_embed", "[", "domain_idy", "]", ",", "\n", "dim", "=", "0", ",", "eps", "=", "1e-8", ")", "\n", "", "elif", "method", "==", "\"l2\"", ":", "\n", "            ", "sim", "=", "torch", ".", "norm", "(", "self", ".", "domain_embed", "[", "domain_idx", "]", "-", "self", ".", "domain_embed", "[", "domain_idy", "]", ")", "\n", "", "else", ":", "\n", "            ", "sim", "=", "-", "1.0", "\n", "\n", "", "return", "sim", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main_single.set_seed": [[54, 61], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main_single.train": [[63, 200], ["torch.utils.data.DataLoader", "logger.info", "torch.nn.parallel.DistributedDataParallel.named_parameters", "transformers.AdamW", "transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "main_single.set_seed", "range", "tensorboardX.SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "enumerate", "tensorboardX.SummaryWriter.close", "any", "logger.info", "int", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "len", "range", "ImportError", "str", "torch.distributed.get_world_size", "batch[].to", "batch[].to", "loss.mean.mean", "loss.mean.backward", "transformers.WarmupLinearSchedule.step", "transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "len", "str", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "batch[].to", "batch[].to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "any", "len", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "logger.info", "main_single.evaluate", "results.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "any", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "transformers.WarmupLinearSchedule.get_lr", "transformers.WarmupLinearSchedule.get_lr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate"], ["", "def", "train", "(", "args", ",", "model", ",", "train_dataset", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", "log_dir", "=", "args", ".", "log_dir", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "no_grad", "=", "[", "\"embeddings\"", "]", "+", "[", "\"layer.\"", "+", "str", "(", "layer_i", ")", "+", "\".\"", "for", "layer_i", "in", "range", "(", "12", ")", "if", "layer_i", "<", "args", ".", "freeze_bottom_layer", "]", "\n", "logger", ".", "info", "(", "\"  The frozen parameters are:\"", ")", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "p", ".", "requires_grad", "=", "False", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_grad", ")", "else", "True", "\n", "if", "not", "p", ".", "requires_grad", ":", "\n", "            ", "logger", ".", "info", "(", "\"    %s\"", ",", "n", ")", "\n", "", "", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "# scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_ratio", ")", ",", "t_total", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "args", ".", "gpu_ids", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  GPU IDs for training: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "args", ".", "gpu_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "epoch_i", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "# batch = tuple(t.to(args.device) for t in batch)", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", ",", "\n", "# XLM and RoBERTa don\"t use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "if", "len", "(", "batch", ")", "<=", "4", "else", "batch", "[", "-", "1", "]", "}", "# add hard-label scheme", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in pytorch-transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"===== evaluate_during_training =====\"", ")", "\n", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"Epoch: {}\\t global_step: {}\\t eval_{}: {}\"", ".", "format", "(", "epoch_i", ",", "\n", "global_step", ",", "key", ",", "value", ")", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\n", "\"Epoch: {}\\t global_step: {}\\t learning rate: {:.8}\\t loss: {:.4f}\"", ".", "format", "(", "\n", "epoch_i", ",", "global_step", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "\n", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\n", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main_single.train_KD": [[201, 355], ["torch.utils.data.DataLoader", "logger.info", "torch.nn.parallel.DistributedDataParallel.named_parameters", "transformers.AdamW", "transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "main_single.set_seed", "range", "tensorboardX.SummaryWriter", "len", "src_probs.size", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "enumerate", "tensorboardX.SummaryWriter.close", "any", "logger.info", "int", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss_KD.mean.item", "len", "range", "ImportError", "str", "torch.distributed.get_world_size", "batch[].to", "batch[].to", "batch[].to", "loss.mean.mean", "loss_KD.mean.mean", "loss_KD.mean.backward", "transformers.WarmupLinearSchedule.step", "transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "len", "str", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "batch[].to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "logger.info", "main_single.evaluate", "results.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "any", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "transformers.WarmupLinearSchedule.get_lr", "transformers.WarmupLinearSchedule.get_lr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate"], ["", "def", "train_KD", "(", "args", ",", "model", ",", "train_dataset", ",", "src_probs", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", "log_dir", "=", "args", ".", "log_dir", ")", "\n", "\n", "# check the size of the two relative datasets, expand train_dataset with src_probs", "\n", "", "assert", "len", "(", "train_dataset", ")", "==", "src_probs", ".", "size", "(", "0", ")", "\n", "train_dataset", ".", "tensors", "+=", "(", "src_probs", ",", ")", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "no_grad", "=", "[", "\"embeddings\"", "]", "+", "[", "\"layer.\"", "+", "str", "(", "layer_i", ")", "+", "\".\"", "for", "layer_i", "in", "range", "(", "12", ")", "if", "\n", "layer_i", "<", "args", ".", "freeze_bottom_layer", "]", "\n", "logger", ".", "info", "(", "\"  The frozen parameters are:\"", ")", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "p", ".", "requires_grad", "=", "False", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_grad", ")", "else", "True", "\n", "if", "not", "p", ".", "requires_grad", ":", "\n", "            ", "logger", ".", "info", "(", "\"    %s\"", ",", "n", ")", "\n", "", "", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "# scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_ratio", ")", ",", "t_total", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "args", ".", "gpu_ids", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  GPU IDs for training: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "args", ".", "gpu_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "tr_loss_KD", ",", "logging_loss_KD", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "epoch_i", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "# batch = tuple(t.to(args.device) for t in batch)", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", ",", "\n", "# XLM and RoBERTa don\"t use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "\"src_probs\"", ":", "batch", "[", "4", "]", "}", "# activate the KD loss", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)", "\n", "loss_KD", ",", "loss", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "loss_KD", "=", "loss_KD", ".", "mean", "(", ")", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "loss_KD", "=", "loss_KD", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "# with amp.scale_loss(loss, optimizer) as scaled_loss:", "\n", "#     scaled_loss.backward()", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss_KD", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "# loss.backward()", "\n", "                ", "loss_KD", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_loss_KD", "+=", "loss_KD", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "logger", ".", "info", "(", "\"===== evaluate_during_training =====\"", ")", "\n", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"Epoch: {}\\t global_step: {}\\t eval_{}: {}\"", ".", "format", "(", "epoch_i", ",", "\n", "global_step", ",", "key", ",", "value", ")", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss_KD\"", ",", "(", "tr_loss_KD", "-", "logging_loss_KD", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\n", "\"Epoch: {}\\t global_step: {}\\t learning rate: {:.8}\\t loss: {:.4f}\\t loss_KD: {:.4f}\"", ".", "format", "(", "\n", "epoch_i", ",", "global_step", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "\n", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "\n", "(", "tr_loss_KD", "-", "logging_loss_KD", ")", "/", "args", ".", "logging_steps", ")", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "logging_loss_KD", "=", "tr_loss_KD", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\n", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss_KD", "/", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main_single.evaluate": [[357, 421], ["main_single.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "numpy.argmax", "range", "logger.info", "sorted", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "tuple", "range", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "results.keys", "logger.info", "torch.no_grad", "model", "tmp_eval_loss.item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "enumerate", "range", "range", "str", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "out_label_list[].append", "preds_list[].append", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "mode", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation %s *****\"", ",", "prefix", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", ",", "\n", "# XLM and RoBERTa don\"t use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "2", ")", "\n", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "\n", "out_label_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "preds_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "out_label_ids", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "out_label_ids", "[", "i", ",", "j", "]", "!=", "pad_token_label_id", ":", "\n", "                ", "out_label_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "out_label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "preds_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "preds", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "\n", "", "", "", "results", "=", "{", "\n", "\"loss\"", ":", "eval_loss", ",", "\n", "\"precision\"", ":", "precision_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"recall\"", ":", "recall_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"f1\"", ":", "f1_score", "(", "out_label_list", ",", "preds_list", ")", "\n", "}", "\n", "\n", "logger", ".", "info", "(", "\"***** Eval results %s *****\"", ",", "prefix", ")", "\n", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "results", ",", "preds_list", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main_single.load_and_cache_examples": [[423, 474], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_ner.read_examples_from_file", "utils_ner.convert_examples_to_features", "torch.distributed.barrier", "logger.info", "random.sample", "logger.info", "list().pop", "str", "logger.info", "torch.save", "int", "bool", "bool", "bool", "len", "len", "list", "tokenizer.convert_tokens_to_ids", "len", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.read_examples_from_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.LogUniformSampler.sample", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "# for distributed training", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Load data features from cache or dataset file", "\n", "", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"cached_{}_{}_{}\"", ".", "format", "(", "mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "\n", "args", ".", "model_name_or_path", ".", "split", "(", "\n", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "examples", "=", "read_examples_from_file", "(", "args", ".", "data_dir", ",", "mode", ")", "\n", "features", "=", "convert_examples_to_features", "(", "examples", ",", "labels", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "sep_token_extra", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"roberta\"", "]", ")", ",", "\n", "# roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "if", "args", ".", "unlabeled_data_ratio", "<", "1.0", ":", "\n", "        ", "logger", ".", "info", "(", "\"==> len of features: {}. data ratio: {}\"", ".", "format", "(", "len", "(", "features", ")", ",", "args", ".", "unlabeled_data_ratio", ")", ")", "\n", "features", "=", "random", ".", "sample", "(", "features", ",", "int", "(", "len", "(", "features", ")", "*", "args", ".", "unlabeled_data_ratio", ")", ")", "\n", "logger", ".", "info", "(", "\"    len of features: {}\"", ".", "format", "(", "len", "(", "features", ")", ")", ")", "\n", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main_single.get_src_probs": [[476, 519], ["os.path.join", "model_class.from_pretrained", "model_class.from_pretrained.to", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model_class.from_pretrained.eval", "torch.nn.functional.softmax", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.basename", "len", "tuple", "torch.no_grad", "model_class.from_pretrained.", "logits.detach", "torch.cat", "t.to", "logits.detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "def", "get_src_probs", "(", "args", ",", "dataset", ",", "model_class", ",", "src_lang", ")", ":", "\n", "    ", "\"\"\" without softmax.\n        preds: dataset_len x seq_len x label_len\n    \"\"\"", "\n", "# load src model", "\n", "src_model_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "src_model_dir", ",", "\"{}{}\"", ".", "format", "(", "args", ".", "src_model_dir_prefix", ",", "src_lang", ")", ")", "\n", "src_model", "=", "model_class", ".", "from_pretrained", "(", "src_model_path", ")", "\n", "src_model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# compute logits for the dataset using the model!", "\n", "logger", ".", "info", "(", "\"***** Compute logits for [%s] dataset using the model [%s] *****\"", ",", "os", ".", "path", ".", "basename", "(", "args", ".", "data_dir", ")", ",", "src_model_path", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "# eval_loss = 0.0", "\n", "# nb_eval_steps = 0", "\n", "preds", "=", "None", "\n", "src_model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", ",", "\n", "# XLM and RoBERTa don\"t use segment_ids", "\n", "\"labels\"", ":", "None", "}", "#batch[3]}", "\n", "outputs", "=", "src_model", "(", "**", "inputs", ")", "\n", "logits", "=", "outputs", "[", "0", "]", "\n", "# tmp_eval_loss, logits = outputs[:2]", "\n", "# eval_loss += tmp_eval_loss.item()", "\n", "\n", "# nb_eval_steps += 1", "\n", "", "preds", "=", "logits", ".", "detach", "(", ")", "if", "preds", "is", "None", "else", "torch", ".", "cat", "(", "(", "preds", ",", "logits", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", "# dataset_len x max_seq_len x label_len", "\n", "\n", "# eval_loss = eval_loss / nb_eval_steps", "\n", "", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "preds", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "preds", "#, eval_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.main_single.main": [[521, 798], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "logging.Formatter", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logger.addHandler", "logger.addHandler", "logger.warning", "main_single.set_seed", "utils_ner.get_labels", "len", "parser.parse_args.model_type.lower", "logger.info", "os.path.exists", "os.listdir", "os.path.exists", "ValueError", "os.path.exists", "os.listdir", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "len", "str", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "os.path.exists", "os.makedirs", "time.strftime", "os.path.basename", "os.path.join", "bool", "torch.nn.CrossEntropyLoss", "torch.distributed.barrier", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "main_single.load_and_cache_examples", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "logger.info", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "main_single.evaluate", "os.path.join", "os.path.join", "os.path.join", "os.path.basename", "ValueError", "os.makedirs", "time.localtime", "torch.distributed.barrier", "logger.info", "logger.info", "main_single.train", "logger.info", "os.makedirs", "hasattr", "os.path.join", "open", "sorted", "open", "torch.distributed.get_rank", "os.path.exists", "bool", "len", "torch.argmax", "main_single.train", "logger.info", "main_single.train_KD", "logger.info", "torch.distributed.get_rank", "os.path.exists", "time.strftime", "os.path.basename", "result.keys", "writer.write", "time.strftime", "os.path.basename", "open", "MODEL_CLASSES.keys", "time.localtime", "time.localtime", "os.path.join", "os.path.basename", "main_single.get_src_probs", "main_single.get_src_probs", "str", "line.startswith", "writer.write", "writer.write", "logger.warning", "predictions[].pop", "line.split", "[].replace", "line.split", "line.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_labels", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train_KD", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "\"./data/ner/conll/debug\"", ",", "type", "=", "str", ",", "# required=True,", "\n", "help", "=", "\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "\"conll-model/test\"", ",", "type", "=", "str", ",", "# required=True,", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--src_model_dir\"", ",", "default", "=", "\"conll-model-22/\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"path to load teacher models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--src_model_dir_prefix\"", ",", "default", "=", "\"mono-src-\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"prefix of the teacher model dir (to indicate the model type)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--src_langs\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "default", "=", "\"en\"", ",", "\n", "help", "=", "\"source languages used for multi-teacher models\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--unlabeled_data_ratio\"", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"Ratio of the training data to use.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "'bert'", ",", "type", "=", "str", ",", "# required=True,", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "'bert-base-multilingual-cased'", ",", "type", "=", "str", ",", "# required=True,", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--labels\"", ",", "default", "=", "\"./data/ner/conll/labels.txt\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_KD\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to train with knowledge distillation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--hard_label\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gradient_accumulation_steps\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--freeze_bottom_layer\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Freeze the bottom n layers of the model during fine-tuning.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_ratio\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Linear warmup over warmup_ratio.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "20000", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "667", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu_ids\"", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ",", "default", "=", "0", ",", "\n", "help", "=", "\"ids of the gpus to use\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--fp16\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp16_opt_level\"", ",", "type", "=", "str", ",", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Check output_dir", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"pytorch_model.bin\"", ")", ")", "and", "os", ".", "path", ".", "basename", "(", "args", ".", "output_dir", ")", "!=", "\"test\"", ":", "\n", "        ", "raise", "ValueError", "(", "\"Train: Output directory already exists and is not empty.\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_predict", ":", "\n", "        ", "is_done", "=", "False", "\n", "for", "name", "in", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", ":", "# result file: \"test_results-TIME-LANGUAGE\"", "\n", "            ", "if", "\"test_results\"", "in", "name", "and", "(", "os", ".", "path", ".", "basename", "(", "args", ".", "data_dir", ")", "+", "\".txt\"", ")", "in", "name", ":", "\n", "                ", "is_done", "=", "True", "\n", "break", "\n", "", "", "if", "is_done", ":", "\n", "            ", "raise", "ValueError", "(", "\"Predict: Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "args", ".", "output_dir", ")", ")", "\n", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "args", ".", "n_gpu", "=", "len", "(", "args", ".", "gpu_ids", ")", "# torch.cuda.device_count()", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "args", ".", "gpu_ids", "[", "0", "]", ")", "\n", "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3,4,5,6\"", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "# device = torch.device(\"cpu\") if (args.n_gpu == 0 or args.no_cuda) else torch.device(", "\n", "#     \"cuda:{}\".format(args.gpu_ids[0]))", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "", "args", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"logs\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ")", "\n", "", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s %(levelname)s: - %(message)s'", ",", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "log_name", "=", "\"log-{}\"", ".", "format", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ",", "time", ".", "localtime", "(", ")", ")", ")", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "log_name", "+=", "\"-train\"", "\n", "", "if", "args", ".", "do_predict", ":", "\n", "        ", "log_name", "+=", "\"-predict\"", "\n", "", "log_name", "+=", "\"-{}\"", ".", "format", "(", "\"_\"", ".", "join", "(", "args", ".", "src_langs", ")", ")", "\n", "log_name", "+=", "\"-{}.txt\"", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "args", ".", "data_dir", ")", ")", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "log_name", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare CONLL-2003 task", "\n", "labels", "=", "get_labels", "(", "args", ".", "labels", ")", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "# Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later", "\n", "pad_token_label_id", "=", "CrossEntropyLoss", "(", ")", ".", "ignore_index", "# -100 here", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "# load target model", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "num_labels", "=", "num_labels", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# prepare target training plain text", "\n", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"train\"", ")", "\n", "\n", "if", "args", ".", "do_KD", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** scheme: training with KD **********\"", ")", "\n", "\n", "# compute probs from source models", "\n", "w", "=", "1.0", "/", "len", "(", "args", ".", "src_langs", ")", "\n", "weight_probs", "=", "{", "l", ":", "w", "for", "l", "in", "args", ".", "src_langs", "}", "\n", "\n", "src_probs", "=", "None", "\n", "for", "lang", "in", "args", ".", "src_langs", ":", "\n", "                ", "if", "src_probs", "is", "None", ":", "\n", "                    ", "src_probs", "=", "weight_probs", "[", "lang", "]", "*", "get_src_probs", "(", "args", ",", "train_dataset", ",", "model_class", ",", "src_lang", "=", "lang", ")", "\n", "", "else", ":", "\n", "                    ", "src_probs", "+=", "weight_probs", "[", "lang", "]", "*", "get_src_probs", "(", "args", ",", "train_dataset", ",", "model_class", ",", "src_lang", "=", "lang", ")", "\n", "\n", "# Train!", "\n", "", "", "if", "args", ".", "hard_label", ":", "\n", "                ", "hard_labels", "=", "torch", ".", "argmax", "(", "src_probs", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", "\n", "train_dataset", ".", "tensors", "+=", "(", "hard_labels", ",", ")", "\n", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "model", ",", "train_dataset", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "", "else", ":", "\n", "                ", "global_step", ",", "tr_loss_KD", ",", "tr_loss", "=", "train_KD", "(", "args", ",", "model", ",", "train_dataset", ",", "src_probs", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average KD loss = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss_KD", ",", "tr_loss", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** scheme: training without KD **********\"", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "model", ",", "train_dataset", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\n", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "\n", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "logger", ".", "info", "(", "\"********** scheme: prediction **********\"", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "predictions", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"test\"", ")", "\n", "# Save results", "\n", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"test_results-{}-{}.txt\"", ".", "format", "(", "\n", "time", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ",", "time", ".", "localtime", "(", ")", ")", ",", "\n", "os", ".", "path", ".", "basename", "(", "args", ".", "data_dir", ")", ")", ")", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "# Save predictions", "\n", "", "", "output_test_predictions_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"test_predictions-{}-{}.txt\"", ".", "format", "(", "\n", "time", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ",", "time", ".", "localtime", "(", ")", ")", ",", "\n", "os", ".", "path", ".", "basename", "(", "args", ".", "data_dir", ")", ")", ")", "\n", "with", "open", "(", "output_test_predictions_file", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"test.txt\"", ")", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "example_id", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                    ", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", "or", "line", "==", "\"\"", "or", "line", "==", "\"\\n\"", ":", "\n", "                        ", "writer", ".", "write", "(", "line", ")", "\n", "if", "not", "predictions", "[", "example_id", "]", ":", "\n", "                            ", "example_id", "+=", "1", "\n", "", "", "elif", "predictions", "[", "example_id", "]", ":", "\n", "                        ", "output_line", "=", "line", ".", "split", "(", ")", "[", "0", "]", "+", "\" \"", "+", "line", ".", "split", "(", ")", "[", "-", "1", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "+", "\" \"", "+", "predictions", "[", "example_id", "]", ".", "pop", "(", "0", ")", "+", "\"\\n\"", "\n", "writer", ".", "write", "(", "output_line", ")", "\n", "", "else", ":", "\n", "                        ", "logger", ".", "warning", "(", "\"Maximum sequence length exceeded: No prediction for '%s'.\"", ",", "line", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.set_seed": [[42, 49], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.train": [[51, 149], ["tensorboardX.SummaryWriter", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "transformers.AdamW", "transformers.WarmupLinearSchedule", "domain_learner.set_seed", "torch.nn.DataParallel.train", "range", "tensorboardX.SummaryWriter.close", "max", "len", "torch.nn.DataParallel.parameters", "torch.nn.DataParallel", "enumerate", "len", "int", "torch.nn.DataParallel.zero_grad", "torch.nn.DataParallel.", "loss.mean.backward", "loss.mean.item", "loss_f.item", "loss_R.item", "torch.nn.utils.clip_grad_norm_", "transformers.WarmupLinearSchedule.step", "transformers.AdamW.step", "len", "str", "loss.mean.mean", "torch.nn.DataParallel.parameters", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "logger.info", "os.path.join", "torch.save", "logger.info", "os.path.exists", "os.makedirs", "torch.nn.DataParallel.state_dict", "os.path.join", "transformers.WarmupLinearSchedule.get_lr", "transformers.WarmupLinearSchedule.get_lr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["", "def", "train", "(", "args", ",", "domain_model", ",", "pt_dataset", ")", ":", "\n", "    ", "\"\"\" Train the model using multi-task training and knowledge distillation \"\"\"", "\n", "tb_writer", "=", "SummaryWriter", "(", "log_dir", "=", "args", ".", "log_dir", ")", "\n", "\n", "# parepare dataloader", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "sampler", "=", "RandomSampler", "(", "pt_dataset", ")", "\n", "dataloader", "=", "DataLoader", "(", "pt_dataset", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "# compute total update steps", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "len", "(", "dataloader", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "dataloader", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num of examples = %d\"", ",", "len", "(", "pt_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  GPU IDs for training: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "args", ".", "gpu_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"  Total task optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "optimizer", "=", "AdamW", "(", "domain_model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ",", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "# scheduler_base = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_ratio", ")", ",", "t_total", "=", "t_total", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "domain_model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "domain_model", ",", "device_ids", "=", "args", ".", "gpu_ids", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "loss_accum", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "loss_f_accum", ",", "logging_loss_f", "=", "0.0", ",", "0.0", "\n", "loss_R_accum", ",", "logging_loss_R", "=", "0.0", ",", "0.0", "\n", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "\n", "domain_model", ".", "train", "(", ")", "\n", "for", "epoch_i", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "for", "step", ",", "(", "features", ",", "labels", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "domain_model", ".", "zero_grad", "(", ")", "\n", "\n", "outputs", "=", "domain_model", "(", "features", ",", "labels", ",", "device", "=", "args", ".", "device", ")", "# loss, logits", "\n", "loss", ",", "loss_f", ",", "loss_R", "=", "outputs", "[", ":", "3", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "loss_accum", "+=", "loss", ".", "item", "(", ")", "\n", "loss_f_accum", "+=", "loss_f", ".", "item", "(", ")", "\n", "loss_R_accum", "+=", "loss_R", ".", "item", "(", ")", "\n", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "domain_model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                ", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "loss_accum", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss_f\"", ",", "(", "loss_f_accum", "-", "logging_loss_f", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss_R\"", ",", "(", "loss_R_accum", "-", "logging_loss_R", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"Epoch: {}\\t global_step: {}\\t lr: {:.8}\\tloss: {:.8f}\"", ".", "format", "(", "epoch_i", ",", "\n", "global_step", ",", "\n", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "(", "\n", "loss_accum", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"    loss_f: {:.8f}\\tloss_R: {:.8f}\"", ".", "format", "(", "(", "loss_f_accum", "-", "logging_loss_f", ")", "/", "args", ".", "logging_steps", ",", "\n", "(", "loss_R_accum", "-", "logging_loss_R", ")", "/", "args", ".", "logging_steps", ")", ")", "\n", "logging_loss", "=", "loss_accum", "\n", "logging_loss_f", "=", "loss_f_accum", "\n", "logging_loss_R", "=", "loss_R_accum", "\n", "\n", "", "if", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "torch", ".", "save", "(", "domain_model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"domain_model.bin\"", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "tb_writer", ".", "close", "(", ")", "\n", "\n", "return", "global_step", ",", "loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.evaluate": [[151, 196], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.eval", "torch.reciprocal", "logger.info", "torch.nn.functional.softmax", "torch.mean", "logger.info", "logger.info", "logger.info", "max", "len", "torch.var", "torch.no_grad", "model", "logits_batch.detach", "torch.cat", "torch.std", "str", "logits_batch.detach", "str", "round", "v.item"], "function", ["None"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "f_dataset", ",", "src_idxs", ")", ":", "\n", "# parepare dataloader", "\n", "    ", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "f_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "f_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Evaluate!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation on %s *****\"", ",", "args", ".", "tgt_lang", ")", "\n", "logger", ".", "info", "(", "\"  Num of examples = %d\"", ",", "len", "(", "f_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_eval_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  GPU IDs for training: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "args", ".", "gpu_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "logits", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "batch", "[", "0", "]", ",", "device", "=", "args", ".", "device", ")", "# loss, logits", "\n", "logits_batch", "=", "outputs", "[", "0", "]", "# batch_size x n_langs", "\n", "\n", "", "logits", "=", "logits_batch", ".", "detach", "(", ")", "if", "logits", "is", "None", "else", "torch", ".", "cat", "(", "(", "logits", ",", "logits_batch", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "logits", "=", "logits", "[", ":", ",", "src_idxs", "]", "\n", "\n", "if", "args", ".", "tau_metric", "==", "\"var\"", ":", "\n", "        ", "tau", "=", "torch", ".", "var", "(", "logits", ")", "\n", "", "elif", "args", ".", "tau_metric", "==", "\"std\"", ":", "\n", "        ", "tau", "=", "torch", ".", "std", "(", "logits", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", "\n", "", "tau", "=", "torch", ".", "reciprocal", "(", "tau", ")", "\n", "logger", ".", "info", "(", "\"==> tau: {}\"", ".", "format", "(", "tau", ")", ")", "\n", "\n", "logits", "*=", "tau", "\n", "\n", "sims", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "# dataset_len x n_src_langs", "\n", "\n", "dm_sims", "=", "torch", ".", "mean", "(", "sims", ",", "dim", "=", "0", ")", "# n_src_langs", "\n", "\n", "logger", ".", "info", "(", "\"  Domain similarities:\"", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"\\t\"", ".", "join", "(", "args", ".", "src_langs", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"\\t\"", ".", "join", "(", "[", "str", "(", "round", "(", "v", ".", "item", "(", ")", ",", "4", ")", ")", "for", "v", "in", "dm_sims", "]", ")", ")", "\n", "\n", "return", "sims", ",", "dm_sims", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.load_and_cache_examples": [[198, 244], ["os.path.join", "os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_ner.read_examples_from_file", "utils_ner.convert_examples_to_features", "logger.info", "torch.save", "torch.tensor", "torch.utils.data.TensorDataset", "torch.tensor", "torch.utils.data.TensorDataset", "list().pop", "str", "args.src_langs.index", "len", "len", "list", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.read_examples_from_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "lang", ",", "mode", ",", "plain_text", "=", "False", ")", ":", "\n", "    ", "data_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "lang", ")", "\n", "# Load data features from cache or dataset file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"cached_{}_{}_{}\"", ".", "format", "(", "mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "\n", "args", ".", "model_name_or_path", ".", "split", "(", "\n", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s. Plain text: %s\"", ",", "cached_features_file", ",", "plain_text", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s. Plain text: %s\"", ",", "data_path", ",", "plain_text", ")", "\n", "examples", "=", "read_examples_from_file", "(", "data_path", ",", "mode", ")", "\n", "features", "=", "convert_examples_to_features", "(", "examples", ",", "labels", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "cls_token_segment_id", "=", "0", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "sep_token_extra", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "if", "not", "plain_text", ":", "\n", "        ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "return", "dataset", "\n", "", "else", ":", "\n", "# assert lang in args.src_langs and lang != args.tgt_lang", "\n", "        ", "language_id", "=", "args", ".", "src_langs", ".", "index", "(", "lang", ")", "if", "lang", "in", "args", ".", "src_langs", "else", "len", "(", "args", ".", "src_langs", ")", "\n", "all_language_id", "=", "torch", ".", "tensor", "(", "[", "language_id", "]", "*", "len", "(", "features", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_language_id", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.get_init_domain_embed": [[246, 278], ["transformers.BertConfig.from_pretrained", "modeling.BaseModel.from_pretrained", "BaseModel.from_pretrained.to", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "BaseModel.from_pretrained.eval", "max", "len", "tuple", "bool", "torch.no_grad", "BaseModel.from_pretrained.", "pooled_outputs.detach", "torch.cat", "t.to", "pooled_outputs.detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_init_domain_embed", "(", "args", ",", "dataset", ",", "lang", ")", ":", "\n", "    ", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "base_model", "=", "BaseModel", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ")", "\n", "base_model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# compute logits for the dataset using the model!", "\n", "logger", ".", "info", "(", "\"***** Compute logits for [%s] dataset using the base_model *****\"", ",", "lang", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "st_embeds", "=", "None", "\n", "base_model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "}", "\n", "outputs", "=", "base_model", "(", "**", "inputs", ")", "\n", "pooled_outputs", "=", "outputs", "[", "1", "]", "\n", "\n", "", "st_embeds", "=", "pooled_outputs", ".", "detach", "(", ")", "if", "st_embeds", "is", "None", "else", "torch", ".", "cat", "(", "(", "st_embeds", ",", "pooled_outputs", ".", "detach", "(", ")", ")", ",", "\n", "dim", "=", "0", ")", "# dataset_len x hidden_size", "\n", "\n", "", "return", "st_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.setup": [[280, 414], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "os.path.join", "logging.Formatter", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logger.addHandler", "logger.addHandler", "logger.warning", "domain_learner.set_seed", "logger.info", "parser.parse_args.src_langs.remove", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.device", "os.makedirs", "os.path.exists", "os.makedirs", "time.strftime", "os.path.join", "os.path.basename", "os.path.exists", "time.localtime"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "setup", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "\"./data/ner/conll\"", ",", "type", "=", "str", ",", "# required=True,", "\n", "help", "=", "\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "\"domain_model/test\"", ",", "type", "=", "str", ",", "# required=True,", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--tgt_lang\"", ",", "default", "=", "\"debug\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"target language to train the student model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--src_langs\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"source languages used for multi-teacher models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--low_rank_size\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "\"size use for low rank approximation of the bilinear operation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma_R\"", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "\"size use for low rank approximation of the bilinear operation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tau_metric\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"metric to implement normalization: var, std\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "'bert-base-multilingual-cased'", ",", "type", "=", "str", ",", "# required=True,", "\n", "help", "=", "\"Path to pre-trained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--labels\"", ",", "default", "=", "\"./data/ner/conll/labels.txt \"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run training on the training set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "1e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_ratio\"", ",", "default", "=", "0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Linear warmup over warmup_ratio.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "# required=True,", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu_ids\"", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ",", "# required=True,", "\n", "help", "=", "\"ids of the gpus to use\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--balance_classes\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"To handle the class imbalance problem or not\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--domain_orthogonal\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"To constrain that the domain embeddings are orthogonal rather than the features are orthogonal.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# args.src_langs = [\"en\", \"es\", \"nl\"]", "\n", "# args.tgt_lang = \"de\"", "\n", "if", "(", "args", ".", "tgt_lang", "in", "args", ".", "src_langs", ")", ":", "\n", "        ", "args", ".", "src_langs", ".", "remove", "(", "args", ".", "tgt_lang", ")", "\n", "\n", "# Check output_dir", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", "and", "os", ".", "path", ".", "basename", "(", "args", ".", "output_dir", ")", "!=", "\"test\"", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", ")", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "args", ".", "n_gpu", "=", "len", "(", "args", ".", "gpu_ids", ")", "# torch.cuda.device_count()", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "if", "args", ".", "n_gpu", "==", "0", "else", "torch", ".", "device", "(", "\"cuda:{}\"", ".", "format", "(", "args", ".", "gpu_ids", "[", "0", "]", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "if", "args", ".", "do_train", "and", "(", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "args", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"logs\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ")", "\n", "", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s %(levelname)s: - %(message)s'", ",", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "log_name", "=", "\"log-{}\"", ".", "format", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ",", "time", ".", "localtime", "(", ")", ")", ")", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "log_name", "+=", "\"-train\"", "\n", "", "if", "args", ".", "do_predict", ":", "\n", "        ", "log_name", "+=", "\"-predict\"", "\n", "", "log_name", "+=", "\"-{}\"", ".", "format", "(", "\"_\"", ".", "join", "(", "args", ".", "src_langs", ")", ")", "\n", "log_name", "+=", "\"-{}.txt\"", ".", "format", "(", "args", ".", "tgt_lang", ")", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "log_name", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "logger", ".", "warning", "(", "\"device: %s, n_gpu: %s\"", ",", "device", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.main": [[416, 495], ["utils_ner.get_labels", "len", "transformers.BertTokenizer.from_pretrained", "transformers.BertConfig.from_pretrained", "torch.nn.CrossEntropyLoss", "logger.info", "enumerate", "torch.utils.data.ConcatDataset", "torch.stack", "modeling.DomainLearner", "modeling.DomainLearner.to", "domain_learner.train", "logger.info", "logger.info", "BertTokenizer.from_pretrained.save_pretrained", "torch.save", "torch.save", "logger.info", "os.path.join", "torch.load", "domain_learner.load_and_cache_examples", "domain_learner.get_init_domain_embed", "torch.utils.data.TensorDataset", "modeling.DomainLearner", "modeling.DomainLearner.load_state_dict", "modeling.DomainLearner.to", "domain_learner.evaluate", "torch.save", "domain_learner.load_and_cache_examples", "domain_learner.get_init_domain_embed", "torch.stack.append", "torch.tensor().to", "torch.utils.data.ConcatDataset.append", "cnt_datasets.append", "torch.from_numpy", "class_weight.to.to", "os.path.exists", "os.makedirs", "modeling.DomainLearner.state_dict", "os.path.join", "os.path.join", "os.path.join", "langs.index", "len", "torch.load", "os.path.join", "torch.mean", "torch.utils.data.TensorDataset", "get_init_domain_embed.size", "torch.sum", "os.path.join", "torch.tensor", "numpy.array", "get_init_domain_embed.size"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_labels", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.get_init_domain_embed", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.domain_learner.get_init_domain_embed"], ["", "def", "main", "(", "args", ")", ":", "\n", "# Prepare CONLL-2003 task", "\n", "    ", "labels", "=", "get_labels", "(", "args", ".", "labels", ")", "\n", "\n", "# langs = [l for l in args.src_langs] + [args.tgt_lang]", "\n", "langs", "=", "args", ".", "src_langs", "\n", "num_langs", "=", "len", "(", "langs", ")", "\n", "\n", "pad_token_label_id", "=", "CrossEntropyLoss", "(", ")", ".", "ignore_index", "# -100 here", "\n", "\n", "# load target model (pretrained BERT) and tokenizer", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "config", "=", "BertConfig", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"********** scheme: train domain learner **********\"", ")", "\n", "# prepare plain text datasets & compute sentence embeddings( the order of the args.src_langs matters!!! )", "\n", "f_datasets", "=", "[", "]", "\n", "domain_embeds", "=", "[", "]", "\n", "cnt_datasets", "=", "[", "]", "\n", "for", "i", ",", "lang", "in", "enumerate", "(", "langs", ")", ":", "\n", "            ", "pt_dts", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "lang", ",", "mode", "=", "\"train\"", ",", "\n", "plain_text", "=", "True", ")", "\n", "st_ebd", "=", "get_init_domain_embed", "(", "args", ",", "pt_dts", ",", "lang", ")", "# dataset_size x hidden_size", "\n", "domain_embeds", ".", "append", "(", "torch", ".", "mean", "(", "st_ebd", ",", "dim", "=", "0", ")", ")", "\n", "lang_id", "=", "torch", ".", "tensor", "(", "[", "i", "]", "*", "st_ebd", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "args", ".", "device", ")", "# dataset_size", "\n", "f_datasets", ".", "append", "(", "TensorDataset", "(", "st_ebd", ",", "lang_id", ")", ")", "\n", "cnt_datasets", ".", "append", "(", "st_ebd", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "f_datasets", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "f_datasets", ")", "\n", "domain_embeds", "=", "torch", ".", "stack", "(", "domain_embeds", ")", "# (n_langs + 1) x hidden_size, device", "\n", "\n", "class_weight", "=", "None", "\n", "if", "args", ".", "balance_classes", ":", "\n", "            ", "class_weight", "=", "torch", ".", "from_numpy", "(", "1.0", "/", "np", ".", "array", "(", "cnt_datasets", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "class_weight", "=", "class_weight", "/", "torch", ".", "sum", "(", "class_weight", ")", "\n", "class_weight", ".", "requires_grad", "=", "False", "\n", "class_weight", "=", "class_weight", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "", "domain_model", "=", "DomainLearner", "(", "num_langs", ",", "config", ".", "hidden_size", ",", "args", ".", "low_rank_size", ",", "weights_init", "=", "domain_embeds", ",", "\n", "gamma", "=", "args", ".", "gamma_R", ",", "class_weight", "=", "class_weight", ",", "domain_orthogonal", "=", "args", ".", "domain_orthogonal", ")", "\n", "domain_model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Train!", "\n", "global_step", ",", "loss", "=", "train", "(", "args", ",", "domain_model", ",", "f_datasets", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, loss = %s\"", ",", "global_step", ",", "loss", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "torch", ".", "save", "(", "domain_model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"domain_model.bin\"", ")", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "", "if", "args", ".", "do_predict", ":", "\n", "# save domain similarity", "\n", "        ", "logger", ".", "info", "(", "\"********** scheme: prediction - compute domain similarity **********\"", ")", "\n", "sims_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}{}{}-rank_{}-gamma_{}\"", ".", "format", "(", "args", ".", "tgt_lang", ",", "''", "if", "not", "args", ".", "balance_classes", "else", "'-balanced'", ",", "\n", "''", "if", "not", "args", ".", "domain_orthogonal", "else", "'-domain_orth'", ",", "args", ".", "low_rank_size", ",", "args", ".", "gamma_R", ")", ")", "\n", "\n", "dm_namespace", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "sims_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "# langs = [l for l in dm_namespace.src_langs] + [dm_namespace.tgt_lang]", "\n", "langs", "=", "dm_namespace", ".", "src_langs", "\n", "src_idxs", "=", "[", "langs", ".", "index", "(", "l", ")", "for", "l", "in", "args", ".", "src_langs", "]", "\n", "\n", "pt_dts", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "args", ".", "tgt_lang", ",", "mode", "=", "\"train\"", ",", "\n", "plain_text", "=", "True", ")", "\n", "st_ebd", "=", "get_init_domain_embed", "(", "args", ",", "pt_dts", ",", "args", ".", "tgt_lang", ")", "# dataset_size x hidden_size", "\n", "dataset_st_ebd", "=", "TensorDataset", "(", "st_ebd", ")", "\n", "\n", "domain_model", "=", "DomainLearner", "(", "len", "(", "langs", ")", ",", "config", ".", "hidden_size", ",", "args", ".", "low_rank_size", ")", "\n", "domain_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "sims_dir", ",", "\"domain_model.bin\"", ")", ",", "map_location", "=", "args", ".", "device", ")", ")", "\n", "domain_model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "st_sims", ",", "dm_sims", "=", "evaluate", "(", "args", ",", "domain_model", ",", "dataset_st_ebd", ",", "src_idxs", ")", "\n", "\n", "torch", ".", "save", "(", "st_sims", ",", "os", ".", "path", ".", "join", "(", "sims_dir", ",", "\"sims-{}-{}-{}-{}.bin\"", ".", "format", "(", "args", ".", "tau_metric", ",", "\"_\"", ".", "join", "(", "args", ".", "src_langs", ")", ",", "args", ".", "tgt_lang", ",", "\"train\"", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.__init__": [[73, 107], ["tokenization_utils.PreTrainedTokenizer.__init__", "collections.Counter", "torch.load", "torch.load.items", "tokenization_transfo_xl.TransfoXLTokenizer.build_vocab"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab"], ["def", "__init__", "(", "self", ",", "special", "=", "None", ",", "min_freq", "=", "0", ",", "max_size", "=", "None", ",", "lower_case", "=", "False", ",", "\n", "delimiter", "=", "None", ",", "vocab_file", "=", "None", ",", "pretrained_vocab_file", "=", "None", ",", "\n", "never_split", "=", "None", ",", "unk_token", "=", "\"<unk>\"", ",", "eos_token", "=", "\"<eos>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<formula>\"", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TransfoXLTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "eos_token", "=", "eos_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "if", "never_split", "is", "None", ":", "\n", "            ", "never_split", "=", "self", ".", "all_special_tokens", "\n", "", "if", "special", "is", "None", ":", "\n", "            ", "special", "=", "[", "]", "\n", "", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "special", "=", "special", "\n", "self", ".", "min_freq", "=", "min_freq", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "lower_case", "=", "lower_case", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n", "if", "pretrained_vocab_file", "is", "not", "None", ":", "\n", "# Hack because, honestly this tokenizer was not made to be used", "\n", "# in a library like ours, at all.", "\n", "            ", "vocab_dict", "=", "torch", ".", "load", "(", "pretrained_vocab_file", ")", "\n", "for", "key", ",", "value", "in", "vocab_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "self", ".", "__dict__", ":", "\n", "                    ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "\n", "", "", "", "if", "vocab_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "build_vocab", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file": [[108, 122], ["os.path.exists", "logger.info", "io.open", "enumerate", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "sents.append", "logger.info"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "", "def", "count_file", "(", "self", ",", "path", ",", "verbose", "=", "False", ",", "add_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "logger", ".", "info", "(", "'counting file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "\n", "sents", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ")", "\n", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "sents", ".", "append", "(", "symbols", ")", "\n", "\n", "", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_sents": [[123, 132], ["enumerate", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "logger.info", "len"], "methods", ["None"], ["", "def", "count_sents", "(", "self", ",", "sents", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            sents : a list of sentences, each a list of tokenized symbols\n        \"\"\"", "\n", "if", "verbose", ":", "logger", ".", "info", "(", "'counting {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file": [[133, 147], ["collections.OrderedDict", "io.open", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "ValueError", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "", "def", "_build_from_file", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "symb", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "self", ".", "add_symbol", "(", "symb", ")", "\n", "", "", "if", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'No <unkown> token in vocabulary'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.save_vocabulary": [[148, 154], ["os.path.isdir", "torch.save", "os.path.join"], "methods", ["None"], ["", "", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "'pretrained_vocab_file'", "]", ")", "\n", "", "torch", ".", "save", "(", "self", ".", "__dict__", ",", "vocab_file", ")", "\n", "return", "(", "vocab_file", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab": [[155, 175], ["logger.info", "tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "logger.info", "logger.info", "collections.OrderedDict", "tokenization_transfo_xl.TransfoXLTokenizer.counter.most_common", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.add_special", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_special", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "def", "build_vocab", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "'building vocab from {}'", ".", "format", "(", "self", ".", "vocab_file", ")", ")", "\n", "self", ".", "_build_from_file", "(", "self", ".", "vocab_file", ")", "\n", "logger", ".", "info", "(", "'final vocab size {}'", ".", "format", "(", "len", "(", "self", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'building vocab with min_freq={}, max_size={}'", ".", "format", "(", "\n", "self", ".", "min_freq", ",", "self", ".", "max_size", ")", ")", "\n", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "sym", "in", "self", ".", "special", ":", "\n", "                ", "self", ".", "add_special", "(", "sym", ")", "\n", "\n", "", "for", "sym", ",", "cnt", "in", "self", ".", "counter", ".", "most_common", "(", "self", ".", "max_size", ")", ":", "\n", "                ", "if", "cnt", "<", "self", ".", "min_freq", ":", "break", "\n", "self", ".", "add_symbol", "(", "sym", ")", "\n", "\n", "", "logger", ".", "info", "(", "'final vocab size {} from {} unique tokens'", ".", "format", "(", "\n", "len", "(", "self", ")", ",", "len", "(", "self", ".", "counter", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file": [[176, 193], ["os.path.exists", "logger.info", "io.open", "enumerate", "torch.cat", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "torch.cat.append", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "", "def", "encode_file", "(", "self", ",", "path", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ",", "add_eos", "=", "True", ",", "\n", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "logger", ".", "info", "(", "'encoding file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "encoded", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ",", "\n", "add_double_eos", "=", "add_double_eos", ")", "\n", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_sents": [[194, 206], ["enumerate", "logger.info", "torch.cat.append", "torch.cat", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "def", "encode_sents", "(", "self", ",", "sents", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "logger", ".", "info", "(", "'encoding {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "encoded", "=", "[", "]", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_special": [[207, 212], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "setattr", "len", "sym.strip"], "methods", ["None"], ["", "def", "add_special", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "setattr", "(", "self", ",", "'{}_idx'", ".", "format", "(", "sym", ".", "strip", "(", "'<>'", ")", ")", ",", "self", ".", "sym2idx", "[", "sym", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol": [[213, 217], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "len"], "methods", ["None"], ["", "", "def", "add_symbol", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer._convert_id_to_token": [[218, 222], ["len"], "methods", ["None"], ["", "", "def", "_convert_id_to_token", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Converts an id in a token (BPE) using the vocab.\"\"\"", "\n", "assert", "0", "<=", "idx", "<", "len", "(", "self", ")", ",", "'Index {} out of vocabulary range'", ".", "format", "(", "idx", ")", "\n", "return", "self", ".", "idx2sym", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer._convert_token_to_id": [[223, 239], ["hasattr", "tokenization_transfo_xl.TransfoXLTokenizer.sym2idx.get", "ValueError"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "sym", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "if", "sym", "in", "self", ".", "sym2idx", ":", "\n", "            ", "return", "self", ".", "sym2idx", "[", "sym", "]", "\n", "", "else", ":", "\n", "# logger.info('encounter unk {}'.format(sym))", "\n", "# assert '<eos>' not in sym", "\n", "            ", "if", "hasattr", "(", "self", ",", "'unk_idx'", ")", ":", "\n", "                ", "return", "self", ".", "sym2idx", ".", "get", "(", "sym", ",", "self", ".", "unk_idx", ")", "\n", "# Backward compatibility with pre-trained models", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "elif", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Token not in vocabulary and no <unk> token in vocabulary for replacement'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_string": [[240, 244], ["None"], "methods", ["None"], ["", "", "", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "' '", ".", "join", "(", "tokens", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor": [[245, 247], ["torch.LongTensor", "tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "convert_to_tensor", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "self", ".", "convert_tokens_to_ids", "(", "symbols", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.vocab_size": [[248, 251], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2sym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer._tokenize": [[252, 270], ["line.lower.lower.strip", "line.lower.lower.lower", "line.lower.lower.split"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "line", ",", "add_eos", "=", "False", ",", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "# convert to lower case", "\n", "if", "self", ".", "lower_case", ":", "\n", "            ", "line", "=", "line", ".", "lower", "(", ")", "\n", "\n", "# empty delimiter '' will evaluate False", "\n", "", "if", "self", ".", "delimiter", "==", "''", ":", "\n", "            ", "symbols", "=", "line", "\n", "", "else", ":", "\n", "            ", "symbols", "=", "line", ".", "split", "(", "self", ".", "delimiter", ")", "\n", "\n", "", "if", "add_double_eos", ":", "# lm1b", "\n", "            ", "return", "[", "'<S>'", "]", "+", "symbols", "+", "[", "'<S>'", "]", "\n", "", "elif", "add_eos", ":", "\n", "            ", "return", "symbols", "+", "[", "'<eos>'", "]", "\n", "", "else", ":", "\n", "            ", "return", "symbols", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.__init__": [[273, 294], ["data.narrow.narrow.narrow", "data.narrow.narrow.view().t().contiguous().to", "data.narrow.narrow.size", "data.narrow.narrow.view().t().contiguous", "data.narrow.narrow.view().t", "data.narrow.narrow.view"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            data -- LongTensor -- the LongTensor is strictly ordered\n        \"\"\"", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "self", ".", "n_step", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "self", ".", "n_step", "*", "bsz", ")", "\n", "\n", "# Evenly divide the data across the bsz batches.", "\n", "self", ".", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Number of mini-batches", "\n", "self", ".", "n_batch", "=", "(", "self", ".", "n_step", "+", "self", ".", "bptt", "-", "1", ")", "//", "self", ".", "bptt", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch": [[295, 309], ["min", "max", "data.transpose().contiguous().to", "target.transpose().contiguous().to", "data.transpose().contiguous", "target.transpose().contiguous", "tokenization_transfo_xl.LMOrderedIterator.data.size", "data.transpose", "target.transpose"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "i", ",", "bptt", "=", "None", ")", ":", "\n", "        ", "if", "bptt", "is", "None", ":", "bptt", "=", "self", ".", "bptt", "\n", "seq_len", "=", "min", "(", "bptt", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", "-", "i", ")", "\n", "\n", "end_idx", "=", "i", "+", "seq_len", "\n", "beg_idx", "=", "max", "(", "0", ",", "i", "-", "self", ".", "ext_len", ")", "\n", "\n", "data", "=", "self", ".", "data", "[", "beg_idx", ":", "end_idx", "]", "\n", "target", "=", "self", ".", "data", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", "\n", "\n", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "data_out", ",", "target_out", ",", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter": [[310, 313], ["range", "tokenization_transfo_xl.LMOrderedIterator.data.size", "tokenization_transfo_xl.LMOrderedIterator.get_batch"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "def", "get_fixlen_iter", "(", "self", ",", "start", "=", "0", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "start", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "self", ".", "bptt", ")", ":", "\n", "            ", "yield", "self", ".", "get_batch", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.get_varlen_iter": [[314, 325], ["min", "tokenization_transfo_xl.LMOrderedIterator.get_batch", "max", "numpy.random.random", "int", "tokenization_transfo_xl.LMOrderedIterator.data.size", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "", "def", "get_varlen_iter", "(", "self", ",", "start", "=", "0", ",", "std", "=", "5", ",", "min_len", "=", "5", ",", "max_deviation", "=", "3", ")", ":", "\n", "        ", "max_len", "=", "self", ".", "bptt", "+", "max_deviation", "*", "std", "\n", "i", "=", "start", "\n", "while", "True", ":", "\n", "            ", "bptt", "=", "self", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "self", ".", "bptt", "/", "2.", "\n", "bptt", "=", "min", "(", "max_len", ",", "max", "(", "min_len", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "std", ")", ")", ")", ")", "\n", "data", ",", "target", ",", "seq_len", "=", "self", ".", "get_batch", "(", "i", ",", "bptt", ")", "\n", "i", "+=", "seq_len", "\n", "yield", "data", ",", "target", ",", "seq_len", "\n", "if", "i", ">=", "self", ".", "data", ".", "size", "(", "0", ")", "-", "2", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.__iter__": [[326, 328], ["tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_fixlen_iter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMShuffledIterator.__init__": [[331, 343], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            data -- list[LongTensor] -- there is no order among the LongTensors\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMShuffledIterator.get_sent_stream": [[344, 352], ["numpy.random.permutation", "numpy.array", "len", "range", "len"], "methods", ["None"], ["", "def", "get_sent_stream", "(", "self", ")", ":", "\n", "# index iterator", "\n", "        ", "epoch_indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "data", ")", ")", "if", "self", ".", "shuffle", "else", "np", ".", "array", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n", "# sentence iterator", "\n", "for", "idx", "in", "epoch_indices", ":", "\n", "            ", "yield", "self", ".", "data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator": [[353, 401], ["torch.LongTensor", "torch.LongTensor", "data[].fill_", "torch.LongTensor.fill_", "range", "torch.LongTensor.transpose().contiguous().to", "torch.LongTensor.transpose().contiguous().to", "min", "torch.LongTensor.resize_", "torch.LongTensor.size", "torch.LongTensor.size", "torch.LongTensor.transpose().contiguous", "torch.LongTensor.transpose().contiguous", "min", "next", "torch.LongTensor.transpose", "torch.LongTensor.transpose", "len", "len"], "methods", ["None"], ["", "", "def", "stream_iterator", "(", "self", ",", "sent_stream", ")", ":", "\n", "# streams for each data in the batch", "\n", "        ", "streams", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "\n", "data", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "\n", "n_retain", "=", "0", "\n", "\n", "while", "True", ":", "\n", "# data   : [n_retain+bptt x bsz]", "\n", "# target : [bptt x bsz]", "\n", "            ", "data", "[", "n_retain", ":", "]", ".", "fill_", "(", "-", "1", ")", "\n", "target", ".", "fill_", "(", "-", "1", ")", "\n", "\n", "valid_batch", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "bsz", ")", ":", "\n", "                ", "n_filled", "=", "0", "\n", "try", ":", "\n", "                    ", "while", "n_filled", "<", "self", ".", "bptt", ":", "\n", "                        ", "if", "streams", "[", "i", "]", "is", "None", "or", "len", "(", "streams", "[", "i", "]", ")", "<=", "1", ":", "\n", "                            ", "streams", "[", "i", "]", "=", "next", "(", "sent_stream", ")", "\n", "# number of new tokens to fill in", "\n", "", "n_new", "=", "min", "(", "len", "(", "streams", "[", "i", "]", ")", "-", "1", ",", "self", ".", "bptt", "-", "n_filled", ")", "\n", "# first n_retain tokens are retained from last batch", "\n", "data", "[", "n_retain", "+", "n_filled", ":", "n_retain", "+", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", ":", "n_new", "]", "\n", "target", "[", "n_filled", ":", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", "1", ":", "n_new", "+", "1", "]", "\n", "streams", "[", "i", "]", "=", "streams", "[", "i", "]", "[", "n_new", ":", "]", "\n", "n_filled", "+=", "n_new", "\n", "", "", "except", "StopIteration", ":", "\n", "                    ", "valid_batch", "=", "False", "\n", "break", "\n", "\n", "", "", "if", "not", "valid_batch", ":", "\n", "                ", "return", "\n", "\n", "", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "yield", "data_out", ",", "target_out", ",", "self", ".", "bptt", "\n", "\n", "n_retain", "=", "min", "(", "data", ".", "size", "(", "0", ")", ",", "self", ".", "ext_len", ")", "\n", "if", "n_retain", ">", "0", ":", "\n", "                ", "data", "[", ":", "n_retain", "]", "=", "data", "[", "-", "n_retain", ":", "]", "\n", "", "data", ".", "resize_", "(", "n_retain", "+", "self", ".", "bptt", ",", "data", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMShuffledIterator.__iter__": [[402, 408], ["tokenization_transfo_xl.LMShuffledIterator.get_sent_stream", "tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "# sent_stream is an iterator", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMMultiFileIterator.__init__": [[411, 423], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "paths", ",", "vocab", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "\n", "shuffle", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "paths", "=", "paths", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream": [[424, 431], ["tokenization_transfo_xl.LMMultiFileIterator.vocab.encode_file", "iter", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "get_sent_stream", "(", "self", ",", "path", ")", ":", "\n", "        ", "sents", "=", "self", ".", "vocab", ".", "encode_file", "(", "path", ",", "add_double_eos", "=", "True", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "sents", ")", "\n", "", "sent_stream", "=", "iter", "(", "sents", ")", "\n", "\n", "return", "sent_stream", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMMultiFileIterator.__iter__": [[432, 441], ["numpy.random.shuffle", "tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "tokenization_transfo_xl.LMMultiFileIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "paths", ")", "\n", "\n", "", "for", "path", "in", "self", ".", "paths", ":", "\n", "# sent_stream is an iterator", "\n", "            ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", "path", ")", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "                ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLCorpus.from_pretrained": [[444, 486], ["TransfoXLTokenizer.from_pretrained", "cls", "torch.load", "torch.load.items", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "logger.error", "PRETRAINED_CORPUS_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path"], ["    ", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a pre-processed corpus.\n        \"\"\"", "\n", "vocab", "=", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_CORPUS_ARCHIVE_MAP", ":", "\n", "            ", "corpus_file", "=", "PRETRAINED_CORPUS_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "corpus_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CORPUS_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_corpus_file", "=", "cached_path", "(", "corpus_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Corpus '{}' was not found in corpus list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_CORPUS_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "corpus_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_corpus_file", "==", "corpus_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {}\"", ".", "format", "(", "corpus_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {} from cache at {}\"", ".", "format", "(", "\n", "corpus_file", ",", "resolved_corpus_file", ")", ")", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "corpus", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "corpus_dict", "=", "torch", ".", "load", "(", "resolved_corpus_file", ")", "\n", "for", "key", ",", "value", "in", "corpus_dict", ".", "items", "(", ")", ":", "\n", "            ", "corpus", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "corpus", ".", "vocab", "=", "vocab", "\n", "if", "corpus", ".", "train", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "train", "=", "torch", ".", "tensor", "(", "corpus", ".", "train", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "valid", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "valid", "=", "torch", ".", "tensor", "(", "corpus", ".", "valid", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "test", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "test", "=", "torch", ".", "tensor", "(", "corpus", ".", "test", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLCorpus.__init__": [[487, 493], ["tokenization_transfo_xl.TransfoXLTokenizer"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "TransfoXLTokenizer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "train", "=", "None", "\n", "self", ".", "valid", "=", "None", "\n", "self", ".", "test", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLCorpus.build_corpus": [[494, 532], ["tokenization_transfo_xl.TransfoXLCorpus.vocab.build_vocab", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "glob.glob", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "build_corpus", "(", "self", ",", "path", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'wt103'", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "train_path_pattern", "=", "os", ".", "path", ".", "join", "(", "\n", "path", ",", "'1-billion-word-language-modeling-benchmark-r13output'", ",", "\n", "'training-monolingual.tokenized.shuffled'", ",", "'news.en-*'", ")", "\n", "train_paths", "=", "glob", ".", "glob", "(", "train_path_pattern", ")", "\n", "# the vocab will load from file when build_vocab() is called", "\n", "\n", "", "self", ".", "vocab", ".", "build_vocab", "(", ")", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "", "elif", "self", ".", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "self", ".", "train", "=", "train_paths", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.TransfoXLCorpus.get_iterator": [[533, 548], ["tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMMultiFileIterator", "tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMShuffledIterator"], "methods", ["None"], ["", "", "def", "get_iterator", "(", "self", ",", "split", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "self", ".", "train", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "kwargs", "[", "'shuffle'", "]", "=", "True", "\n", "data_iter", "=", "LMMultiFileIterator", "(", "self", ".", "train", ",", "self", ".", "vocab", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "elif", "split", "in", "[", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "data", "=", "self", ".", "valid", "if", "split", "==", "'valid'", "else", "self", ".", "test", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "data_iter", "=", "LMShuffledIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "data_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_transfo_xl.get_lm_corpus": [[550, 580], ["os.path.join", "os.path.join", "os.path.exists", "logger.info", "torch.load", "os.path.exists", "logger.info", "logger.info", "tokenization_transfo_xl.TransfoXLCorpus", "torch.save", "io.open", "pickle.load", "os.path.join"], "function", ["None"], ["", "", "def", "get_lm_corpus", "(", "datadir", ",", "dataset", ")", ":", "\n", "    ", "fn", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pt'", ")", "\n", "fn_pickle", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading cached dataset...'", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "fn_pickle", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading cached dataset from pickle...'", ")", "\n", "with", "open", "(", "fn", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "'Producing dataset {}...'", ".", "format", "(", "dataset", ")", ")", "\n", "kwargs", "=", "{", "}", "\n", "if", "dataset", "in", "[", "'wt103'", ",", "'wt2'", "]", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "", "elif", "dataset", "==", "'ptb'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "True", "\n", "", "elif", "dataset", "==", "'lm1b'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "kwargs", "[", "'vocab_file'", "]", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'1b_word_vocab.txt'", ")", "\n", "", "elif", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "pass", "\n", "\n", "", "corpus", "=", "TransfoXLCorpus", "(", "datadir", ",", "dataset", ",", "**", "kwargs", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "fn", ")", "\n", "\n", "", "return", "corpus", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_gpt2.GPT2Config.__init__": [[56, 127], ["configuration_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "\n", "num_labels", "=", "1", ",", "\n", "summary_type", "=", "'cls_index'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs GPT2Config.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `GPT2Model` or a configuration json file.\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            resid_pdrop: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attn_pdrop: The dropout ratio for the attention\n                probabilities.\n            embd_pdrop: The dropout ratio for the embeddings.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "super", "(", "GPT2Config", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_gpt2.GPT2Config.max_position_embeddings": [[130, 133], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_gpt2.GPT2Config.hidden_size": [[134, 137], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_gpt2.GPT2Config.num_attention_heads": [[138, 141], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_gpt2.GPT2Config.num_hidden_layers": [[142, 145], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModel.__init__": [[60, 62], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"TFAutoModel is designed to be instantiated \"", "\n", "\"using the `TFAutoModel.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModel.from_pretrained": [[64, 158], ["ValueError", "modeling_tf_distilbert.TFDistilBertModel.from_pretrained", "modeling_tf_roberta.TFRobertaModel.from_pretrained", "modeling_tf_bert.TFBertModel.from_pretrained", "modeling_tf_openai.TFOpenAIGPTModel.from_pretrained", "modeling_tf_gpt2.TFGPT2Model.from_pretrained", "modeling_tf_transfo_xl.TFTransfoXLModel.from_pretrained", "modeling_tf_xlnet.TFXLNetModel.from_pretrained", "modeling_tf_xlm.TFXLMModel.from_pretrained", "modeling_tf_ctrl.TFCTRLModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a pre-trained model configuration.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: TFDistilBertModel (DistilBERT model)\n            - contains `roberta`: TFRobertaModel (RoBERTa model)\n            - contains `bert`: TFTFBertModel (Bert model)\n            - contains `openai-gpt`: TFOpenAIGPTModel (OpenAI GPT model)\n            - contains `gpt2`: TFGPT2Model (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TFTransfoXLModel (Transformer-XL model)\n            - contains `xlnet`: TFXLNetModel (XLNet model)\n            - contains `ctrl`: TFCTRLModel (CTRL model)\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModel.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModel.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFRobertaModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFOpenAIGPTModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFGPT2Model", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFTransfoXLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'ctrl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFCTRLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta', 'ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModelWithLMHead.__init__": [[184, 186], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"TFAutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `TFAutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModelWithLMHead.from_pretrained": [[188, 286], ["ValueError", "modeling_tf_distilbert.TFDistilBertForMaskedLM.from_pretrained", "modeling_tf_roberta.TFRobertaForMaskedLM.from_pretrained", "modeling_tf_bert.TFBertForMaskedLM.from_pretrained", "modeling_tf_openai.TFOpenAIGPTLMHeadModel.from_pretrained", "modeling_tf_gpt2.TFGPT2LMHeadModel.from_pretrained", "modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.from_pretrained", "modeling_tf_xlnet.TFXLNetLMHeadModel.from_pretrained", "modeling_tf_xlm.TFXLMWithLMHeadModel.from_pretrained", "modeling_tf_ctrl.TFCTRLLMHeadModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the language modeling model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: TFDistilBertForMaskedLM (DistilBERT model)\n            - contains `roberta`: TFRobertaForMaskedLM (RoBERTa model)\n            - contains `bert`: TFBertForMaskedLM (Bert model)\n            - contains `openai-gpt`: TFOpenAIGPTLMHeadModel (OpenAI GPT model)\n            - contains `gpt2`: TFGPT2LMHeadModel (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TFTransfoXLLMHeadModel (Transformer-XL model)\n            - contains `xlnet`: TFXLNetLMHeadModel (XLNet model)\n            - contains `xlm`: TFXLMWithLMHeadModel (XLM model)\n            - contains `ctrl`: TFCTRLLMHeadModel (CTRL model)\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModelWithLMHead.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModelWithLMHead.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModelWithLMHead.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModelWithLMHead.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFRobertaForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFOpenAIGPTLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFGPT2LMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFTransfoXLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMWithLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'ctrl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFCTRLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta', 'ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModelForSequenceClassification.__init__": [[308, 310], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"TFAutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `TFAutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModelForSequenceClassification.from_pretrained": [[312, 400], ["ValueError", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.from_pretrained", "modeling_tf_roberta.TFRobertaForSequenceClassification.from_pretrained", "modeling_tf_bert.TFBertForSequenceClassification.from_pretrained", "modeling_tf_xlnet.TFXLNetForSequenceClassification.from_pretrained", "modeling_tf_xlm.TFXLMForSequenceClassification.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the sequence classification model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: TFDistilBertForSequenceClassification (DistilBERT model)\n            - contains `roberta`: TFRobertaForSequenceClassification (RoBERTa model)\n            - contains `bert`: TFBertForSequenceClassification (Bert model)\n            - contains `xlnet`: TFXLNetForSequenceClassification (XLNet model)\n            - contains `xlm`: TFXLMForSequenceClassification (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModelForSequenceClassification.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModelForSequenceClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFRobertaForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'xlm', 'roberta'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModelForQuestionAnswering.__init__": [[421, 423], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"TFAutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `TFAutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_auto.TFAutoModelForQuestionAnswering.from_pretrained": [[425, 510], ["ValueError", "modeling_tf_distilbert.TFDistilBertForQuestionAnswering.from_pretrained", "modeling_tf_bert.TFBertForQuestionAnswering.from_pretrained", "modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.from_pretrained", "modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the question answering model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: TFDistilBertForQuestionAnswering (DistilBERT model)\n            - contains `bert`: TFBertForQuestionAnswering (Bert model)\n            - contains `xlnet`: TFXLNetForQuestionAnswering (XLNet model)\n            - contains `xlm`: TFXLMForQuestionAnswering (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModelForQuestionAnswering.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModelForQuestionAnswering.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModelForQuestionAnswering.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModelForQuestionAnswering.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetForQuestionAnsweringSimple", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMForQuestionAnsweringSimple", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'xlm'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFPreTrainedModel.__init__": [[56, 67], ["super().__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFPreTrainedModel._get_resized_embeddings": [[68, 82], ["None"], "methods", ["None"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Variable from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``tf.Variable``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "# if new_num_tokens is None:", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFPreTrainedModel.resize_token_embeddings": [[102, 116], ["None"], "methods", ["None"], ["", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end. \n                If not provided or None: does nothing and just returns a pointer to the input tokens ``tf.Variable`` Module of the model.\n\n        Return: ``tf.Variable``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFPreTrainedModel.prune_heads": [[117, 125], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFPreTrainedModel.save_pretrained": [[126, 139], ["os.path.isdir", "modeling_tf_utils.TFPreTrainedModel.config.save_pretrained", "os.path.join", "modeling_tf_utils.TFPreTrainedModel.save_weights", "logger.info"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Save configuration file", "\n", "self", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "TF2_WEIGHTS_NAME", ")", "\n", "self", ".", "save_weights", "(", "output_model_file", ")", "\n", "logger", ".", "info", "(", "\"Model weights saved in {}\"", ".", "format", "(", "output_model_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFPreTrainedModel.from_pretrained": [[140, 279], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "cls.", "os.path.isfile", "cls.load_weights", "cls.", "cls.config_class.from_pretrained", "modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model", "os.path.isdir", "file_utils.cached_path", "logger.info", "logger.info", "os.path.isfile", "os.path.isfile", "os.path.join", "os.path.join", "EnvironmentError", "logger.error", "logger.error", "os.path.isfile", "os.path.join", "EnvironmentError", "os.path.join", "cls.pretrained_model_archive_map.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained TF 2.0 model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch state_dict save file` (e.g. `./pt_model/pytorch_model.bin`). In this case, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the PyTorch checkpoint in a TensorFlow model using the provided conversion scripts and loading the TensorFlow model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            from_pt: (`optional`) boolean, default False:\n                Load the model weights from a PyTorch state_dict save file (see docstring of pretrained_model_name_or_path argument).\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_pt=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_pt", "=", "kwargs", ".", "pop", "(", "'from_pt'", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "from_pt", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\"Error no file named {} found in directory {} or `from_pt` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", "]", ",", "\n", "pretrained_model_name_or_path", ")", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "", "else", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"Error file {} not found\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "force_download", ",", "proxies", "=", "proxies", ")", "\n", "", "except", "EnvironmentError", "as", "e", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "", "raise", "e", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "from_pt", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "            ", "return", "load_pytorch_checkpoint_in_tf2_model", "(", "model", ",", "resolved_archive_file", ")", "\n", "\n", "", "ret", "=", "model", "(", "model", ".", "dummy_inputs", ",", "training", "=", "False", ")", "# build the network with dummy inputs", "\n", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "resolved_archive_file", ")", ",", "\"Error retrieving file {}\"", ".", "format", "(", "resolved_archive_file", ")", "\n", "# 'by_name' allow us to do transfer learning by skipping/adding layers", "\n", "# see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1339-L1357", "\n", "model", ".", "load_weights", "(", "resolved_archive_file", ",", "by_name", "=", "True", ")", "\n", "\n", "ret", "=", "model", "(", "model", ".", "dummy_inputs", ",", "training", "=", "False", ")", "# Make sure restore ops are run", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFConv1D.__init__": [[281, 289], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ",", "initializer_range", "=", "0.02", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" TFConv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", "TFConv1D", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "self", ".", "nx", "=", "nx", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFConv1D.build": [[290, 299], ["modeling_tf_utils.TFConv1D.add_weight", "modeling_tf_utils.TFConv1D.add_weight", "modeling_tf_utils.get_initializer", "tensorflow.zeros_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "weight", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "[", "self", ".", "nx", ",", "self", ".", "nf", "]", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ")", "\n", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "\n", "\"bias\"", ",", "\n", "shape", "=", "[", "1", ",", "self", ".", "nf", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFConv1D.call": [[300, 309], ["tensorflow.reshape", "tensorflow.reshape", "modeling_tf_utils.shape_list", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "bz", ",", "sl", "=", "shape_list", "(", "x", ")", "[", ":", "2", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "self", ".", "nx", "]", ")", "\n", "x", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "weight", ")", "+", "self", ".", "bias", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "bz", ",", "sl", ",", "self", ".", "nf", "]", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFSharedEmbeddings.__init__": [[314, 319], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "hidden_size", ",", "initializer_range", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFSharedEmbeddings", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "initializer_range", "=", "hidden_size", "**", "-", "0.5", "if", "initializer_range", "is", "None", "else", "initializer_range", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFSharedEmbeddings.build": [[320, 330], ["modeling_tf_utils.TFSharedEmbeddings.add_weight", "super().build", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer\n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "self", ".", "weight", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "[", "self", ".", "vocab_size", ",", "self", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ")", "\n", "super", "(", "TFSharedEmbeddings", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFSharedEmbeddings.call": [[331, 352], ["modeling_tf_utils.TFSharedEmbeddings._embedding", "modeling_tf_utils.TFSharedEmbeddings._linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._linear"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mode", "=", "\"embedding\"", ")", ":", "\n", "        ", "\"\"\"Get token embeddings of inputs.\n        Args:\n            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)\n            mode: string, a valid value is one of \"embedding\" and \"linear\".\n        Returns:\n            outputs: (1) If mode == \"embedding\", output embedding tensor, float32 with\n                shape [batch_size, length, embedding_size]; (2) mode == \"linear\", output\n                linear tensor, float32 with shape [batch_size, length, vocab_size].\n        Raises:\n            ValueError: if mode is not valid.\n        \n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "if", "mode", "==", "\"embedding\"", ":", "\n", "            ", "return", "self", ".", "_embedding", "(", "inputs", ")", "\n", "", "elif", "mode", "==", "\"linear\"", ":", "\n", "            ", "return", "self", ".", "_linear", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode {} is not valid.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFSharedEmbeddings._embedding": [[353, 356], ["tensorflow.gather"], "methods", ["None"], ["", "", "def", "_embedding", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "\"\"\"Applies embedding based on inputs tensor.\"\"\"", "\n", "return", "tf", ".", "gather", "(", "self", ".", "weight", ",", "input_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFSharedEmbeddings._linear": [[357, 370], ["tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "_linear", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Computes logits by running inputs through a linear layer.\n            Args:\n                inputs: A float32 tensor with shape [..., hidden_size]\n            Returns:\n                float32 tensor with shape [..., vocab_size].\n        \"\"\"", "\n", "first_dims", "=", "shape_list", "(", "inputs", ")", "[", ":", "-", "1", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "weight", ",", "transpose_b", "=", "True", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "logits", ",", "first_dims", "+", "[", "self", ".", "vocab_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFSequenceSummary.__init__": [[387, 418], ["super().__init__", "hasattr", "hasattr", "tensorflow.keras.layers.Dense", "hasattr", "hasattr", "tensorflow.keras.layers.Dropout", "hasattr", "tensorflow.keras.layers.Dropout", "hasattr", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "initializer_range", "=", "0.02", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFSequenceSummary", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "else", "'last'", "\n", "if", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "has_summary", "=", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "and", "config", ".", "summary_use_proj", "\n", "if", "self", ".", "has_summary", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "'summary_proj_to_labels'", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "num_classes", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "initializer_range", ")", ",", "\n", "name", "=", "'summary'", ")", "\n", "\n", "", "self", ".", "has_activation", "=", "hasattr", "(", "config", ",", "'summary_activation'", ")", "and", "config", ".", "summary_activation", "==", "'tanh'", "\n", "if", "self", ".", "has_activation", ":", "\n", "            ", "self", ".", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "tanh", "\n", "\n", "", "self", ".", "has_first_dropout", "=", "hasattr", "(", "config", ",", "'summary_first_dropout'", ")", "and", "config", ".", "summary_first_dropout", ">", "0", "\n", "if", "self", ".", "has_first_dropout", ":", "\n", "            ", "self", ".", "first_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "has_last_dropout", "=", "hasattr", "(", "config", ",", "'summary_last_dropout'", ")", "and", "config", ".", "summary_last_dropout", ">", "0", "\n", "if", "self", ".", "has_last_dropout", ":", "\n", "            ", "self", ".", "last_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.TFSequenceSummary.call": [[419, 472], ["isinstance", "isinstance", "modeling_tf_utils.TFSequenceSummary.first_dropout", "modeling_tf_utils.TFSequenceSummary.summary", "modeling_tf_utils.TFSequenceSummary.activation", "modeling_tf_utils.TFSequenceSummary.last_dropout", "inputs.get", "inputs.get", "len", "tensorflow.mean", "len", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.gather", "tensorflow.squeeze", "tensorflow.fill", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "(", "dict", ",", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "hidden_states", "=", "inputs", "\n", "cls_index", "=", "None", "\n", "", "elif", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "hidden_states", "=", "inputs", "[", "0", "]", "\n", "cls_index", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "None", "\n", "assert", "len", "(", "inputs", ")", "<=", "2", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "cls_index", "=", "inputs", ".", "get", "(", "'cls_index'", ",", "None", ")", "\n", "\n", "", "if", "self", ".", "summary_type", "==", "'last'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'first'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'mean'", ":", "\n", "            ", "output", "=", "tf", ".", "mean", "(", "hidden_states", ",", "axis", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "'cls_index'", ":", "\n", "            ", "hidden_shape", "=", "shape_list", "(", "hidden_states", ")", "# e.g. [batch, num choices, seq length, hidden dims]", "\n", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "tf", ".", "fill", "(", "hidden_shape", "[", ":", "-", "2", "]", ",", "hidden_shape", "[", "-", "2", "]", "-", "1", ")", "# A tensor full of shape [batch] or [batch, num choices] full of sequence length", "\n", "", "cls_shape", "=", "shape_list", "(", "cls_index", ")", "\n", "if", "len", "(", "cls_shape", ")", "<=", "len", "(", "hidden_shape", ")", "-", "2", ":", "\n", "                ", "cls_index", "=", "cls_index", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "# else:", "\n", "# cls_index = cls_index[..., tf.newaxis]", "\n", "# cls_index = cls_index.expand((-1,) * (cls_index.dim()-1) + (hidden_states.size(-1),))", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "tf", ".", "gather", "(", "hidden_states", ",", "cls_index", ",", "batch_dims", "=", "len", "(", "hidden_shape", ")", "-", "2", ")", "\n", "output", "=", "tf", ".", "squeeze", "(", "output", ",", "axis", "=", "len", "(", "hidden_shape", ")", "-", "2", ")", "# shape of output: (batch, num choices, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "has_first_dropout", ":", "\n", "            ", "output", "=", "self", ".", "first_dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "\n", "", "if", "self", ".", "has_summary", ":", "\n", "            ", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "\n", "", "if", "self", ".", "has_activation", ":", "\n", "            ", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "\n", "", "if", "self", ".", "has_last_dropout", ":", "\n", "            ", "output", "=", "self", ".", "last_dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list": [[473, 478], ["x.shape.as_list", "tensorflow.shape", "enumerate"], "function", ["None"], ["", "", "def", "shape_list", "(", "x", ")", ":", "\n", "    ", "\"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"", "\n", "static", "=", "x", ".", "shape", ".", "as_list", "(", ")", "\n", "dynamic", "=", "tf", ".", "shape", "(", "x", ")", "\n", "return", "[", "dynamic", "[", "i", "]", "if", "s", "is", "None", "else", "s", "for", "i", ",", "s", "in", "enumerate", "(", "static", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer": [[479, 487], ["tensorflow.keras.initializers.TruncatedNormal"], "function", ["None"], ["", "def", "get_initializer", "(", "initializer_range", "=", "0.02", ")", ":", "\n", "  ", "\"\"\"Creates a `tf.initializers.truncated_normal` with the given range.\n  Args:\n    initializer_range: float, initializer range for stddev.\n  Returns:\n    TruncatedNormal initializer with stddev = `initializer_range`.\n  \"\"\"", "\n", "return", "tf", ".", "keras", ".", "initializers", ".", "TruncatedNormal", "(", "stddev", "=", "initializer_range", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_roberta_original_pytorch_checkpoint_to_pytorch.convert_roberta_checkpoint_to_pytorch": [[42, 156], ["fairseq.models.roberta.RobertaModel.from_pretrained", "FairseqRobertaModel.from_pretrained.eval", "transformers.modeling_bert.BertConfig", "print", "model.eval", "torch.zeros_like", "range", "FairseqRobertaModel.from_pretrained.encode().unsqueeze", "print", "torch.max().item", "print", "torch.allclose", "print", "print", "model.save_pretrained", "transformers.modeling_roberta.RobertaForSequenceClassification", "transformers.modeling_roberta.RobertaForMaskedLM", "model", "Exception", "torch.Size", "FairseqRobertaModel.from_pretrained.encode", "FairseqRobertaModel.from_pretrained.extract_features", "FairseqRobertaModel.from_pretrained.model", "torch.max", "torch.abs"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["def", "convert_roberta_checkpoint_to_pytorch", "(", "roberta_checkpoint_path", ",", "pytorch_dump_folder_path", ",", "classification_head", ")", ":", "\n", "    ", "\"\"\"\n    Copy/paste/tweak roberta's weights to our BERT structure.\n    \"\"\"", "\n", "roberta", "=", "FairseqRobertaModel", ".", "from_pretrained", "(", "roberta_checkpoint_path", ")", "\n", "roberta", ".", "eval", "(", ")", "# disable dropout", "\n", "config", "=", "BertConfig", "(", "\n", "vocab_size_or_config_json_file", "=", "50265", ",", "\n", "hidden_size", "=", "roberta", ".", "args", ".", "encoder_embed_dim", ",", "\n", "num_hidden_layers", "=", "roberta", ".", "args", ".", "encoder_layers", ",", "\n", "num_attention_heads", "=", "roberta", ".", "args", ".", "encoder_attention_heads", ",", "\n", "intermediate_size", "=", "roberta", ".", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "max_position_embeddings", "=", "514", ",", "\n", "type_vocab_size", "=", "1", ",", "\n", "layer_norm_eps", "=", "1e-5", ",", "# PyTorch default used in fairseq", "\n", ")", "\n", "if", "classification_head", ":", "\n", "        ", "config", ".", "num_labels", "=", "roberta", ".", "args", ".", "num_classes", "\n", "", "print", "(", "\"Our BERT config:\"", ",", "config", ")", "\n", "\n", "model", "=", "RobertaForSequenceClassification", "(", "config", ")", "if", "classification_head", "else", "RobertaForMaskedLM", "(", "config", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Now let's copy all the weights.", "\n", "# Embeddings", "\n", "roberta_sent_encoder", "=", "roberta", ".", "model", ".", "decoder", ".", "sentence_encoder", "\n", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ".", "weight", "=", "roberta_sent_encoder", ".", "embed_tokens", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "position_embeddings", ".", "weight", "=", "roberta_sent_encoder", ".", "embed_positions", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "=", "torch", ".", "zeros_like", "(", "model", ".", "roberta", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ")", "# just zero them out b/c RoBERTa doesn't use them.", "\n", "model", ".", "roberta", ".", "embeddings", ".", "LayerNorm", ".", "weight", "=", "roberta_sent_encoder", ".", "emb_layer_norm", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "LayerNorm", ".", "bias", "=", "roberta_sent_encoder", ".", "emb_layer_norm", ".", "bias", "\n", "\n", "for", "i", "in", "range", "(", "config", ".", "num_hidden_layers", ")", ":", "\n", "# Encoder: start of layer", "\n", "        ", "layer", ":", "BertLayer", "=", "model", ".", "roberta", ".", "encoder", ".", "layer", "[", "i", "]", "\n", "roberta_layer", ":", "TransformerSentenceEncoderLayer", "=", "roberta_sent_encoder", ".", "layers", "[", "i", "]", "\n", "\n", "### self attention", "\n", "self_attn", ":", "BertSelfAttention", "=", "layer", ".", "attention", ".", "self", "\n", "assert", "(", "\n", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", ".", "shape", "==", "torch", ".", "Size", "(", "(", "3", "*", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ")", "\n", ")", "\n", "# we use three distinct linear layers so we split the source layer here.", "\n", "self_attn", ".", "query", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", "[", ":", "config", ".", "hidden_size", ",", ":", "]", "\n", "self_attn", ".", "query", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_bias", "[", ":", "config", ".", "hidden_size", "]", "\n", "self_attn", ".", "key", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", "[", "config", ".", "hidden_size", ":", "2", "*", "config", ".", "hidden_size", ",", ":", "]", "\n", "self_attn", ".", "key", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_bias", "[", "config", ".", "hidden_size", ":", "2", "*", "config", ".", "hidden_size", "]", "\n", "self_attn", ".", "value", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", "[", "2", "*", "config", ".", "hidden_size", ":", ",", ":", "]", "\n", "self_attn", ".", "value", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_bias", "[", "2", "*", "config", ".", "hidden_size", ":", "]", "\n", "\n", "### self-attention output", "\n", "self_output", ":", "BertSelfOutput", "=", "layer", ".", "attention", ".", "output", "\n", "assert", "(", "\n", "self_output", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "weight", ".", "shape", "\n", ")", "\n", "self_output", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "weight", "\n", "self_output", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "bias", "\n", "self_output", ".", "LayerNorm", ".", "weight", "=", "roberta_layer", ".", "self_attn_layer_norm", ".", "weight", "\n", "self_output", ".", "LayerNorm", ".", "bias", "=", "roberta_layer", ".", "self_attn_layer_norm", ".", "bias", "\n", "\n", "### intermediate", "\n", "intermediate", ":", "BertIntermediate", "=", "layer", ".", "intermediate", "\n", "assert", "(", "\n", "intermediate", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "fc1", ".", "weight", ".", "shape", "\n", ")", "\n", "intermediate", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "fc1", ".", "weight", "\n", "intermediate", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "fc1", ".", "bias", "\n", "\n", "### output", "\n", "bert_output", ":", "BertOutput", "=", "layer", ".", "output", "\n", "assert", "(", "\n", "bert_output", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "fc2", ".", "weight", ".", "shape", "\n", ")", "\n", "bert_output", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "fc2", ".", "weight", "\n", "bert_output", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "fc2", ".", "bias", "\n", "bert_output", ".", "LayerNorm", ".", "weight", "=", "roberta_layer", ".", "final_layer_norm", ".", "weight", "\n", "bert_output", ".", "LayerNorm", ".", "bias", "=", "roberta_layer", ".", "final_layer_norm", ".", "bias", "\n", "#### end of layer", "\n", "\n", "", "if", "classification_head", ":", "\n", "        ", "model", ".", "classifier", ".", "dense", ".", "weight", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "dense", ".", "weight", "\n", "model", ".", "classifier", ".", "dense", ".", "bias", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "dense", ".", "bias", "\n", "model", ".", "classifier", ".", "out_proj", ".", "weight", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "out_proj", ".", "weight", "\n", "model", ".", "classifier", ".", "out_proj", ".", "bias", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "out_proj", ".", "bias", "\n", "", "else", ":", "\n", "# LM Head", "\n", "        ", "model", ".", "lm_head", ".", "dense", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "dense", ".", "weight", "\n", "model", ".", "lm_head", ".", "dense", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "dense", ".", "bias", "\n", "model", ".", "lm_head", ".", "layer_norm", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "layer_norm", ".", "weight", "\n", "model", ".", "lm_head", ".", "layer_norm", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "layer_norm", ".", "bias", "\n", "model", ".", "lm_head", ".", "decoder", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "weight", "\n", "model", ".", "lm_head", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "bias", "\n", "\n", "# Let's check that we get the same results.", "\n", "", "input_ids", ":", "torch", ".", "Tensor", "=", "roberta", ".", "encode", "(", "SAMPLE_TEXT", ")", ".", "unsqueeze", "(", "0", ")", "# batch of size 1", "\n", "\n", "our_output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "if", "classification_head", ":", "\n", "        ", "their_output", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", "(", "roberta", ".", "extract_features", "(", "input_ids", ")", ")", "\n", "", "else", ":", "\n", "        ", "their_output", "=", "roberta", ".", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "", "print", "(", "our_output", ".", "shape", ",", "their_output", ".", "shape", ")", "\n", "max_absolute_diff", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "our_output", "-", "their_output", ")", ")", ".", "item", "(", ")", "\n", "print", "(", "f\"max_absolute_diff = {max_absolute_diff}\"", ")", "# ~ 1e-7", "\n", "success", "=", "torch", ".", "allclose", "(", "our_output", ",", "their_output", ",", "atol", "=", "1e-3", ")", "\n", "print", "(", "\n", "\"Do both models output the same tensors?\"", ",", "\n", "\"\ud83d\udd25\"", "if", "success", "else", "\"\ud83d\udca9\"", "\n", ")", "\n", "if", "not", "success", ":", "\n", "        ", "raise", "Exception", "(", "\"Something went wRoNg\"", ")", "\n", "\n", "", "print", "(", "f\"Saving model to {pytorch_dump_folder_path}\"", ")", "\n", "model", ".", "save_pretrained", "(", "pytorch_dump_folder_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.__init__": [[64, 91], ["tokenization_utils.PreTrainedTokenizer.__init__", "spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "\n", "do_lower_case", "=", "False", ",", "remove_space", "=", "True", ",", "keep_accents", "=", "False", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "unk_token", "=", "\"<unk>\"", ",", "sep_token", "=", "\"<sep>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "cls_token", "=", "\"<cls>\"", ",", "mask_token", "=", "\"<mask>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<eop>\"", ",", "\"<eod>\"", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLNetTokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "additional_special_tokens", "=", "\n", "additional_special_tokens", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", ")", "\n", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "remove_space", "=", "remove_space", "\n", "self", ".", "keep_accents", "=", "keep_accents", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.vocab_size": [[92, 95], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sp_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.__getstate__": [[96, 100], ["tokenization_xlnet.XLNetTokenizer.__dict__.copy"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "state", "[", "\"sp_model\"", "]", "=", "None", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.__setstate__": [[101, 110], ["spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "d", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", ")", "\n", "", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "self", ".", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.preprocess_text": [[111, 128], ["outputs.lower.lower.replace().replace", "isinstance", "outputs.lower.lower.decode", "unicodedata.normalize", "outputs.lower.lower.lower", "inputs.strip().split", "outputs.lower.lower.replace", "inputs.strip", "unicodedata.combining"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.normalize"], ["", "def", "preprocess_text", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "remove_space", ":", "\n", "            ", "outputs", "=", "' '", ".", "join", "(", "inputs", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "inputs", "\n", "", "outputs", "=", "outputs", ".", "replace", "(", "\"``\"", ",", "'\"'", ")", ".", "replace", "(", "\"''\"", ",", "'\"'", ")", "\n", "\n", "if", "six", ".", "PY2", "and", "isinstance", "(", "outputs", ",", "str", ")", ":", "\n", "            ", "outputs", "=", "outputs", ".", "decode", "(", "'utf-8'", ")", "\n", "\n", "", "if", "not", "self", ".", "keep_accents", ":", "\n", "            ", "outputs", "=", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "outputs", ")", "\n", "outputs", "=", "''", ".", "join", "(", "[", "c", "for", "c", "in", "outputs", "if", "not", "unicodedata", ".", "combining", "(", "c", ")", "]", ")", "\n", "", "if", "self", ".", "do_lower_case", ":", "\n", "            ", "outputs", "=", "outputs", ".", "lower", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer._tokenize": [[129, 167], ["tokenization_xlnet.XLNetTokenizer.preprocess_text", "isinstance", "text.encode.encode.encode", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.sp_model.SampleEncodeAsPieces", "piece[].isdigit", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.append", "new_pieces.extend", "new_pieces.append", "isinstance", "ret_pieces.append", "len", "piece[].replace", "piece.decode.decode.decode", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.preprocess_text", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "return_unicode", "=", "True", ",", "sample", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n            return_unicode is used only for py2\n        \"\"\"", "\n", "text", "=", "self", ".", "preprocess_text", "(", "text", ")", "\n", "# note(zhiliny): in some systems, sentencepiece only accepts str for py2", "\n", "if", "six", ".", "PY2", "and", "isinstance", "(", "text", ",", "unicode", ")", ":", "\n", "            ", "text", "=", "text", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "", "if", "not", "sample", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "SampleEncodeAsPieces", "(", "text", ",", "64", ",", "0.1", ")", "\n", "", "new_pieces", "=", "[", "]", "\n", "for", "piece", "in", "pieces", ":", "\n", "            ", "if", "len", "(", "piece", ")", ">", "1", "and", "piece", "[", "-", "1", "]", "==", "','", "and", "piece", "[", "-", "2", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "cur_pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "\n", "piece", "[", ":", "-", "1", "]", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "''", ")", ")", "\n", "if", "piece", "[", "0", "]", "!=", "SPIECE_UNDERLINE", "and", "cur_pieces", "[", "0", "]", "[", "0", "]", "==", "SPIECE_UNDERLINE", ":", "\n", "                    ", "if", "len", "(", "cur_pieces", "[", "0", "]", ")", "==", "1", ":", "\n", "                        ", "cur_pieces", "=", "cur_pieces", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                        ", "cur_pieces", "[", "0", "]", "=", "cur_pieces", "[", "0", "]", "[", "1", ":", "]", "\n", "", "", "cur_pieces", ".", "append", "(", "piece", "[", "-", "1", "]", ")", "\n", "new_pieces", ".", "extend", "(", "cur_pieces", ")", "\n", "", "else", ":", "\n", "                ", "new_pieces", ".", "append", "(", "piece", ")", "\n", "\n", "# note(zhiliny): convert back to unicode for py2", "\n", "", "", "if", "six", ".", "PY2", "and", "return_unicode", ":", "\n", "            ", "ret_pieces", "=", "[", "]", "\n", "for", "piece", "in", "new_pieces", ":", "\n", "                ", "if", "isinstance", "(", "piece", ",", "str", ")", ":", "\n", "                    ", "piece", "=", "piece", ".", "decode", "(", "'utf-8'", ")", "\n", "", "ret_pieces", ".", "append", "(", "piece", ")", "\n", "", "new_pieces", "=", "ret_pieces", "\n", "\n", "", "return", "new_pieces", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer._convert_token_to_id": [[168, 171], ["tokenization_xlnet.XLNetTokenizer.sp_model.PieceToId"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer._convert_id_to_token": [[172, 178], ["tokenization_xlnet.XLNetTokenizer.sp_model.IdToPiece", "isinstance", "token.decode.decode.decode"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ",", "return_unicode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "token", "=", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", ")", "\n", "if", "six", ".", "PY2", "and", "return_unicode", "and", "isinstance", "(", "token", ",", "str", ")", ":", "\n", "            ", "token", "=", "token", ".", "decode", "(", "'utf-8'", ")", "\n", "", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_string": [[179, 183], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "' '", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.build_inputs_with_special_tokens": [[184, 197], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "token_ids_0", "+", "sep", "+", "cls", "\n", "", "return", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "+", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.get_special_tokens_mask": [[198, 223], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", ",", "1", "]", "\n", "", "return", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.create_token_type_ids_from_sequences": [[224, 240], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A BERT sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2\n        | first sequence    | second sequence     | CLS segment ID\n        \n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "cls_segment_id", "=", "[", "2", "]", "\n", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "token_ids_0", "+", "sep", "+", "cls", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "+", "cls_segment_id", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlnet.XLNetTokenizer.save_vocabulary": [[241, 254], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFEmbeddings.__init__": [[69, 87], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFEmbeddings", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "self", ".", "word_embeddings", "=", "TFSharedEmbeddings", "(", "config", ".", "vocab_size", ",", "\n", "config", ".", "dim", ",", "\n", "initializer_range", "=", "config", ".", "initializer_range", ",", "\n", "name", "=", "'word_embeddings'", ")", "# padding_idx=0)", "\n", "self", ".", "position_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "dim", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'position_embeddings'", ")", "\n", "if", "config", ".", "sinusoidal_pos_embds", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFEmbeddings.build": [[88, 98], ["super().build", "tensorflow.name_scope", "modeling_tf_distilbert.TFEmbeddings.add_weight", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"word_embeddings\"", ")", ":", "\n", "# Create and initialize weights. The random normal initializer was chosen", "\n", "# arbitrarily, and works well.", "\n", "            ", "self", ".", "word_embeddings", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "[", "self", ".", "vocab_size", ",", "self", ".", "dim", "]", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ")", "\n", "", "super", "(", "TFEmbeddings", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFEmbeddings.call": [[99, 120], ["modeling_tf_distilbert.TFEmbeddings._embedding", "modeling_tf_distilbert.TFEmbeddings._linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._linear"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mode", "=", "\"embedding\"", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Get token embeddings of inputs.\n        Args:\n            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)\n            mode: string, a valid value is one of \"embedding\" and \"linear\".\n        Returns:\n            outputs: (1) If mode == \"embedding\", output embedding tensor, float32 with\n                shape [batch_size, length, embedding_size]; (2) mode == \"linear\", output\n                linear tensor, float32 with shape [batch_size, length, vocab_size].\n        Raises:\n            ValueError: if mode is not valid.\n        \n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "if", "mode", "==", "\"embedding\"", ":", "\n", "            ", "return", "self", ".", "_embedding", "(", "inputs", ",", "training", "=", "training", ")", "\n", "", "elif", "mode", "==", "\"linear\"", ":", "\n", "            ", "return", "self", ".", "_linear", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode {} is not valid.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFEmbeddings._embedding": [[121, 150], ["tensorflow.gather", "modeling_tf_distilbert.TFEmbeddings.position_embeddings", "modeling_tf_distilbert.TFEmbeddings.LayerNorm", "modeling_tf_distilbert.TFEmbeddings.dropout", "isinstance", "tensorflow.shape", "tensorflow.range"], "methods", ["None"], ["", "", "def", "_embedding", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        input_ids: tf.Tensor(bs, max_seq_length)\n            The token ids to embed.\n\n        Outputs\n        -------\n        embeddings: tf.Tensor(bs, max_seq_length, dim)\n            The embedded tokens (plus position embeddings, no token_type embeddings)\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "position_ids", "=", "None", "\n", "", "else", ":", "\n", "            ", "input_ids", ",", "position_ids", "=", "inputs", "\n", "\n", "", "seq_length", "=", "tf", ".", "shape", "(", "input_ids", ")", "[", "1", "]", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "seq_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "word_embeddings", "=", "tf", ".", "gather", "(", "self", ".", "word_embeddings", ",", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "# (bs, max_seq_length, dim)", "\n", "\n", "embeddings", "=", "word_embeddings", "+", "position_embeddings", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ",", "training", "=", "training", ")", "# (bs, max_seq_length, dim)", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFEmbeddings._linear": [[151, 165], ["tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "_linear", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Computes logits by running inputs through a linear layer.\n            Args:\n                inputs: A float32 tensor with shape [batch_size, length, hidden_size]\n            Returns:\n                float32 tensor with shape [batch_size, length, vocab_size].\n        \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "length", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "dim", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "word_embeddings", ",", "transpose_b", "=", "True", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "logits", ",", "[", "batch_size", ",", "length", ",", "self", ".", "vocab_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFMultiHeadSelfAttention.__init__": [[168, 192], ["super().__init__", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "set", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMultiHeadSelfAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_dropout", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"q_lin\"", ")", "\n", "self", ".", "k_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"k_lin\"", ")", "\n", "self", ".", "v_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"v_lin\"", ")", "\n", "self", ".", "out_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"out_lin\"", ")", "\n", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFMultiHeadSelfAttention.prune_heads": [[193, 195], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFMultiHeadSelfAttention.call": [[196, 255], ["modeling_tf_utils.shape_list", "modeling_tf_distilbert.TFMultiHeadSelfAttention.call.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        query: tf.Tensor(bs, seq_length, dim)\n        key: tf.Tensor(bs, seq_length, dim)\n        value: tf.Tensor(bs, seq_length, dim)\n        mask: tf.Tensor(bs, seq_length)\n\n        Outputs\n        -------\n        weights: tf.Tensor(bs, n_heads, seq_length, seq_length)\n            Attention weights\n        context: tf.Tensor(bs, seq_length, dim)\n            Contextualized layer. Optional: only if `output_attentions=True`\n        \"\"\"", "\n", "query", ",", "key", ",", "value", ",", "mask", ",", "head_mask", "=", "inputs", "\n", "bs", ",", "q_length", ",", "dim", "=", "shape_list", "(", "query", ")", "\n", "k_length", "=", "shape_list", "(", "key", ")", "[", "1", "]", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "# assert key.size() == value.size()", "\n", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "\n", "mask_reshape", "=", "[", "bs", ",", "1", ",", "1", ",", "k_length", "]", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\" separate heads \"\"\"", "\n", "return", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "x", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ")", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\" group heads \"\"\"", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "query", ")", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "key", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "value", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "\n", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "scores", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "# (bs, n_heads, q_length, k_length)", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "mask_reshape", ")", "# (bs, n_heads, qlen, klen)", "\n", "# scores.masked_fill_(mask, -float('inf'))            # (bs, n_heads, q_length, k_length)", "\n", "scores", "=", "scores", "-", "1e30", "*", "(", "1.0", "-", "mask", ")", "\n", "\n", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scores", ",", "axis", "=", "-", "1", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ",", "training", "=", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "tf", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, q_length, dim)", "\n", "context", "=", "self", ".", "out_lin", "(", "context", ")", "# (bs, q_length, dim)", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "(", "context", ",", "weights", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "context", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFFFN.__init__": [[257, 268], ["super().__init__", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFFFN", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "lin1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "hidden_dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"lin1\"", ")", "\n", "self", ".", "lin2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"lin2\"", ")", "\n", "assert", "config", ".", "activation", "in", "[", "'relu'", ",", "'gelu'", "]", ",", "\"activation ({}) must be in ['relu', 'gelu']\"", ".", "format", "(", "config", ".", "activation", ")", "\n", "self", ".", "activation", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "if", "config", ".", "activation", "==", "'gelu'", "else", "tf", ".", "keras", ".", "activations", ".", "relu", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFFFN.call": [[269, 275], ["modeling_tf_distilbert.TFFFN.lin1", "modeling_tf_distilbert.TFFFN.activation", "modeling_tf_distilbert.TFFFN.lin2", "modeling_tf_distilbert.TFFFN.dropout"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFTransformerBlock.__init__": [[278, 295], ["super().__init__", "tensorflow.keras.layers.Dropout", "modeling_tf_distilbert.TFMultiHeadSelfAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_distilbert.TFFFN", "tensorflow.keras.layers.LayerNormalization"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransformerBlock", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "hidden_dim", "=", "config", ".", "hidden_dim", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "activation", "=", "config", ".", "activation", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "config", ".", "dim", "%", "config", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "attention", "=", "TFMultiHeadSelfAttention", "(", "config", ",", "name", "=", "\"attention\"", ")", "\n", "self", ".", "sa_layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"sa_layer_norm\"", ")", "\n", "\n", "self", ".", "ffn", "=", "TFFFN", "(", "config", ",", "name", "=", "\"ffn\"", ")", "\n", "self", ".", "output_layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"output_layer_norm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFTransformerBlock.call": [[296, 329], ["modeling_tf_distilbert.TFTransformerBlock.attention", "modeling_tf_distilbert.TFTransformerBlock.sa_layer_norm", "modeling_tf_distilbert.TFTransformerBlock.ffn", "modeling_tf_distilbert.TFTransformerBlock.output_layer_norm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "# removed: src_enc=None, src_len=None", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: tf.Tensor(bs, seq_length, dim)\n        attn_mask: tf.Tensor(bs, seq_length)\n\n        Outputs\n        -------\n        sa_weights: tf.Tensor(bs, n_heads, seq_length, seq_length)\n            The attention weights\n        ffn_output: tf.Tensor(bs, seq_length, dim)\n            The output of the transformer block contextualization.\n        \"\"\"", "\n", "x", ",", "attn_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "# Self-Attention", "\n", "sa_output", "=", "self", ".", "attention", "(", "[", "x", ",", "x", ",", "x", ",", "attn_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "sa_output", ",", "sa_weights", "=", "sa_output", "# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)", "\n", "", "else", ":", "# To handle these `output_attention` or `output_hidden_states` cases returning tuples", "\n", "# assert type(sa_output) == tuple", "\n", "            ", "sa_output", "=", "sa_output", "[", "0", "]", "\n", "", "sa_output", "=", "self", ".", "sa_layer_norm", "(", "sa_output", "+", "x", ")", "# (bs, seq_length, dim)", "\n", "\n", "# Feed Forward Network", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "sa_output", ",", "training", "=", "training", ")", "# (bs, seq_length, dim)", "\n", "ffn_output", "=", "self", ".", "output_layer_norm", "(", "ffn_output", "+", "sa_output", ")", "# (bs, seq_length, dim)", "\n", "\n", "output", "=", "(", "ffn_output", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "output", "=", "(", "sa_weights", ",", ")", "+", "output", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFTransformer.__init__": [[332, 340], ["super().__init__", "modeling_tf_distilbert.TFTransformerBlock", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransformer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "layer", "=", "[", "TFTransformerBlock", "(", "config", ",", "name", "=", "'layer_._{}'", ".", "format", "(", "i", ")", ")", "\n", "for", "i", "in", "range", "(", "config", ".", "n_layers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFTransformer.call": [[341, 391], ["enumerate", "layer_module", "len", "len"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: tf.Tensor(bs, seq_length, dim)\n            Input sequence embedded.\n        attn_mask: tf.Tensor(bs, seq_length)\n            Attention mask on the sequence.\n\n        Outputs\n        -------\n        hidden_state: tf.Tensor(bs, seq_length, dim)\n            Sequence of hiddens states in the last (top) layer\n        all_hidden_states: Tuple[tf.Tensor(bs, seq_length, dim)]\n            Tuple of length n_layers with the hidden states from each layer.\n            Optional: only if output_hidden_states=True\n        all_attentions: Tuple[tf.Tensor(bs, n_heads, seq_length, seq_length)]\n            Tuple of length n_layers with the attention weights from each layer\n            Optional: only if output_attentions=True\n        \"\"\"", "\n", "x", ",", "attn_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "\n", "hidden_state", "=", "x", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "[", "hidden_state", ",", "attn_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_state", "=", "layer_outputs", "[", "-", "1", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "2", "\n", "attentions", "=", "layer_outputs", "[", "0", "]", "\n", "all_attentions", "=", "all_attentions", "+", "(", "attentions", ",", ")", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "1", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_state", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertMainLayer.__init__": [[394, 400], ["super().__init__", "modeling_tf_distilbert.TFEmbeddings", "modeling_tf_distilbert.TFTransformer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "num_hidden_layers", "\n", "\n", "self", ".", "embeddings", "=", "TFEmbeddings", "(", "config", ",", "name", "=", "\"embeddings\"", ")", "# Embeddings", "\n", "self", ".", "transformer", "=", "TFTransformer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "# Encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertMainLayer._resize_token_embeddings": [[401, 403], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertMainLayer._prune_heads": [[404, 406], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertMainLayer.call": [[407, 439], ["isinstance", "tensorflow.cast", "modeling_tf_distilbert.TFDistilBertMainLayer.embeddings", "modeling_tf_distilbert.TFDistilBertMainLayer.transformer", "isinstance", "tensorflow.ones", "len", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "head_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "3", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "3", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "tf", ".", "ones", "(", "shape_list", "(", "input_ids", ")", ")", "# (bs, seq_length)", "\n", "", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ")", "# (bs, seq_length, dim)", "\n", "tfmr_output", "=", "self", ".", "transformer", "(", "[", "embedding_output", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "\n", "return", "tfmr_output", "# last-layer hidden-state, (all hidden_states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertModel.__init__": [[540, 543], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "# Embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertModel.call": [[544, 547], ["modeling_tf_distilbert.TFDistilBertModel.distilbert"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertLMHead.__init__": [[550, 557], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertLMHead.build": [[558, 564], ["modeling_tf_distilbert.TFDistilBertLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'bias'", ")", "\n", "super", "(", "TFDistilBertLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertLMHead.call": [[565, 569], ["modeling_tf_distilbert.TFDistilBertLMHead.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertForMaskedLM.__init__": [[598, 611], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_distilbert.TFDistilBertLMHead", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "\n", "self", ".", "vocab_transform", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"vocab_transform\"", ")", "\n", "self", ".", "act", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "\n", "self", ".", "vocab_layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"vocab_layer_norm\"", ")", "\n", "self", ".", "vocab_projector", "=", "TFDistilBertLMHead", "(", "config", ",", "self", ".", "distilbert", ".", "embeddings", ",", "name", "=", "\"vocab_projector\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertForMaskedLM.call": [[612, 623], ["modeling_tf_distilbert.TFDistilBertForMaskedLM.distilbert", "modeling_tf_distilbert.TFDistilBertForMaskedLM.vocab_transform", "modeling_tf_distilbert.TFDistilBertForMaskedLM.act", "modeling_tf_distilbert.TFDistilBertForMaskedLM.vocab_layer_norm", "modeling_tf_distilbert.TFDistilBertForMaskedLM.vocab_projector"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "hidden_states", "=", "distilbert_output", "[", "0", "]", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_transform", "(", "hidden_states", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "act", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_layer_norm", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_projector", "(", "prediction_logits", ")", "\n", "\n", "outputs", "=", "(", "prediction_logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification.__init__": [[653, 666], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "\n", "self", ".", "pre_classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "name", "=", "\"pre_classifier\"", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"classifier\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "seq_classif_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification.call": [[667, 678], ["modeling_tf_distilbert.TFDistilBertForSequenceClassification.distilbert", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.pre_classifier", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.dropout", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "hidden_state", "=", "distilbert_output", "[", "0", "]", "# (bs, seq_len, dim)", "\n", "pooled_output", "=", "hidden_state", "[", ":", ",", "0", "]", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "pre_classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "# (bs, dim)", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertForQuestionAnswering.__init__": [[710, 719], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'qa_outputs'", ")", "\n", "assert", "config", ".", "num_labels", "==", "2", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "qa_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.TFDistilBertForQuestionAnswering.call": [[720, 732], ["modeling_tf_distilbert.TFDistilBertForQuestionAnswering.distilbert", "modeling_tf_distilbert.TFDistilBertForQuestionAnswering.dropout", "modeling_tf_distilbert.TFDistilBertForQuestionAnswering.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "hidden_states", "=", "distilbert_output", "[", "0", "]", "# (bs, max_query_len, dim)", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "# (bs, max_query_len, dim)", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "hidden_states", ")", "# (bs, max_query_len, 2)", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "return", "outputs", "# start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.gelu": [[45, 54], ["tensorflow.math.erf", "tensorflow.math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Gaussian Error Linear Unit.\n    Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "math", ".", "erf", "(", "x", "/", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_distilbert.gelu_new": [[55, 67], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["", "def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "\n", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFAttention.__init__": [[65, 82], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "set"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "TFConv1D", "(", "n_state", "*", "3", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_attn'", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_proj'", ")", "\n", "self", ".", "attn_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFAttention.prune_heads": [[83, 85], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFAttention.causal_attention_mask": [[86, 95], ["tensorflow.range", "tensorflow.cast", "tensorflow.range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"1's in the lower triangle, counting from the lower right corner.\n        Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n        \"\"\"", "\n", "i", "=", "tf", ".", "range", "(", "nd", ")", "[", ":", ",", "None", "]", "\n", "j", "=", "tf", ".", "range", "(", "ns", ")", "\n", "m", "=", "i", ">=", "j", "-", "ns", "+", "nd", "\n", "return", "tf", ".", "cast", "(", "m", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFAttention._attn": [[96, 125], ["tensorflow.matmul", "modeling_tf_utils.shape_list", "modeling_tf_openai.TFAttention.causal_attention_mask", "tensorflow.reshape", "tensorflow.nn.softmax", "modeling_tf_openai.TFAttention.attn_dropout", "tensorflow.cast", "tensorflow.matmul", "outputs.append", "tensorflow.math.sqrt", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.causal_attention_mask"], ["", "def", "_attn", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "q", ",", "k", ",", "v", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "# q, k, v have shape [batch, heads, sequence, features]", "\n", "w", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "dk", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "k", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "# scale attention_scores", "\n", "w", "=", "w", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "# w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.", "\n", "", "_", ",", "_", ",", "nd", ",", "ns", "=", "shape_list", "(", "w", ")", "\n", "b", "=", "self", ".", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", "=", "w", ".", "dtype", ")", "\n", "b", "=", "tf", ".", "reshape", "(", "b", ",", "[", "1", ",", "1", ",", "nd", ",", "ns", "]", ")", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "tf", ".", "nn", ".", "softmax", "(", "w", ",", "axis", "=", "-", "1", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "tf", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFAttention.merge_heads": [[126, 131], ["tensorflow.transpose", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "2", "]", "+", "[", "x_shape", "[", "-", "2", "]", "*", "x_shape", "[", "-", "1", "]", "]", "\n", "return", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFAttention.split_heads": [[132, 137], ["modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "split_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "n_head", ",", "x_shape", "[", "-", "1", "]", "//", "self", ".", "n_head", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFAttention.call": [[138, 156], ["modeling_tf_openai.TFAttention.c_attn", "tensorflow.split", "modeling_tf_openai.TFAttention.split_heads", "modeling_tf_openai.TFAttention.split_heads", "modeling_tf_openai.TFAttention.split_heads", "modeling_tf_openai.TFAttention._attn", "modeling_tf_openai.TFAttention.merge_heads", "modeling_tf_openai.TFAttention.c_proj", "modeling_tf_openai.TFAttention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.merge_heads"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "tf", ".", "split", "(", "x", ",", "3", ",", "axis", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "[", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "[", "a", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFMLP.__init__": [[159, 166], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMLP", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_fc'", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "nx", ",", "n_state", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_proj'", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFMLP.call": [[167, 172], ["modeling_tf_openai.TFMLP.act", "modeling_tf_openai.TFMLP.c_proj", "modeling_tf_openai.TFMLP.dropout", "modeling_tf_openai.TFMLP.c_fc"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ",", "training", "=", "False", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "h2", "=", "self", ".", "dropout", "(", "h2", ",", "training", "=", "training", ")", "\n", "return", "h2", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFBlock.__init__": [[175, 182], ["super().__init__", "modeling_tf_openai.TFAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_openai.TFMLP", "tensorflow.keras.layers.LayerNormalization"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBlock", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "attn", "=", "TFAttention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ",", "name", "=", "'attn'", ")", "\n", "self", ".", "ln_1", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "'ln_1'", ")", "\n", "self", ".", "mlp", "=", "TFMLP", "(", "4", "*", "nx", ",", "config", ",", "name", "=", "'mlp'", ")", "\n", "self", ".", "ln_2", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "'ln_2'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFBlock.call": [[183, 195], ["modeling_tf_openai.TFBlock.attn", "modeling_tf_openai.TFBlock.ln_1", "modeling_tf_openai.TFBlock.mlp", "modeling_tf_openai.TFBlock.ln_2"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "output_attn", "=", "self", ".", "attn", "(", "[", "x", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, (attentions)", "\n", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ",", "training", "=", "training", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "\n", "outputs", "=", "[", "h", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer.__init__": [[198, 219], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Dropout", "modeling_tf_openai.TFBlock", "modeling_tf_utils.get_initializer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTMainLayer", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "n_layer", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "\n", "self", ".", "tokens_embed", "=", "TFSharedEmbeddings", "(", "config", ".", "vocab_size", ",", "\n", "config", ".", "n_embd", ",", "\n", "initializer_range", "=", "config", ".", "initializer_range", ",", "\n", "name", "=", "'tokens_embed'", ")", "\n", "self", ".", "positions_embed", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "config", ".", "n_positions", ",", "\n", "config", ".", "n_embd", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'positions_embed'", ")", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "[", "TFBlock", "(", "config", ".", "n_ctx", ",", "\n", "config", ",", "\n", "scale", "=", "True", ",", "\n", "name", "=", "'h_._{}'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer._resize_token_embeddings": [[220, 222], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer._prune_heads": [[223, 228], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer.call": [[229, 321], ["isinstance", "modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.reshape", "modeling_tf_openai.TFOpenAIGPTMainLayer.tokens_embed", "modeling_tf_openai.TFOpenAIGPTMainLayer.positions_embed", "modeling_tf_openai.TFOpenAIGPTMainLayer.drop", "enumerate", "tensorflow.reshape", "isinstance", "tensorflow.cast", "tensorflow.reshape", "modeling_tf_openai.TFOpenAIGPTMainLayer.tokens_embed", "block", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "tensorflow.range", "tuple.append", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "shape_list", "(", "input_ids", ")", "[", "-", "1", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "not", "head_mask", "is", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "[", "-", "1", ",", "input_shape", "[", "-", "1", "]", "]", ")", "\n", "position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "[", "-", "1", ",", "shape_list", "(", "position_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "tokens_embed", "(", "input_ids", ",", "mode", "=", "'embedding'", ")", "\n", "position_embeds", "=", "self", ".", "positions_embed", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "[", "-", "1", ",", "shape_list", "(", "token_type_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "tokens_embed", "(", "token_type_ids", ",", "mode", "=", "'embedding'", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "[", "shape_list", "(", "hidden_states", ")", "[", "-", "1", "]", "]", "\n", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "h", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "1", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "[", "-", "1", "]", "+", "shape_list", "(", "all_attentions", "[", "0", "]", ")", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "tf", ".", "reshape", "(", "t", ",", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTModel.__init__": [[421, 424], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_openai.TFOpenAIGPTMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFOpenAIGPTMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTModel.call": [[425, 428], ["modeling_tf_openai.TFOpenAIGPTModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTLMHeadModel.__init__": [[457, 460], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_openai.TFOpenAIGPTMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFOpenAIGPTMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTLMHeadModel.call": [[461, 470], ["modeling_tf_openai.TFOpenAIGPTLMHeadModel.transformer", "modeling_tf_openai.TFOpenAIGPTLMHeadModel.transformer.tokens_embed"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "tokens_embed", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm_logits, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.__init__": [[518, 522], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_openai.TFOpenAIGPTMainLayer", "modeling_tf_utils.TFSequenceSummary"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTDoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFOpenAIGPTMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "multiple_choice_head", "=", "TFSequenceSummary", "(", "config", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'multiple_choice_head'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.call": [[523, 567], ["isinstance", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.transformer", "tensorflow.reshape", "modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.transformer.tokens_embed", "modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.multiple_choice_head", "tensorflow.squeeze", "isinstance", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "len", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "mc_token_ids", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "mc_token_ids", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "mc_token_ids", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "mc_token_ids", "=", "inputs", ".", "get", "(", "'mc_token_ids'", ",", "mc_token_ids", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "input_shapes", "=", "shape_list", "(", "input_ids", ")", "\n", "\n", "seq_length", "=", "input_shapes", "[", "-", "1", "]", "\n", "\n", "flat_input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "\n", "flat_attention_mask", "=", "tf", ".", "reshape", "(", "attention_mask", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "flat_inputs", "=", "[", "flat_input_ids", ",", "flat_attention_mask", ",", "flat_token_type_ids", ",", "flat_position_ids", ",", "head_mask", "]", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "flat_inputs", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "input_shapes", "+", "shape_list", "(", "hidden_states", ")", "[", "-", "1", ":", "]", ")", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "tokens_embed", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "[", "hidden_states", ",", "mc_token_ids", "]", ",", "training", "=", "training", ")", "\n", "\n", "mc_logits", "=", "tf", ".", "squeeze", "(", "mc_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm logits, mc logits, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.gelu": [[41, 53], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "\n", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_openai.swish": [[55, 57], ["tensorflow.math.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "tf", ".", "math", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFPositionalEmbedding.__init__": [[44, 48], ["super().__init__", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "tf", ".", "range", "(", "0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFPositionalEmbedding.call": [[49, 57], ["tensorflow.einsum", "tensorflow.concat", "tensorflow.tile", "tensorflow.sin", "tensorflow.cos"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "tf", ".", "einsum", "(", "'i,j->ij'", ",", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "sinusoid_inp", ")", ",", "tf", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "tf", ".", "tile", "(", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ",", "[", "1", ",", "bsz", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFPositionwiseFF.__init__": [[60, 80], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ",", "layer_norm_epsilon", "=", "1e-5", ",", "init_std", "=", "0.02", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFPositionwiseFF", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "layer_1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_inner", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "'CoreNet_._0'", ")", "\n", "self", ".", "drop_1", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "\n", "name", "=", "'CoreNet_._3'", ")", "\n", "self", ".", "drop_2", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "'layer_norm'", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFPositionwiseFF.call": [[81, 103], ["modeling_tf_transfo_xl.TFPositionwiseFF.layer_norm", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_1", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_1", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_2", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_2", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_1", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_1", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_2", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_2", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inp", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "layer_norm", "(", "inp", ")", "\n", "core_out", "=", "self", ".", "layer_1", "(", "core_out", ")", "\n", "core_out", "=", "self", ".", "drop_1", "(", "core_out", ",", "training", "=", "training", ")", "\n", "core_out", "=", "self", ".", "layer_2", "(", "core_out", ")", "\n", "core_out", "=", "self", ".", "drop_2", "(", "core_out", ",", "training", "=", "training", ")", "\n", "\n", "##### residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "##### positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "layer_1", "(", "inp", ")", "\n", "core_out", "=", "self", ".", "drop_1", "(", "core_out", ",", "training", "=", "training", ")", "\n", "core_out", "=", "self", ".", "layer_2", "(", "core_out", ")", "\n", "core_out", "=", "self", ".", "drop_2", "(", "core_out", ",", "training", "=", "training", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.__init__": [[106, 147], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "pre_lnorm", "=", "False", ",", "\n", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ",", "output_attentions", "=", "False", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "init_std", "=", "0.02", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "3", "*", "n_head", "*", "d_head", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "\n", "use_bias", "=", "False", ",", "\n", "name", "=", "'qkv_net'", ")", "\n", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "\n", "use_bias", "=", "False", ",", "\n", "name", "=", "'o_net'", ")", "\n", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "'layer_norm'", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "not", "None", "and", "r_w_bias", "is", "not", "None", ":", "# Biases are shared", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "None", "\n", "self", ".", "r_w_bias", "=", "None", "\n", "\n", "", "self", ".", "r_net", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "\n", "use_bias", "=", "False", ",", "\n", "name", "=", "'r_net'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.build": [[148, 159], ["super().build", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.add_weight", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.add_weight"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "r_r_bias", "is", "None", "or", "self", ".", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'r_r_bias'", ")", "\n", "self", ".", "r_w_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'r_w_bias'", ")", "\n", "", "super", "(", "TFRelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn._rel_shift": [[160, 169], ["modeling_tf_utils.shape_list", "tensorflow.pad", "tensorflow.reshape", "tensorflow.slice", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "_rel_shift", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_size", "=", "shape_list", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "x_size", "[", "1", "]", "+", "1", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", "]", ")", "\n", "x", "=", "tf", ".", "slice", "(", "x", ",", "[", "1", ",", "0", ",", "0", ",", "0", "]", ",", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "x_size", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.call": [[170, 249], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.einsum", "tensorflow.einsum", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn._rel_shift", "tensorflow.nn.softmax", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.dropatt", "tensorflow.einsum", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.o_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.drop", "tensorflow.concat", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.r_net", "tensorflow.split", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.r_net", "tensorflow.split", "modeling_tf_utils.shape_list", "outputs.append", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.layer_norm", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.layer_norm", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.layer_norm"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "w", ",", "r", ",", "attn_mask", ",", "mems", ",", "head_mask", "=", "inputs", "\n", "qlen", ",", "rlen", ",", "bsz", "=", "shape_list", "(", "w", ")", "[", "0", "]", ",", "shape_list", "(", "r", ")", "[", "0", "]", ",", "shape_list", "(", "w", ")", "[", "1", "]", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "tf", ".", "split", "(", "w_heads", ",", "3", ",", "axis", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "tf", ".", "split", "(", "w_heads", ",", "3", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "shape_list", "(", "w_head_k", ")", "[", "0", "]", "\n", "\n", "w_head_q", "=", "tf", ".", "reshape", "(", "w_head_q", ",", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "tf", ".", "reshape", "(", "w_head_k", ",", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "tf", ".", "reshape", "(", "w_head_v", ",", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "tf", ".", "reshape", "(", "r_head_k", ",", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "self", ".", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "tf", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "rw_head_q", ",", "w_head_k", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "self", ".", "r_r_bias", "\n", "BD", "=", "tf", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "rr_head_q", ",", "r_head_k", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", "=", "attn_score", "*", "self", ".", "scale", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask_t", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "attn_score", "=", "attn_score", "*", "(", "1", "-", "attn_mask_t", ")", "-", "1e30", "*", "attn_mask_t", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "attn_prob", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_score", ",", "axis", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "#### compute attention vector", "\n", "", "attn_vec", "=", "tf", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "attn_prob", ",", "w_head_v", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec_sizes", "=", "shape_list", "(", "attn_vec", ")", "\n", "attn_vec", "=", "tf", ".", "reshape", "(", "attn_vec", ",", "\n", "(", "attn_vec_sizes", "[", "0", "]", ",", "attn_vec_sizes", "[", "1", "]", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ",", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "outputs", "=", "[", "w", "+", "attn_out", "]", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "outputs", "=", "[", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "]", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "attn_prob", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.__init__": [[252, 273], ["super().__init__", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn", "modeling_tf_transfo_xl.TFPositionwiseFF"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "\n", "dropatt", "=", "0.", ",", "pre_lnorm", "=", "False", ",", "\n", "r_w_bias", "=", "None", ",", "\n", "r_r_bias", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "init_std", "=", "0.02", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "dec_attn", "=", "TFRelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "tgt_len", "=", "tgt_len", ",", "ext_len", "=", "ext_len", ",", "\n", "mem_len", "=", "mem_len", ",", "dropatt", "=", "dropatt", ",", "pre_lnorm", "=", "pre_lnorm", ",", "\n", "r_w_bias", "=", "r_w_bias", ",", "r_r_bias", "=", "r_r_bias", ",", "init_std", "=", "init_std", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "layer_norm_epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "'dec_attn'", ")", "\n", "self", ".", "pos_ff", "=", "TFPositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "pre_lnorm", ",", "init_std", "=", "init_std", ",", "\n", "layer_norm_epsilon", "=", "layer_norm_epsilon", ",", "\n", "name", "=", "'pos_ff'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.call": [[274, 283], ["modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.dec_attn", "modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "dec_inp", ",", "r", ",", "dec_attn_mask", ",", "mems", ",", "head_mask", "=", "inputs", "\n", "attn_outputs", "=", "self", ".", "dec_attn", "(", "[", "dec_inp", ",", "r", ",", "dec_attn_mask", ",", "\n", "mems", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "ff_output", "=", "self", ".", "pos_ff", "(", "attn_outputs", "[", "0", "]", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "[", "ff_output", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFAdaptiveEmbedding.__init__": [[286, 314], ["super().__init__", "range", "len", "modeling_tf_transfo_xl.TFAdaptiveEmbedding.emb_layers.append", "tensorflow.keras.layers.Embedding", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "init_std", "=", "0.02", ",", "\n", "sample_softmax", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "self", ".", "emb_layers", "=", "[", "]", "\n", "self", ".", "emb_projs", "=", "[", "]", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "\n", "d_emb_i", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "\n", "name", "=", "'emb_layers_._{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFAdaptiveEmbedding.build": [[315, 323], ["range", "super().build", "len", "modeling_tf_transfo_xl.TFAdaptiveEmbedding.emb_projs.append", "modeling_tf_transfo_xl.TFAdaptiveEmbedding.add_weight", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["", "", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "d_emb_i", "=", "self", ".", "d_embed", "//", "(", "self", ".", "div_val", "**", "i", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "self", ".", "add_weight", "(", "shape", "=", "(", "d_emb_i", ",", "self", ".", "d_proj", ")", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "init_std", ")", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'emb_projs_._{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "", "super", "(", "TFAdaptiveEmbedding", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFAdaptiveEmbedding.call": [[324, 348], ["tensorflow.reshape", "tensorflow.zeros", "range", "tensorflow.reshape", "len", "tensorflow.einsum", "tensorflow.cast", "tensorflow.scatter_nd", "modeling_tf_utils.shape_list", "tensorflow.boolean_mask", "tensorflow.where", "tensorflow.cast", "modeling_tf_utils.shape_list", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "", "else", ":", "\n", "            ", "inp_flat", "=", "tf", ".", "reshape", "(", "inp", ",", "(", "-", "1", ",", ")", ")", "\n", "emb_flat", "=", "tf", ".", "zeros", "(", "[", "shape_list", "(", "inp_flat", ")", "[", "0", "]", ",", "self", ".", "d_proj", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "\n", "mask_i", "=", "(", "inp_flat", ">=", "l_idx", ")", "&", "(", "inp_flat", "<", "r_idx", ")", "\n", "\n", "inp_i", "=", "tf", ".", "boolean_mask", "(", "inp_flat", ",", "mask_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "inp_i", ")", "\n", "emb_i", "=", "tf", ".", "einsum", "(", "'id,de->ie'", ",", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "\n", "mask_idx", "=", "tf", ".", "cast", "(", "tf", ".", "where", "(", "mask_i", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "emb_flat", "+=", "tf", ".", "scatter_nd", "(", "mask_idx", ",", "emb_i", ",", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "emb_flat", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "\n", "", "embed_shape", "=", "shape_list", "(", "inp", ")", "+", "[", "self", ".", "d_proj", "]", "\n", "embed", "=", "tf", ".", "reshape", "(", "emb_flat", ",", "embed_shape", ")", "\n", "\n", "", "embed", "*=", "self", ".", "emb_scale", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.__init__": [[351, 403], ["super().__init__", "modeling_tf_transfo_xl.TFAdaptiveEmbedding", "tensorflow.keras.layers.Dropout", "range", "modeling_tf_transfo_xl.TFPositionalEmbedding", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.layers.append", "modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransfoXLMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "n_token", "=", "config", ".", "n_token", "\n", "\n", "self", ".", "d_embed", "=", "config", ".", "d_embed", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "untie_r", "=", "config", ".", "untie_r", "\n", "\n", "self", ".", "word_emb", "=", "TFAdaptiveEmbedding", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "\n", "div_val", "=", "config", ".", "div_val", ",", "init_std", "=", "config", ".", "init_std", ",", "name", "=", "'word_emb'", ")", "\n", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "config", ".", "tgt_len", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "ext_len", "=", "config", ".", "ext_len", "\n", "self", ".", "max_klen", "=", "config", ".", "tgt_len", "+", "config", ".", "ext_len", "+", "config", ".", "mem_len", "\n", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "\n", "self", ".", "layers", "=", "[", "]", "\n", "if", "config", ".", "attn_type", "==", "0", ":", "# the default attention", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "TFRelPartialLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "self", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "self", ".", "untie_r", "else", "self", ".", "r_r_bias", ",", "\n", "output_attentions", "=", "self", ".", "output_attentions", ",", "\n", "layer_norm_epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "\n", "init_std", "=", "config", ".", "init_std", ",", "\n", "name", "=", "'layers_._{}'", ".", "format", "(", "i", ")", ")", "\n", ")", "\n", "", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default attention", "\n", "            ", "self", ".", "pos_emb", "=", "TFPositionalEmbedding", "(", "self", ".", "d_model", ",", "name", "=", "'pos_emb'", ")", "\n", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.build": [[404, 415], ["super().build", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.add_weight", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.add_weight"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "not", "self", ".", "untie_r", ":", "\n", "            ", "self", ".", "r_w_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'r_w_bias'", ")", "\n", "self", ".", "r_r_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'r_r_bias'", ")", "\n", "", "super", "(", "TFTransfoXLMainLayer", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer._resize_token_embeddings": [[416, 418], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "return", "self", ".", "word_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.backward_compatible": [[419, 421], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.reset_length": [[422, 426], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer._prune_heads": [[427, 429], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.init_mems": [[430, 440], ["range", "tensorflow.zeros", "mems.append", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", ")", ":", "\n", "                ", "empty", "=", "tf", ".", "zeros", "(", "[", "self", ".", "mem_len", ",", "shape_list", "(", "data", ")", "[", "1", "]", ",", "self", ".", "d_model", "]", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer._update_mems": [[441, 463], ["max", "range", "len", "len", "max", "len", "tensorflow.concat", "tensorflow.stop_gradient", "new_mems.append"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "            ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "axis", "=", "0", ")", "\n", "tf", ".", "stop_gradient", "(", "cat", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ")", "\n", "\n", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.call": [[464, 563], ["isinstance", "tensorflow.transpose", "modeling_tf_utils.shape_list", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.word_emb", "tensorflow.ones", "tensorflow.linalg.band_part", "tensorflow.linalg.band_part", "tensorflow.zeros", "tensorflow.concat", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.drop", "modeling_tf_transfo_xl.TFTransfoXLMainLayer._update_mems", "isinstance", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.init_mems", "tensorflow.linalg.band_part", "tensorflow.concat", "tensorflow.range", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.pos_emb", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.drop", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.drop", "enumerate", "tensorflow.transpose", "list.append", "list", "outputs.append", "list", "outputs.append", "len", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "tensorflow.minimum", "list.append", "layer", "len", "len", "len", "list.append", "tensorflow.transpose", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel._update_mems", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "mems", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "mems", "\n", "head_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "3", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "mems", "=", "inputs", ".", "get", "(", "'mems'", ",", "mems", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "3", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "# the original code for Transformer-XL used shapes [len, bsz] but we want a unified interface in the library", "\n", "# so we transpose here from shape [bsz, len] to shape [len, bsz]", "\n", "", "input_ids", "=", "tf", ".", "transpose", "(", "input_ids", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "\n", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", "input_ids", ")", "\n", "\n", "", "qlen", ",", "bsz", "=", "shape_list", "(", "input_ids", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "not", "head_mask", "is", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "word_emb", "=", "self", ".", "word_emb", "(", "input_ids", ")", "\n", "\n", "mlen", "=", "shape_list", "(", "mems", "[", "0", "]", ")", "[", "0", "]", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "attn_mask", "=", "tf", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ")", "\n", "mask_u", "=", "tf", ".", "linalg", ".", "band_part", "(", "attn_mask", ",", "0", ",", "-", "1", ")", "\n", "mask_dia", "=", "tf", ".", "linalg", ".", "band_part", "(", "attn_mask", ",", "0", ",", "0", ")", "\n", "attn_mask_pad", "=", "tf", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", "\n", "dec_attn_mask", "=", "tf", ".", "concat", "(", "[", "attn_mask_pad", ",", "mask_u", "-", "mask_dia", "]", ",", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_l", "=", "tf", ".", "linalg", ".", "band_part", "(", "attn_mask", ",", "-", "1", ",", "0", ")", "\n", "dec_attn_mask", "=", "tf", ".", "concat", "(", "[", "dec_attn_mask", "[", ":", ",", ":", "qlen", "]", "+", "mask_l", "-", "mask_dia", ",", "\n", "dec_attn_mask", "[", ":", ",", "qlen", ":", "]", "]", ",", "1", ")", "\n", "# ::: PyTorch masking code for reference :::", "\n", "# if self.same_length:", "\n", "#     all_ones = word_emb.new_ones((qlen, klen), dtype=torch.uint8)", "\n", "#     mask_len = klen - self.mem_len", "\n", "#     if mask_len > 0:", "\n", "#         mask_shift_len = qlen - mask_len", "\n", "#     else:", "\n", "#         mask_shift_len = qlen", "\n", "#     dec_attn_mask = (torch.triu(all_ones, 1+mlen)", "\n", "#             + torch.tril(all_ones, -mask_shift_len))[:, :, None] # -1", "\n", "# else:", "\n", "#     dec_attn_mask = torch.triu(", "\n", "#         word_emb.new_ones((qlen, klen), dtype=torch.uint8), diagonal=1+mlen)[:,:,None]", "\n", "\n", "", "hids", "=", "[", "]", "\n", "attentions", "=", "[", "]", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default", "\n", "            ", "pos_seq", "=", "tf", ".", "range", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", "=", "tf", ".", "minimum", "(", "pos_seq", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ",", "training", "=", "training", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ",", "training", "=", "training", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "layer_outputs", "=", "layer", "(", "[", "core_out", ",", "pos_emb", ",", "dec_attn_mask", ",", "\n", "mems_i", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "", "", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ",", "training", "=", "training", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "# We transpose back here to shape [bsz, len, hidden_dim]", "\n", "outputs", "=", "[", "tf", ".", "transpose", "(", "core_out", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", ",", "new_mems", "]", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "# Add last layer and transpose to library standard shape [bsz, len, hidden_dim]", "\n", "            ", "hids", ".", "append", "(", "core_out", ")", "\n", "hids", "=", "list", "(", "tf", ".", "transpose", "(", "t", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "for", "t", "in", "hids", ")", "\n", "outputs", ".", "append", "(", "hids", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# Transpose to library standard shape [bsz, n_heads, query_seq_len, key_seq_len]", "\n", "            ", "attentions", "=", "list", "(", "tf", ".", "transpose", "(", "t", ",", "perm", "=", "(", "2", ",", "3", ",", "0", ",", "1", ")", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", ".", "append", "(", "attentions", ")", "\n", "", "return", "outputs", "# last hidden state, new_mems, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLModel.__init__": [[662, 665], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_transfo_xl.TFTransfoXLMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransfoXLModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFTransfoXLMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLModel.call": [[666, 669], ["modeling_tf_transfo_xl.TFTransfoXLModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.__init__": [[704, 715], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_transfo_xl.TFTransfoXLMainLayer", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TFTransfoXLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "TFTransfoXLMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "sample_softmax", "=", "config", ".", "sample_softmax", "\n", "# use sampled softmax", "\n", "if", "config", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# use adaptive softmax (including standard softmax)", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "TFAdaptiveSoftmaxMask", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "\n", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", ",", "name", "=", "'crit'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.reset_length": [[716, 718], ["modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.transformer.reset_length"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length"], ["", "", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "reset_length", "(", "tgt_len", ",", "ext_len", ",", "mem_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.init_mems": [[719, 721], ["modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.transformer.init_mems"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "init_mems", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.call": [[722, 754], ["isinstance", "modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.transformer", "isinstance", "modeling_tf_utils.shape_list", "modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.crit", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "mems", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "mems", "\n", "head_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "head_mask", "\n", "labels", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "labels", "\n", "assert", "len", "(", "inputs", ")", "<=", "4", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "mems", "=", "inputs", ".", "get", "(", "'mems'", ",", "mems", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "labels", "=", "inputs", ".", "get", "(", "'labels'", ",", "labels", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "4", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "bsz", ",", "tgt_len", "=", "shape_list", "(", "input_ids", ")", "[", ":", "2", "]", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "[", "input_ids", ",", "mems", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "\n", "last_hidden", "=", "transformer_outputs", "[", "0", "]", "\n", "pred_hid", "=", "last_hidden", "[", ":", ",", "-", "tgt_len", ":", "]", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "self", ".", "sample_softmax", ">", "0", "and", "training", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "# pred_hid = tf.reshape(pred_hid, (-1, shape_list(pred_hid)[-1]))", "\n", "            ", "softmax_output", "=", "self", ".", "crit", "(", "[", "pred_hid", ",", "labels", "]", ",", "training", "=", "training", ")", "\n", "# softmax_output = tf.reshape(softmax_output, (bsz, tgt_len, -1))", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "\n", "", "return", "outputs", "# logits, new_mems, (all hidden states), (all attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaEmbeddings.__init__": [[45, 48], ["modeling_tf_bert.TFBertEmbeddings.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaEmbeddings._embedding": [[49, 58], ["super()._embedding", "tensorflow.shape", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._embedding"], ["", "def", "_embedding", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Applies embedding based on inputs tensor.\"\"\"", "\n", "input_ids", ",", "position_ids", ",", "token_type_ids", "=", "inputs", "\n", "\n", "seq_length", "=", "tf", ".", "shape", "(", "input_ids", ")", "[", "1", "]", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "self", ".", "padding_idx", "+", "1", ",", "seq_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "return", "super", "(", "TFRobertaEmbeddings", ",", "self", ")", ".", "_embedding", "(", "[", "input_ids", ",", "position_ids", ",", "token_type_ids", "]", ",", "training", "=", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaMainLayer.__init__": [[64, 67], ["modeling_tf_bert.TFBertMainLayer.__init__", "modeling_tf_roberta.TFRobertaEmbeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaMainLayer", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "embeddings", "=", "TFRobertaEmbeddings", "(", "config", ",", "name", "=", "'embeddings'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaMainLayer.call": [[68, 83], ["isinstance", "tensorflow.not_equal", "super().call", "isinstance", "tensorflow.reduce_sum", "tensorflow.print", "inputs.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.call"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "# Check that input_ids starts with control token", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "tf", ".", "not_equal", "(", "tf", ".", "reduce_sum", "(", "input_ids", "[", ":", ",", "0", "]", ")", ",", "0", ")", ":", "\n", "            ", "tf", ".", "print", "(", "\"A sequence with no special tokens has been passed to the RoBERTa model. \"", "\n", "\"This model requires special tokens in order to work. \"", "\n", "\"Please specify add_special_tokens=True in your encoding.\"", ")", "\n", "\n", "", "return", "super", "(", "TFRobertaMainLayer", ",", "self", ")", ".", "call", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaModel.__init__": [[212, 215], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "'roberta'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaModel.call": [[216, 219], ["modeling_tf_roberta.TFRobertaModel.roberta"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaLMHead.__init__": [[223, 235], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Activation", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'dense'", ")", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'layer_norm'", ")", "\n", "self", ".", "act", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaLMHead.build": [[236, 242], ["modeling_tf_roberta.TFRobertaLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'bias'", ")", "\n", "super", "(", "TFRobertaLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaLMHead.call": [[243, 252], ["modeling_tf_roberta.TFRobertaLMHead.dense", "modeling_tf_roberta.TFRobertaLMHead.act", "modeling_tf_roberta.TFRobertaLMHead.layer_norm", "modeling_tf_roberta.TFRobertaLMHead.decoder"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "features", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ",", "mode", "=", "\"linear\"", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaForMaskedLM.__init__": [[289, 294], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer", "modeling_tf_roberta.TFRobertaLMHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "\"roberta\"", ")", "\n", "self", ".", "lm_head", "=", "TFRobertaLMHead", "(", "config", ",", "self", ".", "roberta", ".", "embeddings", ",", "name", "=", "\"lm_head\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaForMaskedLM.call": [[295, 304], ["modeling_tf_roberta.TFRobertaForMaskedLM.roberta", "modeling_tf_roberta.TFRobertaForMaskedLM.lm_head"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaClassificationHead.__init__": [[309, 319], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaClassificationHead", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "activation", "=", "'tanh'", ",", "\n", "name", "=", "\"dense\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"out_proj\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaClassificationHead.call": [[320, 327], ["modeling_tf_roberta.TFRobertaClassificationHead.dropout", "modeling_tf_roberta.TFRobertaClassificationHead.dense", "modeling_tf_roberta.TFRobertaClassificationHead.dropout", "modeling_tf_roberta.TFRobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "features", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaForSequenceClassification.__init__": [[358, 364], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer", "modeling_tf_roberta.TFRobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "\"roberta\"", ")", "\n", "self", ".", "classifier", "=", "TFRobertaClassificationHead", "(", "config", ",", "name", "=", "\"classifier\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaForSequenceClassification.call": [[365, 374], ["modeling_tf_roberta.TFRobertaForSequenceClassification.roberta", "modeling_tf_roberta.TFRobertaForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaForTokenClassification.__init__": [[404, 413], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "'roberta'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'classifier'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_roberta.TFRobertaForTokenClassification.call": [[414, 425], ["modeling_tf_roberta.TFRobertaForTokenClassification.roberta", "modeling_tf_roberta.TFRobertaForTokenClassification.dropout", "modeling_tf_roberta.TFRobertaForTokenClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# scores, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_xlnet_original_tf_checkpoint_to_pytorch.convert_xlnet_checkpoint_to_pytorch": [[46, 73], ["transformers.XLNetConfig.from_json_file", "transformers.load_tf_weights_in_xlnet", "os.path.join", "os.path.join", "print", "torch.save", "print", "finetuning_task.lower", "print", "transformers.XLNetForSequenceClassification", "transformers.XLNetLMHeadModel.state_dict", "open", "f.write", "transformers.XLNetForQuestionAnswering", "transformers.XLNetLMHeadModel", "os.path.abspath", "os.path.abspath", "XLNetConfig.from_json_file.to_json_string", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.load_tf_weights_in_xlnet", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["def", "convert_xlnet_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_folder_path", ",", "finetuning_task", "=", "None", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "XLNetConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "\n", "finetuning_task", "=", "finetuning_task", ".", "lower", "(", ")", "if", "finetuning_task", "is", "not", "None", "else", "\"\"", "\n", "if", "finetuning_task", "in", "GLUE_TASKS_NUM_LABELS", ":", "\n", "        ", "print", "(", "\"Building PyTorch XLNetForSequenceClassification model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "config", ".", "finetuning_task", "=", "finetuning_task", "\n", "config", ".", "num_labels", "=", "GLUE_TASKS_NUM_LABELS", "[", "finetuning_task", "]", "\n", "model", "=", "XLNetForSequenceClassification", "(", "config", ")", "\n", "", "elif", "'squad'", "in", "finetuning_task", ":", "\n", "        ", "config", ".", "finetuning_task", "=", "finetuning_task", "\n", "model", "=", "XLNetForQuestionAnswering", "(", "config", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "XLNetLMHeadModel", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.Embeddings.__init__": [[63, 75], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "modeling_distilbert.create_sinusoidal_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.create_sinusoidal_embeddings"], ["    ", "def", "__init__", "(", "self", ",", "\n", "config", ")", ":", "\n", "        ", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "dim", ")", "\n", "if", "config", ".", "sinusoidal_pos_embds", ":", "\n", "            ", "create_sinusoidal_embeddings", "(", "n_pos", "=", "config", ".", "max_position_embeddings", ",", "\n", "dim", "=", "config", ".", "dim", ",", "\n", "out", "=", "self", ".", "position_embeddings", ".", "weight", ")", "\n", "\n", "", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.Embeddings.forward": [[76, 99], ["input_ids.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling_distilbert.Embeddings.word_embeddings", "modeling_distilbert.Embeddings.position_embeddings", "modeling_distilbert.Embeddings.LayerNorm", "modeling_distilbert.Embeddings.dropout", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        input_ids: torch.tensor(bs, max_seq_length)\n            The token ids to embed.\n\n        Outputs\n        -------\n        embeddings: torch.tensor(bs, max_seq_length, dim)\n            The embedded tokens (plus position embeddings, no token_type embeddings)\n        \"\"\"", "\n", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "# (max_seq_length)", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "# (bs, max_seq_length)", "\n", "\n", "word_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "# (bs, max_seq_length, dim)", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "# (bs, max_seq_length, dim)", "\n", "\n", "embeddings", "=", "word_embeddings", "+", "position_embeddings", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "# (bs, max_seq_length, dim)", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.MultiHeadSelfAttention.__init__": [[101, 117], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "set"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultiHeadSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", ".", "attention_dropout", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "self", ".", "k_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "self", ".", "v_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "self", ".", "out_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.MultiHeadSelfAttention.prune_heads": [[118, 138], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_distilbert.MultiHeadSelfAttention.pruned_heads.union", "len", "set", "sum", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "attention_head_size", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_heads", ",", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "head", "-=", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q_lin", "=", "prune_linear_layer", "(", "self", ".", "q_lin", ",", "index", ")", "\n", "self", ".", "k_lin", "=", "prune_linear_layer", "(", "self", ".", "k_lin", ",", "index", ")", "\n", "self", ".", "v_lin", "=", "prune_linear_layer", "(", "self", ".", "v_lin", ",", "index", ")", "\n", "self", ".", "out_lin", "=", "prune_linear_layer", "(", "self", ".", "out_lin", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "dim", "=", "attention_head_size", "*", "self", ".", "n_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.MultiHeadSelfAttention.forward": [[139, 196], ["query.size", "key.size", "modeling_distilbert.MultiHeadSelfAttention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        query: torch.tensor(bs, seq_length, dim)\n        key: torch.tensor(bs, seq_length, dim)\n        value: torch.tensor(bs, seq_length, dim)\n        mask: torch.tensor(bs, seq_length)\n\n        Outputs\n        -------\n        weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n            Attention weights\n        context: torch.tensor(bs, seq_length, dim)\n            Contextualized layer. Optional: only if `output_attentions=True`\n        \"\"\"", "\n", "bs", ",", "q_length", ",", "dim", "=", "query", ".", "size", "(", ")", "\n", "k_length", "=", "key", ".", "size", "(", "1", ")", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "# assert key.size() == value.size()", "\n", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "\n", "mask_reshp", "=", "(", "bs", ",", "1", ",", "1", ",", "k_length", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\" separate heads \"\"\"", "\n", "return", "x", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\" group heads \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "query", ")", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "key", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "value", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "\n", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "scores", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "# (bs, n_heads, q_length, k_length)", "\n", "mask", "=", "(", "mask", "==", "0", ")", ".", "view", "(", "mask_reshp", ")", ".", "expand_as", "(", "scores", ")", "# (bs, n_heads, q_length, k_length)", "\n", "scores", ".", "masked_fill_", "(", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "# (bs, n_heads, q_length, k_length)", "\n", "\n", "weights", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "scores", ")", "# (bs, n_heads, q_length, k_length)", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ")", "# (bs, n_heads, q_length, k_length)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "torch", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, q_length, dim)", "\n", "context", "=", "self", ".", "out_lin", "(", "context", ")", "# (bs, q_length, dim)", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "(", "context", ",", "weights", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "context", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.FFN.__init__": [[198, 205], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "FFN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", ".", "dropout", ")", "\n", "self", ".", "lin1", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "hidden_dim", ")", "\n", "self", ".", "lin2", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "hidden_dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "assert", "config", ".", "activation", "in", "[", "'relu'", ",", "'gelu'", "]", ",", "\"activation ({}) must be in ['relu', 'gelu']\"", ".", "format", "(", "config", ".", "activation", ")", "\n", "self", ".", "activation", "=", "gelu", "if", "config", ".", "activation", "==", "'gelu'", "else", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.FFN.forward": [[206, 212], ["modeling_distilbert.FFN.lin1", "modeling_distilbert.FFN.activation", "modeling_distilbert.FFN.lin2", "modeling_distilbert.FFN.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.TransformerBlock.__init__": [[214, 231], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "modeling_distilbert.MultiHeadSelfAttention", "torch.LayerNorm", "torch.LayerNorm", "modeling_distilbert.FFN", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransformerBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "hidden_dim", "=", "config", ".", "hidden_dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", ".", "dropout", ")", "\n", "self", ".", "activation", "=", "config", ".", "activation", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "config", ".", "dim", "%", "config", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "attention", "=", "MultiHeadSelfAttention", "(", "config", ")", "\n", "self", ".", "sa_layer_norm", "=", "nn", ".", "LayerNorm", "(", "normalized_shape", "=", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "\n", "self", ".", "ffn", "=", "FFN", "(", "config", ")", "\n", "self", ".", "output_layer_norm", "=", "nn", ".", "LayerNorm", "(", "normalized_shape", "=", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.TransformerBlock.forward": [[232, 263], ["modeling_distilbert.TransformerBlock.attention", "modeling_distilbert.TransformerBlock.sa_layer_norm", "modeling_distilbert.TransformerBlock.ffn", "modeling_distilbert.TransformerBlock.output_layer_norm", "type"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: torch.tensor(bs, seq_length, dim)\n        attn_mask: torch.tensor(bs, seq_length)\n\n        Outputs\n        -------\n        sa_weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n            The attention weights\n        ffn_output: torch.tensor(bs, seq_length, dim)\n            The output of the transformer block contextualization.\n        \"\"\"", "\n", "# Self-Attention", "\n", "sa_output", "=", "self", ".", "attention", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "mask", "=", "attn_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "sa_output", ",", "sa_weights", "=", "sa_output", "# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)", "\n", "", "else", ":", "# To handle these `output_attention` or `output_hidden_states` cases returning tuples", "\n", "            ", "assert", "type", "(", "sa_output", ")", "==", "tuple", "\n", "sa_output", "=", "sa_output", "[", "0", "]", "\n", "", "sa_output", "=", "self", ".", "sa_layer_norm", "(", "sa_output", "+", "x", ")", "# (bs, seq_length, dim)", "\n", "\n", "# Feed Forward Network", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "sa_output", ")", "# (bs, seq_length, dim)", "\n", "ffn_output", "=", "self", ".", "output_layer_norm", "(", "ffn_output", "+", "sa_output", ")", "# (bs, seq_length, dim)", "\n", "\n", "output", "=", "(", "ffn_output", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "output", "=", "(", "sa_weights", ",", ")", "+", "output", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.Transformer.__init__": [[266, 274], ["torch.Module.__init__", "modeling_distilbert.TransformerBlock", "torch.ModuleList", "torch.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "layer", "=", "TransformerBlock", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "n_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.Transformer.forward": [[275, 325], ["enumerate", "layer_module", "len", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: torch.tensor(bs, seq_length, dim)\n            Input sequence embedded.\n        attn_mask: torch.tensor(bs, seq_length)\n            Attention mask on the sequence.\n\n        Outputs\n        -------\n        hidden_state: torch.tensor(bs, seq_length, dim)\n            Sequence of hiddens states in the last (top) layer\n        all_hidden_states: Tuple[torch.tensor(bs, seq_length, dim)]\n            Tuple of length n_layers with the hidden states from each layer.\n            Optional: only if output_hidden_states=True\n        all_attentions: Tuple[torch.tensor(bs, n_heads, seq_length, seq_length)]\n            Tuple of length n_layers with the attention weights from each layer\n            Optional: only if output_attentions=True\n        \"\"\"", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "\n", "hidden_state", "=", "x", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "x", "=", "hidden_state", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "hidden_state", "=", "layer_outputs", "[", "-", "1", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "2", "\n", "attentions", "=", "layer_outputs", "[", "0", "]", "\n", "all_attentions", "=", "all_attentions", "+", "(", "attentions", ",", ")", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "1", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_state", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertPreTrainedModel.__init__": [[337, 339], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DistilBertPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertPreTrainedModel._init_weights": [[340, 353], ["isinstance", "isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.weight.data.normal_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "if", "module", ".", "weight", ".", "requires_grad", ":", "\n", "                ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertModel.__init__": [[419, 426], ["modeling_distilbert.DistilBertPreTrainedModel.__init__", "modeling_distilbert.Embeddings", "modeling_distilbert.Transformer", "modeling_distilbert.DistilBertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "Embeddings", "(", "config", ")", "# Embeddings", "\n", "self", ".", "transformer", "=", "Transformer", "(", "config", ")", "# Encoder", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertModel._resize_token_embeddings": [[427, 432], ["modeling_distilbert.DistilBertModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "embeddings", ".", "word_embeddings", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertModel._prune_heads": [[433, 440], ["heads_to_prune.items", "modeling_distilbert.DistilBertModel.transformer.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "transformer", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertModel.forward": [[441, 469], ["modeling_distilbert.DistilBertModel.embeddings", "modeling_distilbert.DistilBertModel.transformer", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_distilbert.DistilBertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "\n", "input_ids", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "# (bs, seq_length)", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ")", "# (bs, seq_length, dim)", "\n", "tfmr_output", "=", "self", ".", "transformer", "(", "x", "=", "embedding_output", ",", "\n", "attn_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_state", "=", "tfmr_output", "[", "0", "]", "\n", "output", "=", "(", "hidden_state", ",", ")", "+", "tfmr_output", "[", "1", ":", "]", "\n", "\n", "return", "output", "# last-layer hidden-state, (all hidden_states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertForMaskedLM.__init__": [[503, 517], ["modeling_distilbert.DistilBertPreTrainedModel.__init__", "modeling_distilbert.DistilBertModel", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "modeling_distilbert.DistilBertForMaskedLM.init_weights", "modeling_distilbert.DistilBertForMaskedLM.tie_weights", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "distilbert", "=", "DistilBertModel", "(", "config", ")", "\n", "self", ".", "vocab_transform", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "dim", ")", "\n", "self", ".", "vocab_layer_norm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "vocab_projector", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "vocab_size", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n", "self", ".", "mlm_loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertForMaskedLM.tie_weights": [[518, 524], ["modeling_distilbert.DistilBertForMaskedLM._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "vocab_projector", ",", "\n", "self", ".", "distilbert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertForMaskedLM.forward": [[525, 542], ["modeling_distilbert.DistilBertForMaskedLM.distilbert", "modeling_distilbert.DistilBertForMaskedLM.vocab_transform", "modeling_distilbert.gelu", "modeling_distilbert.DistilBertForMaskedLM.vocab_layer_norm", "modeling_distilbert.DistilBertForMaskedLM.vocab_projector", "modeling_distilbert.DistilBertForMaskedLM.mlm_loss_fct", "modeling_distilbert.DistilBertForMaskedLM.view", "masked_lm_labels.view", "modeling_distilbert.DistilBertForMaskedLM.size"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.gelu"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "dlbrt_output", "=", "self", ".", "distilbert", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "dlbrt_output", "[", "0", "]", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_transform", "(", "hidden_states", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "gelu", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_layer_norm", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_projector", "(", "prediction_logits", ")", "# (bs, seq_length, vocab_size)", "\n", "\n", "outputs", "=", "(", "prediction_logits", ",", ")", "+", "dlbrt_output", "[", "1", ":", "]", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "mlm_loss", "=", "self", ".", "mlm_loss_fct", "(", "prediction_logits", ".", "view", "(", "-", "1", ",", "prediction_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "mlm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (mlm_loss), prediction_logits, (all hidden_states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertForSequenceClassification.__init__": [[578, 588], ["modeling_distilbert.DistilBertPreTrainedModel.__init__", "modeling_distilbert.DistilBertModel", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "modeling_distilbert.DistilBertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "distilbert", "=", "DistilBertModel", "(", "config", ")", "\n", "self", ".", "pre_classifier", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "dim", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "num_labels", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "seq_classif_dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertForSequenceClassification.forward": [[589, 611], ["modeling_distilbert.DistilBertForSequenceClassification.distilbert", "modeling_distilbert.DistilBertForSequenceClassification.pre_classifier", "modeling_distilbert.DistilBertForSequenceClassification.dropout", "modeling_distilbert.DistilBertForSequenceClassification.classifier", "torch.ReLU", "torch.ReLU", "torch.MSELoss", "torch.MSELoss", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "modeling_distilbert.DistilBertForSequenceClassification.view", "labels.view", "modeling_distilbert.DistilBertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_state", "=", "distilbert_output", "[", "0", "]", "# (bs, seq_len, dim)", "\n", "pooled_output", "=", "hidden_state", "[", ":", ",", "0", "]", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "pre_classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "pooled_output", "=", "nn", ".", "ReLU", "(", ")", "(", "pooled_output", ")", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "# (bs, dim)", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "                ", "loss_fct", "=", "nn", ".", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertForQuestionAnswering.__init__": [[653, 662], ["modeling_distilbert.DistilBertPreTrainedModel.__init__", "modeling_distilbert.DistilBertModel", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "modeling_distilbert.DistilBertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "distilbert", "=", "DistilBertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "num_labels", ")", "\n", "assert", "config", ".", "num_labels", "==", "2", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "qa_dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.DistilBertForQuestionAnswering.forward": [[663, 694], ["modeling_distilbert.DistilBertForQuestionAnswering.distilbert", "modeling_distilbert.DistilBertForQuestionAnswering.dropout", "modeling_distilbert.DistilBertForQuestionAnswering.qa_outputs", "modeling_distilbert.DistilBertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "distilbert_output", "[", "0", "]", "# (bs, max_query_len, dim)", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "# (bs, max_query_len, dim)", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "hidden_states", ")", "# (bs, max_query_len, 2)", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "# (bs, max_query_len)", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "# (bs, max_query_len)", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.gelu": [[49, 51], ["torch.erf", "torch.erf", "math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_distilbert.create_sinusoidal_embeddings": [[52, 61], ["numpy.array", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "out.detach_", "numpy.sin", "numpy.cos", "range", "numpy.power", "range"], "function", ["None"], ["", "def", "create_sinusoidal_embeddings", "(", "n_pos", ",", "dim", ",", "out", ")", ":", "\n", "    ", "position_enc", "=", "np", ".", "array", "(", "[", "\n", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "dim", ")", "for", "j", "in", "range", "(", "dim", ")", "]", "\n", "for", "pos", "in", "range", "(", "n_pos", ")", "\n", "]", ")", "\n", "out", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "sin", "(", "position_enc", "[", ":", ",", "0", ":", ":", "2", "]", ")", ")", "\n", "out", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "cos", "(", "position_enc", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", "\n", "out", ".", "detach_", "(", ")", "\n", "out", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Attention.__init__": [[103, 120], ["torch.Module.__init__", "modeling_gpt2.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Attention.prune_heads": [[121, 142], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "modeling_gpt2.Attention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Attention._attn": [[143, 166], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_gpt2.Attention.attn_dropout", "modeling_gpt2.Attention.size", "modeling_gpt2.Attention.size", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Attention.merge_heads": [[167, 171], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Attention.split_heads": [[172, 179], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Attention.forward": [[180, 201], ["modeling_gpt2.Attention.c_attn", "modeling_gpt2.Attention.split", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_gpt2.Attention._attn", "modeling_gpt2.Attention.merge_heads", "modeling_gpt2.Attention.c_proj", "modeling_gpt2.Attention.resid_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.MLP.__init__": [[204, 211], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.MLP.forward": [[212, 216], ["modeling_gpt2.MLP.act", "modeling_gpt2.MLP.c_proj", "modeling_gpt2.MLP.dropout", "modeling_gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Block.__init__": [[219, 226], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.Attention", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.Block.forward": [[227, 240], ["modeling_gpt2.Block.attn", "modeling_gpt2.Block.mlp", "modeling_gpt2.Block.ln_1", "modeling_gpt2.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "output_attn", "=", "self", ".", "attn", "(", "self", ".", "ln_1", "(", "x", ")", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "\n", "x", "=", "x", "+", "a", "\n", "m", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2PreTrainedModel.__init__": [[251, 253], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GPT2PreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2PreTrainedModel._init_weights": [[254, 266], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2Model.__init__": [[346, 359], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.GPT2Model.init_weights", "modeling_gpt2.Block", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2Model", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2Model._resize_token_embeddings": [[360, 363], ["modeling_gpt2.GPT2Model._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "wte", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "wte", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2Model._prune_heads": [[364, 370], ["heads_to_prune.items", "modeling_gpt2.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2Model.forward": [[371, 468], ["input_ids.view.view.size", "input_ids.view.view.view", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.wpe", "modeling_gpt2.GPT2Model.drop", "enumerate", "modeling_gpt2.GPT2Model.ln_f", "hidden_states.view.view.view", "token_type_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "attention_mask.to.to.view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_gpt2.GPT2Model.wte", "zip", "block", "tuple", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "hidden_states.view.view.size", "tuple.append", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "t.view", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "modeling_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "if", "position_ids", "is", "not", "None", ":", "\n", "            ", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_ids", ".", "size", "(", "-", "1", ")", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "hidden_states", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (presents), (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2LMHeadModel.__init__": [[511, 518], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_gpt2.GPT2LMHeadModel.init_weights", "modeling_gpt2.GPT2LMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2LMHeadModel.tie_weights": [[519, 525], ["modeling_gpt2.GPT2LMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "wte", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2LMHeadModel.forward": [[526, 550], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2DoubleHeadsModel.__init__": [[618, 626], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "modeling_gpt2.GPT2DoubleHeadsModel.init_weights", "modeling_gpt2.GPT2DoubleHeadsModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2DoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2DoubleHeadsModel.tie_weights": [[627, 633], ["modeling_gpt2.GPT2DoubleHeadsModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "wte", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.GPT2DoubleHeadsModel.forward": [[634, 663], ["modeling_gpt2.GPT2DoubleHeadsModel.transformer", "modeling_gpt2.GPT2DoubleHeadsModel.lm_head", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "modeling_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "modeling_gpt2.GPT2DoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "mc_labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.load_tf_weights_in_gpt2": [[44, 96], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "logger.error", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'w'", "or", "l", "[", "0", "]", "==", "'g'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'b'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'wpe'", "or", "l", "[", "0", "]", "==", "'wte'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.gelu": [[98, 100], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.__init__": [[195, 222], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "XLNetLayerNorm", "torch.nn.Dropout", "ValueError", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetRelativeAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "if", "config", ".", "d_model", "%", "config", ".", "n_head", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "d_model", ",", "config", ".", "n_head", ")", ")", "\n", "\n", "", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "scale", "=", "1", "/", "(", "config", ".", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "q", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "k", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "o", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_s_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "seg_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.prune_heads": [[223, 225], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift": [[226, 238], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"perform relative shift to form the relative attention score.\"\"\"", "\n", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "1", "]", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "x", "=", "x", "[", "1", ":", ",", "...", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", "-", "1", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "# x = x[:, 0:klen, :, :]", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij": [[239, 253], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift_bnij", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", ",", "x_size", "[", "3", "]", ",", "x_size", "[", "2", "]", ")", "\n", "x", "=", "x", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", "-", "1", ")", "\n", "# Note: the tensor-slice form was faster in my testing than torch.index_select", "\n", "#       However, tracing doesn't like the nature of the slice, and if klen changes", "\n", "#       during the run then it'll fail, whereas index_select will be fine.", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "3", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "# x = x[:, :, :, :klen]", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.rel_attn_core": [[254, 295], ["torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij", "torch.nn.functional.softmax", "modeling_xlnet.XLNetRelativeAttention.dropout", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij"], ["", "def", "rel_attn_core", "(", "self", ",", "q_head", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "None", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Core relative positional attention operations.\"\"\"", "\n", "\n", "# content based attention score", "\n", "ac", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->bnij'", ",", "q_head", "+", "self", ".", "r_w_bias", ",", "k_head_h", ")", "\n", "\n", "# position based attention score", "\n", "bd", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->bnij'", ",", "q_head", "+", "self", ".", "r_r_bias", ",", "k_head_r", ")", "\n", "bd", "=", "self", ".", "rel_shift_bnij", "(", "bd", ",", "klen", "=", "ac", ".", "shape", "[", "3", "]", ")", "\n", "\n", "# segment based attention score", "\n", "if", "seg_mat", "is", "None", ":", "\n", "            ", "ef", "=", "0", "\n", "", "else", ":", "\n", "            ", "ef", "=", "torch", ".", "einsum", "(", "'ibnd,snd->ibns'", ",", "q_head", "+", "self", ".", "r_s_bias", ",", "self", ".", "seg_embed", ")", "\n", "ef", "=", "torch", ".", "einsum", "(", "'ijbs,ibns->bnij'", ",", "seg_mat", ",", "ef", ")", "\n", "\n", "# merge attention scores and perform masking", "\n", "", "attn_score", "=", "(", "ac", "+", "bd", "+", "ef", ")", "*", "self", ".", "scale", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask", "\n", "            ", "if", "attn_mask", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "65500", "*", "torch", ".", "einsum", "(", "'ijbn->bnij'", ",", "attn_mask", ")", "\n", "", "else", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "1e30", "*", "torch", ".", "einsum", "(", "'ijbn->bnij'", ",", "attn_mask", ")", "\n", "\n", "# attention probability", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "3", ")", "\n", "attn_prob", "=", "self", ".", "dropout", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "torch", ".", "einsum", "(", "'ijbn->bnij'", ",", "head_mask", ")", "\n", "\n", "# attention output", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'bnij,jbnd->ibnd'", ",", "attn_prob", ",", "v_head_h", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "attn_vec", ",", "torch", ".", "einsum", "(", "'bnij->ijbn'", ",", "attn_prob", ")", "\n", "\n", "", "return", "attn_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.post_attention": [[296, 307], ["torch.einsum", "modeling_xlnet.XLNetRelativeAttention.dropout", "modeling_xlnet.XLNetRelativeAttention.layer_norm"], "methods", ["None"], ["", "def", "post_attention", "(", "self", ",", "h", ",", "attn_vec", ",", "residual", "=", "True", ")", ":", "\n", "        ", "\"\"\"Post-attention processing.\"\"\"", "\n", "# post-attention projection (back to `d_model`)", "\n", "attn_out", "=", "torch", ".", "einsum", "(", "'ibnd,hnd->ibh'", ",", "attn_vec", ",", "self", ".", "o", ")", "\n", "\n", "attn_out", "=", "self", ".", "dropout", "(", "attn_out", ")", "\n", "if", "residual", ":", "\n", "            ", "attn_out", "=", "attn_out", "+", "h", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "attn_out", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetRelativeAttention.forward": [[308, 400], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.cat", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.cat", "mems.dim", "mems.dim"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core"], ["", "def", "forward", "(", "self", ",", "h", ",", "g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "\n", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "###### Two-stream attention with relative positional encoding.", "\n", "# content based attention score", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content-based key head", "\n", "", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "\n", "# content-based value head", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# position-based key head", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "##### h-stream", "\n", "# content-stream query head", "\n", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec_h", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec_h", ",", "attn_prob_h", "=", "attn_vec_h", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec_h", ")", "\n", "\n", "##### g-stream", "\n", "# query-stream query head", "\n", "q_head_g", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "g", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "                ", "q_head_g", "=", "torch", ".", "einsum", "(", "'mbnd,mlb->lbnd'", ",", "q_head_g", ",", "target_mapping", ")", "\n", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "", "attn_vec_g", "=", "torch", ".", "einsum", "(", "'lbnd,mlb->mbnd'", ",", "attn_vec_g", ",", "target_mapping", ")", "\n", "", "else", ":", "\n", "                ", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "# post processing", "\n", "", "", "output_g", "=", "self", ".", "post_attention", "(", "g", ",", "attn_vec_g", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_prob", "=", "attn_prob_h", ",", "attn_prob_g", "\n", "\n", "", "", "else", ":", "\n", "###### Multi-head attention with relative positional encoding", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content heads", "\n", "", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# positional heads", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec", ",", "attn_prob", "=", "attn_vec", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec", ")", "\n", "output_g", "=", "None", "\n", "\n", "", "outputs", "=", "(", "output_h", ",", "output_g", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_prob", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetFeedForward.__init__": [[402, 413], ["torch.nn.Module.__init__", "XLNetLayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "layer_1", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_inner", ")", "\n", "self", ".", "layer_2", "=", "nn", ".", "Linear", "(", "config", ".", "d_inner", ",", "config", ".", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "if", "isinstance", "(", "config", ".", "ff_activation", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "ff_activation", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "activation_function", "=", "ACT2FN", "[", "config", ".", "ff_activation", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation_function", "=", "config", ".", "ff_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetFeedForward.forward": [[414, 423], ["modeling_xlnet.XLNetFeedForward.layer_1", "modeling_xlnet.XLNetFeedForward.activation_function", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_2", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "inp", "\n", "output", "=", "self", ".", "layer_1", "(", "output", ")", "\n", "output", "=", "self", ".", "activation_function", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "inp", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetLayer.__init__": [[425, 430], ["torch.nn.Module.__init__", "modeling_xlnet.XLNetRelativeAttention", "modeling_xlnet.XLNetFeedForward", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rel_attn", "=", "XLNetRelativeAttention", "(", "config", ")", "\n", "self", ".", "ff", "=", "XLNetFeedForward", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetLayer.forward": [[431, 445], ["modeling_xlnet.XLNetLayer.rel_attn", "modeling_xlnet.XLNetLayer.ff", "modeling_xlnet.XLNetLayer.ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output_h", ",", "output_g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "rel_attn", "(", "output_h", ",", "output_g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "mems", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "output_g", "is", "not", "None", ":", "\n", "            ", "output_g", "=", "self", ".", "ff", "(", "output_g", ")", "\n", "", "output_h", "=", "self", ".", "ff", "(", "output_h", ")", "\n", "\n", "outputs", "=", "(", "output_h", ",", "output_g", ")", "+", "outputs", "[", "2", ":", "]", "# Add again attentions if there are there", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetPreTrainedModel._init_weights": [[456, 475], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "isinstance", "param.data.normal_", "module.mask_emb.data.normal_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "XLNetRelativeAttention", ")", ":", "\n", "            ", "for", "param", "in", "[", "module", ".", "q", ",", "module", ".", "k", ",", "module", ".", "v", ",", "module", ".", "o", ",", "module", ".", "r", ",", "\n", "module", ".", "r_r_bias", ",", "module", ".", "r_s_bias", ",", "module", ".", "r_w_bias", ",", "\n", "module", ".", "seg_embed", "]", ":", "\n", "                ", "param", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetModel", ")", ":", "\n", "                ", "module", ".", "mask_emb", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel.__init__": [[592, 613], ["modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.ModuleList", "torch.nn.Dropout", "modeling_xlnet.XLNetModel.init_weights", "torch.FloatTensor", "modeling_xlnet.XLNetLayer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "reuse_len", "=", "config", ".", "reuse_len", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "bi_data", "=", "config", ".", "bi_data", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "config", ".", "n_token", ",", "config", ".", "d_model", ")", "\n", "self", ".", "mask_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "config", ".", "d_model", ")", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "XLNetLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel._resize_token_embeddings": [[614, 617], ["modeling_xlnet.XLNetModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "word_embedding", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "word_embedding", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel._prune_heads": [[618, 620], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel.create_mask": [[621, 650], ["torch.ones", "torch.triu", "torch.zeros", "torch.cat", "torch.cat.to", "torch.tril", "torch.cat", "next", "modeling_xlnet.XLNetModel.parameters"], "methods", ["None"], ["", "def", "create_mask", "(", "self", ",", "qlen", ",", "mlen", ")", ":", "\n", "        ", "\"\"\"\n        Creates causal attention mask. Float mask where 1.0 indicates masked, 0.0 indicates not-masked.\n\n        Args:\n            qlen: TODO Lysandre didn't fill\n            mlen: TODO Lysandre didn't fill\n\n        ::\n\n                  same_length=False:      same_length=True:\n                  <mlen > <  qlen >       <mlen > <  qlen >\n               ^ [0 0 0 0 0 1 1 1 1]     [0 0 0 0 0 1 1 1 1]\n                 [0 0 0 0 0 0 1 1 1]     [1 0 0 0 0 0 1 1 1]\n            qlen [0 0 0 0 0 0 0 1 1]     [1 1 0 0 0 0 0 1 1]\n                 [0 0 0 0 0 0 0 0 1]     [1 1 1 0 0 0 0 0 1]\n               v [0 0 0 0 0 0 0 0 0]     [1 1 1 1 0 0 0 0 0]\n\n        \"\"\"", "\n", "attn_mask", "=", "torch", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ")", "\n", "mask_up", "=", "torch", ".", "triu", "(", "attn_mask", ",", "diagonal", "=", "1", ")", "\n", "attn_mask_pad", "=", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "attn_mask_pad", ",", "mask_up", "]", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_lo", "=", "torch", ".", "tril", "(", "attn_mask", ",", "diagonal", "=", "-", "1", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "ret", "[", ":", ",", ":", "qlen", "]", "+", "mask_lo", ",", "ret", "[", ":", ",", "qlen", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "ret", "=", "ret", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel.cache_mem": [[651, 662], ["new_mem.detach", "torch.cat"], "methods", ["None"], ["", "def", "cache_mem", "(", "self", ",", "curr_out", ",", "prev_mem", ")", ":", "\n", "        ", "\"\"\"cache hidden states into memory.\"\"\"", "\n", "if", "self", ".", "reuse_len", "is", "not", "None", "and", "self", ".", "reuse_len", ">", "0", ":", "\n", "            ", "curr_out", "=", "curr_out", "[", ":", "self", ".", "reuse_len", "]", "\n", "\n", "", "if", "prev_mem", "is", "None", ":", "\n", "            ", "new_mem", "=", "curr_out", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "", "else", ":", "\n", "            ", "new_mem", "=", "torch", ".", "cat", "(", "[", "prev_mem", ",", "curr_out", "]", ",", "dim", "=", "0", ")", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "\n", "", "return", "new_mem", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel.positional_embedding": [[663, 673], ["torch.einsum", "torch.cat", "pos_emb.expand.expand.expand", "torch.sin", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positional_embedding", "(", "pos_seq", ",", "inv_freq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "einsum", "(", "'i,d->id'", ",", "pos_seq", ",", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "sinusoid_inp", ")", ",", "torch", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "pos_emb", "=", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "pos_emb", "=", "pos_emb", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel.relative_positional_encoding": [[674, 712], ["torch.arange", "modeling_xlnet.XLNetModel.to", "torch.pow", "torch.arange", "torch.arange", "torch.cat", "torch.arange", "modeling_xlnet.XLNetModel.positional_embedding", "next", "ValueError", "fwd_pos_seq.clamp.clamp.clamp", "bwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "fwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.parameters"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding"], ["", "def", "relative_positional_encoding", "(", "self", ",", "qlen", ",", "klen", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "\"\"\"create relative positional encoding.\"\"\"", "\n", "freq_seq", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "d_model", ",", "2.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "inv_freq", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "(", "freq_seq", "/", "self", ".", "d_model", ")", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "# beg, end = klen - 1, -qlen", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "qlen", "\n", "", "elif", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "# beg, end = klen - 1, -1", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown `attn_type` {}.'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "", "if", "self", ".", "bi_data", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bwd_pos_seq", "=", "torch", ".", "arange", "(", "-", "beg", ",", "-", "end", ",", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "bwd_pos_seq", "=", "bwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "\n", "", "if", "bsz", "is", "not", "None", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ")", "\n", "\n", "", "pos_emb", "=", "torch", ".", "cat", "(", "[", "fwd_pos_emb", ",", "bwd_pos_emb", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", ")", "\n", "\n", "", "pos_emb", "=", "pos_emb", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetModel.forward": [[713, 866], ["input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_xlnet.XLNetModel.word_embedding", "modeling_xlnet.XLNetModel.dropout", "modeling_xlnet.XLNetModel.relative_positional_encoding", "modeling_xlnet.XLNetModel.dropout", "enumerate", "modeling_xlnet.XLNetModel.dropout", "token_type_ids.transpose().contiguous", "input_mask.transpose().contiguous", "attention_mask.transpose().contiguous", "perm_mask.permute().contiguous", "target_mapping.permute().contiguous", "next", "next", "modeling_xlnet.XLNetModel.create_mask", "modeling_xlnet.XLNetModel.mask_emb.expand", "modeling_xlnet.XLNetModel.dropout", "torch.nn.functional.one_hot().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "tuple.append", "modeling_xlnet.XLNetModel.permute().contiguous", "tuple", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "modeling_xlnet.XLNetModel.parameters", "modeling_xlnet.XLNetModel.parameters", "ValueError", "torch.zeros().to", "torch.cat", "torch.eye().to", "torch.cat", "torch.zeros", "torch.cat", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "len", "tuple.append", "tuple.append", "tuple", "tuple", "token_type_ids.transpose", "input_mask.transpose", "attention_mask.transpose", "perm_mask.permute", "target_mapping.permute", "torch.nn.functional.one_hot", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.permute", "t.permute().contiguous", "torch.zeros", "torch.eye", "torch.zeros().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_xlnet.XLNetModel.cache_mem", "h.permute().contiguous", "hs.permute().contiguous", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.parameters", "t.permute", "torch.zeros", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "h.permute", "hs.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.create_mask", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.cache_mem"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end", "\n", "# but we want a unified interface in the library with the batch size on the first dimension", "\n", "# so we move here the first dimension (batch) to the end", "\n", "        ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "token_type_ids", "=", "token_type_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "input_mask", "=", "input_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "attention_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "perm_mask", "=", "perm_mask", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "perm_mask", "is", "not", "None", "else", "None", "\n", "target_mapping", "=", "target_mapping", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "target_mapping", "is", "not", "None", "else", "None", "\n", "\n", "qlen", ",", "bsz", "=", "input_ids", ".", "shape", "[", "0", "]", ",", "input_ids", ".", "shape", "[", "1", "]", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "shape", "[", "0", "]", "if", "mems", "is", "not", "None", "and", "mems", "[", "0", "]", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "dtype_float", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "##### Attention mask", "\n", "# causal attention mask", "\n", "if", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "            ", "attn_mask", "=", "self", ".", "create_mask", "(", "qlen", ",", "mlen", ")", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported attention type: {}'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "# data mask: input mask & perm mask", "\n", "", "assert", "input_mask", "is", "None", "or", "attention_mask", "is", "None", ",", "\"You can only use one of input_mask (uses 1 for padding) \"", "\n", "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"", "\n", "if", "input_mask", "is", "None", "and", "attention_mask", "is", "not", "None", ":", "\n", "            ", "input_mask", "=", "1.0", "-", "attention_mask", "\n", "", "if", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "+", "perm_mask", "\n", "", "elif", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "\n", "", "elif", "input_mask", "is", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "perm_mask", "\n", "", "else", ":", "\n", "            ", "data_mask", "=", "None", "\n", "\n", "", "if", "data_mask", "is", "not", "None", ":", "\n", "# all mems can be attended to", "\n", "            ", "if", "mlen", ">", "0", ":", "\n", "                ", "mems_mask", "=", "torch", ".", "zeros", "(", "[", "data_mask", ".", "shape", "[", "0", "]", ",", "mlen", ",", "bsz", "]", ")", ".", "to", "(", "data_mask", ")", "\n", "data_mask", "=", "torch", ".", "cat", "(", "[", "mems_mask", ",", "data_mask", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "attn_mask", "is", "None", ":", "\n", "                ", "attn_mask", "=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "                ", "attn_mask", "+=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "(", "attn_mask", ">", "0", ")", ".", "to", "(", "dtype_float", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "non_tgt_mask", "=", "-", "torch", ".", "eye", "(", "qlen", ")", ".", "to", "(", "attn_mask", ")", "\n", "if", "mlen", ">", "0", ":", "\n", "                ", "non_tgt_mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", ".", "to", "(", "attn_mask", ")", ",", "non_tgt_mask", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "non_tgt_mask", "=", "(", "(", "attn_mask", "+", "non_tgt_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ">", "0", ")", ".", "to", "(", "attn_mask", ")", "\n", "", "else", ":", "\n", "            ", "non_tgt_mask", "=", "None", "\n", "\n", "##### Word embeddings and prepare h & g hidden states", "\n", "", "word_emb_k", "=", "self", ".", "word_embedding", "(", "input_ids", ")", "\n", "output_h", "=", "self", ".", "dropout", "(", "word_emb_k", ")", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "            ", "word_emb_q", "=", "self", ".", "mask_emb", ".", "expand", "(", "target_mapping", ".", "shape", "[", "0", "]", ",", "bsz", ",", "-", "1", ")", "\n", "# else:  # We removed the inp_q input which was same as target mapping", "\n", "#     inp_q_ext = inp_q[:, :, None]", "\n", "#     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k", "\n", "output_g", "=", "self", ".", "dropout", "(", "word_emb_q", ")", "\n", "", "else", ":", "\n", "            ", "output_g", "=", "None", "\n", "\n", "##### Segment embedding", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "# Convert `token_type_ids` to one-hot `seg_mat`", "\n", "            ", "if", "mlen", ">", "0", ":", "\n", "                ", "mem_pad", "=", "torch", ".", "zeros", "(", "[", "mlen", ",", "bsz", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "cat_ids", "=", "torch", ".", "cat", "(", "[", "mem_pad", ",", "token_type_ids", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat_ids", "=", "token_type_ids", "\n", "\n", "# `1` indicates not in the same segment [qlen x klen x bsz]", "\n", "", "seg_mat", "=", "(", "token_type_ids", "[", ":", ",", "None", "]", "!=", "cat_ids", "[", "None", ",", ":", "]", ")", ".", "long", "(", ")", "\n", "seg_mat", "=", "F", ".", "one_hot", "(", "seg_mat", ",", "num_classes", "=", "2", ")", ".", "to", "(", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "seg_mat", "=", "None", "\n", "\n", "##### Positional encoding", "\n", "", "pos_emb", "=", "self", ".", "relative_positional_encoding", "(", "qlen", ",", "klen", ",", "bsz", "=", "bsz", ")", "\n", "pos_emb", "=", "self", ".", "dropout", "(", "pos_emb", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "new_mems", "=", "(", ")", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "[", "None", "]", "*", "len", "(", "self", ".", "layer", ")", "\n", "\n", "", "attentions", "=", "[", "]", "\n", "hidden_states", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "# cache new mems", "\n", "                ", "new_mems", "=", "new_mems", "+", "(", "self", ".", "cache_mem", "(", "output_h", ",", "mems", "[", "i", "]", ")", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "outputs", "=", "layer_module", "(", "output_h", ",", "output_g", ",", "attn_mask_h", "=", "non_tgt_mask", ",", "attn_mask_g", "=", "attn_mask", ",", "\n", "r", "=", "pos_emb", ",", "seg_mat", "=", "seg_mat", ",", "mems", "=", "mems", "[", "i", "]", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "# Add last hidden state", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "output", "=", "self", ".", "dropout", "(", "output_g", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)", "\n", "outputs", "=", "(", "output", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ",", ")", "\n", "\n", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "new_mems", ",", ")", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "if", "output_g", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "h", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", "for", "h", "in", "hs", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "hs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "attentions", "=", "tuple", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# outputs, (new_mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetLMHeadModel.__init__": [[912, 922], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetLMHeadModel.init_weights", "modeling_xlnet.XLNetLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "lm_loss", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "n_token", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetLMHeadModel.tie_weights": [[923, 927], ["modeling_xlnet.XLNetLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_loss", ",", "self", ".", "transformer", ".", "word_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetLMHeadModel.forward": [[928, 951], ["modeling_xlnet.XLNetLMHeadModel.transformer", "modeling_xlnet.XLNetLMHeadModel.lm_loss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetLMHeadModel.view", "labels.view", "modeling_xlnet.XLNetLMHeadModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "logits", "=", "self", ".", "lm_loss", "(", "transformer_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Flatten the tokens", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForSequenceClassification.__init__": [[992, 1001], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.SequenceSummary", "torch.nn.Linear", "modeling_xlnet.XLNetForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "logits_proj", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForSequenceClassification.forward": [[1002, 1030], ["modeling_xlnet.XLNetForSequenceClassification.transformer", "modeling_xlnet.XLNetForSequenceClassification.sequence_summary", "modeling_xlnet.XLNetForSequenceClassification.logits_proj", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForMultipleChoice.__init__": [[1088, 1096], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.SequenceSummary", "torch.nn.Linear", "modeling_xlnet.XLNetForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "logits_proj", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForMultipleChoice.forward": [[1097, 1126], ["input_ids.view", "modeling_xlnet.XLNetForMultipleChoice.transformer", "modeling_xlnet.XLNetForMultipleChoice.sequence_summary", "modeling_xlnet.XLNetForMultipleChoice.logits_proj", "modeling_xlnet.XLNetForMultipleChoice.view", "input_ids.size", "token_type_ids.view", "attention_mask.view", "input_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "token_type_ids.size", "attention_mask.size", "input_mask.size", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_input_mask", "=", "input_mask", ".", "view", "(", "-", "1", ",", "input_mask", ".", "size", "(", "-", "1", ")", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "flat_input_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "input_mask", "=", "flat_input_mask", ",", "attention_mask", "=", "flat_attention_mask", ",", "\n", "mems", "=", "mems", ",", "perm_mask", "=", "perm_mask", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForQuestionAnsweringSimple.__init__": [[1173, 1181], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetForQuestionAnsweringSimple.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForQuestionAnsweringSimple.forward": [[1182, 1221], ["modeling_xlnet.XLNetForQuestionAnsweringSimple.transformer", "modeling_xlnet.XLNetForQuestionAnsweringSimple.qa_outputs", "modeling_xlnet.XLNetForQuestionAnsweringSimple.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForQuestionAnswering.__init__": [[1286, 1297], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass", "modeling_xlnet.XLNetForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.XLNetForQuestionAnswering.forward": [[1298, 1366], ["modeling_xlnet.XLNetForQuestionAnswering.transformer", "modeling_xlnet.XLNetForQuestionAnswering.start_logits", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "is_impossible", "=", "None", ",", "cls_index", "=", "None", ",", "p_mask", "=", "None", ",", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "start_states", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "# get the representation of START as weighted sum of hidden states", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "# Shape (batch size,): one single `cls_logits` for each sample", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.build_tf_xlnet_to_pytorch_map": [[45, 114], ["hasattr", "tf_to_pt_map.update", "enumerate", "tf_to_pt_map.update", "hasattr", "tf_to_pt_map.update", "hasattr", "hasattr", "r_r_list.append", "r_w_list.append", "r_s_list.append", "seg_embed_list.append"], "function", ["None"], ["def", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", "=", "None", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        I use a map to keep the PyTorch model as\n        identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "'lm_loss'", ")", ":", "\n", "# We will load also the output bias", "\n", "            ", "tf_to_pt_map", "[", "'model/lm_loss/bias'", "]", "=", "model", ".", "lm_loss", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'sequence_summary'", ")", "and", "'model/sequnece_summary/summary/kernel'", "in", "tf_weights", ":", "\n", "# We will load also the sequence summary", "\n", "            ", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/kernel'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/bias'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'logits_proj'", ")", "and", "config", ".", "finetuning_task", "is", "not", "None", "and", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "in", "tf_weights", ":", "\n", "            ", "tf_to_pt_map", "[", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/regression_{}/logit/bias'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "bias", "\n", "\n", "# Now load the rest of the transformer", "\n", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings and output", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "'model/transformer/word_embedding/lookup_table'", ":", "model", ".", "word_embedding", ".", "weight", ",", "\n", "'model/transformer/mask_emb/mask_emb'", ":", "model", ".", "mask_emb", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layer", ")", ":", "\n", "        ", "layer_str", "=", "\"model/transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "rel_attn", ".", "o", ",", "\n", "layer_str", "+", "\"rel_attn/q/kernel\"", ":", "b", ".", "rel_attn", ".", "q", ",", "\n", "layer_str", "+", "\"rel_attn/k/kernel\"", ":", "b", ".", "rel_attn", ".", "k", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "rel_attn", ".", "r", ",", "\n", "layer_str", "+", "\"rel_attn/v/kernel\"", ":", "b", ".", "rel_attn", ".", "v", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "ff", ".", "layer_1", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "ff", ".", "layer_1", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "ff", ".", "layer_2", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "ff", ".", "layer_2", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "r_s_list", "=", "[", "]", "\n", "seg_embed_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layer", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_w_bias", ")", "\n", "r_s_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_s_bias", ")", "\n", "seg_embed_list", ".", "append", "(", "b", ".", "rel_attn", ".", "seg_embed", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "r_s_list", "=", "[", "model", ".", "r_s_bias", "]", "\n", "seg_embed_list", "=", "[", "model", ".", "seg_embed", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'model/transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'model/transformer/r_w_bias'", ":", "r_w_list", ",", "\n", "'model/transformer/r_s_bias'", ":", "r_s_list", ",", "\n", "'model/transformer/seg_embed'", ":", "seg_embed_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.load_tf_weights_in_xlnet": [[115, 173], ["tf.train.list_variables", "modeling_xlnet.build_tf_xlnet_to_pytorch_map", "build_tf_xlnet_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "logger.info", "isinstance", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "logger.info", "logger.info", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "len", "logger.info", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.build_tf_xlnet_to_pytorch_map"], ["", "def", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Load weights from TF model", "\n", "", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", ")", "\n", "\n", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Importing {}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "not", "in", "tf_weights", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} not in tf pre-trained weights, skipping\"", ".", "format", "(", "name", ")", ")", "\n", "continue", "\n", "", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "and", "(", "'ff'", "in", "name", "or", "'summary'", "in", "name", "or", "'logit'", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transposing\"", ")", "\n", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "isinstance", "(", "pointer", ",", "list", ")", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.gelu": [[175, 182], ["torch.tanh", "math.sqrt", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function.\n        XLNet is using OpenAI GPT's gelu (not exactly the same as BERT)\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlnet.swish": [[184, 186], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_bert.BertConfig.__init__": [[79, 115], ["configuration_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "30522", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\" or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.ConstantLRSchedule.__init__": [[29, 31], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "ConstantLRSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "lambda", "_", ":", "1.0", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupConstantSchedule.__init__": [[38, 41], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "super", "(", "WarmupConstantSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupConstantSchedule.lr_lambda": [[42, 46], ["float", "float", "max"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "warmup_steps", ")", ")", "\n", "", "return", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupLinearSchedule.__init__": [[53, 57], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "super", "(", "WarmupLinearSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupLinearSchedule.lr_lambda": [[58, 62], ["max", "float", "float", "float", "float", "max", "max"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "warmup_steps", ")", ")", "\n", "", "return", "max", "(", "0.0", ",", "float", "(", "self", ".", "t_total", "-", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupCosineSchedule.__init__": [[70, 75], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "cycles", "=", ".5", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "self", ".", "cycles", "=", "cycles", "\n", "super", "(", "WarmupCosineSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupCosineSchedule.lr_lambda": [[76, 82], ["max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "warmup_steps", ")", ")", "\n", "# progress after warmup", "\n", "", "progress", "=", "float", "(", "step", "-", "self", ".", "warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", "\n", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "float", "(", "self", ".", "cycles", ")", "*", "2.0", "*", "progress", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupCosineWithHardRestartsSchedule.__init__": [[90, 95], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "cycles", "=", "1.", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "self", ".", "cycles", "=", "cycles", "\n", "super", "(", "WarmupCosineWithHardRestartsSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.WarmupCosineWithHardRestartsSchedule.lr_lambda": [[96, 104], ["max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "warmup_steps", ")", ")", "\n", "# progress after warmup", "\n", "", "progress", "=", "float", "(", "step", "-", "self", ".", "warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", "\n", "if", "progress", ">=", "1.0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "(", "(", "float", "(", "self", ".", "cycles", ")", "*", "progress", ")", "%", "1.0", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.__init__": [[117, 129], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "weight_decay", "=", "0.0", ",", "correct_bias", "=", "True", ")", ":", "\n", "        ", "if", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "eps", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "correct_bias", "=", "correct_bias", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step": [[130, 190], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1.0", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1.0", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "step_size", "=", "group", "[", "'lr'", "]", "\n", "if", "group", "[", "'correct_bias'", "]", ":", "# No bias correction for Bert", "\n", "                    ", "bias_correction1", "=", "1.0", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1.0", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "step_size", "=", "step_size", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'lr'", "]", "*", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer.__init__": [[116, 134], ["tokenization_utils.PreTrainedTokenizer.__init__", "json.load", "tokenization_gpt2.bytes_to_unicode", "dict", "regex.compile", "io.open", "io.open().read().split", "tuple", "zip", "tokenization_gpt2.GPT2Tokenizer.encoder.items", "tokenization_gpt2.GPT2Tokenizer.byte_encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.bytes_to_unicode"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "errors", "=", "'replace'", ",", "unk_token", "=", "\"<|endoftext|>\"", ",", "\n", "bos_token", "=", "\"<|endoftext|>\"", ",", "eos_token", "=", "\"<|endoftext|>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GPT2Tokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "bpe_data", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_data", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer.vocab_size": [[135, 138], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer.bpe": [[139, 179], ["tuple", "tokenization_gpt2.get_pairs", "min", "tuple", "len", "len", "tokenization_gpt2.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer._tokenize": [[180, 197], ["regex.findall", "bpe_tokens.extend", "tokenization_gpt2.GPT2Tokenizer.bpe().split", "token.encode", "ord", "tokenization_gpt2.GPT2Tokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "add_prefix_space", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n            Args:\n                - add_prefix_space (boolean, default False):\n                    Begin the sentence with at least one space toto get invariance to word order in GPT-2 (and RoBERTa) tokenizers.\n        \"\"\"", "\n", "if", "add_prefix_space", ":", "\n", "            ", "text", "=", "' '", "+", "text", "\n", "\n", "", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "ord", "(", "b", ")", "]", "for", "b", "in", "token", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n", "", "else", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n", "", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer._convert_token_to_id": [[198, 201], ["tokenization_gpt2.GPT2Tokenizer.encoder.get", "tokenization_gpt2.GPT2Tokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer._convert_id_to_token": [[202, 205], ["tokenization_gpt2.GPT2Tokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_string": [[206, 211], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "text", "=", "''", ".", "join", "(", "tokens", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.GPT2Tokenizer.save_vocabulary": [[212, 235], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "writer.write", "sorted", "json.dumps", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "u'#version: 0.2\\n'", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.bytes_to_unicode": [[67, 90], ["lru_cache", "range", "dict", "list", "_chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a mapping to unicode strings.\n    We specifically avoids mapping to whitespace/control characters the bpe code barfs on.\n    \n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    \"\"\"", "\n", "_chr", "=", "unichr", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "else", "chr", "\n", "bs", "=", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "_chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_gpt2.get_pairs": [[91, 102], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.PositionalEmbedding.__init__": [[177, 184], ["torch.Module.__init__", "modeling_transfo_xl.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inv_freq'", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.PositionalEmbedding.forward": [[185, 193], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.PositionwiseFF.__init__": [[197, 214], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ",", "layer_norm_epsilon", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.PositionwiseFF.forward": [[215, 230], ["modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.layer_norm", "modeling_transfo_xl.PositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "self", ".", "layer_norm", "(", "inp", ")", ")", "\n", "\n", "##### residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "##### positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.__init__": [[233, 265], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "pre_lnorm", "=", "False", ",", "\n", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ",", "output_attentions", "=", "False", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n", "", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift": [[266, 277], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["None"], ["", "def", "_rel_shift", "(", "self", ",", "x", ")", ":", "\n", "        ", "zero_pad_shape", "=", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "zero_pad", "=", "torch", ".", "zeros", "(", "zero_pad_shape", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded_shape", "=", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "*", "x_padded_shape", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.forward": [[278, 368], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "outputs.append", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_mask.dim", "next", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.parameters", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "next", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.parameters", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "self", ".", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "self", ".", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "torch", ".", "sum", "(", "attn_mask", ")", ".", "item", "(", ")", ":", "\n", "            ", "attn_mask", "=", "(", "attn_mask", "==", "1", ")", "# Switch to bool", "\n", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                    ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "65000", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "else", ":", "\n", "                    ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                    ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "65000", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "else", ":", "\n", "                    ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "#### compute attention vector", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "outputs", "=", "[", "w", "+", "attn_out", "]", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "outputs", "=", "[", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "]", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "attn_prob", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.RelPartialLearnableDecoderLayer.__init__": [[371, 380], ["torch.Module.__init__", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "layer_norm_epsilon", "=", "layer_norm_epsilon", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ",", "\n", "layer_norm_epsilon", "=", "layer_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.RelPartialLearnableDecoderLayer.forward": [[381, 391], ["modeling_transfo_xl.RelPartialLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "\n", "        ", "attn_outputs", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "ff_output", "=", "self", ".", "pos_ff", "(", "attn_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "[", "ff_output", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.AdaptiveEmbedding.__init__": [[394, 423], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "range", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "len", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "sample_softmax", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "self", ".", "emb_layers", ".", "append", "(", "\n", "nn", ".", "Embedding", "(", "n_token", ",", "d_embed", ",", "sparse", "=", "sample_softmax", ">", "0", ")", "\n", ")", "\n", "if", "d_proj", "!=", "d_embed", ":", "\n", "                ", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_embed", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ")", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_emb_i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.AdaptiveEmbedding.forward": [[424, 455], ["torch.linear.mul_", "next", "inp.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view", "torch.zeros.view", "torch.linear", "torch.linear", "torch.linear", "modeling_transfo_xl.AdaptiveEmbedding.parameters", "len", "mask_i.nonzero().squeeze", "torch.linear", "torch.linear", "torch.linear", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "inp.size", "inp.view.size", "mask_i.nonzero().squeeze.numel", "inp.view.index_select", "mask_i.nonzero"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "embed", "=", "self", ".", "emb_layers", "[", "0", "]", "(", "inp", ")", "\n", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "                ", "embed", "=", "F", ".", "linear", "(", "embed", ",", "self", ".", "emb_projs", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "inp_flat", "=", "inp", ".", "view", "(", "-", "1", ")", "\n", "emb_flat", "=", "torch", ".", "zeros", "(", "[", "inp_flat", ".", "size", "(", "0", ")", ",", "self", ".", "d_proj", "]", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "\n", "mask_i", "=", "(", "inp_flat", ">=", "l_idx", ")", "&", "(", "inp_flat", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "inp_i", "=", "inp_flat", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "inp_i", ")", "\n", "emb_i", "=", "F", ".", "linear", "(", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "\n", "emb_flat", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "emb_i", ")", "\n", "\n", "", "embed_shape", "=", "inp", ".", "size", "(", ")", "+", "(", "self", ".", "d_proj", ",", ")", "\n", "embed", "=", "emb_flat", ".", "view", "(", "embed_shape", ")", "\n", "\n", "", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight": [[466, 471], ["torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["None"], ["def", "_init_weight", "(", "self", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "init", "==", "'uniform'", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "self", ".", "config", ".", "init_range", ",", "self", ".", "config", ".", "init_range", ")", "\n", "", "elif", "self", ".", "config", ".", "init", "==", "'normal'", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias": [[472, 474], ["torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "", "def", "_init_bias", "(", "self", ",", "bias", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weights": [[475, 515], ["classname.find", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "classname.find", "hasattr", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "range", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "len", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel.__init__": [[586, 641], ["modeling_utils.PreTrainedModel.__init__", "modeling_transfo_xl.AdaptiveEmbedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "modeling_transfo_xl.TransfoXLModel.init_weights", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl.PositionalEmbedding", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "modeling_transfo_xl.TransfoXLModel.layers.append", "modeling_transfo_xl.RelPartialLearnableDecoderLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "n_token", "=", "config", ".", "n_token", "\n", "\n", "self", ".", "d_embed", "=", "config", ".", "d_embed", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "\n", "self", ".", "word_emb", "=", "AdaptiveEmbedding", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "\n", "div_val", "=", "config", ".", "div_val", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "config", ".", "tgt_len", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "ext_len", "=", "config", ".", "ext_len", "\n", "self", ".", "max_klen", "=", "config", ".", "tgt_len", "+", "config", ".", "ext_len", "+", "config", ".", "mem_len", "\n", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "\n", "if", "not", "config", ".", "untie_r", ":", "\n", "            ", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "config", ".", "attn_type", "==", "0", ":", "# the default attention", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ",", "\n", "output_attentions", "=", "self", ".", "output_attentions", ",", "\n", "layer_norm_epsilon", "=", "config", ".", "layer_norm_epsilon", ")", "\n", ")", "\n", "", "", "else", ":", "# learnable embeddings and absolute embeddings are not used in our pretrained checkpoints", "\n", "            ", "raise", "NotImplementedError", "# Removed them to avoid maintaining dead code", "\n", "\n", "", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default attention", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel._resize_token_embeddings": [[642, 644], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "return", "self", ".", "word_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel.backward_compatible": [[645, 647], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel.reset_length": [[648, 652], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel._prune_heads": [[653, 656], ["logger.info"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Head pruning is not implemented for Transformer-XL model\"", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel.init_mems": [[657, 669], ["next", "range", "modeling_transfo_xl.TransfoXLModel.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mems.append", "data.size"], "methods", ["None"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", ")", ":", "\n", "                ", "empty", "=", "torch", ".", "zeros", "(", "self", ".", "mem_len", ",", "data", ".", "size", "(", "1", ")", ",", "self", ".", "config", ".", "d_model", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel._update_mems": [[670, 692], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_mems.append", "cat[].detach"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel.forward": [[693, 775], ["input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "input_ids.transpose().contiguous.transpose().contiguous.size", "modeling_transfo_xl.TransfoXLModel.word_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel._update_mems", "modeling_transfo_xl.TransfoXLModel.init_mems", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "mems[].size", "modeling_transfo_xl.TransfoXLModel.new_ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "modeling_transfo_xl.TransfoXLModel.transpose().contiguous", "list.append", "list", "outputs.append", "list", "outputs.append", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "list.append", "layer", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "modeling_transfo_xl.TransfoXLModel.new_ones", "list.append", "modeling_transfo_xl.TransfoXLModel.transpose", "t.transpose().contiguous", "t.permute().contiguous", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_transfo_xl.TransfoXLModel.parameters", "t.transpose", "t.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLModel._update_mems", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# the original code for Transformer-XL used shapes [len, bsz] but we want a unified interface in the library", "\n", "# so we transpose here from shape [bsz, len] to shape [len, bsz]", "\n", "        ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", "input_ids", ")", "\n", "\n", "", "qlen", ",", "bsz", "=", "input_ids", ".", "size", "(", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "word_emb", "=", "self", ".", "word_emb", "(", "input_ids", ")", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "all_ones", "=", "word_emb", ".", "new_ones", "(", "(", "qlen", ",", "klen", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "mask_len", "=", "klen", "-", "self", ".", "mem_len", "\n", "if", "mask_len", ">", "0", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "-", "mask_len", "\n", "", "else", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "\n", "", "dec_attn_mask", "=", "(", "torch", ".", "triu", "(", "all_ones", ",", "1", "+", "mlen", ")", "\n", "+", "torch", ".", "tril", "(", "all_ones", ",", "-", "mask_shift_len", ")", ")", "[", ":", ",", ":", ",", "None", "]", "# -1", "\n", "", "else", ":", "\n", "            ", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "word_emb", ".", "new_ones", "(", "(", "qlen", ",", "klen", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "diagonal", "=", "1", "+", "mlen", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "hids", "=", "[", "]", "\n", "attentions", "=", "[", "]", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "layer_outputs", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "", "", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "# We transpose back here to shape [bsz, len, hidden_dim]", "\n", "outputs", "=", "[", "core_out", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "new_mems", "]", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "# Add last layer and transpose to library standard shape [bsz, len, hidden_dim]", "\n", "            ", "hids", ".", "append", "(", "core_out", ")", "\n", "hids", "=", "list", "(", "t", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "hids", ")", "\n", "outputs", ".", "append", "(", "hids", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# Transpose to library standard shape [bsz, n_heads, query_seq_len, key_seq_len]", "\n", "            ", "attentions", "=", "list", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", ".", "append", "(", "attentions", ")", "\n", "\n", "", "return", "outputs", "# last hidden state, new_mems, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.__init__": [[816, 830], ["modeling_utils.PreTrainedModel.__init__", "modeling_transfo_xl.TransfoXLModel", "modeling_transfo_xl.TransfoXLLMHeadModel.init_weights", "modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights", "torch.Linear", "torch.Linear", "torch.Linear", "LogUniformSampler", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "TransfoXLModel", "(", "config", ")", "\n", "self", ".", "sample_softmax", "=", "config", ".", "sample_softmax", "\n", "# use sampled softmax", "\n", "if", "config", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "self", ".", "out_layer", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "n_token", ")", "\n", "self", ".", "sampler", "=", "LogUniformSampler", "(", "config", ".", "n_token", ",", "config", ".", "sample_softmax", ")", "\n", "# use adaptive softmax (including standard softmax)", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "ProjectedAdaptiveLogSoftmax", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "\n", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", ")", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights": [[831, 857], ["range", "enumerate", "len", "modeling_transfo_xl.TransfoXLLMHeadModel._tie_or_clone_weights", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer.word_emb.emb_projs[].clone", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer.word_emb.emb_projs[].clone"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run this to be sure output and input (adaptive) softmax weights are tied\n        \"\"\"", "\n", "# sampled softmax", "\n", "if", "self", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "self", ".", "out_layer", ".", "weight", "=", "self", ".", "transformer", ".", "word_emb", ".", "weight", "\n", "# adaptive softmax (including standard softmax)", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "crit", ".", "out_layers", ")", ")", ":", "\n", "                    ", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "crit", ".", "out_layers", "[", "i", "]", ",", "\n", "self", ".", "transformer", ".", "word_emb", ".", "emb_layers", "[", "i", "]", ")", "\n", "", "", "if", "self", ".", "config", ".", "tie_projs", ":", "\n", "                ", "for", "i", ",", "tie_proj", "in", "enumerate", "(", "self", ".", "config", ".", "tie_projs", ")", ":", "\n", "                    ", "if", "tie_proj", "and", "self", ".", "config", ".", "div_val", "==", "1", "and", "self", ".", "config", ".", "d_model", "!=", "self", ".", "config", ".", "d_embed", ":", "\n", "                        ", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "nn", ".", "Parameter", "(", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", "\n", "", "", "elif", "tie_proj", "and", "self", ".", "config", ".", "div_val", "!=", "1", ":", "\n", "                        ", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "nn", ".", "Parameter", "(", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length": [[858, 860], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.reset_length"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length"], ["", "", "", "", "", "", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "reset_length", "(", "tgt_len", ",", "ext_len", ",", "mem_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems": [[861, 863], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.init_mems"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "init_mems", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.forward": [[864, 891], ["input_ids.size", "input_ids.size", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer", "modeling_transfo_xl_utilities.sample_logits", "modeling_transfo_xl.TransfoXLLMHeadModel.crit", "pred_hid.view", "softmax_output.view.view.view", "softmax_output.view.view.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "pred_hid.size"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.sample_logits"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "bsz", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "tgt_len", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "last_hidden", "=", "transformer_outputs", "[", "0", "]", "\n", "pred_hid", "=", "last_hidden", "[", ":", ",", "-", "tgt_len", ":", "]", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "self", ".", "sample_softmax", ">", "0", "and", "self", ".", "training", ":", "\n", "            ", "assert", "self", ".", "config", ".", "tie_weight", "\n", "logit", "=", "sample_logits", "(", "self", ".", "transformer", ".", "word_emb", ",", "self", ".", "out_layer", ".", "bias", ",", "labels", ",", "pred_hid", ",", "self", ".", "sampler", ")", "\n", "softmax_output", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "-", "1", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# TODO: This is not implemented", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "            ", "softmax_output", "=", "self", ".", "crit", "(", "pred_hid", ".", "view", "(", "-", "1", ",", "pred_hid", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ")", "\n", "if", "labels", "is", "None", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ",", "-", "1", ")", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "", "else", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ")", "\n", "outputs", "=", "[", "softmax_output", ",", "None", "]", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "# (loss), logits or None if labels is not None (speed up adaptive softmax), new_mems, (all hidden states), (all attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.build_tf_to_pytorch_map": [[48, 119], ["hasattr", "enumerate", "enumerate", "tf_to_pt_map.update", "tf_to_pt_map.update", "enumerate", "zip", "tf_to_pt_map.update", "tf_to_pt_map.update", "zip", "r_r_list.append", "r_w_list.append", "tf_to_pt_map.update", "tf_to_pt_map.update", "tf_to_pt_map.update"], "function", ["None"], ["def", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        This time I use a map to keep the PyTorch model as identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "# We are loading in a TransfoXLLMHeadModel => we will load also the Adaptive Softmax", "\n", "        ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_W\"", ":", "model", ".", "crit", ".", "cluster_weight", ",", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_b\"", ":", "model", ".", "crit", ".", "cluster_bias", "}", ")", "\n", "for", "i", ",", "(", "out_l", ",", "proj_l", ",", "tie_proj", ")", "in", "enumerate", "(", "zip", "(", "\n", "model", ".", "crit", ".", "out_layers", ",", "\n", "model", ".", "crit", ".", "out_projs", ",", "\n", "config", ".", "tie_projs", ")", ")", ":", "\n", "            ", "layer_str", "=", "\"transformer/adaptive_softmax/cutoff_%d/\"", "%", "i", "\n", "if", "config", ".", "tie_weight", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "# I don't think this is implemented in the TF code", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "out_l", ".", "weight", ",", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "if", "not", "tie_proj", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'proj'", ":", "proj_l", "\n", "}", ")", "\n", "# Now load the rest of the transformer", "\n", "", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings", "\n", "", "for", "i", ",", "(", "embed_l", ",", "proj_l", ")", "in", "enumerate", "(", "zip", "(", "model", ".", "word_emb", ".", "emb_layers", ",", "model", ".", "word_emb", ".", "emb_projs", ")", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/adaptive_embed/cutoff_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "embed_l", ".", "weight", ",", "\n", "layer_str", "+", "'proj_W'", ":", "proj_l", "\n", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layers", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "dec_attn", ".", "o_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/qkv/kernel\"", ":", "b", ".", "dec_attn", ".", "qkv_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "dec_attn", ".", "r_net", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layers", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_w_bias", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'transformer/r_w_bias'", ":", "r_w_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl": [[120, 174], ["modeling_transfo_xl.build_tf_to_pytorch_map", "tf.train.list_variables", "build_tf_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "logger.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.build_tf_to_pytorch_map"], ["", "def", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", "\n", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "assert", "name", "in", "tf_weights", "\n", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "or", "'proj'", "in", "name", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "(", "'r_r_bias'", "in", "name", "or", "'r_w_bias'", "in", "name", ")", "and", "len", "(", "pointer", ")", ">", "1", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer.__init__": [[131, 142], ["tokenization_utils.PreTrainedTokenizer.__init__", "json.load", "dict", "io.open", "io.open().read().split", "tuple", "zip", "tokenization_ctrl.CTRLTokenizer.encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CTRLTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer.vocab_size": [[143, 146], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer.bpe": [[147, 189], ["tuple", "tuple", "tokenization_ctrl.get_pairs", "min", "tuple", "list", "len", "len", "tokenization_ctrl.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_ctrl.CTRLTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "word", "=", "tuple", "(", "list", "(", "word", "[", ":", "-", "1", "]", ")", "+", "[", "word", "[", "-", "1", "]", "+", "'</w>'", "]", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "'@@ '", ".", "join", "(", "word", ")", "\n", "word", "=", "word", "[", ":", "-", "4", "]", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer._tokenize": [[190, 200], ["text.split.split.split", "split_tokens.extend", "tokenization_ctrl.CTRLTokenizer.bpe().split", "tokenization_ctrl.CTRLTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n        \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "\n", "text", "=", "text", ".", "split", "(", "' '", ")", "\n", "\n", "for", "token", "in", "text", ":", "\n", "            ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer._convert_token_to_id": [[201, 204], ["tokenization_ctrl.CTRLTokenizer.encoder.get", "tokenization_ctrl.CTRLTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer._convert_id_to_token": [[205, 208], ["tokenization_ctrl.CTRLTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer.convert_tokens_to_string": [[209, 213], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "' '", ".", "join", "(", "tokens", ")", ".", "replace", "(", "'@@ '", ",", "''", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.CTRLTokenizer.save_vocabulary": [[214, 237], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "writer.write", "sorted", "json.dumps", "tokenization_ctrl.CTRLTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "u'#version: 0.2\\n'", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_ctrl.get_pairs": [[107, 120], ["set", "set", "set.add"], "function", ["None"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "\n", "", "pairs", "=", "set", "(", "pairs", ")", "\n", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.__init__": [[539, 573], ["tokenization_utils.PreTrainedTokenizer.__init__", "dict", "dict", "set", "json.load", "dict", "io.open", "io.open().read().split", "tuple", "zip", "len", "len", "tokenization_xlm.XLMTokenizer.encoder.items", "range", "io.open().read", "merge.split", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "bos_token", "=", "\"<s>\"", ",", "\n", "sep_token", "=", "\"</s>\"", ",", "pad_token", "=", "\"<pad>\"", ",", "cls_token", "=", "\"</s>\"", ",", "\n", "mask_token", "=", "\"<special1>\"", ",", "additional_special_tokens", "=", "[", "\"<special0>\"", ",", "\n", "\"<special1>\"", ",", "\"<special2>\"", ",", "\"<special3>\"", ",", "\"<special4>\"", ",", "\"<special5>\"", ",", "\n", "\"<special6>\"", ",", "\"<special7>\"", ",", "\"<special8>\"", ",", "\"<special9>\"", "]", ",", "\n", "lang2id", "=", "None", ",", "id2lang", "=", "None", ",", "do_lowercase_and_remove_accent", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLMTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "bos_token", "=", "bos_token", ",", "\n", "sep_token", "=", "sep_token", ",", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "mask_token", "=", "mask_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", ")", "\n", "\n", "# cache of sm.MosesPunctNormalizer instance", "\n", "self", ".", "cache_moses_punct_normalizer", "=", "dict", "(", ")", "\n", "# cache of sm.MosesTokenizer instance", "\n", "self", ".", "cache_moses_tokenizer", "=", "dict", "(", ")", "\n", "self", ".", "lang_with_custom_tokenizer", "=", "set", "(", "[", "'zh'", ",", "'th'", ",", "'ja'", "]", ")", "\n", "# True for current supported model (v1.2.0), False for XLM-17 & 100", "\n", "self", ".", "do_lowercase_and_remove_accent", "=", "do_lowercase_and_remove_accent", "\n", "self", ".", "lang2id", "=", "lang2id", "\n", "self", ".", "id2lang", "=", "id2lang", "\n", "if", "lang2id", "is", "not", "None", "and", "id2lang", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "lang2id", ")", "==", "len", "(", "id2lang", ")", "\n", "\n", "", "self", ".", "ja_word_tokenizer", "=", "None", "\n", "self", ".", "zh_word_tokenizer", "=", "None", "\n", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", "[", ":", "2", "]", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_punct_norm": [[574, 581], ["sacremoses.MosesPunctNormalizer.normalize", "sacremoses.MosesPunctNormalizer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.normalize"], ["", "def", "moses_punct_norm", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "if", "lang", "not", "in", "self", ".", "cache_moses_punct_normalizer", ":", "\n", "            ", "punct_normalizer", "=", "sm", ".", "MosesPunctNormalizer", "(", "lang", "=", "lang", ")", "\n", "self", ".", "cache_moses_punct_normalizer", "[", "lang", "]", "=", "punct_normalizer", "\n", "", "else", ":", "\n", "            ", "punct_normalizer", "=", "self", ".", "cache_moses_punct_normalizer", "[", "lang", "]", "\n", "", "return", "punct_normalizer", ".", "normalize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_tokenize": [[582, 589], ["sacremoses.MosesTokenizer.tokenize", "sacremoses.MosesTokenizer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "moses_tokenize", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "if", "lang", "not", "in", "self", ".", "cache_moses_tokenizer", ":", "\n", "            ", "moses_tokenizer", "=", "sm", ".", "MosesTokenizer", "(", "lang", "=", "lang", ")", "\n", "self", ".", "cache_moses_tokenizer", "[", "lang", "]", "=", "moses_tokenizer", "\n", "", "else", ":", "\n", "            ", "moses_tokenizer", "=", "self", ".", "cache_moses_tokenizer", "[", "lang", "]", "\n", "", "return", "moses_tokenizer", ".", "tokenize", "(", "text", ",", "return_str", "=", "False", ",", "escape", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline": [[590, 595], ["tokenization_xlm.replace_unicode_punct", "tokenization_xlm.XLMTokenizer.moses_punct_norm", "tokenization_xlm.remove_non_printing_char"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.replace_unicode_punct", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_punct_norm", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.remove_non_printing_char"], ["", "def", "moses_pipeline", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "text", "=", "replace_unicode_punct", "(", "text", ")", "\n", "text", "=", "self", ".", "moses_punct_norm", "(", "text", ",", "lang", ")", "\n", "text", "=", "remove_non_printing_char", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.ja_tokenize": [[596, 610], ["list", "tokenization_xlm.XLMTokenizer.ja_word_tokenizer.getWS", "Mykytea.Mykytea", "logger.error", "logger.error", "logger.error", "logger.error", "logger.error", "logger.error", "os.path.expanduser"], "methods", ["None"], ["", "def", "ja_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "ja_word_tokenizer", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "import", "Mykytea", "\n", "self", ".", "ja_word_tokenizer", "=", "Mykytea", ".", "Mykytea", "(", "'-model %s/local/share/kytea/model.bin'", "%", "os", ".", "path", ".", "expanduser", "(", "'~'", ")", ")", "\n", "", "except", "(", "AttributeError", ",", "ImportError", ")", "as", "e", ":", "\n", "                ", "logger", ".", "error", "(", "\"Make sure you install KyTea (https://github.com/neubig/kytea) and it's python wrapper (https://github.com/chezou/Mykytea-python) with the following steps\"", ")", "\n", "logger", ".", "error", "(", "\"1. git clone git@github.com:neubig/kytea.git && cd kytea\"", ")", "\n", "logger", ".", "error", "(", "\"2. autoreconf -i\"", ")", "\n", "logger", ".", "error", "(", "\"3. ./configure --prefix=$HOME/local\"", ")", "\n", "logger", ".", "error", "(", "\"4. make && make install\"", ")", "\n", "logger", ".", "error", "(", "\"5. pip install kytea\"", ")", "\n", "raise", "e", "\n", "", "", "return", "list", "(", "self", ".", "ja_word_tokenizer", ".", "getWS", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.vocab_size": [[611, 614], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.bpe": [[615, 657], ["tokenization_xlm.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_xlm.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_xlm.XLMTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "'\\n</w>'", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer._tokenize": [[658, 743], ["logger.error", "tokenization_xlm.XLMTokenizer.split", "tokenization_xlm.lowercase_and_remove_accent", "tokenization_xlm.XLMTokenizer.moses_pipeline", "tokenization_xlm.XLMTokenizer.moses_tokenize", "split_tokens.extend", "tokenization_xlm.romanian_preprocessing", "tokenization_xlm.XLMTokenizer.moses_pipeline", "th_word_tokenize", "tokenization_xlm.XLMTokenizer.moses_pipeline", "tokenization_xlm.XLMTokenizer.split", "logger.error", "logger.error", "jieba.cut", "tokenization_xlm.XLMTokenizer.moses_pipeline", "tokenization_xlm.XLMTokenizer.ja_tokenize", "ValueError", "tokenization_xlm.XLMTokenizer.bpe().split", "logger.error", "logger.error", "tokenization_xlm.XLMTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.lowercase_and_remove_accent", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.romanian_preprocessing", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.ja_tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "lang", "=", "'en'", ",", "bypass_tokenizer", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Tokenize a string given language code. For Chinese, Japanese and Thai, we use a language specific tokenizerself. Otherwise, we use Moses.\n\n        Details of tokenization:\n        - [sacremoses](https://github.com/alvations/sacremoses): port of Moses\n            - Install with `pip install sacremoses`\n        - [pythainlp](https://github.com/PyThaiNLP/pythainlp): Thai tokenizer\n            - Install with `pip install pythainlp`\n        - [kytea](https://github.com/chezou/Mykytea-python): Japanese tokenizer, wrapper of [KyTea](https://github.com/neubig/kytea)\n            - Install with the following steps:\n            ```\n            git clone git@github.com:neubig/kytea.git && cd kytea\n            autoreconf -i\n            ./configure --prefix=$HOME/local\n            make && make install\n            pip install kytea\n            ```\n        - [jieba](https://github.com/fxsjy/jieba): Chinese tokenizer *\n            - Install with `pip install jieba`\n\n        \\* The original XLM used [Stanford Segmenter](https://nlp.stanford.edu/software/stanford-segmenter-2018-10-16.zip).\n        However, the wrapper (`nltk.tokenize.stanford_segmenter`) is slow due to JVM overhead, and it will be deprecated.\n        Jieba is a lot faster and pip-installable. Note there is some mismatch with the Stanford Segmenter. It should be fine\n        if you fine-tune the model with Chinese supervisionself. If you want the same exact behaviour, use the original XLM\n        [preprocessing script](https://github.com/facebookresearch/XLM/tree/master/tools) to tokenize the sentence externally,\n        and set `bypass_tokenizer=True` to bypass the tokenizer.\n\n        Args:\n            - lang: ISO language code (default = 'en') (string). Languages should belong of the model supported languages. However, we don't enforce it.\n            - bypass_tokenizer: Allow users to preprocess and tokenize the sentences externally (default = False)  (bool). If True, we only apply BPE.\n\n        Returns:\n            List of tokens.\n        \"\"\"", "\n", "if", "lang", "and", "self", ".", "lang2id", "and", "lang", "not", "in", "self", ".", "lang2id", ":", "\n", "            ", "logger", ".", "error", "(", "\"Supplied language code not found in lang2id mapping. Please check that your language is supported by the loaded pretrained model.\"", ")", "\n", "", "if", "bypass_tokenizer", ":", "\n", "            ", "text", "=", "text", ".", "split", "(", ")", "\n", "", "elif", "lang", "not", "in", "self", ".", "lang_with_custom_tokenizer", ":", "\n", "            ", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "# TODO: make sure we are using `xlm-mlm-enro-1024`, since XLM-100 doesn't have this step", "\n", "if", "lang", "==", "'ro'", ":", "\n", "                ", "text", "=", "romanian_preprocessing", "(", "text", ")", "\n", "", "text", "=", "self", ".", "moses_tokenize", "(", "text", ",", "lang", "=", "lang", ")", "\n", "", "elif", "lang", "==", "'th'", ":", "\n", "            ", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "try", ":", "\n", "                ", "if", "'pythainlp'", "not", "in", "sys", ".", "modules", ":", "\n", "                    ", "from", "pythainlp", ".", "tokenize", "import", "word_tokenize", "as", "th_word_tokenize", "\n", "", "else", ":", "\n", "                    ", "th_word_tokenize", "=", "sys", ".", "modules", "[", "'pythainlp'", "]", ".", "word_tokenize", "\n", "", "", "except", "(", "AttributeError", ",", "ImportError", ")", "as", "e", ":", "\n", "                ", "logger", ".", "error", "(", "\"Make sure you install PyThaiNLP (https://github.com/PyThaiNLP/pythainlp) with the following steps\"", ")", "\n", "logger", ".", "error", "(", "\"1. pip install pythainlp\"", ")", "\n", "raise", "e", "\n", "", "text", "=", "th_word_tokenize", "(", "text", ")", "\n", "", "elif", "lang", "==", "'zh'", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "'jieba'", "not", "in", "sys", ".", "modules", ":", "\n", "                    ", "import", "jieba", "\n", "", "else", ":", "\n", "                    ", "jieba", "=", "sys", ".", "modules", "[", "'jieba'", "]", "\n", "", "", "except", "(", "AttributeError", ",", "ImportError", ")", "as", "e", ":", "\n", "                ", "logger", ".", "error", "(", "\"Make sure you install Jieba (https://github.com/fxsjy/jieba) with the following steps\"", ")", "\n", "logger", ".", "error", "(", "\"1. pip install jieba\"", ")", "\n", "raise", "e", "\n", "", "text", "=", "' '", ".", "join", "(", "jieba", ".", "cut", "(", "text", ")", ")", "\n", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "text", "=", "text", ".", "split", "(", ")", "\n", "", "elif", "lang", "==", "'ja'", ":", "\n", "            ", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "text", "=", "self", ".", "ja_tokenize", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'It should not reach here'", ")", "\n", "\n", "", "if", "self", ".", "do_lowercase_and_remove_accent", "and", "not", "bypass_tokenizer", ":", "\n", "            ", "text", "=", "lowercase_and_remove_accent", "(", "text", ")", "\n", "\n", "", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "            ", "if", "token", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer._convert_token_to_id": [[744, 747], ["tokenization_xlm.XLMTokenizer.encoder.get", "tokenization_xlm.XLMTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer._convert_id_to_token": [[748, 751], ["tokenization_xlm.XLMTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.convert_tokens_to_string": [[752, 756], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.build_inputs_with_special_tokens": [[757, 770], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.get_special_tokens_mask": [[771, 796], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.create_token_type_ids_from_sequences": [[797, 811], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        An XLM sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.XLMTokenizer.save_vocabulary": [[812, 834], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "sorted", "json.dumps", "tokenization_xlm.XLMTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.get_pairs": [[415, 426], ["set", "set.add"], "function", ["None"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.lowercase_and_remove_accent": [[428, 443], ["unicodedata.normalize.lower", "unicodedata.normalize", "unicodedata.category", "output.append"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.normalize"], ["", "def", "lowercase_and_remove_accent", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    Lowercase and strips accents from a piece of text based on\n    https://github.com/facebookresearch/XLM/blob/master/tools/lowercase_and_remove_accent.py\n    \"\"\"", "\n", "text", "=", "' '", ".", "join", "(", "text", ")", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "        ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "            ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", ".", "lower", "(", ")", ".", "split", "(", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.replace_unicode_punct": [[445, 486], ["text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace"], "function", ["None"], ["", "def", "replace_unicode_punct", "(", "text", ")", ":", "\n", "    ", "'''\n    Port of https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/replace-unicode-punctuation.perl\n    '''", "\n", "text", "=", "text", ".", "replace", "(", "'\uff0c'", ",", "','", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\u3002\\s*'", ",", "'. '", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u3001'", ",", "','", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u201d'", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u201c'", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2236'", ",", "':'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff1a'", ",", "':'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff1f'", ",", "'?'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u300a'", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u300b'", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff09'", ",", "')'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff01'", ",", "'!'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff08'", ",", "'('", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff1b'", ",", "';'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff11'", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u300d'", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u300c'", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff10'", ",", "'0'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff13'", ",", "'3'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff12'", ",", "'2'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff15'", ",", "'5'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff16'", ",", "'6'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff19'", ",", "'9'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff17'", ",", "'7'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff18'", ",", "'8'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff14'", ",", "'4'", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\uff0e\\s*'", ",", "'. '", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff5e'", ",", "'~'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2019'", ",", "'\\''", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2501'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u3008'", ",", "'<'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u3009'", ",", "'>'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u3010'", ",", "'['", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u3011'", ",", "']'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\uff05'", ",", "'%'", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.remove_non_printing_char": [[488, 499], ["unicodedata.category", "unicodedata.category.startswith", "output.append"], "function", ["None"], ["", "def", "remove_non_printing_char", "(", "text", ")", ":", "\n", "    ", "'''\n    Port of https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/remove-non-printing-char.perl\n    '''", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "        ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "'C'", ")", ":", "\n", "            ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_xlm.romanian_preprocessing": [[501, 513], ["text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace"], "function", ["None"], ["", "def", "romanian_preprocessing", "(", "text", ")", ":", "\n", "    ", "'''Sennrich's WMT16 scripts for Romanian preprocessing, used by model `xlm-mlm-enro-1024`'''", "\n", "# https://github.com/rsennrich/wmt16-scripts/blob/master/preprocess/normalise-romanian.py", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u015e\"", ",", "\"\\u0218\"", ")", ".", "replace", "(", "\"\\u015f\"", ",", "\"\\u0219\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u0162\"", ",", "\"\\u021a\"", ")", ".", "replace", "(", "\"\\u0163\"", ",", "\"\\u021b\"", ")", "\n", "# https://github.com/rsennrich/wmt16-scripts/blob/master/preprocess/remove-diacritics.py", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u0218\"", ",", "\"S\"", ")", ".", "replace", "(", "\"\\u0219\"", ",", "\"s\"", ")", "#s-comma", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u021a\"", ",", "\"T\"", ")", ".", "replace", "(", "\"\\u021b\"", ",", "\"t\"", ")", "#t-comma", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u0102\"", ",", "\"A\"", ")", ".", "replace", "(", "\"\\u0103\"", ",", "\"a\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u00C2\"", ",", "\"A\"", ")", ".", "replace", "(", "\"\\u00E2\"", ",", "\"a\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u00CE\"", ",", "\"I\"", ")", ".", "replace", "(", "\"\\u00EE\"", ",", "\"i\"", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer.__init__": [[129, 168], ["tokenization_utils.PreTrainedTokenizer.__init__", "tokenization_bert.load_vocab", "collections.OrderedDict", "tokenization_bert.WordpieceTokenizer", "os.path.isfile", "ValueError", "tokenization_bert.BasicTokenizer", "tokenization_bert.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ",", "do_basic_tokenize", "=", "True", ",", "never_split", "=", "None", ",", "\n", "unk_token", "=", "\"[UNK]\"", ",", "sep_token", "=", "\"[SEP]\"", ",", "pad_token", "=", "\"[PAD]\"", ",", "cls_token", "=", "\"[CLS]\"", ",", "\n", "mask_token", "=", "\"[MASK]\"", ",", "tokenize_chinese_chars", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs a BertTokenizer.\n\n        Args:\n            **vocab_file**: Path to a one-wordpiece-per-line vocabulary file\n            **do_lower_case**: (`optional`) boolean (default True)\n                Whether to lower case the input\n                Only has an effect when do_basic_tokenize=True\n            **do_basic_tokenize**: (`optional`) boolean (default True)\n                Whether to do basic tokenization before wordpiece.\n            **never_split**: (`optional`) list of string\n                List of tokens which will never be split during tokenization.\n                Only has an effect when do_basic_tokenize=True\n            **tokenize_chinese_chars**: (`optional`) boolean (default True)\n                Whether to tokenize Chinese characters.\n                This should likely be deactivated for Japanese:\n                see: https://github.com/huggingface/pytorch-pretrained-BERT/issues/328\n        \"\"\"", "\n", "super", "(", "BertTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "**", "kwargs", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "do_basic_tokenize", "=", "do_basic_tokenize", "\n", "if", "do_basic_tokenize", ":", "\n", "            ", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ",", "\n", "never_split", "=", "never_split", ",", "\n", "tokenize_chinese_chars", "=", "tokenize_chinese_chars", ")", "\n", "", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ",", "unk_token", "=", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer.vocab_size": [[169, 172], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer._tokenize": [[173, 182], ["tokenization_bert.BertTokenizer.basic_tokenizer.tokenize", "tokenization_bert.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization_bert.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization_bert.BertTokenizer.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "do_basic_tokenize", ":", "\n", "            ", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ",", "never_split", "=", "self", ".", "all_special_tokens", ")", ":", "\n", "                ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                    ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "", "else", ":", "\n", "            ", "split_tokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer._convert_token_to_id": [[183, 186], ["tokenization_bert.BertTokenizer.vocab.get", "tokenization_bert.BertTokenizer.vocab.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "vocab", ".", "get", "(", "token", ",", "self", ".", "vocab", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer._convert_id_to_token": [[187, 190], ["tokenization_bert.BertTokenizer.ids_to_tokens.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "ids_to_tokens", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer.convert_tokens_to_string": [[191, 195], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "' '", ".", "join", "(", "tokens", ")", ".", "replace", "(", "' ##'", ",", "''", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer.build_inputs_with_special_tokens": [[196, 209], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A BERT sequence has the following format:\n            single sequence: [CLS] X [SEP]\n            pair of sequences: [CLS] A [SEP] B [SEP]\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer.get_special_tokens_mask": [[210, 235], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer.create_token_type_ids_from_sequences": [[236, 250], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A BERT sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BertTokenizer.save_vocabulary": [[251, 267], ["os.path.isdir", "os.path.join", "io.open", "sorted", "tokenization_bert.BertTokenizer.vocab.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "index", "=", "0", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "vocab_path", "\n", "", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "token", ",", "token_index", "in", "sorted", "(", "self", ".", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"", "\n", "\" Please check that the vocabulary is not corrupted!\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "token", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "", "", "return", "(", "vocab_file", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer.__init__": [[272, 291], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "do_lower_case", "=", "True", ",", "never_split", "=", "None", ",", "tokenize_chinese_chars", "=", "True", ")", ":", "\n", "        ", "\"\"\" Constructs a BasicTokenizer.\n\n        Args:\n            **do_lower_case**: Whether to lower case the input.\n            **never_split**: (`optional`) list of str\n                Kept for backward compatibility purposes.\n                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)\n                List of token not to split.\n            **tokenize_chinese_chars**: (`optional`) boolean (default True)\n                Whether to tokenize Chinese characters.\n                This should likely be deactivated for Japanese:\n                see: https://github.com/huggingface/pytorch-pretrained-BERT/issues/328\n        \"\"\"", "\n", "if", "never_split", "is", "None", ":", "\n", "            ", "never_split", "=", "[", "]", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "\n", "self", ".", "tokenize_chinese_chars", "=", "tokenize_chinese_chars", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer.tokenize": [[292, 322], ["tokenization_bert.BasicTokenizer._clean_text", "tokenization_bert.whitespace_tokenize", "tokenization_bert.whitespace_tokenize", "tokenization_bert.BasicTokenizer._tokenize_chinese_chars", "split_tokens.extend", "tokenization_bert.BasicTokenizer.lower", "tokenization_bert.BasicTokenizer._run_strip_accents", "tokenization_bert.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.whitespace_tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.whitespace_tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "never_split", "=", "None", ")", ":", "\n", "        ", "\"\"\" Basic Tokenization of a piece of text.\n            Split on \"white spaces\" only, for sub-word tokenization, see WordPieceTokenizer.\n\n        Args:\n            **never_split**: (`optional`) list of str\n                Kept for backward compatibility purposes.\n                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)\n                List of token not to split.\n        \"\"\"", "\n", "never_split", "=", "self", ".", "never_split", "+", "(", "never_split", "if", "never_split", "is", "not", "None", "else", "[", "]", ")", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "if", "self", ".", "tokenize_chinese_chars", ":", "\n", "            ", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._run_strip_accents": [[323, 333], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.normalize"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._run_split_on_punc": [[334, 355], ["list", "len", "tokenization_bert._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ",", "never_split", "=", "None", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "never_split", "is", "not", "None", "and", "text", "in", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._tokenize_chinese_chars": [[356, 368], ["ord", "tokenization_bert.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._is_chinese_char": [[369, 390], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.BasicTokenizer._clean_text": [[391, 403], ["ord", "tokenization_bert._is_whitespace", "tokenization_bert._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.WordpieceTokenizer.__init__": [[408, 412], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.WordpieceTokenizer.tokenize": [[413, 463], ["tokenization_bert.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.load_vocab": [[89, 98], ["collections.OrderedDict", "enumerate", "io.open", "reader.readlines", "token.rstrip.rstrip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "tokens", "=", "reader", ".", "readlines", "(", ")", "\n", "", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "token", "=", "token", ".", "rstrip", "(", "'\\n'", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert.whitespace_tokenize": [[100, 107], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace": [[465, 475], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_control": [[477, 487], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation": [[489, 503], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.__init__": [[32, 77], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.Linear", "torch.Linear", "torch.Linear", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "keep_order", "=", "False", ")", ":", "\n", "        ", "super", "(", "ProjectedAdaptiveLogSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "if", "self", ".", "n_clusters", ">", "0", ":", "\n", "            ", "self", ".", "cluster_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ",", "self", ".", "d_embed", ")", ")", "\n", "self", ".", "cluster_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ")", ")", "\n", "\n", "", "self", ".", "out_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "d_proj", "!=", "d_embed", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_embed", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "None", ")", "\n", "\n", "", "", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_embed", ",", "n_token", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "\n", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_emb_i", ")", ")", "\n", ")", "\n", "\n", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "r_idx", "-", "l_idx", ")", ")", "\n", "\n", "", "", "self", ".", "keep_order", "=", "keep_order", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit": [[78, 91], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "proj.t().contiguous", "proj.t"], "methods", ["None"], ["", "def", "_compute_logit", "(", "self", ",", "hidden", ",", "weight", ",", "bias", ",", "proj", ")", ":", "\n", "        ", "if", "proj", "is", "None", ":", "\n", "            ", "logit", "=", "F", ".", "linear", "(", "hidden", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# if CUDA_MAJOR <= 9 and CUDA_MINOR <= 1:", "\n", "            ", "proj_hid", "=", "F", ".", "linear", "(", "hidden", ",", "proj", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "\n", "logit", "=", "F", ".", "linear", "(", "proj_hid", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "# else:", "\n", "#     logit = torch.einsum('bd,de,ev->bv', (hidden, proj, weight.t()))", "\n", "#     if bias is not None:", "\n", "#         logit = logit + bias", "\n", "\n", "", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.forward": [[92, 196], ["labels.view.view.view", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "hidden.size", "labels.view.view.size", "RuntimeError", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "len", "weights.append", "biases.append", "hidden.new_empty", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "mask_i.nonzero().squeeze", "torch.log_softmax.index_select", "hidden.index_select", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "head_logprob.index_select.gather().squeeze.size", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "mask_i.nonzero().squeeze.numel", "labels.view.view.index_select", "F.log_softmax.index_select.gather().squeeze", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "out[].copy_", "torch.log_softmax().gather", "torch.log_softmax().gather", "torch.log_softmax().gather", "mask_i.nonzero", "torch.log_softmax.gather().squeeze", "hasattr", "labels.view.view.unsqueeze", "F.log_softmax.index_select.gather", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.gather", "head_logprob.index_select.gather().squeeze.size"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "labels", "=", "None", ",", "keep_order", "=", "False", ")", ":", "\n", "        ", "'''\n            Params:\n                hidden :: [len*bsz x d_proj]\n                labels :: [len*bsz]\n            Return:\n                if labels is None:\n                    out :: [len*bsz] Negative log likelihood\n                else:\n                    out :: [len*bsz x n_tokens] log probabilities of tokens over the vocabulary\n            We could replace this implementation by the native PyTorch one\n            if their's had an option to set bias on all clusters in the native one.\n            here: https://github.com/pytorch/pytorch/blob/dbe6a7a9ff1a364a8706bf5df58a1ca96d2fd9da/torch/nn/modules/adaptive.py#L138\n        '''", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "if", "hidden", ".", "size", "(", "0", ")", "!=", "labels", ".", "size", "(", "0", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Input and labels should have the same size '", "\n", "'in the batch dimension.'", ")", "\n", "\n", "", "", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                ", "out", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", ".", "gather", "(", "1", ",", "labels", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "                ", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "torch", ".", "zeros_like", "(", "labels", ",", "dtype", "=", "hidden", ".", "dtype", ",", "device", "=", "hidden", ".", "device", ")", "\n", "\n", "", "offset", "=", "0", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "mask_i", "=", "(", "labels", ">=", "l_idx", ")", "&", "(", "labels", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "target_i", "=", "labels", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "head_logprob_i", "=", "head_logprob", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "hidden_i", "=", "hidden", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "", "else", ":", "\n", "                    ", "hidden_i", "=", "hidden", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "if", "labels", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden_i", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "cluster_prob_idx", "=", "self", ".", "cutoffs", "[", "0", "]", "+", "i", "-", "1", "# No probability for the head cluster", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", "[", ":", ",", "cluster_prob_idx", "]", "+", "tail_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "logprob_i", "=", "head_logprob", "[", ":", ",", "cluster_prob_idx", ",", "None", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "l_idx", ":", "r_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "if", "(", "hasattr", "(", "self", ",", "'keep_order'", ")", "and", "self", ".", "keep_order", ")", "or", "keep_order", ":", "\n", "                        ", "out", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "-", "logprob_i", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", "offset", ":", "offset", "+", "logprob_i", ".", "size", "(", "0", ")", "]", ".", "copy_", "(", "-", "logprob_i", ")", "\n", "", "offset", "+=", "logprob_i", ".", "size", "(", "0", ")", "\n", "\n", "", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob": [[198, 258], ["modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "hidden.new_empty", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "len", "weights.append", "biases.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "log_prob", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "r\"\"\" Computes log probabilities for all :math:`n\\_classes`\n        From: https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/adaptive.py\n        Args:\n            hidden (Tensor): a minibatch of examples\n        Returns:\n            log-probabilities of for each class :math:`c`\n            in range :math:`0 <= c <= n\\_classes`, where :math:`n\\_classes` is a\n            parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.\n        Shape:\n            - Input: :math:`(N, in\\_features)`\n            - Output: :math:`(N, n\\_classes)`\n        \"\"\"", "\n", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "return", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "\n", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "start_idx", ",", "stop_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "\n", "logprob_i", "=", "head_logprob", "[", ":", ",", "-", "i", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "start_idx", ",", "stop_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.LogUniformSampler.__init__": [[261, 279], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double().log1p_", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "range_max", ",", "n_sample", ")", ":", "\n", "        ", "\"\"\"\n        Reference : https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/ops/candidate_sampling_ops.py\n            `P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)`\n\n        expected count can be approximated by 1 - (1 - p)^n\n        and we use a numerically stable version -expm1(num_tries * log1p(-p))\n\n        Our implementation fixes num_tries at 2 * n_sample, and the actual #samples will vary from run to run\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "range_max", "=", "range_max", "\n", "log_indices", "=", "torch", ".", "arange", "(", "1.", ",", "range_max", "+", "2.", ",", "1.", ")", ".", "log_", "(", ")", "\n", "self", ".", "dist", "=", "(", "log_indices", "[", "1", ":", "]", "-", "log_indices", "[", ":", "-", "1", "]", ")", "/", "log_indices", "[", "-", "1", "]", "\n", "\n", "self", ".", "log_q", "=", "(", "-", "(", "-", "self", ".", "dist", ".", "double", "(", ")", ".", "log1p_", "(", ")", "*", "2", "*", "n_sample", ")", ".", "expm1_", "(", ")", ")", ".", "log_", "(", ")", ".", "float", "(", ")", "\n", "\n", "", "self", ".", "n_sample", "=", "n_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.LogUniformSampler.sample": [[280, 300], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "neg_samples.to.to.to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n            labels: [b1, b2]\n        Return\n            true_log_probs: [b1, b2]\n            samp_log_probs: [n_sample]\n            neg_samples: [n_sample]\n        \"\"\"", "\n", "\n", "# neg_samples = torch.empty(0).long()", "\n", "n_sample", "=", "self", ".", "n_sample", "\n", "n_tries", "=", "2", "*", "n_sample", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "neg_samples", "=", "torch", ".", "multinomial", "(", "self", ".", "dist", ",", "n_tries", ",", "replacement", "=", "True", ")", ".", "unique", "(", ")", "\n", "device", "=", "labels", ".", "device", "\n", "neg_samples", "=", "neg_samples", ".", "to", "(", "device", ")", "\n", "true_log_probs", "=", "self", ".", "log_q", "[", "labels", "]", ".", "to", "(", "device", ")", "\n", "samp_log_probs", "=", "self", ".", "log_q", "[", "neg_samples", "]", ".", "to", "(", "device", ")", "\n", "return", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.sample_logits": [[301, 333], ["sampler.sample", "neg_samples.size", "torch.cat", "torch.cat", "torch.cat", "embedding", "all_w[].view", "all_w[].view", "all_b[].view", "sample_logits.masked_fill_", "torch.cat", "torch.cat", "torch.cat", "labels.size", "labels.size", "labels.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.LogUniformSampler.sample"], ["", "", "", "def", "sample_logits", "(", "embedding", ",", "bias", ",", "labels", ",", "inputs", ",", "sampler", ")", ":", "\n", "    ", "\"\"\"\n        embedding: an nn.Embedding layer\n        bias: [n_vocab]\n        labels: [b1, b2]\n        inputs: [b1, b2, n_emb]\n        sampler: you may use a LogUniformSampler\n    Return\n        logits: [b1, b2, 1 + n_sample]\n    \"\"\"", "\n", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "=", "sampler", ".", "sample", "(", "labels", ")", "\n", "n_sample", "=", "neg_samples", ".", "size", "(", "0", ")", "\n", "b1", ",", "b2", "=", "labels", ".", "size", "(", "0", ")", ",", "labels", ".", "size", "(", "1", ")", "\n", "all_ids", "=", "torch", ".", "cat", "(", "[", "labels", ".", "view", "(", "-", "1", ")", ",", "neg_samples", "]", ")", "\n", "all_w", "=", "embedding", "(", "all_ids", ")", "\n", "true_w", "=", "all_w", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ",", "-", "1", ")", "\n", "sample_w", "=", "all_w", "[", "-", "n_sample", ":", "]", ".", "view", "(", "n_sample", ",", "-", "1", ")", "\n", "\n", "all_b", "=", "bias", "[", "all_ids", "]", "\n", "true_b", "=", "all_b", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ")", "\n", "sample_b", "=", "all_b", "[", "-", "n_sample", ":", "]", "\n", "\n", "hit", "=", "(", "labels", "[", ":", ",", ":", ",", "None", "]", "==", "neg_samples", ")", ".", "detach", "(", ")", "\n", "\n", "true_logits", "=", "torch", ".", "einsum", "(", "'ijk,ijk->ij'", ",", "\n", "[", "true_w", ",", "inputs", "]", ")", "+", "true_b", "-", "true_log_probs", "\n", "sample_logits", "=", "torch", ".", "einsum", "(", "'lk,ijk->ijl'", ",", "\n", "[", "sample_w", ",", "inputs", "]", ")", "+", "sample_b", "-", "samp_log_probs", "\n", "sample_logits", ".", "masked_fill_", "(", "hit", ",", "-", "1e30", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "true_logits", "[", ":", ",", ":", ",", "None", "]", ",", "sample_logits", "]", ",", "-", "1", ")", "\n", "\n", "return", "logits", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.is_torch_available": [[75, 77], ["None"], "function", ["None"], ["def", "is_torch_available", "(", ")", ":", "\n", "    ", "return", "_torch_available", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.is_tf_available": [[78, 80], ["None"], "function", ["None"], ["", "def", "is_tf_available", "(", ")", ":", "\n", "    ", "return", "_tf_available", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.url_to_filename": [[105, 127], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "url.endswith", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) ands '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "if", "url", ".", "endswith", "(", "'.h5'", ")", ":", "\n", "        ", "filename", "+=", "'.h5'", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.filename_to_url": [[129, 153], ["os.path.join", "isinstance", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path": [[155, 186], ["urlparse", "isinstance", "str", "isinstance", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ",", "force_download", "=", "False", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    Args:\n        cache_dir: specify a cache directory to save the file to (overwrite the default cache dir).\n        force_download: if True, re-dowload the file even if it's already cached in the cache dir.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "force_download", ",", "proxies", "=", "proxies", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.split_s3_path": [[188, 199], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.s3_request": [[201, 218], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.s3_etag": [[220, 227], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object", "botocore.config.Config"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.s3_get": [[229, 235], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "botocore.config.Config", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.http_get": [[237, 247], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["None"], ["", "def", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ",", "proxies", "=", "proxies", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.get_from_cache": [[249, 325], ["url.startswith", "file_utils.url_to_filename", "os.path.join", "isinstance", "str", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "response.headers.get.decode", "fnmatch.filter", "list", "isinstance", "requests.head", "os.path.exists", "os.listdir", "filter", "os.path.join", "os.path.exists", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "requests.head.headers.get", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dumps", "meta_file.write", "isinstance", "unicode", "s.endswith"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.url_to_filename", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.s3_etag", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.s3_get", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ",", "force_download", "=", "False", ",", "proxies", "=", "None", ",", "etag_timeout", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "not", "isinstance", "(", "cache_dir", ",", "str", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ",", "proxies", "=", "proxies", ",", "timeout", "=", "etag_timeout", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "(", "EnvironmentError", ",", "requests", ".", "exceptions", ".", "Timeout", ")", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "etag", "is", "not", "None", ":", "\n", "        ", "etag", "=", "etag", ".", "decode", "(", "'utf-8'", ")", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "'.*'", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "'.json'", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "or", "force_download", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache or force_download set to True, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ")", "as", "meta_file", ":", "\n", "                ", "output_string", "=", "json", ".", "dumps", "(", "meta", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "output_string", ",", "str", ")", ":", "\n", "                    ", "output_string", "=", "unicode", "(", "output_string", ",", "'utf-8'", ")", "# The beauty of python 2", "\n", "", "meta_file", ".", "write", "(", "output_string", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_transfo_xl_original_tf_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch": [[48, 91], ["print", "torch.save", "corpus_dict_no_vocab.pop", "print", "torch.save", "os.path.abspath", "os.path.abspath", "print", "print", "transformers.TransfoXLLMHeadModel", "transformers.load_tf_weights_in_transfo_xl", "os.path.join", "os.path.join", "print", "torch.save", "print", "io.open", "pickle.load", "transformers.TransfoXLConfig", "transformers.TransfoXLConfig.from_json_file", "transformers.load_tf_weights_in_transfo_xl.state_dict", "io.open", "f.write", "str", "os.path.abspath", "os.path.abspath", "TransfoXLConfig.from_json_file.to_json_string"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["def", "convert_transfo_xl_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "\n", "transfo_xl_config_file", ",", "\n", "pytorch_dump_folder_path", ",", "\n", "transfo_xl_dataset_file", ")", ":", "\n", "    ", "if", "transfo_xl_dataset_file", ":", "\n", "# Convert a pre-processed corpus (see original TensorFlow repo)", "\n", "        ", "with", "open", "(", "transfo_xl_dataset_file", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ",", "encoding", "=", "\"latin1\"", ")", "\n", "# Save vocabulary and dataset cache as Dictionaries (should be better than pickles for the long-term)", "\n", "", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "VOCAB_FILES_NAMES", "[", "'pretrained_vocab_file'", "]", "\n", "print", "(", "\"Save vocabulary to {}\"", ".", "format", "(", "pytorch_vocab_dump_path", ")", ")", "\n", "corpus_vocab_dict", "=", "corpus", ".", "vocab", ".", "__dict__", "\n", "torch", ".", "save", "(", "corpus_vocab_dict", ",", "pytorch_vocab_dump_path", ")", "\n", "\n", "corpus_dict_no_vocab", "=", "corpus", ".", "__dict__", "\n", "corpus_dict_no_vocab", ".", "pop", "(", "'vocab'", ",", "None", ")", "\n", "pytorch_dataset_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CORPUS_NAME", "\n", "print", "(", "\"Save dataset to {}\"", ".", "format", "(", "pytorch_dataset_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "corpus_dict_no_vocab", ",", "pytorch_dataset_dump_path", ")", "\n", "\n", "", "if", "tf_checkpoint_path", ":", "\n", "# Convert a pre-trained TensorFlow model", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "abspath", "(", "transfo_xl_config_file", ")", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "\n", "print", "(", "\"Converting Transformer XL checkpoint from {} with config at {}\"", ".", "format", "(", "tf_path", ",", "config_path", ")", ")", "\n", "# Initialise PyTorch model", "\n", "if", "transfo_xl_config_file", "==", "\"\"", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", ")", "\n", "", "else", ":", "\n", "            ", "config", "=", "TransfoXLConfig", ".", "from_json_file", "(", "transfo_xl_config_file", ")", "\n", "", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "TransfoXLLMHeadModel", "(", "config", ")", "\n", "\n", "model", "=", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModel.__init__": [[62, 64], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoModel is designed to be instantiated \"", "\n", "\"using the `AutoModel.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModel.from_pretrained": [[66, 160], ["ValueError", "modeling_distilbert.DistilBertModel.from_pretrained", "modeling_roberta.RobertaModel.from_pretrained", "modeling_bert.BertModel.from_pretrained", "modeling_openai.OpenAIGPTModel.from_pretrained", "modeling_gpt2.GPT2Model.from_pretrained", "modeling_transfo_xl.TransfoXLModel.from_pretrained", "modeling_xlnet.XLNetModel.from_pretrained", "modeling_xlm.XLMModel.from_pretrained", "modeling_ctrl.CTRLModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a pre-trained model configuration.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertModel (DistilBERT model)\n            - contains `roberta`: RobertaModel (RoBERTa model)\n            - contains `bert`: BertModel (Bert model)\n            - contains `openai-gpt`: OpenAIGPTModel (OpenAI GPT model)\n            - contains `gpt2`: GPT2Model (OpenAI GPT-2 model)\n            - contains `ctrl`: CTRLModel (Salesforce CTRL  model)\n            - contains `transfo-xl`: TransfoXLModel (Transformer-XL model)\n            - contains `xlnet`: XLNetModel (XLNet model)\n            - contains `xlm`: XLMModel (XLM model)\n\n            The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n            To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModel.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModel.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Model", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'ctrl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta, 'ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModelWithLMHead.__init__": [[186, 188], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `AutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModelWithLMHead.from_pretrained": [[190, 286], ["ValueError", "modeling_distilbert.DistilBertForMaskedLM.from_pretrained", "modeling_roberta.RobertaForMaskedLM.from_pretrained", "modeling_bert.BertForMaskedLM.from_pretrained", "modeling_openai.OpenAIGPTLMHeadModel.from_pretrained", "modeling_gpt2.GPT2LMHeadModel.from_pretrained", "modeling_transfo_xl.TransfoXLLMHeadModel.from_pretrained", "modeling_xlnet.XLNetLMHeadModel.from_pretrained", "modeling_xlm.XLMWithLMHeadModel.from_pretrained", "modeling_ctrl.CTRLLMHeadModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the language modeling model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertForMaskedLM (DistilBERT model)\n            - contains `roberta`: RobertaForMaskedLM (RoBERTa model)\n            - contains `bert`: BertForMaskedLM (Bert model)\n            - contains `openai-gpt`: OpenAIGPTLMHeadModel (OpenAI GPT model)\n            - contains `gpt2`: GPT2LMHeadModel (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLLMHeadModel (Transformer-XL model)\n            - contains `xlnet`: XLNetLMHeadModel (XLNet model)\n            - contains `xlm`: XLMWithLMHeadModel (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModelWithLMHead.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModelWithLMHead.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModelWithLMHead.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModelWithLMHead.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2LMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMWithLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'ctrl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta','ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModelForSequenceClassification.__init__": [[308, 310], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `AutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModelForSequenceClassification.from_pretrained": [[312, 397], ["ValueError", "modeling_distilbert.DistilBertForSequenceClassification.from_pretrained", "modeling_roberta.RobertaForSequenceClassification.from_pretrained", "modeling_bert.BertForSequenceClassification.from_pretrained", "modeling_xlnet.XLNetForSequenceClassification.from_pretrained", "modeling_xlm.XLMForSequenceClassification.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the sequence classification model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertForSequenceClassification (DistilBERT model)\n            - contains `roberta`: RobertaForSequenceClassification (RoBERTa model)\n            - contains `bert`: BertForSequenceClassification (Bert model)\n            - contains `xlnet`: XLNetForSequenceClassification (XLNet model)\n            - contains `xlm`: XLMForSequenceClassification (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModelForSequenceClassification.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModelForSequenceClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'xlm', 'roberta'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModelForQuestionAnswering.__init__": [[418, 420], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `AutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_auto.AutoModelForQuestionAnswering.from_pretrained": [[422, 504], ["ValueError", "modeling_distilbert.DistilBertForQuestionAnswering.from_pretrained", "modeling_bert.BertForQuestionAnswering.from_pretrained", "modeling_xlnet.XLNetForQuestionAnswering.from_pretrained", "modeling_xlm.XLMForQuestionAnswering.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the question answering model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertForQuestionAnswering (DistilBERT model)\n            - contains `bert`: BertForQuestionAnswering (Bert model)\n            - contains `xlnet`: XLNetForQuestionAnswering (XLNet model)\n            - contains `xlm`: XLMForQuestionAnswering (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModelForQuestionAnswering.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModelForQuestionAnswering.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModelForQuestionAnswering.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModelForQuestionAnswering.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'xlm'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_gpt2_original_tf_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch": [[33, 52], ["transformers.GPT2Model", "transformers.load_tf_weights_in_gpt2", "print", "torch.save", "print", "transformers.GPT2Config", "transformers.GPT2Config.from_json_file", "transformers.GPT2Model.state_dict", "io.open", "f.write", "GPT2Config.from_json_file.to_json_string"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_gpt2.load_tf_weights_in_gpt2", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["def", "convert_gpt2_checkpoint_to_pytorch", "(", "gpt2_checkpoint_path", ",", "gpt2_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "gpt2_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "GPT2Config", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "GPT2Config", ".", "from_json_file", "(", "gpt2_config_file", ")", "\n", "", "model", "=", "GPT2Model", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaEmbeddings.__init__": [[44, 50], ["modeling_bert.BertEmbeddings.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "self", ".", "padding_idx", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ",", "\n", "padding_idx", "=", "self", ".", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaEmbeddings.forward": [[51, 61], ["input_ids.size", "super().forward", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "if", "position_ids", "is", "None", ":", "\n", "# Position numbers begin at padding_idx+1. Padding symbols are ignored.", "\n", "# cf. fairseq's `utils.make_positions`", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "self", ".", "padding_idx", "+", "1", ",", "seq_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "", "return", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaModel.__init__": [[166, 171], ["modeling_bert.BertModel.__init__", "modeling_roberta.RobertaEmbeddings", "modeling_roberta.RobertaModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "RobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaModel.forward": [[172, 183], ["super().forward", "input_ids[].sum().item", "logger.warning", "input_ids[].sum"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "[", ":", ",", "0", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "!=", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"A sequence with no special tokens has been passed to the RoBERTa model. \"", "\n", "\"This model requires special tokens in order to work. \"", "\n", "\"Please specify add_special_tokens=True in your tokenize.encode()\"", "\n", "\"or tokenizer.convert_tokens_to_ids().\"", ")", "\n", "", "return", "super", "(", "RobertaModel", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForMaskedLM.__init__": [[221, 229], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForMaskedLM.init_weights", "modeling_roberta.RobertaForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForMaskedLM.tie_weights": [[230, 235], ["modeling_roberta.RobertaForMaskedLM._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ".", "decoder", ",", "self", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForMaskedLM.forward": [[236, 254], ["modeling_roberta.RobertaForMaskedLM.roberta", "modeling_roberta.RobertaForMaskedLM.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaLMHead.__init__": [[259, 266], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "modeling_bert.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaLMHead.forward": [[267, 276], ["modeling_roberta.RobertaLMHead.dense", "modeling_bert.gelu", "modeling_roberta.RobertaLMHead.layer_norm", "modeling_roberta.RobertaLMHead.decoder"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.gelu"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "gelu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForSequenceClassification.__init__": [[316, 322], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForSequenceClassification.forward": [[323, 345], ["modeling_roberta.RobertaForSequenceClassification.roberta", "modeling_roberta.RobertaForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForMultipleChoice.__init__": [[420, 428], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForMultipleChoice.forward": [[429, 453], ["input_ids.view", "modeling_roberta.RobertaForMultipleChoice.roberta", "modeling_roberta.RobertaForMultipleChoice.dropout", "modeling_roberta.RobertaForMultipleChoice.classifier", "modeling_roberta.RobertaForMultipleChoice.view", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "position_ids.size", "token_type_ids.size", "attention_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "outputs", "=", "self", ".", "roberta", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForTokenClassification.__init__": [[491, 500], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaForTokenClassification.forward": [[501, 529], ["modeling_roberta.RobertaForTokenClassification.roberta", "modeling_roberta.RobertaForTokenClassification.dropout", "modeling_roberta.RobertaForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaClassificationHead.__init__": [[534, 539], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_roberta.RobertaClassificationHead.forward": [[540, 548], ["modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_ctrl.CTRLConfig.__init__": [[53, 126], ["configuration_utils.PretrainedConfig.__init__", "isinstance", "isinstance", "json.loads.items", "isinstance", "io.open", "json.loads", "isinstance", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "246534", ",", "\n", "n_positions", "=", "256", ",", "\n", "n_ctx", "=", "256", ",", "\n", "n_embd", "=", "1280", ",", "\n", "dff", "=", "8192", ",", "\n", "n_layer", "=", "48", ",", "\n", "n_head", "=", "16", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-6", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "\n", "num_labels", "=", "1", ",", "\n", "summary_type", "=", "'cls_index'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs CTRLConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `CTRLModel` or a configuration json file.\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            dff: Size of the inner dimension of the FFN.\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            resid_pdrop: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attn_pdrop: The dropout ratio for the attention\n                probabilities.\n            embd_pdrop: The dropout ratio for the embeddings.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "super", "(", "CTRLConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", "else", "-", "1", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "dff", "=", "dff", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "not", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_ctrl.CTRLConfig.max_position_embeddings": [[129, 132], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_ctrl.CTRLConfig.hidden_size": [[133, 136], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_ctrl.CTRLConfig.num_attention_heads": [[137, 140], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_ctrl.CTRLConfig.num_hidden_layers": [[141, 144], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.bos_token": [[135, 138], ["None"], "methods", ["None"], ["", "@", "bos_token", ".", "setter", "\n", "def", "bos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.eos_token": [[139, 142], ["None"], "methods", ["None"], ["", "@", "eos_token", ".", "setter", "\n", "def", "eos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_eos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.unk_token": [[143, 146], ["None"], "methods", ["None"], ["", "@", "unk_token", ".", "setter", "\n", "def", "unk_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_unk_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.sep_token": [[147, 150], ["None"], "methods", ["None"], ["", "@", "sep_token", ".", "setter", "\n", "def", "sep_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_sep_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.pad_token": [[151, 154], ["None"], "methods", ["None"], ["", "@", "pad_token", ".", "setter", "\n", "def", "pad_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_pad_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.cls_token": [[155, 158], ["None"], "methods", ["None"], ["", "@", "cls_token", ".", "setter", "\n", "def", "cls_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_cls_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.mask_token": [[159, 162], ["None"], "methods", ["None"], ["", "@", "mask_token", ".", "setter", "\n", "def", "mask_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_mask_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.additional_special_tokens": [[163, 166], ["None"], "methods", ["None"], ["", "@", "additional_special_tokens", ".", "setter", "\n", "def", "additional_special_tokens", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_additional_special_tokens", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.bos_token_id": [[167, 171], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "bos_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the beginning of sentence token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "bos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.eos_token_id": [[172, 176], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "eos_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the end of sentence token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "eos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.unk_token_id": [[177, 181], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "unk_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the unknown token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.sep_token_id": [[182, 186], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "sep_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the separation token in the vocabulary. E.g. separate context and query in an input sequence. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "sep_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.pad_token_id": [[187, 191], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "pad_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the padding token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "pad_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.cls_token_id": [[192, 196], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "cls_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the classification token in the vocabulary. E.g. to extract a summary of an input sequence leveraging self-attention along the full depth of the model. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "cls_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.mask_token_id": [[197, 201], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "mask_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the mask token in the vocabulary. E.g. when training a model with masked-language modeling. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "mask_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.additional_special_tokens_ids": [[202, 206], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "additional_special_tokens_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\" Ids of all the additional special tokens in the vocabulary (list of integers). Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "additional_special_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.__init__": [[207, 234], ["kwargs.items", "int", "setattr", "isinstance", "all", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "max_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "None", "\n", "self", ".", "_eos_token", "=", "None", "\n", "self", ".", "_unk_token", "=", "None", "\n", "self", ".", "_sep_token", "=", "None", "\n", "self", ".", "_pad_token", "=", "None", "\n", "self", ".", "_cls_token", "=", "None", "\n", "self", ".", "_mask_token", "=", "None", "\n", "self", ".", "_additional_special_tokens", "=", "[", "]", "\n", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "\n", "# Added tokens", "\n", "self", ".", "added_tokens_encoder", "=", "{", "}", "\n", "self", ".", "added_tokens_decoder", "=", "{", "}", "\n", "\n", "# inputs and kwargs for saving and re-loading (see ``from_pretrained`` and ``save_pretrained``)", "\n", "self", ".", "init_inputs", "=", "(", ")", "\n", "self", ".", "init_kwargs", "=", "{", "}", "\n", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "                ", "if", "key", "==", "'additional_special_tokens'", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "isinstance", "(", "t", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "t", ",", "unicode", ")", ")", "for", "t", "in", "value", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "value", ",", "unicode", ")", ")", "\n", "", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.from_pretrained": [[236, 283], ["cls._from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._from_pretrained"], ["", "", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"\n        Instantiate a :class:`~transformers.PreTrainedTokenizer` (or a derived class) from a predefined tokenizer.\n\n        Args:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a predefined tokenizer to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing vocabulary files required by the tokenizer, for instance saved using the :func:`~transformers.PreTrainedTokenizer.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - (not applicable to all derived classes) a path or url to a single saved vocabulary file if and only if the tokenizer only requires a single vocabulary file (e.g. Bert, XLNet), e.g.: ``./my_model_directory/vocab.txt``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded predefined tokenizer vocabulary files should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the vocabulary files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            inputs: (`optional`) positional arguments: will be passed to the Tokenizer ``__init__`` method.\n\n            kwargs: (`optional`) keyword arguments: will be passed to the Tokenizer ``__init__`` method. Can be used to set special tokens like ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``, ``additional_special_tokens``. See parameters in the doc string of :class:`~transformers.PreTrainedTokenizer` for details.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PreTrainedTokenizer` so let's show our examples on a derived class: BertTokenizer\n\n            # Download vocabulary from S3 and cache.\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n            # If vocabulary files are in a directory (e.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`)\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/')\n\n            # If the tokenizer uses a single vocabulary file, you can point directly to this file\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/my_vocab.txt')\n\n            # You can link tokens to special vocabulary when instantiating\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', unk_token='<unk>')\n            # You should be sure '<unk>' is in the vocabulary when doing that.\n            # Otherwise use tokenizer.add_special_tokens({'unk_token': '<unk>'}) instead)\n            assert tokenizer.unk_token == '<unk>'\n\n        \"\"\"", "\n", "return", "cls", ".", "_from_pretrained", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._from_pretrained": [[285, 425], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "list", "vocab_files.items", "resolved_vocab_files.pop", "json.load.update", "resolved_vocab_files.pop", "resolved_vocab_files.pop", "resolved_vocab_files.items", "cls", "cls.max_model_input_sizes.keys", "cls.pretrained_vocab_files_map.items", "logger.info", "cls.vocab_files_names.items", "additional_files_names.items", "all", "vocab_files.items", "json.load", "json.load.pop", "json.load", "json.load.items", "json.load", "cls.added_tokens_encoder.update", "cls.added_tokens_decoder.update", "os.path.isdir", "os.path.exists", "os.path.dirname", "os.path.join", "EnvironmentError", "EnvironmentError", "logger.info", "logger.info", "io.open", "isinstance", "min", "io.open", "io.open", "os.path.join", "os.path.exists", "logger.info", "os.path.isdir", "os.path.exists", "logger.info", "file_utils.cached_path", "json.load.get", "json.load.items", "vocab_files.values", "list", "list", "int", "cls.vocab_files_names.values", "cls.vocab_files_names.values"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "_from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "init_inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "\n", "s3_models", "=", "list", "(", "cls", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "vocab_files", "=", "{", "}", "\n", "init_configuration", "=", "{", "}", "\n", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "# Get the vocabulary from AWS S3 bucket", "\n", "            ", "for", "file_id", ",", "map_list", "in", "cls", ".", "pretrained_vocab_files_map", ".", "items", "(", ")", ":", "\n", "                ", "vocab_files", "[", "file_id", "]", "=", "map_list", "[", "pretrained_model_name_or_path", "]", "\n", "", "if", "cls", ".", "pretrained_init_configuration", "and", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_init_configuration", ":", "\n", "                ", "init_configuration", "=", "cls", ".", "pretrained_init_configuration", "[", "pretrained_model_name_or_path", "]", "\n", "", "", "else", ":", "\n", "# Get the vocabulary from local files", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Model name '{}' not found in model shortcut name list ({}). \"", "\n", "\"Assuming '{}' is a path or url to a directory containing tokenizer files.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ")", ")", "\n", "\n", "# Look for the tokenizer main vocabulary files", "\n", "for", "file_id", ",", "file_name", "in", "cls", ".", "vocab_files_names", ".", "items", "(", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "# If a directory is provided we look for the standard filenames", "\n", "                    ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "file_name", ")", "\n", "", "else", ":", "\n", "# If a path to a file is provided we use it (will only work for non-BPE tokenizer using a single vocabulary file)", "\n", "                    ", "full_file_name", "=", "pretrained_model_name_or_path", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "# Look for the additional tokens files", "\n", "", "additional_files_names", "=", "{", "'added_tokens_file'", ":", "ADDED_TOKENS_FILE", ",", "\n", "'special_tokens_map_file'", ":", "SPECIAL_TOKENS_MAP_FILE", ",", "\n", "'tokenizer_config_file'", ":", "TOKENIZER_CONFIG_FILE", ",", "\n", "}", "\n", "\n", "# If a path to a file was provided, get the parent directory", "\n", "saved_directory", "=", "pretrained_model_name_or_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "saved_directory", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "saved_directory", ")", ":", "\n", "                ", "saved_directory", "=", "os", ".", "path", ".", "dirname", "(", "saved_directory", ")", "\n", "\n", "", "for", "file_id", ",", "file_name", "in", "additional_files_names", ".", "items", "(", ")", ":", "\n", "                ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "saved_directory", ",", "file_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "", "if", "all", "(", "full_file_name", "is", "None", "for", "full_file_name", "in", "vocab_files", ".", "values", "(", ")", ")", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\n", "\"Model name '{}' was not found in tokenizers model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to a directory containing vocabulary files \"", "\n", "\"named {} but couldn't find such vocabulary files at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "list", "(", "cls", ".", "vocab_files_names", ".", "values", "(", ")", ")", ")", ")", "\n", "\n", "# Get files from url, cache, or disk depending on the case", "\n", "", "", "try", ":", "\n", "            ", "resolved_vocab_files", "=", "{", "}", "\n", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "                ", "if", "file_path", "is", "None", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "None", "\n", "", "else", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "cached_path", "(", "file_path", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "force_download", ",", "proxies", "=", "proxies", ")", "\n", "", "", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "                ", "msg", "=", "\"Couldn't reach server at '{}' to download vocabulary files.\"", "\n", "", "else", ":", "\n", "                ", "msg", "=", "\"Model name '{}' was not found in tokenizers model name list ({}). \"", "\"We assumed '{}' was a path or url to a directory containing vocabulary files \"", "\"named {}, but couldn't find such vocabulary files at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "list", "(", "cls", ".", "vocab_files_names", ".", "values", "(", ")", ")", ")", "\n", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "file_path", "==", "resolved_vocab_files", "[", "file_id", "]", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {} from cache at {}\"", ".", "format", "(", "\n", "file_path", ",", "resolved_vocab_files", "[", "file_id", "]", ")", ")", "\n", "\n", "# Prepare tokenizer initialization kwargs", "\n", "# Did we saved some inputs and kwargs to reload ?", "\n", "", "", "tokenizer_config_file", "=", "resolved_vocab_files", ".", "pop", "(", "'tokenizer_config_file'", ",", "None", ")", "\n", "if", "tokenizer_config_file", "is", "not", "None", ":", "\n", "            ", "init_kwargs", "=", "json", ".", "load", "(", "open", "(", "tokenizer_config_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "saved_init_inputs", "=", "init_kwargs", ".", "pop", "(", "'init_inputs'", ",", "(", ")", ")", "\n", "if", "not", "init_inputs", ":", "\n", "                ", "init_inputs", "=", "saved_init_inputs", "\n", "", "", "else", ":", "\n", "            ", "init_kwargs", "=", "init_configuration", "\n", "\n", "# Update with newly provided kwargs", "\n", "", "init_kwargs", ".", "update", "(", "kwargs", ")", "\n", "\n", "# Set max length if needed", "\n", "if", "pretrained_model_name_or_path", "in", "cls", ".", "max_model_input_sizes", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer", "\n", "# wont index sequences longer than the number of positional embeddings", "\n", "            ", "max_len", "=", "cls", ".", "max_model_input_sizes", "[", "pretrained_model_name_or_path", "]", "\n", "if", "max_len", "is", "not", "None", "and", "isinstance", "(", "max_len", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "init_kwargs", "[", "'max_len'", "]", "=", "min", "(", "init_kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "\n", "# Merge resolved_vocab_files arguments in init_kwargs.", "\n", "", "", "added_tokens_file", "=", "resolved_vocab_files", ".", "pop", "(", "'added_tokens_file'", ",", "None", ")", "\n", "special_tokens_map_file", "=", "resolved_vocab_files", ".", "pop", "(", "'special_tokens_map_file'", ",", "None", ")", "\n", "for", "args_name", ",", "file_path", "in", "resolved_vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "args_name", "not", "in", "init_kwargs", ":", "\n", "                ", "init_kwargs", "[", "args_name", "]", "=", "file_path", "\n", "", "", "if", "special_tokens_map_file", "is", "not", "None", ":", "\n", "            ", "special_tokens_map", "=", "json", ".", "load", "(", "open", "(", "special_tokens_map_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "for", "key", ",", "value", "in", "special_tokens_map", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "init_kwargs", ":", "\n", "                    ", "init_kwargs", "[", "key", "]", "=", "value", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "", "", "tokenizer", "=", "cls", "(", "*", "init_inputs", ",", "**", "init_kwargs", ")", "\n", "\n", "# Save inputs and kwargs for saving and re-loading with ``save_pretrained``", "\n", "tokenizer", ".", "init_inputs", "=", "init_inputs", "\n", "tokenizer", ".", "init_kwargs", "=", "init_kwargs", "\n", "\n", "# Add supplementary tokens.", "\n", "if", "added_tokens_file", "is", "not", "None", ":", "\n", "            ", "added_tok_encoder", "=", "json", ".", "load", "(", "open", "(", "added_tokens_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "tokenizer", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "tokenizer", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.save_pretrained": [[427, 467], ["os.path.join", "os.path.join", "os.path.join", "copy.deepcopy", "copy.deepcopy", "tokenization_utils.PreTrainedTokenizer.vocab_files_names.keys", "tokenization_utils.PreTrainedTokenizer.save_vocabulary", "os.path.isdir", "logger.error", "copy.deepcopy.pop", "io.open", "f.write", "io.open", "f.write", "io.open", "f.write", "json.dumps", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.save_vocabulary"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary files together with:\n                - added tokens,\n                - special-tokens-to-class-attributes-mapping,\n                - tokenizer instantiation positional and keywords inputs (e.g. do_lower_case for Bert).\n\n            This won't save modifications other than (added tokens and special token mapping) you may have\n            applied to the tokenizer after the instantiation (e.g. modifying tokenizer.do_lower_case after creation).\n\n            This method make sure the full tokenizer can then be re-loaded using the :func:`~transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Saving directory ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "\n", "", "special_tokens_map_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "SPECIAL_TOKENS_MAP_FILE", ")", "\n", "added_tokens_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "ADDED_TOKENS_FILE", ")", "\n", "tokenizer_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "TOKENIZER_CONFIG_FILE", ")", "\n", "\n", "tokenizer_config", "=", "copy", ".", "deepcopy", "(", "self", ".", "init_kwargs", ")", "\n", "tokenizer_config", "[", "'init_inputs'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "init_inputs", ")", "\n", "for", "file_id", "in", "self", ".", "vocab_files_names", ".", "keys", "(", ")", ":", "\n", "            ", "tokenizer_config", ".", "pop", "(", "file_id", ",", "None", ")", "\n", "\n", "", "with", "open", "(", "tokenizer_config_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "tokenizer_config", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "with", "open", "(", "special_tokens_map_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "special_tokens_map", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "with", "open", "(", "added_tokens_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "if", "self", ".", "added_tokens_encoder", ":", "\n", "                ", "out_str", "=", "json", ".", "dumps", "(", "self", ".", "added_tokens_encoder", ",", "ensure_ascii", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "out_str", "=", "u\"{}\"", "\n", "", "f", ".", "write", "(", "out_str", ")", "\n", "\n", "", "vocab_files", "=", "self", ".", "save_vocabulary", "(", "save_directory", ")", "\n", "\n", "return", "vocab_files", "+", "(", "special_tokens_map_file", ",", "added_tokens_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.save_vocabulary": [[469, 476], ["None"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary to a directory. This method does *NOT* save added tokens\n            and special token mappings.\n\n            Please use :func:`~transformers.PreTrainedTokenizer.save_pretrained` `()` to save the full Tokenizer state if you want to reload it using the :func:`~transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.vocab_size": [[478, 481], ["None"], "methods", ["None"], ["", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the base vocabulary (without the added tokens) \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.__len__": [[483, 486], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the full vocabulary with the added tokens \"\"\"", "\n", "return", "self", ".", "vocab_size", "+", "len", "(", "self", ".", "added_tokens_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens": [[488, 527], ["dict", "tokenization_utils.PreTrainedTokenizer.added_tokens_encoder.update", "tokenization_utils.PreTrainedTokenizer.added_tokens_decoder.update", "len", "isinstance", "to_add_tokens.append", "logger.info", "dict.items", "isinstance", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "add_tokens", "(", "self", ",", "new_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Add a list of new tokens to the tokenizer class. If the new tokens are not in the\n        vocabulary, they are added to it with indices starting from length of the current vocabulary.\n\n        Args:\n            new_tokens: list of string. Each string is a token to add. Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n\n        Returns:\n            Number of tokens added to the vocabulary.\n\n        Examples::\n\n            # Let's see how to increase the vocabulary of Bert model and tokenizer\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n            model = BertModel.from_pretrained('bert-base-uncased')\n\n            num_added_toks = tokenizer.add_tokens(['new_tok1', 'my_new-tok2'])\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n        \"\"\"", "\n", "if", "not", "new_tokens", ":", "\n", "            ", "return", "0", "\n", "\n", "", "to_add_tokens", "=", "[", "]", "\n", "for", "token", "in", "new_tokens", ":", "\n", "            ", "assert", "isinstance", "(", "token", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "token", ",", "unicode", ")", ")", "\n", "if", "token", "!=", "self", ".", "unk_token", "and", "self", ".", "convert_tokens_to_ids", "(", "token", ")", "==", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "unk_token", ")", "and", "token", "not", "in", "to_add_tokens", ":", "\n", "                ", "to_add_tokens", ".", "append", "(", "token", ")", "\n", "logger", ".", "info", "(", "\"Adding %s to the vocabulary\"", ",", "token", ")", "\n", "\n", "", "", "added_tok_encoder", "=", "dict", "(", "(", "tok", ",", "len", "(", "self", ")", "+", "i", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "to_add_tokens", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "self", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "return", "len", "(", "to_add_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.num_added_tokens": [[528, 546], ["len", "tokenization_utils.PreTrainedTokenizer.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens"], ["", "def", "num_added_tokens", "(", "self", ",", "pair", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns the number of added tokens when encoding a sequence with special tokens.\n\n        Note:\n            This encodes inputs and checks the number of added tokens, and is therefore not efficient. Do not put this\n            inside your training loop.\n\n        Args:\n            pair: Returns the number of added tokens in the case of a sequence pair if set to True, returns the\n                number of added tokens in the case of a single sequence if set to False.\n\n        Returns:\n            Number of tokens added to sequences\n        \"\"\"", "\n", "token_ids_0", "=", "[", "]", "\n", "token_ids_1", "=", "[", "]", "\n", "return", "len", "(", "self", ".", "build_inputs_with_special_tokens", "(", "token_ids_0", ",", "token_ids_1", "if", "pair", "else", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens": [[547, 600], ["special_tokens_dict.items", "logger.info", "setattr", "tokenization_utils.PreTrainedTokenizer.add_tokens", "tokenization_utils.PreTrainedTokenizer.add_tokens", "isinstance", "all", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens"], ["", "def", "add_special_tokens", "(", "self", ",", "special_tokens_dict", ")", ":", "\n", "        ", "\"\"\"\n        Add a dictionary of special tokens (eos, pad, cls...) to the encoder and link them\n        to class attributes. If special tokens are NOT in the vocabulary, they are added\n        to it (indexed starting from the last index of the current vocabulary).\n\n        Using `add_special_tokens` will ensure your special tokens can be used in several ways:\n\n        - special tokens are carefully handled by the tokenizer (they are never split)\n        - you can easily refer to special tokens using tokenizer class attributes like `tokenizer.cls_token`. This makes it easy to develop model-agnostic training and fine-tuning scripts.\n\n        When possible, special tokens are already registered for provided pretrained models (ex: BertTokenizer cls_token is already registered to be '[CLS]' and XLM's one is also registered to be '</s>')\n\n        Args:\n            special_tokens_dict: dict of string. Keys should be in the list of predefined special attributes:\n                [``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``,\n                ``additional_special_tokens``].\n\n                Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n\n        Returns:\n            Number of tokens added to the vocabulary.\n\n        Examples::\n\n            # Let's see how to add a new classification token to GPT-2\n            tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n            model = GPT2Model.from_pretrained('gpt2')\n\n            special_tokens_dict = {'cls_token': '<CLS>'}\n\n            num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n\n            assert tokenizer.cls_token == '<CLS>'\n        \"\"\"", "\n", "if", "not", "special_tokens_dict", ":", "\n", "            ", "return", "0", "\n", "\n", "", "added_tokens", "=", "0", "\n", "for", "key", ",", "value", "in", "special_tokens_dict", ".", "items", "(", ")", ":", "\n", "            ", "assert", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", "\n", "if", "key", "==", "'additional_special_tokens'", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "isinstance", "(", "t", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "t", ",", "unicode", ")", ")", "for", "t", "in", "value", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "value", ",", "unicode", ")", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "[", "value", "]", ")", "\n", "", "logger", ".", "info", "(", "\"Assigning %s to the %s key of the tokenizer\"", ",", "value", ",", "key", ")", "\n", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n", "", "return", "added_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize": [[601, 651], ["tokenization_utils.PreTrainedTokenizer.tokenize.split_on_tokens"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Take care of added tokens.\n        \"\"\"", "\n", "def", "split_on_token", "(", "tok", ",", "text", ")", ":", "\n", "            ", "result", "=", "[", "]", "\n", "split_text", "=", "text", ".", "split", "(", "tok", ")", "\n", "for", "i", ",", "sub_text", "in", "enumerate", "(", "split_text", ")", ":", "\n", "                ", "sub_text", "=", "sub_text", ".", "strip", "(", ")", "\n", "if", "i", "==", "0", "and", "not", "sub_text", ":", "\n", "                    ", "result", "+=", "[", "tok", "]", "\n", "", "elif", "i", "==", "len", "(", "split_text", ")", "-", "1", ":", "\n", "                    ", "if", "sub_text", ":", "\n", "                        ", "result", "+=", "[", "sub_text", "]", "\n", "", "else", ":", "\n", "                        ", "pass", "\n", "", "", "else", ":", "\n", "                    ", "if", "sub_text", ":", "\n", "                        ", "result", "+=", "[", "sub_text", "]", "\n", "", "result", "+=", "[", "tok", "]", "\n", "", "", "return", "result", "\n", "\n", "", "def", "split_on_tokens", "(", "tok_list", ",", "text", ")", ":", "\n", "            ", "if", "not", "text", ":", "\n", "                ", "return", "[", "]", "\n", "", "if", "not", "tok_list", ":", "\n", "                ", "return", "self", ".", "_tokenize", "(", "text", ",", "**", "kwargs", ")", "\n", "\n", "", "tokenized_text", "=", "[", "]", "\n", "text_list", "=", "[", "text", "]", "\n", "for", "tok", "in", "tok_list", ":", "\n", "                ", "tokenized_text", "=", "[", "]", "\n", "for", "sub_text", "in", "text_list", ":", "\n", "                    ", "if", "sub_text", "not", "in", "self", ".", "added_tokens_encoder", "and", "sub_text", "not", "in", "self", ".", "all_special_tokens", ":", "\n", "                        ", "tokenized_text", "+=", "split_on_token", "(", "tok", ",", "sub_text", ")", "\n", "", "else", ":", "\n", "                        ", "tokenized_text", "+=", "[", "sub_text", "]", "\n", "", "", "text_list", "=", "tokenized_text", "\n", "\n", "", "return", "sum", "(", "(", "self", ".", "_tokenize", "(", "token", ",", "**", "kwargs", ")", "if", "token", "not", "in", "self", ".", "added_tokens_encoder", "and", "token", "not", "in", "self", ".", "all_special_tokens", "else", "[", "token", "]", "for", "token", "in", "tokenized_text", ")", ",", "[", "]", ")", "\n", "\n", "", "added_tokens", "=", "list", "(", "self", ".", "added_tokens_encoder", ".", "keys", "(", ")", ")", "+", "self", ".", "all_special_tokens", "\n", "tokenized_text", "=", "split_on_tokens", "(", "added_tokens", ",", "text", ")", "\n", "return", "tokenized_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._tokenize": [[652, 660], ["None"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Do NOT take care of added tokens.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids": [[661, 679], ["isinstance", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "ids.append", "len", "logger.warning", "isinstance", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a single token, or a sequence of tokens, (str/unicode) in a single integer id\n            (resp. a sequence of ids), using the vocabulary.\n        \"\"\"", "\n", "if", "tokens", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "isinstance", "(", "tokens", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "tokens", ",", "unicode", ")", ")", ":", "\n", "            ", "return", "self", ".", "_convert_token_to_id_with_added_voc", "(", "tokens", ")", "\n", "\n", "", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "_convert_token_to_id_with_added_voc", "(", "token", ")", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Token indices sequence length is longer than the specified maximum sequence length \"", "\n", "\"for this model ({} > {}). Running this sequence through the model will result in \"", "\n", "\"indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc": [[680, 687], ["tokenization_utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "_convert_token_to_id_with_added_voc", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "token", "in", "self", ".", "added_tokens_encoder", ":", "\n", "            ", "return", "self", ".", "added_tokens_encoder", "[", "token", "]", "\n", "", "return", "self", ".", "_convert_token_to_id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id": [[688, 690], ["None"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode": [[691, 738], ["tokenization_utils.PreTrainedTokenizer.encode_plus"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus"], ["", "def", "encode", "(", "self", ",", "\n", "text", ",", "\n", "text_pair", "=", "None", ",", "\n", "add_special_tokens", "=", "False", ",", "\n", "max_length", "=", "None", ",", "\n", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "'longest_first'", ",", "\n", "return_tensors", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Converts a string in a sequence of ids (integer), using the tokenizer and vocabulary.\n\n        Same as doing ``self.convert_tokens_to_ids(self.tokenize(text))``.\n\n        Args:\n            text: The first sequence to be encoded. This can be a string, a list of strings (tokenized string using\n                the `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\n                method)\n            text_pair: Optional second sequence to be encoded. This can be a string, a list of strings (tokenized\n                string using the `tokenize` method) or a list of integers (tokenized string ids using the\n                `convert_tokens_to_ids` method)\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n            max_length: if set to a number, will limit the total sequence returned so that it has a maximum length.\n                If there are overflowing tokens, those will be added to the returned dictionary\n            stride: if set to a number along with max_length, the overflowing tokens returned will contain some tokens\n                from the main sequence returned. The value of this argument defines the number of additional tokens.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences)\n                - 'only_first': Only truncate the first sequence\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n            return_tensors: (optional) can be set to 'tf' or 'pt' to return respectively TensorFlow tf.constant\n                or PyTorch torch.Tensor instead of a list of python integers.\n            **kwargs: passed to the `self.tokenize()` method\n        \"\"\"", "\n", "encoded_inputs", "=", "self", ".", "encode_plus", "(", "text", ",", "\n", "text_pair", "=", "text_pair", ",", "\n", "max_length", "=", "max_length", ",", "\n", "add_special_tokens", "=", "add_special_tokens", ",", "\n", "stride", "=", "stride", ",", "\n", "truncation_strategy", "=", "truncation_strategy", ",", "\n", "return_tensors", "=", "return_tensors", ",", "\n", "**", "kwargs", ")", "\n", "\n", "return", "encoded_inputs", "[", "\"input_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus": [[739, 796], ["tokenization_utils.PreTrainedTokenizer.encode_plus.get_input_ids"], "methods", ["None"], ["", "def", "encode_plus", "(", "self", ",", "\n", "text", ",", "\n", "text_pair", "=", "None", ",", "\n", "add_special_tokens", "=", "False", ",", "\n", "max_length", "=", "None", ",", "\n", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "'longest_first'", ",", "\n", "return_tensors", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns a dictionary containing the encoded sequence or sequence pair and additional informations:\n        the mask for sequence classification and the overflowing elements if a ``max_length`` is specified.\n\n        Args:\n            text: The first sequence to be encoded. This can be a string, a list of strings (tokenized string using\n                the `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\n                method)\n            text_pair: Optional second sequence to be encoded. This can be a string, a list of strings (tokenized\n                string using the `tokenize` method) or a list of integers (tokenized string ids using the\n                `convert_tokens_to_ids` method)\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n            max_length: if set to a number, will limit the total sequence returned so that it has a maximum length.\n                If there are overflowing tokens, those will be added to the returned dictionary\n            stride: if set to a number along with max_length, the overflowing tokens returned will contain some tokens\n                from the main sequence returned. The value of this argument defines the number of additional tokens.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences)\n                - 'only_first': Only truncate the first sequence\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n            return_tensors: (optional) can be set to 'tf' or 'pt' to return respectively TensorFlow tf.constant\n                or PyTorch torch.Tensor instead of a list of python integers.\n            **kwargs: passed to the `self.tokenize()` method\n        \"\"\"", "\n", "\n", "def", "get_input_ids", "(", "text", ")", ":", "\n", "            ", "if", "isinstance", "(", "text", ",", "six", ".", "string_types", ")", ":", "\n", "                ", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenize", "(", "text", ",", "**", "kwargs", ")", ")", "\n", "", "elif", "isinstance", "(", "text", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "text", ")", ">", "0", "and", "isinstance", "(", "text", "[", "0", "]", ",", "six", ".", "string_types", ")", ":", "\n", "                ", "return", "self", ".", "convert_tokens_to_ids", "(", "text", ")", "\n", "", "elif", "isinstance", "(", "text", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "text", ")", ">", "0", "and", "isinstance", "(", "text", "[", "0", "]", ",", "int", ")", ":", "\n", "                ", "return", "text", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\"", ")", "\n", "\n", "", "", "first_ids", "=", "get_input_ids", "(", "text", ")", "\n", "second_ids", "=", "get_input_ids", "(", "text_pair", ")", "if", "text_pair", "is", "not", "None", "else", "None", "\n", "\n", "return", "self", ".", "prepare_for_model", "(", "first_ids", ",", "\n", "pair_ids", "=", "second_ids", ",", "\n", "max_length", "=", "max_length", ",", "\n", "add_special_tokens", "=", "add_special_tokens", ",", "\n", "stride", "=", "stride", ",", "\n", "truncation_strategy", "=", "truncation_strategy", ",", "\n", "return_tensors", "=", "return_tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.prepare_for_model": [[797, 881], ["bool", "len", "len", "tokenization_utils.PreTrainedTokenizer.truncate_sequences", "tokenization_utils.PreTrainedTokenizer.build_inputs_with_special_tokens", "tokenization_utils.PreTrainedTokenizer.create_token_type_ids_from_sequences", "tokenization_utils.PreTrainedTokenizer.get_special_tokens_mask", "file_utils.is_tf_available", "tf.constant", "tf.constant", "tokenization_utils.PreTrainedTokenizer.num_added_tokens", "file_utils.is_torch_available", "torch.tensor", "torch.tensor", "len", "len", "logger.warning", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.truncate_sequences", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.create_token_type_ids_from_sequences", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.get_special_tokens_mask", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.num_added_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.is_torch_available"], ["", "def", "prepare_for_model", "(", "self", ",", "ids", ",", "pair_ids", "=", "None", ",", "max_length", "=", "None", ",", "add_special_tokens", "=", "False", ",", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "'longest_first'", ",", "return_tensors", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Prepares a sequence of input id, or a pair of sequences of inputs ids so that it can be used by the model.\n        It adds special tokens, truncates\n        sequences if overflowing while taking into account the special tokens and manages a window stride for\n        overflowing tokens\n\n        Args:\n            ids: list of tokenized input ids. Can be obtained from a string by chaining the\n                `tokenize` and `convert_tokens_to_ids` methods.\n            pair_ids: Optional second list of input ids. Can be obtained from a string by chaining the\n                `tokenize` and `convert_tokens_to_ids` methods.\n            max_length: maximum length of the returned list. Will truncate by taking into account the special tokens.\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n            stride: window stride for overflowing tokens. Can be useful for edge effect removal when using sequential\n                list of inputs.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences)\n                - 'only_first': Only truncate the first sequence\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n            return_tensors: (optional) can be set to 'tf' or 'pt' to return respectively TensorFlow tf.constant\n                or PyTorch torch.Tensor instead of a list of python integers.\n\n        Return:\n            A Dictionary of shape::\n\n                {\n                    input_ids: list[int],\n                    overflowing_tokens: list[int] if a ``max_length`` is specified, else None\n                    special_tokens_mask: list[int] if ``add_special_tokens`` if set to ``True``\n                }\n\n            With the fields:\n                ``input_ids``: list of tokens to be fed to a model\n\n                ``overflowing_tokens``: list of overflowing tokens if a max length is specified.\n\n                ``special_tokens_mask``: if adding special tokens, this is a list of [0, 1], with 0 specifying special added\n                tokens and 1 specifying sequence tokens.\n        \"\"\"", "\n", "pair", "=", "bool", "(", "pair_ids", "is", "not", "None", ")", "\n", "len_ids", "=", "len", "(", "ids", ")", "\n", "len_pair_ids", "=", "len", "(", "pair_ids", ")", "if", "pair", "else", "0", "\n", "\n", "encoded_inputs", "=", "{", "}", "\n", "total_len", "=", "len_ids", "+", "len_pair_ids", "+", "(", "self", ".", "num_added_tokens", "(", "pair", "=", "pair", ")", "if", "add_special_tokens", "else", "0", ")", "\n", "if", "max_length", "and", "total_len", ">", "max_length", ":", "\n", "            ", "ids", ",", "pair_ids", ",", "overflowing_tokens", "=", "self", ".", "truncate_sequences", "(", "ids", ",", "pair_ids", "=", "pair_ids", ",", "\n", "num_tokens_to_remove", "=", "total_len", "-", "max_length", ",", "\n", "truncation_strategy", "=", "truncation_strategy", ",", "\n", "stride", "=", "stride", ")", "\n", "encoded_inputs", "[", "\"overflowing_tokens\"", "]", "=", "overflowing_tokens", "\n", "encoded_inputs", "[", "\"num_truncated_tokens\"", "]", "=", "total_len", "-", "max_length", "\n", "\n", "", "if", "add_special_tokens", ":", "\n", "            ", "sequence", "=", "self", ".", "build_inputs_with_special_tokens", "(", "ids", ",", "pair_ids", ")", "\n", "token_type_ids", "=", "self", ".", "create_token_type_ids_from_sequences", "(", "ids", ",", "pair_ids", ")", "\n", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "=", "self", ".", "get_special_tokens_mask", "(", "ids", ",", "pair_ids", ")", "\n", "", "else", ":", "\n", "            ", "sequence", "=", "ids", "+", "pair_ids", "if", "pair", "else", "ids", "\n", "token_type_ids", "=", "[", "0", "]", "*", "len", "(", "ids", ")", "+", "(", "[", "1", "]", "*", "len", "(", "pair_ids", ")", "if", "pair", "else", "[", "]", ")", "\n", "\n", "", "if", "return_tensors", "==", "'tf'", "and", "is_tf_available", "(", ")", ":", "\n", "            ", "sequence", "=", "tf", ".", "constant", "(", "[", "sequence", "]", ")", "\n", "token_type_ids", "=", "tf", ".", "constant", "(", "[", "token_type_ids", "]", ")", "\n", "", "elif", "return_tensors", "==", "'pt'", "and", "is_torch_available", "(", ")", ":", "\n", "            ", "sequence", "=", "torch", ".", "tensor", "(", "[", "sequence", "]", ")", "\n", "token_type_ids", "=", "torch", ".", "tensor", "(", "[", "token_type_ids", "]", ")", "\n", "", "elif", "return_tensors", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Unable to convert output to tensors format {}, PyTorch or TensorFlow is not available.\"", ".", "format", "(", "return_tensors", ")", ")", "\n", "\n", "", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "sequence", "\n", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "token_type_ids", "\n", "\n", "if", "max_length", "and", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", ">", "max_length", ":", "\n", "            ", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "encoded_inputs", "[", "\"input_ids\"", "]", "[", ":", "max_length", "]", "\n", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "encoded_inputs", "[", "\"token_type_ids\"", "]", "[", ":", "max_length", "]", "\n", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "=", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "[", ":", "max_length", "]", "\n", "\n", "", "return", "encoded_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.truncate_sequences": [[882, 921], ["range", "min", "len", "min", "len", "len", "min", "len", "len", "len", "ValueError", "ValueError", "len"], "methods", ["None"], ["", "def", "truncate_sequences", "(", "self", ",", "ids", ",", "pair_ids", "=", "None", ",", "num_tokens_to_remove", "=", "0", ",", "truncation_strategy", "=", "'longest_first'", ",", "stride", "=", "0", ")", ":", "\n", "        ", "\"\"\"Truncates a sequence pair in place to the maximum length.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences).\n                    Overflowing tokens only contains overflow from the first sequence.\n                - 'only_first': Only truncate the first sequence. raise an error if the first sequence is shorter or equal to than num_tokens_to_remove.\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n        \"\"\"", "\n", "if", "num_tokens_to_remove", "<=", "0", ":", "\n", "            ", "return", "ids", ",", "pair_ids", ",", "[", "]", "\n", "\n", "", "if", "truncation_strategy", "==", "'longest_first'", ":", "\n", "            ", "overflowing_tokens", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_tokens_to_remove", ")", ":", "\n", "                ", "if", "pair_ids", "is", "None", "or", "len", "(", "ids", ")", ">", "len", "(", "pair_ids", ")", ":", "\n", "                    ", "overflowing_tokens", "=", "[", "ids", "[", "-", "1", "]", "]", "+", "overflowing_tokens", "\n", "ids", "=", "ids", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "pair_ids", "=", "pair_ids", "[", ":", "-", "1", "]", "\n", "", "", "window_len", "=", "min", "(", "len", "(", "ids", ")", ",", "stride", ")", "\n", "if", "window_len", ">", "0", ":", "\n", "                ", "overflowing_tokens", "=", "ids", "[", "-", "window_len", ":", "]", "+", "overflowing_tokens", "\n", "", "", "elif", "truncation_strategy", "==", "'only_first'", ":", "\n", "            ", "assert", "len", "(", "ids", ")", ">", "num_tokens_to_remove", "\n", "window_len", "=", "min", "(", "len", "(", "ids", ")", ",", "stride", "+", "num_tokens_to_remove", ")", "\n", "overflowing_tokens", "=", "ids", "[", "-", "window_len", ":", "]", "\n", "ids", "=", "ids", "[", ":", "-", "num_tokens_to_remove", "]", "\n", "", "elif", "truncation_strategy", "==", "'only_second'", ":", "\n", "            ", "assert", "pair_ids", "is", "not", "None", "and", "len", "(", "pair_ids", ")", ">", "num_tokens_to_remove", "\n", "window_len", "=", "min", "(", "len", "(", "pair_ids", ")", ",", "stride", "+", "num_tokens_to_remove", ")", "\n", "overflowing_tokens", "=", "pair_ids", "[", "-", "window_len", ":", "]", "\n", "pair_ids", "=", "pair_ids", "[", ":", "-", "num_tokens_to_remove", "]", "\n", "", "elif", "truncation_strategy", "==", "'do_not_truncate'", ":", "\n", "            ", "raise", "ValueError", "(", "\"Input sequence are too long for max_length. Please select a truncation strategy.\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Truncation_strategy should be selected in ['longest_first', 'only_first', 'only_second', 'do_not_truncate']\"", ")", "\n", "", "return", "(", "ids", ",", "pair_ids", ",", "overflowing_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.create_token_type_ids_from_sequences": [[922, 927], ["logger.warning", "len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\"This tokenizer does not make use of special tokens.\"", ")", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "token_ids_0", ")", "*", "[", "0", "]", "\n", "", "return", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", "+", "[", "1", "]", "*", "len", "(", "token_ids_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.build_inputs_with_special_tokens": [[928, 940], ["logger.warning"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "logger", ".", "warning", "(", "\"This tokenizer does not make use of special tokens. Input is returned with no modification.\"", ")", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "token_ids_0", "\n", "", "return", "token_ids_0", "+", "token_ids_1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.get_special_tokens_mask": [[941, 957], ["len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n        \"\"\"", "\n", "return", "[", "0", "]", "*", "(", "(", "len", "(", "token_ids_1", ")", "if", "token_ids_1", "else", "0", ")", "+", "len", "(", "token_ids_0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens": [[958, 979], ["isinstance", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token", "tokens.append", "tokens.append", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\" Converts a single index or a sequence of indices (integers) in a token \"\n            (resp.) a sequence of tokens (str/unicode), using the vocabulary and added tokens.\n\n            Args:\n                skip_special_tokens: Don't decode special tokens (self.all_special_tokens). Default: False\n        \"\"\"", "\n", "if", "isinstance", "(", "ids", ",", "int", ")", ":", "\n", "            ", "if", "ids", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "return", "self", ".", "added_tokens_decoder", "[", "ids", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_convert_id_to_token", "(", "ids", ")", "\n", "", "", "tokens", "=", "[", "]", "\n", "for", "index", "in", "ids", ":", "\n", "            ", "if", "skip_special_tokens", "and", "index", "in", "self", ".", "all_special_ids", ":", "\n", "                ", "continue", "\n", "", "if", "index", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "added_tokens_decoder", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "_convert_id_to_token", "(", "index", ")", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer._convert_id_to_token": [[980, 982], ["None"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string": [[983, 989], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string.\n            The most simple way to do it is ' '.join(self.convert_ids_to_tokens(token_ids))\n            but we often want to remove sub-word tokenization artifacts at the same time.\n        \"\"\"", "\n", "return", "' '", ".", "join", "(", "self", ".", "convert_ids_to_tokens", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode": [[990, 1027], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "sub_texts.append", "tokenization_utils.PreTrainedTokenizer.clean_up_tokenization", "sub_texts.append", "current_sub_text.append", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "sub_texts.append", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.clean_up_tokenization", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_string"], ["", "def", "decode", "(", "self", ",", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Converts a sequence of ids (integer) in a string, using the tokenizer and vocabulary\n        with options to remove special tokens and clean up tokenization spaces.\n        Similar to doing ``self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))``.\n\n        Args:\n            token_ids: list of tokenized input ids. Can be obtained using the `encode` or `encode_plus` methods.\n            skip_special_tokens: if set to True, will replace special tokens.\n            clean_up_tokenization_spaces: if set to True, will clean up the tokenization spaces.\n        \"\"\"", "\n", "filtered_tokens", "=", "self", ".", "convert_ids_to_tokens", "(", "token_ids", ",", "skip_special_tokens", "=", "skip_special_tokens", ")", "\n", "\n", "# To avoid mixing byte-level and unicode for byte-level BPT", "\n", "# we need to build string separatly for added tokens and byte-level tokens", "\n", "# cf. https://github.com/huggingface/transformers/issues/1133", "\n", "sub_texts", "=", "[", "]", "\n", "current_sub_text", "=", "[", "]", "\n", "for", "token", "in", "filtered_tokens", ":", "\n", "            ", "if", "skip_special_tokens", "and", "token", "in", "self", ".", "all_special_ids", ":", "\n", "                ", "continue", "\n", "", "if", "token", "in", "self", ".", "added_tokens_encoder", ":", "\n", "                ", "if", "current_sub_text", ":", "\n", "                    ", "sub_texts", ".", "append", "(", "self", ".", "convert_tokens_to_string", "(", "current_sub_text", ")", ")", "\n", "current_sub_text", "=", "[", "]", "\n", "", "sub_texts", ".", "append", "(", "\" \"", "+", "token", ")", "\n", "", "else", ":", "\n", "                ", "current_sub_text", ".", "append", "(", "token", ")", "\n", "", "", "if", "current_sub_text", ":", "\n", "            ", "sub_texts", ".", "append", "(", "self", ".", "convert_tokens_to_string", "(", "current_sub_text", ")", ")", "\n", "", "text", "=", "''", ".", "join", "(", "sub_texts", ")", "\n", "\n", "if", "clean_up_tokenization_spaces", ":", "\n", "            ", "clean_text", "=", "self", ".", "clean_up_tokenization", "(", "text", ")", "\n", "return", "clean_text", "\n", "", "else", ":", "\n", "            ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.special_tokens_map": [[1028, 1039], ["getattr"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "special_tokens_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" A dictionary mapping special token class attribute (cls_token, unk_token...) to their\n            values ('<unk>', '<cls>'...)\n        \"\"\"", "\n", "set_attr", "=", "{", "}", "\n", "for", "attr", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "            ", "attr_value", "=", "getattr", "(", "self", ",", "\"_\"", "+", "attr", ")", "\n", "if", "attr_value", ":", "\n", "                ", "set_attr", "[", "attr", "]", "=", "attr_value", "\n", "", "", "return", "set_attr", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.all_special_tokens": [[1040, 1051], ["set_attr.values", "list", "set", "isinstance", "list"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_special_tokens", "(", "self", ")", ":", "\n", "        ", "\"\"\" List all the special tokens ('<unk>', '<cls>'...) mapped to class attributes\n            (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "[", "]", "\n", "set_attr", "=", "self", ".", "special_tokens_map", "\n", "for", "attr_value", "in", "set_attr", ".", "values", "(", ")", ":", "\n", "            ", "all_toks", "=", "all_toks", "+", "(", "list", "(", "attr_value", ")", "if", "isinstance", "(", "attr_value", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "attr_value", "]", ")", "\n", "", "all_toks", "=", "list", "(", "set", "(", "all_toks", ")", ")", "\n", "return", "all_toks", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.all_special_ids": [[1052, 1060], ["list", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "@", "property", "\n", "def", "all_special_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\" List the vocabulary indices of the special tokens ('<unk>', '<cls>'...) mapped to\n            class attributes (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "self", ".", "all_special_tokens", "\n", "all_ids", "=", "list", "(", "self", ".", "_convert_token_to_id", "(", "t", ")", "for", "t", "in", "all_toks", ")", "\n", "return", "all_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.clean_up_tokenization": [[1061, 1069], ["out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "clean_up_tokenization", "(", "out_string", ")", ":", "\n", "        ", "\"\"\" Clean up a list of simple English tokenization artifacts like spaces before punctuations and abreviated forms.\n        \"\"\"", "\n", "out_string", "=", "out_string", ".", "replace", "(", "' .'", ",", "'.'", ")", ".", "replace", "(", "' ?'", ",", "'?'", ")", ".", "replace", "(", "' !'", ",", "'!'", ")", ".", "replace", "(", "' ,'", ",", "','", "\n", ")", ".", "replace", "(", "\" ' \"", ",", "\"'\"", ")", ".", "replace", "(", "\" n't\"", ",", "\"n't\"", ")", ".", "replace", "(", "\" 'm\"", ",", "\"'m\"", ")", ".", "replace", "(", "\" do not\"", ",", "\" don't\"", "\n", ")", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "\" 've\"", ",", "\"'ve\"", ")", ".", "replace", "(", "\" 're\"", ",", "\"'re\"", ")", "\n", "return", "out_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.__init__": [[74, 85], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings": [[86, 119], ["old_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.to", "modeling_utils.PreTrainedModel._init_weights", "min"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTPreTrainedModel._init_weights"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Module from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``torch.nn.Embeddings``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", "\n", "new_embeddings", ".", "to", "(", "old_embeddings", ".", "weight", ".", "device", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "_init_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy word embeddings from the previous weights", "\n", "num_tokens_to_copy", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights": [[120, 134], ["torch.nn.Parameter", "hasattr", "torch.nn.functional.pad", "second_module.weight.clone"], "methods", ["None"], ["", "def", "_tie_or_clone_weights", "(", "self", ",", "first_module", ",", "second_module", ")", ":", "\n", "        ", "\"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "            ", "first_module", ".", "weight", "=", "nn", ".", "Parameter", "(", "second_module", ".", "weight", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "first_module", ".", "weight", "=", "second_module", ".", "weight", "\n", "\n", "", "if", "hasattr", "(", "first_module", ",", "'bias'", ")", "and", "first_module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "first_module", ".", "bias", ".", "data", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "first_module", ".", "bias", ".", "data", ",", "\n", "(", "0", ",", "first_module", ".", "weight", ".", "shape", "[", "0", "]", "-", "first_module", ".", "bias", ".", "shape", "[", "0", "]", ")", ",", "\n", "'constant'", ",", "\n", "0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.resize_token_embeddings": [[136, 163], ["getattr", "getattr._resize_token_embeddings", "hasattr", "modeling_utils.PreTrainedModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTModel._resize_token_embeddings", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n\n        Return: ``torch.nn.Embeddings``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "model_embeds", "=", "base_model", ".", "_resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "model_embeds", "\n", "\n", "# Update base model and current model config", "\n", "", "self", ".", "config", ".", "vocab_size", "=", "new_num_tokens", "\n", "base_model", ".", "vocab_size", "=", "new_num_tokens", "\n", "\n", "# Tie weights again if needed", "\n", "if", "hasattr", "(", "self", ",", "'tie_weights'", ")", ":", "\n", "            ", "self", ".", "tie_weights", "(", ")", "\n", "\n", "", "return", "model_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights": [[164, 172], ["modeling_utils.PreTrainedModel.apply", "modeling_utils.PreTrainedModel.prune_heads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize and prunes weights if needed. \"\"\"", "\n", "# Initialize weights", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n", "# Prune heads if needed", "\n", "if", "self", ".", "config", ".", "pruned_heads", ":", "\n", "            ", "self", ".", "prune_heads", "(", "self", ".", "config", ".", "pruned_heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.prune_heads": [[173, 189], ["getattr", "heads_to_prune.items", "getattr._prune_heads", "list", "set", "set", "modeling_utils.PreTrainedModel.config.pruned_heads.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTModel._prune_heads"], ["", "", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n                E.g. {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "\n", "# save new sets of pruned heads as union of previously stored pruned heads and newly pruned heads", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "union_heads", "=", "set", "(", "self", ".", "config", ".", "pruned_heads", ".", "get", "(", "layer", ",", "[", "]", ")", ")", "|", "set", "(", "heads", ")", "\n", "self", ".", "config", ".", "pruned_heads", "[", "layer", "]", "=", "list", "(", "union_heads", ")", "# Unfortunately we have to store it as list for JSON", "\n", "\n", "", "base_model", ".", "_prune_heads", "(", "heads_to_prune", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.save_pretrained": [[190, 206], ["os.path.isdir", "model_to_save.config.save_pretrained", "os.path.join", "torch.save", "logger.info", "hasattr", "model_to_save.state_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Only save the model it-self if we are using distributed training", "\n", "model_to_save", "=", "self", ".", "module", "if", "hasattr", "(", "self", ",", "'module'", ")", "else", "self", "\n", "\n", "# Save configuration file", "\n", "model_to_save", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "WEIGHTS_NAME", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "logger", ".", "info", "(", "\"Model weights saved in {}\"", ".", "format", "(", "output_model_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.from_pretrained": [[207, 424], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "hasattr", "load_tf2_checkpoint_in_pytorch_model.eval", "cls.config_class.from_pretrained", "torch.load", "file_utils.cached_path.endswith", "state_dict.copy.copy.keys", "zip", "getattr", "state_dict.copy.copy.copy", "modeling_utils.PreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n                - None if you are both providing the configuration and state dictionary (resp. with keyword arguments ``config`` and ``state_dict``)\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "'state_dict'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "'from_tf'", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "'output_loading_info'", ",", "False", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", ")", ":", "\n", "# Load from a TF 1.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "elif", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\"Error no file named {} found in directory {} or `from_tf` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", "]", ",", "\n", "pretrained_model_name_or_path", ")", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "", "else", ":", "\n", "                ", "assert", "from_tf", ",", "\"Error finding file {}, no file or TF 1.X checkpoint found\"", ".", "format", "(", "pretrained_model_name_or_path", ")", "\n", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "force_download", ",", "proxies", "=", "proxies", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", "\n", "", "else", ":", "\n", "                    ", "msg", "=", "\"Model name '{}' was not found in model name list ({}). \"", "\"We assumed '{}' was a path or url to model weight files named one of {} but \"", "\"couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ",", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "]", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "if", "from_tf", ":", "\n", "            ", "if", "resolved_archive_file", ".", "endswith", "(", "'.index'", ")", ":", "\n", "# Load from a TensorFlow 1.X checkpoint - provided by original authors", "\n", "                ", "model", "=", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "", "else", ":", "\n", "# Load from our TensorFlow 2.0 checkpoints", "\n", "                ", "try", ":", "\n", "                    ", "from", "transformers", "import", "load_tf2_checkpoint_in_pytorch_model", "\n", "model", "=", "load_tf2_checkpoint_in_pytorch_model", "(", "model", ",", "resolved_archive_file", ",", "allow_missing_keys", "=", "True", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "                    ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "e", "\n", "", "", "", "else", ":", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "            ", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                    ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "                ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "                ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "                ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                    ", "if", "child", "is", "not", "None", ":", "\n", "                        ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "''", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "                ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "'.'", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "                ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "\n", "", "", "if", "hasattr", "(", "model", ",", "'tie_weights'", ")", ":", "\n", "            ", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.Conv1D.__init__": [[427, 437], ["torch.nn.Module.__init__", "torch.empty", "torch.nn.init.normal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "\"\"\" Conv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.Conv1D.forward": [[438, 443], ["torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PoolerStartLogits.__init__": [[447, 450], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerStartLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PoolerStartLogits.forward": [[451, 466], ["modeling_utils.PoolerStartLogits.dense().squeeze", "modeling_utils.PoolerStartLogits.dense", "next", "modeling_utils.PoolerStartLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape `(batch_size, seq_len)`\n                invalid position mask such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "x", "=", "self", ".", "dense", "(", "hidden_states", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PoolerEndLogits.__init__": [[471, 477], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.LayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerEndLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PoolerEndLogits.forward": [[478, 510], ["modeling_utils.PoolerEndLogits.dense_0", "modeling_utils.PoolerEndLogits.activation", "modeling_utils.PoolerEndLogits.LayerNorm", "modeling_utils.PoolerEndLogits.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather", "start_states.expand.expand.expand", "torch.cat", "modeling_utils.PoolerEndLogits.dense_1", "next", "modeling_utils.PoolerEndLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to hidden_states\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, seq_len)``\n                Mask of invalid position such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "slen", ",", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "2", ":", "]", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "start_states", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ")", "# shape (bsz, slen, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "hidden_states", ",", "start_states", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "LayerNorm", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PoolerAnswerClass.__init__": [[514, 519], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerAnswerClass", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PoolerAnswerClass.forward": [[520, 554], ["modeling_utils.PoolerAnswerClass.dense_0", "modeling_utils.PoolerAnswerClass.activation", "modeling_utils.PoolerAnswerClass.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather().squeeze", "cls_index[].expand", "hidden_states.gather().squeeze", "torch.cat", "modeling_utils.PoolerAnswerClass.dense_1", "hidden_states.gather", "hidden_states.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to ``hidden_states``.\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span.\n            **cls_index**: torch.LongTensor of shape ``(batch_size,)``\n                position of the CLS token. If None, take the last token.\n\n            note(Original repo):\n                no dependency on end_feature so that we can obtain one single `cls_logits`\n                for each sample\n        \"\"\"", "\n", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "1", "]", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "\n", "", "if", "cls_index", "is", "not", "None", ":", "\n", "            ", "cls_index", "=", "cls_index", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "cls_token_state", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "", "else", ":", "\n", "            ", "cls_token_state", "=", "hidden_states", "[", ":", ",", "-", "1", ",", ":", "]", "# shape (bsz, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "start_states", ",", "cls_token_state", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.SQuADHead.__init__": [[596, 604], ["torch.nn.Module.__init__", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SQuADHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.SQuADHead.forward": [[605, 663], ["modeling_utils.SQuADHead.start_logits", "modeling_utils.SQuADHead.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_utils.SQuADHead.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_utils.SQuADHead.answer_class", "modeling_utils.SQuADHead.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "\n", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "start_states", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.SequenceSummary.__init__": [[680, 709], ["torch.nn.Module.__init__", "Identity", "Identity", "Identity", "Identity", "hasattr", "hasattr", "torch.nn.Linear", "hasattr", "torch.nn.Tanh", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SequenceSummary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "else", "'last'", "\n", "if", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "'summary_proj_to_labels'", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "\n", "", "self", ".", "activation", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_activation'", ")", "and", "config", ".", "summary_activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "self", ".", "first_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_first_dropout'", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_last_dropout'", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.SequenceSummary.forward": [[710, 740], ["modeling_utils.SequenceSummary.first_dropout", "modeling_utils.SequenceSummary.summary", "modeling_utils.SequenceSummary.activation", "modeling_utils.SequenceSummary.last_dropout", "hidden_states.mean", "hidden_states.gather().squeeze", "torch.full_like", "cls_index.expand.expand.unsqueeze().unsqueeze", "cls_index.expand.expand.expand", "hidden_states.gather", "cls_index.expand.expand.unsqueeze", "hidden_states.size", "cls_index.expand.expand.dim"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, ..., seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "'last'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'first'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'mean'", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "'cls_index'", ":", "\n", "            ", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "cls_index", "=", "cls_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cls_index", "=", "cls_index", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "cls_index", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer": [[742, 765], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "torch.nn.Linear().to", "nn.Linear().to.weight.copy_", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "nn.Linear().to.bias.copy_", "layer.weight.index_select().clone", "layer.bias.clone().detach", "layer.bias[].clone().detach", "torch.nn.Linear", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select", "layer.bias.clone", "layer.bias[].clone"], "function", ["None"], ["", "", "def", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\" Prune a linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "if", "dim", "==", "1", ":", "\n", "            ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "nn", ".", "Linear", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ",", "bias", "=", "layer", ".", "bias", "is", "not", "None", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_conv1d_layer": [[767, 789], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "Conv1D().to", "Conv1D().to.weight.copy_", "Conv1D().to.bias.copy_", "layer.bias.clone().detach", "layer.bias[].clone().detach", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select().clone", "modeling_utils.Conv1D", "layer.bias.clone", "layer.bias[].clone", "layer.weight.index_select"], "function", ["None"], ["", "def", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D layer (a model parameters) to keep only entries in index.\n        A Conv1D work as a Linear layer (see e.g. BERT) but the weights are transposed.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "        ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "Conv1D", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_layer": [[791, 802], ["isinstance", "modeling_utils.prune_linear_layer", "isinstance", "modeling_utils.prune_conv1d_layer", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D or nn.Linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "if", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "return", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "elif", "isinstance", "(", "layer", ",", "Conv1D", ")", ":", "\n", "        ", "return", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Can't prune layer of class {}\"", ".", "format", "(", "layer", ".", "__class__", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFMultiHeadAttention.__init__": [[78, 91], ["super().__init__", "int", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model_size", ",", "num_heads", ",", "output_attentions", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMultiHeadAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "d_model_size", "=", "d_model_size", "\n", "\n", "self", ".", "depth", "=", "int", "(", "d_model_size", "/", "self", ".", "num_heads", ")", "\n", "\n", "self", ".", "Wq", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "'Wq'", ")", "\n", "self", ".", "Wk", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "'Wk'", ")", "\n", "self", ".", "Wv", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "'Wv'", ")", "\n", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "'dense'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads": [[92, 95], ["tensorflow.reshape", "tensorflow.transpose"], "methods", ["None"], ["", "def", "split_into_heads", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_heads", ",", "self", ".", "depth", ")", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFMultiHeadAttention.call": [[96, 123], ["modeling_tf_ctrl.TFMultiHeadAttention.Wq", "modeling_tf_ctrl.TFMultiHeadAttention.Wk", "modeling_tf_ctrl.TFMultiHeadAttention.Wv", "modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads", "modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads", "modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads", "tensorflow.stack", "modeling_tf_ctrl.scaled_dot_product_attention", "tensorflow.transpose", "tensorflow.reshape", "modeling_tf_ctrl.TFMultiHeadAttention.dense", "tensorflow.unstack", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.scaled_dot_product_attention"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "v", ",", "k", ",", "q", ",", "mask", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "batch_size", "=", "q", ".", "shape", "[", "0", "]", "\n", "\n", "q", "=", "self", ".", "Wq", "(", "q", ")", "\n", "k", "=", "self", ".", "Wk", "(", "k", ")", "\n", "v", "=", "self", ".", "Wv", "(", "v", ")", "\n", "\n", "q", "=", "self", ".", "split_into_heads", "(", "q", ",", "batch_size", ")", "\n", "k", "=", "self", ".", "split_into_heads", "(", "k", ",", "batch_size", ")", "\n", "v", "=", "self", ".", "split_into_heads", "(", "v", ",", "batch_size", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "tf", ".", "unstack", "(", "layer_past", ",", "axis", "=", "1", ")", "\n", "k", "=", "tf", ".", "concat", "(", "(", "past_key", ",", "k", ")", ",", "dim", "=", "-", "2", ")", "\n", "v", "=", "tf", ".", "concat", "(", "(", "past_value", ",", "v", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "tf", ".", "stack", "(", "(", "k", ",", "v", ")", ",", "axis", "=", "1", ")", "\n", "\n", "output", "=", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", ",", "head_mask", ")", "\n", "scaled_attention", "=", "tf", ".", "transpose", "(", "output", "[", "0", "]", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "attn", "=", "output", "[", "1", "]", "\n", "original_size_attention", "=", "tf", ".", "reshape", "(", "scaled_attention", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "d_model_size", ")", ")", "\n", "output", "=", "self", ".", "dense", "(", "original_size_attention", ")", "\n", "\n", "outputs", "=", "(", "output", ",", "present", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFEncoderLayer.__init__": [[134, 148], ["super().__init__", "modeling_tf_ctrl.TFMultiHeadAttention", "modeling_tf_ctrl.point_wise_feed_forward_network", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.point_wise_feed_forward_network"], ["    ", "def", "__init__", "(", "self", ",", "d_model_size", ",", "num_heads", ",", "dff", ",", "rate", "=", "0.1", ",", "layer_norm_epsilon", "=", "1e-6", ",", "output_attentions", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFEncoderLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "multi_head_attention", "=", "TFMultiHeadAttention", "(", "d_model_size", ",", "\n", "num_heads", ",", "\n", "output_attentions", ",", "\n", "name", "=", "\"multi_head_attention\"", ")", "\n", "self", ".", "ffn", "=", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ",", "name", "=", "\"ffn\"", ")", "\n", "\n", "self", ".", "layernorm1", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "\"layernorm1\"", ")", "\n", "self", ".", "layernorm2", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "\"layernorm2\"", ")", "\n", "\n", "self", ".", "dropout1", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", ")", "\n", "self", ".", "dropout2", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFEncoderLayer.call": [[149, 165], ["modeling_tf_ctrl.TFEncoderLayer.layernorm1", "modeling_tf_ctrl.TFEncoderLayer.multi_head_attention", "modeling_tf_ctrl.TFEncoderLayer.dropout1", "modeling_tf_ctrl.TFEncoderLayer.layernorm2", "modeling_tf_ctrl.TFEncoderLayer.ffn", "modeling_tf_ctrl.TFEncoderLayer.dropout2"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "mask", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "normed", "=", "self", ".", "layernorm1", "(", "x", ")", "\n", "attn_outputs", "=", "self", ".", "multi_head_attention", "(", "[", "normed", ",", "normed", ",", "normed", ",", "mask", ",", "layer_past", ",", "\n", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "attn_output", "=", "attn_outputs", "[", "0", "]", "\n", "attn_output", "=", "self", ".", "dropout1", "(", "attn_output", ",", "training", "=", "training", ")", "\n", "out1", "=", "x", "+", "attn_output", "\n", "\n", "out2", "=", "self", ".", "layernorm2", "(", "out1", ")", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "out2", ")", "\n", "ffn_output", "=", "self", ".", "dropout2", "(", "ffn_output", ",", "training", "=", "training", ")", "\n", "out2", "=", "out1", "+", "ffn_output", "\n", "\n", "outputs", "=", "(", "out2", ",", ")", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLMainLayer.__init__": [[168, 194], ["super().__init__", "modeling_tf_ctrl.positional_encoding", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_ctrl.TFEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.positional_encoding"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "d_model_size", "=", "config", ".", "n_embd", "\n", "self", ".", "num_layers", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "pos_encoding", "=", "positional_encoding", "(", "config", ".", "n_positions", ",", "self", ".", "d_model_size", ")", "\n", "\n", "\n", "self", ".", "w", "=", "TFSharedEmbeddings", "(", "config", ".", "vocab_size", ",", "\n", "config", ".", "n_embd", ",", "\n", "initializer_range", "=", "config", ".", "initializer_range", ",", "\n", "name", "=", "\"w\"", ")", "\n", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "[", "TFEncoderLayer", "(", "config", ".", "n_embd", ",", "\n", "config", ".", "n_head", ",", "\n", "config", ".", "dff", ",", "\n", "config", ".", "resid_pdrop", ",", "\n", "config", ".", "layer_norm_epsilon", ",", "\n", "config", ".", "output_attentions", ",", "\n", "name", "=", "'h_._{}'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "]", "\n", "self", ".", "layernorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"layernorm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLMainLayer._resize_token_embeddings": [[195, 197], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLMainLayer._prune_heads": [[198, 203], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n                heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLMainLayer.call": [[204, 318], ["isinstance", "modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.reshape", "modeling_tf_ctrl.TFCTRLMainLayer.w", "tensorflow.math.sqrt", "tensorflow.gather", "modeling_tf_ctrl.TFCTRLMainLayer.dropout", "enumerate", "modeling_tf_ctrl.TFCTRLMainLayer.layernorm", "tensorflow.reshape", "isinstance", "tensorflow.tile", "tensorflow.cast", "tensorflow.reshape", "modeling_tf_ctrl.TFCTRLMainLayer.w", "tensorflow.math.sqrt", "tensorflow.linalg.band_part", "tensorflow.cast", "zip", "h", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "len", "modeling_tf_utils.shape_list", "tensorflow.range", "tensorflow.cast", "tensorflow.ones", "tuple.append", "len", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "past", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "past", "\n", "attention_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "past", "=", "inputs", ".", "get", "(", "'past'", ",", "past", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "[", "-", "1", ",", "input_shape", "[", "-", "1", "]", "]", ")", "\n", "\n", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "shape_list", "(", "past", "[", "0", "]", "[", "0", "]", ")", "[", "-", "2", "]", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "past_length", ",", "shape_list", "(", "input_ids", ")", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "position_ids", "=", "tf", ".", "tile", "(", "position_ids", ",", "[", "shape_list", "(", "input_ids", ")", "[", "0", "]", ",", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_layers", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "[", "-", "1", ",", "shape_list", "(", "token_type_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "w", "(", "token_type_ids", ",", "mode", "=", "'embedding'", ")", "\n", "token_type_embeds", "*=", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "cast", "(", "self", ".", "d_model_size", ",", "tf", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "[", "-", "1", ",", "shape_list", "(", "position_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "w", "(", "input_ids", ",", "mode", "=", "'embedding'", ")", "\n", "# x = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded", "\n", "seq_len", "=", "input_shape", "[", "-", "1", "]", "\n", "mask", "=", "1", "-", "tf", ".", "linalg", ".", "band_part", "(", "tf", ".", "ones", "(", "(", "seq_len", ",", "seq_len", ")", ")", ",", "-", "1", ",", "0", ")", "\n", "\n", "inputs_embeds", "*=", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "cast", "(", "self", ".", "d_model_size", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "pos_embeds", "=", "tf", ".", "gather", "(", "self", ".", "pos_encoding", ",", "position_ids", ")", "\n", "\n", "hidden_states", "=", "inputs_embeds", "+", "pos_embeds", "+", "token_type_embeds", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "[", "shape_list", "(", "hidden_states", ")", "[", "-", "1", "]", "]", "\n", "presents", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "for", "i", ",", "(", "h", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", ",", ")", "\n", "", "outputs", "=", "h", "(", "[", "hidden_states", ",", "mask", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "layernorm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "[", "-", "1", "]", "+", "shape_list", "(", "all_attentions", "[", "0", "]", ")", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "tf", ".", "reshape", "(", "t", ",", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLModel.__init__": [[410, 413], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_ctrl.TFCTRLMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFCTRLMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLModel.call": [[414, 417], ["modeling_tf_ctrl.TFCTRLModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLLMHead.__init__": [[420, 427], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLLMHead.build": [[428, 434], ["modeling_tf_ctrl.TFCTRLLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'bias'", ")", "\n", "super", "(", "TFCTRLLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLLMHead.call": [[435, 439], ["modeling_tf_ctrl.TFCTRLLMHead.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLLMHeadModel.__init__": [[473, 478], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_ctrl.TFCTRLMainLayer", "modeling_tf_ctrl.TFCTRLLMHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFCTRLMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n", "self", ".", "lm_head", "=", "TFCTRLLMHead", "(", "config", ",", "self", ".", "transformer", ".", "w", ",", "name", "=", "\"lm_head\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.TFCTRLLMHeadModel.call": [[479, 488], ["modeling_tf_ctrl.TFCTRLLMHeadModel.transformer", "modeling_tf_ctrl.TFCTRLLMHeadModel.lm_head"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm_logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.angle_defn": [[35, 38], ["numpy.power", "numpy.float32"], "function", ["None"], ["def", "angle_defn", "(", "pos", ",", "i", ",", "d_model_size", ")", ":", "\n", "    ", "angle_rates", "=", "1", "/", "np", ".", "power", "(", "10000", ",", "(", "2", "*", "(", "i", "//", "2", ")", ")", "/", "np", ".", "float32", "(", "d_model_size", ")", ")", "\n", "return", "pos", "*", "angle_rates", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.positional_encoding": [[39, 51], ["modeling_tf_ctrl.angle_defn", "numpy.sin", "numpy.cos", "tensorflow.cast", "numpy.concatenate", "numpy.arange", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.angle_defn"], ["", "def", "positional_encoding", "(", "position", ",", "d_model_size", ")", ":", "\n", "# create the sinusoidal pattern for the positional encoding", "\n", "    ", "angle_rads", "=", "angle_defn", "(", "np", ".", "arange", "(", "position", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "np", ".", "arange", "(", "d_model_size", ")", "[", "np", ".", "newaxis", ",", ":", "]", ",", "\n", "d_model_size", ")", "\n", "\n", "sines", "=", "np", ".", "sin", "(", "angle_rads", "[", ":", ",", "0", ":", ":", "2", "]", ")", "\n", "cosines", "=", "np", ".", "cos", "(", "angle_rads", "[", ":", ",", "1", ":", ":", "2", "]", ")", "\n", "\n", "# pos_encoding = tf.cast(np.concatenate([sines, cosines], axis=-1)[np.newaxis, ...], dtype=tf.float32)", "\n", "pos_encoding", "=", "tf", ".", "cast", "(", "np", ".", "concatenate", "(", "[", "sines", ",", "cosines", "]", ",", "axis", "=", "-", "1", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "pos_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.scaled_dot_product_attention": [[52, 75], ["tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.math.sqrt", "modeling_tf_utils.shape_list"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# calculate attention", "\n", "    ", "matmul_qk", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "\n", "\n", "dk", "=", "tf", ".", "cast", "(", "shape_list", "(", "k", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "scaled_attention_logits", "=", "matmul_qk", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "scaled_attention_logits", "+=", "(", "mask", "*", "-", "1e4", ")", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "        ", "scaled_attention_logits", "=", "scaled_attention_logits", "+", "attention_mask", "\n", "\n", "", "attention_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scaled_attention_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "        ", "attention_weights", "=", "attention_weights", "*", "head_mask", "\n", "\n", "", "output", "=", "tf", ".", "matmul", "(", "attention_weights", ",", "v", ")", "\n", "\n", "return", "output", ",", "attention_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_ctrl.point_wise_feed_forward_network": [[126, 131], ["tensorflow.keras.Sequential", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "function", ["None"], ["", "", "def", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ",", "name", "=", "\"\"", ")", ":", "\n", "    ", "return", "tf", ".", "keras", ".", "Sequential", "(", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dff", ",", "activation", "=", "'relu'", ",", "name", "=", "\"0\"", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "\"2\"", ")", "\n", "]", ",", "name", "=", "\"ffn\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertEmbeddings.__init__": [[148, 158], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertEmbeddings.forward": [[159, 175], ["input_ids.size", "modeling_bert.BertEmbeddings.word_embeddings", "modeling_bert.BertEmbeddings.position_embeddings", "modeling_bert.BertEmbeddings.token_type_embeddings", "modeling_bert.BertEmbeddings.LayerNorm", "modeling_bert.BertEmbeddings.dropout", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertSelfAttention.__init__": [[178, 195], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertSelfAttention.transpose_for_scores": [[196, 200], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertSelfAttention.forward": [[201, 236], ["modeling_bert.BertSelfAttention.query", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_bert.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_bert.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.query", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertSelfOutput.__init__": [[239, 244], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertSelfOutput.forward": [[245, 250], ["modeling_bert.BertSelfOutput.dense", "modeling_bert.BertSelfOutput.dropout", "modeling_bert.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertAttention.__init__": [[253, 258], ["torch.nn.Module.__init__", "modeling_bert.BertSelfAttention", "modeling_bert.BertSelfOutput", "set"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertAttention.prune_heads": [[259, 281], ["torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_bert.BertAttention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "\n", "# Prune linear layers", "\n", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertAttention.forward": [[282, 287], ["modeling_bert.BertAttention.self", "modeling_bert.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "input_tensor", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertIntermediate.__init__": [[290, 297], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertIntermediate.forward": [[298, 302], ["modeling_bert.BertIntermediate.dense", "modeling_bert.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertOutput.__init__": [[305, 310], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertOutput.forward": [[311, 316], ["modeling_bert.BertOutput.dense", "modeling_bert.BertOutput.dropout", "modeling_bert.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertLayer.__init__": [[319, 324], ["torch.nn.Module.__init__", "modeling_bert.BertAttention", "modeling_bert.BertIntermediate", "modeling_bert.BertOutput"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertLayer.forward": [[325, 332], ["modeling_bert.BertLayer.attention", "modeling_bert.BertLayer.intermediate", "modeling_bert.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "attention_outputs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertEncoder.__init__": [[335, 340], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "modeling_bert.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertEncoder.forward": [[341, 364], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertPooler.__init__": [[367, 371], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertPooler.forward": [[372, 379], ["modeling_bert.BertPooler.dense", "modeling_bert.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertPredictionHeadTransform.__init__": [[382, 390], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertPredictionHeadTransform.forward": [[391, 396], ["modeling_bert.BertPredictionHeadTransform.dense", "modeling_bert.BertPredictionHeadTransform.transform_act_fn", "modeling_bert.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertLMPredictionHead.__init__": [[399, 410], ["torch.nn.Module.__init__", "modeling_bert.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "vocab_size", ",", "\n", "bias", "=", "False", ")", "\n", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertLMPredictionHead.forward": [[411, 415], ["modeling_bert.BertLMPredictionHead.transform", "modeling_bert.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertOnlyMLMHead.__init__": [[418, 421], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertOnlyMLMHead.forward": [[422, 425], ["modeling_bert.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertOnlyNSPHead.__init__": [[428, 431], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertOnlyNSPHead.forward": [[432, 435], ["modeling_bert.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertPreTrainingHeads.__init__": [[438, 442], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertPreTrainingHeads.forward": [[443, 447], ["modeling_bert.BertPreTrainingHeads.predictions", "modeling_bert.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertPreTrainedModel._init_weights": [[458, 469], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertModel.__init__": [[565, 573], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertEmbeddings", "modeling_bert.BertEncoder", "modeling_bert.BertPooler", "modeling_bert.BertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertModel._resize_token_embeddings": [[574, 579], ["modeling_bert.BertModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "embeddings", ".", "word_embeddings", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertModel._prune_heads": [[580, 587], ["heads_to_prune.items", "modeling_bert.BertModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertModel.forward": [[588, 633], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling_bert.BertModel.embeddings", "modeling_bert.BertModel.encoder", "modeling_bert.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "torch.ones_like.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForPreTraining.__init__": [[675, 683], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertPreTrainingHeads", "modeling_bert.BertForPreTraining.init_weights", "modeling_bert.BertForPreTraining.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForPreTraining.tie_weights": [[684, 690], ["modeling_bert.BertForPreTraining._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForPreTraining.forward": [[691, 713], ["modeling_bert.BertForPreTraining.bert", "modeling_bert.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), prediction_scores, seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForMaskedLM.__init__": [[747, 755], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyMLMHead", "modeling_bert.BertForMaskedLM.init_weights", "modeling_bert.BertForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForMaskedLM.tie_weights": [[756, 762], ["modeling_bert.BertForMaskedLM._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForMaskedLM.forward": [[763, 782], ["modeling_bert.BertForMaskedLM.bert", "modeling_bert.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForNextSentencePrediction.__init__": [[816, 823], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyNSPHead", "modeling_bert.BertForNextSentencePrediction.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForNextSentencePrediction.forward": [[824, 844], ["modeling_bert.BertForNextSentencePrediction.bert", "modeling_bert.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "next_sentence_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (next_sentence_loss), seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForSequenceClassification.__init__": [[880, 889], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForSequenceClassification.forward": [[890, 917], ["modeling_bert.BertForSequenceClassification.bert", "modeling_bert.BertForSequenceClassification.dropout", "modeling_bert.BertForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForSequenceClassification.view", "labels.view", "modeling_bert.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForMultipleChoice.__init__": [[954, 962], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForMultipleChoice.forward": [[963, 992], ["input_ids.view.view.view", "modeling_bert.BertForMultipleChoice.bert", "modeling_bert.BertForMultipleChoice.dropout", "modeling_bert.BertForMultipleChoice.classifier", "modeling_bert.BertForMultipleChoice.view", "input_ids.view.view.size", "attention_mask.view", "token_type_ids.view", "position_ids.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "attention_mask.size", "token_type_ids.size", "position_ids.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForTokenClassification.__init__": [[1026, 1035], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForTokenClassification.forward": [[1036, 1064], ["modeling_bert.BertForTokenClassification.bert", "modeling_bert.BertForTokenClassification.dropout", "modeling_bert.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_bert.BertForTokenClassification.view", "labels.view", "modeling_bert.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForQuestionAnswering.__init__": [[1110, 1118], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Linear", "modeling_bert.BertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.BertForQuestionAnswering.forward": [[1119, 1154], ["modeling_bert.BertForQuestionAnswering.bert", "modeling_bert.BertForQuestionAnswering.qa_outputs", "modeling_bert.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.load_tf_weights_in_bert": [[55, 120], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "logger.info", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+_\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'_(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'kernel'", "or", "l", "[", "0", "]", "==", "'gamma'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_bias'", "or", "l", "[", "0", "]", "==", "'beta'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_weights'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'squad'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'classifier'", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "'_embeddings'", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "m_name", "==", "'kernel'", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.gelu": [[122, 129], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.gelu_new": [[130, 135], ["torch.tanh", "math.sqrt", "torch.pow"], "function", ["None"], ["", "def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.swish": [[136, 138], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings.__init__": [[90, 109], ["super().__init__", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertEmbeddings", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "hidden_size", "=", "config", ".", "hidden_size", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "\n", "self", ".", "position_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "hidden_size", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ",", "\n", "name", "=", "'position_embeddings'", ")", "\n", "self", ".", "token_type_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "\n", "config", ".", "hidden_size", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ",", "\n", "name", "=", "'token_type_embeddings'", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'LayerNorm'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings.build": [[110, 120], ["super().build", "tensorflow.name_scope", "modeling_tf_bert.TFBertEmbeddings.add_weight", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"word_embeddings\"", ")", ":", "\n", "# Create and initialize weights. The random normal initializer was chosen", "\n", "# arbitrarily, and works well.", "\n", "            ", "self", ".", "word_embeddings", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "[", "self", ".", "vocab_size", ",", "self", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ")", "\n", "", "super", "(", "TFBertEmbeddings", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings.call": [[121, 142], ["modeling_tf_bert.TFBertEmbeddings._embedding", "modeling_tf_bert.TFBertEmbeddings._linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._linear"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mode", "=", "\"embedding\"", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Get token embeddings of inputs.\n        Args:\n            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)\n            mode: string, a valid value is one of \"embedding\" and \"linear\".\n        Returns:\n            outputs: (1) If mode == \"embedding\", output embedding tensor, float32 with\n                shape [batch_size, length, embedding_size]; (2) mode == \"linear\", output\n                linear tensor, float32 with shape [batch_size, length, vocab_size].\n        Raises:\n            ValueError: if mode is not valid.\n        \n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "if", "mode", "==", "\"embedding\"", ":", "\n", "            ", "return", "self", ".", "_embedding", "(", "inputs", ",", "training", "=", "training", ")", "\n", "", "elif", "mode", "==", "\"linear\"", ":", "\n", "            ", "return", "self", ".", "_linear", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode {} is not valid.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._embedding": [[143, 161], ["tensorflow.gather", "modeling_tf_bert.TFBertEmbeddings.position_embeddings", "modeling_tf_bert.TFBertEmbeddings.token_type_embeddings", "modeling_tf_bert.TFBertEmbeddings.LayerNorm", "modeling_tf_bert.TFBertEmbeddings.dropout", "tensorflow.shape", "tensorflow.fill", "tensorflow.range", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "_embedding", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Applies embedding based on inputs tensor.\"\"\"", "\n", "input_ids", ",", "position_ids", ",", "token_type_ids", "=", "inputs", "\n", "\n", "seq_length", "=", "tf", ".", "shape", "(", "input_ids", ")", "[", "1", "]", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "seq_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "input_ids", ")", ",", "0", ")", "\n", "\n", "", "words_embeddings", "=", "tf", ".", "gather", "(", "self", ".", "word_embeddings", ",", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ",", "training", "=", "training", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEmbeddings._linear": [[162, 176], ["tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "_linear", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Computes logits by running inputs through a linear layer.\n            Args:\n                inputs: A float32 tensor with shape [batch_size, length, hidden_size]\n            Returns:\n                float32 tensor with shape [batch_size, length, vocab_size].\n        \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "length", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "word_embeddings", ",", "transpose_b", "=", "True", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "logits", ",", "[", "batch_size", ",", "length", ",", "self", ".", "vocab_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.__init__": [[179, 203], ["super().__init__", "int", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "ValueError", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertSelfAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "assert", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "==", "0", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "all_head_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'query'", ")", "\n", "self", ".", "key", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "all_head_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'key'", ")", "\n", "self", ".", "value", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "all_head_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'value'", ")", "\n", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores": [[204, 207], ["tensorflow.reshape", "tensorflow.transpose"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.call": [[208, 248], ["modeling_tf_bert.TFBertSelfAttention.query", "modeling_tf_bert.TFBertSelfAttention.key", "modeling_tf_bert.TFBertSelfAttention.value", "modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.softmax", "modeling_tf_bert.TFBertSelfAttention.dropout", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.shape", "tensorflow.math.sqrt", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.query", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "hidden_states", ")", "[", "0", "]", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ",", "batch_size", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ",", "batch_size", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ",", "batch_size", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "tf", ".", "matmul", "(", "query_layer", ",", "key_layer", ",", "transpose_b", "=", "True", ")", "# (batch size, num_heads, seq_len_q, seq_len_k)", "\n", "dk", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "key_layer", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "# scale attention_scores", "\n", "attention_scores", "=", "attention_scores", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in TFBertModel call() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "attention_scores", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "tf", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "tf", ".", "transpose", "(", "context_layer", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "context_layer", "=", "tf", ".", "reshape", "(", "context_layer", ",", "\n", "(", "batch_size", ",", "-", "1", ",", "self", ".", "all_head_size", ")", ")", "# (batch_size, seq_len_q, all_head_size)", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfOutput.__init__": [[251, 258], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertSelfOutput", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'dense'", ")", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'LayerNorm'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertSelfOutput.call": [[259, 266], ["modeling_tf_bert.TFBertSelfOutput.dense", "modeling_tf_bert.TFBertSelfOutput.dropout", "modeling_tf_bert.TFBertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "input_tensor", "=", "inputs", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertAttention.__init__": [[269, 273], ["super().__init__", "modeling_tf_bert.TFBertSelfAttention", "modeling_tf_bert.TFBertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "self_attention", "=", "TFBertSelfAttention", "(", "config", ",", "name", "=", "'self'", ")", "\n", "self", ".", "dense_output", "=", "TFBertSelfOutput", "(", "config", ",", "name", "=", "'output'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertAttention.prune_heads": [[274, 276], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertAttention.call": [[277, 284], ["modeling_tf_bert.TFBertAttention.self_attention", "modeling_tf_bert.TFBertAttention.dense_output"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "input_tensor", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "self_outputs", "=", "self", ".", "self_attention", "(", "[", "input_tensor", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "attention_output", "=", "self", ".", "dense_output", "(", "[", "self_outputs", "[", "0", "]", ",", "input_tensor", "]", ",", "training", "=", "training", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertIntermediate.__init__": [[287, 296], ["super().__init__", "tensorflow.keras.layers.Dense", "isinstance", "modeling_tf_utils.get_initializer", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertIntermediate", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "intermediate_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'dense'", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertIntermediate.call": [[297, 301], ["modeling_tf_bert.TFBertIntermediate.dense", "modeling_tf_bert.TFBertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertOutput.__init__": [[304, 311], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertOutput", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'dense'", ")", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'LayerNorm'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertOutput.call": [[312, 319], ["modeling_tf_bert.TFBertOutput.dense", "modeling_tf_bert.TFBertOutput.dropout", "modeling_tf_bert.TFBertOutput.LayerNorm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "input_tensor", "=", "inputs", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertLayer.__init__": [[322, 327], ["super().__init__", "modeling_tf_bert.TFBertAttention", "modeling_tf_bert.TFBertIntermediate", "modeling_tf_bert.TFBertOutput"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "attention", "=", "TFBertAttention", "(", "config", ",", "name", "=", "'attention'", ")", "\n", "self", ".", "intermediate", "=", "TFBertIntermediate", "(", "config", ",", "name", "=", "'intermediate'", ")", "\n", "self", ".", "bert_output", "=", "TFBertOutput", "(", "config", ",", "name", "=", "'output'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertLayer.call": [[328, 337], ["modeling_tf_bert.TFBertLayer.attention", "modeling_tf_bert.TFBertLayer.intermediate", "modeling_tf_bert.TFBertLayer.bert_output"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "attention_outputs", "=", "self", ".", "attention", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "bert_output", "(", "[", "intermediate_output", ",", "attention_output", "]", ",", "training", "=", "training", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEncoder.__init__": [[340, 345], ["super().__init__", "modeling_tf_bert.TFBertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertEncoder", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "[", "TFBertLayer", "(", "config", ",", "name", "=", "'layer_._{}'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertEncoder.call": [[346, 371], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertPooler.__init__": [[374, 380], ["super().__init__", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertPooler", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "activation", "=", "'tanh'", ",", "\n", "name", "=", "'dense'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertPooler.call": [[381, 387], ["modeling_tf_bert.TFBertPooler.dense"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertPredictionHeadTransform.__init__": [[390, 400], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "isinstance", "modeling_tf_utils.get_initializer", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'dense'", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'LayerNorm'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertPredictionHeadTransform.call": [[401, 406], ["modeling_tf_bert.TFBertPredictionHeadTransform.dense", "modeling_tf_bert.TFBertPredictionHeadTransform.transform_act_fn", "modeling_tf_bert.TFBertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertLMPredictionHead.__init__": [[409, 417], ["super().__init__", "modeling_tf_bert.TFBertPredictionHeadTransform"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "transform", "=", "TFBertPredictionHeadTransform", "(", "config", ",", "name", "=", "'transform'", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertLMPredictionHead.build": [[418, 424], ["modeling_tf_bert.TFBertLMPredictionHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'bias'", ")", "\n", "super", "(", "TFBertLMPredictionHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertLMPredictionHead.call": [[425, 430], ["modeling_tf_bert.TFBertLMPredictionHead.transform", "modeling_tf_bert.TFBertLMPredictionHead.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertMLMHead.__init__": [[433, 436], ["super().__init__", "modeling_tf_bert.TFBertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertMLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "predictions", "=", "TFBertLMPredictionHead", "(", "config", ",", "input_embeddings", ",", "name", "=", "'predictions'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertMLMHead.call": [[437, 440], ["modeling_tf_bert.TFBertMLMHead.predictions"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertNSPHead.__init__": [[443, 448], ["super().__init__", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertNSPHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "seq_relationship", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "2", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'seq_relationship'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertNSPHead.call": [[449, 452], ["modeling_tf_bert.TFBertNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertMainLayer.__init__": [[455, 462], ["super().__init__", "modeling_tf_bert.TFBertEmbeddings", "modeling_tf_bert.TFBertEncoder", "modeling_tf_bert.TFBertPooler"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "num_hidden_layers", "\n", "\n", "self", ".", "embeddings", "=", "TFBertEmbeddings", "(", "config", ",", "name", "=", "'embeddings'", ")", "\n", "self", ".", "encoder", "=", "TFBertEncoder", "(", "config", ",", "name", "=", "'encoder'", ")", "\n", "self", ".", "pooler", "=", "TFBertPooler", "(", "config", ",", "name", "=", "'pooler'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertMainLayer._resize_token_embeddings": [[463, 465], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertMainLayer._prune_heads": [[466, 472], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertMainLayer.call": [[473, 531], ["isinstance", "tensorflow.cast", "modeling_tf_bert.TFBertMainLayer.embeddings", "modeling_tf_bert.TFBertMainLayer.encoder", "modeling_tf_bert.TFBertMainLayer.pooler", "isinstance", "tensorflow.fill", "tensorflow.fill", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "tensorflow.shape", "tensorflow.shape", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "input_ids", ")", ",", "1", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "input_ids", ")", ",", "0", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "extended_attention_mask", "=", "tf", ".", "cast", "(", "extended_attention_mask", ",", "tf", ".", "float32", ")", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "not", "head_mask", "is", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "[", "input_ids", ",", "position_ids", ",", "token_type_ids", "]", ",", "training", "=", "training", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "[", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertModel.__init__": [[655, 658], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertModel.call": [[659, 662], ["modeling_tf_bert.TFBertModel.bert"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForPreTraining.__init__": [[694, 700], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "modeling_tf_bert.TFBertNSPHead", "modeling_tf_bert.TFBertMLMHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "self", ".", "nsp", "=", "TFBertNSPHead", "(", "config", ",", "name", "=", "'nsp___cls'", ")", "\n", "self", ".", "mlm", "=", "TFBertMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ",", "name", "=", "'mlm___cls'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForPreTraining.call": [[701, 711], ["modeling_tf_bert.TFBertForPreTraining.bert", "modeling_tf_bert.TFBertForPreTraining.mlm", "modeling_tf_bert.TFBertForPreTraining.nsp", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", "=", "self", ".", "mlm", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "\n", "seq_relationship_score", "=", "self", ".", "nsp", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# prediction_scores, seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForMaskedLM.__init__": [[740, 745], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "modeling_tf_bert.TFBertMLMHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "self", ".", "mlm", "=", "TFBertMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ",", "name", "=", "'mlm___cls'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForMaskedLM.call": [[746, 755], ["modeling_tf_bert.TFBertForMaskedLM.bert", "modeling_tf_bert.TFBertForMaskedLM.mlm", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "mlm", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForNextSentencePrediction.__init__": [[784, 789], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "modeling_tf_bert.TFBertNSPHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "self", ".", "nsp", "=", "TFBertNSPHead", "(", "config", ",", "name", "=", "'nsp___cls'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForNextSentencePrediction.call": [[790, 799], ["modeling_tf_bert.TFBertForNextSentencePrediction.bert", "modeling_tf_bert.TFBertForNextSentencePrediction.nsp"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "seq_relationship_score", "=", "self", ".", "nsp", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForSequenceClassification.__init__": [[829, 838], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'classifier'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForSequenceClassification.call": [[839, 850], ["modeling_tf_bert.TFBertForSequenceClassification.bert", "modeling_tf_bert.TFBertForSequenceClassification.dropout", "modeling_tf_bert.TFBertForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForMultipleChoice.__init__": [[882, 890], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'classifier'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForMultipleChoice.call": [[891, 930], ["isinstance", "tensorflow.reshape", "modeling_tf_bert.TFBertForMultipleChoice.bert", "modeling_tf_bert.TFBertForMultipleChoice.dropout", "modeling_tf_bert.TFBertForMultipleChoice.classifier", "tensorflow.reshape", "isinstance", "tensorflow.shape", "tensorflow.shape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "num_choices", "=", "tf", ".", "shape", "(", "input_ids", ")", "[", "1", "]", "\n", "seq_length", "=", "tf", ".", "shape", "(", "input_ids", ")", "[", "2", "]", "\n", "\n", "flat_input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "\n", "flat_attention_mask", "=", "tf", ".", "reshape", "(", "attention_mask", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "flat_inputs", "=", "[", "flat_input_ids", ",", "flat_attention_mask", ",", "flat_token_type_ids", ",", "flat_position_ids", ",", "head_mask", "]", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "flat_inputs", ",", "training", "=", "training", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "training", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "tf", ".", "reshape", "(", "logits", ",", "(", "-", "1", ",", "num_choices", ")", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForTokenClassification.__init__": [[960, 969], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'classifier'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForTokenClassification.call": [[970, 981], ["modeling_tf_bert.TFBertForTokenClassification.bert", "modeling_tf_bert.TFBertForTokenClassification.dropout", "modeling_tf_bert.TFBertForTokenClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "'training'", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForQuestionAnswering.__init__": [[1013, 1021], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "'bert'", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'qa_outputs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.TFBertForQuestionAnswering.call": [[1022, 1035], ["modeling_tf_bert.TFBertForQuestionAnswering.bert", "modeling_tf_bert.TFBertForQuestionAnswering.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "return", "outputs", "# start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.gelu": [[54, 63], ["tensorflow.math.erf", "tensorflow.math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Gaussian Error Linear Unit.\n    Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "math", ".", "erf", "(", "x", "/", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.gelu_new": [[64, 76], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["", "def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "\n", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_bert.swish": [[77, 79], ["tensorflow.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "tf", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFMultiHeadAttention.__init__": [[100, 114], ["super().__init__", "next", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "set", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "n_heads", ",", "dim", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMultiHeadAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "layer_id", "=", "next", "(", "TFMultiHeadAttention", ".", "NEW_ID", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "'q_lin'", ")", "\n", "self", ".", "k_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "'k_lin'", ")", "\n", "self", ".", "v_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "'v_lin'", ")", "\n", "self", ".", "out_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "'out_lin'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_dropout", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFMultiHeadAttention.prune_heads": [[115, 117], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFMultiHeadAttention.call": [[118, 182], ["modeling_tf_utils.shape_list", "modeling_tf_xlm.TFMultiHeadAttention.call.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "input", ",", "mask", ",", "kv", ",", "cache", ",", "head_mask", "=", "inputs", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "bs", ",", "qlen", ",", "dim", "=", "shape_list", "(", "input", ")", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "qlen", "if", "cache", "is", "None", "else", "cache", "[", "'slen'", "]", "+", "qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "shape_list", "(", "kv", ")", "[", "1", "]", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "", "n_heads", "=", "self", ".", "n_heads", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "n_heads", "\n", "mask_reshape", "=", "(", "bs", ",", "1", ",", "qlen", ",", "klen", ")", "if", "len", "(", "shape_list", "(", "mask", ")", ")", "==", "3", "else", "(", "bs", ",", "1", ",", "1", ",", "klen", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "x", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ")", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "cache", "is", "None", "or", "self", ".", "layer_id", "not", "in", "cache", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "layer_id", "in", "cache", ":", "\n", "                ", "if", "kv", "is", "None", ":", "\n", "                    ", "k_", ",", "v_", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "k", "=", "tf", ".", "concat", "(", "[", "k_", ",", "k", "]", ",", "axis", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "tf", ".", "concat", "(", "[", "v_", ",", "v", "]", ",", "axis", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                    ", "k", ",", "v", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "", "", "cache", "[", "self", ".", "layer_id", "]", "=", "(", "k", ",", "v", ")", "\n", "\n", "", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "scores", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "# (bs, n_heads, qlen, klen)", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "mask_reshape", ")", "# (bs, n_heads, qlen, klen)", "\n", "# scores.masked_fill_(mask, -float('inf'))                            # (bs, n_heads, qlen, klen)", "\n", "scores", "=", "scores", "-", "1e30", "*", "(", "1.0", "-", "mask", ")", "\n", "\n", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scores", ",", "axis", "=", "-", "1", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ",", "training", "=", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "tf", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "outputs", "=", "(", "self", ".", "out_lin", "(", "context", ")", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFTransformerFFN.__init__": [[186, 192], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "dim_hidden", ",", "out_dim", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransformerFFN", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "lin1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim_hidden", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "'lin1'", ")", "\n", "self", ".", "lin2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "out_dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "'lin2'", ")", "\n", "self", ".", "act", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "if", "config", ".", "gelu_activation", "else", "tf", ".", "keras", ".", "activations", ".", "relu", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFTransformerFFN.call": [[193, 199], ["modeling_tf_xlm.TFTransformerFFN.lin1", "modeling_tf_xlm.TFTransformerFFN.act", "modeling_tf_xlm.TFTransformerFFN.lin2", "modeling_tf_xlm.TFTransformerFFN.dropout"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMMainLayer.__init__": [[202, 277], ["super().__init__", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Embedding", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.LayerNormalization", "range", "hasattr", "NotImplementedError", "tensorflow.keras.layers.Embedding", "modeling_tf_xlm.TFXLMMainLayer.attentions.append", "modeling_tf_xlm.TFXLMMainLayer.layer_norm1.append", "modeling_tf_xlm.TFXLMMainLayer.ffns.append", "modeling_tf_xlm.TFXLMMainLayer.layer_norm2.append", "config.pruned_heads.copy().items", "modeling_tf_utils.get_initializer", "modeling_tf_xlm.TFMultiHeadAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_xlm.TFTransformerFFN", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_utils.get_initializer", "config.pruned_heads.copy", "modeling_tf_xlm.TFXLMMainLayer.prune_heads", "int", "list", "int", "map"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "# encoder / decoder, output layer", "\n", "self", ".", "is_encoder", "=", "config", ".", "is_encoder", "\n", "self", ".", "is_decoder", "=", "not", "config", ".", "is_encoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Currently XLM can only be used as an encoder\"", ")", "\n", "# self.with_output = with_output", "\n", "", "self", ".", "causal", "=", "config", ".", "causal", "\n", "\n", "# dictionary / languages", "\n", "self", ".", "n_langs", "=", "config", ".", "n_langs", "\n", "self", ".", "use_lang_emb", "=", "config", ".", "use_lang_emb", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "eos_index", "=", "config", ".", "eos_index", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "# self.dico = dico", "\n", "# self.id2lang = config.id2lang", "\n", "# self.lang2id = config.lang2id", "\n", "# assert len(self.dico) == self.n_words", "\n", "# assert len(self.id2lang) == len(self.lang2id) == self.n_langs", "\n", "\n", "# model parameters", "\n", "self", ".", "dim", "=", "config", ".", "emb_dim", "# 512 by default", "\n", "self", ".", "hidden_dim", "=", "self", ".", "dim", "*", "4", "# 2048 by default", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "# 8 by default", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", ",", "'transformer dim must be a multiple of n_heads'", "\n", "\n", "# embeddings", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "attention_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_dropout", ")", "\n", "\n", "self", ".", "position_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "\n", "self", ".", "dim", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "embed_init_std", ")", ",", "\n", "name", "=", "'position_embeddings'", ")", "\n", "if", "config", ".", "sinusoidal_embeddings", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# create_sinusoidal_embeddings(config.max_position_embeddings, self.dim, out=self.position_embeddings.weight)", "\n", "", "if", "config", ".", "n_langs", ">", "1", "and", "config", ".", "use_lang_emb", ":", "\n", "            ", "self", ".", "lang_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "self", ".", "n_langs", ",", "\n", "self", ".", "dim", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "embed_init_std", ")", ",", "\n", "name", "=", "'lang_embeddings'", ")", "\n", "", "self", ".", "embeddings", "=", "TFSharedEmbeddings", "(", "self", ".", "n_words", ",", "self", ".", "dim", ",", "initializer_range", "=", "config", ".", "embed_init_std", ",", "name", "=", "'embeddings'", ")", "# padding_idx=self.pad_index)", "\n", "self", ".", "layer_norm_emb", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'layer_norm_emb'", ")", "\n", "\n", "# transformer layers", "\n", "self", ".", "attentions", "=", "[", "]", "\n", "self", ".", "layer_norm1", "=", "[", "]", "\n", "self", ".", "ffns", "=", "[", "]", "\n", "self", ".", "layer_norm2", "=", "[", "]", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15 = []", "\n", "#     self.encoder_attn = []", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "self", ".", "attentions", ".", "append", "(", "TFMultiHeadAttention", "(", "self", ".", "n_heads", ",", "self", ".", "dim", ",", "config", "=", "config", ",", "name", "=", "'attentions_._{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "self", ".", "layer_norm1", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'layer_norm1_._{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15.append(nn.LayerNorm(self.dim, eps=config.layer_norm_eps))", "\n", "#     self.encoder_attn.append(MultiHeadAttention(self.n_heads, self.dim, dropout=self.attention_dropout))", "\n", "self", ".", "ffns", ".", "append", "(", "TFTransformerFFN", "(", "self", ".", "dim", ",", "self", ".", "hidden_dim", ",", "self", ".", "dim", ",", "config", "=", "config", ",", "name", "=", "'ffns_._{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "self", ".", "layer_norm2", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'layer_norm2_._{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "config", ",", "\"pruned_heads\"", ")", ":", "\n", "            ", "pruned_heads", "=", "config", ".", "pruned_heads", ".", "copy", "(", ")", ".", "items", "(", ")", "\n", "config", ".", "pruned_heads", "=", "{", "}", "\n", "for", "layer", ",", "heads", "in", "pruned_heads", ":", "\n", "                ", "if", "self", ".", "attentions", "[", "int", "(", "layer", ")", "]", ".", "n_heads", "==", "config", ".", "n_heads", ":", "\n", "                    ", "self", ".", "prune_heads", "(", "{", "int", "(", "layer", ")", ":", "list", "(", "map", "(", "int", ",", "heads", ")", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMMainLayer._resize_token_embeddings": [[279, 281], ["None"], "methods", ["None"], ["", "", "", "", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMMainLayer._prune_heads": [[282, 288], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMMainLayer.call": [[289, 422], ["isinstance", "modeling_tf_utils.shape_list", "modeling_tf_xlm.get_masks", "modeling_tf_xlm.TFXLMMainLayer.embeddings", "modeling_tf_xlm.TFXLMMainLayer.layer_norm_emb", "modeling_tf_xlm.TFXLMMainLayer.dropout", "range", "isinstance", "tensorflow.reduce_sum", "tensorflow.expand_dims", "modeling_tf_xlm.TFXLMMainLayer.position_embeddings", "modeling_tf_xlm.TFXLMMainLayer.dropout", "modeling_tf_xlm.TFXLMMainLayer.size", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "tensorflow.cast", "modeling_tf_utils.shape_list", "tensorflow.range", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_xlm.TFXLMMainLayer.lang_embeddings", "modeling_tf_xlm.TFXLMMainLayer.embeddings", "len", "len", "len", "len", "len", "len", "len", "len", "tensorflow.not_equal"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.get_masks", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "lengths", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "training", "=", "False", ")", ":", "# removed: src_enc=None, src_len=None", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "langs", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "langs", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "lengths", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "lengths", "\n", "cache", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "cache", "\n", "head_mask", "=", "inputs", "[", "7", "]", "if", "len", "(", "inputs", ")", ">", "7", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "8", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "langs", "=", "inputs", ".", "get", "(", "'langs'", ",", "langs", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "lengths", "=", "inputs", ".", "get", "(", "'lengths'", ",", "lengths", ")", "\n", "cache", "=", "inputs", ".", "get", "(", "'cache'", ",", "cache", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "8", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "lengths", "is", "None", ":", "\n", "            ", "lengths", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "input_ids", ",", "self", ".", "pad_index", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "axis", "=", "1", ")", "\n", "# mask = input_ids != self.pad_index", "\n", "\n", "# check inputs", "\n", "", "bs", ",", "slen", "=", "shape_list", "(", "input_ids", ")", "\n", "assert", "shape_list", "(", "lengths", ")", "[", "0", "]", "==", "bs", "\n", "# assert lengths.max().item() <= slen", "\n", "# input_ids = input_ids.transpose(0, 1)  # batch size as dimension 0", "\n", "# assert (src_enc is None) == (src_len is None)", "\n", "# if src_enc is not None:", "\n", "#     assert self.is_decoder", "\n", "#     assert src_enc.size(0) == bs", "\n", "\n", "# generate masks", "\n", "mask", ",", "attn_mask", "=", "get_masks", "(", "slen", ",", "lengths", ",", "self", ".", "causal", ",", "padding_mask", "=", "attention_mask", ")", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     src_mask = torch.arange(src_len.max(), dtype=torch.long, device=lengths.device) < src_len[:, None]", "\n", "\n", "# position_ids", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "slen", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "assert", "shape_list", "(", "position_ids", ")", "==", "[", "bs", ",", "slen", "]", "# (slen, bs)", "\n", "# position_ids = position_ids.transpose(0, 1)", "\n", "\n", "# langs", "\n", "", "if", "langs", "is", "not", "None", ":", "\n", "            ", "assert", "shape_list", "(", "langs", ")", "==", "[", "bs", ",", "slen", "]", "# (slen, bs)", "\n", "# langs = langs.transpose(0, 1)", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x qlen x klen]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layers", "\n", "\n", "# do not recompute cached elements", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "_slen", "=", "slen", "-", "cache", "[", "'slen'", "]", "\n", "input_ids", "=", "input_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "position_ids", "=", "position_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "if", "langs", "is", "not", "None", ":", "\n", "                ", "langs", "=", "langs", "[", ":", ",", "-", "_slen", ":", "]", "\n", "", "mask", "=", "mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "\n", "# embeddings", "\n", "", "tensor", "=", "self", ".", "embeddings", "(", "input_ids", ")", "\n", "tensor", "=", "tensor", "+", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "if", "langs", "is", "not", "None", "and", "self", ".", "use_lang_emb", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "lang_embeddings", "(", "langs", ")", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "embeddings", "(", "token_type_ids", ")", "\n", "", "tensor", "=", "self", ".", "layer_norm_emb", "(", "tensor", ")", "\n", "tensor", "=", "self", ".", "dropout", "(", "tensor", ",", "training", "=", "training", ")", "\n", "tensor", "=", "tensor", "*", "mask", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "\n", "# transformer layers", "\n", "hidden_states", "=", "(", ")", "\n", "attentions", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# self attention", "\n", "", "attn_outputs", "=", "self", ".", "attentions", "[", "i", "]", "(", "[", "tensor", ",", "attn_mask", ",", "None", ",", "cache", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "attn", "=", "attn_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", "=", "attentions", "+", "(", "attn_outputs", "[", "1", "]", ",", ")", "\n", "", "attn", "=", "self", ".", "dropout", "(", "attn", ",", "training", "=", "training", ")", "\n", "tensor", "=", "tensor", "+", "attn", "\n", "tensor", "=", "self", ".", "layer_norm1", "[", "i", "]", "(", "tensor", ")", "\n", "\n", "# encoder attention (for decoder only)", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     attn = self.encoder_attn[i](tensor, src_mask, kv=src_enc, cache=cache)", "\n", "#     attn = F.dropout(attn, p=self.dropout, training=self.training)", "\n", "#     tensor = tensor + attn", "\n", "#     tensor = self.layer_norm15[i](tensor)", "\n", "\n", "# FFN", "\n", "tensor", "=", "tensor", "+", "self", ".", "ffns", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "=", "self", ".", "layer_norm2", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "=", "tensor", "*", "mask", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "\n", "# Add last hidden state", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# update cache length", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "cache", "[", "'slen'", "]", "+=", "tensor", ".", "size", "(", "1", ")", "\n", "\n", "# move back sequence length to dimension 0", "\n", "# tensor = tensor.transpose(0, 1)", "\n", "\n", "", "outputs", "=", "(", "tensor", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMPreTrainedModel.dummy_inputs": [[432, 442], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "# Sometimes XLM has language embeddings so don't forget to build them as well if needed", "\n", "        ", "inputs_list", "=", "tf", ".", "constant", "(", "[", "[", "7", ",", "6", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "2", ",", "3", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "4", ",", "5", "]", "]", ")", "\n", "attns_list", "=", "tf", ".", "constant", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "if", "self", ".", "config", ".", "use_lang_emb", "and", "self", ".", "config", ".", "n_langs", ">", "1", ":", "\n", "            ", "langs_list", "=", "tf", ".", "constant", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "langs_list", "=", "None", "\n", "", "return", "[", "inputs_list", ",", "attns_list", ",", "langs_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMModel.__init__": [[558, 561], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMModel.call": [[562, 565], ["modeling_tf_xlm.TFXLMModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMPredLayer.__init__": [[572, 581], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMPredLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "asm", "=", "config", ".", "asm", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "if", "config", ".", "asm", "is", "False", ":", "\n", "            ", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# self.proj = nn.AdaptiveLogSoftmaxWithLoss(", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMPredLayer.build": [[589, 596], ["modeling_tf_xlm.TFXLMPredLayer.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "# The output weights are the same as the input embeddings, but there is an output-only bias for each token.", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_words", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'bias'", ")", "\n", "super", "(", "TFXLMPredLayer", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMPredLayer.call": [[597, 601], ["modeling_tf_xlm.TFXLMPredLayer.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMWithLMHeadModel.__init__": [[631, 635], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer", "modeling_tf_xlm.TFXLMPredLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMWithLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "pred_layer", "=", "TFXLMPredLayer", "(", "config", ",", "self", ".", "transformer", ".", "embeddings", ",", "name", "=", "'pred_layer_._proj'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMWithLMHeadModel.call": [[637, 645], ["modeling_tf_xlm.TFXLMWithLMHeadModel.transformer", "modeling_tf_xlm.TFXLMWithLMHeadModel.pred_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "outputs", "=", "self", ".", "pred_layer", "(", "output", ")", "\n", "outputs", "=", "(", "outputs", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMForSequenceClassification.__init__": [[676, 682], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer", "modeling_tf_utils.TFSequenceSummary"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "sequence_summary", "=", "TFSequenceSummary", "(", "config", ",", "initializer_range", "=", "config", ".", "init_std", ",", "name", "=", "'sequence_summary'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMForSequenceClassification.call": [[683, 691], ["modeling_tf_xlm.TFXLMForSequenceClassification.transformer", "modeling_tf_xlm.TFXLMForSequenceClassification.sequence_summary"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.__init__": [[723, 729], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "\n", "name", "=", "'qa_outputs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.call": [[730, 743], ["modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.transformer", "modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.create_sinusoidal_embeddings": [[47, 54], ["numpy.array", "tensorflow.constant", "tensorflow.constant", "numpy.sin", "numpy.cos", "range", "numpy.power", "range"], "function", ["None"], ["def", "create_sinusoidal_embeddings", "(", "n_pos", ",", "dim", ",", "out", ")", ":", "\n", "    ", "position_enc", "=", "np", ".", "array", "(", "[", "\n", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "dim", ")", "for", "j", "in", "range", "(", "dim", ")", "]", "\n", "for", "pos", "in", "range", "(", "n_pos", ")", "\n", "]", ")", "\n", "out", "[", ":", ",", "0", ":", ":", "2", "]", "=", "tf", ".", "constant", "(", "np", ".", "sin", "(", "position_enc", "[", ":", ",", "0", ":", ":", "2", "]", ")", ")", "\n", "out", "[", ":", ",", "1", ":", ":", "2", "]", "=", "tf", ".", "constant", "(", "np", ".", "cos", "(", "position_enc", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.gelu": [[56, 65], ["tensorflow.math.erf", "tensorflow.math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Gaussian Error Linear Unit.\n    Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "math", ".", "erf", "(", "x", "/", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlm.get_masks": [[67, 94], ["tensorflow.cast", "tensorflow.cast", "modeling_tf_utils.shape_list", "tensorflow.range", "tensorflow.math.less", "tensorflow.less_equal", "modeling_tf_utils.shape_list", "tensorflow.tile", "modeling_tf_utils.shape_list"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "get_masks", "(", "slen", ",", "lengths", ",", "causal", ",", "padding_mask", "=", "None", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "    ", "\"\"\"\n    Generate hidden states mask, and optionally an attention mask.\n    \"\"\"", "\n", "bs", "=", "shape_list", "(", "lengths", ")", "[", "0", "]", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "padding_mask", "\n", "", "else", ":", "\n", "# assert lengths.max().item() <= slen", "\n", "        ", "alen", "=", "tf", ".", "range", "(", "slen", ")", "\n", "mask", "=", "tf", ".", "math", ".", "less", "(", "alen", ",", "lengths", "[", ":", ",", "tf", ".", "newaxis", "]", ")", "\n", "\n", "# attention mask is the same as mask, or triangular inferior attention (causal)", "\n", "", "if", "causal", ":", "\n", "        ", "attn_mask", "=", "tf", ".", "less_equal", "(", "tf", ".", "tile", "(", "alen", "[", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", ",", "(", "bs", ",", "slen", ",", "1", ")", ")", ",", "\n", "alen", "[", "tf", ".", "newaxis", ",", ":", ",", "tf", ".", "newaxis", "]", ")", "\n", "", "else", ":", "\n", "        ", "attn_mask", "=", "mask", "\n", "\n", "# sanity check", "\n", "", "assert", "shape_list", "(", "mask", ")", "==", "[", "bs", ",", "slen", "]", "\n", "assert", "causal", "is", "False", "or", "shape_list", "(", "attn_mask", ")", "==", "[", "bs", ",", "slen", ",", "slen", "]", "\n", "\n", "mask", "=", "tf", ".", "cast", "(", "mask", ",", "dtype", "=", "dtype", ")", "\n", "attn_mask", "=", "tf", ".", "cast", "(", "attn_mask", ",", "dtype", "=", "dtype", ")", "\n", "\n", "return", "mask", ",", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.__main__.main": [[2, 127], ["print", "len", "len", "len", "print", "sys.argv.pop", "sys.argv.pop", "sys.argv.pop", "convert_tf_checkpoint_to_pytorch", "print", "print", "convert_openai_checkpoint_to_pytorch", "len", "len", "len", "print", "convert_transfo_xl_checkpoint_to_pytorch", "print", "len", "len", "sys.argv[].lower", "len", "print", "convert_gpt2_checkpoint_to_pytorch", "print", "len", "len", "len", "print", "convert_xlnet_checkpoint_to_pytorch", "print", "len", "len", "len", "len", "print", "convert_xlm_checkpoint_to_pytorch"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_bert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_openai_original_tf_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_transfo_xl_original_tf_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_gpt2_original_tf_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_xlnet_original_tf_checkpoint_to_pytorch.convert_xlnet_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_xlm_original_pytorch_checkpoint_to_pytorch.convert_xlm_checkpoint_to_pytorch"], ["def", "main", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "if", "(", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "6", ")", "or", "sys", ".", "argv", "[", "1", "]", "not", "in", "[", "\"bert\"", ",", "\"gpt\"", ",", "\"transfo_xl\"", ",", "\"gpt2\"", ",", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "        ", "print", "(", "\n", "\"This command line utility let you convert original (author released) model checkpoint to pytorch.\\n\"", "\n", "\"It should be used as one of: \\n\"", "\n", "\">> transformers bert TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT, \\n\"", "\n", "\">> transformers gpt OPENAI_GPT_CHECKPOINT_FOLDER_PATH PYTORCH_DUMP_OUTPUT [OPENAI_GPT_CONFIG], \\n\"", "\n", "\">> transformers transfo_xl TF_CHECKPOINT_OR_DATASET PYTORCH_DUMP_OUTPUT [TF_CONFIG] or \\n\"", "\n", "\">> transformers gpt2 TF_CHECKPOINT PYTORCH_DUMP_OUTPUT [GPT2_CONFIG] or \\n\"", "\n", "\">> transformers xlnet TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT [FINETUNING_TASK_NAME] or \\n\"", "\n", "\">> transformers xlm XLM_CHECKPOINT_PATH PYTORCH_DUMP_OUTPUT\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "sys", ".", "argv", "[", "1", "]", "==", "\"bert\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_bert_original_tf_checkpoint_to_pytorch", "import", "convert_tf_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "!=", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `transformers bert TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT`\"", ")", "\n", "", "else", ":", "\n", "                ", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CONFIG", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CHECKPOINT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "convert_tf_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"gpt\"", ":", "\n", "            ", "from", ".", "convert_openai_original_tf_checkpoint_to_pytorch", "import", "convert_openai_checkpoint_to_pytorch", "\n", "if", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `transformers gpt OPENAI_GPT_CHECKPOINT_FOLDER_PATH PYTORCH_DUMP_OUTPUT [OPENAI_GPT_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "                ", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                    ", "OPENAI_GPT_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "OPENAI_GPT_CONFIG", "=", "\"\"", "\n", "", "convert_openai_checkpoint_to_pytorch", "(", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", ",", "\n", "OPENAI_GPT_CONFIG", ",", "\n", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"transfo_xl\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_transfo_xl_original_tf_checkpoint_to_pytorch", "import", "convert_transfo_xl_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `transformers transfo_xl TF_CHECKPOINT/TF_DATASET_FILE PYTORCH_DUMP_OUTPUT [TF_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "                ", "if", "'ckpt'", "in", "sys", ".", "argv", "[", "2", "]", ".", "lower", "(", ")", ":", "\n", "                    ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_DATASET_FILE", "=", "\"\"", "\n", "", "else", ":", "\n", "                    ", "TF_DATASET_FILE", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_CHECKPOINT", "=", "\"\"", "\n", "", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                    ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_transfo_xl_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ",", "TF_DATASET_FILE", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"gpt2\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_gpt2_original_tf_checkpoint_to_pytorch", "import", "convert_gpt2_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `transformers gpt2 TF_CHECKPOINT PYTORCH_DUMP_OUTPUT [TF_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "                ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                    ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_gpt2_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"xlnet\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_xlnet_original_tf_checkpoint_to_pytorch", "import", "convert_xlnet_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "<", "5", "or", "len", "(", "sys", ".", "argv", ")", ">", "6", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `transformers xlnet TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT [FINETUNING_TASK_NAME]`\"", ")", "\n", "", "else", ":", "\n", "                ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_CONFIG", "=", "sys", ".", "argv", "[", "3", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "4", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "6", ":", "\n", "                    ", "FINETUNING_TASK", "=", "sys", ".", "argv", "[", "5", "]", "\n", "", "else", ":", "\n", "                    ", "FINETUNING_TASK", "=", "None", "\n", "\n", "", "convert_xlnet_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "\n", "TF_CONFIG", ",", "\n", "PYTORCH_DUMP_OUTPUT", ",", "\n", "FINETUNING_TASK", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"xlm\"", ":", "\n", "            ", "from", ".", "convert_xlm_original_pytorch_checkpoint_to_pytorch", "import", "convert_xlm_checkpoint_to_pytorch", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "!=", "4", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `transformers xlm XLM_CHECKPOINT_PATH PYTORCH_DUMP_OUTPUT`\"", ")", "\n", "", "else", ":", "\n", "                ", "XLM_CHECKPOINT_PATH", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "\n", "convert_xlm_checkpoint_to_pytorch", "(", "XLM_CHECKPOINT_PATH", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_distilbert.DistilBertConfig.__init__": [[37, 78], ["configuration_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "30522", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "sinusoidal_pos_embds", "=", "False", ",", "\n", "n_layers", "=", "6", ",", "\n", "n_heads", "=", "12", ",", "\n", "dim", "=", "768", ",", "\n", "hidden_dim", "=", "4", "*", "768", ",", "\n", "dropout", "=", "0.1", ",", "\n", "attention_dropout", "=", "0.1", ",", "\n", "activation", "=", "'gelu'", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "tie_weights_", "=", "True", ",", "\n", "qa_dropout", "=", "0.1", ",", "\n", "seq_classif_dropout", "=", "0.2", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DistilBertConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "sinusoidal_pos_embds", "=", "sinusoidal_pos_embds", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "attention_dropout", "=", "attention_dropout", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "tie_weights_", "=", "tie_weights_", "\n", "self", ".", "qa_dropout", "=", "qa_dropout", "\n", "self", ".", "seq_classif_dropout", "=", "seq_classif_dropout", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\" or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_distilbert.DistilBertConfig.hidden_size": [[79, 82], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_distilbert.DistilBertConfig.num_attention_heads": [[83, 86], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_distilbert.DistilBertConfig.num_hidden_layers": [[87, 90], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_transfo_xl.TransfoXLConfig.__init__": [[70, 144], ["configuration_utils.PretrainedConfig.__init__", "configuration_transfo_xl.TransfoXLConfig.cutoffs.extend", "isinstance", "isinstance", "json.loads.items", "isinstance", "io.open", "json.loads", "isinstance", "ValueError", "len", "len", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "267735", ",", "\n", "cutoffs", "=", "[", "20000", ",", "40000", ",", "200000", "]", ",", "\n", "d_model", "=", "1024", ",", "\n", "d_embed", "=", "1024", ",", "\n", "n_head", "=", "16", ",", "\n", "d_head", "=", "64", ",", "\n", "d_inner", "=", "4096", ",", "\n", "div_val", "=", "4", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "n_layer", "=", "18", ",", "\n", "tgt_len", "=", "128", ",", "\n", "ext_len", "=", "0", ",", "\n", "mem_len", "=", "1600", ",", "\n", "clamp_len", "=", "1000", ",", "\n", "same_length", "=", "True", ",", "\n", "proj_share_all_but_first", "=", "True", ",", "\n", "attn_type", "=", "0", ",", "\n", "sample_softmax", "=", "-", "1", ",", "\n", "adaptive", "=", "True", ",", "\n", "tie_weight", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "dropatt", "=", "0.0", ",", "\n", "untie_r", "=", "True", ",", "\n", "init", "=", "\"normal\"", ",", "\n", "init_range", "=", "0.01", ",", "\n", "proj_init_std", "=", "0.01", ",", "\n", "init_std", "=", "0.02", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs TransfoXLConfig.\n        \"\"\"", "\n", "super", "(", "TransfoXLConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "n_token", "=", "vocab_size_or_config_json_file", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", "else", "-", "1", "\n", "self", ".", "cutoffs", "=", "[", "]", "\n", "self", ".", "cutoffs", ".", "extend", "(", "cutoffs", ")", "\n", "self", ".", "tie_weight", "=", "tie_weight", "\n", "if", "proj_share_all_but_first", ":", "\n", "            ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "True", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "False", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "sample_softmax", "=", "sample_softmax", "\n", "self", ".", "adaptive", "=", "adaptive", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropatt", "=", "dropatt", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "init", "=", "init", "\n", "self", ".", "init_range", "=", "init_range", "\n", "self", ".", "proj_init_std", "=", "proj_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "not", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\" or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_transfo_xl.TransfoXLConfig.max_position_embeddings": [[146, 149], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tgt_len", "+", "self", ".", "ext_len", "+", "self", ".", "mem_len", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_transfo_xl.TransfoXLConfig.vocab_size": [[154, 157], ["None"], "methods", ["None"], ["", "@", "vocab_size", ".", "setter", "\n", "def", "vocab_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "n_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_transfo_xl.TransfoXLConfig.hidden_size": [[158, 161], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_transfo_xl.TransfoXLConfig.num_attention_heads": [[162, 165], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_transfo_xl.TransfoXLConfig.num_hidden_layers": [[166, 169], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.MultiHeadAttention.__init__": [[101, 115], ["torch.nn.Module.__init__", "next", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "set"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "n_heads", ",", "dim", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_id", "=", "next", "(", "MultiHeadAttention", ".", "NEW_ID", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dropout", "=", "config", ".", "attention_dropout", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "k_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "v_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "out_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.MultiHeadAttention.prune_heads": [[116, 136], ["torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_xlm.MultiHeadAttention.pruned_heads.union", "len", "set", "sum", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "attention_head_size", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_heads", ",", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "head", "-=", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q_lin", "=", "prune_linear_layer", "(", "self", ".", "q_lin", ",", "index", ")", "\n", "self", ".", "k_lin", "=", "prune_linear_layer", "(", "self", ".", "k_lin", ",", "index", ")", "\n", "self", ".", "v_lin", "=", "prune_linear_layer", "(", "self", ".", "v_lin", ",", "index", ")", "\n", "self", ".", "out_lin", "=", "prune_linear_layer", "(", "self", ".", "out_lin", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "dim", "=", "attention_head_size", "*", "self", ".", "n_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.MultiHeadAttention.forward": [[137, 199], ["input.size", "modeling_xlm.MultiHeadAttention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "mask", ",", "kv", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "bs", ",", "qlen", ",", "dim", "=", "input", ".", "size", "(", ")", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "qlen", "if", "cache", "is", "None", "else", "cache", "[", "'slen'", "]", "+", "qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "kv", ".", "size", "(", "1", ")", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "", "n_heads", "=", "self", ".", "n_heads", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "n_heads", "\n", "mask_reshape", "=", "(", "bs", ",", "1", ",", "qlen", ",", "klen", ")", "if", "mask", ".", "dim", "(", ")", "==", "3", "else", "(", "bs", ",", "1", ",", "1", ",", "klen", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "cache", "is", "None", "or", "self", ".", "layer_id", "not", "in", "cache", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "layer_id", "in", "cache", ":", "\n", "                ", "if", "kv", "is", "None", ":", "\n", "                    ", "k_", ",", "v_", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k_", ",", "k", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v_", ",", "v", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                    ", "k", ",", "v", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "", "", "cache", "[", "self", ".", "layer_id", "]", "=", "(", "k", ",", "v", ")", "\n", "\n", "", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "scores", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "# (bs, n_heads, qlen, klen)", "\n", "mask", "=", "(", "mask", "==", "0", ")", ".", "view", "(", "mask_reshape", ")", ".", "expand_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "scores", ".", "masked_fill_", "(", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "weights", "=", "F", ".", "softmax", "(", "scores", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "F", ".", "dropout", "(", "weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "torch", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "outputs", "=", "(", "self", ".", "out_lin", "(", "context", ")", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.TransformerFFN.__init__": [[203, 209], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "dim_hidden", ",", "out_dim", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransformerFFN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "lin1", "=", "nn", ".", "Linear", "(", "in_dim", ",", "dim_hidden", ")", "\n", "self", ".", "lin2", "=", "nn", ".", "Linear", "(", "dim_hidden", ",", "out_dim", ")", "\n", "self", ".", "act", "=", "gelu", "if", "config", ".", "gelu_activation", "else", "F", ".", "relu", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.TransformerFFN.forward": [[210, 216], ["modeling_xlm.TransformerFFN.lin1", "modeling_xlm.TransformerFFN.act", "modeling_xlm.TransformerFFN.lin2", "torch.nn.functional.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMPreTrainedModel.__init__": [[227, 229], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLMPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMPreTrainedModel._init_weights": [[230, 243], ["isinstance", "isinstance", "isinstance", "module.bias.data.zero_", "module.weight.data.fill_", "torch.nn.init.normal_", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights. \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "if", "self", ".", "config", "is", "not", "None", "and", "self", ".", "config", ".", "embed_init_std", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "config", ".", "embed_init_std", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "if", "self", ".", "config", "is", "not", "None", "and", "self", ".", "config", ".", "init_std", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "config", ".", "init_std", ")", "\n", "if", "hasattr", "(", "module", ",", "'bias'", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0.", ")", "\n", "", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMModel.__init__": [[340, 409], ["modeling_xlm.XLMPreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "hasattr", "modeling_xlm.XLMModel.init_weights", "NotImplementedError", "modeling_xlm.create_sinusoidal_embeddings", "torch.nn.Embedding", "modeling_xlm.XLMModel.attentions.append", "modeling_xlm.XLMModel.layer_norm1.append", "modeling_xlm.XLMModel.ffns.append", "modeling_xlm.XLMModel.layer_norm2.append", "config.pruned_heads.copy().items", "modeling_xlm.MultiHeadAttention", "torch.nn.LayerNorm", "modeling_xlm.TransformerFFN", "torch.nn.LayerNorm", "config.pruned_heads.copy", "modeling_xlm.XLMModel.prune_heads", "int", "list", "int", "map"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.create_sinusoidal_embeddings", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "#, dico, is_encoder, with_output):", "\n", "        ", "super", "(", "XLMModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "# encoder / decoder, output layer", "\n", "self", ".", "is_encoder", "=", "config", ".", "is_encoder", "\n", "self", ".", "is_decoder", "=", "not", "config", ".", "is_encoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Currently XLM can only be used as an encoder\"", ")", "\n", "# self.with_output = with_output", "\n", "", "self", ".", "causal", "=", "config", ".", "causal", "\n", "\n", "# dictionary / languages", "\n", "self", ".", "n_langs", "=", "config", ".", "n_langs", "\n", "self", ".", "use_lang_emb", "=", "config", ".", "use_lang_emb", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "eos_index", "=", "config", ".", "eos_index", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "# self.dico = dico", "\n", "# self.id2lang = config.id2lang", "\n", "# self.lang2id = config.lang2id", "\n", "# assert len(self.dico) == self.n_words", "\n", "# assert len(self.id2lang) == len(self.lang2id) == self.n_langs", "\n", "\n", "# model parameters", "\n", "self", ".", "dim", "=", "config", ".", "emb_dim", "# 512 by default", "\n", "self", ".", "hidden_dim", "=", "self", ".", "dim", "*", "4", "# 2048 by default", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "# 8 by default", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "attention_dropout", "=", "config", ".", "attention_dropout", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", ",", "'transformer dim must be a multiple of n_heads'", "\n", "\n", "# embeddings", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "self", ".", "dim", ")", "\n", "if", "config", ".", "sinusoidal_embeddings", ":", "\n", "            ", "create_sinusoidal_embeddings", "(", "config", ".", "max_position_embeddings", ",", "self", ".", "dim", ",", "out", "=", "self", ".", "position_embeddings", ".", "weight", ")", "\n", "", "if", "config", ".", "n_langs", ">", "1", "and", "config", ".", "use_lang_emb", ":", "\n", "            ", "self", ".", "lang_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "n_langs", ",", "self", ".", "dim", ")", "\n", "", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "n_words", ",", "self", ".", "dim", ",", "padding_idx", "=", "self", ".", "pad_index", ")", "\n", "self", ".", "layer_norm_emb", "=", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# transformer layers", "\n", "self", ".", "attentions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer_norm1", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "ffns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer_norm2", "=", "nn", ".", "ModuleList", "(", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15 = nn.ModuleList()", "\n", "#     self.encoder_attn = nn.ModuleList()", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "self", ".", "attentions", ".", "append", "(", "MultiHeadAttention", "(", "self", ".", "n_heads", ",", "self", ".", "dim", ",", "config", "=", "config", ")", ")", "\n", "self", ".", "layer_norm1", ".", "append", "(", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15.append(nn.LayerNorm(self.dim, eps=config.layer_norm_eps))", "\n", "#     self.encoder_attn.append(MultiHeadAttention(self.n_heads, self.dim, dropout=self.attention_dropout))", "\n", "self", ".", "ffns", ".", "append", "(", "TransformerFFN", "(", "self", ".", "dim", ",", "self", ".", "hidden_dim", ",", "self", ".", "dim", ",", "config", "=", "config", ")", ")", "\n", "self", ".", "layer_norm2", ".", "append", "(", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "config", ",", "\"pruned_heads\"", ")", ":", "\n", "            ", "pruned_heads", "=", "config", ".", "pruned_heads", ".", "copy", "(", ")", ".", "items", "(", ")", "\n", "config", ".", "pruned_heads", "=", "{", "}", "\n", "for", "layer", ",", "heads", "in", "pruned_heads", ":", "\n", "                ", "if", "self", ".", "attentions", "[", "int", "(", "layer", ")", "]", ".", "n_heads", "==", "config", ".", "n_heads", ":", "\n", "                    ", "self", ".", "prune_heads", "(", "{", "int", "(", "layer", ")", ":", "list", "(", "map", "(", "int", ",", "heads", ")", ")", "}", ")", "\n", "\n", "", "", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMModel._resize_token_embeddings": [[410, 413], ["modeling_xlm.XLMModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "embeddings", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMModel._prune_heads": [[414, 421], ["heads_to_prune.items", "modeling_xlm.XLMModel.attentions[].prune_heads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "attentions", "[", "layer", "]", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMModel.forward": [[422, 537], ["input_ids.size", "modeling_xlm.get_masks", "modeling_xlm.XLMModel.embeddings", "modeling_xlm.XLMModel.layer_norm_emb", "torch.nn.functional.dropout", "mask.unsqueeze().to", "range", "lengths.size", "lengths.max().item", "input_ids.new().long", "torch.arange().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_xlm.XLMModel.position_embeddings().expand_as", "torch.nn.functional.dropout", "mask.unsqueeze().to", "torch.nn.functional.dropout.size", "torch.arange().unsqueeze.size", "langs.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "modeling_xlm.XLMModel.lang_embeddings", "modeling_xlm.XLMModel.embeddings", "mask.unsqueeze", "lengths.max", "input_ids.new", "torch.arange", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlm.XLMModel.position_embeddings", "mask.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlm.XLMModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.get_masks"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ")", ":", "# removed: src_enc=None, src_len=None", "\n", "        ", "if", "lengths", "is", "None", ":", "\n", "            ", "lengths", "=", "(", "input_ids", "!=", "self", ".", "pad_index", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "# mask = input_ids != self.pad_index", "\n", "\n", "# check inputs", "\n", "", "bs", ",", "slen", "=", "input_ids", ".", "size", "(", ")", "\n", "assert", "lengths", ".", "size", "(", "0", ")", "==", "bs", "\n", "assert", "lengths", ".", "max", "(", ")", ".", "item", "(", ")", "<=", "slen", "\n", "# input_ids = input_ids.transpose(0, 1)  # batch size as dimension 0", "\n", "# assert (src_enc is None) == (src_len is None)", "\n", "# if src_enc is not None:", "\n", "#     assert self.is_decoder", "\n", "#     assert src_enc.size(0) == bs", "\n", "\n", "# generate masks", "\n", "mask", ",", "attn_mask", "=", "get_masks", "(", "slen", ",", "lengths", ",", "self", ".", "causal", ",", "padding_mask", "=", "attention_mask", ")", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     src_mask = torch.arange(src_len.max(), dtype=torch.long, device=lengths.device) < src_len[:, None]", "\n", "\n", "# position_ids", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "input_ids", ".", "new", "(", "(", "slen", ",", ")", ")", ".", "long", "(", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "slen", ",", "out", "=", "position_ids", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "assert", "position_ids", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "# (slen, bs)", "\n", "# position_ids = position_ids.transpose(0, 1)", "\n", "\n", "# langs", "\n", "", "if", "langs", "is", "not", "None", ":", "\n", "            ", "assert", "langs", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "# (slen, bs)", "\n", "# langs = langs.transpose(0, 1)", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x qlen x klen]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layers", "\n", "\n", "# do not recompute cached elements", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "_slen", "=", "slen", "-", "cache", "[", "'slen'", "]", "\n", "input_ids", "=", "input_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "position_ids", "=", "position_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "if", "langs", "is", "not", "None", ":", "\n", "                ", "langs", "=", "langs", "[", ":", ",", "-", "_slen", ":", "]", "\n", "", "mask", "=", "mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "\n", "# embeddings", "\n", "", "tensor", "=", "self", ".", "embeddings", "(", "input_ids", ")", "\n", "tensor", "=", "tensor", "+", "self", ".", "position_embeddings", "(", "position_ids", ")", ".", "expand_as", "(", "tensor", ")", "\n", "if", "langs", "is", "not", "None", "and", "self", ".", "use_lang_emb", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "lang_embeddings", "(", "langs", ")", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "embeddings", "(", "token_type_ids", ")", "\n", "", "tensor", "=", "self", ".", "layer_norm_emb", "(", "tensor", ")", "\n", "tensor", "=", "F", ".", "dropout", "(", "tensor", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "tensor", "*=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "tensor", ".", "dtype", ")", "\n", "\n", "# transformer layers", "\n", "hidden_states", "=", "(", ")", "\n", "attentions", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# self attention", "\n", "", "attn_outputs", "=", "self", ".", "attentions", "[", "i", "]", "(", "tensor", ",", "attn_mask", ",", "cache", "=", "cache", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "attn", "=", "attn_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", "=", "attentions", "+", "(", "attn_outputs", "[", "1", "]", ",", ")", "\n", "", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "tensor", "=", "tensor", "+", "attn", "\n", "tensor", "=", "self", ".", "layer_norm1", "[", "i", "]", "(", "tensor", ")", "\n", "\n", "# encoder attention (for decoder only)", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     attn = self.encoder_attn[i](tensor, src_mask, kv=src_enc, cache=cache)", "\n", "#     attn = F.dropout(attn, p=self.dropout, training=self.training)", "\n", "#     tensor = tensor + attn", "\n", "#     tensor = self.layer_norm15[i](tensor)", "\n", "\n", "# FFN", "\n", "tensor", "=", "tensor", "+", "self", ".", "ffns", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "=", "self", ".", "layer_norm2", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "*=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "tensor", ".", "dtype", ")", "\n", "\n", "# Add last hidden state", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# update cache length", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "cache", "[", "'slen'", "]", "+=", "tensor", ".", "size", "(", "1", ")", "\n", "\n", "# move back sequence length to dimension 0", "\n", "# tensor = tensor.transpose(0, 1)", "\n", "\n", "", "outputs", "=", "(", "tensor", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMPredLayer.__init__": [[543, 559], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.AdaptiveLogSoftmaxWithLoss"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMPredLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "asm", "=", "config", ".", "asm", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "dim", "=", "config", ".", "emb_dim", "\n", "\n", "if", "config", ".", "asm", "is", "False", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "config", ".", "n_words", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "AdaptiveLogSoftmaxWithLoss", "(", "\n", "in_features", "=", "dim", ",", "\n", "n_classes", "=", "config", ".", "n_words", ",", "\n", "cutoffs", "=", "config", ".", "asm_cutoffs", ",", "\n", "div_value", "=", "config", ".", "asm_div_value", ",", "\n", "head_bias", "=", "True", ",", "# default is False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMPredLayer.forward": [[561, 579], ["modeling_xlm.XLMPredLayer.proj", "modeling_xlm.XLMPredLayer.proj.log_prob", "torch.nn.functional.cross_entropy", "modeling_xlm.XLMPredLayer.proj", "modeling_xlm.XLMPredLayer.view", "y.view"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "        ", "\"\"\" Compute the loss, and optionally the scores.\n        \"\"\"", "\n", "outputs", "=", "(", ")", "\n", "if", "self", ".", "asm", "is", "False", ":", "\n", "            ", "scores", "=", "self", ".", "proj", "(", "x", ")", "\n", "outputs", "=", "(", "scores", ",", ")", "+", "outputs", "\n", "if", "y", "is", "not", "None", ":", "\n", "                ", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ".", "view", "(", "-", "1", ",", "self", ".", "n_words", ")", ",", "y", ".", "view", "(", "-", "1", ")", ",", "reduction", "=", "'elementwise_mean'", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "", "else", ":", "\n", "            ", "scores", "=", "self", ".", "proj", ".", "log_prob", "(", "x", ")", "\n", "outputs", "=", "(", "scores", ",", ")", "+", "outputs", "\n", "if", "y", "is", "not", "None", ":", "\n", "                ", "_", ",", "loss", "=", "self", ".", "proj", "(", "x", ",", "y", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMWithLMHeadModel.__init__": [[615, 622], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_xlm.XLMPredLayer", "modeling_xlm.XLMWithLMHeadModel.init_weights", "modeling_xlm.XLMWithLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMWithLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "pred_layer", "=", "XLMPredLayer", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMWithLMHeadModel.tie_weights": [[623, 627], ["modeling_xlm.XLMWithLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "pred_layer", ".", "proj", ",", "self", ".", "transformer", ".", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMWithLMHeadModel.forward": [[628, 644], ["modeling_xlm.XLMWithLMHeadModel.transformer", "modeling_xlm.XLMWithLMHeadModel.pred_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "outputs", "=", "self", ".", "pred_layer", "(", "output", ",", "labels", ")", "\n", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMForSequenceClassification.__init__": [[680, 688], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_utils.SequenceSummary", "modeling_xlm.XLMForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMForSequenceClassification.forward": [[689, 716], ["modeling_xlm.XLMForSequenceClassification.transformer", "modeling_xlm.XLMForSequenceClassification.sequence_summary", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlm.XLMForSequenceClassification.view", "labels.view", "modeling_xlm.XLMForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMForQuestionAnsweringSimple.__init__": [[764, 771], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "torch.nn.Linear", "modeling_xlm.XLMForQuestionAnsweringSimple.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMForQuestionAnsweringSimple.forward": [[772, 811], ["modeling_xlm.XLMForQuestionAnsweringSimple.transformer", "modeling_xlm.XLMForQuestionAnsweringSimple.qa_outputs", "modeling_xlm.XLMForQuestionAnsweringSimple.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMForQuestionAnswering.__init__": [[859, 866], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_utils.SQuADHead", "modeling_xlm.XLMForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "SQuADHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.XLMForQuestionAnswering.forward": [[867, 887], ["modeling_xlm.XLMForQuestionAnswering.transformer", "modeling_xlm.XLMForQuestionAnswering.qa_outputs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "\n", "is_impossible", "=", "None", ",", "cls_index", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "outputs", "=", "self", ".", "qa_outputs", "(", "output", ",", "start_positions", "=", "start_positions", ",", "end_positions", "=", "end_positions", ",", "\n", "cls_index", "=", "cls_index", ",", "is_impossible", "=", "is_impossible", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.create_sinusoidal_embeddings": [[50, 59], ["numpy.array", "torch.FloatTensor", "torch.FloatTensor", "out.detach_", "numpy.sin", "numpy.cos", "range", "numpy.power", "range"], "function", ["None"], ["def", "create_sinusoidal_embeddings", "(", "n_pos", ",", "dim", ",", "out", ")", ":", "\n", "    ", "position_enc", "=", "np", ".", "array", "(", "[", "\n", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "dim", ")", "for", "j", "in", "range", "(", "dim", ")", "]", "\n", "for", "pos", "in", "range", "(", "n_pos", ")", "\n", "]", ")", "\n", "out", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "sin", "(", "position_enc", "[", ":", ",", "0", ":", ":", "2", "]", ")", ")", "\n", "out", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "cos", "(", "position_enc", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", "\n", "out", ".", "detach_", "(", ")", "\n", "out", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.gelu": [[61, 70], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    GELU activation\n    https://arxiv.org/abs/1606.08415\n    https://github.com/huggingface/pytorch-openai-transformer-lm/blob/master/model_pytorch.py#L14\n    https://github.com/huggingface/transformers/blob/master/modeling.py\n    \"\"\"", "\n", "# return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))", "\n", "return", "0.5", "*", "x", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_xlm.get_masks": [[72, 95], ["lengths.size", "torch.arange", "mask.size", "lengths.max().item", "alen[].repeat", "attn_mask.size", "lengths.max"], "function", ["None"], ["", "def", "get_masks", "(", "slen", ",", "lengths", ",", "causal", ",", "padding_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Generate hidden states mask, and optionally an attention mask.\n    \"\"\"", "\n", "bs", "=", "lengths", ".", "size", "(", "0", ")", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "padding_mask", "\n", "", "else", ":", "\n", "        ", "assert", "lengths", ".", "max", "(", ")", ".", "item", "(", ")", "<=", "slen", "\n", "alen", "=", "torch", ".", "arange", "(", "slen", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "lengths", ".", "device", ")", "\n", "mask", "=", "alen", "<", "lengths", "[", ":", ",", "None", "]", "\n", "\n", "# attention mask is the same as mask, or triangular inferior attention (causal)", "\n", "", "if", "causal", ":", "\n", "        ", "attn_mask", "=", "alen", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "bs", ",", "slen", ",", "1", ")", "<=", "alen", "[", "None", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "        ", "attn_mask", "=", "mask", "\n", "\n", "# sanity check", "\n", "", "assert", "mask", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "\n", "assert", "causal", "is", "False", "or", "attn_mask", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ",", "slen", ")", "\n", "\n", "return", "mask", ",", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_xlm_original_pytorch_checkpoint_to_pytorch.convert_xlm_checkpoint_to_pytorch": [[32, 67], ["torch.load", "state_dict.items", "dict", "dict", "print", "torch.save", "print", "print", "io.open", "f.write", "io.open", "f.write", "dict.items", "dict.items", "json.dumps", "json.dumps", "isinstance", "s.replace", "s.find"], "function", ["None"], ["def", "convert_xlm_checkpoint_to_pytorch", "(", "xlm_checkpoint_path", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Load checkpoint", "\n", "    ", "chkpt", "=", "torch", ".", "load", "(", "xlm_checkpoint_path", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "state_dict", "=", "chkpt", "[", "'model'", "]", "\n", "\n", "# We have the base model one level deeper than the original XLM repository", "\n", "two_levels_state_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "'pred_layer'", "in", "k", ":", "\n", "            ", "two_levels_state_dict", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "            ", "two_levels_state_dict", "[", "'transformer.'", "+", "k", "]", "=", "v", "\n", "\n", "", "", "config", "=", "chkpt", "[", "'params'", "]", "\n", "config", "=", "dict", "(", "(", "n", ",", "v", ")", "for", "n", ",", "v", "in", "config", ".", "items", "(", ")", "if", "not", "isinstance", "(", "v", ",", "(", "torch", ".", "FloatTensor", ",", "numpy", ".", "ndarray", ")", ")", ")", "\n", "\n", "vocab", "=", "chkpt", "[", "'dico_word2id'", "]", "\n", "vocab", "=", "dict", "(", "(", "s", "+", "'</w>'", "if", "s", ".", "find", "(", "'@@'", ")", "==", "-", "1", "and", "i", ">", "13", "else", "s", ".", "replace", "(", "'@@'", ",", "''", ")", ",", "i", ")", "for", "s", ",", "i", "in", "vocab", ".", "items", "(", ")", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", "\n", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "two_levels_state_dict", ",", "pytorch_weights_dump_path", ")", "\n", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "config", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "print", "(", "\"Save vocab file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_vocab_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vocab", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.__init__": [[51, 60], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "finetuning_task", "=", "kwargs", ".", "pop", "(", "'finetuning_task'", ",", "None", ")", "\n", "self", ".", "num_labels", "=", "kwargs", ".", "pop", "(", "'num_labels'", ",", "2", ")", "\n", "self", ".", "output_attentions", "=", "kwargs", ".", "pop", "(", "'output_attentions'", ",", "False", ")", "\n", "self", ".", "output_hidden_states", "=", "kwargs", ".", "pop", "(", "'output_hidden_states'", ",", "False", ")", "\n", "self", ".", "output_past", "=", "kwargs", ".", "pop", "(", "'output_past'", ",", "True", ")", "# Not used by all models", "\n", "self", ".", "torchscript", "=", "kwargs", ".", "pop", "(", "'torchscript'", ",", "False", ")", "# Only used by PyTorch models", "\n", "self", ".", "use_bfloat16", "=", "kwargs", ".", "pop", "(", "'use_bfloat16'", ",", "False", ")", "\n", "self", ".", "pruned_heads", "=", "kwargs", ".", "pop", "(", "'pruned_heads'", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained": [[61, 72], ["os.path.isdir", "os.path.join", "configuration_utils.PretrainedConfig.to_json_file", "logger.info"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.to_json_file"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a configuration object to the directory `save_directory`, so that it\n            can be re-loaded using the :func:`~transformers.PretrainedConfig.from_pretrained` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "logger", ".", "info", "(", "\"Configuration saved in {}\"", ".", "format", "(", "output_config_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_pretrained": [[73, 173], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls.from_json_file", "hasattr", "kwargs.items", "logger.info", "os.path.isdir", "file_utils.cached_path", "logger.info", "logger.info", "dict", "hasattr", "kwargs.pop", "str", "os.path.join", "EnvironmentError", "setattr", "to_remove.append", "int", "cls.from_json_file.pruned_heads.items", "cls.pretrained_config_archive_map.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a :class:`~transformers.PretrainedConfig` (or a derived class) from a pre-trained model configuration.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing a configuration file saved using the :func:`~transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved configuration JSON `file`, e.g.: ``./my_model_directory/configuration.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the configuration object after loading.\n\n                - The values in kwargs of any keys which are configuration attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PretrainedConfig` so let's show the examples on a\n            # derived class: BertConfig\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n            config = BertConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = BertConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "return_unused_kwargs", "=", "kwargs", ".", "pop", "(", "'return_unused_kwargs'", ",", "False", ")", "\n", "\n", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "            ", "config_file", "=", "cls", ".", "pretrained_config_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "", "else", ":", "\n", "            ", "config_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "force_download", ",", "proxies", "=", "proxies", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "                ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained model configuration file.\"", ".", "format", "(", "\n", "config_file", ")", "\n", "", "else", ":", "\n", "                ", "msg", "=", "\"Model name '{}' was not found in model name list ({}). \"", "\"We assumed '{}' was a path or url to a configuration file named {} or \"", "\"a directory containing such a file but couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_config_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "config_file", ",", "CONFIG_NAME", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "\n", "# Load config", "\n", "", "config", "=", "cls", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'pruned_heads'", ")", ":", "\n", "            ", "config", ".", "pruned_heads", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "config", ".", "pruned_heads", ".", "items", "(", ")", ")", "\n", "\n", "# Update config with kwargs if needed", "\n", "", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model config %s\"", ",", "str", "(", "config", ")", ")", "\n", "if", "return_unused_kwargs", ":", "\n", "            ", "return", "config", ",", "kwargs", "\n", "", "else", ":", "\n", "            ", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_dict": [[174, 181], ["cls", "json_object.items", "setattr"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "cls", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file": [[182, 188], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.__eq__": [[189, 191], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.__repr__": [[192, 194], ["str", "configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.to_dict": [[195, 199], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.to_json_string": [[200, 203], ["json.dumps", "configuration_utils.PretrainedConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.to_json_file": [[204, 208], ["io.open", "writer.write", "configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.__init__": [[84, 97], ["super().__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model_size", ",", "num_heads", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "d_model_size", "=", "d_model_size", "\n", "\n", "self", ".", "depth", "=", "int", "(", "d_model_size", "/", "self", ".", "num_heads", ")", "\n", "\n", "self", ".", "Wq", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "self", ".", "Wk", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "self", ".", "Wv", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "\n", "self", ".", "dense", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads": [[98, 101], ["x.reshape.reshape.reshape", "x.reshape.reshape.permute"], "methods", ["None"], ["", "def", "split_into_heads", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_heads", ",", "self", ".", "depth", ")", "\n", "return", "x", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.forward": [[102, 128], ["modeling_ctrl.MultiHeadAttention.Wq", "modeling_ctrl.MultiHeadAttention.Wk", "modeling_ctrl.MultiHeadAttention.Wv", "modeling_ctrl.MultiHeadAttention.split_into_heads", "modeling_ctrl.MultiHeadAttention.split_into_heads", "modeling_ctrl.MultiHeadAttention.split_into_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_ctrl.scaled_dot_product_attention", "output[].permute", "output[].permute.reshape", "modeling_ctrl.MultiHeadAttention.dense", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.scaled_dot_product_attention"], ["", "def", "forward", "(", "self", ",", "v", ",", "k", ",", "q", ",", "mask", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "q", ".", "shape", "[", "0", "]", "\n", "\n", "q", "=", "self", ".", "Wq", "(", "q", ")", "\n", "k", "=", "self", ".", "Wk", "(", "k", ")", "\n", "v", "=", "self", ".", "Wv", "(", "v", ")", "\n", "\n", "q", "=", "self", ".", "split_into_heads", "(", "q", ",", "batch_size", ")", "\n", "k", "=", "self", ".", "split_into_heads", "(", "k", ",", "batch_size", ")", "\n", "v", "=", "self", ".", "split_into_heads", "(", "v", ",", "batch_size", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ",", "layer_past", "[", "1", "]", "\n", "k", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "k", ")", ",", "dim", "=", "-", "2", ")", "\n", "v", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "v", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "output", "=", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", ",", "head_mask", ")", "\n", "scaled_attention", "=", "output", "[", "0", "]", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "attn", "=", "output", "[", "1", "]", "\n", "original_size_attention", "=", "scaled_attention", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "self", ".", "d_model_size", ")", "\n", "output", "=", "self", ".", "dense", "(", "original_size_attention", ")", "\n", "\n", "outputs", "=", "(", "output", ",", "present", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.EncoderLayer.__init__": [[138, 149], ["super().__init__", "modeling_ctrl.MultiHeadAttention", "modeling_ctrl.point_wise_feed_forward_network", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.point_wise_feed_forward_network"], ["    ", "def", "__init__", "(", "self", ",", "d_model_size", ",", "num_heads", ",", "dff", ",", "rate", "=", "0.1", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "multi_head_attention", "=", "MultiHeadAttention", "(", "d_model_size", ",", "num_heads", ",", "output_attentions", ")", "\n", "self", ".", "ffn", "=", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ")", "\n", "\n", "self", ".", "layernorm1", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model_size", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "layernorm2", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model_size", ",", "eps", "=", "1e-6", ")", "\n", "\n", "self", ".", "dropout1", "=", "torch", ".", "nn", ".", "Dropout", "(", "rate", ")", "\n", "self", ".", "dropout2", "=", "torch", ".", "nn", ".", "Dropout", "(", "rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.EncoderLayer.forward": [[150, 167], ["modeling_ctrl.EncoderLayer.layernorm1", "modeling_ctrl.EncoderLayer.multi_head_attention", "modeling_ctrl.EncoderLayer.dropout1", "modeling_ctrl.EncoderLayer.layernorm2", "modeling_ctrl.EncoderLayer.ffn", "modeling_ctrl.EncoderLayer.dropout2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "normed", "=", "self", ".", "layernorm1", "(", "x", ")", "\n", "attn_outputs", "=", "self", ".", "multi_head_attention", "(", "normed", ",", "normed", ",", "normed", ",", "mask", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "attn_output", "=", "attn_outputs", "[", "0", "]", "\n", "attn_output", "=", "self", ".", "dropout1", "(", "attn_output", ")", "\n", "out1", "=", "x", "+", "attn_output", "\n", "\n", "out2", "=", "self", ".", "layernorm2", "(", "out1", ")", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "out2", ")", "\n", "ffn_output", "=", "self", ".", "dropout2", "(", "ffn_output", ")", "\n", "out2", "=", "out1", "+", "ffn_output", "\n", "\n", "outputs", "=", "(", "out2", ",", ")", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLPreTrainedModel._init_weights": [[177, 189], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLModel.__init__": [[269, 291], ["modeling_utils.PreTrainedModel.__init__", "modeling_ctrl.positional_encoding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "modeling_ctrl.CTRLModel.init_weights", "modeling_ctrl.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.positional_encoding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CTRLModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "d_model_size", "=", "config", ".", "n_embd", "\n", "self", ".", "num_layers", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "pos_encoding", "=", "positional_encoding", "(", "config", ".", "n_positions", ",", "self", ".", "d_model_size", ",", "torch", ".", "float", ")", "\n", "\n", "self", ".", "w", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "EncoderLayer", "(", "config", ".", "n_embd", ",", "\n", "config", ".", "n_head", ",", "\n", "config", ".", "dff", ",", "\n", "config", ".", "resid_pdrop", ",", "\n", "config", ".", "output_attentions", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "layernorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLModel._resize_token_embeddings": [[292, 295], ["modeling_ctrl.CTRLModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "w", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "w", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLModel._prune_heads": [[296, 302], ["heads_to_prune.items", "modeling_ctrl.CTRLModel.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n                heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLModel.forward": [[303, 403], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_ctrl.CTRLModel.w", "torch.triu().to", "torch.triu().to", "torch.triu().to", "torch.triu().to", "numpy.sqrt", "modeling_ctrl.CTRLModel.pos_encoding[].to", "modeling_ctrl.CTRLModel.dropout", "enumerate", "modeling_ctrl.CTRLModel.layernorm", "hidden_states.view.view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "attention_mask.to.to.view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "token_type_ids.view.view.view", "modeling_ctrl.CTRLModel.w", "numpy.sqrt", "zip", "h", "tuple", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "modeling_ctrl.CTRLModel.size", "tuple.append", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "t.view", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "modeling_ctrl.CTRLModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_ctrl.CTRLModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_ids", ".", "size", "(", "-", "1", ")", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "w", "(", "token_type_ids", ")", "\n", "token_type_embeds", "*=", "np", ".", "sqrt", "(", "self", ".", "d_model_size", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "w", "(", "input_ids", ")", "\n", "# inputs_embeds = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded", "\n", "seq_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "mask", "=", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "seq_len", ",", "seq_len", ")", ",", "1", ")", ".", "to", "(", "inputs_embeds", ".", "device", ")", "\n", "\n", "inputs_embeds", "*=", "np", ".", "sqrt", "(", "self", ".", "d_model_size", ")", "\n", "\n", "pos_embeds", "=", "self", ".", "pos_encoding", "[", "position_ids", ",", ":", "]", ".", "to", "(", "inputs_embeds", ".", "device", ")", "\n", "\n", "hidden_states", "=", "inputs_embeds", "+", "pos_embeds", "+", "token_type_embeds", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "inputs_embeds", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "presents", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "for", "i", ",", "(", "h", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "", "outputs", "=", "h", "(", "hidden_states", ",", "\n", "mask", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "layernorm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLLMHeadModel.__init__": [[446, 453], ["modeling_utils.PreTrainedModel.__init__", "modeling_ctrl.CTRLModel", "torch.Linear", "torch.Linear", "modeling_ctrl.CTRLLMHeadModel.init_weights", "modeling_ctrl.CTRLLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CTRLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "CTRLModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLLMHeadModel.tie_weights": [[454, 459], ["modeling_ctrl.CTRLLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n                Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "self", ".", "transformer", ".", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.CTRLLMHeadModel.forward": [[460, 486], ["modeling_ctrl.CTRLLMHeadModel.transformer", "modeling_ctrl.CTRLLMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.angle_defn": [[42, 45], ["torch.pow", "torch.pow"], "function", ["None"], ["def", "angle_defn", "(", "pos", ",", "i", ",", "d_model_size", ")", ":", "\n", "    ", "angle_rates", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "(", "2", "*", "(", "i", "//", "2", ")", ")", "/", "d_model_size", ")", "\n", "return", "pos", "*", "angle_rates", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.positional_encoding": [[46, 57], ["modeling_ctrl.angle_defn", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cat", "torch.cat", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.float", "torch.float"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.angle_defn"], ["", "def", "positional_encoding", "(", "position", ",", "d_model_size", ",", "dtype", ")", ":", "\n", "# create the sinusoidal pattern for the positional encoding", "\n", "    ", "angle_rads", "=", "(", "angle_defn", "(", "torch", ".", "arange", "(", "position", ",", "dtype", "=", "dtype", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "arange", "(", "d_model_size", ",", "dtype", "=", "dtype", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "d_model_size", ")", ")", "\n", "\n", "sines", "=", "torch", ".", "sin", "(", "angle_rads", "[", ":", ",", "0", ":", ":", "2", "]", ")", "\n", "cosines", "=", "torch", ".", "cos", "(", "angle_rads", "[", ":", ",", "1", ":", ":", "2", "]", ")", "\n", "\n", "pos_encoding", "=", "torch", ".", "cat", "(", "[", "sines", ",", "cosines", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "pos_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.scaled_dot_product_attention": [[58, 81], ["torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "k.permute", "numpy.sqrt"], "function", ["None"], ["", "def", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# calculate attention", "\n", "    ", "matmul_qk", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ")", ")", "\n", "\n", "dk", "=", "k", ".", "shape", "[", "-", "1", "]", "\n", "scaled_attention_logits", "=", "matmul_qk", "/", "np", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "scaled_attention_logits", "+=", "(", "mask", "*", "-", "1e4", ")", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "        ", "scaled_attention_logits", "=", "scaled_attention_logits", "+", "attention_mask", "\n", "\n", "", "attention_weights", "=", "torch", ".", "softmax", "(", "scaled_attention_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "        ", "attention_weights", "=", "attention_weights", "*", "head_mask", "\n", "\n", "", "output", "=", "torch", ".", "matmul", "(", "attention_weights", ",", "v", ")", "\n", "\n", "return", "output", ",", "attention_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_ctrl.point_wise_feed_forward_network": [[131, 135], ["torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "function", ["None"], ["", "", "def", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ")", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "Sequential", "(", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "dff", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "dff", ",", "d_model_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.__init__": [[63, 80], ["super().__init__", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetRelativeAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "if", "config", ".", "d_model", "%", "config", ".", "n_head", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "d_model", ",", "config", ".", "n_head", ")", ")", "\n", "\n", "", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "scale", "=", "1", "/", "(", "config", ".", "d_head", "**", "0.5", ")", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'layer_norm'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.build": [[81, 111], ["modeling_tf_utils.get_initializer", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", "\n", "self", ".", "q", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "initializer", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'q'", ")", "\n", "self", ".", "k", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "initializer", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'k'", ")", "\n", "self", ".", "v", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "initializer", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'v'", ")", "\n", "self", ".", "o", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "initializer", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'o'", ")", "\n", "self", ".", "r", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "initializer", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'r'", ")", "\n", "self", ".", "r_r_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'r_r_bias'", ")", "\n", "self", ".", "r_s_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'r_s_bias'", ")", "\n", "self", ".", "r_w_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'r_w_bias'", ")", "\n", "self", ".", "seg_embed", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "2", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "\n", "initializer", "=", "initializer", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'seg_embed'", ")", "\n", "super", "(", "TFXLNetRelativeAttention", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.prune_heads": [[112, 114], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_shift": [[115, 127], ["modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "@", "staticmethod", "\n", "def", "rel_shift", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"perform relative shift to form the relative attention score.\"\"\"", "\n", "x_size", "=", "shape_list", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "x_size", "[", "1", "]", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", ")", "\n", "x", "=", "x", "[", "1", ":", ",", "...", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", "-", "1", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", ")", "\n", "x", "=", "x", "[", ":", ",", "0", ":", "klen", ",", ":", ",", ":", "]", "\n", "# x = torch.index_select(x, 1, torch.arange(klen, device=x.device, dtype=torch.long))", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core": [[128, 172], ["tensorflow.einsum", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_shift", "tensorflow.nn.softmax", "modeling_tf_xlnet.TFXLNetRelativeAttention.dropout", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_shift"], ["", "def", "rel_attn_core", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Core relative positional attention operations.\"\"\"", "\n", "\n", "q_head", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "# content based attention score", "\n", "ac", "=", "tf", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "q_head", "+", "self", ".", "r_w_bias", ",", "k_head_h", ")", "\n", "\n", "# position based attention score", "\n", "bd", "=", "tf", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "q_head", "+", "self", ".", "r_r_bias", ",", "k_head_r", ")", "\n", "bd", "=", "self", ".", "rel_shift", "(", "bd", ",", "klen", "=", "ac", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# segment based attention score", "\n", "if", "seg_mat", "is", "None", ":", "\n", "            ", "ef", "=", "0", "\n", "", "else", ":", "\n", "            ", "ef", "=", "tf", ".", "einsum", "(", "'ibnd,snd->ibns'", ",", "q_head", "+", "self", ".", "r_s_bias", ",", "self", ".", "seg_embed", ")", "\n", "ef", "=", "tf", ".", "einsum", "(", "'ijbs,ibns->ijbn'", ",", "seg_mat", ",", "ef", ")", "\n", "\n", "# merge attention scores and perform masking", "\n", "", "attn_score", "=", "(", "ac", "+", "bd", "+", "ef", ")", "*", "self", ".", "scale", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask", "\n", "            ", "if", "attn_mask", ".", "dtype", "==", "tf", ".", "float16", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "65500", "*", "attn_mask", "\n", "", "else", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "1e30", "*", "attn_mask", "\n", "\n", "# attention probability", "\n", "", "", "attn_prob", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_score", ",", "axis", "=", "1", ")", "\n", "\n", "attn_prob", "=", "self", ".", "dropout", "(", "attn_prob", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "# attention output", "\n", "", "attn_vec", "=", "tf", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "attn_prob", ",", "v_head_h", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "attn_vec", ",", "attn_prob", "\n", "\n", "", "return", "attn_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention": [[173, 187], ["tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.dropout", "modeling_tf_xlnet.TFXLNetRelativeAttention.layer_norm"], "methods", ["None"], ["", "def", "post_attention", "(", "self", ",", "inputs", ",", "residual", "=", "True", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Post-attention processing.\"\"\"", "\n", "# post-attention projection (back to `d_model`)", "\n", "h", ",", "attn_vec", "=", "inputs", "\n", "\n", "attn_out", "=", "tf", ".", "einsum", "(", "'ibnd,hnd->ibh'", ",", "attn_vec", ",", "self", ".", "o", ")", "\n", "\n", "attn_out", "=", "self", ".", "dropout", "(", "attn_out", ",", "training", "=", "training", ")", "\n", "\n", "if", "residual", ":", "\n", "            ", "attn_out", "=", "attn_out", "+", "h", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "attn_out", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.call": [[188, 284], ["tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "tensorflow.concat", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "(", "h", ",", "g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", ",", "target_mapping", ",", "head_mask", ")", "=", "inputs", "\n", "\n", "if", "g", "is", "not", "None", ":", "\n", "###### Two-stream attention with relative positional encoding.", "\n", "# content based attention score", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "shape", ".", "ndims", ">", "1", ":", "\n", "                ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", ",", "h", "]", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content-based key head", "\n", "", "k_head_h", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "\n", "# content-based value head", "\n", "v_head_h", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# position-based key head", "\n", "k_head_r", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "##### h-stream", "\n", "# content-stream query head", "\n", "q_head_h", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec_h", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_h", ",", "head_mask", "]", ",", "\n", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec_h", ",", "attn_prob_h", "=", "attn_vec_h", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "[", "h", ",", "attn_vec_h", "]", ",", "training", "=", "training", ")", "\n", "\n", "##### g-stream", "\n", "# query-stream query head", "\n", "q_head_g", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "g", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "                ", "q_head_g", "=", "tf", ".", "einsum", "(", "'mbnd,mlb->lbnd'", ",", "q_head_g", ",", "target_mapping", ")", "\n", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_g", ",", "head_mask", "]", ",", "\n", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "", "attn_vec_g", "=", "tf", ".", "einsum", "(", "'lbnd,mlb->mbnd'", ",", "attn_vec_g", ",", "target_mapping", ")", "\n", "", "else", ":", "\n", "                ", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_g", ",", "head_mask", "]", ",", "\n", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "# post processing", "\n", "", "", "output_g", "=", "self", ".", "post_attention", "(", "[", "g", ",", "attn_vec_g", "]", ",", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_prob", "=", "attn_prob_h", ",", "attn_prob_g", "\n", "\n", "", "", "else", ":", "\n", "###### Multi-head attention with relative positional encoding", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "shape", ".", "ndims", ">", "1", ":", "\n", "                ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", ",", "h", "]", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content heads", "\n", "", "q_head_h", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "k_head_h", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "v_head_h", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# positional heads", "\n", "k_head_r", "=", "tf", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_h", ",", "head_mask", "]", ",", "\n", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec", ",", "attn_prob", "=", "attn_vec", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "[", "h", ",", "attn_vec", "]", ",", "training", "=", "training", ")", "\n", "output_g", "=", "None", "\n", "\n", "", "outputs", "=", "(", "output_h", ",", "output_g", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_prob", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetFeedForward.__init__": [[286, 301], ["super().__init__", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "isinstance", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "isinstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetFeedForward", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "'layer_norm'", ")", "\n", "self", ".", "layer_1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "d_inner", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'layer_1'", ")", "\n", "self", ".", "layer_2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "d_model", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'layer_2'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "if", "isinstance", "(", "config", ".", "ff_activation", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "ff_activation", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "activation_function", "=", "ACT2FN", "[", "config", ".", "ff_activation", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation_function", "=", "config", ".", "ff_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetFeedForward.call": [[302, 311], ["modeling_tf_xlnet.TFXLNetFeedForward.layer_1", "modeling_tf_xlnet.TFXLNetFeedForward.activation_function", "modeling_tf_xlnet.TFXLNetFeedForward.dropout", "modeling_tf_xlnet.TFXLNetFeedForward.layer_2", "modeling_tf_xlnet.TFXLNetFeedForward.dropout", "modeling_tf_xlnet.TFXLNetFeedForward.layer_norm"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inp", ",", "training", "=", "False", ")", ":", "\n", "        ", "output", "=", "inp", "\n", "output", "=", "self", ".", "layer_1", "(", "output", ")", "\n", "output", "=", "self", ".", "activation_function", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "output", "=", "self", ".", "layer_2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "inp", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetLayer.__init__": [[313, 318], ["super().__init__", "modeling_tf_xlnet.TFXLNetRelativeAttention", "modeling_tf_xlnet.TFXLNetFeedForward", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "rel_attn", "=", "TFXLNetRelativeAttention", "(", "config", ",", "name", "=", "'rel_attn'", ")", "\n", "self", ".", "ff", "=", "TFXLNetFeedForward", "(", "config", ",", "name", "=", "'ff'", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetLayer.call": [[319, 329], ["modeling_tf_xlnet.TFXLNetLayer.rel_attn", "modeling_tf_xlnet.TFXLNetLayer.ff", "modeling_tf_xlnet.TFXLNetLayer.ff"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "rel_attn", "(", "inputs", ",", "training", "=", "training", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "output_g", "is", "not", "None", ":", "\n", "            ", "output_g", "=", "self", ".", "ff", "(", "output_g", ",", "training", "=", "training", ")", "\n", "", "output_h", "=", "self", ".", "ff", "(", "output_h", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "(", "output_h", ",", "output_g", ")", "+", "outputs", "[", "2", ":", "]", "# Add again attentions if there are there", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetLMHead.__init__": [[332, 338], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetLMHead.build": [[339, 345], ["modeling_tf_xlnet.TFXLNetLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'bias'", ")", "\n", "super", "(", "TFXLNetLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetLMHead.call": [[346, 350], ["modeling_tf_xlnet.TFXLNetLMHead.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.__init__": [[353, 373], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Dropout", "modeling_tf_xlnet.TFXLNetLayer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "reuse_len", "=", "config", ".", "reuse_len", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "bi_data", "=", "config", ".", "bi_data", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "self", ".", "use_bfloat16", "=", "config", ".", "use_bfloat16", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "\n", "self", ".", "word_embedding", "=", "TFSharedEmbeddings", "(", "config", ".", "n_token", ",", "config", ".", "d_model", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'word_embedding'", ")", "\n", "self", ".", "layer", "=", "[", "TFXLNetLayer", "(", "config", ",", "name", "=", "'layer_._{}'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "]", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.build": [[374, 379], ["modeling_tf_utils.get_initializer", "modeling_tf_xlnet.TFXLNetMainLayer.add_weight"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", "\n", "self", ".", "mask_emb", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "1", ",", "1", ",", "self", ".", "d_model", ")", ",", "\n", "initializer", "=", "initializer", ",", "\n", "trainable", "=", "True", ",", "name", "=", "'mask_emb'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer._resize_token_embeddings": [[380, 382], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer._prune_heads": [[383, 385], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.create_mask": [[386, 414], ["tensorflow.ones", "tensorflow.matrix_band_part", "tensorflow.matrix_band_part", "tensorflow.zeros", "tensorflow.concat", "tensorflow.matrix_band_part", "tensorflow.concat"], "methods", ["None"], ["", "def", "create_mask", "(", "self", ",", "qlen", ",", "mlen", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "        ", "\"\"\"\n        Creates causal attention mask. Float mask where 1.0 indicates masked, 0.0 indicates not-masked.\n\n        Args:\n            qlen: TODO Lysandre didn't fill\n            mlen: TODO Lysandre didn't fill\n\n        ::\n\n                  same_length=False:      same_length=True:\n                  <mlen > <  qlen >       <mlen > <  qlen >\n               ^ [0 0 0 0 0 1 1 1 1]     [0 0 0 0 0 1 1 1 1]\n                 [0 0 0 0 0 0 1 1 1]     [1 0 0 0 0 0 1 1 1]\n            qlen [0 0 0 0 0 0 0 1 1]     [1 1 0 0 0 0 0 1 1]\n                 [0 0 0 0 0 0 0 0 1]     [1 1 1 0 0 0 0 0 1]\n               v [0 0 0 0 0 0 0 0 0]     [1 1 1 1 0 0 0 0 0]\n\n        \"\"\"", "\n", "attn_mask", "=", "tf", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ",", "dtype", "=", "dtype", ")", "\n", "mask_u", "=", "tf", ".", "matrix_band_part", "(", "attn_mask", ",", "0", ",", "-", "1", ")", "\n", "mask_dia", "=", "tf", ".", "matrix_band_part", "(", "attn_mask", ",", "0", ",", "0", ")", "\n", "attn_mask_pad", "=", "tf", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ",", "dtype", "=", "dtype", ")", "\n", "ret", "=", "tf", ".", "concat", "(", "[", "attn_mask_pad", ",", "mask_u", "-", "mask_dia", "]", ",", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_l", "=", "tf", ".", "matrix_band_part", "(", "attn_mask", ",", "-", "1", ",", "0", ")", "\n", "ret", "=", "tf", ".", "concat", "(", "[", "ret", "[", ":", ",", ":", "qlen", "]", "+", "mask_l", "-", "mask_dia", ",", "ret", "[", ":", ",", "qlen", ":", "]", "]", ",", "1", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.cache_mem": [[415, 426], ["tensorflow.stop_gradient", "tensorflow.concat"], "methods", ["None"], ["", "def", "cache_mem", "(", "self", ",", "curr_out", ",", "prev_mem", ")", ":", "\n", "        ", "\"\"\"cache hidden states into memory.\"\"\"", "\n", "if", "self", ".", "reuse_len", "is", "not", "None", "and", "self", ".", "reuse_len", ">", "0", ":", "\n", "            ", "curr_out", "=", "curr_out", "[", ":", "self", ".", "reuse_len", "]", "\n", "\n", "", "if", "prev_mem", "is", "None", ":", "\n", "            ", "new_mem", "=", "curr_out", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "", "else", ":", "\n", "            ", "new_mem", "=", "tf", ".", "concat", "(", "[", "prev_mem", ",", "curr_out", "]", ",", "0", ")", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "\n", "", "return", "tf", ".", "stop_gradient", "(", "new_mem", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding": [[427, 437], ["tensorflow.einsum", "tensorflow.concat", "tensorflow.tile", "tensorflow.sin", "tensorflow.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positional_embedding", "(", "pos_seq", ",", "inv_freq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "tf", ".", "einsum", "(", "'i,d->id'", ",", "pos_seq", ",", "inv_freq", ")", "\n", "pos_emb", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "sinusoid_inp", ")", ",", "tf", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "pos_emb", "=", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "pos_emb", "=", "tf", ".", "tile", "(", "pos_emb", ",", "[", "1", ",", "bsz", ",", "1", "]", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding": [[438, 485], ["tensorflow.range", "tensorflow.cast", "tensorflow.range", "tensorflow.range", "tensorflow.concat", "tensorflow.range", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "ValueError", "tensorflow.cast", "tensorflow.cast", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "tensorflow.cast", "tensorflow.clip_by_value"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding"], ["", "def", "relative_positional_encoding", "(", "self", ",", "qlen", ",", "klen", ",", "bsz", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "\"\"\"create relative positional encoding.\"\"\"", "\n", "freq_seq", "=", "tf", ".", "range", "(", "0", ",", "self", ".", "d_model", ",", "2.0", ")", "\n", "if", "dtype", "is", "not", "None", "and", "dtype", "!=", "tf", ".", "float32", ":", "\n", "            ", "freq_seq", "=", "tf", ".", "cast", "(", "freq_seq", ",", "dtype", "=", "dtype", ")", "\n", "", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "freq_seq", "/", "self", ".", "d_model", ")", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "# beg, end = klen - 1, -qlen", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "qlen", "\n", "", "elif", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "# beg, end = klen - 1, -1", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown `attn_type` {}.'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "", "if", "self", ".", "bi_data", ":", "\n", "            ", "fwd_pos_seq", "=", "tf", ".", "range", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "bwd_pos_seq", "=", "tf", ".", "range", "(", "-", "beg", ",", "-", "end", ",", "1.0", ")", "\n", "\n", "if", "dtype", "is", "not", "None", "and", "dtype", "!=", "tf", ".", "float32", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "cast", "(", "fwd_pos_seq", ",", "dtype", "=", "dtype", ")", "\n", "bwd_pos_seq", "=", "tf", ".", "cast", "(", "bwd_pos_seq", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "clip_by_value", "(", "fwd_pos_seq", ",", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "bwd_pos_seq", "=", "tf", ".", "clip_by_value", "(", "bwd_pos_seq", ",", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "\n", "", "if", "bsz", "is", "not", "None", ":", "\n", "# With bi_data, the batch size should be divisible by 2.", "\n", "                ", "assert", "bsz", "%", "2", "==", "0", "\n", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ")", "\n", "\n", "", "pos_emb", "=", "tf", ".", "concat", "(", "[", "fwd_pos_emb", ",", "bwd_pos_emb", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fwd_pos_seq", "=", "tf", ".", "range", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "if", "dtype", "is", "not", "None", "and", "dtype", "!=", "tf", ".", "float32", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "cast", "(", "fwd_pos_seq", ",", "dtype", "=", "dtype", ")", "\n", "", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "clip_by_value", "(", "fwd_pos_seq", ",", "-", "clamp_len", ",", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.call": [[486, 660], ["isinstance", "tensorflow.transpose", "modeling_tf_xlnet.TFXLNetMainLayer.word_embedding", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "enumerate", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "isinstance", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "modeling_tf_utils.shape_list", "modeling_tf_xlnet.TFXLNetMainLayer.create_mask", "tensorflow.zeros", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "tensorflow.cast", "tensorflow.tile", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "tensorflow.zeros", "tensorflow.concat", "tensorflow.cast", "tensorflow.one_hot", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "tuple.append", "tensorflow.transpose", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "ValueError", "tensorflow.eye", "tensorflow.logical_not", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "len", "tuple.append", "tuple.append", "tuple", "tuple", "len", "len", "len", "len", "len", "len", "len", "len", "tensorflow.zeros", "tensorflow.equal", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "tensorflow.transpose", "tensorflow.shape", "tensorflow.shape", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_tf_xlnet.TFXLNetMainLayer.cache_mem", "tensorflow.transpose", "tensorflow.transpose", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_tf_xlnet.TFXLNetMainLayer.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.create_mask", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetMainLayer.cache_mem"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "mems", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "mems", "\n", "perm_mask", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "perm_mask", "\n", "target_mapping", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "target_mapping", "\n", "token_type_ids", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "token_type_ids", "\n", "input_mask", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "input_mask", "\n", "head_mask", "=", "inputs", "[", "7", "]", "if", "len", "(", "inputs", ")", ">", "7", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "8", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "mems", "=", "inputs", ".", "get", "(", "'mems'", ",", "mems", ")", "\n", "perm_mask", "=", "inputs", ".", "get", "(", "'perm_mask'", ",", "perm_mask", ")", "\n", "target_mapping", "=", "inputs", ".", "get", "(", "'target_mapping'", ",", "target_mapping", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "input_mask", "=", "inputs", ".", "get", "(", "'input_mask'", ",", "input_mask", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "8", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "# the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end", "\n", "# but we want a unified interface in the library with the batch size on the first dimension", "\n", "# so we move here the first dimension (batch) to the end", "\n", "\n", "", "input_ids", "=", "tf", ".", "transpose", "(", "input_ids", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "\n", "token_type_ids", "=", "tf", ".", "transpose", "(", "token_type_ids", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "input_mask", "=", "tf", ".", "transpose", "(", "input_mask", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "tf", ".", "transpose", "(", "attention_mask", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "perm_mask", "=", "tf", ".", "transpose", "(", "perm_mask", ",", "perm", "=", "(", "1", ",", "2", ",", "0", ")", ")", "if", "perm_mask", "is", "not", "None", "else", "None", "\n", "target_mapping", "=", "tf", ".", "transpose", "(", "target_mapping", ",", "perm", "=", "(", "1", ",", "2", ",", "0", ")", ")", "if", "target_mapping", "is", "not", "None", "else", "None", "\n", "\n", "qlen", ",", "bsz", "=", "shape_list", "(", "input_ids", ")", "[", ":", "2", "]", "\n", "mlen", "=", "shape_list", "(", "mems", "[", "0", "]", ")", "[", "0", "]", "if", "mems", "is", "not", "None", "and", "mems", "[", "0", "]", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "dtype_float", "=", "tf", ".", "bfloat16", "if", "self", ".", "use_bfloat16", "else", "tf", ".", "float32", "\n", "\n", "##### Attention mask", "\n", "# causal attention mask", "\n", "if", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "            ", "attn_mask", "=", "self", ".", "create_mask", "(", "qlen", ",", "mlen", ")", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported attention type: {}'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "# data mask: input mask & perm mask", "\n", "", "assert", "input_mask", "is", "None", "or", "attention_mask", "is", "None", ",", "\"You can only use one of input_mask (uses 1 for padding) \"", "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"", "\n", "if", "input_mask", "is", "None", "and", "attention_mask", "is", "not", "None", ":", "\n", "            ", "input_mask", "=", "1.0", "-", "attention_mask", "\n", "", "if", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "+", "perm_mask", "\n", "", "elif", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "\n", "", "elif", "input_mask", "is", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "perm_mask", "\n", "", "else", ":", "\n", "            ", "data_mask", "=", "None", "\n", "\n", "", "if", "data_mask", "is", "not", "None", ":", "\n", "# all mems can be attended to", "\n", "            ", "mems_mask", "=", "tf", ".", "zeros", "(", "[", "tf", ".", "shape", "(", "data_mask", ")", "[", "0", "]", ",", "mlen", ",", "bsz", "]", ",", "\n", "dtype", "=", "dtype_float", ")", "\n", "data_mask", "=", "tf", ".", "concat", "(", "[", "mems_mask", ",", "data_mask", "]", ",", "axis", "=", "1", ")", "\n", "if", "attn_mask", "is", "None", ":", "\n", "                ", "attn_mask", "=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "                ", "attn_mask", "+=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "tf", ".", "cast", "(", "attn_mask", ">", "0", ",", "dtype", "=", "dtype_float", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "non_tgt_mask", "=", "-", "tf", ".", "eye", "(", "qlen", ",", "dtype", "=", "dtype_float", ")", "\n", "non_tgt_mask", "=", "tf", ".", "concat", "(", "[", "tf", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ",", "dtype", "=", "dtype_float", ")", ",", "non_tgt_mask", "]", ",", "axis", "=", "-", "1", ")", "\n", "non_tgt_mask", "=", "tf", ".", "cast", "(", "(", "attn_mask", "+", "non_tgt_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ">", "0", ",", "dtype", "=", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "non_tgt_mask", "=", "None", "\n", "\n", "##### Word embeddings and prepare h & g hidden states", "\n", "", "word_emb_k", "=", "self", ".", "word_embedding", "(", "input_ids", ")", "\n", "output_h", "=", "self", ".", "dropout", "(", "word_emb_k", ",", "training", "=", "training", ")", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "            ", "word_emb_q", "=", "tf", ".", "tile", "(", "self", ".", "mask_emb", ",", "[", "tf", ".", "shape", "(", "target_mapping", ")", "[", "0", "]", ",", "bsz", ",", "1", "]", ")", "\n", "# else:  # We removed the inp_q input which was same as target mapping", "\n", "#     inp_q_ext = inp_q[:, :, None]", "\n", "#     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k", "\n", "output_g", "=", "self", ".", "dropout", "(", "word_emb_q", ",", "training", "=", "training", ")", "\n", "", "else", ":", "\n", "            ", "output_g", "=", "None", "\n", "\n", "##### Segment embedding", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "# Convert `token_type_ids` to one-hot `seg_mat`", "\n", "            ", "mem_pad", "=", "tf", ".", "zeros", "(", "[", "mlen", ",", "bsz", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "cat_ids", "=", "tf", ".", "concat", "(", "[", "mem_pad", ",", "token_type_ids", "]", ",", "0", ")", "\n", "\n", "# `1` indicates not in the same segment [qlen x klen x bsz]", "\n", "seg_mat", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "logical_not", "(", "tf", ".", "equal", "(", "token_type_ids", "[", ":", ",", "None", "]", ",", "cat_ids", "[", "None", ",", ":", "]", ")", ")", ",", "\n", "tf", ".", "int32", ")", "\n", "seg_mat", "=", "tf", ".", "one_hot", "(", "seg_mat", ",", "2", ",", "dtype", "=", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "seg_mat", "=", "None", "\n", "\n", "##### Positional encoding", "\n", "", "pos_emb", "=", "self", ".", "relative_positional_encoding", "(", "qlen", ",", "klen", ",", "bsz", "=", "bsz", ",", "dtype", "=", "dtype_float", ")", "\n", "pos_emb", "=", "self", ".", "dropout", "(", "pos_emb", ",", "training", "=", "training", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "new_mems", "=", "(", ")", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "[", "None", "]", "*", "len", "(", "self", ".", "layer", ")", "\n", "\n", "", "attentions", "=", "[", "]", "\n", "hidden_states", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "# cache new mems", "\n", "            ", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "                ", "new_mems", "=", "new_mems", "+", "(", "self", ".", "cache_mem", "(", "output_h", ",", "mems", "[", "i", "]", ")", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "outputs", "=", "layer_module", "(", "[", "output_h", ",", "output_g", ",", "non_tgt_mask", ",", "attn_mask", ",", "\n", "pos_emb", ",", "seg_mat", ",", "mems", "[", "i", "]", ",", "target_mapping", ",", "\n", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "# Add last hidden state", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "output", "=", "self", ".", "dropout", "(", "output_g", "if", "output_g", "is", "not", "None", "else", "output_h", ",", "training", "=", "training", ")", "\n", "\n", "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)", "\n", "outputs", "=", "(", "tf", ".", "transpose", "(", "output", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", ",", ")", "\n", "\n", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "new_mems", ",", ")", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "if", "output_g", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "tf", ".", "transpose", "(", "h", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "for", "hs", "in", "hidden_states", "for", "h", "in", "hs", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "tf", ".", "transpose", "(", "hs", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "for", "hs", "in", "hidden_states", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "attentions", "=", "tuple", "(", "tf", ".", "transpose", "(", "t", ",", "perm", "=", "(", "2", ",", "3", ",", "0", ",", "1", ")", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# outputs, (new_mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetModel.__init__": [[799, 802], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetModel.call": [[803, 806], ["modeling_tf_xlnet.TFXLNetModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetLMHeadModel.__init__": [[848, 852], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer", "modeling_tf_xlnet.TFXLNetLMHead"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "lm_loss", "=", "TFXLNetLMHead", "(", "config", ",", "self", ".", "transformer", ".", "word_embedding", ",", "name", "=", "'lm_loss'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetLMHeadModel.call": [[853, 861], ["modeling_tf_xlnet.TFXLNetLMHeadModel.transformer", "modeling_tf_xlnet.TFXLNetLMHeadModel.lm_loss"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_state", "=", "transformer_outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "lm_loss", "(", "hidden_state", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# return logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetForSequenceClassification.__init__": [[896, 905], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer", "modeling_tf_utils.TFSequenceSummary", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "sequence_summary", "=", "TFSequenceSummary", "(", "config", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'sequence_summary'", ")", "\n", "self", ".", "logits_proj", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'logits_proj'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetForSequenceClassification.call": [[906, 916], ["modeling_tf_xlnet.TFXLNetForSequenceClassification.transformer", "modeling_tf_xlnet.TFXLNetForSequenceClassification.sequence_summary", "modeling_tf_xlnet.TFXLNetForSequenceClassification.logits_proj"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# return logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.__init__": [[954, 960], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "num_labels", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'qa_outputs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.call": [[961, 974], ["modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.transformer", "modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# start_logits, end_logits, (mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.gelu": [[43, 51], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function.\n        XLNet is using OpenAI GPT's gelu\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "\n", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_xlnet.swish": [[53, 55], ["tensorflow.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "tf", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_openai.OpenAIGPTConfig.__init__": [[59, 117], ["configuration_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "40478", ",", "\n", "n_positions", "=", "512", ",", "\n", "n_ctx", "=", "512", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "afn", "=", "\"gelu\"", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "predict_special_tokens", "=", "True", ",", "\n", "\n", "num_labels", "=", "1", ",", "\n", "summary_type", "=", "'cls_index'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs OpenAIGPTConfig.\n        \"\"\"", "\n", "super", "(", "OpenAIGPTConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "afn", "=", "afn", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "predict_special_tokens", "=", "predict_special_tokens", "\n", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_openai.OpenAIGPTConfig.max_position_embeddings": [[120, 123], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_openai.OpenAIGPTConfig.hidden_size": [[124, 127], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_openai.OpenAIGPTConfig.num_attention_heads": [[128, 131], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_openai.OpenAIGPTConfig.num_hidden_layers": [[132, 135], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.__init__": [[28, 47], ["super().__init__", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "keep_order", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAdaptiveSoftmaxMask", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "self", ".", "keep_order", "=", "keep_order", "\n", "\n", "self", ".", "out_layers", "=", "[", "]", "\n", "self", ".", "out_projs", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build": [[48, 98], ["super().build", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "range", "range", "len", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_layers.append", "len", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_projs.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_layers.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_projs.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_projs.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "n_clusters", ">", "0", ":", "\n", "            ", "self", ".", "cluster_weight", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_clusters", ",", "self", ".", "d_embed", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'cluster_weight'", ")", "\n", "self", ".", "cluster_bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_clusters", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'cluster_bias'", ")", "\n", "\n", "", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "                    ", "weight", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "d_embed", ",", "self", ".", "d_proj", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'out_projs_._{}'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "out_projs", ".", "append", "(", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "None", ")", "\n", "", "weight", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_token", ",", "self", ".", "d_embed", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'out_layers_._{}_._weight'", ".", "format", "(", "i", ")", ")", "\n", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_token", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'out_layers_._{}_._bias'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "out_layers", ".", "append", "(", "(", "weight", ",", "bias", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "self", ".", "d_embed", "//", "(", "self", ".", "div_val", "**", "i", ")", "\n", "\n", "weight", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "d_emb_i", ",", "self", ".", "d_proj", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'out_projs_._{}'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "out_projs", ".", "append", "(", "weight", ")", "\n", "weight", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'out_layers_._{}_._weight'", ".", "format", "(", "i", ")", ")", "\n", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "r_idx", "-", "l_idx", ",", ")", ",", "\n", "initializer", "=", "'zeros'", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "'out_layers_._{}_._bias'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "out_layers", ".", "append", "(", "(", "weight", ",", "bias", ")", ")", "\n", "", "", "super", "(", "TFAdaptiveSoftmaxMask", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit": [[99, 105], ["tensorflow.einsum", "tensorflow.einsum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_logit", "(", "x", ",", "W", ",", "b", ",", "proj", "=", "None", ")", ":", "\n", "        ", "y", "=", "x", "\n", "if", "proj", "is", "not", "None", ":", "\n", "            ", "y", "=", "tf", ".", "einsum", "(", "'ibd,ed->ibe'", ",", "y", ",", "proj", ")", "\n", "", "return", "tf", ".", "einsum", "(", "'ibd,nd->ibn'", ",", "y", ",", "W", ")", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob": [[106, 112], ["tensorflow.shape", "tensorflow.range", "tensorflow.stack", "tensorflow.gather_nd"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_gather_logprob", "(", "logprob", ",", "target", ")", ":", "\n", "        ", "lp_size", "=", "tf", ".", "shape", "(", "logprob", ")", "\n", "r", "=", "tf", ".", "range", "(", "lp_size", "[", "0", "]", ")", "\n", "idx", "=", "tf", ".", "stack", "(", "[", "r", ",", "target", "]", ",", "1", ")", "\n", "return", "tf", ".", "gather_nd", "(", "logprob", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.call": [[113, 176], ["tensorflow.get_variable", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "tensorflow.nn.log_softmax", "modeling_tf_utils.shape_list", "tensorflow.zeros", "range", "tensorflow.concat", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_loss", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_metric", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "len", "tensorflow.reduce_mean", "tensorflow.zeros_initializer", "tensorflow.where", "tensorflow.concat", "tensorflow.concat", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "tensorflow.nn.log_softmax", "tensorflow.concat.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "tensorflow.nn.log_softmax", "tensorflow.concat.append", "tensorflow.scatter_nd", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob", "tensorflow.cast", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob"], ["", "def", "call", "(", "self", ",", "inputs", ",", "return_mean", "=", "True", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden", ",", "target", "=", "inputs", "\n", "head_logprob", "=", "0", "\n", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "softmax_b", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "n_token", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "output", "=", "self", ".", "_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", "[", "0", "]", ",", "self", ".", "out_layers", "[", "0", "]", "[", "1", "]", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "target", ",", "logits", "=", "output", ")", "\n", "", "out", "=", "tf", ".", "nn", ".", "log_softmax", "(", "output", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "hidden_sizes", "=", "shape_list", "(", "hidden", ")", "\n", "out", "=", "[", "]", "\n", "loss", "=", "tf", ".", "zeros", "(", "hidden_sizes", "[", ":", "2", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "if", "target", "is", "not", "None", ":", "\n", "                    ", "mask", "=", "(", "target", ">=", "l_idx", ")", "&", "(", "target", "<", "r_idx", ")", "\n", "mask_idx", "=", "tf", ".", "where", "(", "mask", ")", "\n", "cur_target", "=", "tf", ".", "boolean_mask", "(", "target", ",", "mask", ")", "-", "l_idx", "\n", "\n", "", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "cur_W", "=", "self", ".", "out_layers", "[", "0", "]", "[", "0", "]", "[", "l_idx", ":", "r_idx", "]", "\n", "cur_b", "=", "self", ".", "out_layers", "[", "0", "]", "[", "1", "]", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "cur_W", "=", "self", ".", "out_layers", "[", "i", "]", "[", "0", "]", "\n", "cur_b", "=", "self", ".", "out_layers", "[", "i", "]", "[", "1", "]", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "cur_W", "=", "tf", ".", "concat", "(", "[", "cur_W", ",", "self", ".", "cluster_weight", "]", ",", "0", ")", "\n", "cur_b", "=", "tf", ".", "concat", "(", "[", "cur_b", ",", "self", ".", "cluster_bias", "]", ",", "0", ")", "\n", "\n", "head_logit", "=", "self", ".", "_logit", "(", "hidden", ",", "cur_W", ",", "cur_b", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "head_logprob", "=", "tf", ".", "nn", ".", "log_softmax", "(", "head_logit", ")", "\n", "out", ".", "append", "(", "head_logprob", "[", "...", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                        ", "cur_head_logprob", "=", "tf", ".", "boolean_mask", "(", "head_logprob", ",", "mask", ")", "\n", "cur_logprob", "=", "self", ".", "_gather_logprob", "(", "cur_head_logprob", ",", "cur_target", ")", "\n", "", "", "else", ":", "\n", "                    ", "tail_logit", "=", "self", ".", "_logit", "(", "hidden", ",", "cur_W", ",", "cur_b", ",", "self", ".", "out_projs", "[", "i", "]", ")", "\n", "tail_logprob", "=", "tf", ".", "nn", ".", "log_softmax", "(", "tail_logit", ")", "\n", "cluster_prob_idx", "=", "self", ".", "cutoffs", "[", "0", "]", "+", "i", "-", "1", "# No probability for the head cluster", "\n", "logprob_i", "=", "head_logprob", "[", "...", ",", "cluster_prob_idx", ",", "None", "]", "+", "tail_logprob", "\n", "out", ".", "append", "(", "logprob_i", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                        ", "cur_head_logprob", "=", "tf", ".", "boolean_mask", "(", "head_logprob", ",", "mask", ")", "\n", "cur_tail_logprob", "=", "tf", ".", "boolean_mask", "(", "tail_logprob", ",", "mask", ")", "\n", "cur_logprob", "=", "self", ".", "_gather_logprob", "(", "cur_tail_logprob", ",", "cur_target", ")", "\n", "cur_logprob", "+=", "cur_head_logprob", "[", ":", ",", "self", ".", "cutoff_ends", "[", "1", "]", "+", "i", "-", "1", "]", "\n", "", "", "if", "target", "is", "not", "None", ":", "\n", "                    ", "loss", "+=", "tf", ".", "scatter_nd", "(", "mask_idx", ",", "-", "cur_logprob", ",", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "loss", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "", "", "out", "=", "tf", ".", "concat", "(", "out", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "if", "target", "is", "not", "None", ":", "\n", "            ", "if", "return_mean", ":", "\n", "                ", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "# Add the training-time loss value to the layer using `self.add_loss()`.", "\n", "", "self", ".", "add_loss", "(", "loss", ")", "\n", "\n", "# Log the loss as a metric (we could log arbitrary metrics,", "\n", "# including different metrics for training and inference.", "\n", "self", ".", "add_metric", "(", "loss", ",", "name", "=", "self", ".", "name", ",", "aggregation", "=", "'mean'", "if", "return_mean", "else", "''", ")", "\n", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.__init__": [[59, 76], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "set"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "TFConv1D", "(", "n_state", "*", "3", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_attn'", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_proj'", ")", "\n", "self", ".", "attn_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.prune_heads": [[77, 79], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.causal_attention_mask": [[80, 89], ["tensorflow.range", "tensorflow.cast", "tensorflow.range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"1's in the lower triangle, counting from the lower right corner.\n        Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n        \"\"\"", "\n", "i", "=", "tf", ".", "range", "(", "nd", ")", "[", ":", ",", "None", "]", "\n", "j", "=", "tf", ".", "range", "(", "ns", ")", "\n", "m", "=", "i", ">=", "j", "-", "ns", "+", "nd", "\n", "return", "tf", ".", "cast", "(", "m", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention._attn": [[90, 119], ["tensorflow.matmul", "modeling_tf_utils.shape_list", "modeling_tf_gpt2.TFAttention.causal_attention_mask", "tensorflow.reshape", "tensorflow.nn.softmax", "modeling_tf_gpt2.TFAttention.attn_dropout", "tensorflow.cast", "tensorflow.matmul", "outputs.append", "tensorflow.math.sqrt", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.causal_attention_mask"], ["", "def", "_attn", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "q", ",", "k", ",", "v", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "# q, k, v have shape [batch, heads, sequence, features]", "\n", "w", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "dk", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "k", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "# scale attention_scores", "\n", "w", "=", "w", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "# w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.", "\n", "", "_", ",", "_", ",", "nd", ",", "ns", "=", "shape_list", "(", "w", ")", "\n", "b", "=", "self", ".", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", "=", "w", ".", "dtype", ")", "\n", "b", "=", "tf", ".", "reshape", "(", "b", ",", "[", "1", ",", "1", ",", "nd", ",", "ns", "]", ")", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "tf", ".", "nn", ".", "softmax", "(", "w", ",", "axis", "=", "-", "1", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "tf", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.merge_heads": [[120, 125], ["tensorflow.transpose", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "2", "]", "+", "[", "x_shape", "[", "-", "2", "]", "*", "x_shape", "[", "-", "1", "]", "]", "\n", "return", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.split_heads": [[126, 131], ["modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "split_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "n_head", ",", "x_shape", "[", "-", "1", "]", "//", "self", ".", "n_head", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFAttention.call": [[132, 155], ["modeling_tf_gpt2.TFAttention.c_attn", "tensorflow.split", "modeling_tf_gpt2.TFAttention.split_heads", "modeling_tf_gpt2.TFAttention.split_heads", "modeling_tf_gpt2.TFAttention.split_heads", "tensorflow.stack", "modeling_tf_gpt2.TFAttention._attn", "modeling_tf_gpt2.TFAttention.merge_heads", "modeling_tf_gpt2.TFAttention.c_proj", "modeling_tf_gpt2.TFAttention.resid_dropout", "tensorflow.unstack", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.merge_heads"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "tf", ".", "split", "(", "x", ",", "3", ",", "axis", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "tf", ".", "unstack", "(", "layer_past", ",", "axis", "=", "1", ")", "\n", "key", "=", "tf", ".", "concat", "(", "[", "past_key", ",", "key", "]", ",", "axis", "=", "-", "2", ")", "\n", "value", "=", "tf", ".", "concat", "(", "[", "past_value", ",", "value", "]", ",", "axis", "=", "-", "2", ")", "\n", "", "present", "=", "tf", ".", "stack", "(", "[", "key", ",", "value", "]", ",", "axis", "=", "1", ")", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "[", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFMLP.__init__": [[158, 165], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMLP", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_fc'", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "nx", ",", "n_state", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'c_proj'", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFMLP.call": [[166, 171], ["modeling_tf_gpt2.TFMLP.act", "modeling_tf_gpt2.TFMLP.c_proj", "modeling_tf_gpt2.TFMLP.dropout", "modeling_tf_gpt2.TFMLP.c_fc"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ",", "training", "=", "False", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "h2", "=", "self", ".", "dropout", "(", "h2", ",", "training", "=", "training", ")", "\n", "return", "h2", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFBlock.__init__": [[174, 181], ["super().__init__", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_gpt2.TFAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_gpt2.TFMLP"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBlock", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "'ln_1'", ")", "\n", "self", ".", "attn", "=", "TFAttention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ",", "name", "=", "'attn'", ")", "\n", "self", ".", "ln_2", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "'ln_2'", ")", "\n", "self", ".", "mlp", "=", "TFMLP", "(", "4", "*", "nx", ",", "config", ",", "name", "=", "'mlp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFBlock.call": [[182, 196], ["modeling_tf_gpt2.TFBlock.ln_1", "modeling_tf_gpt2.TFBlock.attn", "modeling_tf_gpt2.TFBlock.ln_2", "modeling_tf_gpt2.TFBlock.mlp"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "a", "=", "self", ".", "ln_1", "(", "x", ")", "\n", "output_attn", "=", "self", ".", "attn", "(", "[", "a", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "x", "=", "x", "+", "a", "\n", "\n", "m", "=", "self", ".", "ln_2", "(", "x", ")", "\n", "m", "=", "self", ".", "mlp", "(", "m", ",", "training", "=", "training", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2MainLayer.__init__": [[199, 221], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_gpt2.TFBlock", "modeling_tf_utils.get_initializer", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2MainLayer", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "n_layer", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "\n", "self", ".", "wte", "=", "TFSharedEmbeddings", "(", "config", ".", "vocab_size", ",", "\n", "config", ".", "hidden_size", ",", "\n", "initializer_range", "=", "config", ".", "initializer_range", ",", "\n", "name", "=", "'wte'", ")", "\n", "self", ".", "wpe", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "config", ".", "n_positions", ",", "\n", "config", ".", "n_embd", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "'wpe'", ")", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "[", "TFBlock", "(", "config", ".", "n_ctx", ",", "\n", "config", ",", "\n", "scale", "=", "True", ",", "\n", "name", "=", "'h_._{}'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "]", "\n", "self", ".", "ln_f", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "'ln_f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2MainLayer._resize_token_embeddings": [[222, 224], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2MainLayer._prune_heads": [[225, 230], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2MainLayer.call": [[231, 336], ["isinstance", "modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.reshape", "modeling_tf_gpt2.TFGPT2MainLayer.wte", "modeling_tf_gpt2.TFGPT2MainLayer.wpe", "modeling_tf_gpt2.TFGPT2MainLayer.drop", "enumerate", "modeling_tf_gpt2.TFGPT2MainLayer.ln_f", "tensorflow.reshape", "isinstance", "tensorflow.cast", "tensorflow.reshape", "modeling_tf_gpt2.TFGPT2MainLayer.wte", "zip", "block", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "len", "modeling_tf_utils.shape_list", "tensorflow.range", "tuple.append", "len", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "past", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "past", "\n", "attention_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "past", "=", "inputs", ".", "get", "(", "'past'", ",", "past", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "shape_list", "(", "past", "[", "0", "]", "[", "0", "]", ")", "[", "-", "2", "]", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "past_length", ",", "shape_list", "(", "input_ids", ")", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "not", "head_mask", "is", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "[", "-", "1", ",", "input_shape", "[", "-", "1", "]", "]", ")", "\n", "position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "[", "-", "1", ",", "shape_list", "(", "position_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ",", "mode", "=", "'embedding'", ")", "\n", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "[", "-", "1", ",", "shape_list", "(", "token_type_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ",", "mode", "=", "'embedding'", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "[", "shape_list", "(", "hidden_states", ")", "[", "-", "1", "]", "]", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "[", "hidden_states", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", "presents", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "[", "-", "1", "]", "+", "shape_list", "(", "all_attentions", "[", "0", "]", ")", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "tf", ".", "reshape", "(", "t", ",", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2Model.__init__": [[444, 447], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_gpt2.TFGPT2MainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2Model", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFGPT2MainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2Model.call": [[448, 451], ["modeling_tf_gpt2.TFGPT2Model.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2LMHeadModel.__init__": [[485, 488], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_gpt2.TFGPT2MainLayer"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFGPT2MainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2LMHeadModel.call": [[489, 498], ["modeling_tf_gpt2.TFGPT2LMHeadModel.transformer", "modeling_tf_gpt2.TFGPT2LMHeadModel.transformer.wte"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "wte", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.__init__": [[554, 558], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_gpt2.TFGPT2MainLayer", "modeling_tf_utils.TFSequenceSummary"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2DoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFGPT2MainLayer", "(", "config", ",", "name", "=", "'transformer'", ")", "\n", "self", ".", "multiple_choice_head", "=", "TFSequenceSummary", "(", "config", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "'multiple_choice_head'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.call": [[559, 605], ["isinstance", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_gpt2.TFGPT2DoubleHeadsModel.transformer", "tensorflow.reshape", "modeling_tf_gpt2.TFGPT2DoubleHeadsModel.transformer.wte", "modeling_tf_gpt2.TFGPT2DoubleHeadsModel.multiple_choice_head", "tensorflow.squeeze", "isinstance", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "len", "len", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "mc_token_ids", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "past", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "past", "\n", "attention_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "head_mask", "\n", "mc_token_ids", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "mc_token_ids", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "'input_ids'", ")", "\n", "past", "=", "inputs", ".", "get", "(", "'past'", ",", "past", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "'attention_mask'", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "'token_type_ids'", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "'position_ids'", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "'head_mask'", ",", "head_mask", ")", "\n", "mc_token_ids", "=", "inputs", ".", "get", "(", "'mc_token_ids'", ",", "mc_token_ids", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "input_shapes", "=", "shape_list", "(", "input_ids", ")", "\n", "\n", "seq_length", "=", "input_shapes", "[", "-", "1", "]", "\n", "\n", "flat_input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "\n", "flat_attention_mask", "=", "tf", ".", "reshape", "(", "attention_mask", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "flat_inputs", "=", "[", "flat_input_ids", ",", "past", ",", "flat_attention_mask", ",", "flat_token_type_ids", ",", "flat_position_ids", ",", "head_mask", "]", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "flat_inputs", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "input_shapes", "+", "shape_list", "(", "hidden_states", ")", "[", "-", "1", ":", "]", ")", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "wte", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "[", "hidden_states", ",", "mc_token_ids", "]", ",", "training", "=", "training", ")", "\n", "\n", "mc_logits", "=", "tf", ".", "squeeze", "(", "mc_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_gpt2.gelu": [[44, 56], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "\n", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.__init__": [[81, 89], ["tokenization_gpt2.GPT2Tokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "errors", "=", "'replace'", ",", "bos_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "sep_token", "=", "\"</s>\"", ",", "\n", "cls_token", "=", "\"<s>\"", ",", "unk_token", "=", "\"<unk>\"", ",", "pad_token", "=", "'<pad>'", ",", "mask_token", "=", "'<mask>'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RobertaTokenizer", ",", "self", ")", ".", "__init__", "(", "vocab_file", "=", "vocab_file", ",", "merges_file", "=", "merges_file", ",", "errors", "=", "errors", ",", "\n", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "cls_token", "=", "cls_token", ",", "pad_token", "=", "pad_token", ",", "\n", "mask_token", "=", "mask_token", ",", "**", "kwargs", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "4", "# take into account special tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens": [[90, 103], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.get_special_tokens_mask": [[104, 128], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n        \"\"\"", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", ",", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.create_token_type_ids_from_sequences": [[129, 144], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A RoBERTa sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_pytorch_checkpoint_to_tf2.convert_pt_checkpoint_to_tf": [[91, 134], ["config_class.from_json_file", "print", "model_class", "transformers.load_pytorch_checkpoint_in_tf2_model", "print", "transformers.load_pytorch_checkpoint_in_tf2_model.save_weights", "ValueError", "transformers.cached_path", "transformers.cached_path", "tensorflow.constant", "transformers.load_pytorch_checkpoint_in_tf2_model.", "pt_model_class.from_pretrained", "torch.tensor", "pto[].detach().numpy", "tfo[].numpy", "np.amax", "print", "str", "torch.no_grad", "pt_model_class.from_pretrained.", "np.abs", "list", "torch.load", "pto[].detach", "MODEL_CLASSES.keys"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["def", "convert_pt_checkpoint_to_tf", "(", "model_type", ",", "pytorch_checkpoint_path", ",", "config_file", ",", "tf_dump_path", ",", "compare_with_pt_model", "=", "False", ",", "use_cached_models", "=", "True", ")", ":", "\n", "    ", "if", "model_type", "not", "in", "MODEL_CLASSES", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unrecognized model type, should be one of {}.\"", ".", "format", "(", "list", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "", "config_class", ",", "model_class", ",", "pt_model_class", ",", "aws_model_maps", ",", "aws_config_map", "=", "MODEL_CLASSES", "[", "model_type", "]", "\n", "\n", "# Initialise TF model", "\n", "if", "config_file", "in", "aws_config_map", ":", "\n", "        ", "config_file", "=", "cached_path", "(", "aws_config_map", "[", "config_file", "]", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "", "config", "=", "config_class", ".", "from_json_file", "(", "config_file", ")", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "config", ".", "output_attentions", "=", "True", "\n", "print", "(", "\"Building TensorFlow model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "tf_model", "=", "model_class", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "if", "pytorch_checkpoint_path", "in", "aws_model_maps", ":", "\n", "        ", "pytorch_checkpoint_path", "=", "cached_path", "(", "aws_model_maps", "[", "pytorch_checkpoint_path", "]", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "# Load PyTorch checkpoint in tf2 model:", "\n", "", "tf_model", "=", "load_pytorch_checkpoint_in_tf2_model", "(", "tf_model", ",", "pytorch_checkpoint_path", ")", "\n", "\n", "if", "compare_with_pt_model", ":", "\n", "        ", "inputs_list", "=", "[", "[", "7", ",", "6", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "2", ",", "3", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "4", ",", "5", "]", "]", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "inputs_list", ")", "\n", "tfo", "=", "tf_model", "(", "tf_inputs", ",", "training", "=", "False", ")", "# build the network", "\n", "\n", "pt_model", "=", "pt_model_class", ".", "from_pretrained", "(", "None", ",", "\n", "config", "=", "config", ",", "\n", "state_dict", "=", "torch", ".", "load", "(", "pytorch_checkpoint_path", ",", "\n", "map_location", "=", "'cpu'", ")", ")", "\n", "pt_inputs", "=", "torch", ".", "tensor", "(", "inputs_list", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pto", "=", "pt_model", "(", "pt_inputs", ")", "\n", "\n", "", "np_pt", "=", "pto", "[", "0", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "np_tf", "=", "tfo", "[", "0", "]", ".", "numpy", "(", ")", "\n", "diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "np_pt", "-", "np_tf", ")", ")", "\n", "print", "(", "\"Max absolute difference between models outputs {}\"", ".", "format", "(", "diff", ")", ")", "\n", "assert", "diff", "<=", "2e-2", ",", "\"Error, model absolute difference is >2e-2\"", "\n", "\n", "# Save pytorch-model", "\n", "", "print", "(", "\"Save TensorFlow model to {}\"", ".", "format", "(", "tf_dump_path", ")", ")", "\n", "tf_model", ".", "save_weights", "(", "tf_dump_path", ",", "save_format", "=", "'h5'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_pytorch_checkpoint_to_tf2.convert_all_pt_checkpoints_to_tf": [[136, 192], ["os.path.isdir", "enumerate", "list", "print", "print", "print", "enumerate", "MODEL_CLASSES.keys", "ValueError", "list", "zip", "print", "print", "print", "os.path.isfile", "convert_pytorch_checkpoint_to_tf2.convert_pt_checkpoint_to_tf", "os.remove", "os.remove", "len", "aws_model_maps.keys", "transformers.cached_path", "transformers.cached_path", "transformers.cached_path", "transformers.cached_path", "list", "print", "print", "len", "os.path.join", "MODEL_CLASSES.keys"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_pytorch_checkpoint_to_tf2.convert_pt_checkpoint_to_tf", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.cached_path"], ["", "def", "convert_all_pt_checkpoints_to_tf", "(", "args_model_type", ",", "tf_dump_path", ",", "model_shortcut_names_or_path", "=", "None", ",", "config_shortcut_names_or_path", "=", "None", ",", "\n", "compare_with_pt_model", "=", "False", ",", "use_cached_models", "=", "False", ",", "only_convert_finetuned_models", "=", "False", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "isdir", "(", "args", ".", "tf_dump_path", ")", ",", "\"--tf_dump_path should be a directory\"", "\n", "\n", "if", "args_model_type", "is", "None", ":", "\n", "        ", "model_types", "=", "list", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_types", "=", "[", "args_model_type", "]", "\n", "\n", "", "for", "j", ",", "model_type", "in", "enumerate", "(", "model_types", ",", "start", "=", "1", ")", ":", "\n", "        ", "print", "(", "\"=\"", "*", "100", ")", "\n", "print", "(", "\" Converting model type {}/{}: {}\"", ".", "format", "(", "j", ",", "len", "(", "model_types", ")", ",", "model_type", ")", ")", "\n", "print", "(", "\"=\"", "*", "100", ")", "\n", "if", "model_type", "not", "in", "MODEL_CLASSES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unrecognized model type {}, should be one of {}.\"", ".", "format", "(", "model_type", ",", "list", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "", "config_class", ",", "model_class", ",", "pt_model_class", ",", "aws_model_maps", ",", "aws_config_map", "=", "MODEL_CLASSES", "[", "model_type", "]", "\n", "\n", "if", "model_shortcut_names_or_path", "is", "None", ":", "\n", "            ", "model_shortcut_names_or_path", "=", "list", "(", "aws_model_maps", ".", "keys", "(", ")", ")", "\n", "", "if", "config_shortcut_names_or_path", "is", "None", ":", "\n", "            ", "config_shortcut_names_or_path", "=", "model_shortcut_names_or_path", "\n", "\n", "", "for", "i", ",", "(", "model_shortcut_name", ",", "config_shortcut_name", ")", "in", "enumerate", "(", "\n", "zip", "(", "model_shortcut_names_or_path", ",", "config_shortcut_names_or_path", ")", ",", "start", "=", "1", ")", ":", "\n", "            ", "print", "(", "\"-\"", "*", "100", ")", "\n", "if", "'-squad'", "in", "model_shortcut_name", "or", "'-mrpc'", "in", "model_shortcut_name", "or", "'-mnli'", "in", "model_shortcut_name", ":", "\n", "                ", "if", "not", "only_convert_finetuned_models", ":", "\n", "                    ", "print", "(", "\"    Skipping finetuned checkpoint {}\"", ".", "format", "(", "model_shortcut_name", ")", ")", "\n", "continue", "\n", "", "model_type", "=", "model_shortcut_name", "\n", "", "elif", "only_convert_finetuned_models", ":", "\n", "                ", "print", "(", "\"    Skipping not finetuned checkpoint {}\"", ".", "format", "(", "model_shortcut_name", ")", ")", "\n", "continue", "\n", "", "print", "(", "\"    Converting checkpoint {}/{}: {} - model_type {}\"", ".", "format", "(", "i", ",", "len", "(", "aws_config_map", ")", ",", "model_shortcut_name", ",", "model_type", ")", ")", "\n", "print", "(", "\"-\"", "*", "100", ")", "\n", "\n", "if", "config_shortcut_name", "in", "aws_config_map", ":", "\n", "                ", "config_file", "=", "cached_path", "(", "aws_config_map", "[", "config_shortcut_name", "]", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "", "else", ":", "\n", "                ", "config_file", "=", "cached_path", "(", "config_shortcut_name", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "\n", "", "if", "model_shortcut_name", "in", "aws_model_maps", ":", "\n", "                ", "model_file", "=", "cached_path", "(", "aws_model_maps", "[", "model_shortcut_name", "]", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "", "else", ":", "\n", "                ", "model_file", "=", "cached_path", "(", "model_shortcut_name", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "model_shortcut_name", ")", ":", "\n", "                ", "model_shortcut_name", "=", "'converted_model'", "\n", "", "convert_pt_checkpoint_to_tf", "(", "model_type", "=", "model_type", ",", "\n", "pytorch_checkpoint_path", "=", "model_file", ",", "\n", "config_file", "=", "config_file", ",", "\n", "tf_dump_path", "=", "os", ".", "path", ".", "join", "(", "tf_dump_path", ",", "model_shortcut_name", "+", "'-tf_model.h5'", ")", ",", "\n", "compare_with_pt_model", "=", "compare_with_pt_model", ")", "\n", "os", ".", "remove", "(", "config_file", ")", "\n", "os", ".", "remove", "(", "model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf": [[26, 93], ["model.state_dict", "tensorflow.reset_default_graph", "os.path.isdir", "os.makedirs", "iter", "tensorflow.dtypes.as_dtype", "tensorflow.get_variable", "session.run", "session.run", "tensorflow.Session", "tensorflow.train.Saver", "tf.train.Saver.save", "name.replace.replace", "tensorflow.variables_initializer", "convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf.to_tf_var_name"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.run", "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.run"], ["def", "convert_pytorch_checkpoint_to_tf", "(", "model", ":", "BertModel", ",", "ckpt_dir", ":", "str", ",", "model_name", ":", "str", ")", ":", "\n", "\n", "    ", "\"\"\"\n    :param model:BertModel Pytorch model instance to be converted\n    :param ckpt_dir: Tensorflow model directory\n    :param model_name: model name\n    :return:\n\n    Currently supported HF models:\n        Y BertModel\n        N BertForMaskedLM\n        N BertForPreTraining\n        N BertForMultipleChoice\n        N BertForNextSentencePrediction\n        N BertForSequenceClassification\n        N BertForQuestionAnswering\n    \"\"\"", "\n", "\n", "tensors_to_transpose", "=", "(", "\n", "\"dense.weight\"", ",", "\n", "\"attention.self.query\"", ",", "\n", "\"attention.self.key\"", ",", "\n", "\"attention.self.value\"", "\n", ")", "\n", "\n", "var_map", "=", "(", "\n", "(", "'layer.'", ",", "'layer_'", ")", ",", "\n", "(", "'word_embeddings.weight'", ",", "'word_embeddings'", ")", ",", "\n", "(", "'position_embeddings.weight'", ",", "'position_embeddings'", ")", ",", "\n", "(", "'token_type_embeddings.weight'", ",", "'token_type_embeddings'", ")", ",", "\n", "(", "'.'", ",", "'/'", ")", ",", "\n", "(", "'LayerNorm/weight'", ",", "'LayerNorm/gamma'", ")", ",", "\n", "(", "'LayerNorm/bias'", ",", "'LayerNorm/beta'", ")", ",", "\n", "(", "'weight'", ",", "'kernel'", ")", "\n", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "ckpt_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "ckpt_dir", ")", "\n", "\n", "", "state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "\n", "def", "to_tf_var_name", "(", "name", ":", "str", ")", ":", "\n", "        ", "for", "patt", ",", "repl", "in", "iter", "(", "var_map", ")", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "patt", ",", "repl", ")", "\n", "", "return", "'bert/{}'", ".", "format", "(", "name", ")", "\n", "\n", "", "def", "create_tf_var", "(", "tensor", ":", "np", ".", "ndarray", ",", "name", ":", "str", ",", "session", ":", "tf", ".", "Session", ")", ":", "\n", "        ", "tf_dtype", "=", "tf", ".", "dtypes", ".", "as_dtype", "(", "tensor", ".", "dtype", ")", "\n", "tf_var", "=", "tf", ".", "get_variable", "(", "dtype", "=", "tf_dtype", ",", "shape", "=", "tensor", ".", "shape", ",", "name", "=", "name", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "session", ".", "run", "(", "tf", ".", "variables_initializer", "(", "[", "tf_var", "]", ")", ")", "\n", "session", ".", "run", "(", "tf_var", ")", "\n", "return", "tf_var", "\n", "\n", "", "tf", ".", "reset_default_graph", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "for", "var_name", "in", "state_dict", ":", "\n", "            ", "tf_name", "=", "to_tf_var_name", "(", "var_name", ")", "\n", "torch_tensor", "=", "state_dict", "[", "var_name", "]", ".", "numpy", "(", ")", "\n", "if", "any", "(", "[", "x", "in", "var_name", "for", "x", "in", "tensors_to_transpose", "]", ")", ":", "\n", "                ", "torch_tensor", "=", "torch_tensor", ".", "T", "\n", "", "tf_var", "=", "create_tf_var", "(", "tensor", "=", "torch_tensor", ",", "name", "=", "tf_name", ",", "session", "=", "session", ")", "\n", "tf", ".", "keras", ".", "backend", ".", "set_value", "(", "tf_var", ",", "torch_tensor", ")", "\n", "tf_weight", "=", "session", ".", "run", "(", "tf_var", ")", "\n", "print", "(", "\"Successfully created {}: {}\"", ".", "format", "(", "tf_name", ",", "np", ".", "allclose", "(", "tf_weight", ",", "torch_tensor", ")", ")", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "os", ".", "path", ".", "join", "(", "ckpt_dir", ",", "model_name", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "+", "\".ckpt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_bert_pytorch_checkpoint_to_original_tf.main": [[95, 126], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "transformers.BertModel.from_pretrained", "convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf", "torch.load"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf"], ["", "", "def", "main", "(", "raw_args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"model name e.g. bert-base-uncased\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Directory containing pytorch model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pytorch_model_path\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"/path/to/<pytorch-model-name>.bin\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tf_cache_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Directory in which to save tensorflow model\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "raw_args", ")", "\n", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", "=", "args", ".", "model_name", ",", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "pytorch_model_path", ")", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "\n", ")", "\n", "\n", "convert_pytorch_checkpoint_to_tf", "(", "\n", "model", "=", "model", ",", "\n", "ckpt_dir", "=", "args", ".", "tf_cache_dir", ",", "\n", "model_name", "=", "args", ".", "model_name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.__init__": [[129, 146], ["torch.Module.__init__", "modeling_openai.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads": [[147, 165], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "modeling_openai.Attention.pruned_heads.union", "len", "set", "sum", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "head", "-=", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention._attn": [[166, 190], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_openai.Attention.attn_dropout", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size", "modeling_openai.Attention.size", "modeling_openai.Attention.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "# w = w * self.bias + -1e9 * (1 - self.bias)  # TF implem method: mask_attn_weights", "\n", "# XD: self.b may be larger than w, so we need to crop it", "\n", "", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", ":", "w", ".", "size", "(", "-", "2", ")", ",", ":", "w", ".", "size", "(", "-", "1", ")", "]", "\n", "w", "=", "w", "*", "b", "+", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.merge_heads": [[191, 195], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads": [[196, 203], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.forward": [[204, 220], ["modeling_openai.Attention.c_attn", "modeling_openai.Attention.split", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention._attn", "modeling_openai.Attention.merge_heads", "modeling_openai.Attention.c_proj", "modeling_openai.Attention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.MLP.__init__": [[223, 230], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT_FNS", "[", "config", ".", "afn", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.MLP.forward": [[231, 235], ["modeling_openai.MLP.act", "modeling_openai.MLP.c_proj", "modeling_openai.MLP.dropout", "modeling_openai.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Block.__init__": [[238, 245], ["torch.Module.__init__", "modeling_openai.Attention", "torch.LayerNorm", "torch.LayerNorm", "modeling_openai.MLP", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Block.forward": [[246, 256], ["modeling_openai.Block.attn", "modeling_openai.Block.ln_1", "modeling_openai.Block.mlp", "modeling_openai.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "attn_outputs", "=", "self", ".", "attn", "(", "x", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "\n", "outputs", "=", "[", "h", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTPreTrainedModel._init_weights": [[267, 279], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTModel.__init__": [[351, 362], ["modeling_utils.PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "modeling_openai.OpenAIGPTModel.init_weights", "modeling_openai.Block", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "tokens_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "positions_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTModel._resize_token_embeddings": [[363, 366], ["modeling_openai.OpenAIGPTModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "tokens_embed", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "tokens_embed", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "tokens_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTModel._prune_heads": [[367, 373], ["heads_to_prune.items", "modeling_openai.OpenAIGPTModel.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTModel.forward": [[374, 451], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "modeling_openai.OpenAIGPTModel.positions_embed", "modeling_openai.OpenAIGPTModel.drop", "enumerate", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.size", "token_type_ids.view.view.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "block", "modeling_openai.OpenAIGPTModel.view", "input_ids.view.view.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "token_type_ids.view.view.size", "modeling_openai.OpenAIGPTModel.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_openai.OpenAIGPTModel.view", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_openai.OpenAIGPTModel.view", "modeling_openai.OpenAIGPTModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_openai.OpenAIGPTModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "position_ids", "is", "None", ":", "\n", "# This was used when we had a single embedding matrice from position and token embeddings", "\n", "# start = self.config.vocab_size + self.config.n_special", "\n", "# end = start + input_ids.size(-1)", "\n", "# position_ids = torch.arange(start, end, dtype=torch.long, device=input_ids.device)", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "input_ids", ".", "size", "(", "-", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "tokens_embed", "(", "input_ids", ")", "\n", "position_embeds", "=", "self", ".", "positions_embed", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "token_type_embeds", "=", "self", ".", "tokens_embed", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "all_attentions", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "h", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", "=", "outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTLMHeadModel.__init__": [[486, 493], ["modeling_utils.PreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "torch.Linear", "torch.Linear", "modeling_openai.OpenAIGPTLMHeadModel.init_weights", "modeling_openai.OpenAIGPTLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTLMHeadModel.tie_weights": [[494, 500], ["modeling_openai.OpenAIGPTLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "tokens_embed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTLMHeadModel.forward": [[501, 523], ["modeling_openai.OpenAIGPTLMHeadModel.transformer", "modeling_openai.OpenAIGPTLMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.__init__": [[578, 587], ["modeling_utils.PreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "modeling_openai.OpenAIGPTDoubleHeadsModel.init_weights", "modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTDoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights": [[588, 594], ["modeling_openai.OpenAIGPTDoubleHeadsModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "tokens_embed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.forward": [[595, 622], ["modeling_openai.OpenAIGPTDoubleHeadsModel.transformer", "modeling_openai.OpenAIGPTDoubleHeadsModel.lm_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "modeling_openai.OpenAIGPTDoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "mc_labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.load_tf_weights_in_openai_gpt": [[42, 115], ["logger.info", "json.load", "json.load", "np.cumsum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "json.load.pop", "init_params.pop", "init_params.pop", "zip", "os.path.dirname", "io.open", "io.open", "np.load", "np.split", "param.reshape", "arr.squeeze", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "np.prod", "range", "np.concatenate", "zip", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_openai_gpt", "(", "model", ",", "config", ",", "openai_checkpoint_folder_path", ")", ":", "\n", "    ", "\"\"\" Load tf pre-trained weights in a pytorch model (from NumPy arrays here)\n    \"\"\"", "\n", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "\n", "if", "'.ckpt'", "in", "openai_checkpoint_folder_path", ":", "\n", "        ", "openai_checkpoint_folder_path", "=", "os", ".", "path", ".", "dirname", "(", "openai_checkpoint_folder_path", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Loading weights from {}\"", ".", "format", "(", "openai_checkpoint_folder_path", ")", ")", "\n", "\n", "names", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/parameters_names.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "shapes", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/params_shapes.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "offsets", "=", "np", ".", "cumsum", "(", "[", "np", ".", "prod", "(", "shape", ")", "for", "shape", "in", "shapes", "]", ")", "\n", "init_params", "=", "[", "np", ".", "load", "(", "openai_checkpoint_folder_path", "+", "'/params_{}.npy'", ".", "format", "(", "n", ")", ")", "for", "n", "in", "range", "(", "10", ")", "]", "\n", "init_params", "=", "np", ".", "split", "(", "np", ".", "concatenate", "(", "init_params", ",", "0", ")", ",", "offsets", ")", "[", ":", "-", "1", "]", "\n", "init_params", "=", "[", "param", ".", "reshape", "(", "shape", ")", "for", "param", ",", "shape", "in", "zip", "(", "init_params", ",", "shapes", ")", "]", "\n", "\n", "# This was used when we had a single embedding matrix for positions and tokens", "\n", "# init_params[0] = np.concatenate([init_params[1], init_params[0]], 0)", "\n", "# del init_params[1]", "\n", "init_params", "=", "[", "arr", ".", "squeeze", "(", ")", "for", "arr", "in", "init_params", "]", "\n", "\n", "try", ":", "\n", "        ", "assert", "model", ".", "tokens_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "1", "]", ".", "shape", "\n", "assert", "model", ".", "positions_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "0", "]", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "e", ".", "args", "+=", "(", "model", ".", "tokens_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "1", "]", ".", "shape", ")", "\n", "e", ".", "args", "+=", "(", "model", ".", "positions_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "0", "]", ".", "shape", ")", "\n", "raise", "\n", "\n", "", "model", ".", "tokens_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "1", "]", ")", "\n", "model", ".", "positions_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "0", "]", ")", "\n", "names", ".", "pop", "(", "0", ")", "\n", "# Pop position and token embedding arrays", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "\n", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "init_params", ")", ":", "# names[1:n_transfer], init_params[1:n_transfer]):", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "assert", "name", "[", "-", "2", ":", "]", "==", "\":0\"", "\n", "name", "=", "name", "[", ":", "-", "2", "]", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'g'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'b'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'w'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.gelu": [[117, 119], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.swish": [[121, 123], ["torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name": [[28, 61], ["tf_name.replace.replace", "re.sub", "tf_name.replace.replace", "re.sub", "tf_name.replace.split", "bool", "tf_name.replace.replace"], "function", ["None"], ["def", "convert_tf_weight_name_to_pt_weight_name", "(", "tf_name", ",", "start_prefix_to_remove", "=", "''", ")", ":", "\n", "    ", "\"\"\" Convert a TF 2.0 model variable name in a pytorch model weight name.\n\n        Conventions for TF2.0 scopes -> PyTorch attribute names conversions:\n            - '$1___$2' is replaced by $2 (can be used to duplicate or remove layers in TF2.0 vs PyTorch)\n            - '_._' is replaced by a new level separation (can be used to convert TF2.0 lists in PyTorch nn.ModulesList)\n\n        return tuple with:\n            - pytorch model weight name\n            - transpose: boolean indicating weither TF2.0 and PyTorch weights matrices are transposed with regards to each other\n    \"\"\"", "\n", "tf_name", "=", "tf_name", ".", "replace", "(", "':0'", ",", "''", ")", "# device ids", "\n", "tf_name", "=", "re", ".", "sub", "(", "r'/[^/]*___([^/]*)/'", ",", "r'/\\1/'", ",", "tf_name", ")", "# '$1___$2' is replaced by $2 (can be used to duplicate or remove layers in TF2.0 vs PyTorch)", "\n", "tf_name", "=", "tf_name", ".", "replace", "(", "'_._'", ",", "'/'", ")", "# '_._' is replaced by a level separation (can be used to convert TF2.0 lists in PyTorch nn.ModulesList)", "\n", "tf_name", "=", "re", ".", "sub", "(", "r'//+'", ",", "'/'", ",", "tf_name", ")", "# Remove empty levels at the end", "\n", "tf_name", "=", "tf_name", ".", "split", "(", "'/'", ")", "# Convert from TF2.0 '/' separators to PyTorch '.' separators", "\n", "tf_name", "=", "tf_name", "[", "1", ":", "]", "# Remove level zero", "\n", "\n", "# When should we transpose the weights", "\n", "transpose", "=", "bool", "(", "tf_name", "[", "-", "1", "]", "==", "'kernel'", "or", "'emb_projs'", "in", "tf_name", "or", "'out_projs'", "in", "tf_name", ")", "\n", "\n", "# Convert standard TF2.0 names in PyTorch names", "\n", "if", "tf_name", "[", "-", "1", "]", "==", "'kernel'", "or", "tf_name", "[", "-", "1", "]", "==", "'embeddings'", "or", "tf_name", "[", "-", "1", "]", "==", "'gamma'", ":", "\n", "        ", "tf_name", "[", "-", "1", "]", "=", "'weight'", "\n", "", "if", "tf_name", "[", "-", "1", "]", "==", "'beta'", ":", "\n", "        ", "tf_name", "[", "-", "1", "]", "=", "'bias'", "\n", "\n", "# Remove prefix if needed", "\n", "", "tf_name", "=", "'.'", ".", "join", "(", "tf_name", ")", "\n", "if", "start_prefix_to_remove", ":", "\n", "        ", "tf_name", "=", "tf_name", ".", "replace", "(", "start_prefix_to_remove", ",", "''", ",", "1", ")", "\n", "\n", "", "return", "tf_name", ",", "transpose", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model": [[66, 83], ["os.path.abspath", "logger.info", "torch.load", "modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model", "logger.error"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model"], ["", "def", "load_pytorch_checkpoint_in_tf2_model", "(", "tf_model", ",", "pytorch_checkpoint_path", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load pytorch checkpoints in a TF 2.0 model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "import", "torch", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a PyTorch model in TensorFlow, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "e", "\n", "\n", "", "pt_path", "=", "os", ".", "path", ".", "abspath", "(", "pytorch_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Loading PyTorch weights from {}\"", ".", "format", "(", "pt_path", ")", ")", "\n", "\n", "pt_state_dict", "=", "torch", ".", "load", "(", "pt_path", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "return", "load_pytorch_weights_in_tf2_model", "(", "tf_model", ",", "pt_state_dict", ",", "tf_inputs", "=", "tf_inputs", ",", "allow_missing_keys", "=", "allow_missing_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_pytorch_model_in_tf2_model": [[85, 91], ["pt_model.state_dict", "modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model"], ["", "def", "load_pytorch_model_in_tf2_model", "(", "tf_model", ",", "pt_model", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load pytorch checkpoints in a TF 2.0 model\n    \"\"\"", "\n", "pt_state_dict", "=", "pt_model", ".", "state_dict", "(", ")", "\n", "\n", "return", "load_pytorch_weights_in_tf2_model", "(", "tf_model", ",", "pt_state_dict", ",", "tf_inputs", "=", "tf_inputs", ",", "allow_missing_keys", "=", "allow_missing_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model": [[93, 172], ["pt_state_dict.keys", "zip", "set", "K.batch_set_value", "logger.info", "tf_model", "pt_state_dict.pop", "any", "list", "modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name", "pt_state_dict[].numpy", "logger.info", "weight_value_tuples.append", "set.discard", "tf_model", "logger.error", "key.replace", "key.replace", "old_keys.append", "new_keys.append", "pt_state_dict.keys", "numpy.transpose", "len", "len", "numpy.squeeze", "s.startswith", "len", "len", "numpy.expand_dims", "list", "list", "pt_state_dict.keys"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name"], ["", "def", "load_pytorch_weights_in_tf2_model", "(", "tf_model", ",", "pt_state_dict", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load pytorch state_dict in a TF 2.0 model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "torch", "\n", "import", "tensorflow", "as", "tf", "\n", "from", "tensorflow", ".", "python", ".", "keras", "import", "backend", "as", "K", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a PyTorch model in TensorFlow, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "e", "\n", "\n", "", "if", "tf_inputs", "is", "None", ":", "\n", "        ", "tf_inputs", "=", "tf_model", ".", "dummy_inputs", "\n", "\n", "", "if", "tf_inputs", "is", "not", "None", ":", "\n", "        ", "tfo", "=", "tf_model", "(", "tf_inputs", ",", "training", "=", "False", ")", "# Make sure model is built", "\n", "\n", "# Adapt state dict - TODO remove this and update the AWS weights files instead", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "pt_state_dict", ".", "keys", "(", ")", ":", "\n", "        ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "            ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "            ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "            ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "        ", "pt_state_dict", "[", "new_key", "]", "=", "pt_state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# Make sure we are able to load PyTorch base models as well as derived models (with heads)", "\n", "# TF models always have a prefix, some of PyTorch models (base ones) don't", "\n", "", "start_prefix_to_remove", "=", "''", "\n", "if", "not", "any", "(", "s", ".", "startswith", "(", "tf_model", ".", "base_model_prefix", ")", "for", "s", "in", "pt_state_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "start_prefix_to_remove", "=", "tf_model", ".", "base_model_prefix", "+", "'.'", "\n", "\n", "", "symbolic_weights", "=", "tf_model", ".", "trainable_weights", "+", "tf_model", ".", "non_trainable_weights", "\n", "\n", "weight_value_tuples", "=", "[", "]", "\n", "all_pytorch_weights", "=", "set", "(", "list", "(", "pt_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "for", "symbolic_weight", "in", "symbolic_weights", ":", "\n", "        ", "sw_name", "=", "symbolic_weight", ".", "name", "\n", "name", ",", "transpose", "=", "convert_tf_weight_name_to_pt_weight_name", "(", "sw_name", ",", "start_prefix_to_remove", "=", "start_prefix_to_remove", ")", "\n", "\n", "# Find associated numpy array in pytorch model state dict", "\n", "assert", "name", "in", "pt_state_dict", ",", "\"{} not found in PyTorch model\"", ".", "format", "(", "name", ")", "\n", "array", "=", "pt_state_dict", "[", "name", "]", ".", "numpy", "(", ")", "\n", "\n", "if", "transpose", ":", "\n", "            ", "array", "=", "numpy", ".", "transpose", "(", "array", ")", "\n", "\n", "", "if", "len", "(", "symbolic_weight", ".", "shape", ")", "<", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "squeeze", "(", "array", ")", "\n", "", "elif", "len", "(", "symbolic_weight", ".", "shape", ")", ">", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "expand_dims", "(", "array", ",", "axis", "=", "0", ")", "\n", "\n", "", "try", ":", "\n", "            ", "assert", "list", "(", "symbolic_weight", ".", "shape", ")", "==", "list", "(", "array", ".", "shape", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "symbolic_weight", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "e", "\n", "\n", "", "logger", ".", "info", "(", "\"Initialize TF weight {}\"", ".", "format", "(", "symbolic_weight", ".", "name", ")", ")", "\n", "\n", "weight_value_tuples", ".", "append", "(", "(", "symbolic_weight", ",", "array", ")", ")", "\n", "all_pytorch_weights", ".", "discard", "(", "name", ")", "\n", "\n", "", "K", ".", "batch_set_value", "(", "weight_value_tuples", ")", "\n", "\n", "if", "tf_inputs", "is", "not", "None", ":", "\n", "        ", "tfo", "=", "tf_model", "(", "tf_inputs", ",", "training", "=", "False", ")", "# Make sure restore ops are run", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights or buffers not loaded from PyTorch model: {}\"", ".", "format", "(", "all_pytorch_weights", ")", ")", "\n", "\n", "return", "tf_model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_tf2_checkpoint_in_pytorch_model": [[177, 209], ["os.path.abspath", "logger.info", "getattr", "getattr.", "tf_model_class.load_weights", "modeling_tf_pytorch_utils.load_tf2_model_in_pytorch_model", "tf_model_class.", "logger.error"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_tf2_model_in_pytorch_model"], ["", "def", "load_tf2_checkpoint_in_pytorch_model", "(", "pt_model", ",", "tf_checkpoint_path", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load TF 2.0 HDF5 checkpoint in a PyTorch model\n        We use HDF5 to easily do transfer learning\n        (see https://github.com/tensorflow/tensorflow/blob/ee16fcac960ae660e0e4496658a366e2f745e1f0/tensorflow/python/keras/engine/network.py#L1352-L1357).\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "import", "torch", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "e", "\n", "\n", "", "import", "transformers", "\n", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Loading TensorFlow weights from {}\"", ".", "format", "(", "tf_checkpoint_path", ")", ")", "\n", "\n", "# Instantiate and load the associated TF 2.0 model", "\n", "tf_model_class_name", "=", "\"TF\"", "+", "pt_model", ".", "__class__", ".", "__name__", "# Add \"TF\" at the beggining", "\n", "tf_model_class", "=", "getattr", "(", "transformers", ",", "tf_model_class_name", ")", "\n", "tf_model", "=", "tf_model_class", "(", "pt_model", ".", "config", ")", "\n", "\n", "if", "tf_inputs", "is", "None", ":", "\n", "        ", "tf_inputs", "=", "tf_model", ".", "dummy_inputs", "\n", "\n", "", "if", "tf_inputs", "is", "not", "None", ":", "\n", "        ", "tfo", "=", "tf_model", "(", "tf_inputs", ",", "training", "=", "False", ")", "# Make sure model is built", "\n", "\n", "", "tf_model", ".", "load_weights", "(", "tf_checkpoint_path", ",", "by_name", "=", "True", ")", "\n", "\n", "return", "load_tf2_model_in_pytorch_model", "(", "pt_model", ",", "tf_model", ",", "allow_missing_keys", "=", "allow_missing_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_tf2_model_in_pytorch_model": [[210, 216], ["modeling_tf_pytorch_utils.load_tf2_weights_in_pytorch_model"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_tf2_weights_in_pytorch_model"], ["", "def", "load_tf2_model_in_pytorch_model", "(", "pt_model", ",", "tf_model", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load TF 2.0 model in a pytorch model\n    \"\"\"", "\n", "weights", "=", "tf_model", ".", "weights", "\n", "\n", "return", "load_tf2_weights_in_pytorch_model", "(", "pt_model", ",", "weights", ",", "allow_missing_keys", "=", "allow_missing_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.load_tf2_weights_in_pytorch_model": [[218, 290], ["dict", "set", "dict.items", "pt_model.load_state_dict", "logger.info", "pt_model.named_parameters", "any", "modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name", "list", "logger.info", "torch.from_numpy", "torch.from_numpy", "set.discard", "len", "logger.info", "len", "logger.info", "logger.error", "tf_weight.numpy", "tf_weights_map.keys", "pt_weight.data_ptr", "ValueError", "numpy.transpose", "len", "len", "numpy.squeeze", "s.startswith", "len", "len", "numpy.expand_dims", "list", "list", "pt_weight.data_ptr", "dict.keys", "pt_weight.data_ptr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name"], ["", "def", "load_tf2_weights_in_pytorch_model", "(", "pt_model", ",", "tf_weights", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load TF2.0 symbolic weights in a PyTorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "import", "torch", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "e", "\n", "\n", "", "new_pt_params_dict", "=", "{", "}", "\n", "current_pt_params_dict", "=", "dict", "(", "pt_model", ".", "named_parameters", "(", ")", ")", "\n", "\n", "# Make sure we are able to load PyTorch base models as well as derived models (with heads)", "\n", "# TF models always have a prefix, some of PyTorch models (base ones) don't", "\n", "start_prefix_to_remove", "=", "''", "\n", "if", "not", "any", "(", "s", ".", "startswith", "(", "pt_model", ".", "base_model_prefix", ")", "for", "s", "in", "current_pt_params_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "start_prefix_to_remove", "=", "pt_model", ".", "base_model_prefix", "+", "'.'", "\n", "\n", "# Build a map from potential PyTorch weight names to TF 2.0 Variables", "\n", "", "tf_weights_map", "=", "{", "}", "\n", "for", "tf_weight", "in", "tf_weights", ":", "\n", "        ", "pt_name", ",", "transpose", "=", "convert_tf_weight_name_to_pt_weight_name", "(", "tf_weight", ".", "name", ",", "start_prefix_to_remove", "=", "start_prefix_to_remove", ")", "\n", "tf_weights_map", "[", "pt_name", "]", "=", "(", "tf_weight", ".", "numpy", "(", ")", ",", "transpose", ")", "\n", "\n", "", "all_tf_weights", "=", "set", "(", "list", "(", "tf_weights_map", ".", "keys", "(", ")", ")", ")", "\n", "loaded_pt_weights_data_ptr", "=", "{", "}", "\n", "for", "pt_weight_name", ",", "pt_weight", "in", "current_pt_params_dict", ".", "items", "(", ")", ":", "\n", "# Handle PyTorch shared weight ()not duplicated in TF 2.0", "\n", "        ", "if", "pt_weight", ".", "data_ptr", "(", ")", "in", "loaded_pt_weights_data_ptr", ":", "\n", "            ", "new_pt_params_dict", "[", "pt_weight_name", "]", "=", "loaded_pt_weights_data_ptr", "[", "pt_weight", ".", "data_ptr", "(", ")", "]", "\n", "continue", "\n", "\n", "# Find associated numpy array in pytorch model state dict", "\n", "", "if", "pt_weight_name", "not", "in", "tf_weights_map", ":", "\n", "            ", "raise", "ValueError", "(", "\"{} not found in TF 2.0 model\"", ".", "format", "(", "pt_weight_name", ")", ")", "\n", "\n", "", "array", ",", "transpose", "=", "tf_weights_map", "[", "pt_weight_name", "]", "\n", "\n", "if", "transpose", ":", "\n", "            ", "array", "=", "numpy", ".", "transpose", "(", "array", ")", "\n", "\n", "", "if", "len", "(", "pt_weight", ".", "shape", ")", "<", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "squeeze", "(", "array", ")", "\n", "", "elif", "len", "(", "pt_weight", ".", "shape", ")", ">", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "expand_dims", "(", "array", ",", "axis", "=", "0", ")", "\n", "\n", "", "try", ":", "\n", "            ", "assert", "list", "(", "pt_weight", ".", "shape", ")", "==", "list", "(", "array", ".", "shape", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pt_weight", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "e", "\n", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "pt_weight_name", ")", ")", "\n", "\n", "new_pt_params_dict", "[", "pt_weight_name", "]", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "loaded_pt_weights_data_ptr", "[", "pt_weight", ".", "data_ptr", "(", ")", "]", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "all_tf_weights", ".", "discard", "(", "pt_weight_name", ")", "\n", "\n", "", "missing_keys", ",", "unexpected_keys", "=", "pt_model", ".", "load_state_dict", "(", "new_pt_params_dict", ",", "strict", "=", "False", ")", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"Weights of {} not initialized from TF 2.0 model: {}\"", ".", "format", "(", "\n", "pt_model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"Weights from TF 2.0 model not used in {}: {}\"", ".", "format", "(", "\n", "pt_model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights or buffers not loaded from TF 2.0 model: {}\"", ".", "format", "(", "all_tf_weights", ")", ")", "\n", "\n", "return", "pt_model", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_openai_original_tf_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch": [[33, 52], ["transformers.OpenAIGPTModel", "transformers.load_tf_weights_in_openai_gpt", "print", "torch.save", "print", "transformers.OpenAIGPTConfig", "transformers.OpenAIGPTConfig.from_json_file", "transformers.OpenAIGPTModel.state_dict", "io.open", "f.write", "OpenAIGPTConfig.from_json_file.to_json_string"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_openai.load_tf_weights_in_openai_gpt", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["def", "convert_openai_checkpoint_to_pytorch", "(", "openai_checkpoint_folder_path", ",", "openai_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "openai_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", ".", "from_json_file", "(", "openai_config_file", ")", "\n", "", "model", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_openai_gpt", "(", "model", ",", "config", ",", "openai_checkpoint_folder_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlm.XLMConfig.__init__": [[83, 161], ["configuration_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "30145", ",", "\n", "emb_dim", "=", "2048", ",", "\n", "n_layers", "=", "12", ",", "\n", "n_heads", "=", "16", ",", "\n", "dropout", "=", "0.1", ",", "\n", "attention_dropout", "=", "0.1", ",", "\n", "gelu_activation", "=", "True", ",", "\n", "sinusoidal_embeddings", "=", "False", ",", "\n", "causal", "=", "False", ",", "\n", "asm", "=", "False", ",", "\n", "n_langs", "=", "1", ",", "\n", "use_lang_emb", "=", "True", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "embed_init_std", "=", "2048", "**", "-", "0.5", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "init_std", "=", "0.02", ",", "\n", "bos_index", "=", "0", ",", "\n", "eos_index", "=", "1", ",", "\n", "pad_index", "=", "2", ",", "\n", "unk_index", "=", "3", ",", "\n", "mask_index", "=", "5", ",", "\n", "is_encoder", "=", "True", ",", "\n", "\n", "finetuning_task", "=", "None", ",", "\n", "num_labels", "=", "2", ",", "\n", "summary_type", "=", "'first'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "start_n_top", "=", "5", ",", "\n", "end_n_top", "=", "5", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs XLMConfig.\n        \"\"\"", "\n", "super", "(", "XLMConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_words", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "emb_dim", "=", "emb_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "attention_dropout", "=", "attention_dropout", "\n", "self", ".", "gelu_activation", "=", "gelu_activation", "\n", "self", ".", "sinusoidal_embeddings", "=", "sinusoidal_embeddings", "\n", "self", ".", "causal", "=", "causal", "\n", "self", ".", "asm", "=", "asm", "\n", "self", ".", "n_langs", "=", "n_langs", "\n", "self", ".", "use_lang_emb", "=", "use_lang_emb", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "self", ".", "bos_index", "=", "bos_index", "\n", "self", ".", "eos_index", "=", "eos_index", "\n", "self", ".", "pad_index", "=", "pad_index", "\n", "self", ".", "unk_index", "=", "unk_index", "\n", "self", ".", "mask_index", "=", "mask_index", "\n", "self", ".", "is_encoder", "=", "is_encoder", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "embed_init_std", "=", "embed_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "self", ".", "finetuning_task", "=", "finetuning_task", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "start_n_top", "=", "start_n_top", "\n", "self", ".", "end_n_top", "=", "end_n_top", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\" or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlm.XLMConfig.vocab_size": [[167, 170], ["None"], "methods", ["None"], ["", "@", "vocab_size", ".", "setter", "\n", "def", "vocab_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "n_words", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlm.XLMConfig.hidden_size": [[171, 174], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "emb_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlm.XLMConfig.num_attention_heads": [[175, 178], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlm.XLMConfig.num_hidden_layers": [[179, 182], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_auto.AutoTokenizer.__init__": [[56, 58], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoTokenizer is designed to be instantiated \"", "\n", "\"using the `AutoTokenizer.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_auto.AutoTokenizer.from_pretrained": [[60, 125], ["ValueError", "tokenization_distilbert.DistilBertTokenizer.from_pretrained", "tokenization_roberta.RobertaTokenizer.from_pretrained", "tokenization_bert.BertTokenizer.from_pretrained", "tokenization_openai.OpenAIGPTTokenizer.from_pretrained", "tokenization_gpt2.GPT2Tokenizer.from_pretrained", "tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained", "tokenization_xlnet.XLNetTokenizer.from_pretrained", "tokenization_xlm.XLMTokenizer.from_pretrained", "tokenization_ctrl.CTRLTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a one of the tokenizer classes of the library\n        from a pre-trained model vocabulary.\n\n        The tokenizer class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertTokenizer (DistilBert model)\n            - contains `roberta`: RobertaTokenizer (XLM model)\n            - contains `bert`: BertTokenizer (Bert model)\n            - contains `openai-gpt`: OpenAIGPTTokenizer (OpenAI GPT model)\n            - contains `gpt2`: GPT2Tokenizer (OpenAI GPT-2 model)\n            - contains `ctrl`: CTRLTokenizer (Salesforce CTRL model)\n            - contains `transfo-xl`: TransfoXLTokenizer (Transformer-XL model)\n            - contains `xlnet`: XLNetTokenizer (XLNet model)\n            - contains `xlm`: XLMTokenizer (XLM model)\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a predefined tokenizer to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing vocabulary files required by the tokenizer, for instance saved using the :func:`~transformers.PreTrainedTokenizer.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - (not applicable to all derived classes) a path or url to a single saved vocabulary file if and only if the tokenizer only requires a single vocabulary file (e.g. Bert, XLNet), e.g.: ``./my_model_directory/vocab.txt``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded predefined tokenizer vocabulary files should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the vocabulary files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            inputs: (`optional`) positional arguments: will be passed to the Tokenizer ``__init__`` method.\n\n            kwargs: (`optional`) keyword arguments: will be passed to the Tokenizer ``__init__`` method. Can be used to set special tokens like ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``, ``additional_special_tokens``. See parameters in the doc string of :class:`~transformers.PreTrainedTokenizer` for details.\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')    # Download vocabulary from S3 and cache.\n            tokenizer = AutoTokenizer.from_pretrained('./test/bert_saved_model/')  # E.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Tokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'ctrl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta', 'ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlnet.XLNetConfig.__init__": [[74, 146], ["configuration_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "setattr", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "32000", ",", "\n", "d_model", "=", "1024", ",", "\n", "n_layer", "=", "24", ",", "\n", "n_head", "=", "16", ",", "\n", "d_inner", "=", "4096", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "ff_activation", "=", "\"gelu\"", ",", "\n", "untie_r", "=", "True", ",", "\n", "attn_type", "=", "\"bi\"", ",", "\n", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "\n", "dropout", "=", "0.1", ",", "\n", "mem_len", "=", "None", ",", "\n", "reuse_len", "=", "None", ",", "\n", "bi_data", "=", "False", ",", "\n", "clamp_len", "=", "-", "1", ",", "\n", "same_length", "=", "False", ",", "\n", "\n", "finetuning_task", "=", "None", ",", "\n", "num_labels", "=", "2", ",", "\n", "summary_type", "=", "'last'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "'tanh'", ",", "\n", "summary_last_dropout", "=", "0.1", ",", "\n", "start_n_top", "=", "5", ",", "\n", "end_n_top", "=", "5", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs XLNetConfig.\n        \"\"\"", "\n", "super", "(", "XLNetConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_token", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "assert", "d_model", "%", "n_head", "==", "0", "\n", "self", ".", "d_head", "=", "d_model", "//", "n_head", "\n", "self", ".", "ff_activation", "=", "ff_activation", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "reuse_len", "=", "reuse_len", "\n", "self", ".", "bi_data", "=", "bi_data", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "\n", "self", ".", "finetuning_task", "=", "finetuning_task", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_last_dropout", "=", "summary_last_dropout", "\n", "self", ".", "start_n_top", "=", "start_n_top", "\n", "self", ".", "end_n_top", "=", "end_n_top", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\" or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlnet.XLNetConfig.max_position_embeddings": [[148, 151], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlnet.XLNetConfig.vocab_size": [[156, 159], ["None"], "methods", ["None"], ["", "@", "vocab_size", ".", "setter", "\n", "def", "vocab_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "n_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlnet.XLNetConfig.hidden_size": [[160, 163], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlnet.XLNetConfig.num_attention_heads": [[164, 167], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_xlnet.XLNetConfig.num_hidden_layers": [[168, 171], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.__init__": [[87, 110], ["tokenization_utils.PreTrainedTokenizer.__init__", "json.load", "dict", "English", "English.Defaults.create_tokenizer", "io.open", "io.open().read().split", "tuple", "zip", "logger.warning", "tokenization_bert.BasicTokenizer", "tokenization_openai.OpenAIGPTTokenizer.encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "try", ":", "\n", "            ", "import", "ftfy", "\n", "from", "spacy", ".", "lang", ".", "en", "import", "English", "\n", "_nlp", "=", "English", "(", ")", "\n", "self", ".", "nlp", "=", "_nlp", ".", "Defaults", ".", "create_tokenizer", "(", "_nlp", ")", "\n", "self", ".", "fix_text", "=", "ftfy", ".", "fix_text", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"", ")", "\n", "self", ".", "nlp", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "self", ".", "fix_text", "=", "None", "\n", "\n", "", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.vocab_size": [[111, 114], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe": [[115, 157], ["tokenization_openai.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_openai.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "'\\n</w>'", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer._tokenize": [[158, 172], ["tokenization_openai.OpenAIGPTTokenizer.nlp.tokenize", "tokenization_openai.OpenAIGPTTokenizer.nlp", "split_tokens.extend", "tokenization_openai.text_standardize", "split_tokens.extend", "tokenization_openai.OpenAIGPTTokenizer.fix_text", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe", "tokenization_openai.OpenAIGPTTokenizer.bpe", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.text_standardize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer", "\n", "            ", "text", "=", "self", ".", "nlp", ".", "tokenize", "(", "text", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "else", ":", "\n", "# Using SpaCy & ftfy (original tokenization process of OpenAI GPT)", "\n", "            ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "self", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id": [[173, 176], ["tokenization_openai.OpenAIGPTTokenizer.encoder.get", "tokenization_openai.OpenAIGPTTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token": [[177, 180], ["tokenization_openai.OpenAIGPTTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an id in a token (BPE) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_string": [[181, 185], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.OpenAIGPTTokenizer.save_vocabulary": [[186, 209], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "writer.write", "sorted", "json.dumps", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "u'#version: 0.2\\n'", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.get_pairs": [[50, 61], ["set", "set.add"], "function", ["None"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_openai.text_standardize": [[62, 76], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "'\u2014'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2013'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2015'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u00b4'", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)'''", ",", "r' \\1 '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\s*\\n\\s*'", ",", "' \\n '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^\\S\\n]+'", ",", "' '", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.convert_bert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[29, 41], ["transformers.BertConfig.from_json_file", "print", "transformers.BertForPreTraining", "transformers.load_tf_weights_in_bert", "print", "torch.save", "transformers.BertForPreTraining.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_bert.load_tf_weights_in_bert"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "BertConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "BertForPreTraining", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.__init__": [[56, 58], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoConfig is designed to be instantiated \"", "\n", "\"using the `AutoConfig.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained": [[60, 138], ["ValueError", "configuration_distilbert.DistilBertConfig.from_pretrained", "configuration_roberta.RobertaConfig.from_pretrained", "configuration_bert.BertConfig.from_pretrained", "configuration_openai.OpenAIGPTConfig.from_pretrained", "configuration_gpt2.GPT2Config.from_pretrained", "configuration_transfo_xl.TransfoXLConfig.from_pretrained", "configuration_xlnet.XLNetConfig.from_pretrained", "configuration_xlm.XLMConfig.from_pretrained", "configuration_ctrl.CTRLConfig.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a one of the configuration classes of the library\n        from a pre-trained model configuration.\n\n        The configuration class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertConfig (DistilBERT model)\n            - contains `bert`: BertConfig (Bert model)\n            - contains `openai-gpt`: OpenAIGPTConfig (OpenAI GPT model)\n            - contains `gpt2`: GPT2Config (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLConfig (Transformer-XL model)\n            - contains `xlnet`: XLNetConfig (XLNet model)\n            - contains `xlm`: XLMConfig (XLM model)\n            - contains `roberta`: RobertaConfig (RoBERTa model)\n            - contains `ctrl` : CTRLConfig (CTRL model)\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing a configuration file saved using the :func:`~transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved configuration JSON `file`, e.g.: ``./my_model_directory/configuration.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the configuration object after loading.\n\n                - The values in kwargs of any keys which are configuration attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Examples::\n\n            config = AutoConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = AutoConfig.from_pretrained('./test/bert_saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = AutoConfig.from_pretrained('./test/bert_saved_model/my_configuration.json')\n            config = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "if", "'distilbert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Config", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'ctrl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta', 'ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_ctrl_test.CTRLTokenizationTest.setUp": [[29, 44], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "io.open", "fp.write", "io.open", "fp.write", "range", "len", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "CTRLTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "'adapt'", ",", "'re@@'", ",", "'a@@'", ",", "'apt'", ",", "'c@@'", ",", "'t'", ",", "'<unk>'", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "'a p'", ",", "'ap t</w>'", ",", "'r e'", ",", "'a d'", ",", "'ad apt</w>'", ",", "''", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", "+", "\"\\n\"", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_ctrl_test.CTRLTokenizationTest.get_tokenizer": [[45, 48], ["kwargs.update", "transformers.tokenization_ctrl.CTRLTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", ".", "update", "(", "self", ".", "special_tokens_map", ")", "\n", "return", "CTRLTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_ctrl_test.CTRLTokenizationTest.get_input_output_texts": [[49, 53], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"adapt react readapt apt\"", "\n", "output_text", "=", "u\"adapt react readapt apt\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_ctrl_test.CTRLTokenizationTest.test_full_tokenizer": [[54, 66], ["transformers.tokenization_ctrl.CTRLTokenizer", "transformers.tokenization_ctrl.CTRLTokenizer.tokenize", "tokenization_ctrl_test.CTRLTokenizationTest.assertListEqual", "tokenization_ctrl_test.CTRLTokenizationTest.assertListEqual", "transformers.tokenization_ctrl.CTRLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "CTRLTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"adapt react readapt apt\"", "\n", "bpe_tokens", "=", "'adapt re@@ a@@ c@@ t re@@ adapt apt'", ".", "split", "(", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "\n", "input_bpe_tokens", "=", "[", "0", ",", "1", ",", "2", ",", "4", ",", "5", ",", "1", ",", "0", ",", "3", ",", "6", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_gpt2_test.GPT2ModelTest.setUp": [[219, 222], ["GPT2ModelTest.GPT2ModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "GPT2ModelTest", ".", "GPT2ModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "GPT2Config", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_gpt2_test.GPT2ModelTest.test_config": [[223, 225], ["modeling_gpt2_test.GPT2ModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_gpt2_test.GPT2ModelTest.test_gpt2_model": [[226, 229], ["modeling_gpt2_test.GPT2ModelTest.model_tester.prepare_config_and_inputs", "modeling_gpt2_test.GPT2ModelTest.model_tester.create_and_check_gpt2_model"], "methods", ["None"], ["", "def", "test_gpt2_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_gpt2_test.GPT2ModelTest.test_gpt2_lm_head_model": [[230, 233], ["modeling_gpt2_test.GPT2ModelTest.model_tester.prepare_config_and_inputs", "modeling_gpt2_test.GPT2ModelTest.model_tester.create_and_check_lm_head_model"], "methods", ["None"], ["", "def", "test_gpt2_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_gpt2_test.GPT2ModelTest.test_gpt2_double_lm_head_model": [[234, 237], ["modeling_gpt2_test.GPT2ModelTest.model_tester.prepare_config_and_inputs", "modeling_gpt2_test.GPT2ModelTest.model_tester.create_and_check_double_lm_head_model"], "methods", ["None"], ["", "def", "test_gpt2_double_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_double_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_gpt2_test.GPT2ModelTest.test_model_from_pretrained": [[238, 245], ["list", "GPT2Model.from_pretrained", "shutil.rmtree", "modeling_gpt2_test.GPT2ModelTest.assertIsNotNone", "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "GPT2Model", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_openai_test.OpenAIGPTModelTest.setUp": [[187, 190], ["OpenAIGPTModelTest.OpenAIGPTModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "OpenAIGPTModelTest", ".", "OpenAIGPTModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "OpenAIGPTConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_openai_test.OpenAIGPTModelTest.test_config": [[191, 193], ["modeling_openai_test.OpenAIGPTModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_openai_test.OpenAIGPTModelTest.test_openai_gpt_model": [[194, 197], ["modeling_openai_test.OpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "modeling_openai_test.OpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_model"], "methods", ["None"], ["", "def", "test_openai_gpt_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_openai_test.OpenAIGPTModelTest.test_openai_gpt_lm_head_model": [[198, 201], ["modeling_openai_test.OpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "modeling_openai_test.OpenAIGPTModelTest.model_tester.create_and_check_lm_head_model"], "methods", ["None"], ["", "def", "test_openai_gpt_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_openai_test.OpenAIGPTModelTest.test_openai_gpt_double_lm_head_model": [[202, 205], ["modeling_openai_test.OpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "modeling_openai_test.OpenAIGPTModelTest.model_tester.create_and_check_double_lm_head_model"], "methods", ["None"], ["", "def", "test_openai_gpt_double_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_double_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_openai_test.OpenAIGPTModelTest.test_model_from_pretrained": [[206, 213], ["list", "OpenAIGPTModel.from_pretrained", "shutil.rmtree", "modeling_openai_test.OpenAIGPTModelTest.assertIsNotNone", "OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "OpenAIGPTModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test.ConfigTester.__init__": [[696, 700], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parent", ",", "config_class", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "parent", "=", "parent", "\n", "self", ".", "config_class", "=", "config_class", "\n", "self", ".", "inputs_dict", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test.ConfigTester.create_and_test_config_common_properties": [[701, 707], ["modeling_common_test.ConfigTester.config_class", "modeling_common_test.ConfigTester.parent.assertTrue", "modeling_common_test.ConfigTester.parent.assertTrue", "modeling_common_test.ConfigTester.parent.assertTrue", "modeling_common_test.ConfigTester.parent.assertTrue", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["", "def", "create_and_test_config_common_properties", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'vocab_size'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'hidden_size'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'num_attention_heads'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'num_hidden_layers'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test.ConfigTester.create_and_test_config_to_json_string": [[708, 713], ["modeling_common_test.ConfigTester.config_class", "json.loads", "modeling_common_test.ConfigTester.inputs_dict.items", "modeling_common_test.ConfigTester.to_json_string", "modeling_common_test.ConfigTester.parent.assertEqual"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["", "def", "create_and_test_config_to_json_string", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "obj", "=", "json", ".", "loads", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "inputs_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "parent", ".", "assertEqual", "(", "obj", "[", "key", "]", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test.ConfigTester.create_and_test_config_to_json_file": [[714, 721], ["modeling_common_test.ConfigTester.config_class", "os.path.join", "modeling_common_test.ConfigTester.to_json_file", "modeling_common_test.ConfigTester.config_class.from_json_file", "os.remove", "modeling_common_test.ConfigTester.parent.assertEqual", "os.getcwd", "modeling_common_test.ConfigTester.to_dict", "modeling_common_test.ConfigTester.to_dict", "str", "uuid.uuid4"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.to_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict"], ["", "", "def", "create_and_test_config_to_json_file", "(", "self", ")", ":", "\n", "        ", "config_first", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "json_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"config_\"", "+", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "+", "\".json\"", ")", "\n", "config_first", ".", "to_json_file", "(", "json_file_path", ")", "\n", "config_second", "=", "self", ".", "config_class", ".", "from_json_file", "(", "json_file_path", ")", "\n", "os", ".", "remove", "(", "json_file_path", ")", "\n", "self", ".", "parent", ".", "assertEqual", "(", "config_second", ".", "to_dict", "(", ")", ",", "config_first", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test.ConfigTester.run_common_tests": [[722, 726], ["modeling_common_test.ConfigTester.create_and_test_config_common_properties", "modeling_common_test.ConfigTester.create_and_test_config_to_json_string", "modeling_common_test.ConfigTester.create_and_test_config_to_json_file"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_common_properties", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_to_json_string", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_to_json_file"], ["", "def", "run_common_tests", "(", "self", ")", ":", "\n", "        ", "self", ".", "create_and_test_config_common_properties", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_string", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_file", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test.ModelUtilsTest.test_model_from_pretrained": [[748, 767], ["logging.basicConfig", "list", "BertConfig.from_pretrained", "modeling_common_test.ModelUtilsTest.assertIsNotNone", "modeling_common_test.ModelUtilsTest.assertIsInstance", "BertModel.from_pretrained", "BertModel.from_pretrained", "modeling_common_test.ModelUtilsTest.assertIsNotNone", "modeling_common_test.ModelUtilsTest.assertIsInstance", "loading_info.values", "BertConfig.from_pretrained", "BertModel.from_pretrained", "modeling_common_test.ModelUtilsTest.assertEqual", "modeling_common_test.ModelUtilsTest.assertEqual", "modeling_common_test.ModelUtilsTest.assertEqual", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "modeling_common_test.ModelUtilsTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "PretrainedConfig", ")", "\n", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "PreTrainedModel", ")", "\n", "for", "value", "in", "loading_info", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "len", "(", "value", ")", ",", "0", ")", "\n", "\n", "", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_name", ",", "output_attentions", "=", "True", ",", "output_hidden_states", "=", "True", ")", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "output_attentions", "=", "True", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test._config_zero_init": [[59, 65], ["copy.deepcopy", "copy.deepcopy.__dict__.keys", "setattr"], "function", ["None"], ["", "def", "_config_zero_init", "(", "config", ")", ":", "\n", "    ", "configs_no_init", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "for", "key", "in", "configs_no_init", ".", "__dict__", ".", "keys", "(", ")", ":", "\n", "        ", "if", "'_range'", "in", "key", "or", "'_std'", "in", "key", ":", "\n", "            ", "setattr", "(", "configs_no_init", ",", "key", ",", "0.0", ")", "\n", "", "", "return", "configs_no_init", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_common_test.ids_tensor": [[731, 745], ["range", "torch.tensor().view().contiguous", "values.append", "rng.randint", "torch.tensor().view", "torch.tensor"], "function", ["None"], ["def", "ids_tensor", "(", "shape", ",", "vocab_size", ",", "rng", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a random int32 tensor of the shape within the vocab size.\"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "        ", "rng", "=", "global_rng", "\n", "\n", "", "total_dims", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "        ", "total_dims", "*=", "dim", "\n", "\n", "", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "total_dims", ")", ":", "\n", "        ", "values", ".", "append", "(", "rng", ".", "randint", "(", "0", ",", "vocab_size", "-", "1", ")", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "data", "=", "values", ",", "dtype", "=", "torch", ".", "long", ")", ".", "view", "(", "shape", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.setUp": [[288, 291], ["XLMModelTest.XLMModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "XLMModelTest", ".", "XLMModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLMConfig", ",", "emb_dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.test_config": [[292, 294], ["modeling_xlm_test.XLMModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.test_xlm_model": [[295, 298], ["modeling_xlm_test.XLMModelTest.model_tester.prepare_config_and_inputs", "modeling_xlm_test.XLMModelTest.model_tester.create_and_check_xlm_model"], "methods", ["None"], ["", "def", "test_xlm_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.test_xlm_lm_head": [[299, 302], ["modeling_xlm_test.XLMModelTest.model_tester.prepare_config_and_inputs", "modeling_xlm_test.XLMModelTest.model_tester.create_and_check_xlm_lm_head"], "methods", ["None"], ["", "def", "test_xlm_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.test_xlm_simple_qa": [[303, 306], ["modeling_xlm_test.XLMModelTest.model_tester.prepare_config_and_inputs", "modeling_xlm_test.XLMModelTest.model_tester.create_and_check_xlm_simple_qa"], "methods", ["None"], ["", "def", "test_xlm_simple_qa", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_simple_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.test_xlm_qa": [[307, 310], ["modeling_xlm_test.XLMModelTest.model_tester.prepare_config_and_inputs", "modeling_xlm_test.XLMModelTest.model_tester.create_and_check_xlm_qa"], "methods", ["None"], ["", "def", "test_xlm_qa", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.test_xlm_sequence_classif": [[311, 314], ["modeling_xlm_test.XLMModelTest.model_tester.prepare_config_and_inputs", "modeling_xlm_test.XLMModelTest.model_tester.create_and_check_xlm_sequence_classif"], "methods", ["None"], ["", "def", "test_xlm_sequence_classif", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlm_test.XLMModelTest.test_model_from_pretrained": [[315, 322], ["list", "XLMModel.from_pretrained", "shutil.rmtree", "modeling_xlm_test.XLMModelTest.assertIsNotNone", "XLM_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "XLM_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XLMModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_ctrl_test.CTRLModelTest.setUp": [[190, 193], ["CTRLModelTest.CTRLModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "CTRLModelTest", ".", "CTRLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "CTRLConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_ctrl_test.CTRLModelTest.test_config": [[194, 196], ["modeling_ctrl_test.CTRLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_ctrl_test.CTRLModelTest.test_ctrl_model": [[197, 200], ["modeling_ctrl_test.CTRLModelTest.model_tester.prepare_config_and_inputs", "modeling_ctrl_test.CTRLModelTest.model_tester.create_and_check_ctrl_model"], "methods", ["None"], ["", "def", "test_ctrl_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_ctrl_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_ctrl_test.CTRLModelTest.test_ctrl_lm_head_model": [[201, 204], ["modeling_ctrl_test.CTRLModelTest.model_tester.prepare_config_and_inputs", "modeling_ctrl_test.CTRLModelTest.model_tester.create_and_check_lm_head_model"], "methods", ["None"], ["", "def", "test_ctrl_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_ctrl_test.CTRLModelTest.test_model_from_pretrained": [[205, 212], ["list", "CTRLModel.from_pretrained", "shutil.rmtree", "modeling_ctrl_test.CTRLModelTest.assertIsNotNone", "CTRL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "CTRL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "CTRLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.__init__": [[31, 35], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parent", ",", "config_class", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "parent", "=", "parent", "\n", "self", ".", "config_class", "=", "config_class", "\n", "self", ".", "inputs_dict", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_common_properties": [[36, 42], ["configuration_common_test.ConfigTester.config_class", "configuration_common_test.ConfigTester.parent.assertTrue", "configuration_common_test.ConfigTester.parent.assertTrue", "configuration_common_test.ConfigTester.parent.assertTrue", "configuration_common_test.ConfigTester.parent.assertTrue", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["", "def", "create_and_test_config_common_properties", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'vocab_size'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'hidden_size'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'num_attention_heads'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'num_hidden_layers'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_to_json_string": [[43, 48], ["configuration_common_test.ConfigTester.config_class", "json.loads", "configuration_common_test.ConfigTester.inputs_dict.items", "configuration_common_test.ConfigTester.to_json_string", "configuration_common_test.ConfigTester.parent.assertEqual"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["", "def", "create_and_test_config_to_json_string", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "obj", "=", "json", ".", "loads", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "inputs_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "parent", ".", "assertEqual", "(", "obj", "[", "key", "]", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_to_json_file": [[49, 56], ["configuration_common_test.ConfigTester.config_class", "os.path.join", "configuration_common_test.ConfigTester.to_json_file", "configuration_common_test.ConfigTester.config_class.from_json_file", "os.remove", "configuration_common_test.ConfigTester.parent.assertEqual", "os.getcwd", "configuration_common_test.ConfigTester.to_dict", "configuration_common_test.ConfigTester.to_dict", "str", "uuid.uuid4"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.to_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict"], ["", "", "def", "create_and_test_config_to_json_file", "(", "self", ")", ":", "\n", "        ", "config_first", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "json_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"config_\"", "+", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "+", "\".json\"", ")", "\n", "config_first", ".", "to_json_file", "(", "json_file_path", ")", "\n", "config_second", "=", "self", ".", "config_class", ".", "from_json_file", "(", "json_file_path", ")", "\n", "os", ".", "remove", "(", "json_file_path", ")", "\n", "self", ".", "parent", ".", "assertEqual", "(", "config_second", ".", "to_dict", "(", ")", ",", "config_first", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests": [[57, 61], ["configuration_common_test.ConfigTester.create_and_test_config_common_properties", "configuration_common_test.ConfigTester.create_and_test_config_to_json_string", "configuration_common_test.ConfigTester.create_and_test_config_to_json_file"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_common_properties", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_to_json_string", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.create_and_test_config_to_json_file"], ["", "def", "run_common_tests", "(", "self", ")", ":", "\n", "        ", "self", ".", "create_and_test_config_common_properties", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_string", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_file", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlnet_test.TFXLNetModelTest.setUp": [[270, 273], ["TFXLNetModelTest.TFXLNetModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFXLNetModelTest", ".", "TFXLNetModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLNetConfig", ",", "d_inner", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlnet_test.TFXLNetModelTest.test_config": [[274, 276], ["modeling_tf_xlnet_test.TFXLNetModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlnet_test.TFXLNetModelTest.test_xlnet_base_model": [[277, 281], ["modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.set_seed", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.create_and_check_xlnet_base_model"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_base_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_base_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlnet_test.TFXLNetModelTest.test_xlnet_lm_head": [[282, 286], ["modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.set_seed", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.create_and_check_xlnet_lm_head"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlnet_test.TFXLNetModelTest.test_xlnet_sequence_classif": [[287, 291], ["modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.set_seed", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.create_and_check_xlnet_sequence_classif"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_sequence_classif", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlnet_test.TFXLNetModelTest.test_xlnet_qa": [[292, 296], ["modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.set_seed", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlnet_test.TFXLNetModelTest.model_tester.create_and_check_xlnet_qa"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_qa", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlnet_test.TFXLNetModelTest.test_model_from_pretrained": [[297, 304], ["list", "TFXLNetModel.from_pretrained", "shutil.rmtree", "modeling_tf_xlnet_test.TFXLNetModelTest.assertIsNotNone", "TF_XLNET_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TF_XLNET_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFXLNetModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_gpt2_test.TFGPT2ModelTest.setUp": [[203, 206], ["TFGPT2ModelTest.TFGPT2ModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFGPT2ModelTest", ".", "TFGPT2ModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "GPT2Config", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_gpt2_test.TFGPT2ModelTest.test_config": [[207, 209], ["modeling_tf_gpt2_test.TFGPT2ModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_gpt2_test.TFGPT2ModelTest.test_gpt2_model": [[210, 213], ["modeling_tf_gpt2_test.TFGPT2ModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_gpt2_test.TFGPT2ModelTest.model_tester.create_and_check_gpt2_model"], "methods", ["None"], ["", "def", "test_gpt2_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_gpt2_test.TFGPT2ModelTest.test_gpt2_lm_head": [[214, 217], ["modeling_tf_gpt2_test.TFGPT2ModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_gpt2_test.TFGPT2ModelTest.model_tester.create_and_check_gpt2_lm_head"], "methods", ["None"], ["", "def", "test_gpt2_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_gpt2_test.TFGPT2ModelTest.test_gpt2_double_head": [[218, 221], ["modeling_tf_gpt2_test.TFGPT2ModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_gpt2_test.TFGPT2ModelTest.model_tester.create_and_check_gpt2_double_head"], "methods", ["None"], ["", "def", "test_gpt2_double_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_double_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_gpt2_test.TFGPT2ModelTest.test_model_from_pretrained": [[222, 229], ["list", "TFGPT2Model.from_pretrained", "shutil.rmtree", "modeling_tf_gpt2_test.TFGPT2ModelTest.assertIsNotNone", "TF_GPT2_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TF_GPT2_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFGPT2Model", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_auto_test.TFAutoModelTest.test_model_from_pretrained": [[41, 55], ["modeling_tf_auto_test.TFAutoModelTest.assertTrue", "logging.basicConfig", "h5py.version.hdf5_version.startswith", "AutoConfig.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance", "TFAutoModel.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "import", "h5py", "\n", "self", ".", "assertTrue", "(", "h5py", ".", "version", ".", "hdf5_version", ".", "startswith", "(", "\"1.10\"", ")", ")", "\n", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "'bert-base-uncased'", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModel", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertModel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_auto_test.TFAutoModelTest.test_lmhead_model_from_pretrained": [[56, 67], ["logging.basicConfig", "AutoConfig.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance", "TFAutoModelWithLMHead.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_lmhead_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "'bert-base-uncased'", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModelWithLMHead", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertForMaskedLM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_auto_test.TFAutoModelTest.test_sequence_classification_model_from_pretrained": [[68, 79], ["logging.basicConfig", "AutoConfig.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance", "TFAutoModelForSequenceClassification.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_sequence_classification_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "'bert-base-uncased'", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModelForSequenceClassification", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertForSequenceClassification", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_auto_test.TFAutoModelTest.test_question_answering_model_from_pretrained": [[80, 91], ["logging.basicConfig", "AutoConfig.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance", "TFAutoModelForQuestionAnswering.from_pretrained", "modeling_tf_auto_test.TFAutoModelTest.assertIsNotNone", "modeling_tf_auto_test.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_question_answering_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "'bert-base-uncased'", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModelForQuestionAnswering", ".", "from_pretrained", "(", "model_name", ",", "force_download", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertForQuestionAnswering", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_distilbert_test.TFDistilBertModelTest.setUp": [[190, 193], ["TFDistilBertModelTest.TFDistilBertModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFDistilBertModelTest", ".", "TFDistilBertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "DistilBertConfig", ",", "dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_distilbert_test.TFDistilBertModelTest.test_config": [[194, 196], ["modeling_tf_distilbert_test.TFDistilBertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_distilbert_test.TFDistilBertModelTest.test_distilbert_model": [[197, 200], ["modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.create_and_check_distilbert_model"], "methods", ["None"], ["", "def", "test_distilbert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_distilbert_test.TFDistilBertModelTest.test_for_masked_lm": [[201, 204], ["modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.create_and_check_distilbert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_distilbert_test.TFDistilBertModelTest.test_for_question_answering": [[205, 208], ["modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.create_and_check_distilbert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_distilbert_test.TFDistilBertModelTest.test_for_sequence_classification": [[209, 212], ["modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_distilbert_test.TFDistilBertModelTest.model_tester.create_and_check_distilbert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.setUp": [[272, 275], ["BertModelTest.BertModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "BertModelTest", ".", "BertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "BertConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_config": [[276, 278], ["modeling_bert_test.BertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_bert_model": [[279, 282], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_model"], "methods", ["None"], ["", "def", "test_bert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_for_masked_lm": [[283, 286], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_for_multiple_choice": [[287, 290], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_multiple_choice"], "methods", ["None"], ["", "def", "test_for_multiple_choice", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_multiple_choice", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_for_next_sequence_prediction": [[291, 294], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_next_sequence_prediction"], "methods", ["None"], ["", "def", "test_for_next_sequence_prediction", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_next_sequence_prediction", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_for_pretraining": [[295, 298], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_pretraining"], "methods", ["None"], ["", "def", "test_for_pretraining", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_pretraining", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_for_question_answering": [[299, 302], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_for_sequence_classification": [[303, 306], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_for_token_classification": [[307, 310], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_bert_test.BertModelTest.test_model_from_pretrained": [[311, 318], ["list", "BertModel.from_pretrained", "shutil.rmtree", "modeling_bert_test.BertModelTest.assertIsNotNone", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlnet_test.XLNetTokenizationTest.setUp": [[31, 37], ["super().setUp", "transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.save_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "XLNetTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# We have a SentencePiece fixture for testing", "\n", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "keep_accents", "=", "True", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlnet_test.XLNetTokenizationTest.get_tokenizer": [[38, 40], ["transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "XLNetTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlnet_test.XLNetTokenizationTest.get_input_output_texts": [[41, 45], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"This is a test\"", "\n", "output_text", "=", "u\"This is a test\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_full_tokenizer": [[47, 74], ["transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_ids", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.convert_ids_to_tokens", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "keep_accents", "=", "True", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u'This is a test'", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "u'\u2581This'", ",", "u'\u2581is'", ",", "u'\u2581a'", ",", "u'\u2581t'", ",", "u'est'", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "285", ",", "46", ",", "10", ",", "170", ",", "382", "]", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u'I'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "\n", "u'or'", ",", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "SPIECE_UNDERLINE", "+", "u''", ",", "\n", "u'9'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u's'", ",", "u'\u00e9'", ",", "u'.'", "]", ")", "\n", "ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "ids", ",", "[", "8", ",", "21", ",", "84", ",", "55", ",", "24", ",", "19", ",", "7", ",", "0", ",", "\n", "602", ",", "347", ",", "347", ",", "347", ",", "3", ",", "12", ",", "66", ",", "\n", "46", ",", "72", ",", "80", ",", "6", ",", "0", ",", "4", "]", ")", "\n", "\n", "back_tokens", "=", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", "\n", "self", ".", "assertListEqual", "(", "back_tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u'I'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "\n", "u'or'", ",", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "\n", "SPIECE_UNDERLINE", "+", "u''", ",", "u'<unk>'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "\n", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u's'", ",", "\n", "u'<unk>'", ",", "u'.'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_tokenizer_lower": [[75, 83], ["transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "do_lower_case", "=", "True", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u''", ",", "u'i'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "\n", "u'or'", ",", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "SPIECE_UNDERLINE", "+", "u''", ",", "\n", "u'9'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u'se'", ",", "u'.'", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "u\"H\\u00E9llo\"", ")", ",", "[", "u\"\u2581he\"", ",", "u\"ll\"", ",", "u\"o\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_tokenizer_no_lower": [[84, 91], ["transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "do_lower_case", "=", "False", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u'I'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "u'or'", ",", "\n", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "SPIECE_UNDERLINE", "+", "u''", ",", "\n", "u'9'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u'se'", ",", "u'.'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_sequence_builders": [[92, 103], ["transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.encode", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.encode", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", ".", "from_pretrained", "(", "\"xlnet-base-cased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "text", "+", "[", "4", ",", "3", "]", "\n", "assert", "encoded_pair", "==", "text", "+", "[", "4", "]", "+", "text_2", "+", "[", "4", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_transfo_xl_test.TransfoXLModelTest.setUp": [[188, 191], ["TransfoXLModelTest.TransfoXLModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TransfoXLModelTest", ".", "TransfoXLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "TransfoXLConfig", ",", "d_embed", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_config": [[192, 194], ["modeling_transfo_xl_test.TransfoXLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_transfo_xl_model": [[195, 200], ["modeling_transfo_xl_test.TransfoXLModelTest.model_tester.set_seed", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.prepare_config_and_inputs", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.create_transfo_xl_model", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.check_transfo_xl_model_output"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_transfo_xl_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "output_result", "=", "self", ".", "model_tester", ".", "create_transfo_xl_model", "(", "*", "config_and_inputs", ")", "\n", "self", ".", "model_tester", ".", "check_transfo_xl_model_output", "(", "output_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_transfo_xl_lm_head": [[201, 206], ["modeling_transfo_xl_test.TransfoXLModelTest.model_tester.set_seed", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.prepare_config_and_inputs", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.create_transfo_xl_lm_head", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.check_transfo_xl_lm_head_output"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_transfo_xl_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "output_result", "=", "self", ".", "model_tester", ".", "create_transfo_xl_lm_head", "(", "*", "config_and_inputs", ")", "\n", "self", ".", "model_tester", ".", "check_transfo_xl_lm_head_output", "(", "output_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_model_from_pretrained": [[207, 214], ["list", "TransfoXLModel.from_pretrained", "shutil.rmtree", "modeling_transfo_xl_test.TransfoXLModelTest.assertIsNotNone", "TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TransfoXLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_utils_test.TokenizerUtilsTest.check_tokenizer_from_pretrained": [[26, 41], ["list", "tokenizer_class.max_model_input_sizes.keys", "tokenizer_class.from_pretrained", "tokenization_utils_test.TokenizerUtilsTest.assertIsNotNone", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenizer_class.from_pretrained.convert_tokens_to_ids", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["    ", "def", "check_tokenizer_from_pretrained", "(", "self", ",", "tokenizer_class", ")", ":", "\n", "        ", "s3_models", "=", "list", "(", "tokenizer_class", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "for", "model_name", "in", "s3_models", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "tokenizer_class", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "PreTrainedTokenizer", ")", "\n", "\n", "for", "special_tok", "in", "tokenizer", ".", "all_special_tokens", ":", "\n", "                ", "if", "six", ".", "PY2", ":", "\n", "                    ", "self", ".", "assertIsInstance", "(", "special_tok", ",", "unicode", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertIsInstance", "(", "special_tok", ",", "str", ")", "\n", "", "special_tok_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "special_tok", ")", "\n", "self", ".", "assertIsInstance", "(", "special_tok_id", ",", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_utils_test.TokenizerUtilsTest.test_pretrained_tokenizers": [[42, 44], ["tokenization_utils_test.TokenizerUtilsTest.check_tokenizer_from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_utils_test.TokenizerUtilsTest.check_tokenizer_from_pretrained"], ["", "", "", "def", "test_pretrained_tokenizers", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_tokenizer_from_pretrained", "(", "GPT2Tokenizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.setUp": [[30, 47], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"w</w>\"", ",", "\"r</w>\"", ",", "\"t</w>\"", ",", "\n", "\"lo\"", ",", "\"low\"", ",", "\"er</w>\"", ",", "\n", "\"low</w>\"", ",", "\"lowest</w>\"", ",", "\"newer</w>\"", ",", "\"wider</w>\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"l o\"", ",", "\"lo w\"", ",", "\"e r</w>\"", ",", "\"\"", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.get_tokenizer": [[48, 50], ["transformers.tokenization_openai.OpenAIGPTTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "OpenAIGPTTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.get_input_output_texts": [[51, 55], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.test_full_tokenizer": [[57, 69], ["transformers.tokenization_openai.OpenAIGPTTokenizer", "transformers.tokenization_openai.OpenAIGPTTokenizer.tokenize", "tokenization_openai_test.OpenAIGPTTokenizationTest.assertListEqual", "tokenization_openai_test.OpenAIGPTTokenizationTest.assertListEqual", "transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "OpenAIGPTTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ")", "\n", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er</w>\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "\"<unk>\"", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "20", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_gpt2_test.GPT2TokenizationTest.setUp": [[30, 48], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "io.open", "fp.write", "io.open", "fp.write", "range", "len", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "GPT2TokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"\\u0120\"", ",", "\"\\u0120l\"", ",", "\"\\u0120n\"", ",", "\n", "\"\\u0120lo\"", ",", "\"\\u0120low\"", ",", "\"er\"", ",", "\n", "\"\\u0120lowest\"", ",", "\"\\u0120newer\"", ",", "\"\\u0120wider\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"\\u0120 l\"", ",", "\"\\u0120l o\"", ",", "\"\\u0120lo w\"", ",", "\"e r\"", ",", "\"\"", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", "+", "\"\\n\"", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_gpt2_test.GPT2TokenizationTest.get_tokenizer": [[49, 52], ["kwargs.update", "transformers.tokenization_gpt2.GPT2Tokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", ".", "update", "(", "self", ".", "special_tokens_map", ")", "\n", "return", "GPT2Tokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_gpt2_test.GPT2TokenizationTest.get_input_output_texts": [[53, 57], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_gpt2_test.GPT2TokenizationTest.test_full_tokenizer": [[58, 69], ["transformers.tokenization_gpt2.GPT2Tokenizer", "transformers.tokenization_gpt2.GPT2Tokenizer.tokenize", "tokenization_gpt2_test.GPT2TokenizationTest.assertListEqual", "tokenization_gpt2_test.GPT2TokenizationTest.assertListEqual", "transformers.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "GPT2Tokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"lower newer\"", "\n", "bpe_tokens", "=", "[", "\"\\u0120low\"", ",", "\"er\"", ",", "\"\\u0120\"", ",", "\"n\"", ",", "\"e\"", ",", "\"w\"", ",", "\"er\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ",", "add_prefix_space", "=", "True", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "10", ",", "9", ",", "3", ",", "2", ",", "15", ",", "19", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_ctrl_test.TFCTRLModelTest.setUp": [[176, 179], ["TFCTRLModelTest.TFCTRLModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFCTRLModelTest", ".", "TFCTRLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "CTRLConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_ctrl_test.TFCTRLModelTest.test_config": [[180, 182], ["modeling_tf_ctrl_test.TFCTRLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_ctrl_test.TFCTRLModelTest.test_ctrl_model": [[183, 186], ["modeling_tf_ctrl_test.TFCTRLModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_ctrl_test.TFCTRLModelTest.model_tester.create_and_check_ctrl_model"], "methods", ["None"], ["", "def", "test_ctrl_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_ctrl_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_ctrl_test.TFCTRLModelTest.test_ctrl_lm_head": [[187, 190], ["modeling_tf_ctrl_test.TFCTRLModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_ctrl_test.TFCTRLModelTest.model_tester.create_and_check_ctrl_lm_head"], "methods", ["None"], ["", "def", "test_ctrl_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_ctrl_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_ctrl_test.TFCTRLModelTest.test_model_from_pretrained": [[191, 198], ["list", "TFCTRLModel.from_pretrained", "shutil.rmtree", "modeling_tf_ctrl_test.TFCTRLModelTest.assertIsNotNone", "TF_CTRL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TF_CTRL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFCTRLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_distilbert_test.DistilBertModelTest.setUp": [[189, 192], ["DistilBertModelTest.DistilBertModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "DistilBertModelTest", ".", "DistilBertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "DistilBertConfig", ",", "dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_distilbert_test.DistilBertModelTest.test_config": [[193, 195], ["modeling_distilbert_test.DistilBertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_distilbert_test.DistilBertModelTest.test_distilbert_model": [[196, 199], ["modeling_distilbert_test.DistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_distilbert_test.DistilBertModelTest.model_tester.create_and_check_distilbert_model"], "methods", ["None"], ["", "def", "test_distilbert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_distilbert_test.DistilBertModelTest.test_for_masked_lm": [[200, 203], ["modeling_distilbert_test.DistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_distilbert_test.DistilBertModelTest.model_tester.create_and_check_distilbert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_distilbert_test.DistilBertModelTest.test_for_question_answering": [[204, 207], ["modeling_distilbert_test.DistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_distilbert_test.DistilBertModelTest.model_tester.create_and_check_distilbert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_distilbert_test.DistilBertModelTest.test_for_sequence_classification": [[208, 211], ["modeling_distilbert_test.DistilBertModelTest.model_tester.prepare_config_and_inputs", "modeling_distilbert_test.DistilBertModelTest.model_tester.create_and_check_distilbert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelTest.setUp": [[183, 186], ["RobertaModelTest.RobertaModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "RobertaModelTest", ".", "RobertaModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "RobertaConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelTest.test_config": [[187, 189], ["modeling_roberta_test.RobertaModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelTest.test_roberta_model": [[190, 193], ["modeling_roberta_test.RobertaModelTest.model_tester.prepare_config_and_inputs", "modeling_roberta_test.RobertaModelTest.model_tester.create_and_check_roberta_model"], "methods", ["None"], ["", "def", "test_roberta_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelTest.test_for_masked_lm": [[194, 197], ["modeling_roberta_test.RobertaModelTest.model_tester.prepare_config_and_inputs", "modeling_roberta_test.RobertaModelTest.model_tester.create_and_check_roberta_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelTest.test_model_from_pretrained": [[198, 205], ["list", "RobertaModel.from_pretrained", "shutil.rmtree", "modeling_roberta_test.RobertaModelTest.assertIsNotNone", "ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelIntegrationTest.test_inference_masked_lm": [[210, 229], ["RobertaForMaskedLM.from_pretrained", "torch.tensor", "torch.Size", "modeling_roberta_test.RobertaModelIntegrationTest.assertEqual", "torch.Tensor", "modeling_roberta_test.RobertaModelIntegrationTest.assertTrue", "RobertaForMaskedLM.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_masked_lm", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaForMaskedLM", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "torch", ".", "Size", "(", "(", "1", ",", "11", ",", "50265", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "output", ".", "shape", ",", "\n", "expected_shape", "\n", ")", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "33.8843", ",", "-", "4.3107", ",", "22.7779", "]", ",", "\n", "[", "4.6533", ",", "-", "2.8099", ",", "13.6252", "]", ",", "\n", "[", "1.8222", ",", "-", "3.6898", ",", "8.8600", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ",", "expected_slice", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelIntegrationTest.test_inference_no_head": [[231, 245], ["RobertaModel.from_pretrained", "torch.tensor", "torch.Tensor", "modeling_roberta_test.RobertaModelIntegrationTest.assertTrue", "RobertaModel.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_no_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "-", "0.0231", ",", "0.0782", ",", "0.0074", "]", ",", "\n", "[", "-", "0.1854", ",", "0.0539", ",", "-", "0.0174", "]", ",", "\n", "[", "0.0548", ",", "0.0799", ",", "0.1687", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ",", "expected_slice", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_roberta_test.RobertaModelIntegrationTest.test_inference_classification_head": [[247, 261], ["RobertaForSequenceClassification.from_pretrained", "torch.tensor", "torch.Size", "modeling_roberta_test.RobertaModelIntegrationTest.assertEqual", "torch.Tensor", "modeling_roberta_test.RobertaModelIntegrationTest.assertTrue", "RobertaForSequenceClassification.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_classification_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaForSequenceClassification", ".", "from_pretrained", "(", "'roberta-large-mnli'", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "torch", ".", "Size", "(", "(", "1", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "output", ".", "shape", ",", "\n", "expected_shape", "\n", ")", "\n", "expected_tensor", "=", "torch", ".", "Tensor", "(", "[", "[", "-", "0.9469", ",", "0.3913", ",", "0.5118", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "output", ",", "expected_tensor", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.setUp": [[202, 205], ["TFOpenAIGPTModelTest.TFOpenAIGPTModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFOpenAIGPTModelTest", ".", "TFOpenAIGPTModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "OpenAIGPTConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.test_config": [[206, 208], ["modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.test_openai_gpt_model": [[209, 212], ["modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_model"], "methods", ["None"], ["", "def", "test_openai_gpt_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.test_openai_gpt_lm_head": [[213, 216], ["modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_lm_head"], "methods", ["None"], ["", "def", "test_openai_gpt_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.test_openai_gpt_double_head": [[217, 220], ["modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_double_head"], "methods", ["None"], ["", "def", "test_openai_gpt_double_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_double_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.test_model_from_pretrained": [[221, 228], ["list", "TFOpenAIGPTModel.from_pretrained", "shutil.rmtree", "modeling_tf_openai_gpt_test.TFOpenAIGPTModelTest.assertIsNotNone", "TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFOpenAIGPTModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlnet_test.XLNetModelTest.setUp": [[297, 300], ["XLNetModelTest.XLNetModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "XLNetModelTest", ".", "XLNetModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLNetConfig", ",", "d_inner", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlnet_test.XLNetModelTest.test_config": [[301, 303], ["modeling_xlnet_test.XLNetModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_base_model": [[304, 308], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_base_model"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_base_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_base_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_lm_head": [[309, 313], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_lm_head"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_sequence_classif": [[314, 318], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_sequence_classif"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_sequence_classif", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_qa": [[319, 323], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_qa"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_xlnet_qa", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_xlnet_test.XLNetModelTest.test_model_from_pretrained": [[324, 331], ["list", "XLNetModel.from_pretrained", "shutil.rmtree", "modeling_xlnet_test.XLNetModelTest.assertIsNotNone", "XLNET_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "XLNET_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XLNetModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_distilbert_test.DistilBertTokenizationTest.get_tokenizer": [[30, 32], ["transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "DistilBertTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_distilbert_test.DistilBertTokenizationTest.test_sequence_builders": [[33, 45], ["transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.encode", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.encode", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "DistilBertTokenizer", ".", "from_pretrained", "(", "\"distilbert-base-uncased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "tokenizer", ".", "cls_token_id", "]", "+", "text", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "assert", "encoded_pair", "==", "[", "tokenizer", ".", "cls_token_id", "]", "+", "text", "+", "[", "tokenizer", ".", "sep_token_id", "]", "+", "text_2", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.OptimizationTest.assertListAlmostEqual": [[59, 63], ["optimization_test.OptimizationTest.assertEqual", "zip", "len", "len", "optimization_test.OptimizationTest.assertAlmostEqual"], "methods", ["None"], ["    ", "def", "assertListAlmostEqual", "(", "self", ",", "list1", ",", "list2", ",", "tol", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "a", ",", "b", ",", "delta", "=", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.OptimizationTest.test_adam_w": [[64, 77], ["torch.tensor", "torch.tensor", "torch.nn.MSELoss", "AdamW", "range", "optimization_test.OptimizationTest.assertListAlmostEqual", "torch.nn.MSELoss.", "torch.nn.MSELoss.backward", "AdamW.step", "torch.tensor.grad.detach_", "torch.tensor.grad.zero_", "torch.tensor.tolist"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["", "", "def", "test_adam_w", "(", "self", ")", ":", "\n", "        ", "w", "=", "torch", ".", "tensor", "(", "[", "0.1", ",", "-", "0.2", ",", "-", "0.1", "]", ",", "requires_grad", "=", "True", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "0.4", ",", "0.2", ",", "-", "0.5", "]", ")", "\n", "criterion", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "# No warmup, constant schedule, no gradient clipping", "\n", "optimizer", "=", "AdamW", "(", "params", "=", "[", "w", "]", ",", "lr", "=", "2e-1", ",", "weight_decay", "=", "0.0", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "            ", "loss", "=", "criterion", "(", "w", ",", "target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "w", ".", "grad", ".", "detach_", "(", ")", "# No zero_grad() function on simple tensors. we do it ourselves.", "\n", "w", ".", "grad", ".", "zero_", "(", ")", "\n", "", "self", ".", "assertListAlmostEqual", "(", "w", ".", "tolist", "(", ")", ",", "[", "0.4", ",", "0.2", ",", "-", "0.5", "]", ",", "tol", "=", "1e-2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual": [[84, 88], ["optimization_test.ScheduleInitTest.assertEqual", "zip", "len", "len", "optimization_test.ScheduleInitTest.assertAlmostEqual"], "methods", ["None"], ["def", "assertListAlmostEqual", "(", "self", ",", "list1", ",", "list2", ",", "tol", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "a", ",", "b", ",", "delta", "=", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.test_constant_scheduler": [[89, 99], ["ConstantLRSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListEqual", "ConstantLRSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "", "def", "test_constant_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "ConstantLRSchedule", "(", "self", ".", "optimizer", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "10.", "]", "*", "self", ".", "num_steps", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "ConstantLRSchedule", "(", "self", ".", "optimizer", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.test_warmup_constant_scheduler": [[100, 110], ["WarmupConstantSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListEqual", "WarmupConstantSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_constant_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupConstantSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "4", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "2.5", ",", "5.0", ",", "7.5", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "WarmupConstantSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "4", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.test_warmup_linear_scheduler": [[111, 121], ["WarmupLinearSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListEqual", "WarmupLinearSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_linear_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupLinearSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "8.75", ",", "7.5", ",", "6.25", ",", "5.0", ",", "3.75", ",", "2.5", ",", "1.25", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.test_warmup_cosine_scheduler": [[122, 132], ["WarmupCosineSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListAlmostEqual", "WarmupCosineSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_cosine_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupCosineSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "9.61", ",", "8.53", ",", "6.91", ",", "5.0", ",", "3.08", ",", "1.46", ",", "0.38", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ",", "tol", "=", "1e-2", ")", "\n", "\n", "scheduler", "=", "WarmupCosineSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.test_warmup_cosine_hard_restart_scheduler": [[133, 143], ["WarmupCosineWithHardRestartsSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListAlmostEqual", "WarmupCosineWithHardRestartsSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_cosine_hard_restart_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupCosineWithHardRestartsSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "cycles", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "8.53", ",", "5.0", ",", "1.46", ",", "10.0", ",", "8.53", ",", "5.0", ",", "1.46", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ",", "tol", "=", "1e-2", ")", "\n", "\n", "scheduler", "=", "WarmupCosineWithHardRestartsSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "cycles", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_schedule": [[36, 42], ["range", "scheduler.step", "lrs.append", "scheduler.get_lr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["def", "unwrap_schedule", "(", "scheduler", ",", "num_steps", "=", "10", ")", ":", "\n", "    ", "lrs", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "scheduler", ".", "step", "(", ")", "\n", "lrs", ".", "append", "(", "scheduler", ".", "get_lr", "(", ")", ")", "\n", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.optimization_test.unwrap_and_save_reload_schedule": [[43, 56], ["range", "scheduler.step", "lrs.append", "scheduler.get_lr", "tokenization_tests_commons.TemporaryDirectory", "os.path.join", "torch.save", "torch.load", "scheduler.load_state_dict", "scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["", "def", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "num_steps", "=", "10", ")", ":", "\n", "    ", "lrs", "=", "[", "]", "\n", "for", "step", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "scheduler", ".", "step", "(", ")", "\n", "lrs", ".", "append", "(", "scheduler", ".", "get_lr", "(", ")", ")", "\n", "if", "step", "==", "num_steps", "//", "2", ":", "\n", "            ", "with", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "                ", "file_name", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "'schedule.bin'", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "file_name", ")", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "file_name", ")", "\n", "scheduler", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_roberta_test.RobertaTokenizationTest.setUp": [[29, 47], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "io.open", "fp.write", "io.open", "fp.write", "range", "len", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "RobertaTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"\\u0120\"", ",", "\"\\u0120l\"", ",", "\"\\u0120n\"", ",", "\n", "\"\\u0120lo\"", ",", "\"\\u0120low\"", ",", "\"er\"", ",", "\n", "\"\\u0120lowest\"", ",", "\"\\u0120newer\"", ",", "\"\\u0120wider\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"\\u0120 l\"", ",", "\"\\u0120l o\"", ",", "\"\\u0120lo w\"", ",", "\"e r\"", ",", "\"\"", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", "+", "\"\\n\"", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_roberta_test.RobertaTokenizationTest.get_tokenizer": [[48, 51], ["kwargs.update", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", ".", "update", "(", "self", ".", "special_tokens_map", ")", "\n", "return", "RobertaTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_roberta_test.RobertaTokenizationTest.get_input_output_texts": [[52, 56], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_roberta_test.RobertaTokenizationTest.test_full_tokenizer": [[57, 68], ["transformers.tokenization_roberta.RobertaTokenizer", "transformers.tokenization_roberta.RobertaTokenizer.tokenize", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "transformers.tokenization_roberta.RobertaTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "RobertaTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"lower newer\"", "\n", "bpe_tokens", "=", "[", "\"\\u0120low\"", ",", "\"er\"", ",", "\"\\u0120\"", ",", "\"n\"", ",", "\"e\"", ",", "\"w\"", ",", "\"er\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ",", "add_prefix_space", "=", "True", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "10", ",", "9", ",", "3", ",", "2", ",", "15", ",", "19", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_roberta_test.RobertaTokenizationTest.roberta_dict_integration_testing": [[69, 79], ["tokenization_roberta_test.RobertaTokenizationTest.get_tokenizer", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "tokenization_roberta_test.RobertaTokenizationTest.encode", "tokenization_roberta_test.RobertaTokenizationTest.encode"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "def", "roberta_dict_integration_testing", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "encode", "(", "'Hello world!'", ")", ",", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "2", "]", "\n", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "encode", "(", "'Hello world! c\u00e9c\u00e9 herlolip 418'", ")", ",", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_roberta_test.RobertaTokenizationTest.test_sequence_builders": [[81, 95], ["transformers.tokenization_roberta.RobertaTokenizer.from_pretrained", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "\"roberta-base\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_text_from_decode", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "True", ")", "\n", "encoded_pair_from_decode", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "True", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "encoded_text_from_decode", "\n", "assert", "encoded_pair", "==", "encoded_pair_from_decode", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_auto_test.AutoModelTest.test_model_from_pretrained": [[41, 54], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "AutoModel.from_pretrained", "AutoModel.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "loading_info.values", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "modeling_auto_test.AutoModelTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertModel", ")", "\n", "for", "value", "in", "loading_info", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "len", "(", "value", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_auto_test.AutoModelTest.test_lmhead_model_from_pretrained": [[55, 66], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "AutoModelWithLMHead.from_pretrained", "AutoModelWithLMHead.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "", "def", "test_lmhead_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertForMaskedLM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_auto_test.AutoModelTest.test_sequence_classification_model_from_pretrained": [[67, 78], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "AutoModelForSequenceClassification.from_pretrained", "AutoModelForSequenceClassification.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_sequence_classification_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertForSequenceClassification", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_auto_test.AutoModelTest.test_question_answering_model_from_pretrained": [[79, 90], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "AutoModelForQuestionAnswering.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_question_answering_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertForQuestionAnswering", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelTest.setUp": [[179, 182], ["TFRobertaModelTest.TFRobertaModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFRobertaModelTest", ".", "TFRobertaModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "RobertaConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelTest.test_config": [[183, 185], ["modeling_tf_roberta_test.TFRobertaModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelTest.test_roberta_model": [[186, 189], ["modeling_tf_roberta_test.TFRobertaModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_roberta_test.TFRobertaModelTest.model_tester.create_and_check_roberta_model"], "methods", ["None"], ["", "def", "test_roberta_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelTest.test_for_masked_lm": [[190, 193], ["modeling_tf_roberta_test.TFRobertaModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_roberta_test.TFRobertaModelTest.model_tester.create_and_check_roberta_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelTest.test_model_from_pretrained": [[194, 201], ["list", "TFRobertaModel.from_pretrained", "shutil.rmtree", "modeling_tf_roberta_test.TFRobertaModelTest.assertIsNotNone", "TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFRobertaModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelIntegrationTest.test_inference_masked_lm": [[206, 225], ["TFRobertaForMaskedLM.from_pretrained", "tf.constant", "modeling_tf_roberta_test.TFRobertaModelIntegrationTest.assertEqual", "tf.constant", "modeling_tf_roberta_test.TFRobertaModelIntegrationTest.assertTrue", "TFRobertaForMaskedLM.from_pretrained.", "list", "numpy.allclose", "output[].numpy", "tf.constant.numpy", "output.numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_masked_lm", "(", "self", ")", ":", "\n", "        ", "model", "=", "TFRobertaForMaskedLM", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n", "input_ids", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "[", "1", ",", "11", ",", "50265", "]", "\n", "self", ".", "assertEqual", "(", "\n", "list", "(", "output", ".", "numpy", "(", ")", ".", "shape", ")", ",", "\n", "expected_shape", "\n", ")", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "tf", ".", "constant", "(", "\n", "[", "[", "[", "33.8843", ",", "-", "4.3107", ",", "22.7779", "]", ",", "\n", "[", "4.6533", ",", "-", "2.8099", ",", "13.6252", "]", ",", "\n", "[", "1.8222", ",", "-", "3.6898", ",", "8.8600", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "numpy", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ".", "numpy", "(", ")", ",", "expected_slice", ".", "numpy", "(", ")", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelIntegrationTest.test_inference_no_head": [[227, 241], ["TFRobertaModel.from_pretrained", "tf.constant", "tf.constant", "modeling_tf_roberta_test.TFRobertaModelIntegrationTest.assertTrue", "TFRobertaModel.from_pretrained.", "numpy.allclose", "output[].numpy", "tf.constant.numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_no_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "TFRobertaModel", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n", "input_ids", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "tf", ".", "constant", "(", "\n", "[", "[", "[", "-", "0.0231", ",", "0.0782", ",", "0.0074", "]", ",", "\n", "[", "-", "0.1854", ",", "0.0539", ",", "-", "0.0174", "]", ",", "\n", "[", "0.0548", ",", "0.0799", ",", "0.1687", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "numpy", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ".", "numpy", "(", ")", ",", "expected_slice", ".", "numpy", "(", ")", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_roberta_test.TFRobertaModelIntegrationTest.test_inference_classification_head": [[243, 257], ["TFRobertaForSequenceClassification.from_pretrained", "tf.constant", "modeling_tf_roberta_test.TFRobertaModelIntegrationTest.assertEqual", "tf.constant", "modeling_tf_roberta_test.TFRobertaModelIntegrationTest.assertTrue", "TFRobertaForSequenceClassification.from_pretrained.", "list", "numpy.allclose", "output.numpy", "tf.constant.numpy", "output.numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_classification_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "TFRobertaForSequenceClassification", ".", "from_pretrained", "(", "'roberta-large-mnli'", ")", "\n", "\n", "input_ids", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "[", "1", ",", "3", "]", "\n", "self", ".", "assertEqual", "(", "\n", "list", "(", "output", ".", "numpy", "(", ")", ".", "shape", ")", ",", "\n", "expected_shape", "\n", ")", "\n", "expected_tensor", "=", "tf", ".", "constant", "(", "[", "[", "-", "0.9469", ",", "0.3913", ",", "0.5118", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "\n", "numpy", ".", "allclose", "(", "output", ".", "numpy", "(", ")", ",", "expected_tensor", ".", "numpy", "(", ")", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.setUp": [[36, 46], ["super().setUp", "os.path.join", "io.open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "TransfoXLTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"<unk>\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"want\"", ",", "\"unwanted\"", ",", "\"wa\"", ",", "\"un\"", ",", "\n", "\"running\"", ",", "\",\"", ",", "\"low\"", ",", "\"l\"", ",", "\n", "]", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.get_tokenizer": [[47, 50], ["TransfoXLTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", "[", "'lower_case'", "]", "=", "True", "\n", "return", "TransfoXLTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.get_input_output_texts": [[51, 55], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"<unk> UNwanted , running\"", "\n", "output_text", "=", "u\"<unk> unwanted, running\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.test_full_tokenizer": [[56, 64], ["TransfoXLTokenizer", "TransfoXLTokenizer.tokenize", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "vocab_file", "=", "self", ".", "vocab_file", ",", "lower_case", "=", "True", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"<unk> UNwanted , running\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"<unk>\"", ",", "\"unwanted\"", ",", "\",\"", ",", "\"running\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "0", ",", "4", ",", "8", ",", "7", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.test_full_tokenizer_lower": [[65, 71], ["TransfoXLTokenizer", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "TransfoXLTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_full_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "lower_case", "=", "True", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo ! how  \\n Are yoU ?  \"", ")", ",", "\n", "[", "\"hello\"", ",", "\"!\"", ",", "\"how\"", ",", "\"are\"", ",", "\"you\"", ",", "\"?\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.test_full_tokenizer_no_lower": [[72, 78], ["TransfoXLTokenizer", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "TransfoXLTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_full_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "lower_case", "=", "False", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo ! how  \\n Are yoU ?  \"", ")", ",", "\n", "[", "\"HeLLo\"", ",", "\"!\"", ",", "\"how\"", ",", "\"Are\"", ",", "\"yoU\"", ",", "\"?\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.setUp": [[277, 280], ["TFBertModelTest.TFBertModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFBertModelTest", ".", "TFBertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "BertConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_config": [[281, 283], ["modeling_tf_bert_test.TFBertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_bert_model": [[284, 287], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_model"], "methods", ["None"], ["", "def", "test_bert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_for_masked_lm": [[288, 291], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_for_multiple_choice": [[292, 295], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_for_multiple_choice"], "methods", ["None"], ["", "def", "test_for_multiple_choice", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_multiple_choice", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_for_next_sequence_prediction": [[296, 299], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_for_next_sequence_prediction"], "methods", ["None"], ["", "def", "test_for_next_sequence_prediction", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_next_sequence_prediction", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_for_pretraining": [[300, 303], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_for_pretraining"], "methods", ["None"], ["", "def", "test_for_pretraining", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_pretraining", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_for_question_answering": [[304, 307], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_for_sequence_classification": [[308, 311], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_for_token_classification": [[312, 315], ["modeling_tf_bert_test.TFBertModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_bert_test.TFBertModelTest.model_tester.create_and_check_bert_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_bert_test.TFBertModelTest.test_model_from_pretrained": [[316, 324], ["TFBertModel.from_pretrained", "shutil.rmtree", "modeling_tf_bert_test.TFBertModelTest.assertIsNotNone"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "'bert-base-uncased'", "]", ":", "\n", "            ", "model", "=", "TFBertModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_auto_test.AutoTokenizerTest.test_tokenizer_from_pretrained": [[29, 42], ["logging.basicConfig", "list", "transformers.AutoTokenizer.from_pretrained", "tokenization_auto_test.AutoTokenizerTest.assertIsNotNone", "tokenization_auto_test.AutoTokenizerTest.assertIsInstance", "tokenization_auto_test.AutoTokenizerTest.assertGreater", "list", "transformers.AutoTokenizer.from_pretrained", "tokenization_auto_test.AutoTokenizerTest.assertIsNotNone", "tokenization_auto_test.AutoTokenizerTest.assertIsInstance", "tokenization_auto_test.AutoTokenizerTest.assertGreater", "transformers.BERT_PRETRAINED_CONFIG_ARCHIVE_MAP.keys", "len", "transformers.GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP.keys", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "def", "test_tokenizer_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_CONFIG_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "BertTokenizer", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "tokenizer", ")", ",", "0", ")", "\n", "\n", "", "for", "model_name", "in", "list", "(", "GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "GPT2Tokenizer", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "tokenizer", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.conftest.pytest_addoption": [[6, 9], ["parser.addoption"], "function", ["None"], ["def", "pytest_addoption", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "addoption", "(", "\n", "\"--runslow\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ",", "help", "=", "\"run slow tests\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.conftest.pytest_collection_modifyitems": [[12, 20], ["config.getoption", "pytest.mark.skip", "item.add_marker"], "function", ["None"], ["", "def", "pytest_collection_modifyitems", "(", "config", ",", "items", ")", ":", "\n", "    ", "if", "config", ".", "getoption", "(", "\"--runslow\"", ")", ":", "\n", "# --runslow given in cli: do not skip slow tests", "\n", "        ", "return", "\n", "", "skip_slow", "=", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"need --runslow option to run\"", ")", "\n", "for", "item", "in", "items", ":", "\n", "        ", "if", "\"slow\"", "in", "item", ".", "keywords", ":", "\n", "            ", "item", ".", "add_marker", "(", "skip_slow", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_common_test.TFModelUtilsTest.test_model_from_pretrained": [[426, 429], ["pytest.mark.skipif"], "methods", ["None"], ["    ", "@", "pytest", ".", "mark", ".", "skipif", "(", "'tensorflow'", "not", "in", "sys", ".", "modules", ",", "reason", "=", "\"requires TensorFlow\"", ")", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "# logging.basicConfig(level=logging.INFO)", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_common_test._config_zero_init": [[56, 62], ["copy.deepcopy", "copy.deepcopy.__dict__.keys", "setattr"], "function", ["None"], ["", "def", "_config_zero_init", "(", "config", ")", ":", "\n", "    ", "configs_no_init", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "for", "key", "in", "configs_no_init", ".", "__dict__", ".", "keys", "(", ")", ":", "\n", "        ", "if", "'_range'", "in", "key", "or", "'_std'", "in", "key", ":", "\n", "            ", "setattr", "(", "configs_no_init", ",", "key", ",", "0.0", ")", "\n", "", "", "return", "configs_no_init", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_common_test.ids_tensor": [[405, 423], ["range", "tf.constant", "random.Random", "values.append", "random.Random.randint"], "function", ["None"], ["", "", "", "", "def", "ids_tensor", "(", "shape", ",", "vocab_size", ",", "rng", "=", "None", ",", "name", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a random int32 tensor of the shape within the vocab size.\"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "        ", "rng", "=", "random", ".", "Random", "(", ")", "\n", "\n", "", "total_dims", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "        ", "total_dims", "*=", "dim", "\n", "\n", "", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "total_dims", ")", ":", "\n", "        ", "values", ".", "append", "(", "rng", ".", "randint", "(", "0", ",", "vocab_size", "-", "1", ")", ")", "\n", "\n", "", "output", "=", "tf", ".", "constant", "(", "values", ",", "\n", "shape", "=", "shape", ",", "\n", "dtype", "=", "dtype", "if", "dtype", "is", "not", "None", "else", "tf", ".", "int32", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlm_test.TFXLMModelTest.setUp": [[231, 234], ["TFXLMModelTest.TFXLMModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFXLMModelTest", ".", "TFXLMModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLMConfig", ",", "emb_dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlm_test.TFXLMModelTest.test_config": [[235, 237], ["modeling_tf_xlm_test.TFXLMModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlm_test.TFXLMModelTest.test_xlm_model": [[238, 241], ["modeling_tf_xlm_test.TFXLMModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlm_test.TFXLMModelTest.model_tester.create_and_check_xlm_model"], "methods", ["None"], ["", "def", "test_xlm_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlm_test.TFXLMModelTest.test_xlm_lm_head": [[242, 245], ["modeling_tf_xlm_test.TFXLMModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlm_test.TFXLMModelTest.model_tester.create_and_check_xlm_lm_head"], "methods", ["None"], ["", "def", "test_xlm_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlm_test.TFXLMModelTest.test_xlm_qa": [[246, 249], ["modeling_tf_xlm_test.TFXLMModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlm_test.TFXLMModelTest.model_tester.create_and_check_xlm_qa"], "methods", ["None"], ["", "def", "test_xlm_qa", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlm_test.TFXLMModelTest.test_xlm_sequence_classif": [[250, 253], ["modeling_tf_xlm_test.TFXLMModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_xlm_test.TFXLMModelTest.model_tester.create_and_check_xlm_sequence_classif"], "methods", ["None"], ["", "def", "test_xlm_sequence_classif", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_xlm_test.TFXLMModelTest.test_model_from_pretrained": [[254, 261], ["list", "XLMModel.from_pretrained", "shutil.rmtree", "modeling_tf_xlm_test.TFXLMModelTest.assertIsNotNone", "TF_XLM_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TF_XLM_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XLMModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlm_test.XLMTokenizationTest.setUp": [[29, 46], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "XLMTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"w</w>\"", ",", "\"r</w>\"", ",", "\"t</w>\"", ",", "\n", "\"lo\"", ",", "\"low\"", ",", "\"er</w>\"", ",", "\n", "\"low</w>\"", ",", "\"lowest</w>\"", ",", "\"newer</w>\"", ",", "\"wider</w>\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"l o 123\"", ",", "\"lo w 1456\"", ",", "\"e r</w> 1789\"", ",", "\"\"", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlm_test.XLMTokenizationTest.get_tokenizer": [[47, 49], ["transformers.tokenization_xlm.XLMTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "XLMTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlm_test.XLMTokenizationTest.get_input_output_texts": [[50, 54], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlm_test.XLMTokenizationTest.test_full_tokenizer": [[55, 68], ["transformers.tokenization_xlm.XLMTokenizer", "transformers.tokenization_xlm.XLMTokenizer.tokenize", "tokenization_xlm_test.XLMTokenizationTest.assertListEqual", "tokenization_xlm_test.XLMTokenizationTest.assertListEqual", "transformers.tokenization_xlm.XLMTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "\"\"\" Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt \"\"\"", "\n", "tokenizer", "=", "XLMTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ")", "\n", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er</w>\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "\"<unk>\"", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "20", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_xlm_test.XLMTokenizationTest.test_sequence_builders": [[69, 80], ["transformers.tokenization_xlm.XLMTokenizer.from_pretrained", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.encode", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.encode", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLMTokenizer", ".", "from_pretrained", "(", "\"xlm-mlm-en-2048\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "1", "]", "+", "text", "+", "[", "1", "]", "\n", "assert", "encoded_pair", "==", "[", "1", "]", "+", "text", "+", "[", "1", "]", "+", "text_2", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.setUp": [[33, 43], ["super().setUp", "os.path.join", "io.open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "BertTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"want\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"wa\"", ",", "\"un\"", ",", "\"runn\"", ",", "\n", "\"##ing\"", ",", "\",\"", ",", "\"low\"", ",", "\"lowest\"", ",", "\n", "]", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.get_tokenizer": [[44, 46], ["transformers.tokenization_bert.BertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.get_input_output_texts": [[47, 51], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"UNwant\\u00E9d,running\"", "\n", "output_text", "=", "u\"unwanted, running\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_full_tokenizer": [[52, 58], ["tokenization_bert_test.BertTokenizationTest.tokenizer_class", "tokenization_bert_test.BertTokenizationTest.tokenize", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", "(", "self", ".", "vocab_file", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"UNwant\\u00E9d,running\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"un\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\",\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "7", ",", "4", ",", "5", ",", "10", ",", "8", ",", "9", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_chinese": [[59, 65], ["transformers.tokenization_bert.BasicTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_chinese", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\"ah\\u535A\\u63A8zz\"", ")", ",", "\n", "[", "u\"ah\"", ",", "u\"\\u535A\"", ",", "u\"\\u63A8\"", ",", "u\"zz\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_basic_tokenizer_lower": [[66, 73], ["transformers.tokenization_bert.BasicTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.BasicTokenizer.tokenize", "transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_basic_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo!how  \\n Are yoU?  \"", ")", ",", "\n", "[", "\"hello\"", ",", "\"!\"", ",", "\"how\"", ",", "\"are\"", ",", "\"you\"", ",", "\"?\"", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "u\"H\\u00E9llo\"", ")", ",", "[", "\"hello\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_basic_tokenizer_no_lower": [[74, 80], ["transformers.tokenization_bert.BasicTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_basic_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo!how  \\n Are yoU?  \"", ")", ",", "\n", "[", "\"HeLLo\"", ",", "\"!\"", ",", "\"how\"", ",", "\"Are\"", ",", "\"yoU\"", ",", "\"?\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_wordpiece_tokenizer": [[81, 100], ["enumerate", "transformers.tokenization_bert.WordpieceTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.WordpieceTokenizer.tokenize", "transformers.tokenization_bert.WordpieceTokenizer.tokenize", "transformers.tokenization_bert.WordpieceTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "test_wordpiece_tokenizer", "(", "self", ")", ":", "\n", "        ", "vocab_tokens", "=", "[", "\n", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"want\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"wa\"", ",", "\"un\"", ",", "\"runn\"", ",", "\n", "\"##ing\"", "\n", "]", "\n", "\n", "vocab", "=", "{", "}", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "vocab_tokens", ")", ":", "\n", "            ", "vocab", "[", "token", "]", "=", "i", "\n", "", "tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\"", ")", ",", "[", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\"unwanted running\"", ")", ",", "\n", "[", "\"un\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\"unwantedX running\"", ")", ",", "[", "\"[UNK]\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_is_whitespace": [[101, 110], ["tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_whitespace"], ["", "def", "test_is_whitespace", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\" \"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\t\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\r\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\n\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\u00A0\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_whitespace", "(", "u\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_whitespace", "(", "u\"-\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_is_control": [[111, 118], ["tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_control"], ["", "def", "test_is_control", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_control", "(", "u\"\\u0005\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\" \"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\"\\t\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\"\\r\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_is_punctuation": [[119, 127], ["tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_bert._is_punctuation"], ["", "def", "test_is_punctuation", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\"-\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\"$\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\"`\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\".\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_punctuation", "(", "u\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_punctuation", "(", "u\" \"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.tokenization_bert_test.BertTokenizationTest.test_sequence_builders": [[128, 139], ["tokenization_bert_test.BertTokenizationTest.tokenizer_class.from_pretrained", "tokenization_bert_test.BertTokenizationTest.encode", "tokenization_bert_test.BertTokenizationTest.encode", "tokenization_bert_test.BertTokenizationTest.build_inputs_with_special_tokens", "tokenization_bert_test.BertTokenizationTest.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", ".", "from_pretrained", "(", "\"bert-base-uncased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "101", "]", "+", "text", "+", "[", "102", "]", "\n", "assert", "encoded_pair", "==", "[", "101", "]", "+", "text", "+", "[", "102", "]", "+", "text_2", "+", "[", "102", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.setUp": [[190, 193], ["TFTransfoXLModelTest.TFTransfoXLModelTester", "configuration_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFTransfoXLModelTest", ".", "TFTransfoXLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "TransfoXLConfig", ",", "d_embed", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.test_config": [[194, 196], ["modeling_tf_transfo_xl_test.TFTransfoXLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.tests.configuration_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.test_transfo_xl_model": [[197, 201], ["modeling_tf_transfo_xl_test.TFTransfoXLModelTest.model_tester.set_seed", "modeling_tf_transfo_xl_test.TFTransfoXLModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_transfo_xl_test.TFTransfoXLModelTest.model_tester.create_and_check_transfo_xl_model"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_transfo_xl_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_transfo_xl_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.test_transfo_xl_lm_head": [[202, 206], ["modeling_tf_transfo_xl_test.TFTransfoXLModelTest.model_tester.set_seed", "modeling_tf_transfo_xl_test.TFTransfoXLModelTest.model_tester.prepare_config_and_inputs", "modeling_tf_transfo_xl_test.TFTransfoXLModelTest.model_tester.create_and_check_transfo_xl_lm_head"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed"], ["", "def", "test_transfo_xl_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_transfo_xl_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.tests.modeling_tf_transfo_xl_test.TFTransfoXLModelTest.test_model_from_pretrained": [[207, 214], ["list", "TFTransfoXLModel.from_pretrained", "shutil.rmtree", "modeling_tf_transfo_xl_test.TFTransfoXLModelTest.assertIsNotNone", "TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFTransfoXLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MrpcProcessor.get_example_from_tensor_dict": [[156, 162], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'sentence1'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "tensor_dict", "[", "'sentence2'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MrpcProcessor.get_train_examples": [[163, 168], ["logger.info", "glue.MrpcProcessor._create_examples", "glue.MrpcProcessor._read_tsv", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MrpcProcessor.get_dev_examples": [[169, 173], ["glue.MrpcProcessor._create_examples", "glue.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MrpcProcessor.get_labels": [[174, 177], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MrpcProcessor._create_examples": [[178, 191], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "label", "=", "line", "[", "0", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MnliProcessor.get_example_from_tensor_dict": [[196, 202], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'premise'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "tensor_dict", "[", "'hypothesis'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MnliProcessor.get_train_examples": [[203, 207], ["glue.MnliProcessor._create_examples", "glue.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MnliProcessor.get_dev_examples": [[208, 213], ["glue.MnliProcessor._create_examples", "glue.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_matched.tsv\"", ")", ")", ",", "\n", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MnliProcessor.get_labels": [[214, 217], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MnliProcessor._create_examples": [[218, 231], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "8", "]", "\n", "text_b", "=", "line", "[", "9", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.MnliMismatchedProcessor.get_dev_examples": [[236, 241], ["glue.MnliMismatchedProcessor._create_examples", "glue.MnliMismatchedProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ")", ",", "\n", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.ColaProcessor.get_example_from_tensor_dict": [[246, 252], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'sentence'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "None", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.ColaProcessor.get_train_examples": [[253, 257], ["glue.ColaProcessor._create_examples", "glue.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.ColaProcessor.get_dev_examples": [[258, 262], ["glue.ColaProcessor._create_examples", "glue.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.ColaProcessor.get_labels": [[263, 266], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.ColaProcessor._create_examples": [[267, 277], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.Sst2Processor.get_example_from_tensor_dict": [[282, 288], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'sentence'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "None", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.Sst2Processor.get_train_examples": [[289, 293], ["glue.Sst2Processor._create_examples", "glue.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.Sst2Processor.get_dev_examples": [[294, 298], ["glue.Sst2Processor._create_examples", "glue.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.Sst2Processor.get_labels": [[299, 302], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.Sst2Processor._create_examples": [[303, 315], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "0", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.StsbProcessor.get_example_from_tensor_dict": [[320, 326], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'sentence1'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "tensor_dict", "[", "'sentence2'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.StsbProcessor.get_train_examples": [[327, 331], ["glue.StsbProcessor._create_examples", "glue.StsbProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.StsbProcessor.get_dev_examples": [[332, 336], ["glue.StsbProcessor._create_examples", "glue.StsbProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.StsbProcessor.get_labels": [[337, 340], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.StsbProcessor._create_examples": [[341, 354], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "7", "]", "\n", "text_b", "=", "line", "[", "8", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QqpProcessor.get_example_from_tensor_dict": [[359, 365], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'question1'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "tensor_dict", "[", "'question2'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QqpProcessor.get_train_examples": [[366, 370], ["glue.QqpProcessor._create_examples", "glue.QqpProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QqpProcessor.get_dev_examples": [[371, 375], ["glue.QqpProcessor._create_examples", "glue.QqpProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QqpProcessor.get_labels": [[376, 379], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QqpProcessor._create_examples": [[380, 396], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "try", ":", "\n", "                ", "text_a", "=", "line", "[", "3", "]", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "label", "=", "line", "[", "5", "]", "\n", "", "except", "IndexError", ":", "\n", "                ", "continue", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QnliProcessor.get_example_from_tensor_dict": [[401, 407], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'question'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "tensor_dict", "[", "'sentence'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QnliProcessor.get_train_examples": [[408, 412], ["glue.QnliProcessor._create_examples", "glue.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QnliProcessor.get_dev_examples": [[413, 418], ["glue.QnliProcessor._create_examples", "glue.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\n", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QnliProcessor.get_labels": [[419, 422], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.QnliProcessor._create_examples": [[423, 436], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.RteProcessor.get_example_from_tensor_dict": [[441, 447], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'sentence1'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "tensor_dict", "[", "'sentence2'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.RteProcessor.get_train_examples": [[448, 452], ["glue.RteProcessor._create_examples", "glue.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.RteProcessor.get_dev_examples": [[453, 457], ["glue.RteProcessor._create_examples", "glue.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.RteProcessor.get_labels": [[458, 461], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.RteProcessor._create_examples": [[462, 475], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor.get_example_from_tensor_dict": [[480, 486], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "tensor_dict", "[", "'idx'", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "'sentence1'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "tensor_dict", "[", "'sentence2'", "]", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "str", "(", "tensor_dict", "[", "'label'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor.get_train_examples": [[487, 491], ["glue.WnliProcessor._create_examples", "glue.WnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor.get_dev_examples": [[492, 496], ["glue.WnliProcessor._create_examples", "glue.WnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor.get_labels": [[497, 500], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.WnliProcessor._create_examples": [[501, 514], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.glue.glue_convert_examples_to_features": [[30, 151], ["enumerate", "file_utils.is_tf_available", "isinstance", "tokenizer.encode_plus", "features.append", "file_utils.is_tf_available", "tf.data.Dataset.from_generator", "processor.get_labels", "logger.info", "logger.info", "enumerate", "logger.info", "processor.get_example_from_tensor_dict", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "float", "KeyError", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_labels", "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor.get_example_from_tensor_dict"], ["def", "glue_convert_examples_to_features", "(", "examples", ",", "tokenizer", ",", "\n", "max_length", "=", "512", ",", "\n", "task", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "output_mode", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of ``InputFeatures``\n\n    Args:\n        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n        tokenizer: Instance of a tokenizer that will tokenize the examples\n        max_length: Maximum example length\n        task: GLUE task\n        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n        pad_token: Padding token\n        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n            actual values)\n\n    Returns:\n        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n        a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n    \"\"\"", "\n", "is_tf_dataset", "=", "False", "\n", "if", "is_tf_available", "(", ")", "and", "isinstance", "(", "examples", ",", "tf", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "is_tf_dataset", "=", "True", "\n", "\n", "", "if", "task", "is", "not", "None", ":", "\n", "        ", "processor", "=", "glue_processors", "[", "task", "]", "(", ")", "\n", "if", "label_list", "is", "None", ":", "\n", "            ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "logger", ".", "info", "(", "\"Using label list %s for task %s\"", "%", "(", "label_list", ",", "task", ")", ")", "\n", "", "if", "output_mode", "is", "None", ":", "\n", "            ", "output_mode", "=", "glue_output_modes", "[", "task", "]", "\n", "logger", ".", "info", "(", "\"Using output mode %s for task %s\"", "%", "(", "output_mode", ",", "task", ")", ")", "\n", "\n", "", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d\"", "%", "(", "ex_index", ")", ")", "\n", "", "if", "is_tf_dataset", ":", "\n", "            ", "example", "=", "processor", ".", "get_example_from_tensor_dict", "(", "example", ")", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "\n", "example", ".", "text_a", ",", "\n", "example", ".", "text_b", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "max_length", ",", "\n", ")", "\n", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "input_ids", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "attention_mask", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "token_type_ids", ")", ",", "max_length", ")", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "token_type_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "label", "=", "label", ")", ")", "\n", "\n", "", "if", "is_tf_available", "(", ")", "and", "is_tf_dataset", ":", "\n", "        ", "def", "gen", "(", ")", ":", "\n", "            ", "for", "ex", "in", "features", ":", "\n", "                ", "yield", "(", "{", "'input_ids'", ":", "ex", ".", "input_ids", ",", "\n", "'attention_mask'", ":", "ex", ".", "attention_mask", ",", "\n", "'token_type_ids'", ":", "ex", ".", "token_type_ids", "}", ",", "\n", "ex", ".", "label", ")", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "gen", ",", "\n", "(", "{", "'input_ids'", ":", "tf", ".", "int32", ",", "\n", "'attention_mask'", ":", "tf", ".", "int32", ",", "\n", "'token_type_ids'", ":", "tf", ".", "int32", "}", ",", "\n", "tf", ".", "int64", ")", ",", "\n", "(", "{", "'input_ids'", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "'attention_mask'", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "'token_type_ids'", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", "}", ",", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputExample.__init__": [[35, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputExample.__repr__": [[41, 43], ["str", "utils.InputExample.to_json_string"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputExample.to_dict": [[44, 48], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputExample.to_json_string": [[49, 52], ["json.dumps", "utils.InputExample.to_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.__init__": [[67, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "label", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.__repr__": [[73, 75], ["str", "utils.InputFeatures.to_json_string"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict": [[76, 80], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string": [[81, 84], ["json.dumps", "utils.InputFeatures.to_dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor.get_example_from_tensor_dict": [[89, 97], ["NotImplementedError"], "methods", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"Gets an example from a dict with tensorflow tensors\n\n        Args:\n            tensor_dict: Keys and values should match the corresponding Glue\n                tensorflow_dataset examples.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor.get_train_examples": [[98, 101], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor.get_dev_examples": [[102, 105], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor.get_labels": [[106, 109], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.DataProcessor._read_tsv": [[110, 121], ["open", "csv.reader", "lines.append", "list", "unicode"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.nn": [[7, 19], ["torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "range", "torch.cat().numpy", "len", "torch.from_numpy().cuda.mm().mm().t", "indexes.append", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "[].cpu", "torch.cat", "tgt_vec.astype", "eng_vec.astype", "torch.from_numpy().cuda.astype", "torch.from_numpy().cuda.mm().mm", "eng[].t", "torch.from_numpy().cuda.mm", "torch.max"], "function", ["None"], ["def", "nn", "(", "tgt_vec", ",", "eng_vec", ",", "O", ",", "bs", ")", ":", "\n", "    ", "esp", "=", "torch", ".", "from_numpy", "(", "tgt_vec", ".", "astype", "(", "'float32'", ")", ")", ".", "cuda", "(", ")", "\n", "eng", "=", "torch", ".", "from_numpy", "(", "eng_vec", ".", "astype", "(", "'float32'", ")", ")", ".", "cuda", "(", ")", "\n", "O", "=", "torch", ".", "from_numpy", "(", "O", ".", "astype", "(", "'float32'", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "indexes", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "eng_vec", ")", ",", "bs", ")", ":", "\n", "        ", "cossim", "=", "esp", ".", "mm", "(", "O", ")", ".", "mm", "(", "eng", "[", "i", ":", "i", "+", "bs", "]", ".", "t", "(", ")", ")", ".", "t", "(", ")", "\n", "indexes", ".", "append", "(", "torch", ".", "max", "(", "cossim", ",", "1", ")", "[", "1", "]", ".", "cpu", "(", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "indexes", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.get_nn_avg_dist": [[20, 35], ["range", "range", "esp.size", "esp[].mm().mm", "torch.topk", "distance_esp.append", "eng.size", "esp.mm().mm().t", "torch.topk", "distance_eng.append", "torch.cat", "torch.cat", "eng.t", "tgt_dist.mean", "eng_dist.mean", "esp[].mm", "esp.mm().mm", "eng[].t", "esp.mm"], "function", ["None"], ["", "def", "get_nn_avg_dist", "(", "esp", ",", "eng", ",", "O", ",", "k", ",", "bs", ")", ":", "\n", "    ", "distance_esp", "=", "[", "]", "\n", "distance_eng", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "esp", ".", "size", "(", "0", ")", ",", "bs", ")", ":", "\n", "        ", "cossim_esp", "=", "esp", "[", "i", ":", "i", "+", "bs", "]", ".", "mm", "(", "O", ")", ".", "mm", "(", "eng", ".", "t", "(", ")", ")", "\n", "tgt_dist", ",", "_", "=", "torch", ".", "topk", "(", "cossim_esp", ",", "k", ")", "\n", "distance_esp", ".", "append", "(", "tgt_dist", ".", "mean", "(", "1", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "0", ",", "eng", ".", "size", "(", "0", ")", ",", "bs", ")", ":", "\n", "        ", "cossim_eng", "=", "esp", ".", "mm", "(", "O", ")", ".", "mm", "(", "eng", "[", "i", ":", "i", "+", "bs", "]", ".", "t", "(", ")", ")", ".", "t", "(", ")", "\n", "eng_dist", ",", "_", "=", "torch", ".", "topk", "(", "cossim_eng", ",", "k", ")", "\n", "distance_eng", ".", "append", "(", "eng_dist", ".", "mean", "(", "1", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "distance_esp", ")", ",", "torch", ".", "cat", "(", "distance_eng", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.csls": [[36, 52], ["torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "translate.get_nn_avg_dist", "range", "torch.cat().numpy", "len", "torch.from_numpy().cuda.mm().mm().t", "indexes.append", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "tgt_distance.unsqueeze", "[].cpu", "torch.cat", "tgt_vec.astype", "eng_vec.astype", "torch.from_numpy().cuda.astype", "torch.from_numpy().cuda.mm().mm", "eng_distance[].unsqueeze", "eng[].t", "torch.from_numpy().cuda.mm", "torch.max"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.get_nn_avg_dist"], ["", "def", "csls", "(", "tgt_vec", ",", "eng_vec", ",", "O", ",", "k", ",", "bs", ")", ":", "\n", "    ", "esp", "=", "torch", ".", "from_numpy", "(", "tgt_vec", ".", "astype", "(", "'float32'", ")", ")", ".", "cuda", "(", ")", "\n", "eng", "=", "torch", ".", "from_numpy", "(", "eng_vec", ".", "astype", "(", "'float32'", ")", ")", ".", "cuda", "(", ")", "\n", "O", "=", "torch", ".", "from_numpy", "(", "O", ".", "astype", "(", "'float32'", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "tgt_distance", ",", "eng_distance", "=", "get_nn_avg_dist", "(", "esp", ",", "eng", ",", "O", ",", "k", ",", "bs", ")", "\n", "\n", "all_scores", "=", "[", "]", "\n", "indexes", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "eng_vec", ")", ",", "bs", ")", ":", "\n", "        ", "cossim", "=", "esp", ".", "mm", "(", "O", ")", ".", "mm", "(", "eng", "[", "i", ":", "i", "+", "bs", "]", ".", "t", "(", ")", ")", ".", "t", "(", ")", "\n", "scores", "=", "cossim", "*", "2", "-", "eng_distance", "[", "i", ":", "i", "+", "bs", "]", ".", "unsqueeze", "(", "1", ")", "-", "tgt_distance", ".", "unsqueeze", "(", "0", ")", "\n", "indexes", ".", "append", "(", "torch", ".", "max", "(", "scores", ",", "1", ")", "[", "1", "]", ".", "cpu", "(", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "indexes", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.load_embedding": [[53, 78], ["open", "print", "len", "translate.normalize", "line.rstrip().split", "len", "words.append", "numpy.array", "word_vector.append", "numpy.vstack", "np.array.split", "print", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.normalize"], ["", "def", "load_embedding", "(", "path", ",", "vocab_size", ")", ":", "\n", "    ", "word_vector", "=", "[", "]", "\n", "word_dict", "=", "{", "}", "\n", "words", "=", "[", "]", "\n", "\n", "num", "=", "0", "\n", "\n", "for", "line", "in", "open", "(", "path", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "        ", "if", "num", "==", "0", ":", "\n", "            ", "num", "+=", "1", "\n", "continue", "\n", "", "if", "num", "<", "vocab_size", ":", "\n", "            ", "word", ",", "vec", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "word_dict", "[", "word", "]", "=", "len", "(", "word_dict", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "vec", "=", "np", ".", "array", "(", "vec", ".", "split", "(", ")", ",", "dtype", "=", "'float32'", ")", "\n", "word_vector", ".", "append", "(", "vec", ")", "\n", "\n", "num", "+=", "1", "\n", "if", "num", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "'To word #%d'", "%", "num", ")", "\n", "\n", "", "", "", "print", "(", "len", "(", "word_vector", ")", ")", "\n", "\n", "return", "word_dict", ",", "normalize", "(", "np", ".", "vstack", "(", "word_vector", ")", ")", ",", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.normalize": [[79, 81], ["numpy.linalg.norm().reshape", "numpy.linalg.norm"], "function", ["None"], ["", "def", "normalize", "(", "vectors", ")", ":", "\n", "    ", "return", "vectors", "/", "LA", ".", "norm", "(", "vectors", ",", "axis", "=", "1", ")", ".", "reshape", "(", "(", "vectors", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.generate_dict": [[82, 109], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "translate.load_embedding", "print", "translate.load_embedding", "torch.load", "open", "range", "open.close", "translate.csls", "len", "open.write", "translate.nn"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.load_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.load_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.csls", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.nn"], ["", "def", "generate_dict", "(", "args", ")", ":", "\n", "    ", "dict_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'en2{}/muse/dict.txt'", ".", "format", "(", "args", ".", "tgt_lang", ")", ")", "\n", "mapping_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'en2{}/muse/best_mapping.pth'", ".", "format", "(", "args", ".", "tgt_lang", ")", ")", "\n", "tgt_embed_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "embed_dir", ",", "\"wiki.{}.vec\"", ".", "format", "(", "args", ".", "tgt_lang", ")", ")", "\n", "src_embed_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "embed_dir", ",", "\"wiki.en.vec\"", ")", "\n", "\n", "print", "(", "'loading eng embedding...'", ")", "\n", "eng_word", ",", "eng_vec", ",", "engs", "=", "load_embedding", "(", "src_embed_path", ",", "args", ".", "vocab_size", ")", "\n", "\n", "print", "(", "'loading tgt embedding...'", ")", "\n", "tgt_word", ",", "tgt_vec", ",", "esps", "=", "load_embedding", "(", "tgt_embed_path", ",", "args", ".", "vocab_size", ")", "\n", "\n", "O", "=", "torch", ".", "load", "(", "mapping_path", ")", "\n", "\n", "if", "args", ".", "distance", "==", "'csls'", ":", "\n", "        ", "indexes", "=", "csls", "(", "tgt_vec", ",", "eng_vec", ",", "O", ",", "args", ".", "k", ",", "args", ".", "batch_size", ")", "\n", "", "elif", "args", ".", "distance", "==", "'nn'", ":", "\n", "        ", "indexes", "=", "nn", "(", "tgt_vec", ",", "eng_vec", ",", "O", ",", "args", ".", "batch_size", ")", "\n", "\n", "", "output", "=", "open", "(", "dict_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "engs", ")", ")", ":", "\n", "        ", "output", ".", "write", "(", "engs", "[", "i", "]", "+", "' '", "+", "esps", "[", "indexes", "[", "i", "]", "]", "+", "'\\n'", ")", "\n", "\n", "", "output", ".", "close", "(", ")", "\n", "\n", "return", "dict_path", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.get_lower_vocab": [[112, 135], ["vocab.items", "print", "open", "line.strip.strip", "sum", "len", "len", "line.strip.split", "word.lower", "numpy.zeros", "word.lower", "word.capitalize", "word.lower", "word.lower", "word.lower", "word.lower"], "function", ["None"], ["", "def", "get_lower_vocab", "(", "fn", ")", ":", "\n", "    ", "vocab", "=", "{", "}", "\n", "with", "open", "(", "fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "word", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "word", ".", "lower", "(", ")", "not", "in", "vocab", ":", "\n", "                ", "vocab", "[", "word", ".", "lower", "(", ")", "]", "=", "np", ".", "zeros", "(", "3", ")", "# {word: [n_lower_case, n_capital, n_upper_case]}", "\n", "", "if", "word", "==", "word", ".", "lower", "(", ")", ":", "\n", "                ", "vocab", "[", "word", ".", "lower", "(", ")", "]", "[", "0", "]", "+=", "1", "\n", "", "elif", "word", "==", "word", ".", "capitalize", "(", ")", ":", "\n", "                ", "vocab", "[", "word", ".", "lower", "(", ")", "]", "[", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "vocab", "[", "word", ".", "lower", "(", ")", "]", "[", "2", "]", "+=", "1", "\n", "\n", "", "", "", "for", "k", ",", "v", "in", "vocab", ".", "items", "(", ")", ":", "\n", "        ", "vocab", "[", "k", "]", "=", "v", "/", "sum", "(", "v", ")", "\n", "\n", "", "print", "(", "'The vocab size is %d'", "%", "len", "(", "vocab", ")", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.adjust_case_with_ner_vocab": [[136, 148], ["numpy.random.choice", "word.upper.capitalize", "word.upper.upper"], "function", ["None"], ["", "def", "adjust_case_with_ner_vocab", "(", "word", ",", "tgt_ner_vocab_lower", ")", ":", "\n", "    ", "p_case", "=", "tgt_ner_vocab_lower", "[", "word", "]", "\n", "id_case", "=", "np", ".", "random", ".", "choice", "(", "3", ",", "p", "=", "p_case", ")", "\n", "\n", "if", "id_case", "==", "1", ":", "# 0: n_lower_case, 1: n_capital, 2: n_upper_case", "\n", "        ", "word", "=", "word", ".", "capitalize", "(", ")", "\n", "", "elif", "id_case", "==", "2", ":", "\n", "        ", "word", "=", "word", ".", "upper", "(", ")", "\n", "", "else", ":", "\n", "        ", "word", "=", "word", "\n", "\n", "", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.translate": [[149, 185], ["open", "line.rstrip().split", "tgt.lower", "open", "enumerate", "open", "line.rstrip", "len", "fw.write", "line.strip().split", "print", "line.strip", "fw.write", "fw.write", "line.strip", "temp.upper.lower", "translate.adjust_case_with_ner_vocab", "temp.upper.isupper", "temp.upper.lower", "temp.upper", "word[].isupper", "temp[].upper"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.adjust_case_with_ner_vocab"], ["", "def", "translate", "(", "dict_en_tgt_path", ",", "output_fn", ",", "args", ",", "tgt_ner_vocab_lower", "=", "None", ")", ":", "\n", "# training_data = 'data/ner/conll/en/train.txt' # source training data file", "\n", "    ", "training_data", "=", "f\"{args.data_dir}/en/train.txt\"", "\n", "\n", "word_dict", "=", "{", "}", "\n", "for", "line", "in", "open", "(", "dict_en_tgt_path", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "        ", "src", ",", "tgt", "=", "line", ".", "rstrip", "(", "'\\n'", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "word_dict", "[", "src", "]", "=", "tgt", ".", "lower", "(", ")", "\n", "\n", "", "with", "open", "(", "output_fn", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "\n", "        ", "for", "idx", ",", "line", "in", "enumerate", "(", "open", "(", "training_data", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", ")", ":", "\n", "            ", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                ", "fw", ".", "write", "(", "line", ")", "\n", "", "else", ":", "\n", "                ", "word", ",", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "# [word, label]", "\n", "\n", "if", "label", "[", "2", ":", "]", "==", "'PER'", "or", "word", ".", "lower", "(", ")", "not", "in", "word_dict", ":", "\n", "                    ", "fw", ".", "write", "(", "word", "+", "' '", "+", "label", "+", "'\\n'", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "temp", "=", "word_dict", "[", "word", ".", "lower", "(", ")", "]", "\n", "if", "tgt_ner_vocab_lower", "is", "not", "None", "and", "temp", "in", "tgt_ner_vocab_lower", ":", "\n", "                        ", "word", "=", "adjust_case_with_ner_vocab", "(", "temp", ",", "tgt_ner_vocab_lower", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "if", "word", ".", "isupper", "(", ")", ":", "\n", "                            ", "word", "=", "temp", ".", "upper", "(", ")", "\n", "", "elif", "word", "[", "0", "]", ".", "isupper", "(", ")", ":", "\n", "                            ", "word", "=", "temp", "[", "0", "]", ".", "upper", "(", ")", "+", "temp", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                            ", "word", "=", "temp", "\n", "\n", "", "", "fw", ".", "write", "(", "word", "+", "' '", "+", "label", "+", "'\\n'", ")", "\n", "", "", "if", "(", "idx", "+", "1", ")", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "'Translate tokens #%d'", "%", "(", "idx", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.main": [[188, 198], ["translate.generate_dict", "os.path.join", "translate.translate", "translate.get_lower_vocab", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.generate_dict", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.translate", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.translate.get_lower_vocab"], ["", "", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "dict_path", "=", "generate_dict", "(", "args", ")", "# according to loaded embeddings", "\n", "fn_ner_translated", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"en2{}/train.txt\"", ".", "format", "(", "args", ".", "tgt_lang", ")", ")", "\n", "\n", "if", "args", ".", "tgt_lang", "==", "'de'", ":", "# adjust capitalization", "\n", "        ", "tgt_ner_vocab_lower", "=", "get_lower_vocab", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "tgt_lang", ",", "\"train.txt\"", ")", ")", "\n", "", "else", ":", "\n", "        ", "tgt_ner_vocab_lower", "=", "None", "\n", "\n", "", "translate", "(", "dict_path", ",", "fn_ner_translated", ",", "args", ",", "tgt_ner_vocab_lower", "=", "tgt_ner_vocab_lower", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.modeling.BertForTokenClassification_.forward": [[44, 113], ["modeling.BertForTokenClassification_.bert", "modeling.BertForTokenClassification_.dropout", "modeling.BertForTokenClassification_.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "labels.view", "active_CE.view", "modeling.BertForTokenClassification_.view", "torch.mean", "torch.mean", "torch.nn.MSELoss", "torch.nn.functional.softmax", "torch.nn.MSELoss.", "attention_mask.view", "pseudo_labels.view", "labels.view", "src_probs.view", "torch.mean", "range", "torch.nn.MSELoss.view", "len", "active_loss.view"], "methods", ["None"], ["start_id", "=", "end_id", "\n", "\n", "# max-loss", "\n", "", "", "if", "lambda_max_loss", "!=", "0.0", ":", "\n", "                    ", "loss_max", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "active_max", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss_max", "=", "0.0", "\n", "\n", "# mask-loss", "\n", "", "if", "lambda_mask_loss", "!=", "0.0", ":", "\n", "                    ", "active_mask", "=", "torch", ".", "cat", "(", "active_mask", ")", "\n", "if", "sum", "(", "active_mask", ")", "!=", "0", ":", "\n", "                        ", "loss_mask", "=", "torch", ".", "sum", "(", "loss", "[", "active_mask", "]", ")", "/", "sum", "(", "active_mask", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss_mask", "=", "0.0", "\n", "\n", "", "return", "loss_crossEntropy", "+", "lambda_max_loss", "*", "loss_max", "+", "lambda_mask_loss", "*", "loss_mask", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "assert", "False", "\n", "", "", "else", ":", "\n", "            ", "return", "logits", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.modeling.BaseModel.__init__": [[116, 123], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Dropout", "modeling.BaseModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.modeling_utils.PreTrainedModel.init_weights"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.modeling.BaseModel.forward": [[124, 136], ["modeling.BaseModel.bert"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.modeling.ViterbiDecoder.__init__": [[138, 148], ["len", "torch.zeros", "range", "range", "enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.modeling.ViterbiDecoder.forward": [[149, 195], ["logprobs.size", "range", "ValueError", "range", "torch.max", "best_label_id.item.item.item", "reversed", "best_path.reverse", "label_seqs.append", "len", "torch.max", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy().tolist", "back_pointers.append", "best_path.append", "len", "len", "ValueError", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.set_seed": [[56, 63], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "train_meta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: Meta Learning **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "True", ",", "support_size", "=", "args", ".", "support_size", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "True", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_optimizer_grouped_parameters": [[64, 85], ["logger.info", "model.named_parameters", "model.named_parameters", "any", "logger.info", "model.named_parameters", "model.named_parameters", "any", "any"], "function", ["None"], ["corpus_en_valid", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'valid'", ",", "\n", "load_data", "=", "True", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_en_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "        ", "progress", "=", "1.0", "*", "step", "/", "args", ".", "max_meta_steps", "\n", "\n", "batch_query", ",", "batch_support", "=", "corpus_en_train", ".", "get_batch_meta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "#(batch_size=32)", "\n", "loss", "=", "learner", ".", "forward_meta", "(", "batch_query", ",", "batch_support", ",", "progress", "=", "progress", ",", "inner_steps", "=", "args", ".", "inner_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train": [[86, 186], ["tensorboardX.SummaryWriter", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "main.get_optimizer_grouped_parameters", "transformers.AdamW", "transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.zero_grad", "main.set_seed", "range", "tensorboardX.SummaryWriter.close", "max", "torch.nn.DataParallel", "len", "enumerate", "int", "torch.nn.DataParallel.train", "torch.nn.DataParallel.", "loss.mean.backward", "loss.mean.item", "len", "range", "str", "batch[].to", "batch[].to", "batch[].to", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "transformers.WarmupLinearSchedule.step", "transformers.AdamW.step", "torch.nn.DataParallel.zero_grad", "len", "str", "batch[].to", "torch.nn.DataParallel.parameters", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "logger.info", "main.evaluate", "results.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "transformers.WarmupLinearSchedule.get_lr", "transformers.WarmupLinearSchedule.get_lr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate"], ["", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [en] - [valid] **********\"", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_en_valid", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Valid F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "\n", "#########################################################", "\n", "# Transfer the source-trained model to target languages", "\n", "#########################################################", "\n", "\n", "", "def", "zero_shot_NOmeta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-NOmeta-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot NO meta learning **********\"", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "zero_shot_meta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot with meta learning (separate support set) **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "reprer", "=", "Reprer", "(", "args", ".", "bert_model", ")", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "\n", "args", ".", "lr_inner", ",", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "args", ".", "support_size", ",", "base_features", "=", "corpus_en_train", ".", "original_features", ",", "\n", "mask_rate", "=", "-", "1.0", ",", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] - support on [en] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_meta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lr", "=", "args", ".", "lr_finetune", ",", "steps", "=", "args", ".", "max_ft_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ",", "\n", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "k_shot", "(", "args", ")", ":", "\n", "# to define: k_shot, max_ft_steps, lr_finetune, lambda_max_loss", "\n", "    ", "res_filename", "=", "'{}/res-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: {}-shot fine-tuning **********\"", ".", "format", "(", "args", ".", "k_shot", ")", ")", "\n", "\n", "learner_pretrained", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train_KD": [[187, 310], ["tensorboardX.SummaryWriter", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "main.get_optimizer_grouped_parameters", "transformers.AdamW", "transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.zero_grad", "main.set_seed", "range", "tensorboardX.SummaryWriter.close", "max", "torch.nn.DataParallel", "len", "enumerate", "int", "torch.nn.DataParallel.train", "torch.nn.DataParallel.zero_grad", "torch.nn.DataParallel.", "loss_KD.mean.backward", "loss.mean.item", "loss_KD.mean.item", "len", "range", "str", "batch[].to", "batch[].to", "batch[].to", "logger.info", "loss.mean.mean", "loss_KD.mean.mean", "torch.nn.utils.clip_grad_norm_", "transformers.WarmupLinearSchedule.step", "transformers.AdamW.step", "len", "str", "batch[].to", "batch[].to", "torch.nn.DataParallel.parameters", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "len", "len", "logger.info", "main.evaluate", "results.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "transformers.WarmupLinearSchedule.get_lr", "transformers.WarmupLinearSchedule.get_lr"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate"], ["\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ",", "k_shot_prop", "=", "args", ".", "k_shot", ")", "# add k_shot_prop", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "deepcopy", "(", "learner_pretrained", ")", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "for", "ft_step", "in", "range", "(", "args", ".", "max_ft_steps", ")", ":", "\n", "            ", "data_batches", "=", "corpus_train", ".", "get_batches", "(", "args", ".", "inner_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", "\n", "\n", "for", "batch_data", "in", "data_batches", ":", "\n", "                ", "loss", "=", "learner", ".", "inner_update", "(", "batch_data", ",", "lr_curr", "=", "args", ".", "lr_finetune", ",", "inner_steps", "=", "1", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "", "if", "ft_step", "in", "[", "0", ",", "4", ",", "9", ",", "14", "]", ":", "\n", "                ", "logger", ".", "info", "(", "'Fine-tune Step: {}/{}, loss = {:8f}, time = {:2f}s.'", ".", "format", "(", "ft_step", ",", "args", ".", "max_ft_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test], Finetune step = {} **********\"", ".", "format", "(", "lang", ",", "ft_step", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "", "", "for", "i", ",", "lang", "in", "enumerate", "(", "languages", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "supervised_NOmeta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: Supervised & NO Meta Learning **********\"", ")", "\n", "lang", "=", "args", ".", "test_langs", "[", "0", "]", "\n", "logger", ".", "info", "(", "\"language: {}\"", ".", "format", "(", "lang", ")", ")", "\n", "\n", "# prepare dataset", "\n", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "\n", "        ", "batch_data", "=", "corpus_train", ".", "get_batch_NOmeta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "\n", "loss", "=", "learner", ".", "forward_NOmeta", "(", "batch_data", ",", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Test F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# dataset settings", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "help", "=", "'where to save the result.'", ",", "default", "=", "'test'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_langs'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'languages to test'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "type", "=", "str", ",", "help", "=", "'dir name of a trained model'", ",", "default", "=", "''", ")", "\n", "\n", "# activate zero_shot only", "\n", "parser", ".", "add_argument", "(", "'--zero_shot'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run 0-shot procedure only.'", ")", "\n", "# activate fine-tune only", "\n", "parser", ".", "add_argument", "(", "'--k_shot'", ",", "type", "=", "float", ",", "default", "=", "-", "1", ",", "help", "=", "'size of k-shot data: k, if >0,  will run fine-ture procedure'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_finetune'", ",", "type", "=", "float", ",", "help", "=", "'finetune learning rate, used in [test_meta]. and [k_shot setting]'", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--max_ft_steps'", ",", "type", "=", "int", ",", "help", "=", "'maximal steps token for fine-tune.'", ",", "default", "=", "1", ")", "# ===>", "\n", "\n", "# activate mBERT only", "\n", "parser", ".", "add_argument", "(", "'--no_meta_learning'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run mBERT only.'", ")", "\n", "parser", ".", "add_argument", "(", "'--supervised'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run mBERT only.'", ")", "\n", "\n", "# meta-learning", "\n", "parser", ".", "add_argument", "(", "'--inner_steps'", ",", "type", "=", "int", ",", "help", "=", "'every ** inner update for one meta-update'", ",", "default", "=", "2", ")", "# ===>", "\n", "parser", ".", "add_argument", "(", "'--inner_size'", ",", "type", "=", "int", ",", "help", "=", "'[number of tasks] for one meta-update'", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--support_size'", ",", "type", "=", "int", ",", "help", "=", "'support size (batch_size) for inner update'", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_inner'", ",", "type", "=", "float", ",", "help", "=", "'inner loop learning rate'", ",", "default", "=", "3e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_meta'", ",", "type", "=", "float", ",", "help", "=", "'meta learning rate'", ",", "default", "=", "3e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--max_meta_steps'", ",", "type", "=", "int", ",", "help", "=", "'maximal steps token for meta training.'", ",", "default", "=", "3001", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every_meta_steps'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_prop_inner'", ",", "type", "=", "int", ",", "help", "=", "'warm up proportion for inner update'", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_prop_meta'", ",", "type", "=", "int", ",", "help", "=", "'warm up proportion for meta update'", ",", "default", "=", "0.1", ")", "\n", "# parser.add_argument('--cross_meta_rate', type=float, help='when > 0, randomly flipping cross objective or normal objective', default=1.0)", "\n", "\n", "\n", "# training paramters", "\n", "parser", ".", "add_argument", "(", "'--mask_rate'", ",", "type", "=", "float", ",", "help", "=", "'the probability to [mask] a token with a B/I-XXX label.'", ",", "default", "=", "-", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_max_loss'", ",", "type", "=", "float", ",", "help", "=", "'the weight of the max-loss.'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_mask_loss'", ",", "type", "=", "float", ",", "help", "=", "'the weight of the mask-loss.'", ",", "default", "=", "0.0", ")", "\n", "\n", "\n", "# permanent params", "\n", "parser", ".", "add_argument", "(", "'--freeze_layer'", ",", "type", "=", "int", ",", "help", "=", "'the layer of mBERT to be frozen'", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seq_len'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.evaluate": [[312, 376], ["main.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "numpy.argmax", "range", "logger.info", "sorted", "max", "len", "tuple", "range", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "results.keys", "logger.info", "torch.no_grad", "model", "tmp_eval_loss.item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "enumerate", "range", "range", "str", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "out_label_list[].append", "preds_list[].append", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples"], ["help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"", "\n", "\"bert-base-multilingual-cased, bert-base-chinese.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "help", "=", "'Where do you want to store the pre-trained models downloaded from s3'", ",", "default", "=", "''", ")", "\n", "# expt setting", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "help", "=", "'random seed to reproduce the result.'", ",", "default", "=", "667", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_device'", ",", "type", "=", "int", ",", "help", "=", "'GPU device num'", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--py_alias'", ",", "type", "=", "str", ",", "help", "=", "'python alias'", ",", "default", "=", "'python'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "# setup random seed", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "\n", "# set up GPU device", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu_device", ")", "\n", "\n", "# setup logger settings", "\n", "if", "args", ".", "zero_shot", ":", "\n", "        ", "assert", "args", ".", "model_dir", "!=", "''", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_dir", ")", "and", "len", "(", "args", ".", "test_langs", ")", ">", "0", "\n", "if", "args", ".", "no_meta_learning", ":", "\n", "            ", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-0shot-NOmeta-{}.txt'", ".", "format", "(", "args", ".", "model_dir", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.txt'", ".", "format", "(", "\n", "args", ".", "model_dir", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "\n", "# dump args", "\n", "", "with", "Path", "(", "'{}/args-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "\n", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "args", ".", "result_dir", "=", "args", ".", "model_dir", "\n", "\n", "", "elif", "args", ".", "k_shot", ">", "0", ":", "\n", "        ", "assert", "args", ".", "model_dir", "!=", "''", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_dir", ")", "and", "len", "(", "args", ".", "test_langs", ")", ">", "0", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.txt'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "\n", "\n", "# dump args", "\n", "with", "Path", "(", "'{}/args-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "args", ".", "result_dir", "=", "args", ".", "model_dir", "\n", "", "elif", "args", ".", "supervised", ":", "\n", "        ", "assert", "args", ".", "model_dir", "==", "''", "\n", "# top_dir = 'models\\\\result-{}'.format(args.expt_comment)", "\n", "top_dir", "=", "'models'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "top_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "top_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", ")", "\n", "", "elif", "args", ".", "result_dir", "!=", "'test'", ":", "\n", "            ", "assert", "False", ",", "'Existing result directory!'", "\n", "\n", "", "args", ".", "result_dir", "=", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", "\n", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-training.txt'", ".", "format", "(", "args", ".", "result_dir", ")", ")", "\n", "\n", "# dump args", "\n", "with", "Path", "(", "'{}/args.json'", ".", "format", "(", "args", ".", "result_dir", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.evaluate_viterbi": [[377, 450], ["main.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "modeling.ViterbiDecoder", "model.eval", "range", "logger.info", "sorted", "max", "len", "tuple", "torch.nn.functional.log_softmax", "modeling.ViterbiDecoder.forward", "pred_label_list.extend", "len", "ValueError", "range", "results.keys", "logger.info", "torch.no_grad", "model", "tmp_eval_loss.item", "logits.detach", "inputs[].detach().cpu().numpy", "numpy.append", "enumerate", "range", "len", "len", "ValueError", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "str", "t.to", "inputs[].detach().cpu().numpy", "out_label_list[].append", "inputs[].detach().cpu", "inputs[].detach().cpu", "inputs[].detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], ["            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "assert", "args", ".", "model_dir", "==", "''", "\n", "# top_dir = 'models\\\\result-{}'.format(args.expt_comment)", "\n", "top_dir", "=", "'models'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "top_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "top_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'{}/{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "'{}/{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ")", ")", "\n", "", "elif", "args", ".", "result_dir", "!=", "'test'", ":", "\n", "            ", "assert", "False", ",", "'Existing result directory!'", "\n", "\n", "", "args", ".", "result_dir", "=", "'{}/{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ")", "\n", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-training.txt'", ".", "format", "(", "args", ".", "result_dir", ")", ")", "\n", "\n", "# dump args", "\n", "with", "Path", "(", "'{}/args-train.json'", ".", "format", "(", "args", ".", "result_dir", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s %(levelname)s: - %(message)s'", ",", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "\n", "if", "args", ".", "zero_shot", ":", "\n", "        ", "if", "args", ".", "no_meta_learning", ":", "\n", "            ", "zero_shot_NOmeta", "(", "args", ")", "\n", "", "else", ":", "\n", "            ", "zero_shot_meta", "(", "args", ")", "\n", "", "", "elif", "args", ".", "k_shot", ">", "0", ":", "\n", "        ", "k_shot", "(", "args", ")", "\n", "", "elif", "args", ".", "supervised", ":", "\n", "        ", "supervised_NOmeta", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "no_meta_learning", ":", "\n", "            ", "train_NOmeta", "(", "args", ")", "\n", "", "else", ":", "\n", "            ", "train_meta", "(", "args", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.load_and_cache_examples": [[452, 490], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_ner.read_examples_from_file", "utils_ner.convert_examples_to_features", "logger.info", "torch.save", "list().pop", "str", "bool", "bool", "bool", "list", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.read_examples_from_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.prepare_dataset_token_level_combine": [[491, 512], ["main.load_and_cache_examples", "main.get_src_probs", "torch.argmax", "isinstance", "ValueError", "main.get_src_probs", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.prepare_dataset_token_level_combine_ensemble": [[513, 531], ["main.load_and_cache_examples", "main.get_ensembled_src_probs", "torch.argmax", "main.get_ensembled_src_probs", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_ensembled_src_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_ensembled_src_probs"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_ensembled_src_probs": [[532, 565], ["os.path.basename", "seeds_tmp.remove", "numpy.random.choice().tolist", "np.random.choice().tolist.append", "len", "len", "ValueError", "numpy.random.choice", "main.get_src_probs", "main.get_src_probs", "ValueError"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs": [[566, 608], ["model_class.from_pretrained", "model_class.from_pretrained.to", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.functional.softmax", "max", "os.path.basename", "len", "logger.info", "model_class.from_pretrained.train", "logger.info", "model_class.from_pretrained.eval", "tuple", "torch.no_grad", "model_class.from_pretrained.", "logits.detach", "torch.cat", "t.to", "logits.detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.save_model": [[610, 624], ["logger.info", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "os.path.exists", "os.makedirs", "hasattr", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_utils.PretrainedConfig.save_pretrained"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.main": [[626, 893], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "str", "torch.device", "utils_ner.update_encoding", "os.path.join", "logging.Formatter", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logger.addHandler", "logger.addHandler", "parser.parse_args.model_type.lower", "logger.info", "logger.warning", "main.set_seed", "utils_ner.get_labels", "len", "os.path.exists", "os.listdir", "os.path.exists", "ValueError", "os.path.exists", "os.listdir", "os.makedirs", "os.path.exists", "os.makedirs", "time.strftime", "os.path.basename", "os.path.join", "torch.nn.CrossEntropyLoss", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "main.save_model", "logger.info", "logger.info", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "main.load_and_cache_examples", "main.train", "logger.info", "main.save_model", "logger.info", "logger.info", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "os.path.join", "os.path.join", "pickle.dump", "os.path.join", "os.path.basename", "os.path.exists", "time.localtime", "logger.info", "main.train_KD", "logger.info", "logger.info", "main.train", "logger.info", "main.evaluate_viterbi", "main.evaluate", "open", "sorted", "open", "open", "bool", "main.load_and_cache_examples", "main.get_src_probs", "main.load_and_cache_examples", "main.load_and_cache_examples", "torch.utils.data.ConcatDataset", "main.load_and_cache_examples", "time.strftime", "os.path.basename", "result.keys", "writer.write", "time.strftime", "os.path.basename", "open", "MODEL_CLASSES.keys", "main.prepare_dataset_token_level_combine_ensemble", "main.prepare_dataset_token_level_combine", "time.localtime", "time.localtime", "os.path.join", "os.path.basename", "len", "str", "line.startswith", "writer.write", "writer.write", "logger.warning", "predictions[].pop", "line.split", "[].replace", "line.split", "line.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.update_encoding", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_labels", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train_KD", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.evaluate_viterbi", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.get_src_probs", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.prepare_dataset_token_level_combine_ensemble", "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.prepare_dataset_token_level_combine"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.InputExample.__init__": [[36, 48], ["None"], "methods", ["None"], ["\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "words", "=", "words", "\n", "self", ".", "labels", "=", "labels", "\n", "\n", "\n", "", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"A single set of features of data.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.InputFeatures.__init__": [[53, 58], ["None"], "methods", ["None"], ["\n", "", "", "def", "read_examples_from_file", "(", "data_dir", ",", "mode", ")", ":", "\n", "    ", "file_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.txt\"", ".", "format", "(", "mode", ")", ")", "\n", "# file_path = os.path.join(data_dir, \"{}.part.txt\".format(mode)) # for debug", "\n", "guid_index", "=", "1", "\n", "examples", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.update_encoding": [[28, 32], ["print"], "function", ["None"], ["    ", "\"\"\"A single training/test example for token classification.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "guid", ",", "words", ",", "labels", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.read_examples_from_file": [[60, 91], ["os.path.join", "io.open", "line.strip().replace.strip().replace", "examples.append", "line.strip().replace.startswith", "line.strip().replace.split", "words.append", "utils_ner.InputExample", "line.strip().replace.strip", "examples.append", "len", "labels.append", "labels.append", "utils_ner.InputExample", "splits[].replace"], "function", ["None"], ["        ", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", "or", "line", "==", "\"\"", "or", "line", "==", "\"\\n\"", ":", "\n", "                ", "if", "words", ":", "\n", "                    ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "\"{}-{}\"", ".", "format", "(", "mode", ",", "guid_index", ")", ",", "\n", "words", "=", "words", ",", "\n", "labels", "=", "labels", ")", ")", "\n", "guid_index", "+=", "1", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                ", "splits", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "words", ".", "append", "(", "splits", "[", "0", "]", ")", "\n", "if", "len", "(", "splits", ")", ">", "1", ":", "\n", "                    ", "labels", ".", "append", "(", "splits", "[", "-", "1", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "", "else", ":", "\n", "# Examples could have no label for mode = \"test\"", "\n", "                    ", "labels", ".", "append", "(", "\"O\"", ")", "\n", "", "", "", "if", "words", ":", "\n", "            ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "\"%s-%d\"", ".", "format", "(", "mode", ",", "guid_index", ")", ",", "\n", "words", "=", "words", ",", "\n", "labels", "=", "labels", ")", ")", "\n", "", "", "return", "examples", "\n", "\n", "\n", "", "def", "convert_examples_to_features", "(", "examples", ",", "\n", "label_list", ",", "\n", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.convert_examples_to_features": [[93, 212], ["enumerate", "zip", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "logger.info", "tokenizer.tokenize", "tokens.extend", "label_ids.extend", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_ner.InputFeatures", "len", "len", "str", "str", "str", "str", "str", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["sep_token", "=", "\"[SEP]\"", ",", "\n", "sep_token_extra", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_token_label_id", "=", "-", "1", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", ",", "ex_index", ",", "len", "(", "examples", ")", ")", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "for", "word", ",", "label", "in", "zip", "(", "example", ".", "words", ",", "example", ".", "labels", ")", ":", "\n", "            ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "if", "len", "(", "word_tokens", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "# Use the real label id for the first token of the word, and padding ids for the remaining tokens", "\n", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "pad_token_label_id", "]", "*", "(", "len", "(", "word_tokens", ")", "-", "1", ")", ")", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.", "\n", "", "special_tokens_count", "=", "3", "if", "sep_token_extra", "else", "2", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_length", "-", "special_tokens_count", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "label_ids", "=", "label_ids", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "if", "sep_token_extra", ":", "\n", "# roberta uses an extra separator b/w pairs of sentences", "\n", "            ", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "+=", "[", "cls_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "segment_ids", "+=", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "label_ids", "=", "[", "pad_token_label_id", "]", "+", "label_ids", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "label_ids", "=", "(", "[", "pad_token_label_id", "]", "*", "padding_length", ")", "+", "label_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "+=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "+=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "+=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "label_ids", "+=", "(", "[", "pad_token_label_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "label_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", ",", "example", ".", "guid", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "label_ids", "]", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_ids", "=", "label_ids", ")", ")", "\n", "", "return", "features", "\n", "\n", "\n", "", "def", "get_labels", "(", "path", ")", ":", "\n", "    ", "if", "path", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "if", "\"O\"", "not", "in", "labels", ":", "\n", "            ", "labels", "=", "[", "\"O\"", "]", "+", "labels", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.get_labels": [[214, 225], ["io.open", "f.read().splitlines", "f.read().splitlines.remove", "f.read"], "function", ["None"], ["            ", "labels", ".", "remove", "(", "''", ")", "\n", "", "return", "labels", "\n", "", "else", ":", "\n", "        ", "return", "[", "\"O\"", ",", "\"B-MISC\"", ",", "\"I-MISC\"", ",", "\"B-PER\"", ",", "\"I-PER\"", ",", "\"B-ORG\"", ",", "\"I-ORG\"", ",", "\"B-LOC\"", ",", "\"I-LOC\"", "]", "\n", "\n", "\n", "", "", "def", "endless_get_next_pt_batch", "(", "pt_loader", ",", "pt_iter", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "pt_batch", "=", "next", "(", "pt_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "        ", "pt_iter", "=", "iter", "(", "pt_loader", ")", "\n", "pt_batch", "=", "next", "(", "pt_iter", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.get_pij_en_valid": [[227, 253], ["len", "numpy.zeros", "os.path.join", "logger.info", "len", "ValueError", "io.open", "enumerate", "os.listdir", "line.strip.strip", "line.strip.split", "file.startswith", "file.endswith", "len", "len", "line.strip.split", "line.strip.split"], "function", ["None"], ["# so we will skip leftover batch of size == 1", "\n", "# if opt.skip_leftover_batch and len(targets) < opt.batch_size:", "\n", "#     return endless_get_next_batch(loaders, iters, lang)", "\n", "", "return", "pt_batch", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.utils_ner.endless_get_next_pt_batch": [[255, 266], ["next", "iter", "next"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.read_data": [[32, 35], ["open", "ii.replace", "f.readlines"], "function", ["None"], ["def", "read_data", "(", "path", ":", "str", ")", "->", "list", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "return", "[", "ii", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "for", "ii", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.mkdir": [[37, 41], ["os.path.exists", "os.mkdir"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.mkdir"], ["", "", "def", "mkdir", "(", "origin_dir", ":", "str", ")", ":", "\n", "    ", "\"\"\" mkdir file dir\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "origin_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "origin_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.load_result_once": [[43, 53], ["statistical.read_data", "re.findall", "len", "float"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.read_data"], ["", "", "def", "load_result_once", "(", "log_path", ":", "str", ")", ":", "\n", "    ", "result", "=", "read_data", "(", "log_path", ")", "\n", "result_str", "=", "\" \"", ".", "join", "(", "result", ")", "\n", "fpr", "=", "re", ".", "findall", "(", "\n", "\"f1 = (\\d{1,3}\\.\\d{0,10}).*precision = (\\d{1,3}\\.\\d{0,10}).*recall = (\\d{1,3}\\.\\d{0,10})\"", ",", "\n", "result_str", ",", "\n", ")", "\n", "assert", "len", "(", "fpr", ")", "==", "1", ",", "fpr", "\n", "f", ",", "p", ",", "r", "=", "fpr", "[", "0", "]", "\n", "return", "[", "float", "(", "ii", ")", "for", "ii", "in", "[", "p", ",", "r", ",", "f", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.load_result": [[55, 61], ["os.path.join", "statistical.load_result_once", "statistical.load_result_once", "os.listdir", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.load_result_once", "home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.load_result_once"], ["", "def", "load_result", "(", "model_dir", ":", "str", ")", ":", "\n", "    ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"logs\"", ")", "\n", "test_p", ",", "dev_p", "=", "os", ".", "listdir", "(", "log_dir", ")", "[", "-", "2", ":", "]", "\n", "t_fpr", "=", "load_result_once", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "test_p", ")", ")", "\n", "d_fpr", "=", "load_result_once", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "dev_p", ")", ")", "\n", "return", "t_fpr", ",", "d_fpr", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.statistical_pipeline": [[63, 101], ["args.seeds.split", "print", "statistical.mkdir", "zip", "os.path.join", "open", "f.write", "ii.replace", "statistical.load_result", "[].append", "[].append", "numpy.array", "numpy.mean", "range", "len", "[].split", "args.unitrans_src_dir.replace", "args.unitrans_src_dir.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.mkdir", "home.repos.pwc.inspect_result.microsoft_vert-papers.scripts.statistical.load_result"], ["", "def", "statistical_pipeline", "(", ")", ":", "\n", "    ", "result", "=", "{", "ii", ":", "{", "jj", ":", "[", "]", "for", "jj", "in", "PRED_MODS", "}", "for", "ii", "in", "ITEMS", "}", "\n", "for", "seed", "in", "args", ".", "seeds", ".", "split", "(", "\",\"", ")", ":", "\n", "        ", "dirs", "=", "[", "\n", "args", ".", "src_dir", ",", "\n", "args", ".", "trans_dir", ",", "\n", "args", ".", "finetune_dir", ",", "\n", "args", ".", "unitrans_src_dir", ",", "\n", "args", ".", "unitrans_finetune_dir", ",", "\n", "]", "\n", "dirs", "=", "[", "ii", ".", "replace", "(", "\"122\"", ",", "seed", ")", "for", "ii", "in", "dirs", "]", "\n", "for", "item", ",", "o_dir", "in", "zip", "(", "ITEMS", ",", "dirs", ")", ":", "\n", "            ", "t_fpr", ",", "d_fpr", "=", "load_result", "(", "o_dir", ")", "\n", "result", "[", "item", "]", "[", "\"dev\"", "]", ".", "append", "(", "d_fpr", ")", "\n", "result", "[", "item", "]", "[", "\"test\"", "]", ".", "append", "(", "t_fpr", ")", "\n", "\n", "", "", "for", "item", "in", "ITEMS", ":", "\n", "        ", "for", "mod", "in", "PRED_MODS", ":", "\n", "            ", "res", "=", "np", ".", "array", "(", "result", "[", "item", "]", "[", "mod", "]", ")", "\n", "mean", "=", "np", ".", "mean", "(", "res", ",", "axis", "=", "0", ")", "\n", "mean", "[", "-", "1", "]", "=", "2", "/", "(", "1", "/", "mean", "[", "0", "]", "+", "1", "/", "mean", "[", "1", "]", ")", "\n", "result", "[", "item", "]", "[", "mod", "]", "=", "[", "*", "res", ",", "mean", "]", "\n", "", "", "print", "(", "result", ")", "\n", "log_str", "=", "[", "\n", "[", "\n", "\"{},{},{},,\"", ".", "format", "(", "*", "result", "[", "item", "]", "[", "mod", "]", "[", "ii", "]", ")", "\n", "for", "item", "in", "ITEMS", "\n", "for", "mod", "in", "PRED_MODS", "\n", "]", "\n", "for", "ii", "in", "range", "(", "len", "(", "result", "[", "\"src\"", "]", "[", "\"dev\"", "]", ")", ")", "\n", "]", "\n", "log_str", "=", "[", "\n", "\",,mBERT Dev,,,,mBERT Test,,,,Translate Dev,,,,Translate Test,,,,Fine Trans Dev,,,,Fine Trans Test,,,,UniTrans-mBERT Dev,,,,UniTrans-mBERT Test,,,,UniTrans-Trans Dev,,,,UniTrans-Trans Test\"", "\n", "]", "+", "[", "\"\"", ".", "join", "(", "ii", ")", "for", "ii", "in", "log_str", "]", "\n", "mkdir", "(", "os", ".", "path", ".", "join", "(", "args", ".", "unitrans_src_dir", ".", "split", "(", "\"/\"", ")", "[", "0", "]", ".", "split", "(", "\"\\\\\"", ")", "[", "0", "]", ",", "\"result\"", ")", ")", "\n", "\n", "with", "open", "(", "args", ".", "unitrans_src_dir", ".", "replace", "(", "\"-122\"", ",", "\"\"", ")", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "log_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.__init__": [[18, 25], ["transformers.BertForTokenClassification.__init__", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "\n", "loss_crossEntropy", "=", "torch", ".", "mean", "(", "loss", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.set_config": [[26, 67], ["logger.info", "torch.LayerNorm", "torch.LayerNorm", "copy.deepcopy", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear"], "methods", ["None"], ["\n", "if", "lambda_max_loss", "==", "0.0", "and", "lambda_mask_loss", "==", "0.0", ":", "\n", "                    ", "return", "loss_crossEntropy", "\n", "\n", "", "active_loss", "=", "active_loss", ".", "view", "(", "batch_size", ",", "max_seq_len", ")", "\n", "\n", "active_max", "=", "[", "]", "\n", "active_mask", "=", "[", "]", "\n", "start_id", "=", "0", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "sent_len", "=", "torch", ".", "sum", "(", "active_loss", "[", "i", "]", ")", "\n", "# mask-loss", "\n", "if", "lambda_mask_loss", "!=", "0.0", ":", "\n", "                        ", "active_mask", ".", "append", "(", "(", "input_ids", "[", "i", "]", "==", "103", ")", "[", ":", "sent_len", "]", ")", "# id of [MASK] is 103, according to the bertTokenizer", "\n", "# max-loss", "\n", "", "if", "lambda_max_loss", "!=", "0.0", ":", "\n", "                        ", "end_id", "=", "start_id", "+", "sent_len", "\n", "active_max", ".", "append", "(", "torch", ".", "max", "(", "loss", "[", "start_id", ":", "end_id", "]", ")", ")", "\n", "start_id", "=", "end_id", "\n", "\n", "# max-loss", "\n", "", "", "if", "lambda_max_loss", "!=", "0.0", ":", "\n", "                    ", "loss_max", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "active_max", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss_max", "=", "0.0", "\n", "\n", "# mask-loss", "\n", "", "if", "lambda_mask_loss", "!=", "0.0", ":", "\n", "                    ", "active_mask", "=", "torch", ".", "cat", "(", "active_mask", ")", "\n", "if", "sum", "(", "active_mask", ")", "!=", "0", ":", "\n", "                        ", "loss_mask", "=", "torch", ".", "sum", "(", "loss", "[", "active_mask", "]", ")", "/", "sum", "(", "active_mask", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss_mask", "=", "0.0", "\n", "\n", "", "return", "loss_crossEntropy", "+", "lambda_max_loss", "*", "loss_max", "+", "lambda_mask_loss", "*", "loss_mask", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "assert", "False", "\n", "", "", "else", ":", "\n", "            ", "return", "logits", "", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh": [[68, 184], ["attention_mask[].type", "modeling.BertForTokenClassification_.bert", "modeling.BertForTokenClassification_.dropout", "[].item", "modeling.BertForTokenClassification_.classifier", "modeling.BertForTokenClassification_.bert2", "modeling.BertForTokenClassification_.dropout", "e_mask[].type", "e_type_mask[].type", "modeling.BertForTokenClassification_.get_enity_hidden", "modeling.BertForTokenClassification_.ln", "modeling.BertForTokenClassification_.unsqueeze().expand", "modeling.BertForTokenClassification_.get_types_embedding", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "e_type_mask[].type.sum", "modeling.BertForTokenClassification_.type_classify", "entity_types.update_type_embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling.BertForTokenClassification_.dis_cls", "e_type_mask[].type.clone", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "modeling.BertForTokenClassification_.calc_loss", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "ValueError", "[].item", "modeling.BertForTokenClassification_.unsqueeze", "attention_mask[].type.view", "modeling.BertForTokenClassification_.reshape", "labels.reshape", "active_loss.view.view.view", "range", "[].nonzero", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "active_max.append", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "e_type_mask[].type.clone.sum", "torch.max", "torch.max", "torch.max", "torch.max", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "[].nonzero", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.get_enity_hidden", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.get_types_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.update_type_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.calc_loss"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.get_enity_hidden": [[185, 195], ["hidden.unsqueeze().expand", "e_mask.unsqueeze", "e_out.sum", "hidden.unsqueeze", "e_mask.sum().unsqueeze", "e_mask.sum"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.get_types_embedding": [[197, 199], ["entity_types.get_types_embedding"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.get_types_embedding"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.calc_loss": [[200, 210], ["target.reshape.reshape.reshape", "preds.reshape.reshape.reshape", "loss_fn", "target.reshape.reshape.long", "mask.reshape.reshape.reshape", "loss_fn.sum", "loss_fn.sum", "target.reshape.reshape.sum", "mask.reshape.reshape.sum"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.ViterbiDecoder.__init__": [[213, 223], ["len", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.ViterbiDecoder.forward": [[224, 271], ["logprobs.size", "range", "ValueError", "range", "torch.max", "torch.max", "torch.max", "torch.max", "best_label_id.item.item.item", "reversed", "best_path.reverse", "label_seqs.append", "len", "torch.max", "torch.max", "torch.max", "torch.max", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy().tolist", "back_pointers.append", "best_path.append", "len", "len", "ValueError", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_label_list": [[20, 29], ["None"], "function", ["None"], ["compute_repr", "=", "False", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_en_valid", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'valid'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_en_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_data_path": [[31, 60], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "\n", "        ", "batch_data", "=", "corpus_en_train", ".", "get_batch_NOmeta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "\n", "loss", "=", "learner", ".", "forward_NOmeta", "(", "batch_data", ",", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [en] - [valid] **********\"", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_en_valid", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Valid F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "", "def", "train_meta", "(", "args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"********** Scheme: Meta Learning **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.replace_type_embedding": [[63, 71], ["logger.info", "joblib.load", "range", "os.path.join"], "function", ["None"], ["\n", "corpus_en_valid", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'valid'", ",", "\n", "load_data", "=", "True", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_en_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.train_meta": [[73, 222], ["logger.info", "main.get_label_list", "main.get_data_path", "preprocessor.Corpus", "learner.Learner", "time.time", "range", "main.get_data_path", "preprocessor.Corpus", "main.replace_type_embedding", "preprocessor.Corpus.get_batch_meta", "main.get_data_path", "preprocessor.Corpus", "learner.Learner.forward_supervise", "learner.Learner.forward_meta", "logger.info", "logger.info", "main.test", "logger.info", "logger.info", "learner.Learner.save_model", "learner.Learner.save_model", "logger.info", "learner.Learner.save_model", "logger.info", "logger.info", "main.test", "logger.info", "logger.info", "time.time"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_label_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_data_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_data_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.replace_type_embedding", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_meta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_data_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.forward_supervise", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.forward_meta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.test", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.test"], ["best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "        ", "progress", "=", "1.0", "*", "step", "/", "args", ".", "max_meta_steps", "\n", "\n", "batch_query", ",", "batch_support", "=", "corpus_en_train", ".", "get_batch_meta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "#(batch_size=32)", "\n", "loss", "=", "learner", ".", "forward_meta", "(", "batch_query", ",", "batch_support", ",", "progress", "=", "progress", ",", "inner_steps", "=", "args", ".", "inner_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [en] - [valid] **********\"", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_en_valid", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Valid F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Best Valid F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "\n", "#########################################################", "\n", "# Transfer the source-trained model to target languages", "\n", "#########################################################", "\n", "\n", "", "def", "zero_shot_NOmeta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-NOmeta-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot NO meta learning **********\"", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "zero_shot_meta", "(", "args", ")", ":", "\n", "    ", "res_filename", "=", "'{}/res-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: 0-shot with meta learning (separate support set) **********\"", ")", "\n", "\n", "## prepare dataset", "\n", "reprer", "=", "Reprer", "(", "args", ".", "bert_model", ")", "\n", "corpus_en_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "'en'", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "\n", "args", ".", "lr_inner", ",", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "args", ".", "support_size", ",", "base_features", "=", "corpus_en_train", ".", "original_features", ",", "\n", "mask_rate", "=", "-", "1.0", ",", "compute_repr", "=", "True", ",", "shuffle", "=", "False", ",", "reprer", "=", "reprer", ")", "\n", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] - support on [en] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_meta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lr", "=", "args", ".", "lr_finetune", ",", "steps", "=", "args", ".", "max_ft_steps", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ",", "\n", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "for", "lang", "in", "languages", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n", "", "", "def", "k_shot", "(", "args", ")", ":", "\n", "# to define: k_shot, max_ft_steps, lr_finetune, lambda_max_loss", "\n", "    ", "res_filename", "=", "'{}/res-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "\n", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "res_filename", ")", ":", "\n", "        ", "assert", "False", ",", "'Already evaluated.'", "\n", "\n", "", "logger", ".", "info", "(", "\"********** Scheme: {}-shot fine-tuning **********\"", ".", "format", "(", "args", ".", "k_shot", ")", ")", "\n", "\n", "learner_pretrained", "=", "Learner", "(", "args", ".", "bert_model", ",", "LABEL_LIST", ",", "args", ".", "freeze_layer", ",", "logger", ",", "lr_meta", "=", "0", ",", "lr_inner", "=", "0", ",", "\n", "warmup_prop_meta", "=", "-", "1", ",", "warmup_prop_inner", "=", "-", "1", ",", "max_meta_steps", "=", "-", "1", ",", "\n", "model_dir", "=", "args", ".", "model_dir", ",", "gpu_no", "=", "args", ".", "gpu_device", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "languages", "=", "args", ".", "test_langs", "\n", "F1s", "=", "{", "lang", ":", "[", "]", "for", "lang", "in", "languages", "}", "\n", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ",", "k_shot_prop", "=", "args", ".", "k_shot", ")", "# add k_shot_prop", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n", "# build the model", "\n", "learner", "=", "deepcopy", "(", "learner_pretrained", ")", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "for", "ft_step", "in", "range", "(", "args", ".", "max_ft_steps", ")", ":", "\n", "            ", "data_batches", "=", "corpus_train", ".", "get_batches", "(", "args", ".", "inner_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", "\n", "\n", "for", "batch_data", "in", "data_batches", ":", "\n", "                ", "loss", "=", "learner", ".", "inner_update", "(", "batch_data", ",", "lr_curr", "=", "args", ".", "lr_finetune", ",", "inner_steps", "=", "1", ",", "\n", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "", "if", "ft_step", "in", "[", "0", ",", "4", ",", "9", ",", "14", "]", ":", "\n", "                ", "logger", ".", "info", "(", "'Fine-tune Step: {}/{}, loss = {:8f}, time = {:2f}s.'", ".", "format", "(", "ft_step", ",", "args", ".", "max_ft_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test], Finetune step = {} **********\"", ".", "format", "(", "lang", ",", "ft_step", ")", ")", "\n", "F1_test", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ",", "lang", "=", "lang", ",", "mode", "=", "'test'", ")", "\n", "F1s", "[", "lang", "]", ".", "append", "(", "F1_test", ")", "\n", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_test", ")", ")", "\n", "\n", "", "", "", "for", "i", ",", "lang", "in", "enumerate", "(", "languages", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'{} Test F1: {}'", ".", "format", "(", "lang", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "F1s", "[", "lang", "]", "]", ")", ")", ")", "\n", "\n", "", "with", "Path", "(", "res_filename", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "F1s", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.test": [[224, 263], ["learner.evaluate_meta_", "modeling.ViterbiDecoder", "main.get_label_list", "main.get_data_path", "preprocessor.Corpus"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.evaluate_meta_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_label_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_data_path"], ["    ", "logger", ".", "info", "(", "\"********** Scheme: Supervised & NO Meta Learning **********\"", ")", "\n", "lang", "=", "args", ".", "test_langs", "[", "0", "]", "\n", "logger", ".", "info", "(", "\"language: {}\"", ".", "format", "(", "lang", ")", ")", "\n", "\n", "# prepare dataset", "\n", "corpus_train", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'train'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "args", ".", "mask_rate", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ")", "\n", "\n", "corpus_test", "=", "Corpus", "(", "'bert-base-multilingual-cased'", ",", "args", ".", "max_seq_len", ",", "logger", ",", "language", "=", "lang", ",", "mode", "=", "'test'", ",", "\n", "load_data", "=", "False", ",", "support_size", "=", "-", "1", ",", "base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "\n", "compute_repr", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "# build the model", "\n", "learner", "=", "Learner", "(", "args", ".", "bert_model", ",", "corpus_train", ".", "label_list", ",", "args", ".", "freeze_layer", ",", "logger", ",", "args", ".", "lr_meta", ",", "args", ".", "lr_inner", ",", "\n", "args", ".", "warmup_prop_meta", ",", "args", ".", "warmup_prop_inner", ",", "args", ".", "max_meta_steps", ",", "py_alias", "=", "args", ".", "py_alias", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "best_en_valid_F1", "=", "-", "1.0", "\n", "best_step", "=", "-", "1.0", "\n", "\n", "for", "step", "in", "range", "(", "args", ".", "max_meta_steps", ")", ":", "\n", "\n", "        ", "batch_data", "=", "corpus_train", ".", "get_batch_NOmeta", "(", "batch_size", "=", "args", ".", "inner_size", ")", "\n", "loss", "=", "learner", ".", "forward_NOmeta", "(", "batch_data", ",", "lambda_max_loss", "=", "args", ".", "lambda_max_loss", ",", "lambda_mask_loss", "=", "args", ".", "lambda_mask_loss", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'Step: {}/{}, loss = {:.6f}, time = {:.2f}s.'", ".", "format", "(", "step", ",", "args", ".", "max_meta_steps", ",", "loss", ",", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "eval_every_meta_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"********** Scheme: evaluate [{}] - [test] **********\"", ".", "format", "(", "lang", ")", ")", "\n", "F1_valid", "=", "learner", ".", "evaluate_NOmeta", "(", "corpus_test", ",", "args", ".", "result_dir", ",", "logger", ")", "\n", "if", "F1_valid", ">", "best_en_valid_F1", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Best Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "logger", ".", "info", "(", "\"  Saving model...\"", ".", "format", "(", "F1_valid", ")", ")", "\n", "learner", ".", "save_model", "(", "args", ".", "result_dir", ",", "'en'", ",", "args", ".", "max_seq_len", ")", "\n", "best_en_valid_F1", "=", "F1_valid", "\n", "best_step", "=", "step", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"===> Test F1: {}\"", ".", "format", "(", "F1_valid", ")", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.evaluate": [[265, 321], ["logger.info", "main.get_label_list", "main.get_data_path", "preprocessor.Corpus", "main.get_data_path", "preprocessor.Corpus", "learner.Learner", "logger.info", "main.test", "logger.info", "main.test"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_label_list", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_data_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_data_path", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.test", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.test"], ["", "", "", "logger", ".", "info", "(", "'Best Test F1: {}, Step: {}'", ".", "format", "(", "best_en_valid_F1", ",", "best_step", ")", ")", "\n", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# dataset settings", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "help", "=", "'where to save the result.'", ",", "default", "=", "'test'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_langs'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'languages to test'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "type", "=", "str", ",", "help", "=", "'dir name of a trained model'", ",", "default", "=", "''", ")", "\n", "\n", "# activate zero_shot only", "\n", "parser", ".", "add_argument", "(", "'--zero_shot'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run 0-shot procedure only.'", ")", "\n", "# activate fine-tune only", "\n", "parser", ".", "add_argument", "(", "'--k_shot'", ",", "type", "=", "float", ",", "default", "=", "-", "1", ",", "help", "=", "'size of k-shot data: k, if >0,  will run fine-ture procedure'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_finetune'", ",", "type", "=", "float", ",", "help", "=", "'finetune learning rate, used in [test_meta]. and [k_shot setting]'", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--max_ft_steps'", ",", "type", "=", "int", ",", "help", "=", "'maximal steps token for fine-tune.'", ",", "default", "=", "1", ")", "# ===>", "\n", "\n", "# activate mBERT only", "\n", "parser", ".", "add_argument", "(", "'--no_meta_learning'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run mBERT only.'", ")", "\n", "parser", ".", "add_argument", "(", "'--supervised'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, will run mBERT only.'", ")", "\n", "\n", "# meta-learning", "\n", "parser", ".", "add_argument", "(", "'--inner_steps'", ",", "type", "=", "int", ",", "help", "=", "'every ** inner update for one meta-update'", ",", "default", "=", "2", ")", "# ===>", "\n", "parser", ".", "add_argument", "(", "'--inner_size'", ",", "type", "=", "int", ",", "help", "=", "'[number of tasks] for one meta-update'", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--support_size'", ",", "type", "=", "int", ",", "help", "=", "'support size (batch_size) for inner update'", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_inner'", ",", "type", "=", "float", ",", "help", "=", "'inner loop learning rate'", ",", "default", "=", "3e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_meta'", ",", "type", "=", "float", ",", "help", "=", "'meta learning rate'", ",", "default", "=", "3e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--max_meta_steps'", ",", "type", "=", "int", ",", "help", "=", "'maximal steps token for meta training.'", ",", "default", "=", "3001", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every_meta_steps'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_prop_inner'", ",", "type", "=", "int", ",", "help", "=", "'warm up proportion for inner update'", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_prop_meta'", ",", "type", "=", "int", ",", "help", "=", "'warm up proportion for meta update'", ",", "default", "=", "0.1", ")", "\n", "# parser.add_argument('--cross_meta_rate', type=float, help='when > 0, randomly flipping cross objective or normal objective', default=1.0)", "\n", "\n", "\n", "# training paramters", "\n", "parser", ".", "add_argument", "(", "'--mask_rate'", ",", "type", "=", "float", ",", "help", "=", "'the probability to [mask] a token with a B/I-XXX label.'", ",", "default", "=", "-", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_max_loss'", ",", "type", "=", "float", ",", "help", "=", "'the weight of the max-loss.'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_mask_loss'", ",", "type", "=", "float", ",", "help", "=", "'the weight of the mask-loss.'", ",", "default", "=", "0.0", ")", "\n", "\n", "\n", "# permanent params", "\n", "parser", ".", "add_argument", "(", "'--freeze_layer'", ",", "type", "=", "int", ",", "help", "=", "'the layer of mBERT to be frozen'", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seq_len'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_model'", ",", "type", "=", "str", ",", "default", "=", "'bert-base-multilingual-cased'", ",", "#required=True,", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"", "\n", "\"bert-base-multilingual-cased, bert-base-chinese.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "help", "=", "'Where do you want to store the pre-trained models downloaded from s3'", ",", "default", "=", "''", ")", "\n", "# expt setting", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "help", "=", "'random seed to reproduce the result.'", ",", "default", "=", "667", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_device'", ",", "type", "=", "int", ",", "help", "=", "'GPU device num'", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--py_alias'", ",", "type", "=", "str", ",", "help", "=", "'python alias'", ",", "default", "=", "'python'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.convert_bpe": [[323, 374], ["logger.info", "os.makedirs", "main.get_label_list", "main.convert_bpe.convert_base"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.main.get_label_list"], ["\n", "# setup random seed", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "\n", "# set up GPU device", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu_device", ")", "\n", "\n", "# setup logger settings", "\n", "if", "args", ".", "zero_shot", ":", "\n", "        ", "assert", "args", ".", "model_dir", "!=", "''", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_dir", ")", "and", "len", "(", "args", ".", "test_langs", ")", ">", "0", "\n", "if", "args", ".", "no_meta_learning", ":", "\n", "            ", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-0shot-NOmeta-{}.txt'", ".", "format", "(", "args", ".", "model_dir", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.txt'", ".", "format", "(", "\n", "args", ".", "model_dir", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "\n", "# dump args", "\n", "", "with", "Path", "(", "'{}/args-0shot-ftLr_{}-ftSteps_{}-spSize_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "\n", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "support_size", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "args", ".", "result_dir", "=", "args", ".", "model_dir", "\n", "\n", "", "elif", "args", ".", "k_shot", ">", "0", ":", "\n", "        ", "assert", "args", ".", "model_dir", "!=", "''", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_dir", ")", "and", "len", "(", "args", ".", "test_langs", ")", ">", "0", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.txt'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", "\n", "\n", "\n", "# dump args", "\n", "with", "Path", "(", "'{}/args-{}shot-ftLr_{}-ftSteps_{}-maxLoss_{}-{}.json'", ".", "format", "(", "args", ".", "model_dir", ",", "args", ".", "k_shot", ",", "args", ".", "lr_finetune", ",", "args", ".", "max_ft_steps", ",", "args", ".", "lambda_max_loss", ",", "'_'", ".", "join", "(", "args", ".", "test_langs", ")", ")", ")", ".", "open", "(", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "fw", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "args", ".", "result_dir", "=", "args", ".", "model_dir", "\n", "", "elif", "args", ".", "supervised", ":", "\n", "        ", "assert", "args", ".", "model_dir", "==", "''", "\n", "# top_dir = 'models\\\\result-{}'.format(args.expt_comment)", "\n", "top_dir", "=", "'models'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "top_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "top_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", ")", "\n", "", "elif", "args", ".", "result_dir", "!=", "'test'", ":", "\n", "            ", "assert", "False", ",", "'Existing result directory!'", "\n", "\n", "", "args", ".", "result_dir", "=", "'{}/{}-{}'", ".", "format", "(", "top_dir", ",", "args", ".", "result_dir", ",", "args", ".", "test_langs", "[", "0", "]", ")", "\n", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}/log-training.txt'", ".", "format", "(", "args", ".", "result_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.__init__": [[20, 27], ["preprocessor.EntityTypes.load_entity_types"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.load_entity_types"], ["\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.load_entity_types": [[28, 35], ["utils.load_file", "sorted", "logger.info", "len", "enumerate", "preprocessor.EntityTypes.types.values"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.utils.load_file"], ["self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n", "", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"A single set of features of data.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_id", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.build_types_embedding": [[36, 75], ["sorted", "torch.Embedding().to", "torch.Embedding().to", "logger.info", "transformers.BertTokenizer.from_pretrained", "max", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "transformers.BertModel.from_pretrained().to", "transformers.BertModel.from_pretrained().to.", "types_mode.lower", "torch.Parameter", "torch.Parameter", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.Embedding", "torch.Embedding", "preprocessor.EntityTypes.types.values", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "transformers.BertModel.from_pretrained", "transformers.BertTokenizer.from_pretrained.convert_tokens_to_ids", "len", "numpy.array", "numpy.array", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "transformers.BertTokenizer.from_pretrained.tokenize", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "self", ".", "representation", "=", "None", "\n", "\n", "", "", "class", "NerProcessor", "(", "object", ")", ":", "\n", "    ", "\"\"\"Processor for the CoNLL-2003 data set.\"\"\"", "\n", "\n", "def", "get_examples", "(", "self", ",", "language", ",", "mode", ")", ":", "\n", "        ", "\"\"\"\n        :param mode: one element in ['train', 'valid', 'test']\n        \"\"\"", "\n", "sentences", "=", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "\"data\"", ",", "language", ",", "\"{}.txt\"", ".", "format", "(", "mode", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "sentences", ",", "mode", ")", "# [list of labels, list of words(no split)]", "\n", "\n", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "for", "i", ",", "(", "sentence", ",", "label", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "sentence", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n", "", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "## read file", "\n", "# return format :", "\n", "# [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]", "\n", "f", "=", "open", "(", "input_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "data", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "sentence_id", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "if", "len", "(", "line", ")", "==", "0", "or", "line", ".", "startswith", "(", "'-DOCSTART'", ")", "or", "line", "[", "0", "]", "==", "\"\\n\"", ":", "\n", "                ", "if", "len", "(", "sentence", ")", ">", "0", ":", "\n", "                    ", "data", ".", "append", "(", "(", "sentence", ",", "label", ")", ")", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "sentence_id", "+=", "1", "\n", "", "continue", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.generate_negative_types": [[76, 102], ["len", "numpy.zeros", "set", "min", "enumerate", "len", "list", "numpy.concatenate", "len", "len", "set", "len", "numpy.random.choice", "numpy.random.choice", "set", "list", "range", "len", "set"], "methods", ["None"], ["", "splits", "=", "line", ".", "split", "(", "' '", ")", "\n", "sentence", ".", "append", "(", "splits", "[", "0", "]", ")", "\n", "label", ".", "append", "(", "splits", "[", "-", "1", "]", "[", ":", "-", "1", "]", ")", "\n", "\n", "", "if", "len", "(", "sentence", ")", ">", "0", ":", "\n", "            ", "data", ".", "append", "(", "(", "sentence", ",", "label", ")", ")", "\n", "sentence", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "", "return", "data", "#, type_idxs", "\n", "\n", "", "", "def", "compute_represenation", "(", "sents", ",", "bert_model", ",", "logger", ",", "device", "=", "\"cuda\"", ",", "reprer", "=", "None", ")", ":", "\n", "    ", "if", "reprer", "is", "None", ":", "\n", "        ", "model", "=", "BertModel", ".", "from_pretrained", "(", "bert_model", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "reprer", ".", "model", "\n", "", "model", ".", "eval", "(", ")", "\n", "batch_size", "=", "100", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sents", ")", ",", "batch_size", ")", ":", "\n", "        ", "items", "=", "sents", "[", "i", ":", "min", "(", "len", "(", "sents", ")", ",", "i", "+", "batch_size", ")", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "torch", ".", "tensor", "(", "[", "item", ".", "input_ids", "for", "item", "in", "items", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "[", "item", ".", "segment_ids", "for", "item", "in", "items", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "item", ".", "input_mask", "for", "item", "in", "items", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "all_encoder_layers", ",", "_", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "# batch_size x seq_len x target_size", "\n", "", "layer_output", "=", "all_encoder_layers", "[", "-", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# batch_size x seq_len x target_size", "\n", "for", "j", ",", "item", "in", "enumerate", "(", "items", ")", ":", "\n", "            ", "item", ".", "representation", "=", "layer_output", "[", "j", "]", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.get_types_embedding": [[103, 105], ["preprocessor.EntityTypes.types_embedding"], "methods", ["None"], ["# item.representation = layer_output", "\n", "", "if", "i", "%", "(", "10", "*", "batch_size", ")", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'  Compute sentence representation. To {}...'", ".", "format", "(", "i", ")", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.update_type_embedding": [[106, 112], ["set", "labels.detach().cpu().numpy", "hiddens[].mean", "labels.detach().cpu", "labels.detach"], "methods", ["None"], ["", "", "logger", ".", "info", "(", "'  Finish.'", ")", "\n", "\n", "", "class", "Reprer", "(", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "bert_model", ",", "device", "=", "\"cuda\"", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "model", "=", "BertModel", ".", "from_pretrained", "(", "bert_model", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.InputExample.__init__": [[115, 123], ["None"], "methods", ["None"], ["base_features", "=", "None", ",", "mask_rate", "=", "-", "1.0", ",", "compute_repr", "=", "False", ",", "shuffle", "=", "True", ",", "k_shot_prop", "=", "-", "1.0", ",", "reprer", "=", "None", ")", ":", "\n", "        ", "self", ".", "processor", "=", "NerProcessor", "(", ")", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "label_list", "=", "LABEL_LIST", "\n", "self", ".", "num_labels", "=", "len", "(", "self", ".", "label_list", ")", "+", "1", "# if not +1, then the loss returned may be `nan`", "\n", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "language", "=", "language", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.InputFeatures.__init__": [[126, 147], ["None"], "methods", ["None"], ["self", ".", "load_data", "=", "load_data", "\n", "self", ".", "mask_rate", "=", "mask_rate", "\n", "\n", "# get original feature list (do not consider [MASK] scheme)", "\n", "self", ".", "original_features", "=", "self", ".", "build_original_features", "(", "language", ",", "mode", ",", "load_data", "=", "load_data", ")", "\n", "\n", "if", "k_shot_prop", ">", "0", ":", "\n", "            ", "n_tmp", "=", "len", "(", "self", ".", "original_features", ")", "\n", "kept_idxs", "=", "np", ".", "random", ".", "permutation", "(", "n_tmp", ")", ".", "tolist", "(", ")", "[", ":", "int", "(", "n_tmp", "*", "k_shot_prop", ")", "]", "if", "k_shot_prop", "<", "1.0", "else", "np", ".", "random", ".", "permutation", "(", "n_tmp", ")", ".", "tolist", "(", ")", "[", ":", "int", "(", "k_shot_prop", ")", "]", "\n", "logger", ".", "info", "(", "'  The kept {}-shot-prop idxs are: {}'", ".", "format", "(", "k_shot_prop", ",", "', '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "kept_idxs", "]", ")", ")", ")", "\n", "self", ".", "original_features", "=", "[", "self", ".", "original_features", "[", "i", "]", "for", "i", "in", "kept_idxs", "]", "\n", "\n", "# compute representations for original features (in-place operation)", "\n", "", "if", "compute_repr", ":", "\n", "            ", "compute_represenation", "(", "self", ".", "original_features", ",", "bert_model", ",", "logger", ",", "reprer", "=", "reprer", ")", "\n", "\n", "# build query set", "\n", "", "if", "mask_rate", "<", "0", ":", "# NO [MASK] scheme", "\n", "            ", "self", ".", "query_features", "=", "self", ".", "original_features", "\n", "", "else", ":", "\n", "            ", "self", ".", "query_features", "=", "self", ".", "build_query_features_with_mask", "(", "mask_rate", ")", "# (masked)", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.__init__": [[150, 234], ["transformers.BertTokenizer.from_pretrained", "len", "logger.info", "preprocessor.Corpus.read_tasks_from_file", "len", "numpy.random.permutation", "numpy.array", "enumerate", "enumerate", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "ValueError", "ValueError", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.read_tasks_from_file"], ["if", "support_size", ">", "0", ":", "# build support set (NOT masked)", "\n", "            ", "if", "base_features", "is", "None", ":", "\n", "                ", "self", ".", "support_features", "=", "self", ".", "build_support_features_", "(", "self", ".", "original_features", ",", "support_size", "=", "support_size", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "support_features", "=", "self", ".", "build_support_features_", "(", "base_features", ",", "support_size", "=", "support_size", ")", "\n", "\n", "", "", "self", ".", "n_total", "=", "len", "(", "self", ".", "query_features", ")", "\n", "self", ".", "batch_start_idx", "=", "0", "\n", "self", ".", "batch_idxs", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n_total", ")", "if", "shuffle", "else", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "self", ".", "n_total", ")", "]", ")", "# for batch sampling in training", "\n", "\n", "\n", "", "def", "reset_batch_info", "(", "self", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "self", ".", "batch_start_idx", "=", "0", "\n", "self", ".", "batch_idxs", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n_total", ")", "if", "shuffle", "else", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "self", ".", "n_total", ")", "]", ")", "# for batch sampling in training", "\n", "\n", "\n", "", "def", "build_original_features", "(", "self", ",", "lang", ",", "mode", ",", "load_data", "=", "True", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Build original features for [{}-{}]...\"", ".", "format", "(", "lang", ",", "mode", ")", ")", "\n", "\n", "# examples: a list of sentences. each item is a tuple of a list of words and a list of tags > (['words'], ['tags'])", "\n", "examples", "=", "self", ".", "processor", ".", "get_examples", "(", "lang", ",", "mode", ")", "# 'en', 'train'", "\n", "\n", "# prepare data (max length limitation...)", "\n", "if", "not", "load_data", ":", "\n", "            ", "tokens_labels", "=", "self", ".", "_prepare_data", "(", "examples", ",", "'data/{}-{}-processed.txt'", ".", "format", "(", "lang", ",", "mode", ")", ")", "\n", "", "else", ":", "\n", "            ", "tokens_labels", "=", "self", ".", "_load_data", "(", "'data/{}-{}-processed.txt'", ".", "format", "(", "lang", ",", "mode", ")", ")", "\n", "\n", "# convert texts and labels to ids, add segments and mask", "\n", "", "features", "=", "[", "]", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "\n", "for", "item", "in", "tokens_labels", ":", "\n", "            ", "tokens", ",", "labels", "=", "item", ".", "split", "(", "'\\t|\\t'", ")", "\n", "tokens", "=", "tokens", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "labels", "=", "labels", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "label_ids", "=", "[", "label_map", "[", "label", "]", "for", "label", "in", "labels", "]", "\n", "\n", "if", "len", "(", "label_ids", ")", "!=", "len", "(", "input_ids", ")", ":", "\n", "                ", "assert", "False", "\n", "", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "input_ids", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "label_ids", "+=", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "[", "0", "]", "*", "(", "self", ".", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "\n", "features", ".", "append", "(", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "input_mask", "=", "input_mask", ",", "segment_ids", "=", "segment_ids", ",", "label_id", "=", "label_ids", ")", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'  Num examples: {}, Num examples after split: {}'", ".", "format", "(", "len", "(", "examples", ")", ",", "len", "(", "features", ")", ")", ")", "\n", "return", "features", "\n", "\n", "", "def", "build_query_features_with_mask", "(", "self", ",", "mask_rate", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Build query features with MASK for [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "\n", "assert", "mask_rate", ">", "0", "\n", "features", "=", "deepcopy", "(", "self", ".", "original_features", ")", "\n", "mask_id", "=", "self", ".", "tokenizer", ".", "vocab", "[", "'[MASK]'", "]", "\n", "\n", "n_BIs", "=", "0", "\n", "n_masked", "=", "0", "\n", "for", "item", "in", "features", ":", "\n", "            ", "for", "i", ",", "label_id", "in", "enumerate", "(", "item", ".", "label_id", ")", ":", "\n", "                ", "if", "label_id", "==", "0", ":", "# [PAD] token", "\n", "                    ", "break", "\n", "", "label", "=", "self", ".", "label_list", "[", "label_id", "-", "1", "]", "\n", "if", "len", "(", "label", ")", ">", "1", "and", "label", "[", "1", "]", "==", "'-'", ":", "# -: both B-XXX and I-XXX have a '-'", "\n", "                    ", "n_BIs", "+=", "1", "\n", "if", "np", ".", "random", ".", "random", "(", ")", "<", "mask_rate", ":", "\n", "                        ", "item", ".", "input_ids", "[", "i", "]", "=", "mask_id", "\n", "n_masked", "+=", "1", "\n", "\n", "", "", "", "", "self", ".", "logger", ".", "info", "(", "'  Masked {}/{} tokens in total.'", ".", "format", "(", "n_masked", ",", "n_BIs", ")", ")", "\n", "\n", "return", "features", "\n", "\n", "", "def", "_prepare_data", "(", "self", ",", "examples", ",", "fn", ")", ":", "\n", "\n", "        ", "def", "output_item", "(", "tokens", ",", "labels", ",", "res_list", ",", "fw", ")", ":", "\n", "            ", "item", "=", "' '", ".", "join", "(", "[", "'[CLS]'", "]", "+", "tokens", "+", "[", "'[SEP]'", "]", ")", "+", "'\\t|\\t'", "+", "' '", ".", "join", "(", "[", "'[CLS]'", "]", "+", "labels", "+", "[", "'[SEP]'", "]", ")", "\n", "res_list", ".", "append", "(", "item", ")", "\n", "fw", ".", "write", "(", "item", "+", "'\\n'", ")", "\n", "\n", "", "fw", "=", "open", "(", "fn", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "res", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.read_tasks_from_file": [[236, 363], ["preprocessor.Corpus.logger.info", "preprocessor.Corpus.logger.info", "preprocessor.Corpus.logger.info", "enumerate", "preprocessor.Corpus.logger.info", "open", "list", "preprocessor.Corpus._convert_Domain2FewNERD", "max", "enumerate", "enumerate", "output_tasks.append", "preprocessor.Corpus._count_transition_matrix_", "preprocessor.Corpus.logger.info", "json.loads", "len", "set", "set.remove", "preprocessor.Corpus.__tokenize_types__", "zip", "preprocessor.Corpus._convert_label_to_entities_", "max", "preprocessor.Corpus._convert_example_to_feature_", "tmp_support.append", "tmp_support_tokens.append", "zip", "preprocessor.Corpus._convert_label_to_entities_", "max", "preprocessor.Corpus._convert_example_to_feature_", "tmp_query.append", "tmp_query_tokens.append", "len", "len", "set.update", "len", "preprocessor.Corpus._convert_label_to_BIOES_", "preprocessor.InputExample", "all_labels.append", "len", "preprocessor.Corpus._convert_label_to_BIOES_", "preprocessor.InputExample", "all_labels.append", "preprocessor.Corpus._convert_label_to_BIO_", "preprocessor.Corpus._convert_label_to_BIO_", "preprocessor.Corpus._convert_label_to_IO_", "ValueError", "preprocessor.Corpus._convert_label_to_IO_", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_Domain2FewNERD", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._count_transition_matrix_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.__tokenize_types__", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_entities_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_example_to_feature_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_entities_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_example_to_feature_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_BIOES_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_BIOES_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_BIO_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_BIO_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_IO_", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_IO_"], ["for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "            ", "textList", "=", "example", ".", "text_a", "\n", "labelList", "=", "example", ".", "label", "\n", "tokens", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "textList", ")", ":", "\n", "                ", "token", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "label", "=", "[", "labelList", "[", "i", "]", "]", "+", "[", "'X'", "]", "*", "(", "len", "(", "token", ")", "-", "1", ")", "\n", "if", "len", "(", "token", ")", "!=", "len", "(", "label", ")", ":", "\n", "                    ", "assert", "False", "\n", "", "tokens", ".", "extend", "(", "token", ")", "\n", "labels", ".", "extend", "(", "label", ")", "\n", "\n", "", "if", "len", "(", "tokens", ")", ">=", "self", ".", "max_seq_length", "-", "1", ":", "\n", "                ", "tokens_", "=", "tokens", "[", "0", ":", "(", "self", ".", "max_seq_length", "-", "2", ")", "]", "\n", "labels_", "=", "labels", "[", "0", ":", "(", "self", ".", "max_seq_length", "-", "2", ")", "]", "\n", "output_item", "(", "tokens_", ",", "labels_", ",", "res", ",", "fw", ")", "\n", "\n", "curr_idx", "=", "self", ".", "max_seq_length", "-", "2", "\n", "while", "len", "(", "tokens", ")", ">=", "curr_idx", "+", "self", ".", "max_seq_length", "//", "2", "-", "2", ":", "\n", "                    ", "tokens_", "=", "tokens", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "curr_idx", "+", "self", ".", "max_seq_length", "//", "2", "-", "2", "]", "\n", "labels_", "=", "labels", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "curr_idx", "+", "self", ".", "max_seq_length", "//", "2", "-", "2", "]", "\n", "output_item", "(", "tokens_", ",", "labels_", ",", "res", ",", "fw", ")", "\n", "curr_idx", "+=", "self", ".", "max_seq_length", "//", "2", "-", "2", "\n", "\n", "", "tokens_", "=", "tokens", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "]", "\n", "labels_", "=", "labels", "[", "curr_idx", "-", "self", ".", "max_seq_length", "//", "2", ":", "]", "\n", "output_item", "(", "tokens_", ",", "labels_", ",", "res", ",", "fw", ")", "\n", "\n", "", "else", ":", "\n", "                ", "output_item", "(", "tokens", ",", "labels", ",", "res", ",", "fw", ")", "\n", "\n", "", "", "return", "res", "\n", "\n", "", "def", "_load_data", "(", "self", ",", "fn", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "with", "open", "(", "fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "res", ".", "append", "(", "line", ")", "\n", "", "", "return", "res", "\n", "\n", "\n", "", "def", "get_support_ids", "(", "self", ",", "base_features", ",", "support_size", "=", "2", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Getting support feature ids for [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "target_features", "=", "self", ".", "query_features", "\n", "\n", "target_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "target_features", "]", ")", "\n", "base_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "base_features", "]", ")", "# sample_num x feature_dim", "\n", "\n", "# compute pairwise cosine distance", "\n", "dis", "=", "np", ".", "matmul", "(", "target_reprs", ",", "base_reprs", ".", "T", ")", "# target_num x base_num", "\n", "\n", "base_norm", "=", "np", ".", "linalg", ".", "norm", "(", "base_reprs", ",", "axis", "=", "1", ")", "# base_num", "\n", "base_norm", "=", "np", ".", "stack", "(", "[", "base_norm", "]", "*", "len", "(", "target_features", ")", ",", "axis", "=", "0", ")", "# target_num x base_num", "\n", "\n", "dis", "=", "dis", "/", "base_norm", "# target_num x base_num", "\n", "relevance", "=", "np", ".", "argsort", "(", "dis", ",", "axis", "=", "1", ")", "\n", "\n", "support_id_set", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "target_features", ")", ":", "\n", "            ", "chosen_ids", "=", "relevance", "[", "i", "]", "[", "-", "1", "*", "(", "support_size", "+", "1", ")", ":", "-", "1", "]", "\n", "if", "i", "<=", "9", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'  Support set info: {}: {}'", ".", "format", "(", "i", ",", "', '", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "chosen_ids", "]", ")", ")", ")", "\n", "", "support_id_set", ".", "extend", "(", "chosen_ids", ")", "\n", "\n", "", "support_id_set", "=", "set", "(", "support_id_set", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'  size of support ids: {}'", ".", "format", "(", "len", "(", "support_id_set", ")", ")", ")", "\n", "return", "list", "(", "support_id_set", ")", "\n", "\n", "", "def", "reset_query_features", "(", "self", ",", "feature_ids", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Reset query features of [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "self", ".", "query_features", "=", "[", "self", ".", "original_features", "[", "i", "]", "for", "i", "in", "feature_ids", "]", "\n", "\n", "self", ".", "n_total", "=", "len", "(", "self", ".", "query_features", ")", "\n", "self", ".", "reset_batch_info", "(", "shuffle", "=", "shuffle", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'  size of current query features: {}'", ".", "format", "(", "self", ".", "n_total", ")", ")", "\n", "\n", "", "def", "build_support_features_", "(", "self", ",", "base_features", ",", "support_size", "=", "2", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Build support features for [{}-{}]...\"", ".", "format", "(", "self", ".", "language", ",", "self", ".", "mode", ")", ")", "\n", "target_features", "=", "self", ".", "query_features", "\n", "\n", "target_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "target_features", "]", ")", "\n", "base_reprs", "=", "np", ".", "stack", "(", "[", "item", ".", "representation", "for", "item", "in", "base_features", "]", ")", "# sample_num x feature_dim", "\n", "\n", "# compute pairwise cosine distance", "\n", "dis", "=", "np", ".", "matmul", "(", "target_reprs", ",", "base_reprs", ".", "T", ")", "# target_num x base_num", "\n", "\n", "base_norm", "=", "np", ".", "linalg", ".", "norm", "(", "base_reprs", ",", "axis", "=", "1", ")", "# base_num", "\n", "base_norm", "=", "np", ".", "stack", "(", "[", "base_norm", "]", "*", "len", "(", "target_features", ")", ",", "axis", "=", "0", ")", "# target_num x base_num", "\n", "\n", "dis", "=", "dis", "/", "base_norm", "# target_num x base_num", "\n", "relevance", "=", "np", ".", "argsort", "(", "dis", ",", "axis", "=", "1", ")", "\n", "\n", "support_set", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "target_features", ")", ":", "\n", "            ", "chosen_ids", "=", "relevance", "[", "i", "]", "[", "-", "1", "*", "(", "support_size", "+", "1", ")", ":", "-", "1", "]", "\n", "self", ".", "logger", ".", "info", "(", "'  Support set info: {}: {}'", ".", "format", "(", "i", ",", "', '", ".", "join", "(", "[", "str", "(", "id", ")", "for", "id", "in", "chosen_ids", "]", ")", ")", ")", "\n", "support", "=", "[", "base_features", "[", "id", "]", "for", "id", "in", "chosen_ids", "]", "\n", "support_set", ".", "append", "(", "support", ")", "\n", "\n", "", "return", "support_set", "\n", "\n", "\n", "", "def", "get_batch_meta", "(", "self", ",", "batch_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "batch_start_idx", "+", "batch_size", ">=", "self", ".", "n_total", ":", "\n", "            ", "self", ".", "reset_batch_info", "(", "shuffle", "=", "shuffle", ")", "\n", "if", "self", ".", "mask_rate", ">=", "0", ":", "\n", "                ", "self", ".", "query_features", "=", "self", ".", "build_query_features_with_mask", "(", "mask_rate", "=", "self", ".", "mask_rate", ")", "\n", "\n", "\n", "", "", "query_batch", "=", "[", "]", "\n", "support_batch", "=", "[", "]", "\n", "start_id", "=", "self", ".", "batch_start_idx", "\n", "\n", "for", "i", "in", "range", "(", "start_id", ",", "start_id", "+", "batch_size", ")", ":", "\n", "            ", "idx", "=", "self", ".", "batch_idxs", "[", "i", "]", "\n", "query_i", "=", "self", ".", "query_features", "[", "idx", "]", "\n", "query_item", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "input_ids", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "# 1 x max_seq_len", "\n", "'input_mask'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "input_mask", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "segment_ids", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "query_i", ".", "label_id", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([query_i.flag], dtype=torch.long).to(device)", "\n", "}", "\n", "query_batch", ".", "append", "(", "query_item", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_Domain2FewNERD": [[364, 389], ["json.loads", "json.loads.keys", "res.extend", "jj.replace().replace", "preprocessor.Corpus._convert_Domain2FewNERD.decode_batch"], "methods", ["None"], ["\n", "support_i", "=", "self", ".", "support_features", "[", "idx", "]", "\n", "support_item", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'input_mask'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "support_i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([f.flag for f in support_i], dtype=torch.long).to(device)", "\n", "}", "\n", "support_batch", ".", "append", "(", "support_item", ")", "\n", "\n", "", "self", ".", "batch_start_idx", "+=", "batch_size", "\n", "\n", "return", "query_batch", ",", "support_batch", "\n", "\n", "", "def", "get_batch_NOmeta", "(", "self", ",", "batch_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "batch_start_idx", "+", "batch_size", ">=", "self", ".", "n_total", ":", "\n", "            ", "self", ".", "reset_batch_info", "(", "shuffle", "=", "shuffle", ")", "\n", "if", "self", ".", "mask_rate", ">=", "0", ":", "\n", "                ", "self", ".", "query_features", "=", "self", ".", "build_query_features_with_mask", "(", "mask_rate", "=", "self", ".", "mask_rate", ")", "\n", "\n", "", "", "idxs", "=", "self", ".", "batch_idxs", "[", "self", ".", "batch_start_idx", ":", "self", ".", "batch_start_idx", "+", "batch_size", "]", "\n", "batch_features", "=", "[", "self", ".", "query_features", "[", "idx", "]", "for", "idx", "in", "idxs", "]", "\n", "# batch_features = self.query_features[self.batch_start_idx : self.batch_start_idx + batch_size]", "\n", "\n", "batch", "=", "{", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.__tokenize_types__": [[390, 403], ["tokens.pop", "tokens.extend", "tokens.append", "preprocessor.Corpus.tokenizer.tokenize", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], ["'input_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'input_mask'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([f.flag for f in batch_features], dtype=torch.long).to(device)", "\n", "}", "\n", "\n", "self", ".", "batch_start_idx", "+=", "batch_size", "\n", "\n", "return", "batch", "\n", "\n", "", "def", "get_batches", "(", "self", ",", "batch_size", ",", "device", "=", "\"cuda\"", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "batches", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._count_transition_matrix_": [[404, 414], ["preprocessor.Corpus.logger.info", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "preprocessor.Corpus.logger.info", "range", "len"], "methods", ["None"], ["if", "shuffle", ":", "\n", "            ", "idxs", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n_total", ")", "\n", "features", "=", "[", "self", ".", "query_features", "[", "i", "]", "for", "i", "in", "idxs", "]", "\n", "", "else", ":", "\n", "            ", "features", "=", "self", ".", "query_features", "\n", "\n", "", "for", "i", "in", "range", "(", "0", ",", "self", ".", "n_total", ",", "batch_size", ")", ":", "\n", "            ", "batch_features", "=", "features", "[", "i", ":", "min", "(", "self", ".", "n_total", ",", "i", "+", "batch_size", ")", "]", "\n", "\n", "batch", "=", "{", "\n", "'input_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_entities_": [[415, 430], ["len", "range", "range", "zip"], "methods", ["None"], ["'input_mask'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'segment_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ",", "\n", "'label_ids'", ":", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "batch_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "#,", "\n", "# 'flag_ids': torch.tensor([f.flag for f in batch_features], dtype=torch.long).to(device)", "\n", "}", "\n", "\n", "batches", ".", "append", "(", "batch", ")", "\n", "\n", "", "return", "batches", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_BIOES_": [[431, 462], ["range", "len", "res.append", "res.append", "res.append", "res.append", "res.append", "ValueError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_BIO_": [[463, 476], ["label_output.append", "label_output.append", "label_output.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_label_to_IO_": [[477, 486], ["label_output.append", "label_output.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._convert_example_to_feature_": [[487, 644], ["zip", "max", "numpy.zeros", "numpy.zeros", "numpy.ones", "enumerate", "preprocessor.Corpus.entity_types.generate_negative_types", "preprocessor.Corpus.tokenizer.convert_tokens_to_ids", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "preprocessor.Corpus.tokenizer.tokenize", "token_sum.append", "tokens.extend", "label_ids.extend", "len", "len", "numpy.concatenate", "len", "len", "len", "len", "len", "len", "len", "len", "preprocessor.InputFeatures", "len", "len", "len", "zip", "len", "ValueError", "len", "ValueError", "len", "len", "len", "len", "numpy.array", "numpy.array", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.EntityTypes.generate_negative_types", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.reset_batch_info": [[646, 652], ["numpy.random.permutation", "numpy.array", "range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_meta": [[654, 728], ["range", "preprocessor.Corpus.reset_batch_info", "query_batch.append", "support_batch.append", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.reset_batch_info"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_NOmeta": [[729, 769], ["preprocessor.Corpus.reset_batch_info", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "preprocessor.Corpus.build_query_features_with_mask", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.reset_batch_info", "home.repos.pwc.inspect_result.microsoft_vert-papers.Meta-Cross.preprocessor.Corpus.build_query_features_with_mask"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batches": [[770, 811], ["range", "numpy.random.permutation", "batches.append", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "min", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus._decoder_bpe_index": [[812, 827], ["enumerate", "len", "len", "res.append", "len", "len", "bisect.bisect_left", "bisect.bisect_left", "tmp.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.utils.load_file": [[12, 27], ["os.path.exists", "open", "ii.strip", "f.read", "f.readlines", "list", "f.readlines", "json.loads", "f.read", "json.loads", "f.readlines"], "function", ["None"], ["# distributed under the License is distributed on an \"AS IS\" BASIS,", "\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.", "\n", "# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n", "\n", "import", "csv", "\n", "import", "sys", "\n", "import", "copy", "\n", "import", "json", "\n", "\n", "class", "InputExample", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.utils.set_seed": [[29, 36], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["\n", "def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.__init__": [[30, 93], ["torch.nn.Module.__init__", "len", "logger.info", "modeling.BertForTokenClassification_.from_pretrained().to", "learner.Learner.model.set_config", "learner.Learner.model.to", "learner.Learner.layer_set", "learner.Learner.load_model", "str", "modeling.BertForTokenClassification_.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.set_config", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.layer_set", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained"], ["\n", "## load model", "\n", "if", "model_dir", "!=", "''", ":", "\n", "            ", "logger", ".", "info", "(", "'********** Loading saved model **********'", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "CONFIG_NAME", ")", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'en_{}'", ".", "format", "(", "WEIGHTS_NAME", ")", ")", "\n", "config", "=", "BertConfig", "(", "output_config_file", ")", "\n", "self", ".", "model", "=", "BertForTokenClassification_", "(", "config", ",", "num_labels", "=", "num_labels", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_model_file", ",", "map_location", "=", "\"cuda:{}\"", ".", "format", "(", "gpu_no", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'********** Loading pre-trained model **********'", ")", "\n", "cache_dir", "=", "cache_dir", "if", "cache_dir", "else", "str", "(", "PYTORCH_PRETRAINED_BERT_CACHE", ")", "\n", "self", ".", "model", "=", "BertForTokenClassification_", ".", "from_pretrained", "(", "bert_model", ",", "cache_dir", "=", "cache_dir", ",", "num_labels", "=", "num_labels", ")", "\n", "\n", "## layer freezing", "\n", "", "if", "freeze_layer", "==", "0", ":", "\n", "            ", "no_grad_param_names", "=", "[", "'embeddings'", "]", "# layer.0", "\n", "", "else", ":", "\n", "            ", "no_grad_param_names", "=", "[", "'embeddings'", ",", "'pooler'", "]", "+", "[", "'layer.{}.'", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "freeze_layer", "+", "1", ")", "]", "\n", "", "logger", ".", "info", "(", "\"The frozen parameters are:\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "any", "(", "no_grad_pn", "in", "name", "for", "no_grad_pn", "in", "no_grad_param_names", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "logger", ".", "info", "(", "\"  {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "", "self", ".", "opt", "=", "BertAdam", "(", "self", ".", "get_optimizer_grouped_parameters", "(", ")", ",", "lr", "=", "lr_meta", ",", "\n", "warmup", "=", "warmup_prop_meta", ",", "t_total", "=", "max_meta_steps", ")", "\n", "\n", "\n", "", "def", "get_optimizer_grouped_parameters", "(", "self", ")", ":", "\n", "        ", "param_optimizer", "=", "list", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "return", "optimizer_grouped_parameters", "\n", "\n", "\n", "", "def", "get_names", "(", "self", ")", ":", "\n", "        ", "names", "=", "[", "n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "return", "names", "\n", "\n", "", "def", "get_params", "(", "self", ")", ":", "\n", "        ", "params", "=", "[", "p", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "return", "params", "\n", "\n", "\n", "", "def", "load_weights", "(", "self", ",", "names", ",", "params", ")", ":", "\n", "        ", "model_params", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "for", "n", ",", "p", "in", "zip", "(", "names", ",", "params", ")", ":", "\n", "            ", "model_params", "[", "n", "]", ".", "data", ".", "copy_", "(", "p", ".", "data", ")", "\n", "\n", "", "", "def", "load_gradients", "(", "self", ",", "names", ",", "grads", ")", ":", "\n", "        ", "model_params", "=", "self", ".", "model", ".", "state_dict", "(", "keep_vars", "=", "True", ")", "\n", "for", "n", ",", "g", "in", "zip", "(", "names", ",", "grads", ")", ":", "\n", "            ", "model_params", "[", "n", "]", ".", "grad", ".", "data", ".", "add_", "(", "g", ".", "data", ")", "# accumulate", "\n", "\n", "\n", "", "", "def", "get_learning_rate", "(", "self", ",", "lr", ",", "progress", ",", "warmup", ",", "schedule", "=", "'linear'", ")", ":", "\n", "        ", "if", "schedule", "==", "'linear'", ":", "\n", "            ", "if", "progress", "<", "warmup", ":", "\n", "                ", "lr", "*=", "progress", "/", "warmup", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.layer_set": [[94, 110], ["logger.info", "learner.Learner.model.named_parameters", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "any", "learner.Learner.get_optimizer_grouped_parameters", "logger.info", "int", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters"], ["                ", "lr", "*=", "max", "(", "(", "progress", "-", "1.", ")", "/", "(", "warmup", "-", "1.", ")", ",", "0.", ")", "\n", "\n", "", "", "return", "lr", "\n", "\n", "\n", "", "def", "inner_update", "(", "self", ",", "data_support", ",", "lr_curr", ",", "inner_steps", ",", "lambda_max_loss", ",", "lambda_mask_loss", ")", ":", "\n", "        ", "inner_opt", "=", "BertAdam", "(", "self", ".", "get_optimizer_grouped_parameters", "(", ")", ",", "lr", "=", "self", ".", "lr_inner", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "inner_steps", ")", ":", "\n", "            ", "inner_opt", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr_curr", "\n", "inner_opt", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", "=", "lr_curr", "\n", "\n", "inner_opt", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "model", ".", "forward_wuqh", "(", "data_support", "[", "'input_ids'", "]", ",", "data_support", "[", "'segment_ids'", "]", ",", "\n", "data_support", "[", "'input_mask'", "]", ",", "data_support", "[", "'label_ids'", "]", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_optimizer_grouped_parameters": [[112, 134], ["list", "learner.Learner.model.named_parameters", "any", "any"], "methods", ["None"], ["loss", ".", "backward", "(", ")", "\n", "inner_opt", ".", "step", "(", ")", "\n", "\n", "", "return", "loss", ".", "item", "(", ")", "\n", "\n", "\n", "", "def", "forward_meta", "(", "self", ",", "batch_query", ",", "batch_support", ",", "progress", ",", "inner_steps", ",", "lambda_max_loss", ",", "lambda_mask_loss", ")", ":", "# for one task", "\n", "        ", "names", "=", "self", ".", "get_names", "(", ")", "\n", "params", "=", "self", ".", "get_params", "(", ")", "\n", "weights", "=", "deepcopy", "(", "params", ")", "\n", "\n", "meta_grad", "=", "[", "]", "\n", "meta_loss", "=", "[", "]", "\n", "\n", "task_num", "=", "len", "(", "batch_query", ")", "\n", "lr_inner", "=", "self", ".", "get_learning_rate", "(", "self", ".", "lr_inner", ",", "progress", ",", "self", ".", "warmup_prop_inner", ")", "\n", "\n", "# compute meta_grad of each task", "\n", "for", "task_id", "in", "range", "(", "task_num", ")", ":", "\n", "            ", "self", ".", "inner_update", "(", "batch_support", "[", "task_id", "]", ",", "lr_inner", ",", "inner_steps", "=", "inner_steps", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n", "loss", "=", "self", ".", "model", ".", "forward_wuqh", "(", "batch_query", "[", "task_id", "]", "[", "'input_ids'", "]", ",", "batch_query", "[", "task_id", "]", "[", "'segment_ids'", "]", ",", "\n", "batch_query", "[", "task_id", "]", "[", "'input_mask'", "]", ",", "batch_query", "[", "task_id", "]", "[", "'label_ids'", "]", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_names": [[135, 138], ["learner.Learner.model.named_parameters"], "methods", ["None"], ["lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "params", ")", "\n", "meta_grad", ".", "append", "(", "grad", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_params": [[139, 142], ["learner.Learner.model.parameters"], "methods", ["None"], ["meta_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "load_weights", "(", "names", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights": [[143, 147], ["learner.Learner.model.state_dict", "zip", "model_params[].data.copy_"], "methods", ["None"], ["# accumulate grads of all tasks to param.grad", "\n", "", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "# similar to backward()", "\n", "for", "g", "in", "meta_grad", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_gradients": [[148, 154], ["learner.Learner.model.state_dict", "zip", "model_params[].grad.data.add_"], "methods", ["None"], ["            ", "self", ".", "load_gradients", "(", "names", ",", "g", ")", "\n", "", "self", ".", "opt", ".", "step", "(", ")", "\n", "\n", "ave_loss", "=", "numpy", ".", "mean", "(", "numpy", ".", "array", "(", "meta_loss", ")", ")", "\n", "\n", "return", "ave_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_learning_rate": [[155, 162], ["max"], "methods", ["None"], ["\n", "", "def", "forward_NOmeta", "(", "self", ",", "batch_data", ",", "lambda_max_loss", ",", "lambda_mask_loss", ")", ":", "#, lambda_flag=-1.0):", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "loss", "=", "self", ".", "model", ".", "forward_wuqh", "(", "batch_data", "[", "'input_ids'", "]", ",", "batch_data", "[", "'segment_ids'", "]", ",", "\n", "batch_data", "[", "'input_mask'", "]", ",", "batch_data", "[", "'label_ids'", "]", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.inner_update": [[163, 195], ["transformers.AdamW", "learner.Learner.model.train", "range", "loss.item", "learner.Learner.get_optimizer_grouped_parameters", "transformers.AdamW.zero_grad", "learner.Learner.model.forward_wuqh", "loss.backward", "transformers.AdamW.step"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.UniTrans.main.train", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["lambda_mask_loss", "=", "lambda_mask_loss", ")", "#, lambda_flag=lambda_flag)", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "\n", "\n", "##---------------------------------------- Evaluation --------------------------------------##", "\n", "\n", "", "def", "write_result", "(", "self", ",", "words", ",", "y_true", ",", "y_pred", ",", "tmp_fn", ")", ":", "\n", "        ", "assert", "len", "(", "y_pred", ")", "==", "len", "(", "y_true", ")", "\n", "with", "open", "(", "tmp_fn", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fw", ":", "\n", "            ", "for", "i", ",", "sent", "in", "enumerate", "(", "y_true", ")", ":", "\n", "                ", "for", "j", ",", "word", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "fw", ".", "write", "(", "'{} {} {}\\n'", ".", "format", "(", "words", "[", "i", "]", "[", "j", "]", ",", "word", ",", "y_pred", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "", "fw", ".", "write", "(", "'\\n'", ")", "\n", "\n", "", "", "def", "evaluate_meta", "(", "self", ",", "corpus", ",", "result_dir", ",", "logger", ",", "lr", ",", "steps", ",", "lambda_max_loss", ",", "lambda_mask_loss", ",", "lang", "=", "'en'", ",", "mode", "=", "'valid'", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "bert_model", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "names", "=", "self", ".", "get_names", "(", ")", "\n", "params", "=", "self", ".", "get_params", "(", ")", "\n", "weights", "=", "deepcopy", "(", "params", ")", "\n", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "\n", "t_tmp", "=", "time", ".", "time", "(", ")", "\n", "for", "item_id", "in", "range", "(", "corpus", ".", "n_total", ")", ":", "\n", "            ", "eval_query", ",", "eval_support", "=", "corpus", ".", "get_batch_meta", "(", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "\n", "# train on support examples", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.forward_supervise": [[196, 255], ["len", "range", "range", "learner.Learner.model.forward_wuqh", "loss.backward", "learner.Learner.opt.step", "learner.Learner.scheduler.step", "learner.Learner.model.zero_grad", "learner.Learner.model.forward_wuqh", "loss.backward", "learner.Learner.opt.step", "learner.Learner.scheduler.step", "learner.Learner.model.zero_grad", "span_losses.append", "type_losses.append", "span_losses.append", "type_losses.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "loss.item", "type_loss.item", "loss.item", "type_loss.item"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh", "home.repos.pwc.inspect_result.microsoft_vert-papers.SingleMulti-TS.modeling_single.GRFunction.backward", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step"], ["self", ".", "inner_update", "(", "eval_support", "[", "0", "]", ",", "lr_curr", "=", "lr", ",", "inner_steps", "=", "steps", ",", "\n", "lambda_max_loss", "=", "lambda_max_loss", ",", "lambda_mask_loss", "=", "lambda_mask_loss", ")", "\n", "\n", "# eval on pseudo query examples (test example)", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "logits", "=", "self", ".", "model", "(", "eval_query", "[", "0", "]", "[", "'input_ids'", "]", ",", "eval_query", "[", "0", "]", "[", "'segment_ids'", "]", ",", "\n", "eval_query", "[", "0", "]", "[", "'input_mask'", "]", ")", "# batch_size x seq_len x target_size", "\n", "\n", "", "logits", "=", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "2", ")", ",", "dim", "=", "2", ")", "\n", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "input_ids", "=", "eval_query", "[", "0", "]", "[", "'input_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "label_ids", "=", "eval_query", "[", "0", "]", "[", "'label_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "input_mask", "=", "eval_query", "[", "0", "]", "[", "'input_mask'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "for", "i", ",", "mask", "in", "enumerate", "(", "input_mask", ")", ":", "\n", "                ", "temp_1", "=", "[", "]", "\n", "temp_2", "=", "[", "]", "\n", "temp_word", "=", "[", "]", "\n", "for", "j", ",", "m", "in", "enumerate", "(", "mask", ")", ":", "\n", "                    ", "if", "j", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "if", "m", ":", "\n", "                        ", "if", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", "!=", "\"X\"", ":", "\n", "                            ", "temp_1", ".", "append", "(", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "temp_2", ".", "append", "(", "label_map", "[", "max", "(", "logits", "[", "i", "]", "[", "j", "]", ",", "1", ")", "]", ")", "\n", "temp_word", ".", "append", "(", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "", "else", ":", "\n", "                            ", "tmp", "=", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", "\n", "if", "len", "(", "tmp", ")", ">", "2", "and", "len", "(", "temp_word", ")", ">", "0", ":", "\n", "                                ", "temp_word", "[", "-", "1", "]", "=", "temp_word", "[", "-", "1", "]", "+", "tmp", "[", "2", ":", "]", "\n", "", "", "", "else", ":", "\n", "                        ", "temp_1", ".", "pop", "(", ")", "\n", "temp_2", ".", "pop", "(", ")", "\n", "temp_word", ".", "pop", "(", ")", "\n", "break", "\n", "", "", "y_true", ".", "append", "(", "temp_1", ")", "\n", "y_pred", ".", "append", "(", "temp_2", ")", "\n", "words", ".", "append", "(", "temp_word", ")", "\n", "\n", "", "self", ".", "load_weights", "(", "names", ",", "weights", ")", "\n", "if", "item_id", "%", "50", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'  To sentence {}/{}. Time: {}sec'", ".", "format", "(", "item_id", ",", "corpus", ".", "n_total", ",", "time", ".", "time", "(", ")", "-", "t_tmp", ")", ")", "\n", "\n", "", "", "tmp_fn", "=", "'{}/{}-{}_pred.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "score_fn", "=", "'{}/{}-{}_score.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "self", ".", "write_result", "(", "words", ",", "y_true", ",", "y_pred", ",", "tmp_fn", ")", "\n", "os", ".", "system", "(", "'%s %s < %s > %s'", "%", "(", "self", ".", "py_alias", ",", "'conlleval.py'", ",", "tmp_fn", ",", "score_fn", ")", ")", "\n", "\n", "F1", "=", "-", "1", "\n", "with", "open", "(", "score_fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "            ", "for", "id", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "if", "id", "==", "1", ":", "\n", "                    ", "F1", "=", "float", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "", "logger", ".", "info", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "return", "F1", "\n", "\n", "", "def", "evaluate_NOmeta", "(", "self", ",", "corpus", ",", "result_dir", ",", "logger", ",", "lang", "=", "'en'", ",", "mode", "=", "'valid'", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "bert_model", ",", "do_lower_case", "=", "False", ")", "\n", "data_batches", "=", "corpus", ".", "get_batches", "(", "batch_size", "=", "64", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.forward_meta": [[257, 309], ["learner.Learner.get_names", "learner.Learner.get_params", "copy.deepcopy", "len", "learner.Learner.get_learning_rate", "range", "learner.Learner.opt.zero_grad", "learner.Learner.opt.step", "learner.Learner.scheduler.step", "learner.Learner.inner_update", "learner.Learner.model.forward_wuqh", "torch.autograd.grad", "meta_grad.append", "learner.Learner.load_weights", "learner.Learner.load_gradients", "span_losses.append", "type_losses.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "loss.item", "type_loss.item"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_names", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_params", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_learning_rate", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.optimization.AdamW.step", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.inner_update", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_gradients"], ["\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "for", "batch_id", ",", "data_batch", "in", "enumerate", "(", "data_batches", ")", ":", "\n", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "logits", "=", "self", ".", "model", "(", "data_batch", "[", "'input_ids'", "]", ",", "data_batch", "[", "'segment_ids'", "]", ",", "\n", "data_batch", "[", "'input_mask'", "]", ")", "# batch_size x seq_len x target_size", "\n", "\n", "", "logits", "=", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "2", ")", ",", "dim", "=", "2", ")", "\n", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "input_ids", "=", "data_batch", "[", "'input_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "label_ids", "=", "data_batch", "[", "'label_ids'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "input_mask", "=", "data_batch", "[", "'input_mask'", "]", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "for", "i", ",", "mask", "in", "enumerate", "(", "input_mask", ")", ":", "\n", "                ", "temp_1", "=", "[", "]", "\n", "temp_2", "=", "[", "]", "\n", "temp_word", "=", "[", "]", "\n", "for", "j", ",", "m", "in", "enumerate", "(", "mask", ")", ":", "\n", "                    ", "if", "j", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "if", "m", ":", "\n", "                        ", "if", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", "!=", "\"X\"", ":", "\n", "                            ", "temp_1", ".", "append", "(", "label_map", "[", "label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "temp_2", ".", "append", "(", "label_map", "[", "max", "(", "logits", "[", "i", "]", "[", "j", "]", ",", "1", ")", "]", ")", "\n", "temp_word", ".", "append", "(", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "", "else", ":", "\n", "                            ", "tmp", "=", "tokenizer", ".", "ids_to_tokens", "[", "input_ids", "[", "i", "]", "[", "j", "]", "]", "\n", "if", "len", "(", "tmp", ")", ">", "2", "and", "len", "(", "temp_word", ")", ">", "0", ":", "\n", "                                ", "temp_word", "[", "-", "1", "]", "=", "temp_word", "[", "-", "1", "]", "+", "tmp", "[", "2", ":", "]", "\n", "", "", "", "else", ":", "\n", "                        ", "temp_1", ".", "pop", "(", ")", "# pop [SEP]", "\n", "temp_2", ".", "pop", "(", ")", "\n", "temp_word", ".", "pop", "(", ")", "\n", "break", "\n", "", "", "y_true", ".", "append", "(", "temp_1", ")", "\n", "y_pred", ".", "append", "(", "temp_2", ")", "\n", "words", ".", "append", "(", "temp_word", ")", "\n", "\n", "", "", "tmp_fn", "=", "'{}/{}-{}_pred.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "score_fn", "=", "'{}/{}-{}_score.txt'", ".", "format", "(", "result_dir", ",", "lang", ",", "mode", ")", "\n", "self", ".", "write_result", "(", "words", ",", "y_true", ",", "y_pred", ",", "tmp_fn", ")", "\n", "os", ".", "system", "(", "'%s %s < %s > %s'", "%", "(", "self", ".", "py_alias", ",", "'conlleval.py'", ",", "tmp_fn", ",", "score_fn", ")", ")", "\n", "\n", "F1", "=", "-", "1", "\n", "with", "open", "(", "score_fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fr", ":", "\n", "            ", "for", "id", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "if", "id", "==", "1", ":", "\n", "                    ", "F1", "=", "float", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "", "logger", ".", "info", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.write_result": [[312, 319], ["len", "len", "open", "enumerate", "fw.write", "enumerate", "fw.write"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "result_dir", ",", "fn_prefix", ",", "max_seq_len", ")", ":", "\n", "# Save a trained model and the associated configuration", "\n", "        ", "model_to_save", "=", "self", ".", "model", ".", "module", "if", "hasattr", "(", "self", ".", "model", ",", "'module'", ")", "else", "self", ".", "model", "# Only save the model it-self", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "'{}_{}'", ".", "format", "(", "fn_prefix", ",", "WEIGHTS_NAME", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "CONFIG_NAME", ")", "\n", "with", "open", "(", "output_config_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "model_to_save", ".", "config", ".", "to_json_string", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.batch_test": [[320, 349], ["range", "learner.Learner.model.forward_wuqh", "logits.extend", "e_logits.extend", "data.items", "tmp_l.detach().cpu().numpy", "tmp_el.detach().cpu().numpy", "tmp_l.detach().cpu", "tmp_el.detach().cpu", "tmp_l.detach", "tmp_el.detach"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.forward_wuqh"], ["", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "label_list", ",", "1", ")", "}", "\n", "model_config", "=", "{", "\"bert_model\"", ":", "self", ".", "bert_model", ",", "\"do_lower\"", ":", "False", ",", "\n", "\"max_seq_length\"", ":", "max_seq_len", ",", "\"num_labels\"", ":", "len", "(", "self", ".", "label_list", ")", "+", "1", ",", "\n", "\"label_map\"", ":", "label_map", "}", "\n", "json", ".", "dump", "(", "model_config", ",", "open", "(", "os", ".", "path", ".", "join", "(", "result_dir", ",", "\"model_config.json\"", ")", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.evaluate_meta_": [[350, 567], ["logger.info", "learner.Learner.get_names", "learner.Learner.get_params", "copy.deepcopy", "time.time", "range", "logger.info", "joblib.dump", "joblib.dump", "learner.Learner.cacl_f1", "learner.Learner.cacl_f1", "learner.Learner.cacl_f1", "learner.Learner.cacl_f1", "logger.info", "sorted", "logger.info", "learner.Learner.save_model", "learner.Learner.load_model", "corpus.get_batch_meta", "learner.Learner.model.eval", "learner.Learner.load_weights", "learner.Learner.load_model", "learner.Learner.get_names", "learner.Learner.get_params", "copy.deepcopy", "range", "joblib.dump", "results.keys", "logger.info", "learner.Learner.inner_update", "torch.no_grad", "learner.Learner.batch_test", "lss.append", "logger.info", "corpus.get_batch_meta", "learner.Learner.inner_update", "learner.Learner.model.eval", "learner.Learner.decode_entity", "predes.extend", "learner.Learner.load_weights", "str", "learner.Learner.eval_typing", "type_preds.append", "type_g.append", "learner.Learner.decode_span", "targets.extend", "spans.extend", "torch.no_grad", "learner.Learner.decode_span", "learner.Learner.batch_test", "logger.info", "learner.Learner.batch_test", "learner.Learner.eval_typing", "type_preds.append", "type_g.append", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_names", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_params", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.cacl_f1", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.cacl_f1", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.cacl_f1", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.cacl_f1", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_meta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_model", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_names", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.get_params", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.inner_update", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.batch_test", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.preprocessor.Corpus.get_batch_meta", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.inner_update", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.decode_entity", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.eval_typing", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.decode_span", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.decode_span", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.batch_test", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.batch_test", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.eval_typing"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_model": [[568, 599], ["os.path.join", "torch.save", "os.path.join", "json.dump", "hasattr", "model_to_save.state_dict", "open", "f.write", "open", "joblib.dump", "model_to_save.config.to_json_string", "enumerate", "len", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.processors.utils.InputFeatures.to_json_string"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.save_best_model": [[601, 606], ["os.path.join", "os.path.join", "shutil.copy", "shutil.copy", "os.path.join.replace", "os.path.join.replace"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.load_model": [[607, 628], ["logger.info", "os.path.join", "modeling.BertForTokenClassification_.from_pretrained", "learner.Learner.model.set_config", "learner.Learner.model.to", "learner.Learner.model.load_state_dict", "learner.Learner.layer_set", "torch.load", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.modeling.BertForTokenClassification_.set_config", "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.layer_set"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.decode_span": [[629, 757], ["max", "target.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "max", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "joblib.dump", "range", "logits.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "numpy.argmax", "numpy.argmax", "range", "enumerate", "len", "numpy.ones", "numpy.ones", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "len", "torch.tensor().to", "torch.nn.functional.log_softmax", "viterbi_decoder.forward", "zip", "target.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "res.append", "range", "len", "len", "tmp_logits.unsqueeze.unsqueeze.unsqueeze", "tmp_logits.unsqueeze.unsqueeze.detach", "tmp_target.detach().cpu().numpy", "numpy.argmax.append", "logits.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "tmp.append", "res.append", "len", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tmp.append", "len", "tmp.append", "target.detach().cpu().numpy.detach().cpu().numpy.detach", "len", "len", "tmp_target.detach().cpu", "len", "tmp.append", "logits.detach().cpu().numpy.detach().cpu().numpy.detach", "tmp.append", "len", "len", "len", "tmp_target.detach"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.decode_entity": [[759, 775], ["len", "range", "joblib.dump", "range", "preds.append", "len", "tmp.append", "len", "numpy.argmax", "numpy.argmax", "numpy.argmax", "numpy.argmax"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.cacl_f1": [[776, 787], ["zip", "len", "len", "len", "set", "set"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.DecomposedMetaNER.learner.Learner.eval_typing": [[788, 804], ["e_type_mask.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "len", "range", "joblib.dump", "numpy.argmax", "numpy.argmax", "res.extend", "len", "enumerate", "enumerate", "e_type_mask.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "e_type_mask.detach().cpu().numpy.detach().cpu().numpy.detach"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.context.ContextLayer.__init__": [[8, 18], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feature_dim", "=", "400", ",", "exclusive_context", "=", "False", ",", "use_gpu", "=", "True", ")", ":", "\n", "# checked", "\n", "        ", "super", "(", "ContextLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feature_dim", "=", "feature_dim", "\n", "self", ".", "exclusive_context", "=", "exclusive_context", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "\n", "self", ".", "forget_gate_linear0", "=", "nn", ".", "Linear", "(", "in_features", "=", "feature_dim", ",", "out_features", "=", "feature_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "forget_gate_linear1", "=", "nn", ".", "Linear", "(", "in_features", "=", "feature_dim", ",", "out_features", "=", "feature_dim", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.context.ContextLayer.forward": [[19, 81], ["input.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "context.ContextLayer.forget_gate_linear0", "context.ContextLayer.forget_gate_linear1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "input.view().expand", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "input_masks.view().mul", "selection_mask.view().expand.view().expand.view().expand", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.tanh", "torch.tanh", "torch.tanh", "context.ContextLayer.view().expand", "context.ContextLayer.view().expand", "input_masks.view", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "eye_matrix_seed.to.to.view().expand", "selection_mask.view().expand.view().expand.masked_fill_", "selection_mask.view().expand.view().expand.float", "context_lengths.view().expand().float", "input.view", "input_masks.view", "eye_matrix_seed.to.to.to", "selection_mask.view().expand.view().expand.view", "context.ContextLayer.view", "context.ContextLayer.view", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "eye_matrix_seed.to.to.view", "torch.sum.eq().long", "torch.sum.eq().long", "torch.sum.eq().long", "context_lengths.view().expand", "torch.sum.eq", "torch.sum.eq", "torch.sum.eq", "context_lengths.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_masks", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Get the context vector for each word\n        :param input: features, batch x max_seq x embed/feature\n        :param input_masks: binary mask matrix for the sentence words, batch x max_seq\n        :param device: device to run the algorithm\n        :return: context vector for each word, batch x max_seq x embed/feature\n        \"\"\"", "\n", "batch_size", ",", "max_seq_size", ",", "embed_size", "=", "input", ".", "size", "(", ")", "\n", "sentence_lengths", "=", "torch", ".", "sum", "(", "input_masks", ",", "1", ")", "\n", "\n", "assert", "self", ".", "feature_dim", "==", "embed_size", "\n", "\n", "# attention-based context information", "\n", "# batch x max_seq x embed --> batch x max_seq x max_seq x embed", "\n", "forget_gate0_linear", "=", "self", ".", "forget_gate_linear0", "(", "input", ")", "\n", "forget_gate1_linear", "=", "self", ".", "forget_gate_linear1", "(", "input", ")", "\n", "\n", "sigmoid_input", "=", "forget_gate0_linear", ".", "view", "(", "batch_size", ",", "max_seq_size", ",", "1", ",", "embed_size", ")", ".", "expand", "(", "batch_size", ",", "max_seq_size", ",", "max_seq_size", ",", "embed_size", ")", "+", "forget_gate1_linear", ".", "view", "(", "batch_size", ",", "1", ",", "max_seq_size", ",", "embed_size", ")", ".", "expand", "(", "batch_size", ",", "max_seq_size", ",", "max_seq_size", ",", "embed_size", ")", "\n", "\n", "# batch x max_seq x max_seq x embed", "\n", "forget_gate", "=", "torch", ".", "sigmoid", "(", "sigmoid_input", ")", "\n", "\n", "input_row_expanded", "=", "input", ".", "view", "(", "batch_size", ",", "1", ",", "max_seq_size", ",", "embed_size", ")", ".", "expand", "(", "batch_size", ",", "max_seq_size", ",", "max_seq_size", ",", "embed_size", ")", "\n", "\n", "forget_result", "=", "torch", ".", "mul", "(", "input_row_expanded", ",", "forget_gate", ")", "\n", "\n", "# start_t0 = time.time()", "\n", "selection_mask", "=", "input_masks", ".", "view", "(", "batch_size", ",", "max_seq_size", ",", "1", ")", ".", "mul", "(", "input_masks", ".", "view", "(", "batch_size", ",", "1", ",", "max_seq_size", ")", ")", "\n", "\n", "if", "self", ".", "exclusive_context", ":", "\n", "            ", "eye_matrix_seed", "=", "torch", ".", "eye", "(", "max_seq_size", ")", ".", "byte", "(", ")", "\n", "if", "self", ".", "use_gpu", ":", "\n", "                ", "eye_matrix_seed", "=", "eye_matrix_seed", ".", "to", "(", "device", ")", "\n", "", "eye_matrix", "=", "eye_matrix_seed", ".", "view", "(", "1", ",", "max_seq_size", ",", "max_seq_size", ")", ".", "expand", "(", "batch_size", ",", "max_seq_size", ",", "max_seq_size", ")", "\n", "selection_mask", ".", "masked_fill_", "(", "eye_matrix", ",", "0", ")", "# exclude each word itself", "\n", "context_lengths", "=", "(", "sentence_lengths", "+", "sentence_lengths", ".", "eq", "(", "1", ")", ".", "long", "(", ")", ")", "-", "1", "\n", "", "else", ":", "\n", "            ", "context_lengths", "=", "sentence_lengths", "\n", "\n", "", "selection_mask", "=", "selection_mask", ".", "view", "(", "batch_size", ",", "max_seq_size", ",", "max_seq_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "max_seq_size", ",", "max_seq_size", ",", "self", ".", "feature_dim", ")", "\n", "\n", "# batch x max_seq x max_seq x embed", "\n", "forget_result_masked", "=", "torch", ".", "mul", "(", "forget_result", ",", "selection_mask", ".", "float", "(", ")", ")", "\n", "\n", "# batch x max_seq x embed", "\n", "context_sumup", "=", "torch", ".", "sum", "(", "forget_result_masked", ",", "2", ")", "\n", "\n", "# average", "\n", "context_vector", "=", "torch", ".", "div", "(", "context_sumup", ",", "context_lengths", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", "\n", ".", "expand", "(", "batch_size", ",", "max_seq_size", ",", "self", ".", "feature_dim", ")", ".", "float", "(", ")", ")", "\n", "\n", "output_result", "=", "F", ".", "tanh", "(", "context_vector", ")", "\n", "\n", "return", "output_result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.load_prebuilt_word_embedding": [[13, 39], ["dict", "codecs.open", "len", "line.strip.strip", "line.strip.split", "len", "float", "dict.keys"], "function", ["None"], ["def", "load_prebuilt_word_embedding", "(", "embedding_path", ",", "embedding_dim", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Read prebuilt word embeddings from a file\n    :param embedding_path: string, file path of the word embeddings\n    :param embedding_dim: int, dimensionality of the word embeddings\n    :return: a dictionary mapping each word to its corresponding word embeddings\n    \"\"\"", "\n", "word_embedding_map", "=", "dict", "(", ")", "\n", "\n", "if", "embedding_path", "is", "not", "None", "and", "len", "(", "embedding_path", ")", ">", "0", ":", "\n", "        ", "for", "line", "in", "codecs", ".", "open", "(", "embedding_path", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "word_embedding", "=", "line", ".", "split", "(", ")", "\n", "assert", "len", "(", "word_embedding", ")", "==", "1", "+", "embedding_dim", "\n", "word", "=", "word_embedding", "[", "0", "]", "\n", "embedding", "=", "[", "float", "(", "val", ")", "for", "val", "in", "word_embedding", "[", "1", ":", "]", "]", "\n", "if", "word", "in", "word_embedding_map", ".", "keys", "(", ")", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "word_embedding_map", "[", "word", "]", "=", "embedding", "\n", "\n", "", "", "", "", "return", "word_embedding_map", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping": [[41, 68], ["dict", "dict", "sorted", "sorted", "len", "set", "set", "dict.keys", "dict.items"], "function", ["None"], ["", "def", "create_mapping", "(", "words", ",", "freq_threshold", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Build a lookup table mapping word to its corresponding index\n    :param words: list of string, the list of words, may not be unique at all\n    :param freq_threshold: int, only keep words with the corresponding frequency larger than freq_threshold\n    :return: lookup table\n    \"\"\"", "\n", "\n", "assert", "words", "is", "not", "None", "\n", "\n", "if", "freq_threshold", ">", "1", ":", "\n", "        ", "word_freq", "=", "dict", "(", ")", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "in", "word_freq", ".", "keys", "(", ")", ":", "\n", "                ", "word_freq", "[", "word", "]", "=", "word_freq", "[", "word", "]", "+", "1", "\n", "", "else", ":", "\n", "                ", "word_freq", "[", "word", "]", "=", "1", "\n", "", "", "word_set", "=", "sorted", "(", "set", "(", "[", "k", "for", "k", ",", "v", "in", "word_freq", ".", "items", "(", ")", "if", "v", ">=", "freq_threshold", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "word_set", "=", "sorted", "(", "set", "(", "words", ")", ")", "\n", "\n", "", "lookup_table", "=", "dict", "(", ")", "\n", "for", "word", "in", "word_set", ":", "\n", "        ", "lookup_table", "[", "word", "]", "=", "len", "(", "lookup_table", ")", "\n", "\n", "", "return", "lookup_table", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping_tags": [[70, 87], ["data_processing.create_mapping", "any", "dict", "Exception", "len", "len", "create_mapping.keys", "create_mapping.items"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping"], ["", "def", "create_mapping_tags", "(", "tags", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Build up the lookup tables for all tags\n    :param tags: list of string, all tags\n    :return: the tag_to_id and the id_to_tag lookup tables\n    \"\"\"", "\n", "tag_to_id", "=", "create_mapping", "(", "tags", ")", "\n", "if", "any", "(", "x", "in", "tag_to_id", ".", "keys", "(", ")", "for", "x", "in", "[", "Constants", ".", "Tag_End", ",", "Constants", ".", "Tag_Start", "]", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Error: <START> or <END> cannot appear in the tag set\"", ")", "\n", "", "else", ":", "\n", "        ", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", "=", "len", "(", "tag_to_id", ")", "\n", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", "=", "len", "(", "tag_to_id", ")", "\n", "\n", "", "id_to_tag", "=", "dict", "(", "[", "(", "v", ",", "k", ")", "for", "k", ",", "v", "in", "tag_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n", "return", "tag_to_id", ",", "id_to_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping_words": [[89, 121], ["data_processing.create_mapping", "dict", "any", "dict", "data_processing.load_prebuilt_word_embedding", "sorted", "Exception", "len", "len", "len", "load_prebuilt_word_embedding.keys", "word.lower", "create_mapping.keys", "len", "create_mapping.keys", "create_mapping.items"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.load_prebuilt_word_embedding"], ["", "def", "create_mapping_words", "(", "words", ",", "embedding_path", ",", "embedding_dim", ",", "to_lower", "=", "False", ",", "freq_threshold", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Build up the lookup tables for all words\n    :param words: list of string, all words\n    :param embedding_path: string, file path for loading prebuilt word embeddings\n    :param embedding_dim: int, dimensionality of the word embeddings\n    :param to_lower: bool, invoke lower() or not\n    :param freq_threshold: int, only keep words with the frequency larger than freq_threshold\n    :return: the word_to_id and the id_to_word lookup tables\n    \"\"\"", "\n", "\n", "word_to_id", "=", "create_mapping", "(", "words", ",", "freq_threshold", ")", "\n", "prebuilt_word_embedding", "=", "dict", "(", ")", "\n", "\n", "if", "embedding_path", "is", "not", "None", "and", "len", "(", "embedding_path", ")", ">", "0", ":", "\n", "        ", "prebuilt_word_embedding", "=", "load_prebuilt_word_embedding", "(", "embedding_path", ",", "embedding_dim", ")", "\n", "sorted_prebuilt_words", "=", "sorted", "(", "prebuilt_word_embedding", ".", "keys", "(", ")", ")", "\n", "for", "word", "in", "sorted_prebuilt_words", ":", "\n", "            ", "word", "=", "word", ".", "lower", "(", ")", "if", "to_lower", "else", "word", "\n", "if", "word", "not", "in", "word_to_id", ".", "keys", "(", ")", ":", "\n", "                ", "word_to_id", "[", "word", "]", "=", "len", "(", "word_to_id", ")", "\n", "\n", "", "", "", "if", "any", "(", "x", "in", "word_to_id", ".", "keys", "(", ")", "for", "x", "in", "[", "Constants", ".", "Word_Pad", ",", "Constants", ".", "Word_Unknown", "]", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Error: <PAD> or <UNK> cannot appear in the word set\"", ")", "\n", "", "else", ":", "\n", "        ", "word_to_id", "[", "Constants", ".", "Word_Unknown", "]", "=", "len", "(", "word_to_id", ")", "\n", "word_to_id", "[", "Constants", ".", "Word_Pad", "]", "=", "len", "(", "word_to_id", ")", "\n", "\n", "", "id_to_word", "=", "dict", "(", "[", "(", "v", ",", "k", ")", "for", "k", ",", "v", "in", "word_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n", "return", "word_to_id", ",", "id_to_word", ",", "prebuilt_word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping_chars": [[123, 140], ["data_processing.create_mapping", "any", "dict", "Exception", "len", "len", "create_mapping.keys", "create_mapping.items"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping"], ["", "def", "create_mapping_chars", "(", "chars", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Build up the lookup tables for all characters\n    :param chars: list of string, all characters\n    :return: the char_to_id and the id_to_char lookup tables\n    \"\"\"", "\n", "char_to_id", "=", "create_mapping", "(", "chars", ")", "\n", "if", "any", "(", "x", "in", "char_to_id", ".", "keys", "(", ")", "for", "x", "in", "[", "Constants", ".", "Char_Pad", ",", "Constants", ".", "Char_Unknown", "]", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Error: <C_PAD> or <C_UNK> cannot appear in the char set\"", ")", "\n", "", "else", ":", "\n", "        ", "char_to_id", "[", "Constants", ".", "Char_Unknown", "]", "=", "len", "(", "char_to_id", ")", "\n", "char_to_id", "[", "Constants", ".", "Char_Pad", "]", "=", "len", "(", "char_to_id", ")", "\n", "\n", "", "id_to_char", "=", "dict", "(", "[", "(", "v", ",", "k", ")", "for", "k", ",", "v", "in", "char_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n", "return", "char_to_id", ",", "id_to_char", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.load_dataset_conll": [[142, 187], ["codecs.open", "enumerate", "line.strip.strip", "sentences.append", "tags.append", "len", "len", "len", "data_format_util.iob1_to_iob2", "line.strip.split", "sentence.append", "data_format_util.iob2_to_iobes.append", "len", "Exception", "sentences.append", "tags.append", "len", "data_format_util.iob2_to_iobes", "len", "data_format_util.digit_to_zero"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.iob1_to_iob2", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.iob2_to_iobes", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.digit_to_zero"], ["", "def", "load_dataset_conll", "(", "data_file", ",", "label_schema", "=", "LabellingSchema", ".", "IOBES", ",", "digits_to_zeros", "=", "False", ",", "remove_doc_start", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Read sentences from a CoNLL format data file\n    :param data_file: string, path of the data set\n    :param label_schema: enum of LabellingSchema, the labelling scheme\n    :param digits_to_zeros: bool, transfer all digits into zeros\n    :return: sentences of the dataset, with each sentence containing word_tag pairs\n    \"\"\"", "\n", "# read the data file", "\n", "sentences", "=", "[", "]", "\n", "tags", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "sentence_tag", "=", "[", "]", "\n", "for", "line", "in", "codecs", ".", "open", "(", "data_file", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "not", "line", ":", "\n", "            ", "if", "len", "(", "sentence", ")", ">", "0", "and", "(", "(", "not", "remove_doc_start", ")", "or", "(", "\"DOCSTART\"", "not", "in", "sentence", "[", "0", "]", ")", ")", ":", "\n", "                ", "sentences", ".", "append", "(", "sentence", ")", "\n", "tags", ".", "append", "(", "sentence_tag", ")", "\n", "", "sentence", "=", "[", "]", "\n", "sentence_tag", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "words", "=", "line", ".", "split", "(", ")", "\n", "assert", "len", "(", "words", ")", ">=", "2", "\n", "sentence", ".", "append", "(", "digit_to_zero", "(", "words", "[", "0", "]", ")", "if", "digits_to_zeros", "else", "words", "[", "0", "]", ")", "\n", "sentence_tag", ".", "append", "(", "words", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "len", "(", "sentence", ")", ">", "0", "and", "(", "(", "not", "remove_doc_start", ")", "or", "(", "\"DOCSTART\"", "not", "in", "sentence", "[", "0", "]", ")", ")", ":", "\n", "        ", "sentences", ".", "append", "(", "sentence", ")", "\n", "tags", ".", "append", "(", "sentence_tag", ")", "\n", "\n", "", "assert", "len", "(", "sentences", ")", ">", "0", "\n", "assert", "len", "(", "sentences", ")", "==", "len", "(", "tags", ")", "\n", "\n", "# from IOB1 => IOB2 => IOBES", "\n", "for", "i", ",", "sentence_tag", "in", "enumerate", "(", "tags", ")", ":", "\n", "        ", "if", "iob1_to_iob2", "(", "sentence_tag", ")", ":", "\n", "            ", "if", "label_schema", "==", "LabellingSchema", ".", "IOBES", ":", "\n", "                ", "sentence_tag", "=", "iob2_to_iobes", "(", "sentence_tag", ")", "\n", "", "tags", "[", "i", "]", "=", "sentence_tag", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Error: the input dataset is not in IOB format\"", ")", "\n", "\n", "", "", "return", "sentences", ",", "tags", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping_dataset_conll": [[189, 260], ["isinstance", "range", "data_processing.create_mapping_tags", "data_processing.create_mapping_words", "data_processing.create_mapping_chars", "len", "data_processing.load_dataset_conll", "all_sentences.extend", "all_sentence_tags.extend", "len", "len", "len", "words.extend", "tags.extend", "enumerate", "len", "len", "chars.extend", "len", "word.lower", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping_tags", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping_words", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.create_mapping_chars", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.load_dataset_conll"], ["", "def", "create_mapping_dataset_conll", "(", "data_paths", ",", "\n", "word_embedding_path", ",", "\n", "word_embedding_dim", ",", "\n", "label_schema", "=", "LabellingSchema", ".", "IOBES", ",", "\n", "word_to_lower", "=", "False", ",", "\n", "word_freq_threshold", "=", "1", ",", "\n", "digits_to_zeros", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Build the mapping for words/tags/chars for a given list of datasets\n    :param data_paths: list of string, file paths of to-be-processed dataset\n    :param word_embedding_path: string, file path for the prebuilt word embedding\n    :param word_embedding_dim: int, dimensionality of the prebuilt word embedding\n    :param label_schema: LabellingSchema, labelling scheme for the dataset\n    :param word_to_lower: bool, transform all words to lower case or not\n    :param word_freq_threshold: int, only keep words with the corresponding frequency larger than word_freq_threshold\n    :param digits_to_zeros: bool, transfer all digits into zeros\n    :return: a mapping dictionary containing tag_to_id, id_to_tag, word_to_id, id_to_word, char_to_id, id_to_char\n            and also the prebuilt word embedding dictionary\n    \"\"\"", "\n", "assert", "isinstance", "(", "data_paths", ",", "list", ")", "\n", "assert", "len", "(", "data_paths", ")", ">", "0", "\n", "\n", "all_sentences", "=", "[", "]", "\n", "all_sentence_tags", "=", "[", "]", "\n", "for", "data_path", "in", "data_paths", ":", "\n", "        ", "dataset_sentences", ",", "dataset_tags", "=", "load_dataset_conll", "(", "data_path", ",", "label_schema", ",", "digits_to_zeros", ")", "\n", "all_sentences", ".", "extend", "(", "dataset_sentences", ")", "\n", "all_sentence_tags", ".", "extend", "(", "dataset_tags", ")", "\n", "\n", "", "assert", "len", "(", "all_sentences", ")", "==", "len", "(", "all_sentence_tags", ")", "\n", "\n", "tags", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "chars", "=", "[", "]", "\n", "max_word_length", "=", "0", "\n", "for", "i_sentence", "in", "range", "(", "len", "(", "all_sentences", ")", ")", ":", "\n", "        ", "sentence_words", "=", "all_sentences", "[", "i_sentence", "]", "\n", "sentence_tags", "=", "all_sentence_tags", "[", "i_sentence", "]", "\n", "\n", "assert", "len", "(", "sentence_words", ")", "==", "len", "(", "sentence_tags", ")", "\n", "\n", "words", ".", "extend", "(", "[", "word", ".", "lower", "(", ")", "if", "word_to_lower", "else", "word", "for", "word", "in", "sentence_words", "]", ")", "\n", "tags", ".", "extend", "(", "sentence_tags", ")", "\n", "for", "wi", ",", "sentence_word", "in", "enumerate", "(", "sentence_words", ")", ":", "\n", "            ", "sentence_word_chars", "=", "[", "c", "for", "c", "in", "sentence_word", "]", "\n", "chars", ".", "extend", "(", "sentence_word_chars", ")", "\n", "max_word_length", "=", "max_word_length", "if", "max_word_length", ">=", "len", "(", "sentence_word_chars", ")", "else", "len", "(", "sentence_word_chars", ")", "\n", "\n", "", "", "tag_to_id", ",", "id_to_tag", "=", "create_mapping_tags", "(", "tags", ")", "\n", "word_to_id", ",", "id_to_word", ",", "prebuilt_word_embedding", "=", "create_mapping_words", "(", "words", ",", "\n", "word_embedding_path", ",", "\n", "word_embedding_dim", ",", "\n", "word_to_lower", ",", "\n", "word_freq_threshold", ")", "\n", "char_to_id", ",", "id_to_char", "=", "create_mapping_chars", "(", "chars", ")", "\n", "\n", "mappings", "=", "{", "\n", "\"tag_to_id\"", ":", "tag_to_id", ",", "\n", "\"id_to_tag\"", ":", "id_to_tag", ",", "\n", "\"word_to_id\"", ":", "word_to_id", ",", "\n", "\"id_to_word\"", ":", "id_to_word", ",", "\n", "\"char_to_id\"", ":", "char_to_id", ",", "\n", "\"id_to_char\"", ":", "id_to_char", ",", "\n", "\"max_word_length\"", ":", "max_word_length", ",", "\n", "\"word_to_lower\"", ":", "word_to_lower", ",", "\n", "\"digits_to_zeros\"", ":", "digits_to_zeros", ",", "\n", "\"label_schema\"", ":", "label_schema", "\n", "}", "\n", "\n", "return", "mappings", ",", "prebuilt_word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.pad_word_chars": [[262, 283], ["max", "char_for.append", "char_rev.append", "char_pos.append", "len", "len", "len"], "function", ["None"], ["", "def", "pad_word_chars", "(", "words", ",", "char_pad_id", ")", ":", "\n", "    ", "\"\"\"\n    Pad the characters of the words in a sentence.\n    Input:\n        :param words: list of list of int, char ids of all words in the sentence\n        :param char_pad_id: int, id of Char_Pad\n    Output:\n        - padded list of lists of ints\n        - padded list of lists of ints (where chars are reversed)\n        - list of ints corresponding to the index of the last character of each word\n    \"\"\"", "\n", "max_length", "=", "max", "(", "[", "len", "(", "word", ")", "for", "word", "in", "words", "]", ")", "\n", "char_for", "=", "[", "]", "\n", "char_rev", "=", "[", "]", "\n", "char_pos", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "        ", "padding", "=", "[", "char_pad_id", "]", "*", "(", "max_length", "-", "len", "(", "word", ")", ")", "\n", "char_for", ".", "append", "(", "word", "+", "padding", ")", "\n", "char_rev", ".", "append", "(", "word", "[", ":", ":", "-", "1", "]", "+", "padding", ")", "\n", "char_pos", ".", "append", "(", "len", "(", "word", ")", "-", "1", ")", "\n", "", "return", "char_for", ",", "char_rev", ",", "char_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.generate_mini_batch_input": [[285, 364], ["sorted", "max", "max", "enumerate", "dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "unaligned_tags.append", "len", "_words.extend", "_tags.extend", "sentence_char_lengths.extend", "chars_positions.extend", "_mask.extend", "sentence_masks.append", "words.append", "tags.append", "chars.extend", "str_words.append", "zip", "sorted", "zip", "word_chars.extend", "len", "max", "_tags.copy", "len", "len", "range", "range", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "generate_mini_batch_input", "(", "data_loader_conll", ",", "mini_batch_idx", ",", "mappings", ",", "char_mode", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Pack a mini-batch into tensors\n    :param data_loader_conll: DataLoaderConLL, the given data loader\n    :param mini_batch_idx: list, indecies of the samples in the training set\n    :param mappings: dict, a mapping dictionary containing tag_to_id, id_to_tag, word_to_id, id_to_word, char_to_id, id_to_char\n    :param char_mode: CharEmbeddingSchema, char embedding type, in [LSTM, CNN]\n    :return: a dict containing masks, tags, words, and chars\n    \"\"\"", "\n", "sentences", "=", "[", "data_loader_conll", "[", "idx", "]", "for", "idx", "in", "mini_batch_idx", "]", "\n", "sentences", "=", "sorted", "(", "sentences", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "\"words\"", "]", ")", ",", "reverse", "=", "True", ")", "# longest sentence must be the first", "\n", "max_sentence_length", "=", "max", "(", "[", "len", "(", "sentence", "[", "\"words\"", "]", ")", "for", "sentence", "in", "sentences", "]", ")", "\n", "max_word_length", "=", "max", "(", "[", "max", "(", "len", "(", "tmp_chars", ")", "for", "tmp_chars", "in", "sentence", "[", "\"chars\"", "]", ")", "for", "sentence", "in", "sentences", "]", ")", "\n", "\n", "assert", "max_sentence_length", ">", "0", "\n", "assert", "len", "(", "sentences", ")", ">", "0", "\n", "assert", "max_word_length", ">", "0", "\n", "\n", "tag_to_id", "=", "mappings", "[", "\"tag_to_id\"", "]", "\n", "word_to_id", "=", "mappings", "[", "\"word_to_id\"", "]", "\n", "char_to_id", "=", "mappings", "[", "\"char_to_id\"", "]", "\n", "\n", "sentence_masks", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "sentence_char_lengths", "=", "[", "]", "\n", "chars", "=", "[", "]", "\n", "chars_positions", "=", "[", "]", "\n", "tags", "=", "[", "]", "\n", "str_words", "=", "[", "]", "\n", "unaligned_tags", "=", "[", "]", "\n", "\n", "for", "si", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "_words", "=", "sentence", "[", "\"words\"", "]", "\n", "_chars", "=", "sentence", "[", "\"chars\"", "]", "\n", "_tags", "=", "sentence", "[", "\"tags\"", "]", "\n", "_str_words", "=", "sentence", "[", "\"str_words\"", "]", "\n", "unaligned_tags", ".", "append", "(", "_tags", ".", "copy", "(", ")", ")", "\n", "\n", "length", "=", "len", "(", "_words", ")", "\n", "pad_word_num", "=", "max_sentence_length", "-", "length", "\n", "\n", "_words", ".", "extend", "(", "[", "word_to_id", "[", "Constants", ".", "Word_Pad", "]", "]", "*", "pad_word_num", ")", "\n", "_tags", ".", "extend", "(", "[", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", "]", "*", "pad_word_num", ")", "\n", "\n", "char_lengths", "=", "[", "len", "(", "tmp_chars", ")", "for", "tmp_chars", "in", "_chars", "]", "\n", "sentence_char_lengths", ".", "extend", "(", "char_lengths", ")", "\n", "\n", "_chars_positions", "=", "[", "(", "si", ",", "wi", ")", "for", "wi", "in", "range", "(", "len", "(", "_chars", ")", ")", "]", "\n", "chars_positions", ".", "extend", "(", "_chars_positions", ")", "\n", "\n", "_mask", "=", "[", "1", "]", "*", "length", "\n", "_mask", ".", "extend", "(", "[", "0", "]", "*", "pad_word_num", ")", "\n", "\n", "sentence_masks", ".", "append", "(", "_mask", ")", "\n", "words", ".", "append", "(", "_words", ")", "\n", "tags", ".", "append", "(", "_tags", ")", "\n", "chars", ".", "extend", "(", "_chars", ")", "\n", "str_words", ".", "append", "(", "_str_words", ")", "\n", "\n", "", "sentence_char_position_map", "=", "{", "}", "\n", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "LSTM", ":", "\n", "# rank by the word length in a descending order", "\n", "        ", "chars_with_positions", "=", "zip", "(", "chars", ",", "chars_positions", ",", "sentence_char_lengths", ")", "\n", "sorted_chars_with_positions", "=", "sorted", "(", "chars_with_positions", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "chars", ",", "chars_positions", ",", "sentence_char_lengths", "=", "zip", "(", "*", "sorted_chars_with_positions", ")", "\n", "\n", "", "sentence_char_position_map", "=", "dict", "(", "[", "(", "j", ",", "chars_positions", "[", "j", "]", ")", "for", "j", "in", "range", "(", "len", "(", "chars_positions", ")", ")", "]", ")", "\n", "for", "word_chars", "in", "chars", ":", "\n", "        ", "word_chars", ".", "extend", "(", "[", "char_to_id", "[", "Constants", ".", "Char_Pad", "]", "]", "*", "(", "max_word_length", "-", "len", "(", "word_chars", ")", ")", ")", "\n", "\n", "", "sentence_masks_tensor", "=", "torch", ".", "tensor", "(", "sentence_masks", ",", "requires_grad", "=", "False", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "words_tensor", "=", "torch", ".", "tensor", "(", "words", ",", "requires_grad", "=", "False", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "chars_tensor", "=", "torch", ".", "tensor", "(", "chars", ",", "requires_grad", "=", "False", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "tags_tensor", "=", "torch", ".", "tensor", "(", "tags", ",", "requires_grad", "=", "False", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "sentence_char_lengths_tensor", "=", "torch", ".", "tensor", "(", "sentence_char_lengths", ",", "requires_grad", "=", "False", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "sentence_masks_tensor", ",", "words_tensor", ",", "chars_tensor", ",", "tags_tensor", ",", "sentence_char_lengths_tensor", ",", "sentence_char_position_map", ",", "str_words", ",", "unaligned_tags", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.function_util.log_sum_exp": [[4, 21], ["torch.max", "torch.where", "torch.where.squeeze", "torch.where.view", "torch.log", "float", "float", "torch.sum", "torch.exp"], "function", ["None"], ["def", "log_sum_exp", "(", "x", ",", "dim", "=", "None", ",", "keepdim", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Calculate the log of the sum of the exponential of x, along dimension \"dim\"\n    :param x: tensor\n    :param dim: int, dimension index\n    :param keepdim: bool, keep the size or not\n    :return: log of the sum of the exponential of x, along dimension \"dim\"\n    \"\"\"", "\n", "if", "dim", "is", "None", ":", "\n", "        ", "x", ",", "dim", "=", "x", ".", "view", "(", "-", "1", ")", ",", "0", "\n", "", "xm", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "dim", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "torch", ".", "where", "(", "\n", "(", "xm", "==", "float", "(", "'inf'", ")", ")", "|", "(", "xm", "==", "float", "(", "'-inf'", ")", ")", ",", "\n", "xm", ",", "\n", "xm", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "x", "-", "xm", ")", ",", "dim", ",", "keepdim", "=", "True", ")", ")", ")", "\n", "return", "x", "if", "keepdim", "else", "x", ".", "squeeze", "(", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.inception.InceptionCNN.__init__": [[6, 26], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", "=", "1", ",", "out_channels", "=", "400", ",", "kernel_dim", "=", "400", ",", "inception_mode", "=", "1", ")", ":", "\n", "# checked", "\n", "        ", "super", "(", "InceptionCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_dim", "=", "kernel_dim", "\n", "self", ".", "inception_mode", "=", "inception_mode", "\n", "\n", "if", "self", ".", "inception_mode", "==", "1", ":", "\n", "            ", "self", ".", "conv_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "in_channels", ",", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "kernel_size", "=", "(", "1", ",", "self", ".", "kernel_dim", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ")", "\n", "self", ".", "conv_3", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "in_channels", ",", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "kernel_size", "=", "(", "3", ",", "self", ".", "kernel_dim", ")", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", "self", ".", "conv_5", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "in_channels", ",", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "kernel_size", "=", "(", "5", ",", "self", ".", "kernel_dim", ")", ",", "padding", "=", "(", "2", ",", "0", ")", ")", "\n", "# self.linear = nn.Linear(in_features=self.out_channels*3, out_features=self.out_channels)", "\n", "", "elif", "self", ".", "inception_mode", "==", "2", ":", "\n", "            ", "self", ".", "conv_3", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "in_channels", ",", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "kernel_size", "=", "(", "3", ",", "self", ".", "kernel_dim", ")", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.inception.InceptionCNN.forward": [[27, 64], ["input.size", "input.unsqueeze", "torch.max_pool2d.squeeze().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.max_pool2d.squeeze", "inception.InceptionCNN.conv_1", "inception.InceptionCNN.conv_3", "inception.InceptionCNN.conv_5", "torch.tanh", "torch.tanh", "torch.tanh", "torch.cat.size", "torch.cat.size", "torch.cat.size", "inception.InceptionCNN.conv_3"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# checked", "\n", "        ", "if", "self", ".", "inception_mode", "==", "0", ":", "\n", "            ", "return", "input", "\n", "\n", "", "batch_size", ",", "max_seq", ",", "word_embed_size", "=", "input", ".", "size", "(", ")", "\n", "\n", "# batch x 1 x max_seq x word_embed", "\n", "input_", "=", "input", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# batch x out x max_seq x 1", "\n", "if", "self", ".", "inception_mode", "==", "1", ":", "\n", "            ", "input_1", "=", "F", ".", "tanh", "(", "self", ".", "conv_1", "(", "input_", ")", ")", "[", ":", ",", ":", ",", ":", "max_seq", ",", ":", "]", "\n", "input_3", "=", "F", ".", "tanh", "(", "self", ".", "conv_3", "(", "input_", ")", ")", "[", ":", ",", ":", ",", ":", "max_seq", ",", ":", "]", "\n", "input_5", "=", "F", ".", "tanh", "(", "self", ".", "conv_5", "(", "input_", ")", ")", "[", ":", ",", ":", ",", ":", "max_seq", ",", ":", "]", "\n", "\n", "# # batch x (3*out) x max_seq --> batch x max_seq x (3*out)", "\n", "# linear_input = torch.cat([input_1.squeeze(3), input_3.squeeze(3), input_5.squeeze(3)], 1).transpose(1, 2)", "\n", "# # batch x max_seq x out", "\n", "# output = self.linear(linear_input)", "\n", "\n", "# batch x max_seq x out", "\n", "# output = (input_1 + input_3 + input_5).squeeze(3).transpose(1, 2)", "\n", "\n", "# batch x out_channels x max_seq x 3", "\n", "pooling_input", "=", "torch", ".", "cat", "(", "[", "input_1", ",", "input_3", ",", "input_5", "]", ",", "3", ")", "\n", "# batch x out_channels x max_seq x 1", "\n", "output", "=", "F", ".", "max_pool2d", "(", "pooling_input", ",", "kernel_size", "=", "(", "1", ",", "pooling_input", ".", "size", "(", "3", ")", ")", ")", "\n", "", "elif", "self", ".", "inception_mode", "==", "2", ":", "\n", "            ", "output", "=", "F", ".", "tanh", "(", "self", ".", "conv_3", "(", "input_", ")", ")", "[", ":", ",", ":", ",", ":", "max_seq", ",", ":", "]", "\n", "\n", "# batch x out x max_seq -> batch x max_seq x out", "\n", "", "output", "=", "output", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "#assert output.size() == input.size()", "\n", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.digit_to_zero": [[3, 9], ["re.sub"], "function", ["None"], ["def", "digit_to_zero", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Replace every digit in a string by a zero.\n    \"\"\"", "\n", "return", "re", ".", "sub", "(", "'\\d'", ",", "'0'", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.iob1_to_iob2": [[10, 31], ["enumerate", "tag.split", "len"], "function", ["None"], ["", "def", "iob1_to_iob2", "(", "tags", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Check that tags have a valid IOB or IOB2/BIO format.\n    Tags in IOB1 format are converted to IOB2.\n    \"\"\"", "\n", "for", "i", ",", "tag", "in", "enumerate", "(", "tags", ")", ":", "\n", "        ", "if", "tag", "==", "'O'", ":", "\n", "            ", "continue", "\n", "", "split", "=", "tag", ".", "split", "(", "'-'", ")", "\n", "if", "len", "(", "split", ")", "!=", "2", "or", "split", "[", "0", "]", "not", "in", "[", "'I'", ",", "'B'", "]", ":", "\n", "            ", "return", "False", "\n", "", "if", "split", "[", "0", "]", "==", "'B'", ":", "\n", "            ", "continue", "\n", "", "elif", "i", "==", "0", "or", "tags", "[", "i", "-", "1", "]", "==", "'O'", ":", "# conversion IOB1 to IOB2", "\n", "            ", "tags", "[", "i", "]", "=", "'B'", "+", "tag", "[", "1", ":", "]", "\n", "", "elif", "tags", "[", "i", "-", "1", "]", "[", "1", ":", "]", "==", "tag", "[", "1", ":", "]", ":", "\n", "            ", "continue", "\n", "", "else", ":", "# conversion IOB1 to IOB2", "\n", "            ", "tags", "[", "i", "]", "=", "'B'", "+", "tag", "[", "1", ":", "]", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.iob2_to_iobes": [[33, 57], ["enumerate", "new_tags.append", "tag.split", "new_tags.append", "new_tags.append", "Exception", "len", "tag.replace", "tag.split", "new_tags.append", "new_tags.append", "tags[].split", "len", "tag.replace", "tags[].split"], "function", ["None"], ["", "def", "iob2_to_iobes", "(", "tags", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    IOB2 -> IOBES\n    \"\"\"", "\n", "new_tags", "=", "[", "]", "\n", "for", "i", ",", "tag", "in", "enumerate", "(", "tags", ")", ":", "\n", "        ", "if", "tag", "==", "'O'", ":", "\n", "            ", "new_tags", ".", "append", "(", "tag", ")", "\n", "", "elif", "tag", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'B'", ":", "\n", "            ", "if", "i", "+", "1", "!=", "len", "(", "tags", ")", "and", "tags", "[", "i", "+", "1", "]", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'I'", ":", "\n", "                ", "new_tags", ".", "append", "(", "tag", ")", "\n", "", "else", ":", "\n", "                ", "new_tags", ".", "append", "(", "tag", ".", "replace", "(", "'B-'", ",", "'S-'", ")", ")", "\n", "", "", "elif", "tag", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'I'", ":", "\n", "            ", "if", "i", "+", "1", "<", "len", "(", "tags", ")", "and", "tags", "[", "i", "+", "1", "]", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'I'", ":", "\n", "                ", "new_tags", ".", "append", "(", "tag", ")", "\n", "", "else", ":", "\n", "                ", "new_tags", ".", "append", "(", "tag", ".", "replace", "(", "'I-'", ",", "'E-'", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Invalid IOB format!'", ")", "\n", "", "", "return", "new_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.iobes_to_iob2": [[59, 79], ["enumerate", "new_tags.append", "tag.split", "new_tags.append", "tag.split", "new_tags.append", "tag.split", "tag.replace", "new_tags.append", "tag.split", "tag.replace", "new_tags.append", "Exception", "tag.split"], "function", ["None"], ["", "def", "iobes_to_iob2", "(", "tags", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    IOBES -> IOB2\n    \"\"\"", "\n", "new_tags", "=", "[", "]", "\n", "for", "i", ",", "tag", "in", "enumerate", "(", "tags", ")", ":", "\n", "        ", "if", "tag", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'B'", ":", "\n", "            ", "new_tags", ".", "append", "(", "tag", ")", "\n", "", "elif", "tag", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'I'", ":", "\n", "            ", "new_tags", ".", "append", "(", "tag", ")", "\n", "", "elif", "tag", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'S'", ":", "\n", "            ", "new_tags", ".", "append", "(", "tag", ".", "replace", "(", "'S-'", ",", "'B-'", ")", ")", "\n", "", "elif", "tag", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'E'", ":", "\n", "            ", "new_tags", ".", "append", "(", "tag", ".", "replace", "(", "'E-'", ",", "'I-'", ")", ")", "\n", "", "elif", "tag", ".", "split", "(", "'-'", ")", "[", "0", "]", "==", "'O'", ":", "\n", "            ", "new_tags", ".", "append", "(", "tag", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Invalid format!'", ")", "\n", "", "", "return", "new_tags", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF.__init__": [[15, 94], ["torch.Module.__init__", "len", "print", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "inception.InceptionCNN", "torch.Linear", "torch.Linear", "torch.Linear", "utils.init_linear_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "utils.init_embedding_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "utils.init_cnn_", "utils.init_cnn_", "utils.init_cnn_", "context.ContextLayer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "len", "torch.LSTM", "torch.LSTM", "torch.LSTM", "utils.init_lstm_", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "utils.init_cnn_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "utils.init_cnn_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_embedding_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_cnn_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_cnn_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_cnn_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_lstm_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_cnn_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_cnn_"], ["    ", "def", "__init__", "(", "self", ",", "word_set_size", ",", "tag_to_id", ",", "word_embedding_dim", ",", "word_lstm_dim", ",", "word_lstm_bidirect", "=", "True", ",", "\n", "pre_word_embeds", "=", "None", ",", "char_embedding_dim", "=", "25", ",", "char_mode", "=", "CharEmbeddingSchema", ".", "CNN", ",", "\n", "char_lstm_dim", "=", "25", ",", "char_lstm_bidirect", "=", "True", ",", "char_cnn_win", "=", "3", ",", "char_cnn_output", "=", "25", ",", "\n", "char_to_id", "=", "None", ",", "use_gpu", "=", "False", ",", "dropout", "=", "0.5", ",", "use_crf", "=", "True", ",", "char_embed_dropout", "=", "False", ",", "\n", "inception_mode", "=", "1", ",", "enable_context", "=", "True", ")", ":", "\n", "# checked", "\n", "        ", "super", "(", "GRN_CRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_set_size", "=", "word_set_size", "\n", "self", ".", "tag_to_id", "=", "tag_to_id", "\n", "self", ".", "word_embedding_dim", "=", "word_embedding_dim", "\n", "self", ".", "word_lstm_dim", "=", "word_lstm_dim", "\n", "self", ".", "word_lstm_bidirect", "=", "word_lstm_bidirect", "\n", "self", ".", "char_embedding_dim", "=", "char_embedding_dim", "\n", "self", ".", "char_mode", "=", "char_mode", "\n", "self", ".", "char_lstm_dim", "=", "char_lstm_dim", "\n", "self", ".", "char_lstm_bidirect", "=", "char_lstm_bidirect", "\n", "self", ".", "char_cnn_win", "=", "char_cnn_win", "\n", "self", ".", "char_cnn_output", "=", "char_cnn_output", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "use_crf", "=", "use_crf", "\n", "self", ".", "tag_set_size", "=", "len", "(", "tag_to_id", ")", "\n", "self", ".", "char_embed_dropout", "=", "char_embed_dropout", "\n", "self", ".", "inception_mode", "=", "inception_mode", "\n", "self", ".", "enable_context", "=", "enable_context", "\n", "\n", "print", "(", "'char_mode: {0}, char_embedding_out: {1}, word_hidden_dim: {2}'", ".", "format", "\n", "(", "char_mode", ",", "char_cnn_output", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "CNN", "else", "\n", "(", "char_lstm_dim", "*", "(", "2", "if", "char_lstm_bidirect", "else", "1", ")", ")", ",", "\n", "word_lstm_dim", "*", "(", "2", "if", "word_lstm_bidirect", "else", "1", ")", ")", ")", "\n", "\n", "if", "char_embedding_dim", "is", "not", "None", ":", "\n", "            ", "self", ".", "char_embeds", "=", "nn", ".", "Embedding", "(", "len", "(", "char_to_id", ")", ",", "char_embedding_dim", ")", "\n", "init_embedding_", "(", "self", ".", "char_embeds", ")", "\n", "\n", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "LSTM", ":", "\n", "                ", "self", ".", "char_lstm", "=", "nn", ".", "LSTM", "(", "char_embedding_dim", ",", "char_lstm_dim", ",", "num_layers", "=", "1", ",", "\n", "bidirectional", "=", "char_lstm_bidirect", ",", "batch_first", "=", "True", ")", "\n", "init_lstm_", "(", "self", ".", "char_lstm", ")", "\n", "", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "CNN", ":", "\n", "                ", "self", ".", "char_cnn", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "char_cnn_output", ",", "\n", "kernel_size", "=", "(", "char_cnn_win", ",", "char_embedding_dim", ")", ",", "\n", "padding", "=", "(", "char_cnn_win", "//", "2", ",", "0", ")", ")", "\n", "init_cnn_", "(", "self", ".", "char_cnn", ")", "\n", "\n", "", "", "self", ".", "word_embeds", "=", "nn", ".", "Embedding", "(", "word_set_size", ",", "word_embedding_dim", ")", "\n", "if", "pre_word_embeds", "is", "not", "None", ":", "\n", "            ", "self", ".", "pre_word_embeds", "=", "True", "\n", "self", ".", "word_embeds", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "pre_word_embeds", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pre_word_embeds", "=", "False", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "cnn_input_dim", "=", "(", "word_embedding_dim", "+", "char_lstm_dim", "*", "(", "2", "if", "char_lstm_bidirect", "else", "1", ")", ")", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "LSTM", "else", "(", "word_embedding_dim", "+", "char_cnn_output", ")", "\n", "cnn_output_dim", "=", "word_lstm_dim", "*", "(", "2", "if", "word_lstm_bidirect", "else", "1", ")", "\n", "self", ".", "inception_cnn", "=", "InceptionCNN", "(", "in_channels", "=", "1", ",", "out_channels", "=", "cnn_output_dim", ",", "kernel_dim", "=", "cnn_input_dim", ",", "inception_mode", "=", "self", ".", "inception_mode", ")", "\n", "\n", "if", "self", ".", "inception_mode", "==", "1", ":", "\n", "            ", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_1", ")", "\n", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_3", ")", "\n", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_5", ")", "\n", "", "elif", "self", ".", "inception_mode", "==", "2", ":", "\n", "            ", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_3", ")", "\n", "", "elif", "self", ".", "inception_mode", "==", "0", ":", "\n", "            ", "cnn_output_dim", "=", "cnn_input_dim", "\n", "\n", "", "if", "self", ".", "enable_context", ":", "\n", "            ", "self", ".", "context_layer1", "=", "ContextLayer", "(", "cnn_output_dim", ",", "False", ",", "use_gpu", ")", "\n", "\n", "", "self", ".", "hidden2tag", "=", "nn", ".", "Linear", "(", "cnn_output_dim", ",", "self", ".", "tag_set_size", ")", "\n", "init_linear_", "(", "self", ".", "hidden2tag", ")", "\n", "\n", "if", "use_crf", ":", "\n", "            ", "self", ".", "transitions", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "tag_set_size", ",", "self", ".", "tag_set_size", ")", ")", "\n", "self", ".", "transitions", ".", "data", "[", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", ",", ":", "]", "=", "Constants", ".", "Invalid_Transition", "\n", "self", ".", "transitions", ".", "data", "[", ":", ",", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", "]", "=", "Constants", ".", "Invalid_Transition", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._score_sentence": [[95, 135], ["feats.size", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather().squeeze.masked_fill_", "torch.gather().squeeze.masked_fill_", "torch.gather().squeeze.masked_fill_", "transition_score.masked_fill_", "pad_ones.to.to.to", "tag_start.to.to.to", "tag_end.to.to.to", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "tags.view"], "methods", ["None"], ["", "", "def", "_score_sentence", "(", "self", ",", "feats", ",", "tags", ",", "sentence_masks", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Get the CRF score for the ground-truth tags\n        :param feats: LSTM output, batch x max_seq x tag\n        :param tags: ground-truth tags, batch x max_seq\n        :param sentence_masks: binary (0,1) int matrix, batch x max_seq\n        :param device: device info\n        :return:\n        \"\"\"", "\n", "\n", "batch_size", ",", "max_seq_length", ",", "tag_num", "=", "feats", ".", "size", "(", ")", "\n", "\n", "# batch x max_seq", "\n", "tag_wise_score", "=", "torch", ".", "gather", "(", "feats", ",", "2", ",", "tags", ".", "view", "(", "batch_size", ",", "max_seq_length", ",", "1", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "pad_ones", "=", "torch", ".", "ones", "(", "(", "batch_size", ",", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "requires_grad", "=", "False", ")", "\n", "tag_start", "=", "pad_ones", "*", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", "\n", "tag_end", "=", "pad_ones", "*", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "pad_ones", "=", "pad_ones", ".", "to", "(", "device", ")", "\n", "tag_start", "=", "tag_start", ".", "to", "(", "device", ")", "\n", "tag_end", "=", "tag_end", ".", "to", "(", "device", ")", "\n", "\n", "", "pad_start_tags", "=", "torch", ".", "cat", "(", "[", "tag_start", ",", "tags", "]", ",", "dim", "=", "1", ")", "\n", "pad_end_tags", "=", "torch", ".", "cat", "(", "[", "tags", ",", "tag_end", "]", ",", "dim", "=", "1", ")", "\n", "transition_masks", "=", "torch", ".", "cat", "(", "[", "pad_ones", ",", "sentence_masks", "]", ",", "dim", "=", "1", ")", "\n", "# batch x [max_seq+1]", "\n", "transition_score", "=", "self", ".", "transitions", "[", "pad_end_tags", ",", "pad_start_tags", "]", "\n", "\n", "invalid_sentence_masks", "=", "(", "1", "-", "sentence_masks", ")", ".", "byte", "(", ")", "\n", "invalid_transition_masks", "=", "(", "1", "-", "transition_masks", ")", ".", "byte", "(", ")", "\n", "\n", "tag_wise_score", ".", "masked_fill_", "(", "invalid_sentence_masks", ",", "0", ")", "\n", "transition_score", ".", "masked_fill_", "(", "invalid_transition_masks", ",", "0", ")", "\n", "\n", "score", "=", "torch", ".", "sum", "(", "tag_wise_score", ",", "1", ")", "+", "torch", ".", "sum", "(", "transition_score", ",", "1", ")", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._get_lstm_features": [[136, 217], ["words.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.GRN_CRF.char_embeds", "model.GRN_CRF.word_embeds", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.GRN_CRF.dropout", "model.GRN_CRF.inception_cnn", "model.GRN_CRF.dropout", "model.GRN_CRF.hidden2tag", "model.GRN_CRF.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "model.GRN_CRF.char_lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "chars_embeds_temp.to.to.clone", "chars_embeds_temp.to.clone.unsqueeze", "model.GRN_CRF.char_cnn", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d.squeeze().squeeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "chars_embeds_temp.to.to.clone", "model.GRN_CRF.context_layer1", "chars_embeds_temp.to.to.to", "chars_embeds_temp.to.to.to", "chars_embeds_temp.to.clone.size", "chars_lstm_out.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max_pool2d.squeeze", "chars_embeds_temp.to.clone.size", "chars_embeds_temp.to.clone.size", "model.GRN_CRF.size"], "methods", ["None"], ["", "def", "_get_lstm_features", "(", "self", ",", "words", ",", "sentence_masks", ",", "chars", ",", "chars_length", ",", "char_position_map", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        calculate the LSTM features for each step\n        :param words: int matrix, batch x max_seq\n        :param sentence_masks: binary (0,1) int matrix, batch x max_seq\n        :param chars: int matrix, all_words x max_word\n        :param chars_length: int matrix, all_words\n        :param chars_position_map: dict, all_words\n        :param device: torch.cuda.device\n        :return: LSTM features\n        \"\"\"", "\n", "\n", "batch_size", ",", "max_seq_length", "=", "words", ".", "size", "(", ")", "\n", "sentence_lengths", "=", "torch", ".", "sum", "(", "sentence_masks", ",", "1", ")", "\n", "\n", "# all_chars x max_word x char_embed", "\n", "chars_embeds", "=", "self", ".", "char_embeds", "(", "chars", ")", "\n", "\n", "if", "self", ".", "char_embed_dropout", ":", "\n", "# dropout", "\n", "            ", "chars_embeds", "=", "self", ".", "dropout", "(", "chars_embeds", ")", "\n", "\n", "", "if", "self", ".", "char_mode", "==", "CharEmbeddingSchema", ".", "LSTM", ":", "\n", "# packed char embeddings", "\n", "            ", "packed", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "chars_embeds", ",", "chars_length", ",", "batch_first", "=", "True", ")", "\n", "chars_lstm_out_packed", ",", "_", "=", "self", ".", "char_lstm", "(", "packed", ")", "\n", "# all_chars x max_word x lstm_out", "\n", "chars_lstm_out", ",", "chars_lstm_out_lengths", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "chars_lstm_out_packed", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# restore", "\n", "chars_embeds_temp", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_length", ",", "chars_lstm_out", ".", "size", "(", "2", ")", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "self", ".", "use_gpu", ":", "\n", "                ", "chars_embeds_temp", "=", "chars_embeds_temp", ".", "to", "(", "device", ")", "\n", "", "for", "i", ",", "index", "in", "enumerate", "(", "chars_lstm_out_lengths", ")", ":", "\n", "                ", "last_char_lstm_out", "=", "torch", ".", "cat", "(", "\n", "(", "chars_lstm_out", "[", "i", ",", "index", "-", "1", ",", ":", "self", ".", "char_lstm_dim", "]", ",", "chars_lstm_out", "[", "i", ",", "0", ",", "self", ".", "char_lstm_dim", ":", "]", ")", ")", "if", "self", ".", "char_lstm_bidirect", "else", "chars_lstm_out", "[", "i", ",", "index", "-", "1", ",", ":", "self", ".", "char_lstm_dim", "]", "\n", "chars_embeds_temp", "[", "char_position_map", "[", "i", "]", "[", "0", "]", ",", "char_position_map", "[", "i", "]", "[", "1", "]", "]", "=", "last_char_lstm_out", "\n", "\n", "", "chars_embeds", "=", "chars_embeds_temp", ".", "clone", "(", ")", "\n", "\n", "", "if", "self", ".", "char_mode", "==", "CharEmbeddingSchema", ".", "CNN", ":", "\n", "# all_word x 1 x max_word x char_embed", "\n", "            ", "chars_embeds", "=", "chars_embeds", ".", "unsqueeze", "(", "1", ")", "\n", "# all_word x cnn_output x max_word x 1", "\n", "chars_cnn_out", "=", "self", ".", "char_cnn", "(", "chars_embeds", ")", "\n", "chars_cnn_out", "=", "chars_cnn_out", "[", ":", ",", ":", ",", ":", "chars_embeds", ".", "size", "(", "2", ")", ",", ":", "]", "\n", "# all_word x cnn_output x 1 x 1 -> all_word x cnn_output", "\n", "max_pool_out", "=", "F", ".", "max_pool2d", "(", "chars_cnn_out", ",", "kernel_size", "=", "(", "chars_cnn_out", ".", "size", "(", "2", ")", ",", "1", ")", ")", "\n", "chars_embeds", "=", "max_pool_out", ".", "squeeze", "(", "2", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "# restore", "\n", "chars_embeds_temp", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_length", ",", "chars_embeds", ".", "size", "(", "1", ")", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "self", ".", "use_gpu", ":", "\n", "                ", "chars_embeds_temp", "=", "chars_embeds_temp", ".", "to", "(", "device", ")", "\n", "", "for", "i", "in", "range", "(", "chars_embeds", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "chars_embeds_temp", "[", "char_position_map", "[", "i", "]", "[", "0", "]", ",", "char_position_map", "[", "i", "]", "[", "1", "]", "]", "=", "chars_embeds", "[", "i", "]", "\n", "\n", "", "chars_embeds", "=", "chars_embeds_temp", ".", "clone", "(", ")", "\n", "\n", "# batch x max_seq x word_embed", "\n", "", "embeds", "=", "self", ".", "word_embeds", "(", "words", ")", "\n", "# batch x max_seq x [word_embed + char_embed]", "\n", "embeds", "=", "torch", ".", "cat", "(", "[", "embeds", ",", "chars_embeds", "]", ",", "2", ")", "\n", "\n", "embeds", "=", "self", ".", "dropout", "(", "embeds", ")", "\n", "\n", "lstm_out", "=", "self", ".", "inception_cnn", "(", "embeds", ")", "\n", "\n", "if", "self", ".", "enable_context", ":", "\n", "            ", "context_out", "=", "self", ".", "context_layer1", "(", "lstm_out", ",", "sentence_masks", ",", "device", ")", "\n", "lstm_out", "=", "context_out", "\n", "\n", "# batch x max_seq x hidden_state", "\n", "", "lstm_out", "=", "self", ".", "dropout", "(", "lstm_out", ")", "\n", "# batch x max_seq x tag", "\n", "lstm_feats", "=", "self", ".", "hidden2tag", "(", "lstm_out", ")", "\n", "\n", "return", "lstm_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._forward_alg": [[218, 266], ["feats.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "function_util.log_sum_exp", "function_util.log_sum_exp.unsqueeze.to", "all_alphas.to.to.to", "feat.view", "model.GRN_CRF.transitions.view().expand", "function_util.log_sum_exp", "function_util.log_sum_exp.unsqueeze", "model.GRN_CRF.transitions[].view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "model.GRN_CRF.transitions.view"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.function_util.log_sum_exp", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.function_util.log_sum_exp"], ["", "def", "_forward_alg", "(", "self", ",", "feats", ",", "sentence_masks", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Get alpha values for CRF\n        :param feats: LSTM output, batch x max_seq x tag\n        :param sentence_masks: binary (0,1) int matrix, batch x max_seq\n        :param device: device info\n        :return: alpha values for each sentence\n        \"\"\"", "\n", "\n", "batch_size", ",", "max_seq_length", ",", "tag_num", "=", "feats", ".", "size", "(", ")", "\n", "sentence_lengths", "=", "torch", ".", "sum", "(", "sentence_masks", ",", "1", ")", "\n", "\n", "# initialize alpha with a Tensor with values all equal to Constants.Invalid_Transition, 1 x tag", "\n", "# batch x 1 x tag", "\n", "forward_var", "=", "torch", ".", "Tensor", "(", "batch_size", ",", "1", ",", "self", ".", "tag_set_size", ")", ".", "fill_", "(", "Constants", ".", "Invalid_Transition", ")", "\n", "forward_var", "[", ":", ",", "0", ",", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", "]", "=", "0.", "\n", "\n", "all_alphas", "=", "torch", ".", "zeros", "(", "(", "max_seq_length", ",", "batch_size", ",", "tag_num", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "forward_var", "=", "forward_var", ".", "to", "(", "device", ")", "\n", "all_alphas", "=", "all_alphas", ".", "to", "(", "device", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "max_seq_length", ")", ":", "\n", "# batch x tag", "\n", "            ", "feat", "=", "feats", "[", ":", ",", "i", ",", ":", "]", "\n", "# batch x tag x 1", "\n", "emit_score", "=", "feat", ".", "view", "(", "batch_size", ",", "tag_num", ",", "1", ")", "\n", "# batch x tag x tag", "\n", "transition_expanded", "=", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_num", ",", "tag_num", ")", ".", "expand", "(", "batch_size", ",", "tag_num", ",", "tag_num", ")", "\n", "# batch x tag x tag", "\n", "tag_var", "=", "forward_var", "+", "transition_expanded", "+", "emit_score", "\n", "# batch x tag --> batch x 1 x tag", "\n", "new_forward_var", "=", "log_sum_exp", "(", "tag_var", ",", "dim", "=", "2", ")", "\n", "forward_var", "=", "new_forward_var", ".", "unsqueeze", "(", "1", ")", "\n", "all_alphas", "[", "i", "]", "=", "new_forward_var", "\n", "\n", "# 1 x batch x tag", "\n", "", "forward_var_selection", "=", "(", "sentence_lengths", "-", "1", ")", ".", "view", "(", "1", ",", "batch_size", ",", "1", ")", ".", "expand", "(", "1", ",", "batch_size", ",", "tag_num", ")", "\n", "# batch x tag", "\n", "forward_var_last", "=", "torch", ".", "gather", "(", "all_alphas", ",", "0", ",", "forward_var_selection", ")", ".", "squeeze", "(", "0", ")", "\n", "# same as: forward_var_last = all_alphas[sentence_lengths-1, torch.LongTensor(range(batch_size)), :]", "\n", "\n", "terminal_var", "=", "forward_var_last", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", ",", ":", "]", ".", "view", "(", "1", ",", "tag_num", ")", "\n", "# batch", "\n", "Z", "=", "log_sum_exp", "(", "terminal_var", ",", "dim", "=", "1", ")", "\n", "\n", "return", "Z", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF.viterbi_decode": [[267, 335], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "feats.size", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "terminal_var.squeeze.squeeze.squeeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "reversed", "tag_seqs_var.to.to.transpose", "path_scores.cpu().numpy().tolist", "range", "forward_var.to.to.to", "back_pointers_var.to.to.to", "batch_idx_var.to.to.to", "tag_seqs_var.to.to.to", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "forward_var.to.to.masked_scatter_", "model.GRN_CRF.transitions[].view().expand", "range", "back_pointers_idx.masked_fill_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "model.GRN_CRF.transitions.view().expand", "viterbivars_t.view", "tag_feat.view", "sentence_masks[].view().byte().expand", "back_pointers_idx.lt", "zip", "path_scores.cpu().numpy", "model.GRN_CRF.transitions[].view", "tag_seqs_var.to.to.cpu().numpy().tolist", "torch.sum.cpu().numpy().tolist", "torch.sum.cpu().numpy().tolist", "torch.sum.cpu().numpy().tolist", "model.GRN_CRF.transitions.view", "sentence_masks[].view().byte", "path_scores.cpu", "tag_seqs_var.to.to.cpu().numpy", "torch.sum.cpu().numpy", "torch.sum.cpu().numpy", "torch.sum.cpu().numpy", "sentence_masks[].view", "tag_seqs_var.to.to.cpu", "torch.sum.cpu", "torch.sum.cpu", "torch.sum.cpu"], "methods", ["None"], ["", "def", "viterbi_decode", "(", "self", ",", "feats", ",", "sentence_masks", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Viterbi decoding\n        :param feats: LSTM output, batch x max_seq x tag\n        :param sentence_masks: binary (0,1) int matrix, batch x max_seq\n        :param device: device info\n        :return: tagging result\n        \"\"\"", "\n", "\n", "sentence_lengths", "=", "torch", ".", "sum", "(", "sentence_masks", ",", "1", ")", "\n", "batch_size", ",", "max_seq_length", ",", "tag_num", "=", "feats", ".", "size", "(", ")", "\n", "\n", "\n", "# batch x 1 x tag", "\n", "forward_var", "=", "torch", ".", "Tensor", "(", "batch_size", ",", "1", ",", "self", ".", "tag_set_size", ")", ".", "fill_", "(", "Constants", ".", "Invalid_Transition", ")", "\n", "forward_var", "[", ":", ",", "0", ",", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", "]", "=", "0", "\n", "\n", "back_pointers_var", "=", "torch", ".", "Tensor", "(", "max_seq_length", ",", "batch_size", ",", "self", ".", "tag_set_size", ")", ".", "fill_", "(", "\n", "Constants", ".", "Invalid_Transition", ")", "\n", "batch_idx_var", "=", "torch", ".", "tensor", "(", "range", "(", "batch_size", ")", ")", "\n", "tag_seqs_var", "=", "torch", ".", "zeros", "(", "[", "max_seq_length", ",", "batch_size", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "forward_var", "=", "forward_var", ".", "to", "(", "device", ")", "\n", "back_pointers_var", "=", "back_pointers_var", ".", "to", "(", "device", ")", "\n", "batch_idx_var", "=", "batch_idx_var", ".", "to", "(", "device", ")", "\n", "tag_seqs_var", "=", "tag_seqs_var", ".", "to", "(", "device", ")", "\n", "\n", "", "for", "wi", "in", "range", "(", "max_seq_length", ")", ":", "\n", "# batch x tag", "\n", "            ", "tag_feat", "=", "feats", "[", ":", ",", "wi", ",", ":", "]", "\n", "# batch x tag x tag", "\n", "next_tag_var", "=", "forward_var", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "self", ".", "tag_set_size", ",", "self", ".", "tag_set_size", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "tag_set_size", ",", "self", ".", "tag_set_size", ")", "\n", "# batch x tag", "\n", "viterbivars_t", ",", "bptrs_t", "=", "torch", ".", "max", "(", "next_tag_var", ",", "dim", "=", "2", ")", "\n", "# batch x 1 x tag", "\n", "next_forward_var", "=", "viterbivars_t", ".", "view", "(", "batch_size", ",", "1", ",", "self", ".", "tag_set_size", ")", "+", "tag_feat", ".", "view", "(", "batch_size", ",", "1", ",", "self", ".", "tag_set_size", ")", "\n", "forward_var", ".", "masked_scatter_", "(", "sentence_masks", "[", ":", ",", "wi", "]", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "byte", "(", ")", "\n", ".", "expand", "(", "batch_size", ",", "1", ",", "self", ".", "tag_set_size", ")", ",", "next_forward_var", ")", "\n", "back_pointers_var", "[", "wi", "]", "=", "bptrs_t", "\n", "\n", "# batch x 1 x tag --> batch x tag", "\n", "", "terminal_var", "=", "forward_var", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", ",", ":", "]", ".", "view", "(", "1", ",", "1", ",", "self", ".", "tag_set_size", ")", ".", "expand", "(", "\n", "batch_size", ",", "1", ",", "self", ".", "tag_set_size", ")", "\n", "terminal_var", "[", ":", ",", ":", ",", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", "]", "=", "Constants", ".", "Invalid_Transition", "\n", "terminal_var", "[", ":", ",", ":", ",", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", "]", "=", "Constants", ".", "Invalid_Transition", "\n", "terminal_var", "=", "terminal_var", ".", "squeeze", "(", "1", ")", "\n", "\n", "# batch", "\n", "path_scores", ",", "best_tag_ids", "=", "torch", ".", "max", "(", "terminal_var", ",", "1", ")", "\n", "tag_seqs_var", "[", "-", "1", "]", "=", "best_tag_ids", "\n", "\n", "back_pointers_idx", "=", "sentence_lengths", "-", "1", "\n", "for", "wi", "in", "reversed", "(", "range", "(", "max_seq_length", "-", "1", ")", ")", ":", "\n", "            ", "tag_seqs_var", "[", "wi", "]", "=", "back_pointers_var", "[", "back_pointers_idx", ",", "batch_idx_var", ",", "tag_seqs_var", "[", "wi", "+", "1", "]", "]", "\n", "back_pointers_idx", "=", "back_pointers_idx", "-", "1", "\n", "back_pointers_idx", ".", "masked_fill_", "(", "back_pointers_idx", ".", "lt", "(", "0", ")", ",", "0", ")", "\n", "\n", "", "tag_seqs_var", "=", "tag_seqs_var", ".", "transpose", "(", "0", ",", "1", ")", "\n", "tag_seqs", "=", "[", "tag_seq_np", "[", "0", "]", "[", "(", "max_seq_length", "-", "tag_seq_np", "[", "1", "]", ")", ":", "]", "for", "tag_seq_np", "in", "\n", "zip", "(", "tag_seqs_var", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "sentence_lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "]", "\n", "\n", "scores", "=", "path_scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "return", "scores", ",", "tag_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF.neg_log_likelihood": [[336, 372], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.GRN_CRF._get_lstm_features", "model.GRN_CRF._forward_alg", "model.GRN_CRF._score_sentence", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.size", "torch.sum.size", "torch.sum.size", "torch.sum.size", "torch.sum.size", "torch.sum.size", "all_scores.to.to.to", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._get_lstm_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._forward_alg", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._score_sentence"], ["", "def", "neg_log_likelihood", "(", "self", ",", "words", ",", "sentence_masks", ",", "tags", ",", "chars", ",", "chars_length", ",", "chars_position_map", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Loss function\n        :param words: int matrix, batch x max_seq\n        :param sentence_masks: binary (0,1) int matrix, batch x max_seq\n        :param tags: int matrix, batch x max_seq\n        :param chars: int matrix, batch x max_seq x max_word\n        :param chars_length: int matrix, batch x max_seq\n        :param chars_position_map: dict list, batch x dict_size\n        :param device: torch.cuda.device\n        :return: loss of CRF/Softmax\n        \"\"\"", "\n", "\n", "sentence_lengths", "=", "torch", ".", "sum", "(", "sentence_masks", ",", "1", ")", "\n", "\n", "# batch x max_seq x tag", "\n", "feats", "=", "self", ".", "_get_lstm_features", "(", "words", ",", "sentence_masks", ",", "chars", ",", "chars_length", ",", "chars_position_map", ",", "device", ")", "\n", "\n", "if", "self", ".", "use_crf", ":", "\n", "            ", "forward_score", "=", "self", ".", "_forward_alg", "(", "feats", ",", "sentence_masks", ",", "device", ")", "\n", "gold_score", "=", "self", ".", "_score_sentence", "(", "feats", ",", "tags", ",", "sentence_masks", ",", "device", ")", "\n", "crf_loss", "=", "torch", ".", "sum", "(", "forward_score", "-", "gold_score", ")", "/", "sentence_lengths", ".", "size", "(", "0", ")", "\n", "return", "crf_loss", "\n", "", "else", ":", "\n", "            ", "all_scores", "=", "torch", ".", "zeros", "(", "sentence_lengths", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "self", ".", "use_gpu", ":", "\n", "                ", "all_scores", "=", "all_scores", ".", "to", "(", "device", ")", "\n", "\n", "", "for", "i", ",", "length", "in", "enumerate", "(", "sentence_lengths", ")", ":", "\n", "                ", "sentence_feat", "=", "feats", "[", "i", ",", ":", "length", ",", ":", "]", "\n", "sentence_tags", "=", "tags", "[", "i", ",", ":", "length", "]", "\n", "all_scores", "[", "i", "]", "=", "F", ".", "cross_entropy", "(", "sentence_feat", ",", "sentence_tags", ",", "size_average", "=", "False", ")", "\n", "\n", "", "scores", "=", "torch", ".", "sum", "(", "all_scores", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF.forward": [[373, 401], ["model.GRN_CRF._get_lstm_features", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.GRN_CRF.viterbi_decode", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "enumerate", "tag_seq.append", "score.append", "list", "list", "tag_seq_temp[].cpu().numpy", "score_temp[].cpu().numpy", "tag_seq_temp[].cpu", "score_temp[].cpu"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF._get_lstm_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.model.GRN_CRF.viterbi_decode"], ["", "", "def", "forward", "(", "self", ",", "words", ",", "sentence_masks", ",", "chars", ",", "chars_length", ",", "chars_position_map", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Derive the tagging results\n        :param words: int matrix, batch x max_seq\n        :param sentence_masks: binary (0,1) int matrix, batch x max_seq\n        :param chars: int matrix, batch x max_seq x max_word\n        :param chars_length: int matrix, batch x max_seq\n        :param chars_position_map: dict list, batch x dict_size\n        :param device: torch.cuda.device\n        :return: tagging results\n        \"\"\"", "\n", "\n", "# batch x max_seq x tag", "\n", "feats", "=", "self", ".", "_get_lstm_features", "(", "words", ",", "sentence_masks", ",", "chars", ",", "chars_length", ",", "chars_position_map", ",", "device", ")", "\n", "\n", "sentence_lengths", "=", "torch", ".", "sum", "(", "sentence_masks", ",", "1", ")", "\n", "if", "self", ".", "use_crf", ":", "\n", "            ", "score", ",", "tag_seq", "=", "self", ".", "viterbi_decode", "(", "feats", ",", "sentence_masks", ",", "device", ")", "\n", "", "else", ":", "\n", "            ", "score_temp", ",", "tag_seq_temp", "=", "torch", ".", "max", "(", "feats", ",", "2", ")", "\n", "tag_seq", "=", "[", "]", "\n", "score", "=", "[", "]", "\n", "for", "i", ",", "length", "in", "enumerate", "(", "sentence_lengths", ")", ":", "\n", "                ", "tag_seq", ".", "append", "(", "list", "(", "tag_seq_temp", "[", "i", ",", ":", "length", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "score", ".", "append", "(", "list", "(", "score_temp", "[", "i", ",", ":", "length", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "", "return", "score", ",", "tag_seq", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_loader_conll.DataLoaderCoNLL.__init__": [[11, 32], ["torch.utils.data.Dataset.__init__", "data_processing.load_dataset_conll"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.load_dataset_conll"], ["def", "__init__", "(", "self", ",", "data_file", ",", "mappings", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        :param data_file: string, file path storing the data\n        :param mappings: a mapping dictionary containing tag_to_id, id_to_tag, word_to_id, id_to_word, char_to_id, id_to_char\n        \"\"\"", "\n", "super", "(", "DataLoaderCoNLL", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "data_file", "=", "data_file", "\n", "\n", "self", ".", "tag_to_id", "=", "mappings", "[", "\"tag_to_id\"", "]", "\n", "self", ".", "word_to_id", "=", "mappings", "[", "\"word_to_id\"", "]", "\n", "self", ".", "char_to_id", "=", "mappings", "[", "\"char_to_id\"", "]", "\n", "self", ".", "word_to_lower", "=", "mappings", "[", "\"word_to_lower\"", "]", "\n", "self", ".", "digits_to_zeros", "=", "mappings", "[", "\"digits_to_zeros\"", "]", "\n", "self", ".", "label_schema", "=", "mappings", "[", "\"label_schema\"", "]", "\n", "\n", "# read the data file", "\n", "sentences", ",", "tags", "=", "load_dataset_conll", "(", "data_file", ",", "self", ".", "label_schema", ",", "self", ".", "digits_to_zeros", ")", "\n", "\n", "self", ".", "sentences", "=", "sentences", "\n", "self", ".", "tags", "=", "tags", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_loader_conll.DataLoaderCoNLL.__len__": [[33, 40], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Length of the dataset\n        :return: length\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "sentences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_loader_conll.DataLoaderCoNLL.__getitem__": [[41, 63], ["word.lower", "data_loader_conll.DataLoaderCoNLL.word_to_id.keys", "data_loader_conll.DataLoaderCoNLL.char_to_id.keys"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Get an item of the dataset\n        :param idx: index of the item\n        :return: corresponding data item\n        \"\"\"", "\n", "sentence", "=", "self", ".", "sentences", "[", "idx", "]", "\n", "sentence_words", "=", "[", "word", ".", "lower", "(", ")", "if", "self", ".", "word_to_lower", "else", "word", "for", "word", "in", "sentence", "]", "\n", "sentence_tag", "=", "self", ".", "tags", "[", "idx", "]", "\n", "\n", "sentence_word_id", "=", "[", "self", ".", "word_to_id", "[", "word", "if", "word", "in", "self", ".", "word_to_id", ".", "keys", "(", ")", "else", "Constants", ".", "Word_Unknown", "]", "\n", "for", "word", "in", "sentence_words", "]", "\n", "sentence_tag_id", "=", "[", "self", ".", "tag_to_id", "[", "tag", "]", "for", "tag", "in", "sentence_tag", "]", "\n", "sentence_char_id", "=", "[", "[", "self", ".", "char_to_id", "[", "c", "if", "c", "in", "self", ".", "char_to_id", ".", "keys", "(", ")", "else", "Constants", ".", "Char_Unknown", "]", "for", "c", "in", "word", "]", "\n", "for", "word", "in", "sentence", "]", "\n", "\n", "return", "{", "\n", "\"str_words\"", ":", "sentence", ",", "\n", "\"words\"", ":", "sentence_word_id", ",", "\n", "\"tags\"", ":", "sentence_tag_id", ",", "\n", "\"chars\"", ":", "sentence_char_id", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.adjust_learning_rate": [[6, 13], ["None"], "function", ["None"], ["# you may not use this file except in compliance with the License.", "\n", "# You may obtain a copy of the License at", "\n", "#", "\n", "#     http://www.apache.org/licenses/LICENSE-2.0", "\n", "#", "\n", "# Unless required by applicable law or agreed to in writing, software", "\n", "# distributed under the License is distributed on an \"AS IS\" BASIS,", "\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_": [[15, 21], ["torch.kaiming_uniform_"], "function", ["None"], ["# limitations under the License.", "\n", "\n", "import", "csv", "\n", "import", "sys", "\n", "import", "copy", "\n", "import", "json", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_embedding_": [[23, 29], ["utils.init_weight_"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_linear_": [[31, 39], ["utils.init_weight_", "input_linear.bias.data.zero_"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["\n", "def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_lstm_": [[41, 76], ["range", "eval", "utils.init_weight_", "eval", "utils.init_weight_", "range", "range", "eval", "utils.init_weight_", "eval", "utils.init_weight_", "eval", "eval.data.zero_", "eval", "eval.data.zero_", "range", "str", "str", "eval", "eval.data.zero_", "eval", "eval.data.zero_", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n", "", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    A single set of features of data.\n\n    Args:\n        input_ids: Indices of input sequence tokens in the vocabulary.\n        attention_mask: Mask to avoid performing attention on padding token indices.\n            Mask values selected in ``[0, 1]``:\n            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n        label: Label corresponding to the input\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "label", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n", "", "def", "to_dict", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_cnn_": [[78, 86], ["utils.init_weight_", "input_cnn.bias.data.zero_"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.utils.init_weight_"], ["output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "class", "DataProcessor", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.evaluation.get_perf_metric": [[11, 41], ["os.system", "enumerate", "line.rstrip", "codecs.open", "float", "line.strip().split", "line.strip"], "function", ["None"], ["def", "get_perf_metric", "(", "name", ",", "best_f1", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Evalute the result file and get the new f1 value\n    :param name: name of the model\n    :param best_f1: the current best f1 value\n    :return: new best f1 value, the new f1 value, whether the new best f1 value is updated\n    \"\"\"", "\n", "should_save", "=", "False", "\n", "new_f1", "=", "0.0", "\n", "\n", "eval_path", "=", "Constants", ".", "Eval_Folder", "\n", "eval_tmp_folder", "=", "Constants", ".", "Eval_Temp_Folder", "\n", "eval_script", "=", "Constants", ".", "Eval_Script", "\n", "\n", "prediction_file", "=", "eval_tmp_folder", "+", "'/predition.'", "+", "name", "\n", "score_file", "=", "eval_tmp_folder", "+", "'/score.'", "+", "name", "\n", "\n", "os", ".", "system", "(", "'perl %s <%s >%s'", "%", "(", "eval_script", ",", "prediction_file", ",", "score_file", ")", ")", "\n", "\n", "evaluation_lines", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "codecs", ".", "open", "(", "score_file", ",", "'r'", ",", "'utf8'", ")", "]", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "evaluation_lines", ")", ":", "\n", "        ", "if", "i", "==", "1", ":", "\n", "            ", "new_f1", "=", "float", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "if", "new_f1", ">", "best_f1", ":", "\n", "                ", "best_f1", "=", "new_f1", "\n", "should_save", "=", "True", "\n", "\n", "", "", "", "return", "best_f1", ",", "new_f1", ",", "should_save", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.evaluation.evaluating": [[43, 109], ["list", "math.ceil", "range", "os.path.join", "evaluation.get_perf_metric", "range", "min", "data_processing.generate_mini_batch_input", "time.time", "model", "range", "codecs.open", "f.write", "f.flush", "len", "len", "len", "sentence_masks.to.to", "words.to.to", "chars.to.to", "tags.to.to", "sentence_char_lengths.to.to", "time.time", "data_format_util.iobes_to_iob2", "data_format_util.iobes_to_iob2", "zip", "prediction.append", "prediction.append"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.evaluation.get_perf_metric", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_processing.generate_mini_batch_input", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.iobes_to_iob2", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_format_util.iobes_to_iob2"], ["", "def", "evaluating", "(", "model", ",", "datas", ",", "best_F", ",", "name", ",", "mappings", ",", "char_mode", ",", "use_gpu", ",", "device", ",", "mini_batch_size", ")", ":", "\n", "    ", "\"\"\"\n    checked\n    Evaluate the F1 score on a given dataset\n    :param model: To-be-tested model\n    :param datas: Data set loader\n    :param best_F: Best F1 score already obtained\n    :param name: Name of the model\n    :param mappings: Dict, a mapping dictionary containing tag_to_id, id_to_tag, word_to_id, id_to_word, char_to_id, id_to_char\n    :param char_mode: CharEmbeddingSchema, char embedding type, in [LSTM, CNN]\n    :param use_gpu: Use gpu or not\n    :param device: Device to run the function\n    :param mini_batch_size: Mini-batch size for evaluation\n    :return:\n    \"\"\"", "\n", "prediction", "=", "[", "]", "\n", "\n", "eval_tmp_folder", "=", "Constants", ".", "Eval_Temp_Folder", "\n", "id_to_tag", "=", "mappings", "[", "\"id_to_tag\"", "]", "\n", "char_to_id", "=", "mappings", "[", "\"char_to_id\"", "]", "\n", "\n", "train_indecies", "=", "list", "(", "range", "(", "len", "(", "datas", ")", ")", ")", "\n", "batch_count", "=", "math", ".", "ceil", "(", "len", "(", "datas", ")", "/", "mini_batch_size", ")", "\n", "time_cost", "=", "0", "\n", "\n", "for", "batch_i", "in", "range", "(", "batch_count", ")", ":", "\n", "        ", "start_idx", "=", "batch_i", "*", "mini_batch_size", "\n", "end_idx", "=", "min", "(", "(", "batch_i", "+", "1", ")", "*", "mini_batch_size", ",", "len", "(", "datas", ")", ")", "\n", "\n", "mini_batch_idx", "=", "train_indecies", "[", "start_idx", ":", "end_idx", "]", "\n", "sentence_masks", ",", "words", ",", "chars", ",", "tags", ",", "sentence_char_lengths", ",", "sentence_char_position_map", ",", "str_words", ",", "unaligned_tags", "=", "generate_mini_batch_input", "(", "datas", ",", "mini_batch_idx", ",", "mappings", ",", "char_mode", ")", "\n", "\n", "if", "use_gpu", ":", "\n", "            ", "sentence_masks", "=", "sentence_masks", ".", "to", "(", "device", ")", "\n", "words", "=", "words", ".", "to", "(", "device", ")", "\n", "chars", "=", "chars", ".", "to", "(", "device", ")", "\n", "tags", "=", "tags", ".", "to", "(", "device", ")", "\n", "sentence_char_lengths", "=", "sentence_char_lengths", ".", "to", "(", "device", ")", "\n", "\n", "", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "scores", ",", "tag_id_seqs", "=", "model", "(", "words", ",", "sentence_masks", ",", "chars", ",", "sentence_char_lengths", ",", "sentence_char_position_map", ",", "device", ")", "\n", "eval_time_cost", "=", "time", ".", "time", "(", ")", "-", "eval_start_time", "\n", "time_cost", "+=", "eval_time_cost", "\n", "\n", "predicted_tags", "=", "[", "[", "id_to_tag", "[", "id", "]", "for", "id", "in", "predicted_id", "]", "for", "predicted_id", "in", "tag_id_seqs", "]", "\n", "predicted_tags_bio", "=", "[", "iobes_to_iob2", "(", "predicted_tags_sentence", ")", "for", "predicted_tags_sentence", "in", "predicted_tags", "]", "\n", "\n", "ground_truth_tags", "=", "[", "[", "id_to_tag", "[", "id", "]", "for", "id", "in", "ground_truth_id", "]", "for", "ground_truth_id", "in", "unaligned_tags", "]", "\n", "ground_truth_tags_bio", "=", "[", "iobes_to_iob2", "(", "ground_truth_tags_sentence", ")", "for", "ground_truth_tags_sentence", "in", "ground_truth_tags", "]", "\n", "\n", "for", "si", "in", "range", "(", "end_idx", "-", "start_idx", ")", ":", "\n", "            ", "for", "(", "str_word", ",", "true_tag", ",", "pred_tag", ")", "in", "zip", "(", "str_words", "[", "si", "]", ",", "ground_truth_tags_bio", "[", "si", "]", ",", "predicted_tags_bio", "[", "si", "]", ")", ":", "\n", "                ", "line", "=", "' '", ".", "join", "(", "[", "str_word", ",", "true_tag", ",", "pred_tag", "]", ")", "\n", "prediction", ".", "append", "(", "line", ")", "\n", "", "prediction", ".", "append", "(", "''", ")", "\n", "", "", "predf", "=", "os", ".", "path", ".", "join", "(", "eval_tmp_folder", ",", "'predition.'", "+", "name", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "predf", ",", "'w'", ",", "'utf8'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "prediction", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "best_F", ",", "new_F", ",", "save", "=", "get_perf_metric", "(", "name", ",", "best_F", ")", "\n", "\n", "return", "best_F", ",", "new_F", ",", "save", ",", "time_cost", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.LinkingPark.lp_service.apply_caching": [[22, 29], ["None"], "function", ["None"], ["@", "app", ".", "after_request", "\n", "def", "apply_caching", "(", "response", ")", ":", "\n", "# Adding default CORS headers as required by Excel Add-In", "\n", "    ", "response", ".", "headers", "[", "'Access-Control-Allow-Origin'", "]", "=", "'*'", "\n", "response", ".", "headers", "[", "'Access-Control-Allow-Headers'", "]", "=", "'*'", "\n", "response", ".", "headers", "[", "'Access-Control-Allow-Methods'", "]", "=", "'GET, POST'", "\n", "return", "response", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.LinkingPark.lp_service.not_found": [[31, 34], ["app.errorhandler", "flask.make_response", "flask.jsonify"], "function", ["None"], ["", "@", "app", ".", "errorhandler", "(", "404", ")", "\n", "def", "not_found", "(", "error", ")", ":", "\n", "    ", "return", "make_response", "(", "jsonify", "(", "{", "'Error'", ":", "'Not found'", "}", ")", ",", "404", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.LinkingPark.lp_service.status": [[36, 39], ["app.route", "flask.jsonify"], "function", ["None"], ["", "@", "app", ".", "route", "(", "'/autodetect/api/v1.0'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "status", "(", ")", ":", "\n", "    ", "return", "jsonify", "(", "'OK'", ")", ",", "200", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.LinkingPark.lp_service.detect": [[41, 77], ["app.route", "datetime.datetime.now", "logger.log", "TableAnnotator.Util.utils.InputTable", "flask.request.args.get", "detector.detect_single_table", "detector.detect_single_table.gen_online", "logger.log", "datetime.datetime.now", "logger.log", "print", "flask.abort", "str", "flask.jsonify", "uuid.uuid4", "request.args.get.lower", "json.dumps", "json.dumps", "detector.detect_single_table.dump_one_tab"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.detect_single_table", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.gen_online", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.dump_one_tab"], ["", "@", "app", ".", "route", "(", "'/autodetect/api/v1.0/detect'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "detect", "(", ")", ":", "\n", "\n", "    ", "if", "not", "request", ".", "json", "or", "'table'", "not", "in", "request", ".", "json", ":", "\n", "        ", "abort", "(", "400", ")", "\n", "\n", "", "t1", "=", "datetime", ".", "now", "(", ")", "\n", "logger", ".", "log", "(", "f'Input: {json.dumps(request.json)}'", ")", "\n", "\n", "table", "=", "request", ".", "json", "[", "\"table\"", "]", "\n", "input_tab", "=", "InputTable", "(", "table", ",", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", ")", "\n", "\n", "satori_flag", "=", "request", ".", "args", ".", "get", "(", "'sid'", ")", "\n", "map_flag", "=", "satori_flag", "is", "not", "None", "and", "satori_flag", ".", "lower", "(", ")", "in", "[", "'true'", ",", "'1'", ",", "'t'", ",", "'y'", ",", "'yes'", "]", "\n", "\n", "output_tab", "=", "detector", ".", "detect_single_table", "(", "input_tab", ",", "\n", "keep_N", "=", "args", ".", "keep_N", ",", "\n", "alpha", "=", "args", ".", "alpha", ",", "\n", "beta", "=", "args", ".", "beta", ",", "\n", "gamma", "=", "args", ".", "gamma", ",", "\n", "topk", "=", "args", ".", "topk", ",", "\n", "init_prune_topk", "=", "params", "[", "\"init_prune_topk\"", "]", ",", "\n", "max_iter", "=", "args", ".", "max_iter", ",", "\n", "min_final_diff", "=", "args", ".", "min_final_diff", ",", "\n", "row_feature_only", "=", "params", "[", "\"row_feature_only\"", "]", ",", "\n", "map_ids", "=", "map_flag", ")", "\n", "\n", "info", "=", "output_tab", ".", "gen_online", "(", ")", "\n", "logger", ".", "log", "(", "f'Output: {json.dumps(output_tab.dump_one_tab())}'", ")", "\n", "\n", "t2", "=", "datetime", ".", "now", "(", ")", "\n", "delta", "=", "(", "t2", "-", "t1", ")", ".", "total_seconds", "(", ")", "\n", "logger", ".", "log", "(", "f'Time Consumed: {delta}s\\n'", ")", "\n", "print", "(", "f'Time Consumed: {delta}s\\n'", ")", "\n", "\n", "return", "jsonify", "(", "info", ")", ",", "201", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.elastic_search.ElasticSearcher.__init__": [[16, 29], ["elasticsearch.Elasticsearch", "elasticsearch.client.IndicesClient", "elastic_search.ElasticSearcher.es.ping", "print", "print", "elastic_search.ElasticSearcher.es.indices.exists", "elastic_search.ElasticSearcher.es.indices.create", "print", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "index_name", ")", ":", "\n", "        ", "self", ".", "index_name", "=", "index_name", "\n", "self", ".", "es", "=", "Elasticsearch", "(", "[", "{", "'host'", ":", "'localhost'", ",", "'port'", ":", "9200", "}", "]", ",", "timeout", "=", "120", ")", "\n", "self", ".", "indexES", "=", "client", ".", "IndicesClient", "(", "self", ".", "es", ")", "\n", "if", "self", ".", "es", ".", "ping", "(", ")", ":", "\n", "            ", "print", "(", "\"Connect elasticsearch successfully!\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Connect failed...\"", ")", "\n", "", "if", "not", "self", ".", "es", ".", "indices", ".", "exists", "(", "self", ".", "index_name", ")", ":", "\n", "            ", "self", ".", "es", ".", "indices", ".", "create", "(", "index", "=", "self", ".", "index_name", ",", "ignore", "=", "400", ",", "body", "=", "None", ")", "\n", "print", "(", "\"create index successfully\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"index already exists.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.elastic_search.ElasticSearcher.bulk_index_data": [[30, 55], ["elasticsearch.helpers.parallel_bulk", "print", "tqdm.tqdm.tqdm", "open", "pickle.load", "pickle.load.items", "elastic_search.ElasticSearcher.bulk_index_data.generator"], "methods", ["None"], ["", "", "def", "bulk_index_data", "(", "self", ",", "alias2qids_fn", ")", ":", "\n", "        ", "def", "generator", "(", "alias2qids", ")", ":", "\n", "            ", "cid", "=", "0", "\n", "for", "alias", ",", "qids", "in", "tqdm", "(", "alias2qids", ".", "items", "(", ")", ")", ":", "\n", "                ", "cid", "+=", "1", "\n", "yield", "{", "\n", "'_op_type'", ":", "'index'", ",", "\n", "'_id'", ":", "cid", ",", "\n", "'_index'", ":", "self", ".", "index_name", ",", "\n", "'_source'", ":", "{", "\n", "'title'", ":", "alias", ",", "\n", "'qid'", ":", "\";\"", ".", "join", "(", "qids", ")", ",", "\n", "}", "\n", "}", "\n", "\n", "", "", "with", "open", "(", "alias2qids_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "alias2qids", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "\n", "", "for", "success", ",", "info", "in", "parallel_bulk", "(", "client", "=", "self", ".", "es", ",", "\n", "actions", "=", "generator", "(", "alias2qids", ")", ",", "\n", "thread_count", "=", "5", ",", "\n", "request_timeout", "=", "60", ")", ":", "\n", "            ", "if", "not", "success", ":", "\n", "                ", "print", "(", "\"Doc failed: {}\"", ".", "format", "(", "info", ")", ")", "\n", "", "", "print", "(", "\"index data done.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.elastic_search.ElasticSearcher.query_data": [[56, 95], ["elastic_search.ElasticSearcher.es.search", "len", "ans.append"], "methods", ["None"], ["", "def", "query_data", "(", "self", ",", "\n", "mention", ",", "\n", "top_k", "=", "50", ",", "\n", "score_func", "=", "'token'", ")", ":", "\n", "\n", "        ", "if", "score_func", "==", "'token'", ":", "\n", "            ", "dsl", "=", "{", "\n", "\"query\"", ":", "{", "\n", "# single feature", "\n", "\"match\"", ":", "{", "\"title\"", ":", "mention", "}", "\n", "}", "\n", "}", "\n", "", "else", ":", "\n", "            ", "dsl", "=", "{", "\n", "\"query\"", ":", "{", "\n", "# feature ensemble: title^2 + title.ngram", "\n", "\"multi_match\"", ":", "{", "\n", "\"query\"", ":", "mention", ",", "\n", "\"fields\"", ":", "[", "\"title^2\"", ",", "\"title.ngram\"", "]", ",", "\n", "\"type\"", ":", "\"most_fields\"", "\n", "}", "\n", "}", "\n", "}", "\n", "\n", "", "res", "=", "self", ".", "es", ".", "search", "(", "index", "=", "self", ".", "index_name", ",", "\n", "body", "=", "dsl", ",", "\n", "size", "=", "top_k", ",", "\n", "explain", "=", "False", ")", "\n", "\n", "hits", "=", "res", "[", "\"hits\"", "]", "[", "\"hits\"", "]", "\n", "if", "len", "(", "hits", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "ans", "=", "[", "]", "\n", "for", "hit", "in", "hits", ":", "\n", "# qlist = hit[\"_source\"][\"qid\"].split(\";\")", "\n", "            ", "qstr", "=", "hit", "[", "\"_source\"", "]", "[", "\"qid\"", "]", "\n", "htitle", "=", "hit", "[", "\"_source\"", "]", "[", "\"title\"", "]", "\n", "ans", ".", "append", "(", "(", "qstr", ",", "hit", "[", "'_score'", "]", ",", "htitle", ")", ")", "\n", "", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.elastic_search.ElasticSearcher.delete_indices": [[96, 98], ["elastic_search.ElasticSearcher.es.indices.delete"], "methods", ["None"], ["", "def", "delete_indices", "(", "self", ")", ":", "\n", "        ", "self", ".", "es", ".", "indices", ".", "delete", "(", "index", "=", "self", ".", "index_name", ",", "ignore", "=", "[", "400", ",", "404", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.elastic_search.ElasticSearcher.generate_cands": [[99, 124], ["tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.close", "open", "pickle.load", "tqdm.tqdm.tqdm.update", "open", "pickle.dump", "len", "elastic_search.ElasticSearcher.query_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.query_data"], ["", "def", "generate_cands", "(", "self", ",", "\n", "query_fn", ",", "\n", "output_fn", ",", "\n", "top_k", "=", "50", ",", "\n", "score_func", "=", "'token'", ")", ":", "\n", "        ", "with", "open", "(", "query_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "mentions", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "\n", "", "ans", "=", "{", "}", "\n", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "mentions", ")", ")", "\n", "for", "mention", "in", "mentions", ":", "\n", "            ", "if", "mention", "in", "ans", ":", "\n", "                ", "continue", "\n", "", "try", ":", "\n", "                ", "res", "=", "self", ".", "query_data", "(", "mention", ",", "\n", "top_k", "=", "top_k", ",", "\n", "score_func", "=", "score_func", ")", "\n", "", "except", ":", "\n", "                ", "res", "=", "[", "]", "\n", "", "ans", "[", "mention", "]", "=", "res", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n", "with", "open", "(", "output_fn", ",", "mode", "=", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "ans", ",", "fp", ")", "\n", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.__init__": [[11, 18], ["dict", "print", "wikidata_candid_map_typo.WikidataCandidateTypoMap.load_alias_map"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.combine_wikipedia_alias_map_wikidata_aliases.load_alias_map"], ["    ", "def", "__init__", "(", "self", ",", "\n", "alias_map_fn", ")", ":", "\n", "        ", "if", "config", ".", "debug", ":", "\n", "            ", "self", ".", "alias_map", "=", "dict", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"using RAM alias map\"", ")", "\n", "self", ".", "alias_map", "=", "WikidataCandidateTypoMap", ".", "load_alias_map", "(", "alias_map_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.load_alias_map": [[19, 24], ["open", "pickle.load"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "load_alias_map", "(", "alias_map_fn", ")", ":", "\n", "        ", "with", "open", "(", "alias_map_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "alias_map", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "alias_map", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.edits1": [[25, 35], ["set", "range", "len", "len"], "methods", ["None"], ["", "", "def", "edits1", "(", "self", ",", "word", ")", ":", "\n", "        ", "\"All edits that are one edit away from `word`.\"", "\n", "\n", "letters", "=", "' abcdefghijklmnopqrstuvwxyz'", "+", "string", ".", "punctuation", "+", "'0123456789'", "+", "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'", "\n", "splits", "=", "[", "(", "word", "[", ":", "i", "]", ",", "word", "[", "i", ":", "]", ")", "for", "i", "in", "range", "(", "len", "(", "word", ")", "+", "1", ")", "]", "\n", "deletes", "=", "[", "L", "+", "R", "[", "1", ":", "]", "for", "L", ",", "R", "in", "splits", "if", "R", "]", "\n", "transposes", "=", "[", "L", "+", "R", "[", "1", "]", "+", "R", "[", "0", "]", "+", "R", "[", "2", ":", "]", "for", "L", ",", "R", "in", "splits", "if", "len", "(", "R", ")", ">", "1", "]", "\n", "replaces", "=", "[", "L", "+", "c", "+", "R", "[", "1", ":", "]", "for", "L", ",", "R", "in", "splits", "if", "R", "for", "c", "in", "letters", "]", "\n", "inserts", "=", "[", "L", "+", "c", "+", "R", "for", "L", ",", "R", "in", "splits", "for", "c", "in", "letters", "]", "\n", "return", "set", "(", "deletes", "+", "transposes", "+", "replaces", "+", "inserts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.edits2": [[36, 38], ["set", "wikidata_candid_map_typo.WikidataCandidateTypoMap.edits1", "wikidata_candid_map_typo.WikidataCandidateTypoMap.edits1"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.edits1", "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.edits1"], ["", "def", "edits2", "(", "self", ",", "word", ")", ":", "\n", "        ", "return", "set", "(", "e2", "for", "e1", "in", "self", ".", "edits1", "(", "word", ")", "for", "e2", "in", "self", ".", "edits1", "(", "e1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.edit_mention": [[39, 43], ["wikidata_candid_map_typo.WikidataCandidateTypoMap.edits1"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.edits1"], ["", "def", "edit_mention", "(", "self", ",", "mention", ")", ":", "\n", "        ", "edit_str_set", "=", "self", ".", "edits1", "(", "mention", ")", "\n", "valid_edit_str_set", "=", "[", "x", "for", "x", "in", "edit_str_set", "if", "x", "in", "self", ".", "alias_map", "]", "\n", "return", "valid_edit_str_set", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.gen_candid_spell_corrector": [[44, 61], ["TableAnnotator.Util.utils.check_cell_filtering", "wikidata_candid_map_typo.WikidataCandidateTypoMap.edit_mention", "len", "len", "str"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.check_cell_filtering", "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.edit_mention"], ["", "def", "gen_candid_spell_corrector", "(", "self", ",", "cell_text", ",", "strict_match_first", "=", "False", ",", "min_edit_len", "=", "10", ")", ":", "\n", "        ", "if", "check_cell_filtering", "(", "cell_text", ")", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "if", "strict_match_first", "or", "len", "(", "str", "(", "cell_text", ")", ")", "<=", "min_edit_len", ":", "\n", "            ", "if", "cell_text", "in", "self", ".", "alias_map", ":", "\n", "                ", "entities", "=", "[", "(", "x", ",", "cell_text", ")", "for", "x", "in", "self", ".", "alias_map", "[", "cell_text", "]", "]", "\n", "", "else", ":", "\n", "                ", "entities", "=", "[", "]", "\n", "", "if", "len", "(", "entities", ")", ">", "0", ":", "\n", "                ", "return", "entities", "\n", "", "", "valid_edit_str_set", "=", "self", ".", "edit_mention", "(", "cell_text", ")", "\n", "result", "=", "[", "]", "\n", "for", "mention", "in", "valid_edit_str_set", ":", "\n", "            ", "entities", "=", "[", "(", "x", ",", "mention", ")", "for", "x", "in", "self", ".", "alias_map", "[", "mention", "]", "]", "\n", "result", "+=", "entities", "\n", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.CTA_Evaluator.CTA_Evaluator.__init__": [[14, 22], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "round", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    `round` : Holds the round for which the evaluation is being done. \n    can be 1, 2...upto the number of rounds the challenge has.\n    Different rounds will mostly have different ground truth files.\n    \"\"\"", "\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.CTA_Evaluator.CTA_Evaluator._evaluate": [[23, 109], ["json.load", "json.load", "dict", "pandas.read_csv", "pandas.read_csv.iterrows", "set", "pandas.read_csv", "pandas.read_csv.iterrows", "print", "open", "open", "len", "os.path.join", "os.path.join", "len", "len", "Exception", "set.add", "annotation.startswith", "k.lower", "k.lower", "annotation.lower", "gt_type.lower", "annotation.lower", "int", "pow", "annotation.lower", "int", "pow"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv"], ["", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    ", "\"\"\"\n    `client_payload` will be a dict with (atleast) the following keys :\n      - submission_file_path : local file path of the submitted file\n      - aicrowd_submission_id : A unique id representing the submission\n      - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n    \"\"\"", "\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_ancestor", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\"GT/CTA/cta_gt_ancestor.json\"", ")", ")", ")", "\n", "gt_descendent", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\"GT/CTA/cta_gt_descendent.json\"", ")", ")", ")", "\n", "\n", "col_type", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'type'", ",", "'label'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'type'", ":", "str", ",", "'label'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "        ", "col", "=", "'%s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ")", "\n", "gt_type", "=", "row", "[", "'type'", "]", "\n", "col_type", "[", "col", "]", "=", "gt_type", "\n", "\n", "", "annotated_cols", "=", "set", "(", ")", "\n", "total_score", "=", "0", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'annotation'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'annotation'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "        ", "col", "=", "'%s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ")", "\n", "\n", "if", "col", "in", "col_type", ":", "\n", "            ", "if", "col", "in", "annotated_cols", ":", "\n", "# continue", "\n", "                ", "raise", "Exception", "(", "\"Duplicate columns in the submission file\"", ")", "\n", "", "else", ":", "\n", "                ", "annotated_cols", ".", "add", "(", "col", ")", "\n", "", "annotation", "=", "row", "[", "'annotation'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/entity/'", ")", ":", "\n", "                ", "annotation", "=", "'http://www.wikidata.org/entity/'", "+", "annotation", "\n", "", "gt_type", "=", "col_type", "[", "col", "]", "\n", "ancestor", "=", "gt_ancestor", "[", "gt_type", "]", "\n", "ancestor_keys", "=", "[", "k", ".", "lower", "(", ")", "for", "k", "in", "ancestor", "]", "\n", "descendent", "=", "gt_descendent", "[", "gt_type", "]", "\n", "descendent_keys", "=", "[", "k", ".", "lower", "(", ")", "for", "k", "in", "descendent", "]", "\n", "if", "annotation", ".", "lower", "(", ")", "==", "gt_type", ".", "lower", "(", ")", ":", "\n", "                ", "score", "=", "1.0", "\n", "", "elif", "annotation", ".", "lower", "(", ")", "in", "ancestor_keys", ":", "\n", "                ", "depth", "=", "int", "(", "ancestor", "[", "annotation", "]", ")", "\n", "if", "depth", "<=", "5", ":", "\n", "                    ", "score", "=", "pow", "(", "0.8", ",", "depth", ")", "\n", "", "else", ":", "\n", "                    ", "score", "=", "0", "\n", "", "", "elif", "annotation", ".", "lower", "(", ")", "in", "descendent_keys", ":", "\n", "                ", "depth", "=", "int", "(", "descendent", "[", "annotation", "]", ")", "\n", "if", "depth", "<=", "3", ":", "\n", "                    ", "score", "=", "pow", "(", "0.7", ",", "depth", ")", "\n", "", "else", ":", "\n", "                    ", "score", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "score", "=", "0", "\n", "", "total_score", "+=", "score", "\n", "\n", "", "", "precision", "=", "total_score", "/", "len", "(", "annotated_cols", ")", "if", "len", "(", "annotated_cols", ")", ">", "0", "else", "0", "\n", "recall", "=", "total_score", "/", "len", "(", "col_type", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n", "\"\"\"\n    Do something with your submitted file to come up\n    with a score and a secondary score.\n\n    if you want to report back an error to the user,\n    then you can simply do :\n      `raise Exception(\"YOUR-CUSTOM-ERROR\")`\n\n     You are encouraged to add as many validations as possible\n     to provide meaningful feedback to your users\n    \"\"\"", "\n", "_result_object", "=", "{", "\n", "\"score\"", ":", "main_score", ",", "\n", "\"score_secondary\"", ":", "secondary_score", "\n", "}", "\n", "return", "_result_object", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.CEA_Evaluator.CEA_Evaluator.__init__": [[13, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "round", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n    `round` : Holds the round for which the evaluation is being done. \n    can be 1, 2...upto the number of rounds the challenge has.\n    Different rounds will mostly have different ground truth files.\n    \"\"\"", "\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.CEA_Evaluator.CEA_Evaluator._evaluate": [[22, 80], ["dict", "pandas.read_csv", "pandas.read_csv.iterrows", "pandas.read_csv", "pandas.read_csv.iterrows", "print", "set", "set", "float", "len", "len", "float", "len", "len", "dict.keys", "Exception", "annotated_cells.add", "annotation.startswith", "annotation.lower", "gt_cell_ent[].lower", "correct_cells.add", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv"], ["", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"\n    `client_payload` will be a dict with (atleast) the following keys :\n      - submission_file_path : local file path of the submitted file\n      - aicrowd_submission_id : A unique id representing the submission\n      - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n    \"\"\"", "\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_cell_ent", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'row_id'", ",", "'entity'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'row_id'", ":", "str", ",", "'entity'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "            ", "cell", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ",", "row", "[", "'row_id'", "]", ")", "\n", "gt_cell_ent", "[", "cell", "]", "=", "row", "[", "'entity'", "]", "\n", "\n", "", "correct_cells", ",", "annotated_cells", "=", "set", "(", ")", ",", "set", "(", ")", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'row_id'", ",", "'entity'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'row_id'", ":", "str", ",", "'entity'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "            ", "cell", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ",", "row", "[", "'row_id'", "]", ")", "\n", "if", "cell", "in", "gt_cell_ent", ":", "\n", "                ", "if", "cell", "in", "annotated_cells", ":", "\n", "                    ", "raise", "Exception", "(", "\"Duplicate cells in the submission file\"", ")", "\n", "", "else", ":", "\n", "                    ", "annotated_cells", ".", "add", "(", "cell", ")", "\n", "\n", "", "annotation", "=", "row", "[", "'entity'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/entity/'", ")", ":", "\n", "                    ", "annotation", "=", "'http://www.wikidata.org/entity/'", "+", "annotation", "\n", "", "if", "annotation", ".", "lower", "(", ")", "==", "gt_cell_ent", "[", "cell", "]", ".", "lower", "(", ")", ":", "\n", "                    ", "correct_cells", ".", "add", "(", "cell", ")", "\n", "\n", "", "", "", "precision", "=", "float", "(", "len", "(", "correct_cells", ")", ")", "/", "len", "(", "annotated_cells", ")", "if", "len", "(", "annotated_cells", ")", ">", "0", "else", "0.0", "\n", "recall", "=", "float", "(", "len", "(", "correct_cells", ")", ")", "/", "len", "(", "gt_cell_ent", ".", "keys", "(", ")", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n", "\"\"\"\n    Do something with your submitted file to come up\n    with a score and a secondary score.\n\n    if you want to report back an error to the user,\n    then you can simply do :\n      `raise Exception(\"YOUR-CUSTOM-ERROR\")`\n\n     You are encouraged to add as many validations as possible\n     to provide meaningful feedback to your users\n    \"\"\"", "\n", "_result_object", "=", "{", "\n", "\"score\"", ":", "main_score", ",", "\n", "\"score_secondary\"", ":", "secondary_score", "\n", "}", "\n", "return", "_result_object", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.CPA_Evaluator.CPA_Evaluator.__init__": [[13, 21], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "round", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    `round` : Holds the round for which the evaluation is being done. \n    can be 1, 2...upto the number of rounds the challenge has.\n    Different rounds will mostly have different ground truth files.\n    \"\"\"", "\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.CPA_Evaluator.CPA_Evaluator._evaluate": [[22, 80], ["dict", "pandas.read_csv", "pandas.read_csv.iterrows", "pandas.read_csv", "pandas.read_csv.iterrows", "print", "set", "set", "float", "len", "len", "float", "len", "len", "dict.keys", "Exception", "annotated_cols.add", "annotation.startswith", "annotation.lower", "gt_cols_pro[].lower", "correct_cols.add", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv"], ["", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    ", "\"\"\"\n    `client_payload` will be a dict with (atleast) the following keys :\n      - submission_file_path : local file path of the submitted file\n      - aicrowd_submission_id : A unique id representing the submission\n      - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n    \"\"\"", "\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_cols_pro", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'sub_col_id'", ",", "'obj_col_id'", ",", "'property'", ",", "'label'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'sub_col_id'", ":", "str", ",", "'obj_col_id'", ":", "str", ",", "'property'", ":", "str", ",", "'label'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "        ", "cols", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'sub_col_id'", "]", ",", "row", "[", "'obj_col_id'", "]", ")", "\n", "gt_cols_pro", "[", "cols", "]", "=", "row", "[", "'property'", "]", "\n", "\n", "", "annotated_cols", ",", "correct_cols", "=", "set", "(", ")", ",", "set", "(", ")", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'sub_col_id'", ",", "'obj_col_id'", ",", "'property'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'sub_col_id'", ":", "str", ",", "'obj_row_id'", ":", "str", ",", "'property'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "        ", "cols", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'sub_col_id'", "]", ",", "row", "[", "'obj_col_id'", "]", ")", "\n", "if", "cols", "in", "gt_cols_pro", ":", "\n", "            ", "if", "cols", "in", "annotated_cols", ":", "\n", "# continue", "\n", "                ", "raise", "Exception", "(", "\"Duplicate column pairs in the submission file\"", ")", "\n", "", "else", ":", "\n", "                ", "annotated_cols", ".", "add", "(", "cols", ")", "\n", "", "annotation", "=", "row", "[", "'property'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/prop/direct/'", ")", ":", "\n", "                ", "annotation", "=", "'http://www.wikidata.org/prop/direct/'", "+", "annotation", "\n", "", "if", "annotation", ".", "lower", "(", ")", "==", "gt_cols_pro", "[", "cols", "]", ".", "lower", "(", ")", ":", "\n", "                ", "correct_cols", ".", "add", "(", "cols", ")", "\n", "\n", "", "", "", "precision", "=", "float", "(", "len", "(", "correct_cols", ")", ")", "/", "len", "(", "annotated_cols", ")", "if", "len", "(", "annotated_cols", ")", ">", "0", "else", "0.0", "\n", "recall", "=", "float", "(", "len", "(", "correct_cols", ")", ")", "/", "len", "(", "gt_cols_pro", ".", "keys", "(", ")", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n", "\"\"\"\n    Do something with your submitted file to come up\n    with a score and a secondary score.\n\n    if you want to report back an error to the user,\n    then you can simply do :\n      `raise Exception(\"YOUR-CUSTOM-ERROR\")`\n\n     You are encouraged to add as many validations as possible\n     to provide meaningful feedback to your users\n    \"\"\"", "\n", "_result_object", "=", "{", "\n", "\"score\"", ":", "main_score", ",", "\n", "\"score_secondary\"", ":", "secondary_score", "\n", "}", "\n", "return", "_result_object", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.evaluator.TableAnnotationEvaluator.__init__": [[21, 50], ["CEA_Evaluator", "CPA_Evaluator", "CTA_Evaluator"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "task_name", ",", "round", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    `round` : Holds the round for which the evaluation is being done. \n    can be 1, 2...upto the number of rounds the challenge has.\n    Different rounds will mostly have different ground truth files.\n\n    `task_name` has to be one of \"CEA\", \"CPA\", \"CTA\"\n    \"\"\"", "\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "self", ".", "task_name", "=", "task_name", "\n", "valid_task_names", "=", "[", "\"CEA\"", ",", "\"CPA\"", ",", "\"CTA\"", "]", "\n", "assert", "self", ".", "task_name", "in", "valid_task_names", ",", "\"task_name has to be one of %s \"", ".", "format", "(", "\",\"", ".", "join", "(", "valid_task_names", ")", ")", "\n", "\n", "if", "self", ".", "task_name", "==", "\"CEA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CEA_Evaluator", "(", "\n", "self", ".", "answer_file_path", ",", "\n", "round", "=", "self", ".", "round", "\n", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"CPA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CPA_Evaluator", "(", "\n", "self", ".", "answer_file_path", ",", "\n", "round", "=", "self", ".", "round", "\n", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"CTA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CTA_Evaluator", "(", "\n", "self", ".", "answer_file_path", ",", "\n", "round", "=", "self", ".", "round", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020.evaluator.TableAnnotationEvaluator._evaluate": [[52, 56], ["evaluator.TableAnnotationEvaluator.evaluator._evaluate"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.evaluator.TableAnnotationEvaluator._evaluate"], ["", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    ", "return", "self", ".", "evaluator", ".", "_evaluate", "(", "\n", "client_payload", ",", "\n", "_context", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.CTA_Evaluator.CTA_Evaluator.__init__": [[17, 25], ["None"], "methods", ["None"], ["\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.CTA_Evaluator.CTA_Evaluator._evaluate": [[26, 121], ["json.load", "json.load", "pandas.read_csv", "pandas.read_csv.iterrows", "pandas.read_csv", "pandas.read_csv.iterrows", "get_tables_categories().items", "open", "open", "set", "dict", "gt_cols.add", "row[].split", "dict", "set", "os.path.join", "os.path.join", "dict", "dict", "get_tables_categories", "len", "sum", "print", "Exception", "annotated_cols.add", "dict.update", "dict.update", "a.lower", "a.lower", "annotation.lower", "correct_cols.items", "c_cols.values", "len", "gt[].isin", "annotation.startswith", "dict.items", "dict.items", "x.lower", "annotation.lower", "int", "len", "len", "pow", "annotation.lower", "int", "pow", "annotation.lower", "annotation.lower"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.TT.get_tables_categories"], ["\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_ancestor", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\"GT/CTA/cta_gt_ancestor.json\"", ")", ")", ")", "\n", "gt_descendent", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\"GT/CTA/cta_gt_descendent.json\"", ")", ")", ")", "\n", "\n", "col_type", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'type'", ",", "'label'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'type'", ":", "str", ",", "'label'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "        ", "col", "=", "'%s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ")", "\n", "gt_type", "=", "row", "[", "'type'", "]", "\n", "col_type", "[", "col", "]", "=", "gt_type", "\n", "\n", "", "annotated_cols", "=", "set", "(", ")", "\n", "total_score", "=", "0", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'annotation'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'annotation'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "        ", "col", "=", "'%s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ")", "\n", "\n", "if", "col", "in", "col_type", ":", "\n", "            ", "if", "col", "in", "annotated_cols", ":", "\n", "# continue", "\n", "                ", "raise", "Exception", "(", "\"Duplicate columns in the submission file\"", ")", "\n", "", "else", ":", "\n", "                ", "annotated_cols", ".", "add", "(", "col", ")", "\n", "", "annotation", "=", "row", "[", "'annotation'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/entity/'", ")", ":", "\n", "                ", "annotation", "=", "'http://www.wikidata.org/entity/'", "+", "annotation", "\n", "", "gt_type", "=", "col_type", "[", "col", "]", "\n", "ancestor", "=", "gt_ancestor", "[", "gt_type", "]", "\n", "ancestor_keys", "=", "[", "k", ".", "lower", "(", ")", "for", "k", "in", "ancestor", "]", "\n", "descendent", "=", "gt_descendent", "[", "gt_type", "]", "\n", "descendent_keys", "=", "[", "k", ".", "lower", "(", ")", "for", "k", "in", "descendent", "]", "\n", "if", "annotation", ".", "lower", "(", ")", "==", "gt_type", ".", "lower", "(", ")", ":", "\n", "                ", "score", "=", "1.0", "\n", "", "elif", "annotation", ".", "lower", "(", ")", "in", "ancestor_keys", ":", "\n", "                ", "depth", "=", "int", "(", "ancestor", "[", "annotation", "]", ")", "\n", "if", "depth", "<=", "5", ":", "\n", "                    ", "score", "=", "pow", "(", "0.8", ",", "depth", ")", "\n", "", "else", ":", "\n", "                    ", "score", "=", "0", "\n", "", "", "elif", "annotation", ".", "lower", "(", ")", "in", "descendent_keys", ":", "\n", "                ", "depth", "=", "int", "(", "descendent", "[", "annotation", "]", ")", "\n", "if", "depth", "<=", "3", ":", "\n", "                    ", "score", "=", "pow", "(", "0.7", ",", "depth", ")", "\n", "", "else", ":", "\n", "                    ", "score", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "score", "=", "0", "\n", "", "total_score", "+=", "score", "\n", "\n", "", "", "precision", "=", "total_score", "/", "len", "(", "annotated_cols", ")", "if", "len", "(", "annotated_cols", ")", ">", "0", "else", "0", "\n", "recall", "=", "total_score", "/", "len", "(", "col_type", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n", "\"\"\"\n    Do something with your submitted file to come up\n    with a score and a secondary score.\n\n    if you want to report back an error to the user,\n    then you can simply do :\n      `raise Exception(\"YOUR-CUSTOM-ERROR\")`\n\n     You are encouraged to add as many validations as possible\n     to provide meaningful feedback to your users\n    \"\"\"", "\n", "_result_object", "=", "{", "\n", "\"score\"", ":", "main_score", ",", "\n", "\"score_secondary\"", ":", "secondary_score", "\n", "}", "\n", "return", "_result_object", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--round\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--split\"", ",", "type", "=", "str", ",", "default", "=", "\"all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "split", "==", "\"all\"", ":", "\n", "        ", "answer_file_path", "=", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\n", "\"GT/CTA/CTA_Round{}_gt.csv\"", ".", "format", "(", "args", ".", "round", ")", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.CEA_Evaluator.CEA_Evaluator.__init__": [[16, 24], ["None"], "methods", ["None"], ["\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.CEA_Evaluator.CEA_Evaluator._evaluate": [[25, 104], ["dict", "pandas.read_csv", "pandas.read_csv.iterrows", "pandas.read_csv", "pandas.read_csv.iterrows", "get_tables_categories().items", "row[].lower().split", "set", "set", "get_tables_categories", "len", "print", "row[].lower", "Exception", "annotated_cells.add", "float", "len", "gt[].isin", "correct_cells.add", "annotation.startswith", "annotation.lower", "correct_cells.add", "len", "float", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.TT.get_tables_categories"], ["\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_cell_ent", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'row_id'", ",", "'entity'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'row_id'", ":", "str", ",", "'entity'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "            ", "cell", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ",", "row", "[", "'row_id'", "]", ")", "\n", "gt_cell_ent", "[", "cell", "]", "=", "row", "[", "'entity'", "]", "\n", "\n", "", "correct_cells", ",", "annotated_cells", "=", "set", "(", ")", ",", "set", "(", ")", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'row_id'", ",", "'entity'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'row_id'", ":", "str", ",", "'entity'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "            ", "cell", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ",", "row", "[", "'row_id'", "]", ")", "\n", "if", "cell", "in", "gt_cell_ent", ":", "\n", "                ", "if", "cell", "in", "annotated_cells", ":", "\n", "                    ", "raise", "Exception", "(", "\"Duplicate cells in the submission file\"", ")", "\n", "", "else", ":", "\n", "                    ", "annotated_cells", ".", "add", "(", "cell", ")", "\n", "\n", "", "annotation", "=", "row", "[", "'entity'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/entity/'", ")", ":", "\n", "                    ", "annotation", "=", "'http://www.wikidata.org/entity/'", "+", "annotation", "\n", "", "if", "annotation", ".", "lower", "(", ")", "==", "gt_cell_ent", "[", "cell", "]", ".", "lower", "(", ")", ":", "\n", "                    ", "correct_cells", ".", "add", "(", "cell", ")", "\n", "\n", "", "", "", "precision", "=", "float", "(", "len", "(", "correct_cells", ")", ")", "/", "len", "(", "annotated_cells", ")", "if", "len", "(", "annotated_cells", ")", ">", "0", "else", "0.0", "\n", "recall", "=", "float", "(", "len", "(", "correct_cells", ")", ")", "/", "len", "(", "gt_cell_ent", ".", "keys", "(", ")", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n", "\"\"\"\n    Do something with your submitted file to come up\n    with a score and a secondary score.\n\n    if you want to report back an error to the user,\n    then you can simply do :\n      `raise Exception(\"YOUR-CUSTOM-ERROR\")`\n\n     You are encouraged to add as many validations as possible\n     to provide meaningful feedback to your users\n    \"\"\"", "\n", "_result_object", "=", "{", "\n", "\"score\"", ":", "main_score", ",", "\n", "\"score_secondary\"", ":", "secondary_score", "\n", "}", "\n", "return", "_result_object", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--round\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--split\"", ",", "type", "=", "str", ",", "default", "=", "\"all\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "split", "==", "\"all\"", ":", "\n", "        ", "answer_file_path", "=", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\n", "\"GT/CEA/CEA_Round{}_gt.csv\"", ".", "format", "(", "args", ".", "round", ")", ")", "\n", "", "else", ":", "\n", "        ", "answer_file_path", "=", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\n", "\"GT/CEA/dev/CEA_Round{}_dev_gt.csv\"", ".", "format", "(", "args", ".", "round", ")", ")", "\n", "\n", "# Lets assume the the ground_truth is a CSV file", "\n", "# and is present at data/ground_truth.csv", "\n", "# and a sample submission is present at data/sample_submission.csv", "\n", "\n", "", "results", "=", "PrettyTable", "(", ")", "\n", "results", ".", "field_names", "=", "[", "\n", "\"submission_name\"", ",", "\n", "\"score\"", ",", "\n", "\"score_secondary\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.TT._is_table_in_cat": [[24, 33], ["None"], "function", ["None"], ["def", "_is_table_in_cat", "(", "x", ",", "whitelist", ",", "blacklist", ")", ":", "\n", "    ", "b", "=", "True", "\n", "for", "i", "in", "whitelist", ":", "\n", "        ", "if", "not", "(", "b", "and", "(", "i", "in", "x", ")", ")", ":", "\n", "            ", "return", "False", "\n", "", "", "for", "e", "in", "blacklist", ":", "\n", "        ", "if", "not", "(", "b", "and", "(", "e", "not", "in", "x", ")", ")", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.TT.get_tables_categories": [[35, 42], ["json.load", "open", "os.path.join", "json.load.items", "TT._is_table_in_cat"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.TT._is_table_in_cat"], ["", "def", "get_tables_categories", "(", ")", ":", "\n", "    ", "table_map", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "global_config", ".", "tough_table_benchmark_dir", ",", "\"gt/filename_map.json\"", ")", ",", "'r'", ")", ")", "\n", "categories", "=", "{", "}", "\n", "for", "cat", "in", "_TABLE_CATEGORIES", ":", "\n", "        ", "categories", "[", "cat", "]", "=", "[", "fake_id", "for", "fake_id", ",", "tab_id", "in", "table_map", ".", "items", "(", ")", "\n", "if", "_is_table_in_cat", "(", "tab_id", ",", "*", "_TABLE_CATEGORIES", "[", "cat", "]", ")", "]", "\n", "", "return", "categories", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.evaluator.TableAnnotationEvaluator.__init__": [[23, 47], ["CEA_Evaluator", "CTA_Evaluator"], "methods", ["None"], ["\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "self", ".", "task_name", "=", "task_name", "\n", "valid_task_names", "=", "[", "\"CEA\"", ",", "\"CPA\"", ",", "\"CTA\"", "]", "\n", "assert", "self", ".", "task_name", "in", "valid_task_names", ",", "\"task_name has to be one of %s \"", ".", "format", "(", "\",\"", ".", "join", "(", "valid_task_names", ")", ")", "\n", "\n", "if", "self", ".", "task_name", "==", "\"CEA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CEA_Evaluator", "(", "\n", "self", ".", "answer_file_path", ",", "\n", "round", "=", "self", ".", "round", "\n", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"CPA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CPA_Evaluator", "(", "\n", "self", ".", "answer_file_path", ",", "\n", "round", "=", "self", ".", "round", "\n", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"CTA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CTA_Evaluator", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2020_2T.evaluator.TableAnnotationEvaluator._evaluate": [[49, 53], ["evaluator.TableAnnotationEvaluator.evaluator._evaluate"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.evaluator.TableAnnotationEvaluator._evaluate"], ["round", "=", "self", ".", "round", "\n", ")", "\n", "\n", "", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    ", "return", "self", ".", "evaluator", ".", "_evaluate", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.CTA_Evaluator.CTA_Evaluator.__init__": [[10, 18], ["None"], "methods", ["None"], ["from", "GlobalConfig", "import", "global_config", "\n", "\n", "\n", "class", "CTA_Evaluator", ":", "\n", "  ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "round", "=", "1", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.CTA_Evaluator.CTA_Evaluator._evaluate": [[19, 110], ["pandas.read_csv", "pandas.read_csv.iterrows", "set", "pandas.read_csv", "pandas.read_csv.iterrows", "set", "dict", "dict", "row[].lower().split", "row[].lower().split", "cols.add", "set", "float", "len", "Exception", "set.add", "row[].lower().split", "len", "float", "float", "row[].lower", "row[].lower", "row[].lower"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv"], ["\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    ", "\"\"\"\n    `client_payload` will be a dict with (atleast) the following keys :\n      - submission_file_path : local file path of the submitted file\n      - aicrowd_submission_id : A unique id representing the submission\n      - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n    \"\"\"", "\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_ancestor", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\"GT/CTA/cta_gt_ancestor.json\"", ")", ")", ")", "\n", "gt_descendent", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "global_config", ".", "semtab_benchmark_dir", ",", "\"GT/CTA/cta_gt_descendent.json\"", ")", ")", ")", "\n", "\n", "col_type", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'type'", ",", "'label'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'type'", ":", "str", ",", "'label'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "        ", "col", "=", "'%s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ")", "\n", "gt_type", "=", "row", "[", "'type'", "]", "\n", "col_type", "[", "col", "]", "=", "gt_type", "\n", "\n", "", "annotated_cols", "=", "set", "(", ")", "\n", "total_score", "=", "0", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'annotation'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'annotation'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "        ", "col", "=", "'%s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ")", "\n", "\n", "if", "col", "in", "col_type", ":", "\n", "            ", "if", "col", "in", "annotated_cols", ":", "\n", "# continue", "\n", "                ", "raise", "Exception", "(", "\"Duplicate columns in the submission file\"", ")", "\n", "", "else", ":", "\n", "                ", "annotated_cols", ".", "add", "(", "col", ")", "\n", "", "annotation", "=", "row", "[", "'annotation'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/entity/'", ")", ":", "\n", "                ", "annotation", "=", "'http://www.wikidata.org/entity/'", "+", "annotation", "\n", "", "gt_type", "=", "col_type", "[", "col", "]", "\n", "ancestor", "=", "gt_ancestor", "[", "gt_type", "]", "\n", "ancestor_keys", "=", "[", "k", ".", "lower", "(", ")", "for", "k", "in", "ancestor", "]", "\n", "descendent", "=", "gt_descendent", "[", "gt_type", "]", "\n", "descendent_keys", "=", "[", "k", ".", "lower", "(", ")", "for", "k", "in", "descendent", "]", "\n", "if", "annotation", ".", "lower", "(", ")", "==", "gt_type", ".", "lower", "(", ")", ":", "\n", "                ", "score", "=", "1.0", "\n", "", "elif", "annotation", ".", "lower", "(", ")", "in", "ancestor_keys", ":", "\n", "                ", "depth", "=", "int", "(", "ancestor", "[", "annotation", "]", ")", "\n", "if", "depth", "<=", "5", ":", "\n", "                    ", "score", "=", "pow", "(", "0.8", ",", "depth", ")", "\n", "", "else", ":", "\n", "                    ", "score", "=", "0", "\n", "", "", "elif", "annotation", ".", "lower", "(", ")", "in", "descendent_keys", ":", "\n", "                ", "depth", "=", "int", "(", "descendent", "[", "annotation", "]", ")", "\n", "if", "depth", "<=", "3", ":", "\n", "                    ", "score", "=", "pow", "(", "0.7", ",", "depth", ")", "\n", "", "else", ":", "\n", "                    ", "score", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "score", "=", "0", "\n", "", "total_score", "+=", "score", "\n", "\n", "", "", "precision", "=", "total_score", "/", "len", "(", "annotated_cols", ")", "if", "len", "(", "annotated_cols", ")", ">", "0", "else", "0", "\n", "recall", "=", "total_score", "/", "len", "(", "col_type", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n", "\"\"\"\n    Do something with your submitted file to come up\n    with a score and a secondary score.\n\n    if you want to report back an error to the user,\n    then you can simply do :\n      `raise Exception(\"YOUR-CUSTOM-ERROR\")`\n\n     You are encouraged to add as many validations as possible\n     to provide meaningful feedback to your users\n    \"\"\"", "\n", "_result_object", "=", "{", "\n", "\"score\"", ":", "main_score", ",", "\n", "\"score_secondary\"", ":", "secondary_score", "\n", "}", "\n", "return", "_result_object", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.CEA_Evaluator.CEA_Evaluator.__init__": [[9, 17], ["None"], "methods", ["None"], ["from", "GlobalConfig", "import", "global_config", "\n", "\n", "\n", "class", "CEA_Evaluator", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "round", "=", "1", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.CEA_Evaluator.CEA_Evaluator._evaluate": [[18, 73], ["dict", "pandas.read_csv", "pandas.read_csv.iterrows", "pandas.read_csv", "pandas.read_csv.iterrows", "row[].lower().split", "set", "set", "float", "len", "row[].lower", "len", "float", "len", "len", "dict.keys", "row[].lower", "Exception", "annotated_cells.add", "correct_cells.add", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv"], ["\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"\n    `client_payload` will be a dict with (atleast) the following keys :\n      - submission_file_path : local file path of the submitted file\n      - aicrowd_submission_id : A unique id representing the submission\n      - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n    \"\"\"", "\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_cell_ent", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'row_id'", ",", "'entity'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'row_id'", ":", "str", ",", "'entity'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "            ", "cell", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ",", "row", "[", "'row_id'", "]", ")", "\n", "gt_cell_ent", "[", "cell", "]", "=", "row", "[", "'entity'", "]", "\n", "\n", "", "correct_cells", ",", "annotated_cells", "=", "set", "(", ")", ",", "set", "(", ")", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'col_id'", ",", "'row_id'", ",", "'entity'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'col_id'", ":", "str", ",", "'row_id'", ":", "str", ",", "'entity'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "            ", "cell", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'col_id'", "]", ",", "row", "[", "'row_id'", "]", ")", "\n", "if", "cell", "in", "gt_cell_ent", ":", "\n", "                ", "if", "cell", "in", "annotated_cells", ":", "\n", "                    ", "raise", "Exception", "(", "\"Duplicate cells in the submission file\"", ")", "\n", "", "else", ":", "\n", "                    ", "annotated_cells", ".", "add", "(", "cell", ")", "\n", "\n", "", "annotation", "=", "row", "[", "'entity'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/entity/'", ")", ":", "\n", "                    ", "annotation", "=", "'http://www.wikidata.org/entity/'", "+", "annotation", "\n", "", "if", "annotation", ".", "lower", "(", ")", "==", "gt_cell_ent", "[", "cell", "]", ".", "lower", "(", ")", ":", "\n", "                    ", "correct_cells", ".", "add", "(", "cell", ")", "\n", "\n", "", "", "", "precision", "=", "float", "(", "len", "(", "correct_cells", ")", ")", "/", "len", "(", "annotated_cells", ")", "if", "len", "(", "annotated_cells", ")", ">", "0", "else", "0.0", "\n", "recall", "=", "float", "(", "len", "(", "correct_cells", ")", ")", "/", "len", "(", "gt_cell_ent", ".", "keys", "(", ")", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.CPA_Evaluator.CPA_Evaluator.__init__": [[9, 17], ["None"], "methods", ["None"], ["from", "GlobalConfig", "import", "global_config", "\n", "\n", "\n", "class", "CPA_Evaluator", ":", "\n", "  ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "round", "=", "1", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.CPA_Evaluator.CPA_Evaluator._evaluate": [[18, 71], ["dict", "pandas.read_csv", "pandas.read_csv.iterrows", "pandas.read_csv", "pandas.read_csv.iterrows", "row[].lower().split", "set", "set", "float", "len", "len", "float", "len", "len", "dict.keys", "row[].lower", "Exception", "annotated_cols.add", "row[].lower", "correct_cols.add", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv"], ["\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "\n", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    ", "\"\"\"\n    `client_payload` will be a dict with (atleast) the following keys :\n      - submission_file_path : local file path of the submitted file\n      - aicrowd_submission_id : A unique id representing the submission\n      - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n    \"\"\"", "\n", "submission_file_path", "=", "client_payload", "[", "\"submission_file_path\"", "]", "\n", "aicrowd_submission_id", "=", "client_payload", "[", "\"aicrowd_submission_id\"", "]", "\n", "aicrowd_participant_uid", "=", "client_payload", "[", "\"aicrowd_participant_id\"", "]", "\n", "\n", "gt_cols_pro", "=", "dict", "(", ")", "\n", "gt", "=", "pd", ".", "read_csv", "(", "self", ".", "answer_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'sub_col_id'", ",", "'obj_col_id'", ",", "'property'", ",", "'label'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'sub_col_id'", ":", "str", ",", "'obj_col_id'", ":", "str", ",", "'property'", ":", "str", ",", "'label'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "gt", ".", "iterrows", "(", ")", ":", "\n", "        ", "cols", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'sub_col_id'", "]", ",", "row", "[", "'obj_col_id'", "]", ")", "\n", "gt_cols_pro", "[", "cols", "]", "=", "row", "[", "'property'", "]", "\n", "\n", "", "annotated_cols", ",", "correct_cols", "=", "set", "(", ")", ",", "set", "(", ")", "\n", "sub", "=", "pd", ".", "read_csv", "(", "submission_file_path", ",", "delimiter", "=", "','", ",", "names", "=", "[", "'tab_id'", ",", "'sub_col_id'", ",", "'obj_col_id'", ",", "'property'", "]", ",", "\n", "dtype", "=", "{", "'tab_id'", ":", "str", ",", "'sub_col_id'", ":", "str", ",", "'obj_row_id'", ":", "str", ",", "'property'", ":", "str", "}", ",", "keep_default_na", "=", "False", ")", "\n", "for", "index", ",", "row", "in", "sub", ".", "iterrows", "(", ")", ":", "\n", "        ", "cols", "=", "'%s %s %s'", "%", "(", "row", "[", "'tab_id'", "]", ",", "row", "[", "'sub_col_id'", "]", ",", "row", "[", "'obj_col_id'", "]", ")", "\n", "if", "cols", "in", "gt_cols_pro", ":", "\n", "            ", "if", "cols", "in", "annotated_cols", ":", "\n", "# continue", "\n", "                ", "raise", "Exception", "(", "\"Duplicate column pairs in the submission file\"", ")", "\n", "", "else", ":", "\n", "                ", "annotated_cols", ".", "add", "(", "cols", ")", "\n", "", "annotation", "=", "row", "[", "'property'", "]", "\n", "if", "not", "annotation", ".", "startswith", "(", "'http://www.wikidata.org/prop/direct/'", ")", ":", "\n", "                ", "annotation", "=", "'http://www.wikidata.org/prop/direct/'", "+", "annotation", "\n", "", "if", "annotation", ".", "lower", "(", ")", "==", "gt_cols_pro", "[", "cols", "]", ".", "lower", "(", ")", ":", "\n", "                ", "correct_cols", ".", "add", "(", "cols", ")", "\n", "\n", "", "", "", "precision", "=", "float", "(", "len", "(", "correct_cols", ")", ")", "/", "len", "(", "annotated_cols", ")", "if", "len", "(", "annotated_cols", ")", ">", "0", "else", "0.0", "\n", "recall", "=", "float", "(", "len", "(", "correct_cols", ")", ")", "/", "len", "(", "gt_cols_pro", ".", "keys", "(", ")", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "(", "precision", "+", "recall", ")", ">", "0", "else", "0.0", "\n", "main_score", "=", "f1", "\n", "secondary_score", "=", "precision", "\n", "print", "(", "'%.3f %.3f %.3f'", "%", "(", "f1", ",", "precision", ",", "recall", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.evaluator.TableAnnotationEvaluator.__init__": [[18, 47], ["CEA_Evaluator", "CPA_Evaluator", "CTA_Evaluator"], "methods", ["None"], ["\n", "\n", "", "class", "TableAnnotationEvaluator", ":", "\n", "  ", "def", "__init__", "(", "self", ",", "answer_file_path", ",", "task_name", ",", "round", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    `round` : Holds the round for which the evaluation is being done. \n    can be 1, 2...upto the number of rounds the challenge has.\n    Different rounds will mostly have different ground truth files.\n\n    `task_name` has to be one of \"CEA\", \"CPA\", \"CTA\"\n    \"\"\"", "\n", "self", ".", "answer_file_path", "=", "answer_file_path", "\n", "self", ".", "round", "=", "round", "\n", "self", ".", "task_name", "=", "task_name", "\n", "valid_task_names", "=", "[", "\"CEA\"", ",", "\"CPA\"", ",", "\"CTA\"", "]", "\n", "assert", "self", ".", "task_name", "in", "valid_task_names", ",", "\"task_name has to be one of %s \"", ".", "format", "(", "\",\"", ".", "join", "(", "valid_task_names", ")", ")", "\n", "\n", "if", "self", ".", "task_name", "==", "\"CEA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CEA_Evaluator", "(", "\n", "self", ".", "answer_file_path", ",", "\n", "round", "=", "self", ".", "round", "\n", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"CPA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CPA_Evaluator", "(", "\n", "self", ".", "answer_file_path", ",", "\n", "round", "=", "self", ".", "round", "\n", ")", "\n", "", "elif", "self", ".", "task_name", "==", "\"CTA\"", ":", "\n", "        ", "self", ".", "evaluator", "=", "CTA_Evaluator", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.evaluator.TableAnnotationEvaluator._evaluate": [[49, 53], ["evaluator.TableAnnotationEvaluator.evaluator._evaluate"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Evaluator_2019.evaluator.TableAnnotationEvaluator._evaluate"], ["round", "=", "self", ".", "round", "\n", ")", "\n", "\n", "", "", "def", "_evaluate", "(", "self", ",", "client_payload", ",", "_context", "=", "{", "}", ")", ":", "\n", "    ", "return", "self", ".", "evaluator", ".", "_evaluate", "(", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.merge_results": [[18, 23], ["None"], "function", ["None"], ["def", "merge_results", "(", "all_lines", ")", ":", "\n", "    ", "all_table_out_lines", "=", "[", "]", "\n", "for", "x", "in", "all_lines", ":", "\n", "        ", "all_table_out_lines", "+=", "x", "\n", "", "return", "all_table_out_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.run": [[26, 31], ["print", "func", "print", "multiprocessing.current_process", "multiprocessing.current_process"], "function", ["None"], ["", "def", "run", "(", "func", ",", "args", ")", ":", "\n", "    ", "print", "(", "'{} process running'", ".", "format", "(", "current_process", "(", ")", ".", "name", ")", ")", "\n", "ans", "=", "func", "(", "*", "args", ")", "\n", "print", "(", "'{} process ok'", ".", "format", "(", "current_process", "(", ")", ".", "name", ")", ")", "\n", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.worker": [[33, 53], ["task_queue.get_nowait", "print", "multi_process_offline_predict.run", "done_queue.put", "print"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.run"], ["", "def", "worker", "(", "task_queue", ",", "done_queue", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "'''\n                try to get task from the queue. get_nowait() function will \n                raise queue.Empty exception if the queue is empty. \n                queue(False) function would do the same task also.\n            '''", "\n", "func", ",", "args", "=", "task_queue", ".", "get_nowait", "(", ")", "\n", "print", "(", "'Start new process'", ")", "\n", "", "except", "queue", ".", "Empty", ":", "\n", "            ", "print", "(", "'Error'", ")", "\n", "break", "\n", "", "else", ":", "\n", "            ", "'''\n                if no exception has been raised, add the task completion \n                message to task_that_are_done queue\n            '''", "\n", "result", "=", "run", "(", "func", ",", "args", ")", "\n", "done_queue", ".", "put", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.detect_one_table": [[55, 67], ["detector.detect_single_table"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.detect_single_table"], ["", "", "", "def", "detect_one_table", "(", "detector", ",", "params", ",", "table", ")", ":", "\n", "    ", "output_tab", "=", "detector", ".", "detect_single_table", "(", "table", ",", "\n", "keep_N", "=", "params", "[", "\"keep_N\"", "]", ",", "\n", "alpha", "=", "params", "[", "\"alpha\"", "]", ",", "\n", "beta", "=", "params", "[", "\"beta\"", "]", ",", "\n", "gamma", "=", "params", "[", "\"gamma\"", "]", ",", "\n", "topk", "=", "params", "[", "\"topk\"", "]", ",", "\n", "init_prune_topk", "=", "params", "[", "\"init_prune_topk\"", "]", ",", "\n", "max_iter", "=", "params", "[", "\"max_iter\"", "]", ",", "\n", "min_final_diff", "=", "params", "[", "\"min_final_diff\"", "]", ",", "\n", "row_feature_only", "=", "params", "[", "\"row_feature_only\"", "]", ")", "\n", "return", "output_tab", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.slice_table": [[69, 75], ["len", "range", "math.ceil", "tables.append"], "function", ["None"], ["", "def", "slice_table", "(", "table", ",", "max_row_size", "=", "20", ")", ":", "\n", "    ", "row_size", "=", "len", "(", "table", ")", "\n", "tables", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "math", ".", "ceil", "(", "row_size", "/", "max_row_size", ")", ")", ":", "\n", "        ", "tables", ".", "append", "(", "table", "[", "i", "*", "max_row_size", ":", "(", "i", "+", "1", ")", "*", "max_row_size", "]", ")", "\n", "", "return", "tables", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.split_mini_tables": [[77, 92], ["open", "enumerate", "line.strip().split", "json.loads", "multi_process_offline_predict.slice_table", "enumerate", "table_str.strip", "all_mini_input_tabs.append", "line.strip", "json.dumps"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.slice_table"], ["", "def", "split_mini_tables", "(", "in_fn", ",", "max_row_size", "=", "10", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "all_mini_input_tabs", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "fp", ")", ":", "\n", "            ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "tab_id", ",", "table_str", "=", "words", "[", "0", "]", ",", "words", "[", "1", "]", "\n", "big_table", "=", "json", ".", "loads", "(", "table_str", ".", "strip", "(", ")", ")", "\n", "tables", "=", "slice_table", "(", "big_table", ",", "max_row_size", "=", "max_row_size", ")", "\n", "for", "idx", ",", "mini_tab", "in", "enumerate", "(", "tables", ")", ":", "\n", "# input_tab = InputTable(mini_tab, \"{}||{}\".format(tab_id, idx))", "\n", "# all_mini_input_tabs.append(input_tab)", "\n", "                ", "all_mini_input_tabs", ".", "append", "(", "\"{}\\t{}\\n\"", ".", "format", "(", "\"{}||{}\"", ".", "format", "(", "tab_id", ",", "idx", ")", ",", "json", ".", "dumps", "(", "mini_tab", ")", ")", ")", "\n", "# if i > 50:", "\n", "#     break", "\n", "", "", "return", "all_mini_input_tabs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.divide_mini_tables": [[94, 101], ["math.ceil", "range", "part_tables.append", "len", "sum", "len", "len"], "function", ["None"], ["", "", "def", "divide_mini_tables", "(", "all_mini_input_tabs", ",", "items_per_process", ")", ":", "\n", "    ", "n_parts", "=", "math", ".", "ceil", "(", "len", "(", "all_mini_input_tabs", ")", "/", "items_per_process", ")", "\n", "part_tables", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_parts", ")", ":", "\n", "        ", "part_tables", ".", "append", "(", "all_mini_input_tabs", "[", "i", "*", "items_per_process", ":", "(", "i", "+", "1", ")", "*", "items_per_process", "]", ")", "\n", "", "assert", "(", "len", "(", "all_mini_input_tabs", ")", "==", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "part_tables", "]", ")", ")", "\n", "return", "part_tables", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.detect_multi_tables": [[103, 139], ["datetime.datetime.now", "TableAnnotator.Detect.table_annotator.LinkingPark", "datetime.datetime.now", "print", "print", "tqdm.tqdm", "datetime.datetime.now", "print", "datetime.datetime.now", "print", "print", "print", "open", "multi_process_offline_predict.detect_one_table", "detect_one_table.dump_one_tab", "result_lines.append", "open", "fp.writelines", "print", "line.strip().split", "json.loads", "part_tables.append", "multiprocessing.current_process", "TableAnnotator.Util.utils.InputTable", "json.dumps", "multiprocessing.current_process", "multiprocessing.current_process", "line.strip", "multiprocessing.current_process"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.detect_one_table", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.dump_one_tab"], ["", "def", "detect_multi_tables", "(", "params", ",", "in_fn", ",", "out_fn", ")", ":", "\n", "    ", "t1", "=", "datetime", ".", "now", "(", ")", "\n", "detector", "=", "LinkingPark", "(", "params", ")", "\n", "t2", "=", "datetime", ".", "now", "(", ")", "\n", "model_built_time", "=", "(", "t2", "-", "t1", ")", ".", "total_seconds", "(", ")", "\n", "print", "(", "\"{} model built time: {} seconds\"", ".", "format", "(", "current_process", "(", ")", ".", "name", ",", "model_built_time", ")", ")", "\n", "print", "(", "\"detector building done.\"", ")", "\n", "num", "=", "0", "\n", "result_lines", "=", "[", "]", "\n", "part_tables", "=", "[", "]", "\n", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "tab_id", "=", "words", "[", "0", "]", "\n", "sub_tab", "=", "json", ".", "loads", "(", "words", "[", "1", "]", ")", "\n", "part_tables", ".", "append", "(", "InputTable", "(", "sub_tab", ",", "tab_id", ")", ")", "\n", "\n", "", "", "for", "input_tab", "in", "tqdm", "(", "part_tables", ")", ":", "\n", "        ", "output_tab", "=", "detect_one_table", "(", "detector", ",", "params", ",", "input_tab", ")", "\n", "small_dump_tab", "=", "output_tab", ".", "dump_one_tab", "(", ")", "\n", "num", "+=", "1", "\n", "# if num % 100 == 0:", "\n", "#     print(\"predict {} mini tables...\".format(num))", "\n", "result_lines", ".", "append", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "small_dump_tab", ")", ")", ")", "\n", "", "t3", "=", "datetime", ".", "now", "(", ")", "\n", "model_run_and_format_time", "=", "(", "t3", "-", "t2", ")", ".", "total_seconds", "(", ")", "\n", "print", "(", "\"{} model run and format time: {} seconds\"", ".", "format", "(", "current_process", "(", ")", ".", "name", ",", "model_run_and_format_time", ")", ")", "\n", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "fp", ".", "writelines", "(", "result_lines", ")", "\n", "", "t4", "=", "datetime", ".", "now", "(", ")", "\n", "dump_time", "=", "(", "t4", "-", "t3", ")", ".", "total_seconds", "(", ")", "\n", "print", "(", "\"{} predictions write time: {} seconds\"", ".", "format", "(", "current_process", "(", ")", ".", "name", ",", "dump_time", ")", ")", "\n", "print", "(", "\"---------------\"", ")", "\n", "for", "time_name", "in", "detector", ".", "time_counter", ":", "\n", "        ", "print", "(", "\"{}\\t{}\\t{}\"", ".", "format", "(", "current_process", "(", ")", ".", "name", ",", "time_name", ",", "detector", ".", "time_counter", "[", "time_name", "]", ")", ")", "\n", "", "print", "(", "\"---------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.parallel_processing_mini_tables": [[141, 209], ["datetime.datetime.now", "print", "multi_process_offline_predict.split_mini_tables", "print", "print", "multi_process_offline_predict.divide_mini_tables", "print", "range", "datetime.datetime.now", "print", "print", "enumerate", "multiprocessing.Queue", "multiprocessing.Queue", "print", "range", "print", "datetime.datetime.now", "print", "print", "range", "multi_process_offline_predict.dump_min_tables", "datetime.datetime.now", "print", "print", "print", "exit", "len", "tasks.append", "multiprocessing.Queue.put", "processes.append", "p.start", "p.join", "len", "os.path.join", "len", "len", "open", "fp.writelines", "multiprocessing.Process", "open", "os.path.join", "os.path.join", "small_dump_tab_list.append", "os.path.join", "os.path.join", "json.loads", "line.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.split_mini_tables", "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.divide_mini_tables", "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.dump_min_tables"], ["", "def", "parallel_processing_mini_tables", "(", "params", ",", "\n", "in_fn", ",", "\n", "dump_dir", ",", "\n", "items_per_process", ",", "\n", "max_row_size", "=", "20", ",", "\n", "number_process", "=", "10", ")", ":", "\n", "\n", "    ", "t1", "=", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"[1] Split big table into multiple mini tables...\"", ")", "\n", "all_mini_input_tabs", "=", "split_mini_tables", "(", "in_fn", ",", "max_row_size", "=", "max_row_size", ")", "\n", "\n", "print", "(", "\"    Total mini_input_tables: {}\"", ".", "format", "(", "len", "(", "all_mini_input_tabs", ")", ")", ")", "\n", "\n", "print", "(", "\"[2] Divide mini tables into multiple processes...\"", ")", "\n", "part_tables", "=", "divide_mini_tables", "(", "all_mini_input_tabs", ",", "items_per_process", ")", "\n", "print", "(", "\"    Total {} jobs\"", ".", "format", "(", "len", "(", "part_tables", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "part_tables", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "f\"input_part_{i}.jsonl\"", ")", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "writelines", "(", "part_tables", "[", "i", "]", ")", "\n", "", "", "t_s", "=", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"    Total split time: {}\"", ".", "format", "(", "(", "t_s", "-", "t1", ")", ".", "total_seconds", "(", ")", ")", ")", "\n", "\n", "tasks", "=", "[", "]", "\n", "\n", "print", "(", "\"[3] Running each process ...\"", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "part_tables", ")", ":", "\n", "        ", "tasks", ".", "append", "(", "(", "detect_multi_tables", ",", "(", "params", ",", "\n", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "f\"input_part_{i}.jsonl\"", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "f\"output_part_{i}.jsonl\"", ")", ")", ")", ")", "\n", "\n", "# Create queues", "\n", "", "task_queue", "=", "Queue", "(", ")", "\n", "done_queue", "=", "Queue", "(", ")", "\n", "\n", "# Submit tasks", "\n", "for", "task", "in", "tasks", ":", "\n", "        ", "task_queue", ".", "put", "(", "task", ")", "\n", "\n", "", "print", "(", "'    Start {} processes'", ".", "format", "(", "number_process", ")", ")", "\n", "processes", "=", "[", "]", "\n", "# Start worker processes", "\n", "for", "i", "in", "range", "(", "number_process", ")", ":", "\n", "        ", "processes", ".", "append", "(", "Process", "(", "target", "=", "worker", ",", "args", "=", "(", "task_queue", ",", "done_queue", ")", ")", ")", "\n", "\n", "", "for", "p", "in", "processes", ":", "\n", "        ", "p", ".", "start", "(", ")", "\n", "\n", "", "print", "(", "\"    Waiting each process's stop\"", ")", "\n", "for", "p", "in", "processes", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "\n", "", "t_e", "=", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"    Total subprocesses running time: {}\"", ".", "format", "(", "(", "t_e", "-", "t_s", ")", ".", "total_seconds", "(", ")", ")", ")", "\n", "\n", "print", "(", "\"[4] Merging predictions ...\"", ")", "\n", "small_dump_tab_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "part_tables", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "f\"output_part_{i}.jsonl\"", ")", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "for", "line", "in", "fp", ":", "\n", "                ", "small_dump_tab_list", ".", "append", "(", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "\n", "", "", "", "dump_min_tables", "(", "small_dump_tab_list", ",", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "f\"all_output_tables.jsonl\"", ")", ")", "\n", "t2", "=", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"    Total dump prediction time: {}\"", ".", "format", "(", "(", "t2", "-", "t_e", ")", ".", "total_seconds", "(", ")", ")", ")", "\n", "print", "(", "\"Time Consumed: {}s\\n\"", ".", "format", "(", "(", "t2", "-", "t1", ")", ".", "total_seconds", "(", ")", ")", ")", "\n", "print", "(", "\"--------OVER--------\"", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.load_sub_tables": [[211, 227], ["dict", "dict", "open", "sorted", "json.loads", "int", "all_tables[].append", "line.strip", "tab[].split", "tab[].split"], "function", ["None"], ["", "def", "load_sub_tables", "(", "fn", ")", ":", "\n", "    ", "all_tables", "=", "dict", "(", ")", "\n", "with", "open", "(", "fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "tab", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "tab_id", "=", "tab", "[", "'tab_id'", "]", ".", "split", "(", "\"||\"", ")", "[", "0", "]", "\n", "part_id", "=", "int", "(", "tab", "[", "'tab_id'", "]", ".", "split", "(", "\"||\"", ")", "[", "1", "]", ")", "\n", "if", "tab_id", "not", "in", "all_tables", ":", "\n", "                ", "all_tables", "[", "tab_id", "]", "=", "[", "]", "\n", "", "tab", "[", "\"tab_id\"", "]", "=", "tab_id", "\n", "all_tables", "[", "tab_id", "]", ".", "append", "(", "(", "tab", ",", "part_id", ")", ")", "\n", "", "", "re_all_tables", "=", "dict", "(", ")", "\n", "for", "tab_id", "in", "all_tables", ":", "\n", "        ", "sorted_mini_tables", "=", "sorted", "(", "all_tables", "[", "tab_id", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "re_all_tables", "[", "tab_id", "]", "=", "[", "x", "[", "0", "]", "for", "x", "in", "sorted_mini_tables", "]", "\n", "", "return", "re_all_tables", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.TableAnnotator.multi_process_offline_predict.dump_min_tables": [[229, 272], ["dict", "int", "all_tables[].append", "sorted", "open", "tab[].split", "dict", "dict", "dict", "dict", "re_fp.write", "tab[].split", "print", "row_col_id[].split", "row_col_id[].split", "row_col_id[].split", "json.dumps", "str", "str", "str", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["", "def", "dump_min_tables", "(", "small_dump_tab_list", ",", "out_fn", ")", ":", "\n", "    ", "all_tables", "=", "dict", "(", ")", "\n", "\n", "for", "tab", "in", "small_dump_tab_list", ":", "\n", "        ", "tab_id", "=", "tab", "[", "'tab_id'", "]", ".", "split", "(", "\"||\"", ")", "[", "0", "]", "\n", "part_id", "=", "int", "(", "tab", "[", "'tab_id'", "]", ".", "split", "(", "\"||\"", ")", "[", "1", "]", ")", "\n", "if", "tab_id", "not", "in", "all_tables", ":", "\n", "            ", "all_tables", "[", "tab_id", "]", "=", "[", "]", "\n", "", "all_tables", "[", "tab_id", "]", ".", "append", "(", "(", "tab", ",", "part_id", ")", ")", "\n", "", "for", "tab_id", "in", "all_tables", ":", "\n", "        ", "sorted_mini_tables", "=", "sorted", "(", "all_tables", "[", "tab_id", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "all_tables", "[", "tab_id", "]", "=", "[", "x", "[", "0", "]", "for", "x", "in", "sorted_mini_tables", "]", "\n", "\n", "", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "        ", "num", "=", "0", "\n", "for", "tab_id", "in", "all_tables", ":", "\n", "            ", "tab", "=", "all_tables", "[", "tab_id", "]", "\n", "re_tab", "=", "dict", "(", ")", "\n", "re_tab", "[", "\"tab_id\"", "]", "=", "tab_id", "\n", "re_tab", "[", "\"row_size\"", "]", "=", "0", "\n", "re_tab", "[", "\"col_size\"", "]", "=", "tab", "[", "0", "]", "[", "'col_size'", "]", "\n", "re_tab", "[", "\"revisit_predict_entities\"", "]", "=", "dict", "(", ")", "\n", "re_tab", "[", "\"predict_entities\"", "]", "=", "dict", "(", ")", "\n", "re_tab", "[", "\"tab_pred_type\"", "]", "=", "tab", "[", "0", "]", "[", "\"tab_pred_type\"", "]", "\n", "re_tab", "[", "\"coarse_properties\"", "]", "=", "tab", "[", "0", "]", "[", "\"coarse_properties\"", "]", "\n", "re_tab", "[", "\"coarse_candid_entities_info\"", "]", "=", "dict", "(", ")", "\n", "offset", "=", "0", "\n", "for", "sub_tab", "in", "tab", ":", "\n", "                ", "re_tab", "[", "\"row_size\"", "]", "+=", "sub_tab", "[", "\"row_size\"", "]", "\n", "for", "row_col_id", "in", "sub_tab", "[", "\"revisit_predict_entities\"", "]", ":", "\n", "                    ", "row_id", ",", "col_id", "=", "row_col_id", "[", "1", ":", "-", "1", "]", ".", "split", "(", "', '", ")", "\n", "re_tab", "[", "\"revisit_predict_entities\"", "]", "[", "str", "(", "(", "offset", "+", "int", "(", "row_id", ")", ",", "int", "(", "col_id", ")", ")", ")", "]", "=", "sub_tab", "[", "\"revisit_predict_entities\"", "]", "[", "row_col_id", "]", "\n", "", "for", "row_col_id", "in", "sub_tab", "[", "\"predict_entities\"", "]", ":", "\n", "                    ", "row_id", ",", "col_id", "=", "row_col_id", "[", "1", ":", "-", "1", "]", ".", "split", "(", "', '", ")", "\n", "re_tab", "[", "\"predict_entities\"", "]", "[", "str", "(", "(", "offset", "+", "int", "(", "row_id", ")", ",", "int", "(", "col_id", ")", ")", ")", "]", "=", "sub_tab", "[", "\"predict_entities\"", "]", "[", "row_col_id", "]", "\n", "", "for", "row_col_id", "in", "sub_tab", "[", "\"coarse_candid_entities_info\"", "]", ":", "\n", "                    ", "row_id", ",", "col_id", "=", "row_col_id", "[", "1", ":", "-", "1", "]", ".", "split", "(", "', '", ")", "\n", "re_tab", "[", "\"coarse_candid_entities_info\"", "]", "[", "str", "(", "(", "offset", "+", "int", "(", "row_id", ")", ",", "int", "(", "col_id", ")", ")", ")", "]", "=", "sub_tab", "[", "\"coarse_candid_entities_info\"", "]", "[", "row_col_id", "]", "\n", "", "offset", "+=", "sub_tab", "[", "'row_size'", "]", "\n", "", "re_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "re_tab", ")", ")", ")", "\n", "num", "+=", "1", "\n", "if", "num", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "\"Dump {} lines...\"", ".", "format", "(", "num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_length_units": [[9, 24], ["conversions.append", "conversions.append", "conversions.append"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "convert_length_units", "(", "value", ")", ":", "\n", "# Units in meters", "\n", "        ", "conversions", "=", "[", "]", "\n", "for", "i", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "6", ",", "9", ",", "12", ",", "15", ",", "21", ",", "24", "]", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "/", "10", "**", "i", ")", "\n", "conversions", ".", "append", "(", "value", "*", "10", "**", "i", ")", "\n", "# for i in [1, 2, 3, 6, 9, 12, 15, 21, 24]:", "\n", "#     conversions.append(pvalue*10**i)", "\n", "# Convert to meter, parsec, light-year, light-second, astronomical unit, miles, foot, inch, thou", "\n", "", "for", "val", "in", "[", "value", ",", "value", "/", "3.086e16", ",", "value", "/", "9.461e15", ",", "value", "/", "2.998e8", ",", "value", "/", "1.496e11", ",", "\n", "value", "/", "1609.34", ",", "value", "*", "3.281", ",", "value", "*", "39.37", ",", "value", "*", "39270", "]", ":", "\n", "            ", "conversions", ".", "append", "(", "val", ")", "\n", "\n", "", "return", "conversions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_area_units": [[25, 33], ["conversions.append", "conversions.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_area_units", "(", "value", ")", ":", "\n", "# Units in square metre", "\n", "        ", "conversions", "=", "[", "value", "]", "\n", "for", "i", "in", "[", "4", ",", "6", "]", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "*", "10", "**", "i", ")", "\n", "conversions", ".", "append", "(", "value", "/", "10", "**", "i", ")", "\n", "", "return", "conversions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_volume_units": [[34, 41], ["conversions.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_volume_units", "(", "value", ")", ":", "\n", "# Units in cubic metre", "\n", "        ", "conversions", "=", "[", "value", ",", "value", "/", "1e9", "]", "\n", "for", "i", "in", "[", "1", ",", "2", ",", "3", ",", "5", ",", "6", ",", "9", ",", "15", ",", "18", "]", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "*", "10", "**", "i", ")", "\n", "", "return", "conversions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_frequency_units": [[42, 50], ["conversions.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_frequency_units", "(", "value", ")", ":", "\n", "# Units in hertz", "\n", "        ", "conversions", "=", "[", "value", "]", "\n", "for", "i", "in", "[", "3", ",", "6", ",", "9", "]", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "/", "10", "**", "i", ")", "\n", "\n", "", "return", "conversions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_time_units": [[51, 60], ["range", "conversions.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_time_units", "(", "value", ")", ":", "\n", "# Units in seconds", "\n", "# Convert to seconds, minutes, hour, day, week, month, year", "\n", "        ", "conversions", "=", "[", "value", ",", "value", "/", "60", ",", "value", "/", "360", ",", "value", "/", "86400", ",", "value", "/", "604800", ",", "value", "/", "2.628e6", ",", "\n", "value", "/", "3.154e7", "]", "\n", "for", "i", "in", "range", "(", "3", ",", "19", ",", "3", ")", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "*", "10", "**", "i", ")", "\n", "", "return", "conversions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_mass_units": [[61, 73], ["range", "range", "range", "conversions.append", "conversions.append", "conversions.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_mass_units", "(", "value", ")", ":", "\n", "# Units in Kilogram", "\n", "# Convert to all other units", "\n", "        ", "conversions", "=", "[", "value", ",", "value", "*", "2.205", ",", "value", "/", "1.66e-27", ",", "value", "/", "10", "]", "\n", "for", "i", "in", "range", "(", "3", ",", "22", ",", "3", ")", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "/", "10", "**", "i", ")", "\n", "", "for", "i", "in", "range", "(", "1", ",", "7", ")", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "*", "10", "**", "i", ")", "\n", "", "for", "i", "in", "range", "(", "9", ",", "28", ",", "3", ")", ":", "\n", "            ", "conversions", ".", "append", "(", "value", "*", "10", "**", "i", ")", "\n", "", "return", "conversions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_concentration_units": [[74, 78], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "# TODO: Im unsure whether this will work. The units in Wikidata seem quite obscure so we should check in the future", "\n", "def", "convert_concentration_units", "(", "value", ")", ":", "\n", "        ", "return", "[", "value", ",", "value", "*", "1e3", ",", "value", "*", "1e6", ",", "value", ",", "value", "/", "35.5", ",", "value", ",", "value", ",", "value", ",", "value", ",", "value", ",", "value", ",", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.check_mention_in_conversions": [[79, 85], ["numpy.isclose", "float", "float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_mention_in_conversions", "(", "conversions", ",", "mention", ")", ":", "\n", "        ", "for", "value", "in", "conversions", ":", "\n", "            ", "if", "np", ".", "isclose", "(", "float", "(", "value", ")", ",", "float", "(", "mention", ")", ",", "rtol", "=", "1e-2", ",", "equal_nan", "=", "False", ")", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_temperature_units": [[86, 91], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_temperature_units", "(", "value", ")", ":", "\n", "# Convert to Celsius, Kelvin, Fahrenheit, Rankine", "\n", "        ", "conversions", "=", "[", "value", ",", "value", "+", "273.15", ",", "(", "value", "*", "9", "/", "5", ")", "+", "32", ",", "(", "value", "*", "9", "/", "5", ")", "+", "491.67", "]", "\n", "return", "conversions", "\n", "# return UnitConversionUtils.check_mention_in_conversions(conversions, cell_mention)", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_pressure_units": [[93, 100], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_pressure_units", "(", "value", ")", ":", "\n", "# Unit in standard atmosphere", "\n", "# Convert to standard atmosphere, technical atmosphere, bar, pascal, torr and millimeter of mercury, meter of water", "\n", "        ", "conversions", "=", "[", "value", ",", "value", "*", "1.033", ",", "value", "*", "1.013", ",", "value", "*", "101325", ",", "value", "*", "9.869", ",", "value", "/", "101", ",", "\n", "value", "/", "1013", ",", "value", "*", "760", ",", "value", "/", "0.09869", "]", "\n", "return", "conversions", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_speed_units": [[101, 107], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_speed_units", "(", "value", ")", ":", "\n", "# kilometre per hour", "\n", "# Convert to to kilometre per hour, metre per second and Knot", "\n", "        ", "conversions", "=", "[", "value", ",", "value", "/", "3600", ",", "value", "/", "3.6", ",", "value", "/", "1.852", "]", "\n", "return", "conversions", "\n", "# return UnitConversionUtils.check_mention_in_conversions(conversions, cell_mention)", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.convert_enthalpy_units": [[109, 113], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_enthalpy_units", "(", "value", ")", ":", "\n", "# Convert to joule per mole", "\n", "        ", "return", "[", "value", ",", "value", "*", "1e3", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.__init__": [[19, 24], ["open", "json.load", "open", "json.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "units_dir", ",", "factors_dir", ")", ":", "\n", "        ", "with", "open", "(", "units_dir", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "self", ".", "qnumber_to_unit", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "with", "open", "(", "factors_dir", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "self", ".", "unit_to_standard_value_factor", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.fuzzy_match_dates": [[25, 46], ["datetime.date.fromisoformat", "datetime.date.fromisoformat", "relativedelta", "relativedelta", "cell_value.split", "property_value.split"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "fuzzy_match_dates", "(", "cell_value", ",", "property_value", ",", "threshold", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "cell_date", "=", "datetime", ".", "date", ".", "fromisoformat", "(", "cell_value", ".", "split", "(", "\"T\"", ")", "[", "0", "]", "[", "1", ":", "]", ")", "\n", "property_date", "=", "datetime", ".", "date", ".", "fromisoformat", "(", "property_value", ".", "split", "(", "\"T\"", ")", "[", "0", "]", "[", "1", ":", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "return", "False", "\n", "", "try", ":", "\n", "            ", "range_start", "=", "property_date", "+", "relativedelta", "(", "days", "=", "-", "threshold", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "range_start", "=", "property_date", "\n", "", "except", "OverflowError", ":", "\n", "            ", "range_start", "=", "property_date", "\n", "", "try", ":", "\n", "            ", "range_end", "=", "property_date", "+", "relativedelta", "(", "days", "=", "+", "threshold", ")", "\n", "", "except", "OverflowError", ":", "\n", "            ", "range_end", "=", "property_date", "\n", "", "if", "range_start", "<=", "cell_date", "<=", "range_end", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.get_conversions": [[47, 85], ["property_types.items", "getattr", "getattr."], "methods", ["None"], ["", "", "def", "get_conversions", "(", "self", ",", "pnumber", ",", "pvalue", ",", "punits", ")", ":", "\n", "        ", "property_types", "=", "{", "\n", "\"convert_length_units\"", ":", "{", "\"P2120\"", ",", "\"P2073\"", ",", "\"P2050\"", ",", "\"P2048\"", ",", "\"P2049\"", ",", "\"P2043\"", ",", "\"P2044\"", ",", "\"P2148\"", ",", "\"P2151\"", "}", ",", "\n", "# All area(P2046, P2053, P2112), Volume (P2234), and Frequency (P2114) conversions are in multiples of ten", "\n", "\"convert_area_units\"", ":", "{", "\"P2046\"", ",", "\"P2053\"", ",", "\"P2112\"", "}", ",", "\n", "\"convert_volume_units\"", ":", "{", "\"P2234\"", "}", ",", "\n", "\"convert_frequency_units\"", ":", "{", "\"P2114\"", "}", ",", "\n", "# All volume unit conversions are in multiples of ten", "\n", "\"convert_time_units\"", ":", "{", "\"P2047\"", ",", "\"P2114\"", "}", ",", "\n", "\"convert_mass_units\"", ":", "{", "\"P2067\"", "}", ",", "\n", "\"convert_concentration_units\"", ":", "{", "\"P2177\"", ",", "\"P2202\"", ",", "\"P2203\"", ",", "\"P2240\"", ",", "\"P2300\"", ",", "\"P2404\"", ",", "\"P2405\"", ",", "\"P2406\"", ",", "\n", "\"P2407\"", "}", ",", "\n", "\"convert_temperature_units\"", ":", "{", "\"P2076\"", ",", "\"P2101\"", ",", "\"P2102\"", ",", "\"P2107\"", ",", "\"P2113\"", ",", "\"P2128\"", "}", ",", "\n", "\"convert_pressure_units\"", ":", "{", "\"P2077\"", ",", "\"P2119\"", "}", ",", "\n", "\"convert_speed_units\"", ":", "{", "\"P2052\"", ",", "\"P2075\"", "}", ",", "\n", "\"convert_enthalpy_units\"", ":", "{", "\"P2066\"", ",", "\"P2116\"", ",", "\"P2117\"", "}", ",", "\n", "}", "\n", "\n", "try", ":", "\n", "            ", "units", "=", "self", ".", "qnumber_to_unit", "[", "punits", "]", "\n", "standard_value", "=", "pvalue", "*", "self", ".", "unit_to_standard_value_factor", "[", "units", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "[", "pvalue", "]", "\n", "# cannot use factors for following units", "\n", "", "if", "units", "==", "'kelvin'", ":", "\n", "            ", "standard_value", "-=", "273.15", "\n", "", "elif", "units", "==", "'degree Fahrenheit'", ":", "\n", "            ", "standard_value", "-=", "32", "\n", "", "elif", "units", "==", "'Rankine scale'", ":", "\n", "            ", "standard_value", "-=", "491.67", "\n", "\n", "", "for", "property_type", ",", "properties", "in", "property_types", ".", "items", "(", ")", ":", "\n", "            ", "if", "pnumber", "in", "properties", ":", "\n", "                ", "method_to_call", "=", "getattr", "(", "UnitConversionUtils", ",", "property_type", ")", "\n", "conversions", "=", "method_to_call", "(", "standard_value", ")", "\n", "return", "conversions", "\n", "\n", "", "", "return", "[", "pvalue", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.match_numbers_with_conversion": [[86, 91], ["numerical_utils.NumericalPropertyLinkingUtils.get_conversions", "TableAnnotator.Util.unit_conversion_utils.UnitConversionUtils.check_mention_in_conversions"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.get_conversions", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.unit_conversion_utils.UnitConversionUtils.check_mention_in_conversions"], ["", "def", "match_numbers_with_conversion", "(", "self", ",", "pnumber", ",", "pvalue", ",", "punits", ",", "cell_mention", ")", ":", "\n", "        ", "conversions", "=", "self", ".", "get_conversions", "(", "pnumber", ",", "pvalue", ",", "punits", ")", "\n", "if", "not", "conversions", ":", "\n", "            ", "return", "False", "\n", "", "return", "UnitConversionUtils", ".", "check_mention_in_conversions", "(", "conversions", ",", "cell_mention", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.check_cell_mention_in_range": [[92, 100], ["numerical_utils.NumericalPropertyLinkingUtils.get_conversions", "numerical_utils.NumericalPropertyLinkingUtils.get_conversions", "zip", "float"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.get_conversions", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.get_conversions"], ["", "def", "check_cell_mention_in_range", "(", "self", ",", "pnumber", ",", "range_min", ",", "range_max", ",", "punits", ",", "cell_mention", ")", ":", "\n", "        ", "min_values", "=", "self", ".", "get_conversions", "(", "pnumber", ",", "range_min", ",", "punits", ")", "\n", "max_values", "=", "self", ".", "get_conversions", "(", "pnumber", ",", "range_max", ",", "punits", ")", "\n", "\n", "for", "min_val", ",", "max_val", "in", "zip", "(", "min_values", ",", "max_values", ")", ":", "\n", "            ", "if", "min_val", "<=", "float", "(", "cell_mention", ")", "<=", "max_val", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.__init__": [[162, 173], ["numerical_utils.NumericalPropertyLinkingUtils", "open", "json.load", "open", "json.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "use_characteristics", ")", ":", "\n", "        ", "if", "use_characteristics", ":", "\n", "            ", "with", "open", "(", "config", ".", "property_entity_types_fn", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fp", ":", "\n", "                ", "self", ".", "entity_types", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "with", "open", "(", "config", ".", "type_property_stats_fn", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "self", ".", "type_property_stats", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "", "self", ".", "numerical_property_linker", "=", "NumericalPropertyLinkingUtils", "(", "\n", "config", ".", "qnumbers_to_units_fn", ",", "\n", "config", ".", "unit_to_standard_unit_factors_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.is_match": [[174, 219], ["numerical_utils.is_date", "numpy.isclose", "datetime.datetime.strptime", "numerical_utils.clear_zero_valued_times", "float", "float", "numerical_utils.NumericalPropertyLinker.numerical_property_linker.match_numbers_with_conversion", "cell_mention.replace.replace.replace", "cell_mention.replace.replace.split", "datetime.datetime.strptime.isoformat", "float", "float", "numerical_utils.NumericalPropertyLinker.numerical_property_linker.check_cell_mention_in_range", "numerical_utils.fuzzy_match_dates"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_date", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.clear_zero_valued_times", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.match_numbers_with_conversion", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinkingUtils.check_cell_mention_in_range", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.fuzzy_match_dates"], ["", "def", "is_match", "(", "self", ",", "candidate", ",", "property_number", ",", "property_type", ",", "property_value", ",", "property_units", ",", "cell_mention", ",", "\n", "match_type", ",", "use_characteristics", "=", "False", ")", ":", "\n", "        ", "if", "property_type", "==", "shortname", ".", "STRING", "or", "property_type", "==", "shortname", ".", "MONO", ":", "\n", "            ", "if", "match_type", "==", "\"Direct Match\"", "and", "property_value", "==", "cell_mention", ":", "\n", "                ", "return", "True", "\n", "", "", "elif", "property_type", "==", "shortname", ".", "QUANTITY", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "match_type", "==", "\"Direct Match\"", "and", "np", ".", "isclose", "(", "float", "(", "property_value", ")", ",", "float", "(", "cell_mention", ")", ",", "\n", "rtol", "=", "1e-2", ",", "equal_nan", "=", "False", ")", ":", "\n", "                    ", "return", "True", "\n", "# Try to match with unit conversion", "\n", "", "elif", "match_type", "==", "\"Fuzzy Match\"", "and", "self", ".", "numerical_property_linker", ".", "match_numbers_with_conversion", "(", "property_number", ",", "\n", "float", "(", "property_value", ")", ",", "\n", "property_units", ",", "\n", "float", "(", "cell_mention", ")", ")", ":", "\n", "                    ", "return", "True", "\n", "# Try to match numbers within a range", "\n", "", "elif", "match_type", "==", "\"Fuzzy Match\"", "and", "use_characteristics", ":", "\n", "                    ", "characteristics", "=", "self", ".", "type_property_stats", "[", "self", ".", "entity_types", "[", "candidate", "]", "]", "[", "property_number", "]", "\n", "if", "self", ".", "numerical_property_linker", ".", "check_cell_mention_in_range", "(", "property_number", ",", "\n", "characteristics", "[", "'min'", "]", ",", "\n", "characteristics", "[", "'max'", "]", ",", "\n", "characteristics", "[", "'unit'", "]", ",", "\n", "cell_mention", ")", ":", "\n", "                        ", "return", "True", "\n", "", "", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "elif", "property_type", "==", "shortname", ".", "TIME", ":", "\n", "            ", "if", "is_date", "(", "cell_mention", ")", ":", "\n", "                ", "if", "cell_mention", "[", "0", "]", "==", "'-'", "or", "cell_mention", "[", "0", "]", "==", "'+'", ":", "\n", "                    ", "cell_mention", "=", "cell_mention", "[", "1", ":", "]", "\n", "", "if", "'/'", "in", "cell_mention", ":", "\n", "                    ", "cell_mention", "=", "cell_mention", ".", "replace", "(", "'/'", ",", "'-'", ")", "\n", "", "cell_mention", "=", "cell_mention", ".", "split", "(", "'T'", ")", "[", "0", "]", "\n", "date", "=", "datetime", ".", "datetime", ".", "strptime", "(", "\n", "cell_mention", ",", "\"%Y-%m-%d\"", "\n", ")", "\n", "iso_date", "=", "date", ".", "isoformat", "(", ")", "+", "\"Z\"", "\n", "property_value", "=", "clear_zero_valued_times", "(", "property_value", "[", "1", ":", "]", ")", "\n", "if", "match_type", "==", "\"Direct Match\"", "and", "property_value", "==", "iso_date", ":", "\n", "                    ", "return", "True", "\n", "", "elif", "match_type", "==", "\"Fuzzy Match\"", "and", "fuzzy_match_dates", "(", "iso_date", ",", "property_value", ",", "10", ")", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.is_date": [[103, 119], ["string.replace.replace", "datetime.datetime.strptime", "datetime.datetime.strptime"], "function", ["None"], ["", "", "def", "is_date", "(", "string", ")", ":", "\n", "    ", "if", "string", "==", "\"\"", ":", "\n", "        ", "return", "False", "\n", "", "if", "string", "[", "0", "]", "==", "'-'", "or", "string", "[", "0", "]", "==", "'+'", ":", "\n", "        ", "string", "=", "string", "[", "1", ":", "]", "\n", "", "if", "'/'", "in", "string", ":", "\n", "        ", "string", "=", "string", ".", "replace", "(", "'/'", ",", "'-'", ")", "\n", "", "try", ":", "\n", "        ", "datetime", ".", "datetime", ".", "strptime", "(", "string", ",", "'%Y-%m-%dT%H:%M:%SZ'", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "try", ":", "\n", "            ", "datetime", ".", "datetime", ".", "strptime", "(", "string", ",", "\"%Y-%m-%d\"", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.clear_zero_valued_times": [[121, 129], ["string.split", "times[].split", "range", "len"], "function", ["None"], ["", "", "", "def", "clear_zero_valued_times", "(", "string", ")", ":", "\n", "    ", "times", "=", "string", ".", "split", "(", "\"T\"", ")", "\n", "date", "=", "times", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "date", ")", ")", ":", "\n", "        ", "if", "date", "[", "i", "]", "==", "\"00\"", ":", "\n", "            ", "date", "[", "i", "]", "=", "\"01\"", "\n", "\n", "", "", "return", "\"-\"", ".", "join", "(", "d", "for", "d", "in", "date", ")", "+", "\"T\"", "+", "times", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.fuzzy_match_dates": [[131, 159], ["datetime.date.fromisoformat", "datetime.date.fromisoformat", "cell_value.split", "[].split", "relativedelta", "relativedelta", "property_value.split", "datetime.date.fromisoformat", "property_value.split"], "function", ["None"], ["", "def", "fuzzy_match_dates", "(", "cell_value", ",", "property_value", ",", "threshold", ")", ":", "\n", "    ", "cell_date", "=", "datetime", ".", "date", ".", "fromisoformat", "(", "cell_value", ".", "split", "(", "\"T\"", ")", "[", "0", "]", ")", "\n", "try", ":", "\n", "        ", "property_date", "=", "datetime", ".", "date", ".", "fromisoformat", "(", "property_value", ".", "split", "(", "\"T\"", ")", "[", "0", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "# potential issue with feb 29", "\n", "        ", "date_list", "=", "property_value", ".", "split", "(", "\"T\"", ")", "[", "0", "]", ".", "split", "(", "'-'", ")", "\n", "day", "=", "date_list", "[", "2", "]", "\n", "month", "=", "date_list", "[", "1", "]", "\n", "year", "=", "date_list", "[", "0", "]", "\n", "if", "month", "==", "'02'", "and", "day", "==", "'29'", ":", "\n", "            ", "property_date", "=", "datetime", ".", "date", ".", "fromisoformat", "(", "year", "+", "'-'", "+", "month", "+", "'-28'", ")", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "", "", "try", ":", "\n", "        ", "range_start", "=", "property_date", "+", "relativedelta", "(", "days", "=", "-", "threshold", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "range_start", "=", "property_date", "\n", "", "except", "OverflowError", ":", "\n", "        ", "range_start", "=", "property_date", "\n", "", "try", ":", "\n", "        ", "range_end", "=", "property_date", "+", "relativedelta", "(", "days", "=", "+", "threshold", ")", "\n", "", "except", "OverflowError", ":", "\n", "        ", "range_end", "=", "property_date", "\n", "", "if", "range_start", "<=", "cell_date", "<=", "range_end", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.Util.add_vocab": [[12, 18], ["None"], "methods", ["None"], ["# distributed under the License is distributed on an \"AS IS\" BASIS,", "\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.", "\n", "# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n", "\n", "import", "csv", "\n", "import", "sys", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.__init__": [[21, 33], ["len", "len", "range", "range", "str"], "methods", ["None"], ["\n", "class", "InputExample", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.index_one_cell": [[34, 36], ["None"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.index_one_row": [[37, 39], ["None"], "methods", ["None"], ["self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.index_one_col": [[40, 42], ["range"], "methods", ["None"], ["\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.get_main_column_idx": [[43, 51], ["range", "utils.InputTable.index_one_col", "all", "Utils.utils.is_int", "Utils.utils.is_float", "Utils.utils.is_date"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_col", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_int", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_float", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_date"], ["\n", "", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.__init__": [[54, 67], ["dict", "dict", "dict"], "methods", ["None"], ["", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    A single set of features of data.\n\n    Args:\n        input_ids: Indices of input sequence tokens in the vocabulary.\n        attention_mask: Mask to avoid performing attention on padding token indices.\n            Mask values selected in ``[0, 1]``:\n            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n        label: Label corresponding to the input\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "label", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.short_list_entities": [[68, 70], ["None"], "methods", ["None"], ["        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.remove_low_prior_entities": [[71, 79], ["ret_candid.append"], "methods", ["None"], ["self", ".", "label", "=", "label", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n", "", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.gen_candidates": [[80, 92], ["range", "range", "utils.OutputTable.tab.index_one_cell", "candid_map.gen_candidates_with_features", "utils.OutputTable.short_list_entities", "cell.lower.lower.lower"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.index_one_cell", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.gen_candidates_with_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.short_list_entities"], ["\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "class", "DataProcessor", "(", "object", ")", ":", "\n", "    ", "\"\"\"Base class for data converters for sequence classification data sets.\"\"\"", "\n", "\n", "def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.gen_ent_set": [[93, 99], ["set", "set.add"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.resort_final_prior": [[100, 111], ["range", "range", "len"], "methods", ["None"], ["raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.init_pred": [[112, 160], ["dict", "dict", "range", "range", "sorted"], "methods", ["None"], ["        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.reassign_pred": [[161, 173], ["range", "range", "sorted", "len", "copy.deepcopy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_revisit_pred": [[174, 176], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_item": [[177, 179], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_row": [[180, 182], ["range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_col": [[183, 185], ["range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.add_ent_title": [[186, 195], ["entity_meta_info.get_item_name", "entity_meta_info.get_item_name"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_main_col_idx": [[196, 198], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_tab_pred_type": [[199, 201], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key": [[202, 207], ["dict", "str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_property_feature_cache": [[208, 210], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_tf_property_weights": [[211, 214], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_pre_property": [[215, 217], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.dump_one_tab": [[218, 232], ["utils.OutputTable.str_key", "utils.OutputTable.str_key", "utils.OutputTable.str_key", "utils.OutputTable.str_key", "utils.OutputTable.str_key", "utils.OutputTable.str_key"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.dump_one_tab_v2": [[233, 239], ["utils.OutputTable.str_key"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.str_key"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.extract_entities": [[240, 249], ["dict"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.pack_ent_predictions": [[250, 272], ["range", "utils.OutputTable.mapper.query", "range"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.query"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.pack_property_predictions": [[273, 279], ["dict", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.pack_type_predictions": [[280, 289], ["range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.gen_online": [[290, 298], ["utils.OutputTable.pack_property_predictions", "utils.OutputTable.pack_ent_predictions", "utils.OutputTable.pack_type_predictions"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.pack_property_predictions", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.pack_ent_predictions", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.pack_type_predictions"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.check_cell_filtering": [[300, 311], ["len", "Utils.utils.is_float_but_not_int", "Utils.utils.is_date", "Utils.utils.is_float", "Utils.utils.is_int", "Utils.utils.is_date"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_float_but_not_int", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_date", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_float", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_int", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_date"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.Config.config_utils.process_config": [[9, 77], ["os.environ.get", "os.environ.get", "isinstance", "vars.items", "print", "print", "vars", "print", "vars.keys", "isinstance", "type", "value.replace().replace", "value.startswith", "value.startswith", "value.replace().replace", "value.replace", "value.replace"], "function", ["None"], ["def", "process_config", "(", "args", ":", "argparse", ".", "Namespace", ")", ":", "\n", "\n", "# Read base environment variables", "\n", "    ", "data_path", "=", "os", ".", "environ", ".", "get", "(", "\"DATA_PATH\"", ")", "\n", "lp_path", "=", "os", ".", "environ", ".", "get", "(", "\"LP_HOME\"", ")", "\n", "\n", "if", "lp_path", "is", "None", ":", "\n", "        ", "print", "(", "f\"Warning: LP_HOME environment variable not set. Using default value: {config.DEFAULT_SYSTEM_DIR}\"", ")", "\n", "", "else", ":", "\n", "        ", "config", ".", "base_system_dir", "=", "lp_path", "\n", "\n", "", "if", "data_path", "is", "None", ":", "\n", "        ", "print", "(", "f\"Warning: DATA_PATH environment variable not set. Using default value: {config.DEFAULT_DATA_DIR}\"", ")", "\n", "", "else", ":", "\n", "        ", "config", ".", "base_data_dir", "=", "data_path", "\n", "\n", "", "args_dict", "=", "{", "}", "\n", "if", "isinstance", "(", "args", ",", "argparse", ".", "Namespace", ")", ":", "\n", "        ", "args_dict", "=", "vars", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Warming: Config must be a namespace. \"", "+", "type", "(", "args", ")", ")", "\n", "return", "args", "\n", "\n", "", "if", "'port'", "in", "args_dict", ".", "keys", "(", ")", ":", "\n", "        ", "config", ".", "port", "=", "args", ".", "port", "\n", "\n", "# rewrite relative paths by var references", "\n", "", "for", "key", ",", "value", "in", "args_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "            ", "if", "'$BASE_DATA_DIR'", "in", "value", "or", "'$BASE_SYSTEM_DIR'", "in", "value", ":", "\n", "                ", "args_dict", "[", "key", "]", "=", "value", ".", "replace", "(", "'$BASE_DATA_DIR'", ",", "config", ".", "base_data_dir", ")", ".", "replace", "(", "'$BASE_SYSTEM_DIR'", ",", "config", ".", "base_data_dir", ")", "\n", "", "elif", "value", ".", "startswith", "(", "'./'", ")", "or", "value", ".", "startswith", "(", "'.\\\\'", ")", ":", "\n", "                ", "path", "=", "data_path", "\n", "if", "'/configs/'", "in", "value", "or", "'\\\\configs\\\\'", "in", "value", "or", "'/static'", "in", "value", "or", "'\\\\static'", "in", "value", ":", "\n", "                    ", "path", "=", "lp_path", "\n", "", "args_dict", "[", "key", "]", "=", "value", ".", "replace", "(", "'./'", ",", "path", "+", "'/'", ")", ".", "replace", "(", "'.\\\\'", ",", "path", "+", "'\\\\'", ")", "\n", "\n", "", "", "", "params", "=", "{", "\n", "\"k_level\"", ":", "config", ".", "k_level", ",", "\n", "\"candid_map_fn\"", ":", "config", ".", "candid_map_fn", ",", "\n", "\"type_count_fn\"", ":", "config", ".", "type_count_fn", ",", "\n", "\"property_value_fn\"", ":", "config", ".", "property_value_fn", ",", "\n", "\"entity_meta_fn\"", ":", "config", ".", "entity_meta_fn", ",", "\n", "\"init_prune_topk\"", ":", "args_dict", "[", "'init_prune_topk'", "]", ",", "\n", "\"topk\"", ":", "args_dict", "[", "'topk'", "]", ",", "\n", "\"keep_N\"", ":", "args_dict", "[", "'keep_N'", "]", ",", "\n", "\"alpha\"", ":", "args_dict", "[", "'alpha'", "]", ",", "\n", "\"beta\"", ":", "args_dict", "[", "'beta'", "]", ",", "\n", "\"gamma\"", ":", "args_dict", "[", "'gamma'", "]", ",", "\n", "\"max_iter\"", ":", "args_dict", "[", "'max_iter'", "]", ",", "\n", "\"use_characteristics\"", ":", "args_dict", "[", "'use_characteristics'", "]", ",", "\n", "\"min_final_diff\"", ":", "args_dict", "[", "'min_final_diff'", "]", ",", "\n", "# weight for property", "\n", "\"strict_match_weight\"", ":", "1.0", ",", "\n", "\"fuzzy_match_weight\"", ":", "0.8", ",", "\n", "\"characteristic_match_weight\"", ":", "0.7", ",", "\n", "\"row_feature_only\"", ":", "args_dict", "[", "'row_feature_only'", "]", ",", "\n", "\"ent_feature\"", ":", "args_dict", "[", "'ent_feature'", "]", ",", "\n", "\"alias_map_fn\"", ":", "args_dict", "[", "'alias_map_fn'", "]", ",", "\n", "\"id_mapping_fn\"", ":", "args_dict", "[", "'id_mapping_fn'", "]", ",", "\n", "\"index_name\"", ":", "args_dict", "[", "'index_name'", "]", ",", "\n", "\"in_links_fn\"", ":", "args_dict", "[", "'in_links_fn'", "]", ",", "\n", "\"kb_store\"", ":", "config", ".", "kb_store", ",", "\n", "\"schema_entity_meta_fn\"", ":", "config", ".", "schema_entity_meta_fn", ",", "\n", "\"candid_gen_method\"", ":", "config", ".", "candid_gen_method", ",", "\n", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Config.config_utils.process_relative_path_config": [[79, 103], ["os.environ.get", "isinstance", "vars.items", "argparse.Namespace", "print", "vars", "print", "isinstance", "type", "value.replace().replace", "value.replace"], "function", ["None"], ["", "def", "process_relative_path_config", "(", "args", ":", "argparse", ".", "Namespace", ")", ":", "\n", "\n", "# Read base environment variables", "\n", "    ", "data_path", "=", "os", ".", "environ", ".", "get", "(", "\"BASE_DATA_DIR\"", ")", "\n", "\n", "if", "data_path", "is", "None", ":", "\n", "        ", "print", "(", "f\"Warning: BASE_DATA_DIR environment variable not set. Using default value: {config.DEFAULT_DATA_DIR}\"", ")", "\n", "", "else", ":", "\n", "        ", "config", ".", "base_data_dir", "=", "data_path", "\n", "\n", "", "args_dict", "=", "{", "}", "\n", "if", "isinstance", "(", "args", ",", "argparse", ".", "Namespace", ")", ":", "\n", "        ", "args_dict", "=", "vars", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Warming: Config must be a namespace. \"", "+", "type", "(", "args", ")", ")", "\n", "return", "args", "\n", "\n", "# rewrite relative paths by var references", "\n", "", "for", "key", ",", "value", "in", "args_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "            ", "if", "'$BASE_DATA_DIR'", "in", "value", "or", "'$BASE_SYSTEM_DIR'", "in", "value", ":", "\n", "                ", "args_dict", "[", "key", "]", "=", "value", ".", "replace", "(", "'$BASE_DATA_DIR'", ",", "config", ".", "base_data_dir", ")", ".", "replace", "(", "'$BASE_SYSTEM_DIR'", ",", "config", ".", "base_data_dir", ")", "\n", "\n", "", "", "", "return", "argparse", ".", "Namespace", "(", "**", "args_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.__init__": [[15, 30], ["entity_property_info.KBPropertyVal.load_data", "dict", "TableAnnotator.Maps.kb_store.KBStore"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.load_data"], ["    ", "def", "__init__", "(", "self", ",", "\n", "params", ")", ":", "\n", "        ", "self", ".", "feature", "=", "params", "[", "\"ent_feature\"", "]", "\n", "if", "params", "[", "\"kb_store\"", "]", "==", "\"RAM\"", ":", "\n", "            ", "self", ".", "property_info", "=", "self", ".", "load_data", "(", "params", "[", "\"property_value_fn\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "property_info", "=", "dict", "(", ")", "\n", "params", "=", "{", "\n", "\"feature\"", ":", "params", "[", "\"ent_feature\"", "]", ",", "\n", "\"kb_store\"", ":", "params", "[", "\"kb_store\"", "]", ",", "\n", "\"host\"", ":", "global_config", ".", "property_redis_host", ",", "\n", "\"port\"", ":", "global_config", ".", "property_redis_port", ",", "\n", "\"db_path\"", ":", "global_config", ".", "rocksdb_property_val_info_path", "\n", "}", "\n", "self", ".", "kb_store_interface", "=", "KBStore", "(", "params", "=", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.retrieve_candid_kb_info": [[31, 38], ["time.time", "time.time", "entity_property_info.KBPropertyVal.kb_store_interface.get_obj", "entity_property_info.KBPropertyVal.extract_kb_feature"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.kb_store.KBStore.get_obj", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.extract_kb_feature"], ["", "", "def", "retrieve_candid_kb_info", "(", "self", ",", "ent_set", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "t1", "=", "time", ".", "time", "(", ")", "\n", "for", "ent_id", "in", "ent_set", ":", "\n", "            ", "output", "=", "self", ".", "kb_store_interface", ".", "get_obj", "(", "ent_id", ")", "\n", "if", "output", ":", "\n", "                ", "self", ".", "property_info", "[", "ent_id", "]", "=", "self", ".", "extract_kb_feature", "(", "output", ")", "\n", "", "", "t2", "=", "time", ".", "time", "(", ")", "\n", "# print('kb access for property info {}s'.format(t2-t1))", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.extract_kb_feature": [[40, 48], ["set", "set"], "methods", ["None"], ["", "def", "extract_kb_feature", "(", "self", ",", "ent_obj", ")", ":", "\n", "        ", "if", "self", ".", "feature", "==", "'type'", ":", "\n", "            ", "ent_obj", "[", "\"kb_feature\"", "]", "=", "set", "(", "ent_obj", "[", "shortname", ".", "TYPES", "]", ")", "\n", "", "else", ":", "\n", "            ", "ent_obj", "[", "\"kb_feature\"", "]", "=", "set", "(", "ent_obj", "[", "shortname", ".", "TYPES", "]", "+", "ent_obj", "[", "shortname", ".", "PROPERTIES", "]", ")", "\n", "", "del", "ent_obj", "[", "shortname", ".", "TYPES", "]", "\n", "del", "ent_obj", "[", "shortname", ".", "PROPERTIES", "]", "\n", "return", "ent_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.load_data": [[49, 66], ["jsonlines.open", "dict", "tqdm.tqdm.tqdm", "entity_property_info.KBPropertyVal.extract_kb_feature"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.extract_kb_feature"], ["", "def", "load_data", "(", "self", ",", "fn", ":", "str", ")", "->", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "with", "jsonlines", ".", "open", "(", "fn", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "            ", "property_info", "=", "dict", "(", ")", "\n", "n", "=", "0", "\n", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "property_info", "[", "line", "[", "'id'", "]", "]", "=", "self", ".", "extract_kb_feature", "(", "line", ")", "\n", "# if self.feature == 'type':", "\n", "#     property_info[line['id']][\"kb_feature\"] = set(line[shortname.TYPES])", "\n", "# else:", "\n", "#     property_info[line['id']][\"kb_feature\"] = set(line[shortname.TYPES]+", "\n", "#                                                   line[shortname.PROPERTIES])", "\n", "# del property_info[line['id']][shortname.TYPES]", "\n", "# del property_info[line['id']][shortname.PROPERTIES]", "\n", "n", "+=", "1", "\n", "if", "n", ">", "10000", "and", "config", ".", "debug", ":", "\n", "                    ", "break", "\n", "", "", "return", "property_info", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.query_kb_feature": [[67, 76], ["set"], "methods", ["None"], ["", "", "def", "query_kb_feature", "(", "self", ",", "item_id", ":", "str", ")", "->", "Set", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n                given an entity_id, return all properties + 2 level types of it\n                :param item_id:\n                :return:\n                \"\"\"", "\n", "if", "item_id", "in", "self", ".", "property_info", ":", "\n", "            ", "return", "self", ".", "property_info", "[", "item_id", "]", "[", "'kb_feature'", "]", "\n", "", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values": [[77, 81], ["None"], "methods", ["None"], ["", "def", "get_property_values", "(", "self", ",", "item_id", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "Dict", "[", "str", ",", "str", "]", "]", "]", ":", "\n", "        ", "if", "item_id", "in", "self", ".", "property_info", ":", "\n", "            ", "return", "self", ".", "property_info", "[", "item_id", "]", "[", "shortname", ".", "PROPERTIES_VALUES", "]", "\n", "", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.free": [[82, 86], ["dict"], "methods", ["None"], ["", "def", "free", "(", "self", ")", ":", "\n", "        ", "del", "self", ".", "property_info", "\n", "# gc.collect()", "\n", "self", ".", "property_info", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.ent_sim.SparseEntitySim.__init__": [[9, 12], ["dict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "kb_feature", ":", "KBPropertyVal", ")", ":", "\n", "        ", "self", ".", "kb_feature", "=", "kb_feature", "\n", "self", ".", "sim_cache", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.ent_sim.SparseEntitySim.cosine_sim": [[13, 28], ["ent_sim.SparseEntitySim.kb_feature.query_kb_feature", "ent_sim.SparseEntitySim.kb_feature.query_kb_feature", "len", "max", "max", "len", "math.sqrt", "math.sqrt", "len", "len"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.query_kb_feature", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.query_kb_feature"], ["", "def", "cosine_sim", "(", "self", ",", "e1", ",", "e2", ")", ":", "\n", "        ", "if", "f\"{e1}@@{e2}\"", "in", "self", ".", "sim_cache", ":", "\n", "            ", "return", "self", ".", "sim_cache", "[", "f\"{e1}@@{e2}\"", "]", "\n", "", "f1_labels", "=", "self", ".", "kb_feature", ".", "query_kb_feature", "(", "e1", ")", "\n", "f2_labels", "=", "self", ".", "kb_feature", ".", "query_kb_feature", "(", "e2", ")", "\n", "\n", "f1_f2_labels", "=", "f1_labels", "&", "f2_labels", "\n", "if", "len", "(", "f1_f2_labels", ")", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "v1", "=", "len", "(", "f1_f2_labels", ")", "\n", "e1_len", "=", "max", "(", "math", ".", "sqrt", "(", "len", "(", "f1_labels", ")", ")", ",", "1e-6", ")", "\n", "e2_len", "=", "max", "(", "math", ".", "sqrt", "(", "len", "(", "f2_labels", ")", ")", ",", "1e-6", ")", "\n", "sim", "=", "v1", "/", "(", "e1_len", "*", "e2_len", ")", "\n", "self", ".", "sim_cache", "[", "f\"{e1}@@{e2}\"", "]", "=", "sim", "\n", "return", "sim", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.offline_candid_map.OfflineCandidateMap.__init__": [[9, 12], ["offline_candid_map.OfflineCandidateMap.load_candid_map"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.offline_candid_map.OfflineCandidateMap.load_candid_map"], ["    ", "def", "__init__", "(", "self", ",", "candid_map_fn", ")", ":", "\n", "# do candidate generation using offline prepared candidate map", "\n", "        ", "self", ".", "mention_cache", "=", "OfflineCandidateMap", ".", "load_candid_map", "(", "candid_map_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.offline_candid_map.OfflineCandidateMap.load_candid_map": [[13, 18], ["open", "pickle.load"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_candid_map", "(", "fn", ")", ":", "\n", "        ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "mention_cache", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "mention_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.offline_candid_map.OfflineCandidateMap.gen_candidates_with_features": [[19, 25], ["TableAnnotator.Util.utils.check_cell_filtering"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.check_cell_filtering"], ["", "", "def", "gen_candidates_with_features", "(", "self", ",", "cell_text", ",", "topk", "=", "10", ")", ":", "\n", "        ", "if", "check_cell_filtering", "(", "cell_text", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "cell_text", "in", "self", ".", "mention_cache", ":", "\n", "            ", "return", "self", ".", "mention_cache", "[", "cell_text", "]", "[", ":", "topk", "]", "\n", "", "return", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.kb_store.KBStore.__init__": [[13, 22], ["redis.Redis", "setup_rocksdb", "ValueError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "kb_store", "=", "params", "[", "'kb_store'", "]", "\n", "if", "params", "[", "'kb_store'", "]", "==", "'redis'", ":", "\n", "            ", "self", ".", "info", "=", "redis", ".", "Redis", "(", "host", "=", "params", "[", "\"host\"", "]", ",", "port", "=", "params", "[", "\"port\"", "]", ")", "\n", "", "elif", "params", "[", "'kb_store'", "]", "==", "'rocksdb'", ":", "\n", "            ", "assert", "global_config", ".", "use_rocks_db", "is", "True", "\n", "self", ".", "info", "=", "setup_rocksdb", "(", "params", "[", "\"db_path\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"unsupported kb_store {self.kb_store}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.kb_store.KBStore.get_obj": [[23, 28], ["Utils.utils.redis_get", "rocksdb_get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.redis_get", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.rocksdb_get"], ["", "", "def", "get_obj", "(", "self", ",", "item_id", ")", ":", "\n", "        ", "if", "self", ".", "kb_store", "==", "'redis'", ":", "\n", "            ", "return", "redis_get", "(", "self", ".", "info", ",", "item_id", ")", "\n", "", "else", ":", "\n", "            ", "return", "rocksdb_get", "(", "self", ".", "info", ",", "item_id", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.__init__": [[16, 30], ["entity_meta_info.EntityMetaInfo.load_data", "entity_meta_info.EntityMetaInfo.load_data", "dict", "TableAnnotator.Maps.kb_store.KBStore"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.load_data", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.load_data"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "schema_ent_meta_info", "=", "EntityMetaInfo", ".", "load_data", "(", "params", "[", "\"schema_entity_meta_fn\"", "]", ")", "\n", "if", "params", "[", "\"kb_store\"", "]", "==", "\"RAM\"", ":", "\n", "            ", "self", ".", "ent_meta_info", "=", "EntityMetaInfo", ".", "load_data", "(", "params", "[", "\"entity_meta_fn\"", "]", ")", "\n", "", "else", ":", "\n", "# self.ent_meta_info = EntityMetaInfo.load_data(params[\"schema_entity_meta_fn\"])", "\n", "            ", "self", ".", "ent_meta_info", "=", "dict", "(", ")", "\n", "params", "=", "{", "\n", "\"kb_store\"", ":", "params", "[", "\"kb_store\"", "]", ",", "\n", "\"host\"", ":", "global_config", ".", "ent_meta_redis_host", ",", "\n", "\"port\"", ":", "global_config", ".", "ent_meta_redis_port", ",", "\n", "\"db_path\"", ":", "global_config", ".", "rocksdb_meta_info_path", "\n", "}", "\n", "self", ".", "kb_store_interface", "=", "KBStore", "(", "params", "=", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.retrieve_candid_kb_info": [[31, 40], ["time.time", "time.time", "entity_meta_info.EntityMetaInfo.kb_store_interface.get_obj", "set"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.kb_store.KBStore.get_obj"], ["", "", "def", "retrieve_candid_kb_info", "(", "self", ",", "ent_set", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "t1", "=", "time", ".", "time", "(", ")", "\n", "for", "ent_id", "in", "ent_set", ":", "\n", "            ", "output", "=", "self", ".", "kb_store_interface", ".", "get_obj", "(", "ent_id", ")", "\n", "if", "output", ":", "\n", "                ", "self", ".", "ent_meta_info", "[", "ent_id", "]", "=", "output", "\n", "self", ".", "ent_meta_info", "[", "ent_id", "]", "[", "shortname", ".", "TYPES", "]", "=", "set", "(", "self", ".", "ent_meta_info", "[", "ent_id", "]", "[", "shortname", ".", "TYPES", "]", ")", "\n", "", "", "t2", "=", "time", ".", "time", "(", ")", "\n", "# print('kb access for meta info {}s'.format(t2-t1))", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.load_data": [[42, 55], ["jsonlines.open", "dict", "tqdm.tqdm.tqdm", "set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "fn", ":", "str", ")", "->", "Dict", "[", "str", ",", "Dict", "]", ":", "\n", "        ", "with", "jsonlines", ".", "open", "(", "fn", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "            ", "entity_meta_info", "=", "dict", "(", ")", "\n", "n", "=", "0", "\n", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "entity_meta_info", "[", "line", "[", "\"id\"", "]", "]", "=", "line", "\n", "entity_meta_info", "[", "line", "[", "\"id\"", "]", "]", "[", "shortname", ".", "TYPES", "]", "=", "set", "(", "entity_meta_info", "[", "line", "[", "\"id\"", "]", "]", "[", "shortname", ".", "TYPES", "]", ")", "\n", "n", "+=", "1", "\n", "if", "config", ".", "debug", "and", "n", ">", "10000", ":", "\n", "                    ", "break", "\n", "", "", "return", "entity_meta_info", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_item_name": [[56, 65], ["data[].replace", "data[].replace"], "methods", ["None"], ["", "", "def", "get_item_name", "(", "self", ",", "item_id", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "item_id", "in", "self", ".", "schema_ent_meta_info", ":", "\n", "# if schema node, directly access RAM", "\n", "            ", "data", "=", "self", ".", "schema_ent_meta_info", "[", "item_id", "]", "\n", "return", "data", "[", "shortname", ".", "ENT_NAME", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "", "if", "item_id", "in", "self", ".", "ent_meta_info", ":", "\n", "            ", "data", "=", "self", ".", "ent_meta_info", "[", "item_id", "]", "\n", "return", "data", "[", "shortname", ".", "ENT_NAME", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "", "return", "\"NIL\"", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_types": [[66, 75], ["set"], "methods", ["None"], ["", "def", "get_entity_types", "(", "self", ",", "item_id", ":", "str", ")", "->", "Set", "[", "str", "]", ":", "\n", "        ", "if", "item_id", "in", "self", ".", "schema_ent_meta_info", ":", "\n", "# if schema node, directly access RAM", "\n", "            ", "data", "=", "self", ".", "schema_ent_meta_info", "[", "item_id", "]", "\n", "return", "data", "[", "shortname", ".", "TYPES", "]", "\n", "", "if", "item_id", "in", "self", ".", "ent_meta_info", ":", "\n", "            ", "data", "=", "self", ".", "ent_meta_info", "[", "item_id", "]", "\n", "return", "data", "[", "shortname", ".", "TYPES", "]", "\n", "", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_rank_types": [[76, 87], ["None"], "methods", ["None"], ["", "def", "get_entity_rank_types", "(", "self", ",", "item_id", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "if", "item_id", "in", "self", ".", "schema_ent_meta_info", ":", "\n", "# if schema node, directly access RAM", "\n", "            ", "data", "=", "self", ".", "schema_ent_meta_info", "[", "item_id", "]", "\n", "return", "data", "[", "shortname", ".", "TYPES_RANK", "]", "\n", "", "if", "item_id", "in", "self", ".", "ent_meta_info", ":", "\n", "            ", "data", "=", "self", ".", "ent_meta_info", "[", "item_id", "]", "\n", "return", "data", "[", "shortname", ".", "TYPES_RANK", "]", "\n", "", "return", "{", "\n", "shortname", ".", "INSTANCE_OF", ":", "[", "]", ",", "\n", "shortname", ".", "SUBCLASS_OF", ":", "[", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.track_parents": [[89, 111], ["copy.deepcopy", "range", "entity_meta_info.EntityMetaInfo.get_entity_types", "set", "entity_meta_info.EntityMetaInfo.get_entity_types", "len", "set.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_types", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_types"], ["", "def", "track_parents", "(", "self", ",", "item_id", ":", "str", ",", "level", ":", "int", ")", "->", "Set", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        :param item_id: a Q number\n        :param level: the number of levels above the current level that we want to go to\n        :return: types: a set that contains all the parent types (instance of) of the node up to the number\n                 levels specified. i.e: If Belgium is a federal system, it's also form of government because federal\n                 system is an instance of form of government.\n        \"\"\"", "\n", "types", "=", "deepcopy", "(", "self", ".", "get_entity_types", "(", "item_id", ")", ")", "\n", "pre_level_types", "=", "types", "\n", "for", "i", "in", "range", "(", "level", ")", ":", "\n", "            ", "new_level_types", "=", "set", "(", ")", "\n", "for", "t", "in", "pre_level_types", ":", "\n", "                ", "parents", "=", "self", ".", "get_entity_types", "(", "t", ")", "\n", "if", "len", "(", "parents", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "for", "p", "in", "parents", ":", "\n", "                    ", "if", "p", "not", "in", "types", ":", "\n", "                        ", "new_level_types", ".", "add", "(", "p", ")", "\n", "", "", "", "pre_level_types", "=", "new_level_types", "\n", "types", "|=", "pre_level_types", "\n", "", "return", "types", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.track_parents_level_ins_sub": [[112, 139], ["copy.deepcopy", "range", "set", "set", "entity_meta_info.EntityMetaInfo.get_entity_rank_types", "entity_meta_info.EntityMetaInfo.get_entity_rank_types", "len", "set.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_rank_types", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_rank_types"], ["", "def", "track_parents_level_ins_sub", "(", "self", ",", "item_id", ":", "str", ",", "level", ":", "int", ")", "->", "Tuple", "[", "Set", "[", "str", "]", ",", "Dict", "[", "str", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        :param item_id: a Q number\n        :param level: the number of levels above the current level that we want to go to\n        :return: types: a set that contains all the parent types (instance of) of the node up to the number\n                 levels specified. i.e: If Belgium is a federal system, it's also form of government because federal\n                 system is an instance of form of government.\n        \"\"\"", "\n", "types", "=", "deepcopy", "(", "set", "(", "self", ".", "get_entity_rank_types", "(", "item_id", ")", "[", "shortname", ".", "INSTANCE_OF", "]", ")", ")", "\n", "\n", "pre_level_types", "=", "types", "\n", "type_level", "=", "{", "}", "\n", "for", "t", "in", "types", ":", "\n", "            ", "type_level", "[", "t", "]", "=", "0", "\n", "", "for", "i", "in", "range", "(", "level", ")", ":", "\n", "            ", "new_level_types", "=", "set", "(", ")", "\n", "for", "t", "in", "pre_level_types", ":", "\n", "                ", "parents", "=", "self", ".", "get_entity_rank_types", "(", "t", ")", "[", "shortname", ".", "SUBCLASS_OF", "]", "\n", "if", "len", "(", "parents", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "for", "p", "in", "parents", ":", "\n", "                    ", "if", "p", "not", "in", "types", ":", "\n", "                        ", "type_level", "[", "p", "]", "=", "i", "+", "1", "\n", "new_level_types", ".", "add", "(", "p", ")", "\n", "", "", "", "pre_level_types", "=", "new_level_types", "\n", "types", "|=", "pre_level_types", "\n", "", "return", "types", ",", "type_level", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.is_child": [[140, 143], ["entity_meta_info.EntityMetaInfo.get_entity_types"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_types"], ["", "def", "is_child", "(", "self", ",", "t1", ",", "t2", ")", ":", "\n", "# t1 is a child of t2", "\n", "        ", "return", "t2", "in", "self", ".", "get_entity_types", "(", "t1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.free": [[144, 148], ["dict"], "methods", ["None"], ["", "def", "free", "(", "self", ")", ":", "\n", "        ", "del", "self", ".", "ent_meta_info", "\n", "# gc.collect()", "\n", "self", ".", "ent_meta_info", "=", "dict", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.__init__": [[11, 17], ["type_voter.TypeInference.load_type_count"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.load_type_count"], ["    ", "def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "entity_meta_info", ":", "EntityMetaInfo", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "entity_meta_info", "=", "entity_meta_info", "\n", "self", ".", "type_count", "=", "TypeInference", ".", "load_type_count", "(", "config", "[", "\"type_count_fn\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.load_type_count": [[18, 23], ["open", "pickle.load"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_type_count", "(", "fn", ")", ":", "\n", "        ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "type_count", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "type_count", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.cal_avg_levels": [[24, 30], ["types_level.get"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "cal_avg_levels", "(", "ent_types_level", ",", "node", ")", ":", "\n", "        ", "s", "=", "0", "\n", "for", "types_level", "in", "ent_types_level", ":", "\n", "            ", "s", "+=", "types_level", ".", "get", "(", "node", ",", "100", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.cal_instance_of_rank": [[31, 37], ["dict", "enumerate", "type_voter.TypeInference.entity_meta_info.get_entity_rank_types"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.get_entity_rank_types"], ["", "def", "cal_instance_of_rank", "(", "self", ",", "node", ")", ":", "\n", "        ", "score", "=", "dict", "(", ")", "\n", "instance_of_types", "=", "self", ".", "entity_meta_info", ".", "get_entity_rank_types", "(", "node", ")", "[", "shortname", ".", "INSTANCE_OF", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "instance_of_types", ")", ":", "\n", "            ", "score", "[", "x", "]", "=", "i", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.vote_wikidata_type": [[38, 93], ["max", "dict", "dict", "len", "predict_type_info.values", "type_voter.TypeInference.cal_avg_levels", "type_voter.TypeInference.cal_avg_levels", "min", "sorted", "min", "min", "min", "sorted", "min", "len", "dict.values", "dict.values", "type_voter.TypeInference.type_count.get", "type_voter.TypeInference.type_count.get", "type_voter.TypeInference.type_count.get", "type_voter.TypeInference.type_count.get", "type_voter.TypeInference.type_count.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.cal_avg_levels", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.cal_avg_levels"], ["", "def", "vote_wikidata_type", "(", "self", ",", "\n", "predict_type_info", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "ent_types_level", ":", "List", "[", "Dict", "[", "str", ",", "int", "]", "]", ",", "\n", "ent_instance_rank", ":", "List", "[", "Dict", "[", "str", ",", "int", "]", "]", ",", "\n", "is_main", "=", "True", ")", "->", "Tuple", "[", "str", ",", "int", ",", "Dict", ",", "Dict", ",", "List", ",", "Dict", "]", ":", "\n", "\n", "        ", "if", "len", "(", "predict_type_info", ")", "==", "0", ":", "\n", "            ", "return", "\"\"", ",", "0", ",", "{", "}", ",", "{", "}", ",", "[", "]", ",", "{", "}", "\n", "\n", "", "tie_nodes_debug", "=", "{", "}", "\n", "# by count", "\n", "max_count", "=", "max", "(", "predict_type_info", ".", "values", "(", ")", ")", "\n", "max_nodes", "=", "[", "t", "for", "t", "in", "predict_type_info", "if", "predict_type_info", "[", "t", "]", "==", "max_count", "]", "\n", "tie_nodes_debug", "[", "\"by_count\"", "]", "=", "max_nodes", "\n", "\n", "max_nodes_avg_levels", "=", "dict", "(", ")", "\n", "avg_ent_instance_rank", "=", "dict", "(", ")", "\n", "for", "t", "in", "max_nodes", ":", "\n", "            ", "max_nodes_avg_levels", "[", "t", "]", "=", "TypeInference", ".", "cal_avg_levels", "(", "ent_types_level", ",", "t", ")", "\n", "avg_ent_instance_rank", "[", "t", "]", "=", "TypeInference", ".", "cal_avg_levels", "(", "ent_instance_rank", ",", "t", ")", "\n", "\n", "", "if", "is_main", ":", "\n", "# by min level", "\n", "            ", "min_level_score", "=", "min", "(", "max_nodes_avg_levels", ".", "values", "(", ")", ")", "\n", "max_min_nodes", "=", "[", "t", "for", "t", "in", "max_nodes", "if", "max_nodes_avg_levels", "[", "t", "]", "==", "min_level_score", "]", "\n", "tie_nodes_debug", "[", "\"by_level\"", "]", "=", "max_min_nodes", "\n", "# by min population", "\n", "sorted_nodes", "=", "sorted", "(", "max_min_nodes", ",", "key", "=", "lambda", "x", ":", "self", ".", "type_count", ".", "get", "(", "x", ",", "1000000", ")", ")", "\n", "min_population", "=", "min", "(", "[", "self", ".", "type_count", ".", "get", "(", "x", ",", "1000000", ")", "for", "x", "in", "max_min_nodes", "]", ")", "\n", "min_population_tie_nodes", "=", "[", "t", "for", "t", "in", "max_min_nodes", "if", "self", ".", "type_count", ".", "get", "(", "t", ",", "1000000", ")", "==", "min_population", "]", "\n", "tie_nodes_debug", "[", "\"by_population\"", "]", "=", "min_population_tie_nodes", "\n", "tie_nodes", "=", "min_population_tie_nodes", "\n", "\n", "", "else", ":", "\n", "# by min level", "\n", "# sorted_nodes = sorted(max_nodes, key=lambda x:max_nodes_avg_levels[x])", "\n", "            ", "min_level_score", "=", "min", "(", "max_nodes_avg_levels", ".", "values", "(", ")", ")", "\n", "max_min_nodes", "=", "[", "t", "for", "t", "in", "max_nodes", "if", "max_nodes_avg_levels", "[", "t", "]", "==", "min_level_score", "]", "\n", "tie_nodes_debug", "[", "\"by_level\"", "]", "=", "max_min_nodes", "\n", "\n", "# by population", "\n", "min_population", "=", "min", "(", "[", "self", ".", "type_count", ".", "get", "(", "x", ",", "1000000", ")", "for", "x", "in", "max_min_nodes", "]", ")", "\n", "min_population_tie_nodes", "=", "[", "t", "for", "t", "in", "max_min_nodes", "if", "self", ".", "type_count", ".", "get", "(", "t", ",", "1000000", ")", "==", "min_population", "]", "\n", "tie_nodes_debug", "[", "\"by_population\"", "]", "=", "min_population_tie_nodes", "\n", "\n", "sorted_nodes", "=", "sorted", "(", "max_min_nodes", ",", "key", "=", "lambda", "x", ":", "avg_ent_instance_rank", "[", "x", "]", ")", "\n", "min_avg_ent_instance_rank", "=", "min", "(", "[", "avg_ent_instance_rank", "[", "t", "]", "for", "t", "in", "max_min_nodes", "]", ")", "\n", "tie_nodes", "=", "[", "t", "for", "t", "in", "max_min_nodes", "if", "\n", "avg_ent_instance_rank", "[", "t", "]", "==", "min_avg_ent_instance_rank", "]", "\n", "tie_nodes_debug", "[", "\"by_avg_ent_instance_rank\"", "]", "=", "tie_nodes", "\n", "\n", "", "if", "len", "(", "sorted_nodes", ")", "==", "0", ":", "\n", "            ", "return", "\"\"", ",", "0", ",", "max_nodes_avg_levels", ",", "avg_ent_instance_rank", ",", "tie_nodes", ",", "tie_nodes_debug", "\n", "", "else", ":", "\n", "            ", "return", "sorted_nodes", "[", "0", "]", ",", "predict_type_info", "[", "sorted_nodes", "[", "0", "]", "]", ",", "max_nodes_avg_levels", ",", "avg_ent_instance_rank", ",", "tie_nodes", ",", "tie_nodes_debug", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.pred_type": [[94, 154], ["dict", "range", "dict", "range", "dict", "dict", "type_voter.TypeInference.entity_meta_info.get_item_name().replace", "output_tab.index_one_item", "type_voter.TypeInference.entity_meta_info.track_parents_level_ins_sub", "type_voter.TypeInference.cal_instance_of_rank", "ent_types_level.append", "ent_instance_rank_scores.append", "type_voter.TypeInference.vote_wikidata_type", "type_voter.TypeInference.vote_wikidata_type", "type_voter.TypeInference.entity_meta_info.get_item_name", "type_voter.TypeInference.entity_meta_info.get_item_name", "type_voter.TypeInference.entity_meta_info.get_item_name", "type_voter.TypeInference.entity_meta_info.get_item_name"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_item", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.track_parents_level_ins_sub", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.cal_instance_of_rank", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.vote_wikidata_type", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.vote_wikidata_type", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name"], ["", "", "def", "pred_type", "(", "self", ",", "tab", ",", "output_tab", ",", "main_col_idx", "=", "0", ")", ":", "\n", "# vote type", "\n", "# maps from an entity type to its normalized count across top predicted entities", "\n", "        ", "tab_pred_type", "=", "dict", "(", ")", "\n", "for", "j", "in", "range", "(", "tab", ".", "col_size", ")", ":", "\n", "            ", "predict_type_info", "=", "dict", "(", ")", "\n", "ent_types_level", "=", "[", "]", "\n", "ent_instance_rank_scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "tab", ".", "row_size", ")", ":", "\n", "                ", "predict_entity", "=", "output_tab", ".", "index_one_item", "(", "output_tab", ".", "predict_entities", ",", "i", ",", "j", ")", "\n", "ent_types", ",", "types_level", "=", "self", ".", "entity_meta_info", ".", "track_parents_level_ins_sub", "(", "\n", "predict_entity", "[", "\"entity\"", "]", ",", "\n", "self", ".", "config", "[", "\"k_level\"", "]", ")", "\n", "score", "=", "self", ".", "cal_instance_of_rank", "(", "predict_entity", "[", "\"entity\"", "]", ")", "\n", "ent_types_level", ".", "append", "(", "types_level", ")", "\n", "ent_instance_rank_scores", ".", "append", "(", "score", ")", "\n", "for", "t", "in", "ent_types", ":", "\n", "                    ", "if", "t", "not", "in", "predict_type_info", ":", "\n", "                        ", "predict_type_info", "[", "t", "]", "=", "1", "\n", "", "else", ":", "\n", "                        ", "predict_type_info", "[", "t", "]", "+=", "1", "\n", "\n", "", "", "", "if", "j", "==", "main_col_idx", ":", "\n", "                ", "best_type", ",", "count", ",", "max_nodes_avg_levels", ",", "avg_instance_of_subclass_of_scores", ",", "tie_nodes", ",", "tie_nodes_debug", "=", "self", ".", "vote_wikidata_type", "(", "\n", "predict_type_info", ",", "\n", "ent_types_level", ",", "\n", "ent_instance_rank_scores", ",", "\n", "is_main", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "best_type", ",", "count", ",", "max_nodes_avg_levels", ",", "avg_instance_of_subclass_of_scores", ",", "tie_nodes", ",", "tie_nodes_debug", "=", "self", ".", "vote_wikidata_type", "(", "\n", "predict_type_info", ",", "\n", "ent_types_level", ",", "\n", "ent_instance_rank_scores", ",", "\n", "is_main", "=", "False", ")", "\n", "\n", "", "named_predict_type_info", "=", "dict", "(", ")", "\n", "for", "node", "in", "predict_type_info", ":", "\n", "                ", "named_predict_type_info", "[", "node", "]", "=", "{", "\"name\"", ":", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "node", ")", ",", "\n", "\"count\"", ":", "predict_type_info", "[", "node", "]", "}", "\n", "", "named_tie_nodes_debug", "=", "dict", "(", ")", "\n", "for", "key", "in", "tie_nodes_debug", ":", "\n", "                ", "named_tie_nodes_debug", "[", "key", "]", "=", "[", "(", "x", ",", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "x", ")", ")", "for", "x", "in", "tie_nodes_debug", "[", "key", "]", "]", "\n", "", "named_tie_nodes", "=", "[", "(", "node", ",", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "node", ")", ")", "for", "node", "in", "tie_nodes", "]", "\n", "best_type_name", "=", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "best_type", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "pred_type_details", "=", "{", "\"best_type\"", ":", "best_type", ",", "\n", "\"best_type_name\"", ":", "best_type_name", ",", "\n", "\"confidence\"", ":", "count", "/", "tab", ".", "row_size", ",", "#}", "\n", "\"tie_nodes\"", ":", "named_tie_nodes", ",", "\n", "\"predict_type_info\"", ":", "named_predict_type_info", ",", "\n", "\"ent_types_level\"", ":", "ent_types_level", ",", "\n", "\"avg_level_scores\"", ":", "max_nodes_avg_levels", ",", "\n", "\"instance_of_subclass_of_scores\"", ":", "ent_instance_rank_scores", ",", "\n", "\"avg_instance_of_subclass_of_scores\"", ":", "avg_instance_of_subclass_of_scores", ",", "\n", "\"tie_nodes_debug\"", ":", "named_tie_nodes_debug", "}", "\n", "tab_pred_type", "[", "j", "]", "=", "pred_type_details", "\n", "", "return", "tab_pred_type", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.__init__": [[15, 29], ["TableAnnotator.Maps.ent_sim.SparseEntitySim", "TableAnnotator.Maps.type_voter.TypeInference", "TableAnnotator.Util.numerical_utils.NumericalPropertyLinker"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "config", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "property_info", ":", "KBPropertyVal", ",", "\n", "entity_meta_info", ":", "EntityMetaInfo", ")", ":", "\n", "\n", "        ", "self", ".", "config", ":", "Dict", "[", "str", ",", "Any", "]", "=", "config", "\n", "self", ".", "property_info", "=", "property_info", "\n", "self", ".", "entity_meta_info", "=", "entity_meta_info", "\n", "self", ".", "ent_sim", "=", "SparseEntitySim", "(", "self", ".", "property_info", ")", "\n", "\n", "# Stores the types of an entity", "\n", "self", ".", "wikidata_ent_type_map", "=", "TypeInference", "(", "config", ",", "\n", "entity_meta_info", ")", "\n", "self", ".", "numerical_property_linker", "=", "NumericalPropertyLinker", "(", "config", "[", "'use_characteristics'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.gen_property_item_weights": [[30, 57], ["dict", "enumerate", "wikidata.Wikidata.property_info.get_property_values", "set", "len", "set.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values"], ["", "def", "gen_property_item_weights", "(", "self", ",", "\n", "main_col_predict_entities", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "target_col_predict_entities", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n            Given main column's predict entities & target column's predict entities, make statistics possible property\n            along with their freq, sorted in weights\n        \"\"\"", "\n", "weights", "=", "dict", "(", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "main_col_predict_entities", ")", ":", "\n", "            ", "main_ent", "=", "x", "[", "\"entity\"", "]", "\n", "target_ent", "=", "target_col_predict_entities", "[", "i", "]", "[", "\"entity\"", "]", "\n", "main_ent_property_values", "=", "self", ".", "property_info", ".", "get_property_values", "(", "main_ent", ")", "\n", "exists_properties", "=", "set", "(", ")", "\n", "for", "property", "in", "main_ent_property_values", ":", "\n", "                ", "for", "value", "in", "main_ent_property_values", "[", "property", "]", ":", "\n", "                    ", "if", "value", "[", "shortname", ".", "DTYPE", "]", "==", "shortname", ".", "ENT", "and", "value", "[", "shortname", ".", "VALUE", "]", "==", "target_ent", ":", "\n", "                        ", "exists_properties", ".", "add", "(", "property", ")", "\n", "break", "\n", "", "", "", "for", "property", "in", "exists_properties", ":", "\n", "                ", "if", "property", "not", "in", "weights", ":", "\n", "                    ", "weights", "[", "property", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "weights", "[", "property", "]", "+=", "1", "\n", "# normalize", "\n", "", "", "", "for", "property", "in", "weights", ":", "\n", "            ", "weights", "[", "property", "]", "/=", "len", "(", "main_col_predict_entities", ")", "\n", "", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.gen_candid_property_item_weights": [[58, 87], ["dict", "range", "len", "set", "set", "len", "wikidata.Wikidata.property_info.get_property_values", "set.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values"], ["", "def", "gen_candid_property_item_weights", "(", "self", ",", "\n", "main_col_candid_entities", ":", "List", "[", "Tuple", "[", "str", ",", "float", "]", "]", ",", "\n", "target_col_candid_entities", ":", "List", "[", "Tuple", "[", "str", ",", "float", "]", "]", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "weights", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "main_col_candid_entities", ")", ")", ":", "\n", "            ", "main_col_list", "=", "main_col_candid_entities", "[", "i", "]", "\n", "target_col_list", "=", "target_col_candid_entities", "[", "i", "]", "\n", "target_col_set", "=", "set", "(", "[", "x", "[", "0", "]", "for", "x", "in", "target_col_list", "]", ")", "\n", "exists_properties", "=", "set", "(", ")", "\n", "for", "e1", "in", "main_col_list", ":", "\n", "                ", "main_ent", "=", "e1", "[", "0", "]", "\n", "main_ent_property_values", "=", "self", ".", "property_info", ".", "get_property_values", "(", "main_ent", ")", "\n", "for", "property", "in", "main_ent_property_values", ":", "\n", "                    ", "for", "value", "in", "main_ent_property_values", "[", "property", "]", ":", "\n", "                        ", "if", "value", "[", "shortname", ".", "DTYPE", "]", "==", "shortname", ".", "ENT", "and", "value", "[", "shortname", ".", "VALUE", "]", "in", "target_col_set", ":", "\n", "                            ", "exists_properties", ".", "add", "(", "property", ")", "\n", "break", "\n", "\n", "", "", "", "", "for", "property", "in", "exists_properties", ":", "\n", "                ", "if", "property", "not", "in", "weights", ":", "\n", "                    ", "weights", "[", "property", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "weights", "[", "property", "]", "+=", "1", "\n", "\n", "# normalize", "\n", "", "", "", "for", "property", "in", "weights", ":", "\n", "            ", "weights", "[", "property", "]", "/=", "len", "(", "main_col_candid_entities", ")", "\n", "", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.gen_candid_property_lexical_weights": [[88, 135], ["dict", "range", "len", "dict", "len", "wikidata.Wikidata.property_info.get_property_values", "wikidata.Wikidata.numerical_property_linker.is_match", "wikidata.Wikidata.numerical_property_linker.is_match", "wikidata.Wikidata.numerical_property_linker.is_match", "dict.get", "dict.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.is_match", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.is_match", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.is_match"], ["", "def", "gen_candid_property_lexical_weights", "(", "self", ",", "\n", "main_col_candid_entities", ":", "List", "[", "Tuple", "[", "str", ",", "float", "]", "]", ",", "\n", "target_col", ":", "List", "[", "str", "]", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "weights", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "main_col_candid_entities", ")", ")", ":", "\n", "            ", "main_col_list", "=", "main_col_candid_entities", "[", "i", "]", "\n", "cell_mention", "=", "target_col", "[", "i", "]", "\n", "exists_properties", "=", "dict", "(", ")", "\n", "for", "e1", "in", "main_col_list", ":", "\n", "                ", "main_ent", "=", "e1", "[", "0", "]", "\n", "main_ent_property_values", "=", "self", ".", "property_info", ".", "get_property_values", "(", "main_ent", ")", "\n", "for", "property", "in", "main_ent_property_values", ":", "\n", "                    ", "for", "value", "in", "main_ent_property_values", "[", "property", "]", ":", "\n", "                        ", "pnumber", "=", "property", "\n", "ptype", "=", "value", "[", "shortname", ".", "DTYPE", "]", "\n", "pvalue", "=", "value", "[", "shortname", ".", "VALUE", "]", "\n", "\n", "if", "ptype", "==", "shortname", ".", "QUANTITY", ":", "\n", "                            ", "punits", "=", "value", "[", "\"unit\"", "]", "\n", "", "else", ":", "\n", "                            ", "punits", "=", "\"\"", "\n", "", "if", "self", ".", "numerical_property_linker", ".", "is_match", "(", "main_ent", ",", "pnumber", ",", "ptype", ",", "pvalue", ",", "punits", ",", "cell_mention", ",", "\n", "\"Direct Match\"", ",", "use_characteristics", "=", "False", ")", ":", "\n", "                            ", "exists_properties", "[", "property", "]", "=", "self", ".", "config", "[", "\"strict_match_weight\"", "]", "\n", "continue", "\n", "\n", "", "if", "self", ".", "numerical_property_linker", ".", "is_match", "(", "main_ent", ",", "pnumber", ",", "ptype", ",", "pvalue", ",", "punits", ",", "cell_mention", ",", "\n", "\"Fuzzy Match\"", ",", "use_characteristics", "=", "False", ")", ":", "\n", "                            ", "if", "exists_properties", ".", "get", "(", "property", ",", "0.0", ")", "<", "self", ".", "config", "[", "\"fuzzy_match_weight\"", "]", ":", "\n", "                                ", "exists_properties", "[", "property", "]", "=", "self", ".", "config", "[", "\"fuzzy_match_weight\"", "]", "\n", "", "continue", "\n", "\n", "", "if", "self", ".", "config", "[", "\"use_characteristics\"", "]", "and", "self", ".", "numerical_property_linker", ".", "is_match", "(", "main_ent", ",", "pnumber", ",", "ptype", ",", "pvalue", ",", "punits", ",", "cell_mention", ",", "\n", "\"Fuzzy Match\"", ",", "use_characteristics", "=", "True", ")", ":", "\n", "                            ", "if", "exists_properties", ".", "get", "(", "property", ",", "0.0", ")", "<", "self", ".", "config", "[", "\"characteristic_match_weight\"", "]", ":", "\n", "                                ", "exists_properties", "[", "property", "]", "=", "self", ".", "config", "[", "\"characteristic_match_weight\"", "]", "\n", "", "continue", "\n", "\n", "", "", "", "", "for", "property", "in", "exists_properties", ":", "\n", "                ", "if", "property", "not", "in", "weights", ":", "\n", "                    ", "weights", "[", "property", "]", "=", "exists_properties", "[", "property", "]", "\n", "", "else", ":", "\n", "                    ", "weights", "[", "property", "]", "+=", "exists_properties", "[", "property", "]", "\n", "# normalize", "\n", "", "", "", "for", "property", "in", "weights", ":", "\n", "            ", "weights", "[", "property", "]", "/=", "len", "(", "main_col_candid_entities", ")", "\n", "", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.retrieve_item_pair_possible_properties": [[136, 151], ["set", "wikidata.Wikidata.property_info.get_property_values", "list", "set.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values"], ["", "def", "retrieve_item_pair_possible_properties", "(", "self", ",", "\n", "e1", ":", "str", ",", "\n", "e2", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n            Given e1 and e2, return all possible properties between them\n        \"\"\"", "\n", "possible_properties", "=", "set", "(", ")", "\n", "main_ent_property_values", "=", "self", ".", "property_info", ".", "get_property_values", "(", "e1", ")", "\n", "for", "property", "in", "main_ent_property_values", ":", "\n", "            ", "for", "value", "in", "main_ent_property_values", "[", "property", "]", ":", "\n", "                ", "if", "value", "[", "shortname", ".", "DTYPE", "]", "==", "shortname", ".", "ENT", "and", "value", "[", "shortname", ".", "VALUE", "]", "==", "e2", ":", "\n", "                    ", "possible_properties", ".", "add", "(", "property", ")", "\n", "break", "\n", "", "", "", "return", "list", "(", "possible_properties", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.retrieve_head_item_tail_candid_pair_possible_properties": [[152, 166], ["set", "wikidata.Wikidata.property_info.get_property_values", "set", "list", "set.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values"], ["", "def", "retrieve_head_item_tail_candid_pair_possible_properties", "(", "self", ",", "\n", "e1", ":", "str", ",", "\n", "candid", ":", "List", "[", "Tuple", "[", "str", ",", "float", "]", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "possible_properties", "=", "set", "(", ")", "\n", "main_ent_property_values", "=", "self", ".", "property_info", ".", "get_property_values", "(", "e1", ")", "\n", "candid_set", "=", "set", "(", "[", "x", "[", "0", "]", "for", "x", "in", "candid", "]", ")", "\n", "\n", "for", "property", "in", "main_ent_property_values", ":", "\n", "            ", "for", "value", "in", "main_ent_property_values", "[", "property", "]", ":", "\n", "                ", "if", "value", "[", "shortname", ".", "DTYPE", "]", "==", "shortname", ".", "ENT", "and", "value", "[", "shortname", ".", "VALUE", "]", "in", "candid_set", ":", "\n", "                    ", "possible_properties", ".", "add", "(", "property", ")", "\n", "break", "\n", "", "", "", "return", "list", "(", "possible_properties", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.retrieve_head_candid_tail_item_pair_possible_properties": [[167, 181], ["set", "list", "wikidata.Wikidata.property_info.get_property_values", "set.add"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values"], ["", "def", "retrieve_head_candid_tail_item_pair_possible_properties", "(", "self", ",", "\n", "candid", ":", "List", "[", "Tuple", "[", "str", ",", "float", "]", "]", ",", "\n", "e2", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "possible_properties", "=", "set", "(", ")", "\n", "for", "e1", "in", "candid", ":", "\n", "            ", "e1", "=", "e1", "[", "0", "]", "\n", "main_ent_property_values", "=", "self", ".", "property_info", ".", "get_property_values", "(", "e1", ")", "\n", "for", "property", "in", "main_ent_property_values", ":", "\n", "                ", "for", "value", "in", "main_ent_property_values", "[", "property", "]", ":", "\n", "                    ", "if", "value", "[", "shortname", ".", "DTYPE", "]", "==", "shortname", ".", "ENT", "and", "value", "[", "shortname", ".", "VALUE", "]", "==", "e2", ":", "\n", "                        ", "possible_properties", ".", "add", "(", "property", ")", "\n", "break", "\n", "", "", "", "", "return", "list", "(", "possible_properties", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.retrieve_lexical_matched_possible_properties": [[182, 219], ["dict", "wikidata.Wikidata.property_info.get_property_values", "wikidata.Wikidata.numerical_property_linker.is_match", "wikidata.Wikidata.numerical_property_linker.is_match", "wikidata.Wikidata.numerical_property_linker.is_match", "dict.get", "dict.get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_property_info.KBPropertyVal.get_property_values", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.is_match", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.is_match", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.numerical_utils.NumericalPropertyLinker.is_match"], ["", "def", "retrieve_lexical_matched_possible_properties", "(", "self", ",", "\n", "e1", ":", "str", ",", "\n", "cell_mention", ":", "str", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n            Given cell text and e1, return most align property and value's similarity based on different datatype\n        \"\"\"", "\n", "possible_properties", "=", "dict", "(", ")", "\n", "main_ent_property_values", "=", "self", ".", "property_info", ".", "get_property_values", "(", "e1", ")", "\n", "for", "property", "in", "main_ent_property_values", ":", "\n", "            ", "for", "value", "in", "main_ent_property_values", "[", "property", "]", ":", "\n", "                ", "pnumber", "=", "property", "\n", "ptype", "=", "value", "[", "shortname", ".", "DTYPE", "]", "\n", "pvalue", "=", "value", "[", "shortname", ".", "VALUE", "]", "\n", "\n", "if", "ptype", "==", "shortname", ".", "QUANTITY", ":", "\n", "                    ", "punits", "=", "value", "[", "\"unit\"", "]", "\n", "", "else", ":", "\n", "                    ", "punits", "=", "\"\"", "\n", "\n", "", "if", "self", ".", "numerical_property_linker", ".", "is_match", "(", "e1", ",", "pnumber", ",", "ptype", ",", "pvalue", ",", "punits", ",", "cell_mention", ",", "\n", "\"Direct Match\"", ",", "use_characteristics", "=", "False", ")", ":", "\n", "                    ", "possible_properties", "[", "property", "]", "=", "self", ".", "config", "[", "\"strict_match_weight\"", "]", "\n", "continue", "\n", "\n", "", "if", "self", ".", "numerical_property_linker", ".", "is_match", "(", "e1", ",", "pnumber", ",", "ptype", ",", "pvalue", ",", "punits", ",", "cell_mention", ",", "\n", "\"Fuzzy Match\"", ",", "use_characteristics", "=", "False", ")", ":", "\n", "                    ", "if", "possible_properties", ".", "get", "(", "property", ",", "0.0", ")", "<", "self", ".", "config", "[", "\"fuzzy_match_weight\"", "]", ":", "\n", "                        ", "possible_properties", "[", "property", "]", "=", "self", ".", "config", "[", "\"fuzzy_match_weight\"", "]", "\n", "", "continue", "\n", "\n", "", "if", "self", ".", "config", "[", "\"use_characteristics\"", "]", "and", "self", ".", "numerical_property_linker", ".", "is_match", "(", "e1", ",", "pnumber", ",", "ptype", ",", "pvalue", ",", "punits", ",", "cell_mention", ",", "\n", "\"Fuzzy Match\"", ",", "use_characteristics", "=", "True", ")", ":", "\n", "                    ", "if", "possible_properties", ".", "get", "(", "property", ",", "0.0", ")", "<", "self", ".", "config", "[", "\"characteristic_match_weight\"", "]", ":", "\n", "                        ", "possible_properties", "[", "property", "]", "=", "self", ".", "config", "[", "\"characteristic_match_weight\"", "]", "\n", "", "continue", "\n", "\n", "", "", "", "return", "possible_properties", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.cosine_ent_sim": [[220, 222], ["wikidata.Wikidata.ent_sim.cosine_sim"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.ent_sim.SparseEntitySim.cosine_sim"], ["", "def", "cosine_ent_sim", "(", "self", ",", "e1", ",", "e2", ")", ":", "\n", "        ", "return", "self", ".", "ent_sim", ".", "cosine_sim", "(", "e1", ",", "e2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.name_labels": [[223, 234], ["ret_labels.append", "wikidata.Wikidata.entity_meta_info.get_item_name", "wikidata.Wikidata.entity_meta_info.get_item_name", "wikidata.Wikidata.entity_meta_info.get_item_name", "x[].split", "x[].split"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name"], ["", "def", "name_labels", "(", "self", ",", "labels", ":", "List", "[", "Tuple", "[", "str", ",", "float", ",", "float", "]", "]", ")", "->", "List", "[", "Tuple", "[", "str", ",", "float", ",", "float", "]", "]", ":", "\n", "        ", "ret_labels", "=", "[", "]", "\n", "for", "x", "in", "labels", ":", "\n", "            ", "if", "\"->\"", "in", "x", "[", "0", "]", ":", "\n", "                ", "pname", "=", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "x", "[", "0", "]", ".", "split", "(", "\"->\"", ")", "[", "0", "]", ")", "\n", "idname", "=", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "x", "[", "0", "]", ".", "split", "(", "\"->\"", ")", "[", "1", "]", ")", "\n", "label_name", "=", "\"{}->{}\"", ".", "format", "(", "pname", ",", "idname", ")", "\n", "", "else", ":", "\n", "                ", "label_name", "=", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "x", "[", "0", "]", ")", "\n", "", "ret_labels", ".", "append", "(", "(", "label_name", ",", "x", "[", "1", "]", ",", "x", "[", "2", "]", ")", ")", "\n", "", "return", "ret_labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.__init__": [[40, 47], ["CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap", "CandidGen.elastic_search.ElasticSearcher", "mixed_candid_map.MixedCandidateMap.load_pkl", "dict"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.redis_utils.build_ent_labels_info.load_pkl"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "self", ".", "dict_search", "=", "WikidataCandidateTypoMap", "(", "params", "[", "\"alias_map_fn\"", "]", ")", "\n", "self", ".", "elastic_search", "=", "ElasticSearcher", "(", "index_name", "=", "params", "[", "\"index_name\"", "]", ")", "\n", "\n", "self", ".", "in_links", "=", "self", ".", "load_pkl", "(", "params", "[", "\"in_links_fn\"", "]", ")", "\n", "self", ".", "cache", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.load_pkl": [[48, 52], ["open", "pickle.load"], "methods", ["None"], ["", "def", "load_pkl", "(", "self", ",", "fn", ")", ":", "\n", "        ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "pkl", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "pkl", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.shortlist": [[53, 62], ["cands.sort", "x[].split", "Levenshtein.distance"], "methods", ["None"], ["", "", "def", "shortlist", "(", "self", ",", "mention", ",", "cands", ")", ":", "\n", "        ", "cands", "=", "[", "(", "x", "[", "0", "]", ",", "x", "[", "2", "]", ")", "for", "x", "in", "cands", "]", "\n", "set1", "=", "cands", "[", ":", "30", "]", "\n", "cands", ".", "sort", "(", "key", "=", "lambda", "x", ":", "Levenshtein", ".", "distance", "(", "x", "[", "1", "]", ",", "mention", ")", ")", "\n", "set2", "=", "cands", "[", ":", "30", "]", "\n", "new_cands", "=", "[", "]", "\n", "for", "x", "in", "(", "set1", "+", "set2", ")", ":", "\n", "            ", "new_cands", "+=", "x", "[", "0", "]", ".", "split", "(", "\";\"", ")", "\n", "", "return", "new_cands", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.gen_candidates": [[63, 91], ["TableAnnotator.Util.utils.check_cell_filtering", "mixed_candid_map.MixedCandidateMap.dict_search.gen_candid_spell_corrector", "list", "set", "mixed_candid_map.MixedCandidateMap.elastic_search.query_data", "mixed_candid_map.MixedCandidateMap.shortlist", "list", "mixed_candid_map.MixedCandidateMap.dict_search.gen_candid_spell_corrector", "mixed_candid_map.MixedCandidateMap.elastic_search.query_data", "mixed_candid_map.MixedCandidateMap.shortlist", "list", "set", "len", "list", "set", "set"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.check_cell_filtering", "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.gen_candid_spell_corrector", "home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.query_data", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.shortlist", "home.repos.pwc.inspect_result.microsoft_vert-papers.CandidGen.wikidata_candid_map_typo.WikidataCandidateTypoMap.gen_candid_spell_corrector", "home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.query_data", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.shortlist"], ["", "def", "gen_candidates", "(", "self", ",", "\n", "mention", ",", "\n", "elastic_search_only", "=", "False", ",", "\n", "dictionary_only", "=", "False", ")", ":", "\n", "        ", "assert", "not", "(", "elastic_search_only", "and", "dictionary_only", ")", ",", "\"elastic_search_only and dictionary_search_only can not be both true\"", "\n", "if", "check_cell_filtering", "(", "mention", ")", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "if", "dictionary_only", ":", "\n", "            ", "candid", "=", "self", ".", "dict_search", ".", "gen_candid_spell_corrector", "(", "mention", ",", "\n", "strict_match_first", "=", "True", ",", "\n", "min_edit_len", "=", "10", ")", "\n", "candid", "=", "[", "x", "[", "0", "]", "for", "x", "in", "candid", "]", "\n", "return", "list", "(", "set", "(", "candid", ")", ")", "\n", "", "elif", "elastic_search_only", ":", "\n", "            ", "candid", "=", "self", ".", "elastic_search", ".", "query_data", "(", "mention", ",", "top_k", "=", "50", ",", "score_func", "=", "\"token_char\"", ")", "\n", "candid", "=", "self", ".", "shortlist", "(", "mention", ",", "candid", ")", "\n", "return", "list", "(", "set", "(", "candid", ")", ")", "\n", "", "else", ":", "\n", "            ", "candid", "=", "self", ".", "dict_search", ".", "gen_candid_spell_corrector", "(", "mention", ",", "\n", "strict_match_first", "=", "True", ",", "\n", "min_edit_len", "=", "10", ")", "\n", "candid", "=", "[", "x", "[", "0", "]", "for", "x", "in", "candid", "]", "\n", "if", "len", "(", "candid", ")", ">", "0", ":", "\n", "                ", "return", "list", "(", "set", "(", "candid", ")", ")", "\n", "", "candid", "=", "self", ".", "elastic_search", ".", "query_data", "(", "mention", ",", "top_k", "=", "50", ",", "score_func", "=", "\"token_char\"", ")", "\n", "candid", "=", "self", ".", "shortlist", "(", "mention", ",", "candid", ")", "\n", "return", "list", "(", "set", "(", "candid", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.add_feature": [[92, 102], ["sum", "sorted", "mixed_candid_map.get_max_label_and_score", "mixed_candid_map.MixedCandidateMap.in_links.get", "result.append"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.get_max_label_and_score"], ["", "", "def", "add_feature", "(", "self", ",", "mention", ",", "candid", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "ent", "in", "candid", ":", "\n", "            ", "max_label", ",", "max_score", "=", "get_max_label_and_score", "(", "mention", ",", "ent", ")", "\n", "in_links_count", "=", "self", ".", "in_links", ".", "get", "(", "ent", ",", "1", ")", "\n", "result", ".", "append", "(", "(", "ent", ",", "max_score", ",", "in_links_count", ")", ")", "\n", "", "total_count", "=", "sum", "(", "[", "x", "[", "2", "]", "for", "x", "in", "result", "]", ")", "\n", "candid_list", "=", "[", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "x", "[", "2", "]", "/", "total_count", ")", "for", "x", "in", "result", "]", "\n", "sorted_candid_list", "=", "sorted", "(", "candid_list", ",", "key", "=", "lambda", "x", ":", "x", "[", "2", "]", ",", "reverse", "=", "True", ")", "\n", "return", "sorted_candid_list", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.gen_candidates_with_features": [[103, 116], ["mixed_candid_map.MixedCandidateMap.gen_candidates", "mixed_candid_map.MixedCandidateMap.add_feature"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.candid_gen.all_in_one.gen_candidates", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.add_feature"], ["", "def", "gen_candidates_with_features", "(", "self", ",", "\n", "mention", ",", "\n", "elastic_search_only", "=", "False", ",", "\n", "dictionary_only", "=", "False", ",", "\n", "topk", "=", "100", ")", ":", "\n", "        ", "if", "mention", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "mention", "]", "\n", "", "candid", "=", "self", ".", "gen_candidates", "(", "mention", ",", "\n", "elastic_search_only", "=", "elastic_search_only", ",", "\n", "dictionary_only", "=", "dictionary_only", ")", "\n", "result", "=", "self", ".", "add_feature", "(", "mention", ",", "candid", ")", "[", ":", "topk", "]", "\n", "self", ".", "cache", "[", "mention", "]", "=", "result", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.get_ent_labels": [[18, 23], ["ent_label_redis.get", "json.loads"], "function", ["None"], ["def", "get_ent_labels", "(", "ent", ")", ":", "\n", "    ", "response", "=", "ent_label_redis", ".", "get", "(", "ent", ")", "\n", "if", "response", ":", "\n", "        ", "return", "json", ".", "loads", "(", "response", ")", "\n", "", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.get_max_label_and_score": [[25, 37], ["mixed_candid_map.get_ent_labels", "len", "Levenshtein.ratio"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.get_ent_labels"], ["", "def", "get_max_label_and_score", "(", "mention", ",", "ent", ")", ":", "\n", "    ", "labels", "=", "get_ent_labels", "(", "ent", ")", "\n", "if", "len", "(", "labels", ")", "==", "0", ":", "\n", "        ", "return", "\"No_label_defined\"", ",", "0.0", "\n", "", "max_score", "=", "0.0", "\n", "max_label", "=", "\"No_label_defined\"", "\n", "for", "lang_code", "in", "labels", ":", "\n", "        ", "score", "=", "Levenshtein", ".", "ratio", "(", "mention", ",", "labels", "[", "lang_code", "]", ")", "\n", "if", "score", ">", "max_score", ":", "\n", "            ", "max_score", "=", "score", "\n", "max_label", "=", "labels", "[", "lang_code", "]", "\n", "", "", "return", "max_label", ",", "max_score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.__init__": [[18, 49], ["KBMapping.mappings.KBMapper", "table_annotator.LinkingPark.mapper.init_pairs", "print", "TableAnnotator.Maps.entity_meta_info.EntityMetaInfo", "TableAnnotator.Maps.entity_property_info.KBPropertyVal", "TableAnnotator.Maps.wikidata.Wikidata", "print", "dict", "TableAnnotator.Maps.mixed_candid_map.MixedCandidateMap", "TableAnnotator.Maps.offline_candid_map.OfflineCandidateMap", "ValueError"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.init_pairs"], ["    ", "def", "__init__", "(", "self", ",", "params", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "\n", "        ", "self", ".", "config", ":", "Dict", "[", "str", ",", "Any", "]", "=", "params", "\n", "\n", "# Load wikidata - satori pairs", "\n", "self", ".", "mapper", "=", "KBMapper", "(", ")", "\n", "self", ".", "mapper", ".", "init_pairs", "(", "self", ".", "config", "[", "'id_mapping_fn'", "]", ")", "\n", "\n", "# Stores prior information", "\n", "if", "self", ".", "config", "[", "\"candid_gen_method\"", "]", "==", "\"online\"", ":", "\n", "            ", "self", ".", "candid_gen", "=", "MixedCandidateMap", "(", "params", ")", "\n", "", "elif", "self", ".", "config", "[", "\"candid_gen_method\"", "]", "==", "\"offline\"", ":", "\n", "            ", "self", ".", "candid_gen", "=", "OfflineCandidateMap", "(", "params", "[", "\"candid_map_fn\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"unsupported candid_gen_method: {}\"", ".", "format", "(", "self", ".", "config", "[", "\"candid_gen_method\"", "]", ")", ")", "\n", "", "print", "(", "\"loading prior done.\"", ")", "\n", "\n", "self", ".", "entity_meta_info", "=", "EntityMetaInfo", "(", "params", ")", "\n", "self", ".", "property_info", "=", "KBPropertyVal", "(", "params", ")", "\n", "\n", "# Stores wikidata information", "\n", "self", ".", "wikidata", "=", "Wikidata", "(", "params", ",", "\n", "self", ".", "property_info", ",", "\n", "self", ".", "entity_meta_info", ")", "\n", "print", "(", "\"wikidata loaded.\"", ")", "\n", "\n", "self", ".", "iter_steps_count", "=", "dict", "(", ")", "\n", "self", ".", "time_counter", "=", "{", "\n", "\"kb_access\"", ":", "0", ",", "\n", "\"gen_candid\"", ":", "0", ",", "\n", "\"model_run\"", ":", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._extract_col_feature": [[51, 70], ["enumerate", "output_tab.index_one_col", "table_annotator.LinkingPark.wikidata.cosine_ent_sim", "col_support_scores.append", "sum"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_col", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.cosine_ent_sim"], ["", "def", "_extract_col_feature", "(", "self", ",", "\n", "ent", ":", "str", ",", "\n", "row_idx", ":", "int", ",", "\n", "col_idx", ":", "int", ",", "\n", "row_size", ":", "int", ",", "\n", "output_tab", ":", "OutputTable", ")", ":", "\n", "\n", "        ", "col_support_scores", "=", "[", "]", "\n", "\n", "for", "k", ",", "c2", "in", "enumerate", "(", "output_tab", ".", "index_one_col", "(", "output_tab", ".", "predict_entities", ",", "col_idx", ")", ")", ":", "\n", "# calculate entity similarity with other assigned entities in the same column", "\n", "            ", "if", "k", "!=", "row_idx", ":", "\n", "                ", "sim_score", "=", "self", ".", "wikidata", ".", "cosine_ent_sim", "(", "ent", ",", "c2", "[", "\"entity\"", "]", ")", "\n", "col_support_scores", ".", "append", "(", "sim_score", ")", "\n", "\n", "", "", "col_ent_sim_score", "=", "sum", "(", "col_support_scores", ")", "/", "(", "row_size", "-", "1", ")", "if", "row_size", ">", "1", "else", "0.0", "\n", "\n", "return", "col_ent_sim_score", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._extract_row_feature": [[71, 146], ["range", "table_annotator.LinkingPark.wikidata.retrieve_head_candid_tail_item_pair_possible_properties", "item_matched_properties.append", "table_annotator.LinkingPark.wikidata.retrieve_head_item_tail_candid_pair_possible_properties", "item_matched_properties.append", "table_annotator.LinkingPark.wikidata.retrieve_lexical_matched_possible_properties", "lexical_matched_properties.append", "output_tab.index_one_item", "len", "row_item_support_scores.append", "row_item_support_scores.append", "output_tab.index_one_item", "len", "row_item_support_scores.append", "row_item_support_scores.append", "tab.index_one_cell", "len", "row_lexical_support_scores.append", "row_lexical_support_scores.append", "sum", "max", "max", "max", "max", "tf_property_item_weights[].get", "tf_property_item_weights[].get", "zip", "tf_lexical_item_weights[].get"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.retrieve_head_candid_tail_item_pair_possible_properties", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.retrieve_head_item_tail_candid_pair_possible_properties", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.retrieve_lexical_matched_possible_properties", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_item", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_item", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.index_one_cell"], ["", "def", "_extract_row_feature", "(", "self", ",", "\n", "ent", ":", "str", ",", "\n", "tab", ":", "InputTable", ",", "\n", "output_tab", ":", "OutputTable", ",", "\n", "row_idx", ":", "int", ",", "\n", "col_idx", ":", "int", ",", "\n", "tf_property_item_weights", ":", "Dict", "[", "int", ",", "Dict", "[", "str", ",", "float", "]", "]", ",", "\n", "tf_lexical_item_weights", ":", "Dict", "[", "int", ",", "Dict", "[", "str", ",", "float", "]", "]", ",", "\n", "main_col_idx", "=", "0", ")", ":", "\n", "\n", "        ", "item_matched_properties", "=", "[", "]", "\n", "lexical_matched_properties", "=", "[", "]", "\n", "row_item_support_scores", "=", "[", "]", "\n", "row_lexical_support_scores", "=", "[", "]", "\n", "\n", "if", "col_idx", "==", "main_col_idx", ":", "\n", "\n", "# current column is main row, compare with all other columns", "\n", "            ", "for", "k", "in", "range", "(", "tab", ".", "col_size", ")", ":", "\n", "                ", "if", "k", "==", "main_col_idx", ":", "\n", "                    ", "continue", "\n", "\n", "# item property feature", "\n", "", "possible_item_property_feature", "=", "self", ".", "wikidata", ".", "retrieve_head_item_tail_candid_pair_possible_properties", "(", "\n", "ent", ",", "output_tab", ".", "index_one_item", "(", "output_tab", ".", "candid_list", ",", "row_idx", ",", "k", ")", ")", "\n", "if", "len", "(", "possible_item_property_feature", ")", ">", "0", ":", "\n", "                    ", "row_item_support_scores", ".", "append", "(", "max", "(", "tf_property_item_weights", "[", "k", "]", ".", "get", "(", "p", ",", "0.0", ")", "for", "p", "in", "\n", "possible_item_property_feature", ")", ")", "\n", "", "else", ":", "\n", "                    ", "row_item_support_scores", ".", "append", "(", "0.0", ")", "\n", "", "item_matched_properties", ".", "append", "(", "possible_item_property_feature", ")", "\n", "\n", "# lexical property feature", "\n", "possible_lexical_property_feature", "=", "self", ".", "wikidata", ".", "retrieve_lexical_matched_possible_properties", "(", "\n", "ent", ",", "\n", "tab", ".", "index_one_cell", "(", "row_idx", ",", "k", ")", ")", "\n", "lexical_matched_properties", ".", "append", "(", "possible_lexical_property_feature", ")", "\n", "\n", "if", "len", "(", "possible_lexical_property_feature", ")", ">", "0", ":", "\n", "                    ", "row_lexical_support_scores", ".", "append", "(", "max", "(", "\n", "tf_lexical_item_weights", "[", "k", "]", ".", "get", "(", "p", ",", "0.0", ")", "*", "possible_lexical_property_feature", "[", "p", "]", "for", "p", "in", "\n", "possible_lexical_property_feature", ")", ")", "\n", "", "else", ":", "\n", "                    ", "row_lexical_support_scores", ".", "append", "(", "0.0", ")", "\n", "", "", "row_support_score", "=", "sum", "(", "[", "max", "(", "s1", ",", "s2", ")", "for", "s1", ",", "s2", "in", "zip", "(", "row_item_support_scores", ",", "row_lexical_support_scores", ")", "]", ")", "/", "(", "tab", ".", "col_size", "-", "1", ")", "if", "tab", ".", "col_size", ">", "1", "else", "0.0", "\n", "\n", "property_info", "=", "{", "\n", "\"score\"", ":", "row_support_score", ",", "\n", "\"lexical_matched_properties\"", ":", "lexical_matched_properties", ",", "\n", "\"item_matched_properties\"", ":", "item_matched_properties", ",", "\n", "\"lexical_matched_properties_score\"", ":", "row_lexical_support_scores", ",", "\n", "\"item_matched_properties_score\"", ":", "row_item_support_scores", "\n", "}", "\n", "", "else", ":", "\n", "# item property feature", "\n", "            ", "possible_item_property_feature", "=", "self", ".", "wikidata", ".", "retrieve_head_candid_tail_item_pair_possible_properties", "(", "\n", "output_tab", ".", "index_one_item", "(", "output_tab", ".", "candid_list", ",", "row_idx", ",", "main_col_idx", ")", ",", "ent", ")", "\n", "\n", "if", "len", "(", "possible_item_property_feature", ")", ">", "0", ":", "\n", "                ", "row_item_support_scores", ".", "append", "(", "\n", "max", "(", "tf_property_item_weights", "[", "col_idx", "]", ".", "get", "(", "p", ",", "0.0", ")", "for", "p", "in", "\n", "possible_item_property_feature", ")", ")", "\n", "", "else", ":", "\n", "                ", "row_item_support_scores", ".", "append", "(", "0.0", ")", "\n", "\n", "", "item_matched_properties", ".", "append", "(", "possible_item_property_feature", ")", "\n", "row_support_score", "=", "row_item_support_scores", "[", "0", "]", "\n", "property_info", "=", "{", "\n", "\"score\"", ":", "row_support_score", ",", "\n", "\"item_matched_properties\"", ":", "item_matched_properties", ",", "\n", "\"item_matched_properties_score\"", ":", "row_item_support_scores", "\n", "}", "\n", "", "return", "property_info", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._extract_global_row_feature": [[147, 170], ["dict", "range", "range", "output_tab.index_one_item", "enumerate", "table_annotator.LinkingPark._extract_row_feature"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_item", "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._extract_row_feature"], ["", "def", "_extract_global_row_feature", "(", "self", ",", "\n", "tab", ":", "InputTable", ",", "\n", "output_tab", ":", "OutputTable", ",", "\n", "tf_property_item_weights", ":", "Dict", "[", "int", ",", "Dict", "[", "str", ",", "float", "]", "]", ",", "\n", "tf_lexical_item_weights", ":", "Dict", "[", "int", ",", "Dict", "[", "str", ",", "float", "]", "]", ",", "\n", "main_col_idx", "=", "0", ")", ":", "\n", "\n", "        ", "property_feature_cache", "=", "dict", "(", ")", "\n", "\n", "# calculate context score in each row and column for each cell", "\n", "for", "j", "in", "range", "(", "tab", ".", "col_size", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "tab", ".", "row_size", ")", ":", "\n", "# iterate each cell", "\n", "                ", "candid", "=", "output_tab", ".", "index_one_item", "(", "output_tab", ".", "candid_list", ",", "i", ",", "j", ")", "\n", "for", "k", ",", "c", "in", "enumerate", "(", "candid", ")", ":", "\n", "# extract row ent_sim features", "\n", "                    ", "property_info", "=", "self", ".", "_extract_row_feature", "(", "c", "[", "0", "]", ",", "tab", ",", "\n", "output_tab", ",", "i", ",", "j", ",", "\n", "tf_property_item_weights", ",", "\n", "tf_lexical_item_weights", ",", "\n", "main_col_idx", ")", "\n", "property_feature_cache", "[", "(", "i", ",", "j", ",", "c", "[", "0", "]", ")", "]", "=", "property_info", "\n", "", "", "", "return", "property_feature_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._generate_property_tf_weights": [[171, 200], ["dict", "dict", "range", "output_tab.index_one_col", "output_tab.index_one_col", "table_annotator.LinkingPark.wikidata.gen_candid_property_item_weights", "table_annotator.LinkingPark.wikidata.gen_candid_property_lexical_weights", "tab.index_one_col"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_col", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_col", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.gen_candid_property_item_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.wikidata.Wikidata.gen_candid_property_lexical_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_col"], ["", "def", "_generate_property_tf_weights", "(", "self", ",", "\n", "tab", ":", "InputTable", ",", "\n", "output_tab", ":", "OutputTable", ",", "\n", "main_col_idx", "=", "0", ")", ":", "\n", "# global tf weights", "\n", "        ", "tf_property_item_weights", "=", "dict", "(", ")", "\n", "tf_lexical_item_weights", "=", "dict", "(", ")", "\n", "\n", "# generate main' column & per target column's TF weights for row_ctx_scores", "\n", "for", "j", "in", "range", "(", "tab", ".", "col_size", ")", ":", "\n", "            ", "if", "j", "==", "main_col_idx", ":", "\n", "                ", "continue", "\n", "# use all candidates", "\n", "", "main_candid", "=", "output_tab", ".", "index_one_col", "(", "output_tab", ".", "candid_list", ",", "main_col_idx", ")", "\n", "target_candid", "=", "output_tab", ".", "index_one_col", "(", "output_tab", ".", "candid_list", ",", "j", ")", "\n", "\n", "# compare KB's values w.r.t entity in meaning space", "\n", "item_weights", "=", "self", ".", "wikidata", ".", "gen_candid_property_item_weights", "(", "\n", "main_candid", ",", "\n", "target_candid", ")", "\n", "tf_property_item_weights", "[", "j", "]", "=", "item_weights", "\n", "\n", "# compare KB's values w.r.t cell text in lexical space", "\n", "lexical_weights", "=", "self", ".", "wikidata", ".", "gen_candid_property_lexical_weights", "(", "\n", "main_candid", ",", "\n", "tab", ".", "index_one_col", "(", "j", ")", ")", "\n", "tf_lexical_item_weights", "[", "j", "]", "=", "lexical_weights", "\n", "\n", "", "return", "tf_property_item_weights", ",", "tf_lexical_item_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.ica_predict": [[201, 295], ["table_annotator.LinkingPark._generate_property_tf_weights", "table_annotator.LinkingPark._extract_global_row_feature", "output_tab.init_pred", "output_tab.set_property_feature_cache", "output_tab.set_tf_property_weights", "dict", "range", "output_tab.reassign_pred", "range", "output_tab.index_one_item", "enumerate", "candid_info.append", "table_annotator.LinkingPark._extract_col_feature", "table_annotator.LinkingPark._extract_row_feature"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._generate_property_tf_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._extract_global_row_feature", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.init_pred", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_property_feature_cache", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_tf_property_weights", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.reassign_pred", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.index_one_item", "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._extract_col_feature", "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark._extract_row_feature"], ["", "def", "ica_predict", "(", "self", ",", "\n", "tab", ",", "\n", "output_tab", ":", "OutputTable", ",", "\n", "init_prune_topk", ",", "\n", "max_iter", ",", "\n", "alpha", ",", "\n", "beta", ",", "\n", "gamma", ",", "\n", "row_feature_only", "=", "True", ",", "\n", "main_col_idx", "=", "0", ")", ":", "\n", "\n", "# generate global property tf weights", "\n", "        ", "tf_property_item_weights", ",", "tf_lexical_item_weights", "=", "self", ".", "_generate_property_tf_weights", "(", "tab", ",", "\n", "output_tab", ",", "\n", "main_col_idx", "=", "main_col_idx", ")", "\n", "\n", "# generate global row feature", "\n", "property_feature_cache", "=", "self", ".", "_extract_global_row_feature", "(", "tab", ",", "output_tab", ",", "\n", "tf_property_item_weights", ",", "\n", "tf_lexical_item_weights", ",", "\n", "main_col_idx", "=", "main_col_idx", ")", "\n", "\n", "# init predictions", "\n", "output_tab", ".", "init_pred", "(", "alpha", ",", "beta", ",", "gamma", ",", "property_feature_cache", ",", "init_prune_topk", ")", "\n", "\n", "has_changed", "=", "True", "\n", "iter_step", "=", "0", "\n", "\n", "# property_feature_cache = dict()", "\n", "'''\n        property feature cache: (i, j) ->\n                                {\n                                   \"score\": float,\n                                   \"lexical_matched_properties\": [],\n                                   \"item_matched_properties\": [],\n                                   \"lexical_matched_properties_score\": [],\n                                   \"item_matched_properties_score\": []\n                                }\n        where score = SUM(MAX(lexical_matched_properties_score, item_matched_properties_score)) / LEN(item_matched_properties_score)\n        '''", "\n", "\n", "while", "has_changed", "and", "iter_step", "<", "max_iter", ":", "\n", "            ", "iter_step", "+=", "1", "\n", "\n", "# calculate context score in each row and column for each cell", "\n", "candid_entities_info", "=", "dict", "(", ")", "\n", "for", "j", "in", "range", "(", "tab", ".", "col_size", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "tab", ".", "row_size", ")", ":", "\n", "# iterate each cell", "\n", "\n", "# extract col features", "\n", "                    ", "candid", "=", "output_tab", ".", "index_one_item", "(", "output_tab", ".", "candid_list", ",", "i", ",", "j", ")", "\n", "candid_info", "=", "[", "]", "\n", "for", "k", ",", "c", "in", "enumerate", "(", "candid", ")", ":", "\n", "# for each candidate entity of current cell", "\n", "                        ", "if", "not", "row_feature_only", ":", "\n", "                            ", "col_ent_sim_score", "=", "self", ".", "_extract_col_feature", "(", "c", "[", "0", "]", ",", "\n", "i", ",", "j", ",", "\n", "tab", ".", "row_size", ",", "\n", "output_tab", ")", "\n", "", "else", ":", "\n", "                            ", "col_ent_sim_score", "=", "0.0", "\n", "\n", "", "info", "=", "{", "\n", "\"col_ctx_score\"", ":", "col_ent_sim_score", ",", "\n", "\"str_sim\"", ":", "c", "[", "1", "]", ",", "\n", "\"popularity\"", ":", "c", "[", "2", "]", ",", "\n", "\"entity\"", ":", "c", "[", "0", "]", "\n", "}", "\n", "\n", "# extract row ent_sim features", "\n", "if", "(", "i", ",", "j", ",", "c", "[", "0", "]", ")", "in", "property_feature_cache", ":", "\n", "                            ", "property_info", "=", "property_feature_cache", "[", "(", "i", ",", "j", ",", "c", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "                            ", "property_info", "=", "self", ".", "_extract_row_feature", "(", "c", "[", "0", "]", ",", "tab", ",", "\n", "output_tab", ",", "i", ",", "j", ",", "\n", "tf_property_item_weights", ",", "\n", "tf_lexical_item_weights", ")", "\n", "property_feature_cache", "[", "(", "i", ",", "j", ",", "c", "[", "0", "]", ")", "]", "=", "property_info", "\n", "", "info", "[", "\"row_ctx_score\"", "]", "=", "property_info", "[", "\"score\"", "]", "\n", "# info[\"final\"] = alpha * info[\"col_ctx_score\"] + \\", "\n", "#                 beta * info[\"row_ctx_score\"] + \\", "\n", "#                 gamma * info[\"popularity\"] + \\", "\n", "#                 (1 - alpha - beta - gamma) * info[\"str_sim\"]", "\n", "info", "[", "\"final\"", "]", "=", "alpha", "*", "info", "[", "\"col_ctx_score\"", "]", "+", "beta", "*", "info", "[", "\"row_ctx_score\"", "]", "+", "(", "1", "-", "alpha", "-", "beta", ")", "*", "info", "[", "\"str_sim\"", "]", "\n", "candid_info", ".", "append", "(", "info", ")", "\n", "", "candid_entities_info", "[", "(", "i", ",", "j", ")", "]", "=", "candid_info", "\n", "\n", "", "", "has_changed", "=", "output_tab", ".", "reassign_pred", "(", "candid_entities_info", ")", "\n", "\n", "", "output_tab", ".", "set_property_feature_cache", "(", "property_feature_cache", ")", "\n", "output_tab", ".", "set_tf_property_weights", "(", "tf_property_item_weights", ",", "tf_lexical_item_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.gen_revisit_pred_entities": [[296, 318], ["copy.deepcopy", "range", "range", "table_annotator.LinkingPark.entity_meta_info.track_parents", "table_annotator.LinkingPark.entity_meta_info.track_parents"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_property_values_info_table_file.track_parents", "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_property_values_info_table_file.track_parents"], ["", "def", "gen_revisit_pred_entities", "(", "self", ",", "tab", ",", "output_tab", ",", "alpha", ",", "beta", ",", "tab_pred_type", ")", ":", "\n", "        ", "revisit_predict_entities", "=", "copy", ".", "deepcopy", "(", "output_tab", ".", "predict_entities", ")", "\n", "for", "j", "in", "range", "(", "tab", ".", "col_size", ")", ":", "\n", "            ", "if", "j", ">", "0", ":", "\n", "                ", "continue", "\n", "", "best_type", "=", "tab_pred_type", "[", "j", "]", "[", "\"best_type\"", "]", "\n", "for", "i", "in", "range", "(", "tab", ".", "row_size", ")", ":", "\n", "# If a top candidate for an entity does not have the best type, then we look through", "\n", "# the list of candidates before they were short-listed to see if any of them have that type.", "\n", "                ", "if", "best_type", "not", "in", "self", ".", "entity_meta_info", ".", "track_parents", "(", "\n", "revisit_predict_entities", "[", "(", "i", ",", "j", ")", "]", "[", "\"entity\"", "]", ",", "\n", "self", ".", "config", "[", "\"k_level\"", "]", ")", ":", "\n", "                    ", "for", "c", "in", "output_tab", ".", "candid_list_before_shortlist", "[", "(", "i", ",", "j", ")", "]", ":", "\n", "                        ", "if", "best_type", "in", "self", ".", "entity_meta_info", ".", "track_parents", "(", "c", "[", "0", "]", ",", "self", ".", "config", "[", "\"k_level\"", "]", ")", ":", "\n", "                            ", "revisit_predict_entities", "[", "(", "i", ",", "j", ")", "]", "=", "{", "\"entity\"", ":", "c", "[", "0", "]", ",", "\n", "\"str_sim\"", ":", "c", "[", "1", "]", ",", "\n", "\"popularity\"", ":", "c", "[", "2", "]", ",", "\n", "\"col_ctx_score\"", ":", "0.0", ",", "\n", "\"row_ctx_score\"", ":", "0.0", ",", "\n", "\"final\"", ":", "(", "1", "-", "alpha", "-", "beta", ")", "*", "c", "[", "1", "]", "}", "\n", "break", "\n", "", "", "", "", "", "return", "revisit_predict_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.gen_property_outputs": [[319, 347], ["dict", "range", "dict", "sorted", "list_info.append", "table_annotator.LinkingPark.entity_meta_info.get_item_name"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name"], ["", "def", "gen_property_outputs", "(", "self", ",", "out_tab", ",", "main_col_idx", "=", "0", ")", ":", "\n", "        ", "pre_property", "=", "dict", "(", ")", "\n", "lexical_property_info", "=", "out_tab", ".", "tf_lexical_item_weights", "\n", "item_property_info", "=", "out_tab", ".", "tf_property_item_weights", "\n", "\n", "for", "i", "in", "range", "(", "out_tab", ".", "tab", ".", "col_size", ")", ":", "\n", "            ", "if", "i", "==", "main_col_idx", ":", "\n", "                ", "continue", "\n", "", "col_pre_property", "=", "dict", "(", ")", "\n", "for", "p", "in", "lexical_property_info", "[", "i", "]", ":", "\n", "                ", "col_pre_property", "[", "p", "]", "=", "lexical_property_info", "[", "i", "]", "[", "p", "]", "\n", "", "for", "p", "in", "item_property_info", "[", "i", "]", ":", "\n", "                ", "if", "p", "not", "in", "col_pre_property", ":", "\n", "                    ", "col_pre_property", "[", "p", "]", "=", "item_property_info", "[", "i", "]", "[", "p", "]", "\n", "", "else", ":", "\n", "                    ", "if", "item_property_info", "[", "i", "]", "[", "p", "]", ">", "col_pre_property", "[", "p", "]", ":", "\n", "                        ", "col_pre_property", "[", "p", "]", "=", "item_property_info", "[", "i", "]", "[", "p", "]", "\n", "", "", "", "list_info", "=", "[", "]", "\n", "for", "p", "in", "col_pre_property", ":", "\n", "                ", "list_info", ".", "append", "(", "\n", "{", "\n", "\"property_name\"", ":", "self", ".", "entity_meta_info", ".", "get_item_name", "(", "p", ")", ",", "\n", "\"property\"", ":", "p", ",", "\n", "\"confidence\"", ":", "col_pre_property", "[", "p", "]", "\n", "}", "\n", ")", "\n", "", "pre_property", "[", "i", "]", "=", "sorted", "(", "list_info", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"confidence\"", "]", ",", "reverse", "=", "True", ")", "\n", "", "return", "pre_property", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.detect_single_table": [[348, 421], ["datetime.datetime.datetime.now", "TableAnnotator.Util.utils.OutputTable", "tab.get_main_column_idx", "datetime.datetime.datetime.now", "TableAnnotator.Util.utils.OutputTable.gen_candidates", "datetime.datetime.datetime.now", "datetime.datetime.datetime.now", "table_annotator.LinkingPark.ica_predict", "table_annotator.LinkingPark.gen_property_outputs", "TableAnnotator.Util.utils.OutputTable.set_pre_property", "TableAnnotator.Util.utils.OutputTable.resort_final_prior", "table_annotator.LinkingPark.wikidata.wikidata_ent_type_map.pred_type", "TableAnnotator.Util.utils.OutputTable.set_tab_pred_type", "table_annotator.LinkingPark.gen_revisit_pred_entities", "TableAnnotator.Util.utils.OutputTable.set_revisit_pred", "TableAnnotator.Util.utils.OutputTable.add_ent_title", "TableAnnotator.Util.utils.OutputTable.set_main_col_idx", "datetime.datetime.datetime.now", "TableAnnotator.Util.utils.OutputTable.gen_ent_set", "table_annotator.LinkingPark.entity_meta_info.retrieve_candid_kb_info", "table_annotator.LinkingPark.property_info.retrieve_candid_kb_info", "table_annotator.LinkingPark.entity_meta_info.free", "table_annotator.LinkingPark.property_info.free"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.InputTable.get_main_column_idx", "home.repos.pwc.inspect_result.microsoft_vert-papers.candid_gen.all_in_one.gen_candidates", "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.ica_predict", "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.gen_property_outputs", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_pre_property", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.resort_final_prior", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.type_voter.TypeInference.pred_type", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_tab_pred_type", "home.repos.pwc.inspect_result.microsoft_vert-papers.Detect.table_annotator.LinkingPark.gen_revisit_pred_entities", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_revisit_pred", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.add_ent_title", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.set_main_col_idx", "home.repos.pwc.inspect_result.microsoft_vert-papers.Util.utils.OutputTable.gen_ent_set", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.retrieve_candid_kb_info", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.retrieve_candid_kb_info", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.free", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.entity_meta_info.EntityMetaInfo.free"], ["", "def", "detect_single_table", "(", "self", ",", "\n", "tab", ":", "InputTable", ",", "\n", "keep_N", "=", "10", ",", "\n", "alpha", "=", "0.4", ",", "\n", "beta", "=", "0.3", ",", "\n", "gamma", "=", "0.1", ",", "\n", "max_iter", "=", "10", ",", "\n", "topk", "=", "20", ",", "\n", "init_prune_topk", "=", "10", ",", "\n", "min_final_diff", "=", "0.01", ",", "\n", "row_feature_only", "=", "True", ",", "\n", "map_ids", "=", "False", ")", ":", "\n", "\n", "        ", "start", "=", "datetime", ".", "now", "(", ")", "\n", "\n", "# init a output table", "\n", "output_tab", "=", "OutputTable", "(", "tab", ",", "map_ids", ",", "self", ".", "mapper", ")", "\n", "\n", "# content analysis", "\n", "main_col_idx", "=", "tab", ".", "get_main_column_idx", "(", ")", "\n", "\n", "t1", "=", "datetime", ".", "now", "(", ")", "\n", "# generate candidates", "\n", "# topk is the initial candidate size", "\n", "# keep_N is the shortlisted candidate size", "\n", "output_tab", ".", "gen_candidates", "(", "self", ".", "candid_gen", ",", "topk", ",", "keep_N", ")", "\n", "t2", "=", "datetime", ".", "now", "(", ")", "\n", "self", ".", "time_counter", "[", "'gen_candid'", "]", "+=", "(", "t2", "-", "t1", ")", ".", "total_seconds", "(", ")", "\n", "\n", "if", "self", ".", "config", "[", "'kb_store'", "]", "!=", "'RAM'", ":", "\n", "            ", "ent_set", "=", "output_tab", ".", "gen_ent_set", "(", ")", "\n", "self", ".", "entity_meta_info", ".", "retrieve_candid_kb_info", "(", "ent_set", ")", "\n", "self", ".", "property_info", ".", "retrieve_candid_kb_info", "(", "ent_set", ")", "\n", "", "t3", "=", "datetime", ".", "now", "(", ")", "\n", "self", ".", "time_counter", "[", "'kb_access'", "]", "+=", "(", "t3", "-", "t2", ")", ".", "total_seconds", "(", ")", "\n", "\n", "# ICA", "\n", "self", ".", "ica_predict", "(", "tab", ",", "output_tab", ",", "init_prune_topk", ",", "\n", "max_iter", ",", "alpha", ",", "beta", ",", "gamma", ",", "\n", "row_feature_only", "=", "row_feature_only", ",", "\n", "main_col_idx", "=", "main_col_idx", ")", "\n", "\n", "# generate property outputs", "\n", "pre_property_coarse", "=", "self", ".", "gen_property_outputs", "(", "output_tab", ",", "main_col_idx", "=", "main_col_idx", ")", "\n", "output_tab", ".", "set_pre_property", "(", "pre_property_coarse", ")", "\n", "\n", "# resort prior if top2 diff is smaller than min_final_diff", "\n", "output_tab", ".", "resort_final_prior", "(", "min_final_diff", ")", "\n", "\n", "# vote type", "\n", "tab_pred_type", "=", "self", ".", "wikidata", ".", "wikidata_ent_type_map", ".", "pred_type", "(", "tab", ",", "\n", "output_tab", ",", "\n", "main_col_idx", "=", "main_col_idx", ")", "\n", "output_tab", ".", "set_tab_pred_type", "(", "tab_pred_type", ")", "\n", "\n", "# gen revisit predict entities", "\n", "revisit_predict_entities", "=", "self", ".", "gen_revisit_pred_entities", "(", "tab", ",", "output_tab", ",", "alpha", ",", "beta", ",", "tab_pred_type", ")", "\n", "\n", "# set predictions", "\n", "output_tab", ".", "set_revisit_pred", "(", "revisit_predict_entities", ")", "\n", "output_tab", ".", "add_ent_title", "(", "self", ".", "entity_meta_info", ")", "\n", "\n", "# set main_col_idx", "\n", "output_tab", ".", "set_main_col_idx", "(", "main_col_idx", "=", "main_col_idx", ")", "\n", "\n", "if", "self", ".", "config", "[", "'kb_store'", "]", "!=", "'RAM'", ":", "\n", "# Free KB cache", "\n", "            ", "self", ".", "entity_meta_info", ".", "free", "(", ")", "\n", "self", ".", "property_info", ".", "free", "(", ")", "\n", "", "end", "=", "datetime", ".", "now", "(", ")", "\n", "self", ".", "time_counter", "[", "\"model_run\"", "]", "+=", "(", "end", "-", "start", ")", ".", "total_seconds", "(", ")", "-", "(", "t3", "-", "t1", ")", ".", "total_seconds", "(", ")", "\n", "\n", "return", "output_tab", "\n", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.extract_ent_types.extract_type_rank_data": [[11, 42], ["open", "dict", "tqdm.tqdm", "json.loads", "set", "list", "open", "pickle.dump", "line.strip", "[].append", "set.add", "[].append", "set.add"], "function", ["None"], ["def", "extract_type_rank_data", "(", "fn", ",", "re_rank_fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "type_rank_map", "=", "dict", "(", ")", "\n", "# num = 0", "\n", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "node", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "type_rank_map", "[", "node", "[", "\"id\"", "]", "]", "=", "{", "\n", "\"instance_of\"", ":", "[", "]", ",", "\n", "\"subclass_of\"", ":", "[", "]", "\n", "}", "\n", "\n", "types", "=", "set", "(", ")", "\n", "if", "'P31'", "in", "node", "[", "\"property_values\"", "]", ":", "\n", "                ", "for", "value", "in", "node", "[", "\"property_values\"", "]", "[", "\"P31\"", "]", ":", "\n", "                    ", "if", "value", "[", "\"datatype\"", "]", "==", "\"wikibase-item\"", ":", "\n", "                        ", "type_rank_map", "[", "node", "[", "\"id\"", "]", "]", "[", "\"instance_of\"", "]", ".", "append", "(", "value", "[", "\"datavalue\"", "]", "[", "\"value\"", "]", "[", "\"id\"", "]", ")", "\n", "types", ".", "add", "(", "value", "[", "\"datavalue\"", "]", "[", "\"value\"", "]", "[", "\"id\"", "]", ")", "\n", "\n", "", "", "", "if", "'P279'", "in", "node", "[", "\"property_values\"", "]", ":", "\n", "                ", "for", "value", "in", "node", "[", "\"property_values\"", "]", "[", "\"P279\"", "]", ":", "\n", "                    ", "if", "value", "[", "\"datatype\"", "]", "==", "\"wikibase-item\"", ":", "\n", "                        ", "type_rank_map", "[", "node", "[", "\"id\"", "]", "]", "[", "\"subclass_of\"", "]", ".", "append", "(", "value", "[", "\"datavalue\"", "]", "[", "\"value\"", "]", "[", "\"id\"", "]", ")", "\n", "types", ".", "add", "(", "value", "[", "\"datavalue\"", "]", "[", "\"value\"", "]", "[", "\"id\"", "]", ")", "\n", "\n", "", "", "", "type_rank_map", "[", "node", "[", "\"id\"", "]", "]", "[", "\"types\"", "]", "=", "list", "(", "types", ")", "\n", "# num += 1", "\n", "# if num % 10000 == 0:", "\n", "#     print(\"processing {} lines...\".format(num))", "\n", "\n", "", "with", "open", "(", "re_rank_fn", ",", "mode", "=", "\"wb\"", ")", "as", "re_fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "type_rank_map", ",", "re_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.extract_disambiguation_pages.load_pkl": [[10, 14], ["open", "pickle.load"], "function", ["None"], ["def", "load_pkl", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "pkl", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "pkl", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.extract_disambiguation_pages.filter_disambiguation_pages": [[16, 26], ["set", "tqdm.tqdm", "print", "set", "open", "pickle.dump", "len", "set.add", "len"], "function", ["None"], ["", "", "def", "filter_disambiguation_pages", "(", "ent_types", ",", "re_fn", ")", ":", "\n", "    ", "disambiguation_set", "=", "set", "(", ")", "\n", "for", "ent", "in", "tqdm", "(", "ent_types", ")", ":", "\n", "        ", "_types", "=", "set", "(", "ent_types", "[", "ent", "]", "[", "\"types\"", "]", ")", "\n", "if", "len", "(", "_types", "&", "{", "\"Q4167410\"", ",", "\"Q1151870\"", "}", ")", ">", "0", ":", "\n", "            ", "disambiguation_set", ".", "add", "(", "ent", ")", "\n", "\n", "", "", "print", "(", "\"number of disambiguation pages: {}\"", ".", "format", "(", "len", "(", "disambiguation_set", ")", ")", ")", "\n", "with", "open", "(", "re_fn", ",", "mode", "=", "\"wb\"", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "disambiguation_set", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.convert_wikidata_kb_json_format.parse_one_file": [[11, 68], ["open", "open", "tqdm.tqdm", "json.loads", "re_fp.write", "line.strip", "json.dumps", "value.strip", "[].append", "print", "print", "float", "float", "float", "re.findall"], "function", ["None"], ["def", "parse_one_file", "(", "fn", ",", "out_fn", ")", ":", "\n", "\n", "    ", "with", "open", "(", "fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "out_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "json_obj", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "wikidata", "=", "{", "\n", "\"id\"", ":", "json_obj", "[", "\"id\"", "]", "\n", "}", "\n", "\n", "wikidata", "[", "\"type\"", "]", "=", "json_obj", "[", "\"type\"", "]", "\n", "wikidata", "[", "\"properties\"", "]", "=", "json_obj", "[", "\"properties\"", "]", "\n", "wikidata", "[", "\"property_values\"", "]", "=", "{", "}", "\n", "\n", "for", "property", "in", "json_obj", "[", "\"property_values\"", "]", ":", "\n", "                    ", "wikidata", "[", "\"property_values\"", "]", "[", "property", "]", "=", "[", "]", "\n", "for", "value", "in", "json_obj", "[", "\"property_values\"", "]", "[", "property", "]", ":", "\n", "                        ", "datavalue", "=", "value", "[", "\"datavalue\"", "]", "\n", "datatype", "=", "datavalue", "[", "\"type\"", "]", "\n", "value", "=", "datavalue", "[", "\"value\"", "]", "\n", "obj", "=", "{", "\"dtype\"", ":", "datatype", "}", "\n", "try", ":", "\n", "                            ", "if", "datatype", "==", "\"string\"", ":", "\n", "                                ", "obj", "[", "\"value\"", "]", "=", "value", ".", "strip", "(", ")", "\n", "", "elif", "datatype", "==", "\"quantity\"", ":", "\n", "# TODO why use regular expression to convert amount?", "\n", "# amount = float(re.findall(\"[-]?[0-9]*\\.?[0-9]+\", value[\"amount\"])[0])", "\n", "                                ", "amount", "=", "float", "(", "value", "[", "\"amount\"", "]", ")", "\n", "try", ":", "\n", "                                    ", "unit", "=", "re", ".", "findall", "(", "'Q\\w+'", ",", "value", "[", "\"unit\"", "]", ")", "[", "0", "]", "\n", "# No units specified in wikidata", "\n", "", "except", "IndexError", ":", "\n", "                                    ", "unit", "=", "1", "\n", "", "obj", "[", "\"value\"", "]", "=", "amount", "\n", "obj", "[", "\"unit\"", "]", "=", "unit", "\n", "if", "\"lowerBound\"", "in", "value", ":", "\n", "                                    ", "obj", "[", "\"lowerBound\"", "]", "=", "float", "(", "value", "[", "\"lowerBound\"", "]", ")", "\n", "# print(datavalue)", "\n", "", "if", "\"upperBound\"", "in", "value", ":", "\n", "                                    ", "obj", "[", "\"upperBound\"", "]", "=", "float", "(", "value", "[", "\"upperBound\"", "]", ")", "\n", "# print(datavalue)", "\n", "", "", "elif", "datatype", "==", "\"time\"", ":", "\n", "                                ", "obj", "[", "\"value\"", "]", "=", "value", "[", "\"time\"", "]", "\n", "", "elif", "datatype", "==", "\"monolingualtext\"", ":", "\n", "                                ", "obj", "[", "\"value\"", "]", "=", "value", "[", "\"text\"", "]", "\n", "", "elif", "datatype", "==", "\"wikibase-entityid\"", ":", "\n", "                                ", "obj", "[", "\"value\"", "]", "=", "value", "[", "\"id\"", "]", "\n", "", "else", ":", "\n", "                                ", "obj", "[", "\"value\"", "]", "=", "value", "\n", "", "if", "\"value\"", "in", "obj", ":", "\n", "                                ", "wikidata", "[", "\"property_values\"", "]", "[", "property", "]", ".", "append", "(", "obj", ")", "\n", "", "else", ":", "\n", "                                ", "print", "(", "datavalue", ")", "\n", "", "", "except", ":", "\n", "                            ", "print", "(", "line", ")", "\n", "", "", "", "re_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "wikidata", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_ent_meta_info_table_file.load_pkl": [[11, 15], ["open", "pickle.load"], "function", ["None"], ["def", "load_pkl", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "pkl", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "pkl", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_ent_meta_info_table_file.extract_aliases": [[17, 25], ["set", "list", "set.add", "set.add"], "function", ["None"], ["", "", "def", "extract_aliases", "(", "ent_info", ")", ":", "\n", "    ", "aliases", "=", "set", "(", ")", "\n", "for", "lang_code", "in", "ent_info", "[", "\"labels\"", "]", ":", "\n", "        ", "aliases", ".", "add", "(", "ent_info", "[", "\"labels\"", "]", "[", "lang_code", "]", ")", "\n", "\n", "", "for", "alias", "in", "ent_info", "[", "\"aliases\"", "]", ":", "\n", "        ", "aliases", ".", "add", "(", "alias", ")", "\n", "", "return", "list", "(", "aliases", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_ent_meta_info_table_file.generate_ent_meta_table": [[27, 56], ["open", "open", "tqdm.tqdm", "json.loads", "entity[].get", "generate_ent_meta_info_table_file.extract_aliases", "re_fp.write", "line.strip", "json.dumps"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_ent_meta_info_table_file.extract_aliases"], ["", "def", "generate_ent_meta_table", "(", "ent_types", ",", "in_fn", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "entity", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "ent_name", "=", "entity", "[", "\"labels\"", "]", ".", "get", "(", "\"en\"", ",", "\"No_label_defined\"", ")", "\n", "aliases", "=", "extract_aliases", "(", "entity", ")", "\n", "types", "=", "[", "]", "\n", "types_rank", "=", "{", "\n", "'instance_of'", ":", "[", "]", ",", "\n", "'subclass_of'", ":", "[", "]", "\n", "}", "\n", "\n", "if", "entity", "[", "\"id\"", "]", "in", "ent_types", ":", "\n", "                    ", "types", "=", "ent_types", "[", "entity", "[", "\"id\"", "]", "]", "[", "\"types\"", "]", "\n", "types_rank", "=", "{", "\n", "'instance_of'", ":", "ent_types", "[", "entity", "[", "\"id\"", "]", "]", "[", "'instance_of'", "]", ",", "\n", "'subclass_of'", ":", "ent_types", "[", "entity", "[", "\"id\"", "]", "]", "[", "'subclass_of'", "]", "\n", "}", "\n", "\n", "", "obj", "=", "{", "\n", "\"id\"", ":", "entity", "[", "\"id\"", "]", ",", "\n", "\"ent_name\"", ":", "ent_name", ",", "\n", "\"aliases\"", ":", "aliases", ",", "\n", "\"types\"", ":", "types", ",", "\n", "\"types_rank\"", ":", "types_rank", "\n", "}", "\n", "\n", "re_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "obj", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.extract_wikidata_alias_map.extract_alias_data": [[11, 34], ["open", "dict", "tqdm.tqdm", "set", "json.loads", "open", "pickle.dump", "line.strip", "set.add", "set.add", "alias_map[].append"], "function", ["None"], ["def", "extract_alias_data", "(", "fn", ",", "re_fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "alias_map", "=", "dict", "(", ")", "\n", "\n", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "aliases", "=", "set", "(", ")", "\n", "node", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "for", "lang_code", "in", "node", "[", "\"labels\"", "]", ":", "\n", "                ", "aliases", ".", "add", "(", "node", "[", "\"labels\"", "]", "[", "lang_code", "]", ")", "\n", "\n", "", "for", "alias", "in", "node", "[", "\"aliases\"", "]", ":", "\n", "                ", "aliases", ".", "add", "(", "alias", ")", "\n", "\n", "", "for", "alias", "in", "aliases", ":", "\n", "                ", "if", "alias", "not", "in", "alias_map", ":", "\n", "                    ", "alias_map", "[", "alias", "]", "=", "[", "]", "\n", "", "alias_map", "[", "alias", "]", ".", "append", "(", "node", "[", "\"id\"", "]", ")", "\n", "# num += 1", "\n", "# if num % 10000 == 0:", "\n", "#     print(\"processing {} lines...\".format(num))", "\n", "\n", "", "", "with", "open", "(", "re_fn", ",", "mode", "=", "\"wb\"", ")", "as", "re_fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "alias_map", ",", "re_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.combine_wikipedia_alias_map_wikidata_aliases.load_alias_map": [[9, 13], ["open", "pickle.load"], "function", ["None"], ["def", "load_alias_map", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "alias_map", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "alias_map", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.combine_wikipedia_alias_map_wikidata_aliases.load_disambiguation_pages": [[15, 19], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "load_disambiguation_pages", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "disambiguation_pages", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "disambiguation_pages", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.combine_wikipedia_alias_map_wikidata_aliases.load_wiki_id2wikidata_id": [[21, 30], ["open", "pickle.load", "dict", "str"], "function", ["None"], ["", "", "def", "load_wiki_id2wikidata_id", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "unify_kb_map", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "wiki_id2wikidata_id", "=", "dict", "(", ")", "\n", "\n", "for", "wiki_id", "in", "unify_kb_map", ":", "\n", "            ", "if", "unify_kb_map", "[", "wiki_id", "]", "[", "\"wikidata_id\"", "]", ":", "\n", "                ", "wiki_id2wikidata_id", "[", "str", "(", "wiki_id", ")", "]", "=", "unify_kb_map", "[", "wiki_id", "]", "[", "\"wikidata_id\"", "]", "\n", "", "", "return", "wiki_id2wikidata_id", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.combine_wikipedia_alias_map_wikidata_aliases.load_wikidata_alias_map": [[32, 36], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "load_wikidata_alias_map", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "wikidata_alias_map", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "wikidata_alias_map", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.combine_wikipedia_alias_map_wikidata_aliases.merge": [[38, 71], ["dict", "set", "dict", "open", "pickle.dump", "len", "list", "list", "set.add", "len", "set"], "function", ["None"], ["", "", "def", "merge", "(", "wikipedia_alias_map", ",", "wikidata_alias_map", ",", "\n", "wiki_id2wikidata_id", ",", "disambiguation_pages", ",", "\n", "out_fn", ",", "min_threshold", "=", "0.01", ",", "rm_disambiguation", "=", "True", ")", ":", "\n", "    ", "filtered_wikipedia_alias_map", "=", "dict", "(", ")", "\n", "for", "alias", "in", "wikipedia_alias_map", ":", "\n", "        ", "wikidata_ids", "=", "set", "(", ")", "\n", "for", "c", "in", "wikipedia_alias_map", "[", "alias", "]", ":", "\n", "            ", "wiki_id", "=", "c", "[", "1", "]", "\n", "if", "wiki_id", "in", "wiki_id2wikidata_id", "and", "c", "[", "2", "]", ">=", "min_threshold", ":", "\n", "                ", "wikidata_id", "=", "wiki_id2wikidata_id", "[", "wiki_id", "]", "\n", "wikidata_ids", ".", "add", "(", "wikidata_id", ")", "\n", "", "", "if", "len", "(", "wikidata_ids", ")", ">", "0", ":", "\n", "            ", "filtered_wikipedia_alias_map", "[", "alias", "]", "=", "wikidata_ids", "\n", "\n", "", "", "for", "alias", "in", "filtered_wikipedia_alias_map", ":", "\n", "        ", "if", "alias", "not", "in", "wikidata_alias_map", ":", "\n", "            ", "wikidata_alias_map", "[", "alias", "]", "=", "list", "(", "filtered_wikipedia_alias_map", "[", "alias", "]", ")", "\n", "", "else", ":", "\n", "            ", "wikidata_alias_map", "[", "alias", "]", "=", "list", "(", "filtered_wikipedia_alias_map", "[", "alias", "]", "\n", "|", "set", "(", "wikidata_alias_map", "[", "alias", "]", ")", ")", "\n", "\n", "", "", "if", "rm_disambiguation", ":", "\n", "        ", "result", "=", "dict", "(", ")", "\n", "for", "alias", "in", "wikidata_alias_map", ":", "\n", "            ", "candid", "=", "wikidata_alias_map", "[", "alias", "]", "\n", "candid", "=", "[", "c", "for", "c", "in", "candid", "if", "c", "not", "in", "disambiguation_pages", "]", "\n", "if", "len", "(", "candid", ")", ">", "0", ":", "\n", "                ", "result", "[", "alias", "]", "=", "candid", "\n", "", "", "", "else", ":", "\n", "        ", "result", "=", "wikidata_alias_map", "\n", "\n", "", "with", "open", "(", "out_fn", ",", "mode", "=", "\"wb\"", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "result", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.extract_wikidata_labels.extract_labels_data": [[11, 21], ["open", "dict", "tqdm.tqdm", "json.loads", "open", "pickle.dump", "line.strip"], "function", ["None"], ["def", "extract_labels_data", "(", "fn", ",", "re_fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "label_map", "=", "dict", "(", ")", "\n", "\n", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "node", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "label_map", "[", "node", "[", "'id'", "]", "]", "=", "node", "[", "'labels'", "]", "\n", "\n", "", "with", "open", "(", "re_fn", ",", "mode", "=", "\"wb\"", ")", "as", "re_fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "label_map", ",", "re_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.parse_bz_dump.process_one_line_all_properties": [[19, 76], ["dict", "set", "dict", "list", "json_obj[].keys", "list", "json.dumps", "json.dumps", "set.add", "values.append"], "function", ["None"], ["def", "process_one_line_all_properties", "(", "json_obj", ")", ":", "\n", "    ", "ent_id", "=", "json_obj", "[", "'id'", "]", "\n", "t", "=", "json_obj", "[", "\"type\"", "]", "\n", "# en_label", "\n", "if", "\"en\"", "in", "json_obj", "[", "\"labels\"", "]", "and", "\"value\"", "in", "json_obj", "[", "\"labels\"", "]", "[", "\"en\"", "]", ":", "\n", "        ", "en_label", "=", "json_obj", "[", "'labels'", "]", "[", "'en'", "]", "[", "'value'", "]", "\n", "", "else", ":", "\n", "        ", "en_label", "=", "\"No_label_defined\"", "\n", "\n", "# multi-language labels", "\n", "", "labels", "=", "dict", "(", ")", "\n", "for", "lang_code", "in", "json_obj", "[", "\"labels\"", "]", ":", "\n", "        ", "labels", "[", "lang_code", "]", "=", "json_obj", "[", "\"labels\"", "]", "[", "lang_code", "]", "[", "'value'", "]", "\n", "\n", "# multi-language aliases", "\n", "", "aliases", "=", "set", "(", ")", "\n", "for", "lang_code", "in", "json_obj", "[", "\"aliases\"", "]", ":", "\n", "        ", "for", "alias", "in", "json_obj", "[", "\"aliases\"", "]", "[", "lang_code", "]", ":", "\n", "            ", "aliases", ".", "add", "(", "alias", "[", "'value'", "]", ")", "\n", "\n", "# multi-language descriptions", "\n", "", "", "descriptions", "=", "dict", "(", ")", "\n", "for", "lang_code", "in", "json_obj", "[", "\"descriptions\"", "]", ":", "\n", "        ", "descriptions", "[", "lang_code", "]", "=", "json_obj", "[", "\"descriptions\"", "]", "[", "lang_code", "]", "[", "'value'", "]", "\n", "\n", "", "properties", "=", "list", "(", "json_obj", "[", "\"claims\"", "]", ".", "keys", "(", ")", ")", "\n", "property_values", "=", "{", "}", "\n", "for", "prop", "in", "json_obj", "[", "\"claims\"", "]", ":", "\n", "        ", "values", "=", "[", "]", "\n", "for", "snak", "in", "json_obj", "[", "\"claims\"", "]", "[", "prop", "]", ":", "\n", "            ", "mainsnak", "=", "snak", "[", "\"mainsnak\"", "]", "\n", "datatype", "=", "mainsnak", "[", "\"datatype\"", "]", "\n", "snaketype", "=", "mainsnak", "[", "\"snaktype\"", "]", "\n", "if", "snaketype", "==", "\"value\"", ":", "\n", "                ", "values", ".", "append", "(", "{", "\n", "\"datatype\"", ":", "datatype", ",", "\n", "\"datavalue\"", ":", "mainsnak", "[", "\"datavalue\"", "]", "\n", "}", ")", "\n", "", "", "if", "values", ":", "\n", "            ", "property_values", "[", "prop", "]", "=", "values", "\n", "\n", "", "", "output", "=", "{", "\n", "\"id\"", ":", "ent_id", ",", "\n", "\"type\"", ":", "t", ",", "\n", "\"en_label\"", ":", "en_label", ",", "\n", "\"properties\"", ":", "properties", ",", "\n", "\"property_values\"", ":", "property_values", "\n", "}", "\n", "\n", "ent_meta_info", "=", "{", "\n", "\"id\"", ":", "ent_id", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "\"aliases\"", ":", "list", "(", "aliases", ")", ",", "\n", "\"descriptions\"", ":", "descriptions", "\n", "}", "\n", "\n", "return", "json", ".", "dumps", "(", "output", ")", ",", "json", ".", "dumps", "(", "ent_meta_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.parse_bz_dump.process_one_file": [[78, 102], ["bz2.open", "open", "os.path.join", "open", "os.path.join", "tqdm.tqdm", "pbar.update", "json.loads", "parse_bz_dump.process_one_line_all_properties", "property_out_fp.write", "meta_out_fp.write", "line.strip().strip.strip().strip", "line.strip().strip.strip().strip", "print", "sys.exc_info", "print", "len", "print", "line.strip().strip.strip", "line.strip().strip.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.site_links_utils.extract_wikidata_sitelinks.process_one_line_all_properties"], ["", "def", "process_one_file", "(", "total_lines", ",", "in_fn", ",", "dump_dir", ")", ":", "\n", "    ", "with", "bz2", ".", "open", "(", "in_fn", ",", "\"rt\"", ")", "as", "in_fp", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "\"properties.jsonl\"", ")", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "property_out_fp", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "\"meta.jsonl\"", ")", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "meta_out_fp", ":", "\n", "                ", "with", "tqdm", "(", "total", "=", "total_lines", ")", "as", "pbar", ":", "\n", "                    ", "for", "line", "in", "in_fp", ":", "\n", "                        ", "pbar", ".", "update", "(", ")", "\n", "try", ":", "\n", "                            ", "json_obj", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ".", "strip", "(", "','", ")", ")", "\n", "property_values", ",", "meta_info", "=", "process_one_line_all_properties", "(", "json_obj", ")", "\n", "\n", "property_out_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "property_values", ")", ")", "\n", "meta_out_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "meta_info", ")", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                            ", "line", "=", "line", ".", "strip", "(", ")", ".", "strip", "(", "','", ")", "\n", "print", "(", "line", ")", "\n", "\n", "exc_type", ",", "exc_obj", ",", "exc_tb", "=", "sys", ".", "exc_info", "(", ")", "\n", "print", "(", "\"Exception:\"", ",", "exc_type", ",", "\"- line\"", ",", "exc_tb", ".", "tb_lineno", ")", "\n", "if", "len", "(", "line", ")", "<", "30", ":", "\n", "                                ", "print", "(", "\"Failed line:\"", ",", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_property_values_info_table_file.load_type_map": [[14, 21], ["open", "pickle.load", "dict", "set"], "function", ["None"], ["def", "load_type_map", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "pkl", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "type_map", "=", "dict", "(", ")", "\n", "for", "ent_id", "in", "pkl", ":", "\n", "            ", "type_map", "[", "ent_id", "]", "=", "set", "(", "pkl", "[", "ent_id", "]", "[", "\"types\"", "]", ")", "\n", "", "return", "type_map", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_property_values_info_table_file.track_parents": [[23, 46], ["copy.deepcopy", "range", "type_map.get", "set", "set", "set.add"], "function", ["None"], ["", "", "def", "track_parents", "(", "type_map", ",", "node_id", ":", "str", ",", "level", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    :param node_id: a Q number\n    :param level: the number of levels above the current level that we want to go to\n    :return: types: a set that contains all the parent types (instance of) of the node up to the number\n             levels specified. i.e: If Belgium is a federal system, it's also form of government because federal\n             system is an instance of form of government.\n    \"\"\"", "\n", "types", "=", "deepcopy", "(", "type_map", ".", "get", "(", "node_id", ",", "set", "(", ")", ")", ")", "\n", "pre_level_types", "=", "types", "\n", "for", "i", "in", "range", "(", "level", ")", ":", "\n", "        ", "new_level_types", "=", "set", "(", ")", "\n", "for", "t", "in", "pre_level_types", ":", "\n", "            ", "if", "t", "in", "type_map", ":", "\n", "                ", "parents", "=", "type_map", "[", "t", "]", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "", "for", "p", "in", "parents", ":", "\n", "                ", "if", "p", "not", "in", "types", ":", "\n", "                    ", "new_level_types", ".", "add", "(", "p", ")", "\n", "", "", "", "pre_level_types", "=", "new_level_types", "\n", "types", "|=", "pre_level_types", "\n", "", "return", "types", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_property_values_info_table_file.generate_property_values_table": [[48, 61], ["open", "open", "tqdm.tqdm", "json.loads", "generate_property_values_info_table_file.track_parents", "re_fp.write", "line.strip", "list", "json.dumps"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.WikidataDumpProcessor.generate_property_values_info_table_file.track_parents"], ["", "def", "generate_property_values_table", "(", "type_map", ",", "in_fn", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "entity", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "t_labels", "=", "track_parents", "(", "type_map", ",", "entity", "[", "\"id\"", "]", ",", "k_level", ")", "\n", "obj", "=", "{", "\n", "\"id\"", ":", "entity", "[", "'id'", "]", ",", "\n", "\"properties\"", ":", "entity", "[", "\"properties\"", "]", ",", "\n", "\"types\"", ":", "list", "(", "t_labels", ")", ",", "\n", "\"property_values\"", ":", "entity", "[", "\"property_values\"", "]", ",", "\n", "}", "\n", "re_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "obj", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.compress_wikidata.compress_meta_info.compress": [[10, 21], ["None"], "function", ["None"], ["def", "compress", "(", "in_obj", ")", ":", "\n", "    ", "out_obj", "=", "{", "\n", "\"id\"", ":", "in_obj", "[", "\"id\"", "]", ",", "\n", "\"N\"", ":", "in_obj", "[", "\"ent_name\"", "]", ",", "\n", "\"T\"", ":", "in_obj", "[", "\"types\"", "]", ",", "\n", "\"TR\"", ":", "{", "\n", "\"INS\"", ":", "in_obj", "[", "\"types_rank\"", "]", "[", "\"instance_of\"", "]", ",", "\n", "\"SUB\"", ":", "in_obj", "[", "\"types_rank\"", "]", "[", "\"subclass_of\"", "]", ",", "\n", "}", "\n", "}", "\n", "return", "out_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.compress_wikidata.compress_meta_info.process_file": [[23, 41], ["open", "open", "tqdm.tqdm", "print", "print", "print", "json.loads", "compress_meta_info.compress", "re_fp.write", "line.strip", "json.dumps"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.compress_wikidata.compress_property_info.compress"], ["", "def", "process_file", "(", "in_fn", ",", "out_fn", ")", ":", "\n", "    ", "qnum", "=", "0", "\n", "pnum", "=", "0", "\n", "total", "=", "0", "\n", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "total", "+=", "1", "\n", "in_obj", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "out_obj", "=", "compress", "(", "in_obj", ")", "\n", "if", "out_obj", "[", "\"id\"", "]", "[", "0", "]", "==", "'Q'", ":", "\n", "                    ", "qnum", "+=", "1", "\n", "", "if", "out_obj", "[", "\"id\"", "]", "[", "0", "]", "==", "'P'", ":", "\n", "                    ", "pnum", "+=", "1", "\n", "", "re_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "out_obj", ")", ")", ")", "\n", "", "print", "(", "\"Q Num: {}\"", ".", "format", "(", "qnum", ")", ")", "\n", "print", "(", "\"P Num: {}\"", ".", "format", "(", "pnum", ")", ")", "\n", "print", "(", "\"Total Num: {}\"", ".", "format", "(", "total", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.compress_wikidata.compress_property_info.compress": [[19, 46], ["[].append", "[].append"], "function", ["None"], ["def", "compress", "(", "in_obj", ")", ":", "\n", "    ", "out_obj", "=", "{", "\n", "\"id\"", ":", "in_obj", "[", "\"id\"", "]", ",", "\n", "\"P\"", ":", "in_obj", "[", "\"properties\"", "]", ",", "\n", "\"T\"", ":", "in_obj", "[", "\"types\"", "]", ",", "\n", "\"PV\"", ":", "{", "\n", "}", "\n", "}", "\n", "for", "p", "in", "in_obj", "[", "\"property_values\"", "]", ":", "\n", "        ", "out_obj", "[", "\"PV\"", "]", "[", "p", "]", "=", "[", "]", "\n", "for", "x", "in", "in_obj", "[", "\"property_values\"", "]", "[", "p", "]", ":", "\n", "            ", "if", "\"unit\"", "in", "x", ":", "\n", "                ", "out_obj", "[", "\"PV\"", "]", "[", "p", "]", ".", "append", "(", "\n", "{", "\n", "\"d\"", ":", "datatype_code", "[", "x", "[", "'dtype'", "]", "]", ",", "\n", "\"v\"", ":", "x", "[", "'value'", "]", ",", "\n", "\"unit\"", ":", "x", "[", "'unit'", "]", "\n", "}", "\n", ")", "\n", "", "else", ":", "\n", "                ", "out_obj", "[", "\"PV\"", "]", "[", "p", "]", ".", "append", "(", "\n", "{", "\n", "\"d\"", ":", "datatype_code", "[", "x", "[", "'dtype'", "]", "]", ",", "\n", "\"v\"", ":", "x", "[", "'value'", "]", ",", "\n", "}", "\n", ")", "\n", "", "", "", "return", "out_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.compress_wikidata.compress_property_info.process_file": [[48, 66], ["open", "open", "tqdm.tqdm", "print", "print", "print", "json.loads", "compress_property_info.compress", "re_fp.write", "line.strip", "json.dumps"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.compress_wikidata.compress_property_info.compress"], ["", "def", "process_file", "(", "in_fn", ",", "out_fn", ")", ":", "\n", "    ", "qnum", "=", "0", "\n", "pnum", "=", "0", "\n", "total", "=", "0", "\n", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "total", "+=", "1", "\n", "in_obj", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "out_obj", "=", "compress", "(", "in_obj", ")", "\n", "if", "out_obj", "[", "\"id\"", "]", "[", "0", "]", "==", "'Q'", ":", "\n", "                    ", "qnum", "+=", "1", "\n", "", "if", "out_obj", "[", "\"id\"", "]", "[", "0", "]", "==", "'P'", ":", "\n", "                    ", "pnum", "+=", "1", "\n", "", "re_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "out_obj", ")", ")", ")", "\n", "", "print", "(", "\"Q Num: {}\"", ".", "format", "(", "qnum", ")", ")", "\n", "print", "(", "\"P Num: {}\"", ".", "format", "(", "pnum", ")", ")", "\n", "print", "(", "\"Total Num: {}\"", ".", "format", "(", "total", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.__init__": [[15, 28], ["elasticsearch.Elasticsearch", "elasticsearch.client.IndicesClient", "build_elastic_search.ElasticSearchBuilder.es.ping", "print", "print", "build_elastic_search.ElasticSearchBuilder.es.indices.exists", "build_elastic_search.ElasticSearchBuilder.es.indices.create", "print", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "index_name", ")", ":", "\n", "        ", "self", ".", "index_name", "=", "index_name", "\n", "self", ".", "es", "=", "Elasticsearch", "(", "[", "{", "'host'", ":", "'localhost'", ",", "'port'", ":", "9200", "}", "]", ",", "timeout", "=", "120", ")", "\n", "self", ".", "indexES", "=", "client", ".", "IndicesClient", "(", "self", ".", "es", ")", "\n", "if", "self", ".", "es", ".", "ping", "(", ")", ":", "\n", "            ", "print", "(", "\"Connect elasticsearch successfully!\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Connect failed...\"", ")", "\n", "", "if", "not", "self", ".", "es", ".", "indices", ".", "exists", "(", "self", ".", "index_name", ")", ":", "\n", "            ", "self", ".", "es", ".", "indices", ".", "create", "(", "index", "=", "self", ".", "index_name", ",", "ignore", "=", "400", ",", "body", "=", "None", ")", "\n", "print", "(", "\"create index successfully\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"index already exists.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.bulk_index_data": [[29, 54], ["elasticsearch.helpers.parallel_bulk", "print", "tqdm.tqdm.tqdm", "open", "pickle.load", "pickle.load.items", "build_elastic_search.ElasticSearchBuilder.bulk_index_data.generator"], "methods", ["None"], ["", "", "def", "bulk_index_data", "(", "self", ",", "alias2qids_fn", ")", ":", "\n", "        ", "def", "generator", "(", "alias2qids", ")", ":", "\n", "            ", "cid", "=", "0", "\n", "for", "alias", ",", "qids", "in", "tqdm", "(", "alias2qids", ".", "items", "(", ")", ")", ":", "\n", "                ", "cid", "+=", "1", "\n", "yield", "{", "\n", "'_op_type'", ":", "'index'", ",", "\n", "'_id'", ":", "cid", ",", "\n", "'_index'", ":", "self", ".", "index_name", ",", "\n", "'_source'", ":", "{", "\n", "'title'", ":", "alias", ",", "\n", "'qid'", ":", "\";\"", ".", "join", "(", "qids", ")", ",", "\n", "}", "\n", "}", "\n", "\n", "", "", "with", "open", "(", "alias2qids_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "alias2qids", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "\n", "", "for", "success", ",", "info", "in", "parallel_bulk", "(", "client", "=", "self", ".", "es", ",", "\n", "actions", "=", "generator", "(", "alias2qids", ")", ",", "\n", "thread_count", "=", "5", ",", "\n", "request_timeout", "=", "60", ")", ":", "\n", "            ", "if", "not", "success", ":", "\n", "                ", "print", "(", "\"Doc failed: {}\"", ".", "format", "(", "info", ")", ")", "\n", "", "", "print", "(", "\"index data done.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.query_data": [[55, 94], ["build_elastic_search.ElasticSearchBuilder.es.search", "len", "ans.append"], "methods", ["None"], ["", "def", "query_data", "(", "self", ",", "\n", "mention", ",", "\n", "top_k", "=", "50", ",", "\n", "score_func", "=", "'token'", ")", ":", "\n", "\n", "        ", "if", "score_func", "==", "'token'", ":", "\n", "            ", "dsl", "=", "{", "\n", "\"query\"", ":", "{", "\n", "# single feature", "\n", "\"match\"", ":", "{", "\"title\"", ":", "mention", "}", "\n", "}", "\n", "}", "\n", "", "else", ":", "\n", "            ", "dsl", "=", "{", "\n", "\"query\"", ":", "{", "\n", "# feature ensemble: title^2 + title.ngram", "\n", "\"multi_match\"", ":", "{", "\n", "\"query\"", ":", "mention", ",", "\n", "\"fields\"", ":", "[", "\"title^2\"", ",", "\"title.ngram\"", "]", ",", "\n", "\"type\"", ":", "\"most_fields\"", "\n", "}", "\n", "}", "\n", "}", "\n", "\n", "", "res", "=", "self", ".", "es", ".", "search", "(", "index", "=", "self", ".", "index_name", ",", "\n", "body", "=", "dsl", ",", "\n", "size", "=", "top_k", ",", "\n", "explain", "=", "False", ")", "\n", "\n", "hits", "=", "res", "[", "\"hits\"", "]", "[", "\"hits\"", "]", "\n", "if", "len", "(", "hits", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "ans", "=", "[", "]", "\n", "for", "hit", "in", "hits", ":", "\n", "# qlist = hit[\"_source\"][\"qid\"].split(\";\")", "\n", "            ", "qstr", "=", "hit", "[", "\"_source\"", "]", "[", "\"qid\"", "]", "\n", "htitle", "=", "hit", "[", "\"_source\"", "]", "[", "\"title\"", "]", "\n", "ans", ".", "append", "(", "(", "qstr", ",", "hit", "[", "'_score'", "]", ",", "htitle", ")", ")", "\n", "", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.delete_indices": [[95, 97], ["build_elastic_search.ElasticSearchBuilder.es.indices.delete"], "methods", ["None"], ["", "def", "delete_indices", "(", "self", ")", ":", "\n", "        ", "self", ".", "es", ".", "indices", ".", "delete", "(", "index", "=", "self", ".", "index_name", ",", "ignore", "=", "[", "400", ",", "404", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.generate_cands": [[98, 123], ["tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.close", "open", "pickle.load", "tqdm.tqdm.tqdm.update", "open", "pickle.dump", "len", "build_elastic_search.ElasticSearchBuilder.query_data"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.elastic_search_utils.build_elastic_search.ElasticSearchBuilder.query_data"], ["", "def", "generate_cands", "(", "self", ",", "\n", "query_fn", ",", "\n", "output_fn", ",", "\n", "top_k", "=", "50", ",", "\n", "score_func", "=", "'token'", ")", ":", "\n", "        ", "with", "open", "(", "query_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "mentions", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "\n", "", "ans", "=", "{", "}", "\n", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "mentions", ")", ")", "\n", "for", "mention", "in", "mentions", ":", "\n", "            ", "if", "mention", "in", "ans", ":", "\n", "                ", "continue", "\n", "", "try", ":", "\n", "                ", "res", "=", "self", ".", "query_data", "(", "mention", ",", "\n", "top_k", "=", "top_k", ",", "\n", "score_func", "=", "score_func", ")", "\n", "", "except", ":", "\n", "                ", "res", "=", "[", "]", "\n", "", "ans", "[", "mention", "]", "=", "res", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n", "with", "open", "(", "output_fn", ",", "mode", "=", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "ans", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.site_links_utils.extract_wikidata_sitelinks.process_one_line_all_properties": [[18, 75], ["dict", "set", "dict", "list", "json_obj[].keys", "list", "json.dumps", "json.dumps", "set.add", "values.append"], "function", ["None"], ["def", "process_one_line_all_properties", "(", "json_obj", ")", ":", "\n", "    ", "ent_id", "=", "json_obj", "[", "'id'", "]", "\n", "t", "=", "json_obj", "[", "\"type\"", "]", "\n", "# en_label", "\n", "if", "\"en\"", "in", "json_obj", "[", "\"labels\"", "]", "and", "\"value\"", "in", "json_obj", "[", "\"labels\"", "]", "[", "\"en\"", "]", ":", "\n", "        ", "en_label", "=", "json_obj", "[", "'labels'", "]", "[", "'en'", "]", "[", "'value'", "]", "\n", "", "else", ":", "\n", "        ", "en_label", "=", "\"No_label_defined\"", "\n", "\n", "# multi-language labels", "\n", "", "labels", "=", "dict", "(", ")", "\n", "for", "lang_code", "in", "json_obj", "[", "\"labels\"", "]", ":", "\n", "        ", "labels", "[", "lang_code", "]", "=", "json_obj", "[", "\"labels\"", "]", "[", "lang_code", "]", "[", "'value'", "]", "\n", "\n", "# multi-language aliases", "\n", "", "aliases", "=", "set", "(", ")", "\n", "for", "lang_code", "in", "json_obj", "[", "\"aliases\"", "]", ":", "\n", "        ", "for", "alias", "in", "json_obj", "[", "\"aliases\"", "]", "[", "lang_code", "]", ":", "\n", "            ", "aliases", ".", "add", "(", "alias", "[", "'value'", "]", ")", "\n", "\n", "# multi-language descriptions", "\n", "", "", "descriptions", "=", "dict", "(", ")", "\n", "for", "lang_code", "in", "json_obj", "[", "\"descriptions\"", "]", ":", "\n", "        ", "descriptions", "[", "lang_code", "]", "=", "json_obj", "[", "\"descriptions\"", "]", "[", "lang_code", "]", "[", "'value'", "]", "\n", "\n", "", "properties", "=", "list", "(", "json_obj", "[", "\"claims\"", "]", ".", "keys", "(", ")", ")", "\n", "property_values", "=", "{", "}", "\n", "for", "prop", "in", "json_obj", "[", "\"claims\"", "]", ":", "\n", "        ", "values", "=", "[", "]", "\n", "for", "snak", "in", "json_obj", "[", "\"claims\"", "]", "[", "prop", "]", ":", "\n", "            ", "mainsnak", "=", "snak", "[", "\"mainsnak\"", "]", "\n", "datatype", "=", "mainsnak", "[", "\"datatype\"", "]", "\n", "snaketype", "=", "mainsnak", "[", "\"snaktype\"", "]", "\n", "if", "snaketype", "==", "\"value\"", ":", "\n", "                ", "values", ".", "append", "(", "{", "\n", "\"datatype\"", ":", "datatype", ",", "\n", "\"datavalue\"", ":", "mainsnak", "[", "\"datavalue\"", "]", "\n", "}", ")", "\n", "", "", "if", "values", ":", "\n", "            ", "property_values", "[", "prop", "]", "=", "values", "\n", "\n", "", "", "output", "=", "{", "\n", "\"id\"", ":", "ent_id", ",", "\n", "\"type\"", ":", "t", ",", "\n", "\"en_label\"", ":", "en_label", ",", "\n", "\"properties\"", ":", "properties", ",", "\n", "\"property_values\"", ":", "property_values", "\n", "}", "\n", "\n", "ent_meta_info", "=", "{", "\n", "\"id\"", ":", "ent_id", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "\"aliases\"", ":", "list", "(", "aliases", ")", ",", "\n", "\"descriptions\"", ":", "descriptions", "\n", "}", "\n", "\n", "return", "json", ".", "dumps", "(", "output", ")", ",", "json", ".", "dumps", "(", "ent_meta_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.site_links_utils.extract_wikidata_sitelinks.process_one_file": [[77, 101], ["bz2.open", "open", "os.path.join", "open", "os.path.join", "tqdm.tqdm", "pbar.update", "json.loads", "extract_wikidata_sitelinks.process_one_line_all_properties", "property_out_fp.write", "meta_out_fp.write", "line.strip().strip.strip().strip", "line.strip().strip.strip().strip", "print", "sys.exc_info", "print", "len", "print", "line.strip().strip.strip", "line.strip().strip.strip"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.site_links_utils.extract_wikidata_sitelinks.process_one_line_all_properties"], ["", "def", "process_one_file", "(", "total_lines", ",", "in_fn", ",", "dump_dir", ")", ":", "\n", "    ", "with", "bz2", ".", "open", "(", "in_fn", ",", "\"rt\"", ")", "as", "in_fp", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "\"properties.jsonl\"", ")", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "property_out_fp", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dump_dir", ",", "\"meta.jsonl\"", ")", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "meta_out_fp", ":", "\n", "                ", "with", "tqdm", "(", "total", "=", "total_lines", ")", "as", "pbar", ":", "\n", "                    ", "for", "line", "in", "in_fp", ":", "\n", "                        ", "pbar", ".", "update", "(", ")", "\n", "try", ":", "\n", "                            ", "json_obj", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ".", "strip", "(", "','", ")", ")", "\n", "property_values", ",", "meta_info", "=", "process_one_line_all_properties", "(", "json_obj", ")", "\n", "\n", "property_out_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "property_values", ")", ")", "\n", "meta_out_fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "meta_info", ")", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                            ", "line", "=", "line", ".", "strip", "(", ")", ".", "strip", "(", "','", ")", "\n", "print", "(", "line", ")", "\n", "\n", "exc_type", ",", "exc_obj", ",", "exc_tb", "=", "sys", ".", "exc_info", "(", ")", "\n", "print", "(", "\"Exception:\"", ",", "exc_type", ",", "\"- line\"", ",", "exc_tb", ".", "tb_lineno", ")", "\n", "if", "len", "(", "line", ")", "<", "30", ":", "\n", "                                ", "print", "(", "\"Failed line:\"", ",", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.rocksdb_utils.build_alias_map.build_db": [[12, 19], ["open", "pickle.load", "tqdm.tqdm", "db.put", "bytes", "bytes", "json.dumps"], "function", ["None"], ["def", "build_db", "(", "db", ",", "in_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "alias_map", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "for", "alias", "in", "tqdm", "(", "alias_map", ")", ":", "\n", "            ", "candid", "=", "alias_map", "[", "alias", "]", "\n", "db", ".", "put", "(", "bytes", "(", "alias", ",", "'utf-8'", ")", ",", "\n", "bytes", "(", "json", ".", "dumps", "(", "candid", ")", ",", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.rocksdb_utils.build_ent_meta_info.build_db": [[11, 18], ["open", "tqdm.tqdm", "db.close", "json.loads", "db.put", "line.strip", "bytes", "bytes", "json.dumps"], "function", ["None"], ["def", "build_db", "(", "db", ",", "in_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "db", ".", "put", "(", "bytes", "(", "entity", "[", "'id'", "]", ",", "'utf-8'", ")", ",", "\n", "bytes", "(", "json", ".", "dumps", "(", "entity", ")", ",", "'utf-8'", ")", ")", "\n", "", "db", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.rocksdb_utils.build_property_values_info.build_db": [[11, 18], ["open", "tqdm.tqdm", "db.close", "json.loads", "db.put", "line.strip", "bytes", "bytes", "json.dumps"], "function", ["None"], ["def", "build_db", "(", "db", ",", "in_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "db", ".", "put", "(", "bytes", "(", "entity", "[", "'id'", "]", ",", "'utf-8'", ")", ",", "\n", "bytes", "(", "json", ".", "dumps", "(", "entity", ")", ",", "'utf-8'", ")", ")", "\n", "", "db", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.redis_utils.build_alias_map.load_pkl": [[13, 17], ["open", "pickle.load"], "function", ["None"], ["    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "alias_map", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "for", "alias", "in", "tqdm", "(", "alias_map", ")", ":", "\n", "            ", "candid", "=", "alias_map", "[", "alias", "]", "\n", "db", ".", "put", "(", "bytes", "(", "alias", ",", "'utf-8'", ")", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.redis_utils.build_alias_map.build_db": [[19, 28], ["tqdm.tqdm", "r.set", "json.dumps", "time.sleep", "print"], "function", ["None"], ["\n", "\n", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--db_path\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"$BASE_DATA_DIR/RocksDB/AliasMap/data_keep_disambiguation.db\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--in_fn\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"$BASE_DATA_DIR/wikidata/merged_alias_map/alias_map_keep_disambiguation.pkl\"", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.redis_utils.build_ent_labels_info.load_pkl": [[13, 17], ["open", "pickle.load"], "function", ["None"], ["def", "load_pkl", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "pkl", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "pkl", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.redis_utils.build_ent_labels_info.build_db": [[19, 28], ["tqdm.tqdm", "r.set", "json.dumps", "time.sleep", "print"], "function", ["None"], ["", "", "def", "build_db", "(", "r", ",", "label_map", ")", ":", "\n", "    ", "num", "=", "0", "\n", "for", "qid", "in", "tqdm", "(", "label_map", ")", ":", "\n", "        ", "r", ".", "set", "(", "qid", ",", "\n", "json", ".", "dumps", "(", "label_map", "[", "qid", "]", ")", ")", "\n", "num", "+=", "1", "\n", "if", "num", "%", "1000000", "==", "0", ":", "\n", "            ", "time", ".", "sleep", "(", "30", ")", "\n", "print", "(", "\"processing {} lines\"", ".", "format", "(", "num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.redis_utils.build_property_value_info.build_db": [[12, 23], ["open", "tqdm.tqdm", "json.loads", "r.set", "line.strip", "json.dumps", "time.sleep", "print"], "function", ["None"], ["def", "build_db", "(", "r", ",", "in_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "num", "=", "0", "\n", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "r", ".", "set", "(", "entity", "[", "'id'", "]", ",", "\n", "json", ".", "dumps", "(", "entity", ")", ")", "\n", "num", "+=", "1", "\n", "if", "num", "%", "100000", "==", "0", ":", "\n", "                ", "time", ".", "sleep", "(", "30", ")", "\n", "print", "(", "\"processing {} lines\"", ".", "format", "(", "num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.redis_utils.build_ent_meta_info.build_db": [[12, 23], ["open", "tqdm.tqdm", "json.loads", "r.set", "line.strip", "json.dumps", "time.sleep", "print"], "function", ["None"], ["    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "db", ".", "put", "(", "bytes", "(", "entity", "[", "'id'", "]", ",", "'utf-8'", ")", ",", "\n", "bytes", "(", "json", ".", "dumps", "(", "entity", ")", ",", "'utf-8'", ")", ")", "\n", "", "db", ".", "close", "(", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--db_path\"", ",", "\n", "type", "=", "str", ",", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.schema_processor.extract_schema_nodes.extract_schema_nodes": [[12, 27], ["set", "set", "print", "print", "open", "tqdm.tqdm", "open", "pickle.dump", "json.loads", "set", "len", "len", "line.strip", "set.add"], "function", ["None"], ["def", "extract_schema_nodes", "(", "in_fn", ",", "out_fn", ")", ":", "\n", "    ", "properties_nodes", "=", "set", "(", ")", "\n", "type_nodes", "=", "set", "(", ")", "\n", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "node", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "if", "node", "[", "'id'", "]", "[", "0", "]", "==", "'P'", ":", "\n", "                ", "properties_nodes", ".", "add", "(", "node", "[", "'id'", "]", ")", "\n", "", "type_nodes", "|=", "set", "(", "node", "[", "shortname", ".", "TYPES", "]", ")", "\n", "\n", "", "", "schema_nodes", "=", "type_nodes", "|", "properties_nodes", "\n", "print", "(", "\"number of types : {}\"", ".", "format", "(", "len", "(", "type_nodes", ")", ")", ")", "\n", "print", "(", "\"number of properties: {}\"", ".", "format", "(", "len", "(", "properties_nodes", ")", ")", ")", "\n", "with", "open", "(", "out_fn", ",", "mode", "=", "\"wb\"", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "schema_nodes", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.schema_processor.filter_schema_nodes_meta_info.load_schema_set": [[11, 15], ["open", "pickle.load"], "function", ["None"], ["def", "load_schema_set", "(", "schema_fn", ")", ":", "\n", "    ", "with", "open", "(", "schema_fn", ",", "mode", "=", "\"rb\"", ")", "as", "fp", ":", "\n", "        ", "schema_ent_set", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "return", "schema_ent_set", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.schema_processor.filter_schema_nodes_meta_info.extract_schema_nodes": [[17, 24], ["open", "open", "tqdm.tqdm", "json.loads", "line.strip", "re_fp.write"], "function", ["None"], ["", "", "def", "extract_schema_nodes", "(", "in_fn", ",", "schema_ent_set", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "                ", "node", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "if", "node", "[", "'id'", "]", "in", "schema_ent_set", ":", "\n", "                    ", "re_fp", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.incoming_links.get_incoming_links.get_incoming_links": [[11, 28], ["open", "dict", "tqdm.tqdm", "print", "print", "json.loads", "open", "pickle.dump", "len", "line.strip"], "function", ["None"], ["def", "get_incoming_links", "(", "in_fn", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "in_links", "=", "dict", "(", ")", "\n", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "node", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "for", "p", "in", "node", "[", "'property_values'", "]", ":", "\n", "                ", "for", "v", "in", "node", "[", "'property_values'", "]", "[", "p", "]", ":", "\n", "                    ", "if", "v", "[", "'dtype'", "]", "==", "'wikibase-entityid'", ":", "\n", "                        ", "dest_node", "=", "v", "[", "'value'", "]", "\n", "if", "dest_node", "not", "in", "in_links", ":", "\n", "                            ", "in_links", "[", "dest_node", "]", "=", "1", "\n", "", "else", ":", "\n", "                            ", "in_links", "[", "dest_node", "]", "+=", "1", "\n", "", "", "", "", "", "with", "open", "(", "out_fn", ",", "mode", "=", "\"wb\"", ")", "as", "fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "in_links", ",", "fp", ")", "\n", "", "print", "(", "len", "(", "in_links", ")", ",", "'items is linked.'", ")", "\n", "print", "(", "'over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.retrieve_tsv_mapping": [[27, 46], ["open", "csv.DictReader", "lines.append", "len"], "methods", ["None"], ["def", "retrieve_tsv_mapping", "(", "self", ",", "filename", ",", "languages", "=", "None", ",", "limit", "=", "-", "1", ")", ":", "\n", "\n", "        ", "if", "languages", "is", "None", ":", "\n", "            ", "languages", "=", "[", "self", ".", "DEFAULT_LANGUAGE", "]", "\n", "\n", "", "with", "open", "(", "filename", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "\n", "            ", "lines", "=", "[", "]", "\n", "\n", "reader", "=", "csv", ".", "DictReader", "(", "fp", ",", "fieldnames", "=", "self", ".", "field_names", ",", "dialect", "=", "'excel-tab'", ")", "\n", "\n", "for", "row", "in", "reader", ":", "\n", "                ", "if", "row", "[", "self", ".", "LANG_FIELD", "]", "in", "languages", ":", "\n", "                    ", "lines", ".", "append", "(", "row", ")", "\n", "\n", "", "if", "limit", "is", "not", "-", "1", "and", "len", "(", "lines", ")", "==", "limit", ":", "\n", "                    ", "break", "\n", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.get_wikidata_satori_pairs": [[47, 57], ["dict", "entry.get", "entry.get"], "methods", ["None"], ["", "", "def", "get_wikidata_satori_pairs", "(", "self", ",", "map_table", ")", ":", "\n", "        ", "pairs", "=", "dict", "(", ")", "\n", "\n", "for", "entry", "in", "map_table", ":", "\n", "            ", "wikidata_id", "=", "entry", ".", "get", "(", "self", ".", "WIKIDATA_FIELD", ")", "\n", "satori_id", "=", "entry", ".", "get", "(", "self", ".", "SATORI_FIELD", ")", "\n", "if", "wikidata_id", "is", "not", "None", "and", "satori_id", "is", "not", "None", ":", "\n", "                ", "pairs", "[", "wikidata_id", "]", "=", "satori_id", "\n", "\n", "", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.dump_pairs_as_json": [[58, 64], ["os.path.join", "open", "json.dump"], "methods", ["None"], ["", "def", "dump_pairs_as_json", "(", "self", ",", "pairs", ",", "key_name", ",", "value_name", ",", "filepath", ")", ":", "\n", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "filepath", ",", "f'{key_name}_to_{value_name}.json'", ")", "\n", "\n", "with", "open", "(", "filename", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "pairs", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.process_ids_table": [[66, 73], ["os.path.dirname", "mappings.KBMapper.retrieve_tsv_mapping", "mappings.KBMapper.get_wikidata_satori_pairs", "mappings.KBMapper.dump_pairs_as_json"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.retrieve_tsv_mapping", "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.get_wikidata_satori_pairs", "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.dump_pairs_as_json"], ["", "", "def", "process_ids_table", "(", "self", ",", "filename", ")", ":", "\n", "\n", "        ", "output_dir", "=", "os", ".", "path", ".", "dirname", "(", "filename", ")", "\n", "\n", "map_table", "=", "self", ".", "retrieve_tsv_mapping", "(", "filename", ")", "\n", "pairs", "=", "self", ".", "get_wikidata_satori_pairs", "(", "map_table", ")", "\n", "self", ".", "dump_pairs_as_json", "(", "pairs", ",", "'wikidata'", ",", "'satori'", ",", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.retrieve_pairs": [[74, 78], ["open", "json.load"], "methods", ["None"], ["", "def", "retrieve_pairs", "(", "self", ",", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "return", "json", ".", "load", "(", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.init_pairs": [[79, 81], ["mappings.KBMapper.retrieve_pairs"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.retrieve_pairs"], ["", "", "def", "init_pairs", "(", "self", ",", "filename", ")", ":", "\n", "        ", "self", ".", "wikidata_satori_pairs", "=", "self", ".", "retrieve_pairs", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.KBMapping.mappings.KBMapper.query": [[82, 88], ["mappings.KBMapper.wikidata_satori_pairs.get", "len"], "methods", ["None"], ["", "def", "query", "(", "self", ",", "source_id", ")", ":", "\n", "\n", "        ", "if", "not", "len", "(", "self", ".", "wikidata_satori_pairs", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "wikidata_satori_pairs", ".", "get", "(", "source_id", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.convert_gold2json.read_gold_labels": [[14, 61], ["dict", "dict", "dict", "dict", "open", "open", "open", "set", "line.replace.replace", "line.replace.strip().split", "line.replace.replace", "line.replace.strip().split", "line.replace.replace", "line.replace.strip().split", "set", "set", "dict.keys", "dict.get", "dict.get", "dict.get", "dict", "dict", "dict", "dict.keys", "dict.keys", "line.replace.strip", "str", "len", "line.replace.strip", "len", "line.replace.strip", "len", "int", "int"], "function", ["None"], ["def", "read_gold_labels", "(", "cea_fn", ",", "cta_fn", ",", "cpa_fn", ")", ":", "\n", "    ", "cea", "=", "dict", "(", ")", "\n", "cta", "=", "dict", "(", ")", "\n", "cpa", "=", "dict", "(", ")", "\n", "with", "open", "(", "cea_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", "=", "words", "[", "0", "]", "\n", "row_id", "=", "words", "[", "1", "]", "\n", "col_id", "=", "words", "[", "2", "]", "\n", "if", "tab_id", "not", "in", "cea", ":", "\n", "                ", "cea", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "cea", "[", "tab_id", "]", "[", "str", "(", "(", "int", "(", "row_id", ")", "-", "1", ",", "int", "(", "col_id", ")", ")", ")", "]", "=", "words", "[", "3", "]", "[", "len", "(", "entity_prefix", ")", ":", "]", "\n", "\n", "", "", "with", "open", "(", "cta_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", "=", "words", "[", "0", "]", "\n", "col_id", "=", "words", "[", "1", "]", "\n", "if", "tab_id", "not", "in", "cta", ":", "\n", "                ", "cta", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "cta", "[", "tab_id", "]", "[", "col_id", "]", "=", "words", "[", "2", "]", "[", "len", "(", "entity_prefix", ")", ":", "]", "\n", "\n", "", "", "with", "open", "(", "cpa_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", "=", "words", "[", "0", "]", "\n", "col_id", "=", "words", "[", "2", "]", "\n", "if", "tab_id", "not", "in", "cpa", ":", "\n", "                ", "cpa", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "cpa", "[", "tab_id", "]", "[", "col_id", "]", "=", "words", "[", "3", "]", "[", "len", "(", "property_prefix", ")", ":", "]", "\n", "\n", "\n", "", "", "gold", "=", "dict", "(", ")", "\n", "tab_ids", "=", "set", "(", "cea", ".", "keys", "(", ")", ")", "|", "set", "(", "cta", ".", "keys", "(", ")", ")", "|", "set", "(", "cpa", ".", "keys", "(", ")", ")", "\n", "for", "tab_id", "in", "tab_ids", ":", "\n", "        ", "gold", "[", "tab_id", "]", "=", "{", "\n", "\"tab_id\"", ":", "tab_id", ",", "\n", "\"cea\"", ":", "cea", ".", "get", "(", "tab_id", ",", "{", "}", ")", ",", "\n", "\"cta\"", ":", "cta", ".", "get", "(", "tab_id", ",", "{", "}", ")", ",", "\n", "\"cpa\"", ":", "cpa", ".", "get", "(", "tab_id", ",", "{", "}", ")", "\n", "}", "\n", "\n", "", "return", "gold", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.convert_gold2json.dump_jsonl": [[62, 67], ["open", "fp.write", "json.dumps"], "function", ["None"], ["", "def", "dump_jsonl", "(", "gold", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "tab_id", "in", "gold", ":", "\n", "# try:", "\n", "            ", "fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "gold", "[", "tab_id", "]", ")", ")", ")", "\n", "# except:", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.random_sample_dev.load_round4": [[13, 20], ["set", "open", "json.loads", "set.add", "line.strip"], "function", ["None"], ["def", "load_round4", "(", "fn", ")", ":", "\n", "    ", "ids", "=", "set", "(", ")", "\n", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "table", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "ids", ".", "add", "(", "table", "[", "'tab_id'", "]", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.random_sample_dev.sample_dev": [[22, 33], ["open", "random.shuffle", "line.strip().split", "open", "re_fp.writelines", "lines.append", "line.strip"], "function", ["None"], ["", "", "def", "sample_dev", "(", "in_fn", ",", "out_fn", ",", "tab_ids", ",", "topk", "=", "100", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "for", "line", "in", "fp", ":", "\n", "            ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "words", "[", "0", "]", "in", "tab_ids", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "# lines = fp.readlines()", "\n", "", "", "random", ".", "shuffle", "(", "lines", ")", "\n", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "re_fp", ".", "writelines", "(", "lines", "[", ":", "topk", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.random_sample_dev.sample_dev_v2": [[35, 41], ["open", "fp.readlines", "random.shuffle", "open", "re_fp.writelines"], "function", ["None"], ["", "", "", "def", "sample_dev_v2", "(", "in_fn", ",", "out_fn", ",", "topk", "=", "100", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "lines", "=", "fp", ".", "readlines", "(", ")", "\n", "random", ".", "shuffle", "(", "lines", ")", "\n", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "re_fp", ".", "writelines", "(", "lines", "[", ":", "topk", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.convert_2Tgold2json.read_gold_labels": [[13, 47], ["dict", "dict", "dict", "open", "open", "set", "set", "line.replace.replace", "line.replace.strip().split", "line.replace.replace", "line.replace.strip().split", "dict.keys", "dict.keys", "dict.get", "dict.get", "dict", "dict", "line.replace.strip", "str", "words[].split", "line.replace.strip", "words[].split", "len", "int", "len", "int"], "function", ["None"], ["def", "read_gold_labels", "(", "cea_fn", ",", "cta_fn", ")", ":", "\n", "    ", "cea", "=", "dict", "(", ")", "\n", "cta", "=", "dict", "(", ")", "\n", "with", "open", "(", "cea_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", "=", "words", "[", "0", "]", "\n", "row_id", "=", "words", "[", "1", "]", "\n", "col_id", "=", "words", "[", "2", "]", "\n", "if", "tab_id", "not", "in", "cea", ":", "\n", "                ", "cea", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "cea", "[", "tab_id", "]", "[", "str", "(", "(", "int", "(", "row_id", ")", "-", "1", ",", "int", "(", "col_id", ")", ")", ")", "]", "=", "[", "x", "[", "len", "(", "entity_prefix", ")", ":", "]", "if", "x", "!=", "\"NIL\"", "else", "x", "for", "x", "in", "words", "[", "3", "]", ".", "split", "(", ")", "]", "\n", "\n", "", "", "with", "open", "(", "cta_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", "=", "words", "[", "0", "]", "\n", "col_id", "=", "words", "[", "1", "]", "\n", "if", "tab_id", "not", "in", "cta", ":", "\n", "                ", "cta", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "cta", "[", "tab_id", "]", "[", "col_id", "]", "=", "[", "x", "[", "len", "(", "entity_prefix", ")", ":", "]", "for", "x", "in", "words", "[", "2", "]", ".", "split", "(", ")", "]", "\n", "\n", "", "", "gold", "=", "dict", "(", ")", "\n", "tab_ids", "=", "set", "(", "cea", ".", "keys", "(", ")", ")", "|", "set", "(", "cta", ".", "keys", "(", ")", ")", "\n", "for", "tab_id", "in", "tab_ids", ":", "\n", "        ", "gold", "[", "tab_id", "]", "=", "{", "\n", "\"tab_id\"", ":", "tab_id", ",", "\n", "\"cea\"", ":", "cea", ".", "get", "(", "tab_id", ",", "{", "}", ")", ",", "\n", "\"cta\"", ":", "cta", ".", "get", "(", "tab_id", ",", "{", "}", ")", ",", "\n", "}", "\n", "\n", "", "return", "gold", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.convert_2Tgold2json.dump_jsonl": [[48, 53], ["open", "fp.write", "json.dumps"], "function", ["None"], ["", "def", "dump_jsonl", "(", "gold", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "tab_id", "in", "gold", ":", "\n", "# try:", "\n", "            ", "fp", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "gold", "[", "tab_id", "]", ")", ")", ")", "\n", "# except:", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.convert_tt_csv_to_jsonl.convert_format": [[11, 18], ["open", "os.listdir", "Utils.utils_data.pd_read_csv", "re_fp.write", "os.path.basename().split", "os.path.join", "os.path.basename", "json.dumps"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.pd_read_csv"], ["def", "convert_format", "(", "in_dir", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "        ", "in_fns", "=", "os", ".", "listdir", "(", "in_dir", ")", "\n", "for", "in_fn", "in", "in_fns", ":", "\n", "            ", "tab_id", "=", "os", ".", "path", ".", "basename", "(", "in_fn", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "table", "=", "pd_read_csv", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "in_fn", ")", ")", "\n", "re_fp", ".", "write", "(", "f\"{tab_id}\\t{json.dumps(table)}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.get_target_statistics.get_target_statistics": [[10, 21], ["open", "len", "open", "len", "open", "len", "os.path.join", "fp.readlines", "os.path.join", "fp.readlines", "os.path.join", "fp.readlines"], "function", ["None"], ["def", "get_target_statistics", "(", "round_dir", ",", "data_round", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "round_dir", ",", "f'CEA_Round{data_round}_Targets.csv'", ")", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "cea_targets", "=", "len", "(", "fp", ".", "readlines", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "round_dir", ",", "f'CTA_Round{data_round}_Targets.csv'", ")", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "cta_targets", "=", "len", "(", "fp", ".", "readlines", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "round_dir", ",", "f'CPA_Round{data_round}_Targets.csv'", ")", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "cpa_targets", "=", "len", "(", "fp", ".", "readlines", "(", ")", ")", "\n", "\n", "", "return", "cea_targets", ",", "cta_targets", ",", "cpa_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.get_target_statistics.print_targets": [[23, 37], ["prettytable.PrettyTable", "range", "print", "os.path.join", "get_target_statistics.get_target_statistics", "prettytable.PrettyTable.add_row"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.get_target_statistics.get_target_statistics"], ["", "def", "print_targets", "(", "base_dir", ")", ":", "\n", "    ", "results", "=", "PrettyTable", "(", ")", "\n", "results", ".", "field_names", "=", "[", "\n", "\"round\"", ",", "\n", "\"cea_targets\"", ",", "\n", "\"cta_targets\"", ",", "\n", "\"cpa_targets\"", "\n", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "round_dir", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "f\"Round{i}\"", ")", "\n", "cea_targets", ",", "cta_targets", ",", "cpa_targets", "=", "get_target_statistics", "(", "round_dir", ",", "i", ")", "\n", "results", ".", "add_row", "(", "[", "f'Round{i}'", ",", "cea_targets", ",", "cta_targets", ",", "cpa_targets", "]", ")", "\n", "\n", "", "print", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.get_gold_statistics.get_gold_statistics": [[10, 21], ["open", "len", "open", "len", "open", "len", "os.path.join", "fp.readlines", "os.path.join", "fp.readlines", "os.path.join", "fp.readlines"], "function", ["None"], ["def", "get_gold_statistics", "(", "round_dir", ",", "data_round", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "round_dir", ",", "'CEA'", ",", "f'CEA_Round{data_round}_gt.csv'", ")", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "cea_targets", "=", "len", "(", "fp", ".", "readlines", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "round_dir", ",", "'CTA'", ",", "f'CTA_Round{data_round}_gt.csv'", ")", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "cta_targets", "=", "len", "(", "fp", ".", "readlines", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "round_dir", ",", "'CPA'", ",", "f'CPA_Round{data_round}_gt.csv'", ")", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "cpa_targets", "=", "len", "(", "fp", ".", "readlines", "(", ")", ")", "\n", "\n", "", "return", "cea_targets", ",", "cta_targets", ",", "cpa_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.get_gold_statistics.print_targets": [[23, 36], ["prettytable.PrettyTable", "range", "print", "get_gold_statistics.get_gold_statistics", "prettytable.PrettyTable.add_row"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.get_gold_statistics.get_gold_statistics"], ["", "def", "print_targets", "(", "base_dir", ")", ":", "\n", "    ", "results", "=", "PrettyTable", "(", ")", "\n", "results", ".", "field_names", "=", "[", "\n", "\"round\"", ",", "\n", "\"cea_targets\"", ",", "\n", "\"cta_targets\"", ",", "\n", "\"cpa_targets\"", "\n", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "cea_targets", ",", "cta_targets", ",", "cpa_targets", "=", "get_gold_statistics", "(", "base_dir", ",", "i", ")", "\n", "results", ".", "add_row", "(", "[", "f'Round{i}'", ",", "cea_targets", ",", "cta_targets", ",", "cpa_targets", "]", ")", "\n", "\n", "", "print", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.convert_semtab20_csv_to_jsonl.convert_format": [[11, 18], ["open", "os.listdir", "Utils.utils_data.pd_read_csv", "re_fp.write", "os.path.basename().split", "os.path.join", "os.path.basename", "json.dumps"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.pd_read_csv"], ["def", "convert_format", "(", "in_dir", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "        ", "in_fns", "=", "os", ".", "listdir", "(", "in_dir", ")", "\n", "for", "in_fn", "in", "in_fns", ":", "\n", "            ", "tab_id", "=", "os", ".", "path", ".", "basename", "(", "in_fn", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "table", "=", "pd_read_csv", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "in_fn", ")", ")", "\n", "re_fp", ".", "write", "(", "f\"{tab_id}\\t{json.dumps(table)}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.filter_dev_submission_file.load_tab_ids": [[9, 16], ["set", "open", "line.strip().split", "set.add", "line.strip"], "function", ["None"], ["def", "load_tab_ids", "(", "fn", ")", ":", "\n", "    ", "tab_ids", "=", "set", "(", ")", "\n", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "tab_ids", ".", "add", "(", "words", "[", "0", "]", ")", "\n", "", "", "return", "tab_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.filter_dev_submission_file.filter_gold_output": [[18, 25], ["open", "open", "line.strip().replace().split", "re_fp.write", "line.strip().replace", "line.strip"], "function", ["None"], ["", "def", "filter_gold_output", "(", "tab_ids", ",", "gold_fn", ",", "out_fn", ")", ":", "\n", "    ", "with", "open", "(", "gold_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "out_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "fp", ":", "\n", "                ", "words", "=", "line", ".", "strip", "(", ")", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", "\n", "if", "words", "[", "0", "]", "in", "tab_ids", ":", "\n", "                    ", "re_fp", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.get_table_statistics.get_statistics": [[12, 32], ["Utils.utils.load_json_table", "len", "numpy.std", "numpy.std", "row_num_population.append", "sum", "len", "col_num_population.append", "sum", "len", "len", "len", "print", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.load_json_table"], ["def", "get_statistics", "(", "in_tab_fn", ")", ":", "\n", "    ", "tables", "=", "load_json_table", "(", "in_tab_fn", ")", "\n", "table_num", "=", "len", "(", "tables", ")", "\n", "\n", "row_num_population", "=", "[", "]", "\n", "for", "tab_id", "in", "tables", ":", "\n", "        ", "row_num_population", ".", "append", "(", "len", "(", "tables", "[", "tab_id", "]", ")", ")", "\n", "\n", "", "row_num_std", "=", "numpy", ".", "std", "(", "row_num_population", ")", "\n", "avg_row_num", "=", "sum", "(", "row_num_population", ")", "/", "len", "(", "row_num_population", ")", "\n", "\n", "col_num_population", "=", "[", "]", "\n", "for", "tab_id", "in", "tables", ":", "\n", "        ", "if", "len", "(", "tables", "[", "tab_id", "]", "[", "0", "]", ")", "==", "1", ":", "\n", "            ", "print", "(", "tab_id", ")", "\n", "", "col_num_population", ".", "append", "(", "len", "(", "tables", "[", "tab_id", "]", "[", "0", "]", ")", ")", "\n", "\n", "", "col_num_std", "=", "numpy", ".", "std", "(", "col_num_population", ")", "\n", "avg_col_num", "=", "sum", "(", "col_num_population", ")", "/", "len", "(", "col_num_population", ")", "\n", "return", "table_num", ",", "avg_row_num", ",", "row_num_std", ",", "avg_col_num", ",", "col_num_std", "\n", "# results.add_row([table_num, row_num, row_num_std, col_num, col_num_std])", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.extract_dev_gold.load_tab_ids": [[9, 16], ["set", "open", "line.strip().split", "set.add", "line.strip"], "function", ["None"], ["def", "load_tab_ids", "(", "fn", ")", ":", "\n", "    ", "tab_ids", "=", "set", "(", ")", "\n", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "tab_ids", ".", "add", "(", "words", "[", "0", "]", ")", "\n", "", "return", "tab_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.extract_dev_gold.filter_gold": [[18, 25], ["open", "open", "line.replace().split", "re_fp.write", "line.replace"], "function", ["None"], ["", "", "def", "filter_gold", "(", "in_fn", ",", "tab_ids", ",", "re_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "re_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "re_fp", ":", "\n", "            ", "for", "line", "in", "fp", ":", "\n", "                ", "tab_id", "=", "line", ".", "replace", "(", "'\"'", ",", "''", ")", ".", "split", "(", "','", ")", "[", "0", "]", "\n", "if", "tab_id", "in", "tab_ids", ":", "\n", "                    ", "re_fp", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.split_round4_input.load_2t_table_ids": [[9, 16], ["set", "open", "json.loads", "set.add", "line.strip"], "function", ["None"], ["def", "load_2t_table_ids", "(", "fn", ")", ":", "\n", "    ", "tough_table_ids", "=", "set", "(", ")", "\n", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "table", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "tough_table_ids", ".", "add", "(", "table", "[", "\"tab_id\"", "]", ")", "\n", "", "return", "tough_table_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.prepare_data.split_round4_input.split_files": [[18, 28], ["open", "open", "open", "line.strip().split", "tt_fp.write", "semtab_fp.write", "line.strip"], "function", ["None"], ["", "", "def", "split_files", "(", "tough_tables_ids", ",", "in_fn", ",", "tt_fn", ",", "semtab_fn", ")", ":", "\n", "    ", "with", "open", "(", "in_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "with", "open", "(", "tt_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "tt_fp", ":", "\n", "            ", "with", "open", "(", "semtab_fn", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "semtab_fp", ":", "\n", "                ", "for", "line", "in", "fp", ":", "\n", "                    ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "words", "[", "0", "]", "in", "tough_tables_ids", ":", "\n", "                        ", "tt_fp", ".", "write", "(", "line", ")", "\n", "", "else", ":", "\n", "                        ", "semtab_fp", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_analysis_file_with_gold.load_gold": [[17, 24], ["open", "dict", "json.loads", "line.strip"], "function", ["None"], ["def", "load_gold", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "gold", "=", "dict", "(", ")", "\n", "for", "line", "in", "fp", ":", "\n", "            ", "tab", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "gold", "[", "tab", "[", "'tab_id'", "]", "]", "=", "tab", "\n", "", "return", "gold", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_analysis_file_with_gold.load_pred": [[26, 34], ["dict", "open", "tqdm.tqdm", "json.loads", "line.strip"], "function", ["None"], ["", "", "def", "load_pred", "(", "log_fn", ",", "gold", ")", ":", "\n", "    ", "pred", "=", "dict", "(", ")", "\n", "with", "open", "(", "log_fn", ",", "encoding", "=", "'utf-8'", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "tab", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "if", "tab", "[", "'tab_id'", "]", "in", "gold", ":", "\n", "                ", "pred", "[", "tab", "[", "'tab_id'", "]", "]", "=", "tab", "\n", "", "", "", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_analysis_file_with_gold.load_oracle_entity_cta": [[36, 49], ["dict", "open", "line.replace.replace", "line.replace.strip().split", "dict", "line.replace.strip", "len"], "function", ["None"], ["", "def", "load_oracle_entity_cta", "(", "fn", ")", ":", "\n", "    ", "cta", "=", "dict", "(", ")", "\n", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", "=", "words", "[", "0", "]", "\n", "col_id", "=", "words", "[", "1", "]", "\n", "entity", "=", "words", "[", "2", "]", "[", "len", "(", "entity_prefix", ")", ":", "]", "\n", "if", "tab_id", "not", "in", "cta", ":", "\n", "                ", "cta", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "cta", "[", "tab_id", "]", "[", "col_id", "]", "=", "entity", "\n", "", "return", "cta", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_analysis_file_with_gold.format_result": [[51, 158], ["table.append", "table.append", "range", "table.append", "table.append", "range", "table.append", "table.append", "table.append", "range", "range", "table.append", "str", "type_candid_line.append", "type_candid_line.append", "str", "gold_presult.append", "gold_presult.append", "len", "str", "range", "range", "range", "str", "len", "str", "presult.append", "presult.append", "str", "presult.append", "presult.append", "row_annotation.append", "str", "str", "Utils.utils.get_item_name", "Utils.utils.get_item_name", "str", "row_annotation.append", "row_annotation.append", "str", "str", "str", "entity[].replace", "Utils.utils.get_item_name", "entity[].replace", "Utils.utils.get_item_name", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name"], ["", "", "def", "format_result", "(", "tab_id", ",", "row_tab", ")", ":", "\n", "    ", "col_size", "=", "pred", "[", "tab_id", "]", "[", "'col_size'", "]", "\n", "row_size", "=", "pred", "[", "tab_id", "]", "[", "'row_size'", "]", "\n", "properties", "=", "pred", "[", "tab_id", "]", "[", "\"coarse_properties\"", "]", "\n", "col_types", "=", "pred", "[", "tab_id", "]", "[", "\"tab_pred_type\"", "]", "\n", "entities", "=", "pred", "[", "tab_id", "]", "[", "\"revisit_predict_entities\"", "]", "\n", "\n", "table", "=", "[", "]", "\n", "# append header", "\n", "table", ".", "append", "(", "[", "\"col{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "1", ",", "col_size", "+", "1", ")", "]", ")", "\n", "\n", "# pred type: id | name | confidence", "\n", "table", ".", "append", "(", "[", "(", "\"\\\"{}|{}|{:.2f}\\\"\"", ".", "format", "(", "\n", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"best_type\"", "]", ",", "\n", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"best_type_name\"", "]", ",", "\n", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"confidence\"", "]", ")", "if", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "else", "\"\\\\\"", ")", "for", "j", "in", "range", "(", "col_size", ")", "]", ")", "\n", "\n", "cta_wrong_num", "=", "0", "\n", "for", "x", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", ":", "\n", "        ", "if", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "[", "x", "]", "!=", "col_types", "[", "x", "]", "[", "\"best_type\"", "]", ":", "\n", "            ", "cta_wrong_num", "+=", "1", "\n", "\n", "", "", "type_candid_line", "=", "[", "]", "\n", "# tie nodes", "\n", "for", "j", "in", "range", "(", "0", ",", "col_size", ")", ":", "\n", "        ", "if", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", ":", "\n", "            ", "type_candid_line", ".", "append", "(", "\n", "\"\\\"{}\\\"\"", ".", "format", "(", "\",\"", ".", "join", "(", "[", "\"{}|{}\"", ".", "format", "(", "*", "x", ")", "for", "x", "in", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"tie_nodes\"", "]", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "type_candid_line", ".", "append", "(", "\"\\\\\"", ")", "\n", "\n", "", "", "table", ".", "append", "(", "type_candid_line", ")", "\n", "# table.append(\"\\n\")", "\n", "# gold cta", "\n", "table", ".", "append", "(", "[", "(", "\"\\\"{}|{}\\\"\"", ".", "format", "(", "\n", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "[", "str", "(", "j", ")", "]", ",", "\n", "get_item_name", "(", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "[", "str", "(", "j", ")", "]", ")", "\n", ")", "if", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "else", "\"\\\\\"", ")", "for", "j", "in", "range", "(", "col_size", ")", "]", ")", "\n", "\n", "# table.append(\"\\n\")", "\n", "presult", "=", "[", "\"Property\"", "]", "\n", "# presult = []", "\n", "gold_presult", "=", "[", "\"Property\"", "]", "\n", "\n", "for", "j", "in", "range", "(", "1", ",", "col_size", ")", ":", "\n", "        ", "if", "str", "(", "j", ")", "in", "properties", "and", "len", "(", "properties", "[", "str", "(", "j", ")", "]", ")", ">", "0", ":", "\n", "            ", "if", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cpa'", "]", ":", "\n", "                ", "presult", ".", "append", "(", "\"\\\"{}|{}\\\"\"", ".", "format", "(", "properties", "[", "str", "(", "j", ")", "]", "[", "0", "]", "[", "\"property\"", "]", ",", "properties", "[", "str", "(", "j", ")", "]", "[", "0", "]", "[", "\"property_name\"", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "presult", ".", "append", "(", "\"\\\\\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cpa'", "]", ":", "\n", "                ", "presult", ".", "append", "(", "\"NILP\"", ")", "\n", "", "else", ":", "\n", "                ", "presult", ".", "append", "(", "\"\\\\\"", ")", "\n", "", "", "if", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cpa'", "]", ":", "\n", "            ", "gold_presult", ".", "append", "(", "\"\\\"{}|{}\\\"\"", ".", "format", "(", "gold", "[", "tab_id", "]", "[", "'cpa'", "]", "[", "str", "(", "j", ")", "]", ",", "\n", "get_item_name", "(", "gold", "[", "tab_id", "]", "[", "'cpa'", "]", "[", "str", "(", "j", ")", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "gold_presult", ".", "append", "(", "\"\\\\\"", ")", "\n", "\n", "", "", "cpa_wrong_num", "=", "0", "\n", "for", "x", "in", "gold", "[", "tab_id", "]", "[", "'cpa'", "]", ":", "\n", "        ", "if", "x", "not", "in", "properties", ":", "\n", "            ", "cpa_wrong_num", "+=", "1", "\n", "continue", "\n", "", "if", "len", "(", "properties", "[", "x", "]", ")", "==", "0", ":", "\n", "            ", "cpa_wrong_num", "+=", "1", "\n", "continue", "\n", "", "if", "gold", "[", "tab_id", "]", "[", "'cpa'", "]", "[", "x", "]", "!=", "properties", "[", "x", "]", "[", "0", "]", "[", "'property'", "]", ":", "\n", "            ", "cpa_wrong_num", "+=", "1", "\n", "\n", "", "", "table", ".", "append", "(", "presult", ")", "\n", "table", ".", "append", "(", "gold_presult", ")", "\n", "table", ".", "append", "(", "\"\\n\"", ")", "\n", "cea_wrong_num", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "row_size", ")", ":", "\n", "        ", "row_annotation", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "col_size", ")", ":", "\n", "            ", "entity", "=", "entities", "[", "str", "(", "(", "i", ",", "j", ")", ")", "]", "\n", "\n", "idx", "=", "str", "(", "(", "i", ",", "j", ")", ")", "\n", "if", "idx", "in", "gold", "[", "tab_id", "]", "[", "'cea'", "]", ":", "\n", "                ", "if", "entity", "[", "\"entity\"", "]", "!=", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ":", "\n", "                    ", "row_annotation", ".", "append", "(", "\"\\\"*** {}|{}|{}->{}|{} ***\\\"\"", ".", "format", "(", "row_tab", "[", "i", "]", "[", "j", "]", ",", "\n", "entity", "[", "\"entity\"", "]", ",", "\n", "entity", "[", "\"entity_title\"", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ",", "\n", "get_item_name", "(", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ")", ")", ")", "\n", "\n", "cea_wrong_num", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "row_annotation", ".", "append", "(", "\"\\\"{}|{}|{}->{}|{}\\\"\"", ".", "format", "(", "row_tab", "[", "i", "]", "[", "j", "]", ",", "\n", "entity", "[", "\"entity\"", "]", ",", "\n", "entity", "[", "\"entity_title\"", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ",", "\n", "get_item_name", "(", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "row_annotation", ".", "append", "(", "\"\\\"{}|\\\\|\\\\\\\"\"", ".", "format", "(", "row_tab", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "", "table", ".", "append", "(", "row_annotation", ")", "\n", "\n", "", "ret", "=", "{", "\"format_line\"", ":", "\"{}\\n\"", ".", "format", "(", "\"\\n\"", ".", "join", "(", "[", "','", ".", "join", "(", "line", ")", "for", "line", "in", "table", "]", ")", ")", ",", "\n", "\"cea_wrong_num\"", ":", "cea_wrong_num", ",", "\n", "\"cta_wrong_num\"", ":", "cta_wrong_num", ",", "\n", "\"cpa_wrong_num\"", ":", "cpa_wrong_num", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_2T_analysis_file_with_gold.load_gold": [[15, 22], ["open", "dict", "json.loads", "line.strip"], "function", ["None"], ["def", "load_gold", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "gold", "=", "dict", "(", ")", "\n", "for", "line", "in", "fp", ":", "\n", "            ", "tab", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "gold", "[", "tab", "[", "'tab_id'", "]", "]", "=", "tab", "\n", "", "return", "gold", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_2T_analysis_file_with_gold.load_pred": [[24, 32], ["dict", "open", "tqdm.tqdm", "json.loads", "line.strip"], "function", ["None"], ["", "", "def", "load_pred", "(", "log_fn", ",", "gold", ")", ":", "\n", "    ", "pred", "=", "dict", "(", ")", "\n", "with", "open", "(", "log_fn", ",", "encoding", "=", "'utf-8'", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "fp", ")", ":", "\n", "            ", "tab", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "if", "tab", "[", "'tab_id'", "]", "in", "gold", ":", "\n", "                ", "pred", "[", "tab", "[", "'tab_id'", "]", "]", "=", "tab", "\n", "", "", "", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_2T_analysis_file_with_gold.load_targets": [[34, 40], ["set", "open", "set.add", "line.strip().replace", "line.strip"], "function", ["None"], ["", "def", "load_targets", "(", "fn", ")", ":", "\n", "    ", "targets", "=", "set", "(", ")", "\n", "with", "open", "(", "fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "targets", ".", "add", "(", "line", ".", "strip", "(", ")", ".", "replace", "(", "'\\\"'", ",", "\"\"", ")", ")", "\n", "", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.analysis.gen_2T_analysis_file_with_gold.format_result": [[42, 121], ["table.append", "table.append", "range", "table.append", "table.append", "range", "table.append", "table.append", "range", "range", "table.append", "str", "type_candid_line.append", "type_candid_line.append", "presult.append", "presult.append", "str", "range", "range", "range", "str", "len", "row_annotation.append", "str", "row_annotation.append", "row_annotation.append", "str", "str", "Utils.utils.get_item_name", "str", "entity[].replace", "entity[].replace", "str", "str", "str", "str", "str", "str", "Utils.utils.get_item_name", "Utils.utils.get_item_name", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name"], ["", "", "def", "format_result", "(", "tab_id", ",", "row_tab", ")", ":", "\n", "    ", "col_size", "=", "pred", "[", "tab_id", "]", "[", "'col_size'", "]", "\n", "row_size", "=", "pred", "[", "tab_id", "]", "[", "'row_size'", "]", "\n", "properties", "=", "pred", "[", "tab_id", "]", "[", "\"coarse_properties\"", "]", "\n", "col_types", "=", "pred", "[", "tab_id", "]", "[", "\"tab_pred_type\"", "]", "\n", "entities", "=", "pred", "[", "tab_id", "]", "[", "\"revisit_predict_entities\"", "]", "\n", "\n", "table", "=", "[", "]", "\n", "# append header", "\n", "table", ".", "append", "(", "[", "\"col{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "1", ",", "col_size", "+", "1", ")", "]", ")", "\n", "\n", "# pred type: id | name | confidence", "\n", "table", ".", "append", "(", "[", "(", "\"\\\"{}|{}|{:.2f}\\\"\"", ".", "format", "(", "\n", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"best_type\"", "]", ",", "\n", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"best_type_name\"", "]", ",", "\n", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"confidence\"", "]", ")", "if", "(", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "and", "\"{},{}\"", ".", "format", "(", "tab_id", ",", "j", ")", "in", "cta_targets", ")", "else", "\"\\\\\"", ")", "for", "j", "in", "range", "(", "col_size", ")", "]", ")", "\n", "\n", "cta_wrong_num", "=", "0", "\n", "for", "x", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", ":", "\n", "        ", "if", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "[", "x", "]", "!=", "col_types", "[", "x", "]", "[", "\"best_type\"", "]", ":", "\n", "            ", "cta_wrong_num", "+=", "1", "\n", "\n", "", "", "type_candid_line", "=", "[", "]", "\n", "# tie nodes", "\n", "for", "j", "in", "range", "(", "0", ",", "col_size", ")", ":", "\n", "        ", "if", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", ":", "\n", "            ", "type_candid_line", ".", "append", "(", "\n", "\"\\\"{}\\\"\"", ".", "format", "(", "\",\"", ".", "join", "(", "[", "\"{}|{}\"", ".", "format", "(", "*", "x", ")", "for", "x", "in", "col_types", "[", "str", "(", "j", ")", "]", "[", "\"tie_nodes\"", "]", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "type_candid_line", ".", "append", "(", "\"\\\\\"", ")", "\n", "\n", "", "", "table", ".", "append", "(", "type_candid_line", ")", "\n", "# gold cta", "\n", "table", ".", "append", "(", "[", "(", "\"\\\"{}|{}\\\"\"", ".", "format", "(", "\n", "', '", ".", "join", "(", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "[", "str", "(", "j", ")", "]", ")", ",", "\n", "', '", ".", "join", "(", "[", "get_item_name", "(", "x", ")", "for", "x", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "[", "str", "(", "j", ")", "]", "]", ")", "\n", ")", "if", "(", "str", "(", "j", ")", "in", "gold", "[", "tab_id", "]", "[", "'cta'", "]", "and", "\"{},{}\"", ".", "format", "(", "tab_id", ",", "j", ")", "in", "cta_targets", ")", "else", "\"\\\\\"", ")", "for", "j", "in", "range", "(", "col_size", ")", "]", ")", "\n", "\n", "# presult = [\"Property\"]", "\n", "presult", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "col_size", ")", ":", "\n", "        ", "if", "str", "(", "j", ")", "in", "properties", "and", "len", "(", "properties", "[", "str", "(", "j", ")", "]", ")", ">", "0", ":", "\n", "            ", "presult", ".", "append", "(", "\"\\\"{}|{}\\\"\"", ".", "format", "(", "properties", "[", "str", "(", "j", ")", "]", "[", "0", "]", "[", "\"property\"", "]", ",", "properties", "[", "str", "(", "j", ")", "]", "[", "0", "]", "[", "\"property_name\"", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "presult", ".", "append", "(", "\"\\\\\"", ")", "\n", "\n", "", "", "table", ".", "append", "(", "presult", ")", "\n", "table", ".", "append", "(", "\"\\n\"", ")", "\n", "cea_wrong_num", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "row_size", ")", ":", "\n", "        ", "row_annotation", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "col_size", ")", ":", "\n", "            ", "entity", "=", "entities", "[", "str", "(", "(", "i", ",", "j", ")", ")", "]", "\n", "\n", "idx", "=", "str", "(", "(", "i", ",", "j", ")", ")", "\n", "if", "idx", "in", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "and", "\"{},{},{}\"", ".", "format", "(", "tab_id", ",", "i", "+", "1", ",", "j", ")", "in", "cea_targets", ":", "\n", "                ", "if", "entity", "[", "\"entity\"", "]", "not", "in", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ":", "\n", "                    ", "row_annotation", ".", "append", "(", "\"\\\"*** {}|{}|{}->{}|{} ***\\\"\"", ".", "format", "(", "row_tab", "[", "i", "]", "[", "j", "]", ",", "\n", "entity", "[", "\"entity\"", "]", ",", "\n", "entity", "[", "\"entity_title\"", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "', '", ".", "join", "(", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ")", ",", "\n", "', '", ".", "join", "(", "[", "get_item_name", "(", "x", ")", "for", "x", "in", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", "]", ")", ")", ")", "\n", "\n", "cea_wrong_num", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "row_annotation", ".", "append", "(", "\"\\\"{}|{}|{}->{}|{}\\\"\"", ".", "format", "(", "row_tab", "[", "i", "]", "[", "j", "]", ",", "\n", "entity", "[", "\"entity\"", "]", ",", "\n", "entity", "[", "\"entity_title\"", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "', '", ".", "join", "(", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", ")", ",", "\n", "', '", ".", "join", "(", "[", "get_item_name", "(", "x", ")", "for", "x", "in", "gold", "[", "tab_id", "]", "[", "'cea'", "]", "[", "idx", "]", "]", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "row_annotation", ".", "append", "(", "\"\\\"{}|\\\\|\\\\\\\"\"", ".", "format", "(", "row_tab", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "", "table", ".", "append", "(", "row_annotation", ")", "\n", "\n", "", "ret", "=", "{", "\"format_line\"", ":", "\"{}\\n\"", ".", "format", "(", "\"\\n\"", ".", "join", "(", "[", "','", ".", "join", "(", "line", ")", "for", "line", "in", "table", "]", ")", ")", ",", "\n", "\"cea_wrong_num\"", ":", "cea_wrong_num", ",", "\n", "\"cta_wrong_num\"", ":", "cta_wrong_num", "}", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.candid_gen.all_in_one.read_target_set": [[14, 22], ["set", "open", "line.strip().replace.strip().replace", "line.strip().replace.split", "set.add", "tuple", "line.strip().replace.strip"], "function", ["None"], ["def", "read_target_set", "(", "target_fn", ")", ":", "\n", "    ", "target_set", "=", "set", "(", ")", "\n", "with", "open", "(", "target_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "split", "(", "','", ")", "\n", "target_set", ".", "add", "(", "tuple", "(", "words", ")", ")", "\n", "", "", "return", "target_set", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.candid_gen.all_in_one.gen_candidates": [[24, 82], ["Utils.utils.load_json_table", "dict", "print", "tqdm.tqdm", "tqdm.tqdm.close", "prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "print", "len", "len", "enumerate", "open", "pickle.dump", "enumerate", "tqdm.tqdm.update", "candid_gen.gen_candidates_with_features", "len", "len", "str", "str"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.load_json_table", "home.repos.pwc.inspect_result.microsoft_vert-papers.Maps.mixed_candid_map.MixedCandidateMap.gen_candidates_with_features"], ["", "def", "gen_candidates", "(", "tab_fn", ",", "\n", "candid_gen", ",", "\n", "out_fn", ",", "\n", "topk", "=", "1000", ",", "\n", "target_only", "=", "True", ",", "\n", "elastic_search_only", "=", "False", ",", "\n", "dictionary_only", "=", "False", ")", ":", "\n", "    ", "tables", "=", "load_json_table", "(", "tab_fn", ")", "\n", "alias_table", "=", "dict", "(", ")", "\n", "tab_num", ",", "col_num", ",", "row_num", ",", "cell_num", ",", "matched_cell_num", "=", "0", ",", "0", ",", "0", ",", "0", ",", "0", "\n", "total_cells", "=", "0", "\n", "for", "tab_id", "in", "tables", ":", "\n", "        ", "for", "row", "in", "tables", "[", "tab_id", "]", ":", "\n", "            ", "for", "cell", "in", "row", ":", "\n", "                ", "total_cells", "+=", "1", "\n", "", "", "", "print", "(", "\"total number of cells {}\"", ".", "format", "(", "total_cells", ")", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "total_cells", ")", "\n", "\n", "for", "tab_id", "in", "tables", ":", "\n", "        ", "tab_num", "+=", "1", "\n", "col_num", "+=", "len", "(", "tables", "[", "tab_id", "]", "[", "0", "]", ")", "\n", "row_num", "+=", "len", "(", "tables", "[", "tab_id", "]", ")", "\n", "\n", "for", "row_id", ",", "row", "in", "enumerate", "(", "tables", "[", "tab_id", "]", ")", ":", "\n", "            ", "for", "col_id", ",", "cell", "in", "enumerate", "(", "row", ")", ":", "\n", "                ", "pbar", ".", "update", "(", "1", ")", "\n", "if", "(", "not", "(", "(", "tab_id", ",", "str", "(", "row_id", "+", "1", ")", ",", "str", "(", "col_id", ")", ")", "in", "cea_targets", ")", ")", "and", "target_only", ":", "\n", "                    ", "continue", "\n", "", "cell_num", "+=", "1", "\n", "if", "cell", "in", "alias_table", ":", "\n", "                    ", "if", "len", "(", "alias_table", "[", "cell", "]", ")", ">", "0", ":", "\n", "                        ", "matched_cell_num", "+=", "1", "\n", "", "continue", "\n", "", "candid", "=", "candid_gen", ".", "gen_candidates_with_features", "(", "cell", ",", "\n", "elastic_search_only", "=", "elastic_search_only", ",", "\n", "dictionary_only", "=", "dictionary_only", ",", "\n", "topk", "=", "topk", ")", "\n", "alias_table", "[", "cell", "]", "=", "candid", "\n", "if", "len", "(", "candid", ")", ">", "0", ":", "\n", "                    ", "matched_cell_num", "+=", "1", "\n", "#     break", "\n", "# break", "\n", "", "", "", "", "pbar", ".", "close", "(", ")", "\n", "\n", "with", "open", "(", "out_fn", ",", "mode", "=", "\"wb\"", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "alias_table", ",", "fp", ")", "\n", "\n", "", "results", "=", "PrettyTable", "(", ")", "\n", "results", ".", "field_names", "=", "[", "\n", "\"Table Num\"", ",", "\n", "\"Column Num\"", ",", "\n", "\"Row Num\"", ",", "\n", "\"Cell Num\"", ",", "\n", "\"Matched Cell Num\"", "\n", "]", "\n", "\n", "results", ".", "add_row", "(", "[", "tab_num", ",", "col_num", ",", "row_num", ",", "cell_num", ",", "matched_cell_num", "]", ")", "\n", "print", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_date": [[48, 58], ["datetime.datetime.strptime", "datetime.datetime.strptime"], "function", ["None"], ["\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_float": [[60, 66], ["float"], "function", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_int": [[68, 74], ["s.isdigit", "len", "s[].isdigit"], "function", ["None"], ["        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_float_but_not_int": [[76, 80], ["utils.is_int", "utils.is_float"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_int", "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.is_float"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.rocksdb_get": [[82, 87], ["db.get", "bytes", "json.loads"], "function", ["None"], ["        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "class", "DataProcessor", "(", "object", ")", ":", "\n", "    ", "\"\"\"Base class for data converters for sequence classification data sets.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.redis_get": [[89, 97], ["r.get", "json.loads", "print"], "function", ["None"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"Gets an example from a dict with tensorflow tensors\n\n        Args:\n            tensor_dict: Keys and values should match the corresponding Glue\n                tensorflow_dataset examples.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.load_json_table": [[99, 111], ["open", "dict", "line.strip().split", "json.loads", "str_tab.append", "line.strip", "str"], "function", ["None"], ["        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils.get_item_name": [[113, 119], ["entity_meta_info.get", "json.loads", "data[].replace"], "function", ["None"], ["with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.pd_read_csv": [[11, 14], ["pandas.read_csv", "pd.read_csv.values.tolist"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv"], ["def", "pd_read_csv", "(", "fn", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "fn", ",", "header", "=", "0", ")", "\n", "return", "df", ".", "values", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_csv": [[16, 31], ["list", "open", "fp.readline().split", "line.strip().split", "list.append", "fp.readline", "len", "len", "line.strip"], "function", ["None"], ["", "def", "read_csv", "(", "fn", ")", ":", "\n", "    ", "\"\"\"\n\n    :param fn: file path\n    :return: list of rows\n    \"\"\"", "\n", "table", "=", "list", "(", ")", "\n", "with", "open", "(", "fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "# skip header", "\n", "        ", "header", "=", "fp", ".", "readline", "(", ")", ".", "split", "(", "','", ")", "\n", "for", "line", "in", "fp", ":", "\n", "            ", "cells", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "assert", "len", "(", "header", ")", "==", "len", "(", "cells", ")", "\n", "table", ".", "append", "(", "cells", ")", "\n", "", "", "return", "table", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.transpose_table": [[33, 40], ["list", "len", "len", "range", "list.append", "range"], "function", ["None"], ["", "def", "transpose_table", "(", "row_table", ")", ":", "\n", "    ", "column_table", "=", "list", "(", ")", "\n", "rows", "=", "len", "(", "row_table", ")", "\n", "cols", "=", "len", "(", "row_table", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "cols", ")", ":", "\n", "        ", "column_table", ".", "append", "(", "[", "row_table", "[", "j", "]", "[", "i", "]", "for", "j", "in", "range", "(", "rows", ")", "]", ")", "\n", "", "return", "column_table", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_cea_target": [[42, 57], ["dict", "open", "line.replace.replace", "line.replace.strip().split", "[].append", "int", "int", "dict", "line.replace.strip"], "function", ["None"], ["", "def", "read_cea_target", "(", "target_fn", ")", ":", "\n", "    ", "targets", "=", "dict", "(", ")", "\n", "with", "open", "(", "target_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", ",", "row_id", ",", "col_id", "=", "words", "[", "0", "]", ",", "int", "(", "words", "[", "1", "]", ")", ",", "int", "(", "words", "[", "2", "]", ")", "\n", "if", "tab_id", "not", "in", "targets", ":", "\n", "                ", "targets", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "\n", "", "if", "col_id", "not", "in", "targets", "[", "tab_id", "]", ":", "\n", "                ", "targets", "[", "tab_id", "]", "[", "col_id", "]", "=", "[", "]", "\n", "\n", "", "targets", "[", "tab_id", "]", "[", "col_id", "]", ".", "append", "(", "row_id", ")", "\n", "", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_cta_target": [[59, 70], ["dict", "open", "line.replace.replace", "line.replace.strip().split", "targets[].append", "int", "line.replace.strip"], "function", ["None"], ["", "", "def", "read_cta_target", "(", "target_fn", ")", ":", "\n", "    ", "targets", "=", "dict", "(", ")", "\n", "with", "open", "(", "target_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", ",", "col_id", "=", "words", "[", "0", "]", ",", "int", "(", "words", "[", "1", "]", ")", "\n", "if", "tab_id", "not", "in", "targets", ":", "\n", "                ", "targets", "[", "tab_id", "]", "=", "[", "]", "\n", "", "targets", "[", "tab_id", "]", ".", "append", "(", "col_id", ")", "\n", "", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.read_cpa_target": [[72, 83], ["dict", "open", "line.replace.replace", "line.replace.strip().split", "targets[].append", "int", "int", "line.replace.strip"], "function", ["None"], ["", "", "def", "read_cpa_target", "(", "target_fn", ")", ":", "\n", "    ", "targets", "=", "dict", "(", ")", "\n", "with", "open", "(", "target_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", "\n", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "tab_id", ",", "src_id", ",", "trg_id", "=", "words", "[", "0", "]", ",", "int", "(", "words", "[", "1", "]", ")", ",", "int", "(", "words", "[", "2", "]", ")", "\n", "if", "tab_id", "not", "in", "targets", ":", "\n", "                ", "targets", "[", "tab_id", "]", "=", "[", "]", "\n", "", "targets", "[", "tab_id", "]", ".", "append", "(", "trg_id", ")", "\n", "", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.write_CEA_result": [[85, 102], ["open", "fp.write"], "function", ["None"], ["", "", "def", "write_CEA_result", "(", "re_fn", ",", "col_entities", ",", "cea_targets", ")", ":", "\n", "    ", "with", "open", "(", "re_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "for", "tab_id", "in", "cea_targets", ":", "\n", "            ", "for", "col_id", "in", "cea_targets", "[", "tab_id", "]", ":", "\n", "                ", "if", "tab_id", "in", "col_entities", "and", "col_id", "in", "col_entities", "[", "tab_id", "]", ":", "\n", "                    ", "entities", "=", "col_entities", "[", "tab_id", "]", "[", "col_id", "]", "\n", "for", "row_id", "in", "cea_targets", "[", "tab_id", "]", "[", "col_id", "]", ":", "\n", "# skip header line", "\n", "                        ", "if", "entities", "[", "row_id", "-", "1", "]", "!=", "\"NIL\"", "and", "entities", "[", "row_id", "-", "1", "]", "!=", "None", ":", "\n", "# fp.write(\"\\\"{}\\\",\\\"{}\\\",\\\"{}\\\",\\\"{}\\\"\\n\".format(tab_id,", "\n", "#                                               col_id,", "\n", "#                                               row_id,", "\n", "#                                               wikidata_prefix+entities[row_id-1]))", "\n", "                            ", "fp", ".", "write", "(", "\"\\\"{}\\\",\\\"{}\\\",\\\"{}\\\",\\\"{}\\\"\\n\"", ".", "format", "(", "tab_id", ",", "\n", "row_id", ",", "\n", "col_id", ",", "\n", "wikidata_prefix", "+", "entities", "[", "row_id", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.write_CTA_result": [[104, 114], ["open", "fp.write"], "function", ["None"], ["", "", "", "", "", "", "", "def", "write_CTA_result", "(", "re_fn", ",", "column_types", ",", "cta_targets", ")", ":", "\n", "    ", "with", "open", "(", "re_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "for", "tab_id", "in", "cta_targets", ":", "\n", "            ", "for", "col_id", "in", "cta_targets", "[", "tab_id", "]", ":", "\n", "                ", "if", "(", "tab_id", "in", "column_types", ")", "and", "(", "col_id", "in", "column_types", "[", "tab_id", "]", ")", ":", "\n", "                    ", "best_type", "=", "column_types", "[", "tab_id", "]", "[", "col_id", "]", "\n", "if", "best_type", "!=", "\"\"", ":", "\n", "                        ", "fp", ".", "write", "(", "\"\\\"{}\\\",\\\"{}\\\",\\\"{}\\\"\\n\"", ".", "format", "(", "tab_id", ",", "\n", "col_id", ",", "\n", "wikidata_prefix", "+", "best_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.write_CPA_result": [[116, 125], ["open", "fp.write"], "function", ["None"], ["", "", "", "", "", "", "def", "write_CPA_result", "(", "re_fn", ",", "column_properties", ",", "cpa_targets", ")", ":", "\n", "    ", "with", "open", "(", "re_fn", ",", "encoding", "=", "\"utf-8\"", ",", "mode", "=", "\"w\"", ")", "as", "fp", ":", "\n", "        ", "for", "tab_id", "in", "cpa_targets", ":", "\n", "            ", "for", "col_id", "in", "cpa_targets", "[", "tab_id", "]", ":", "\n", "                ", "if", "(", "tab_id", "in", "column_properties", ")", "and", "(", "col_id", "in", "column_properties", "[", "tab_id", "]", ")", ":", "\n", "                    ", "property", "=", "column_properties", "[", "tab_id", "]", "[", "col_id", "]", "\n", "fp", ".", "write", "(", "\"\\\"{}\\\",\\\"0\\\",\\\"{}\\\",\\\"{}\\\"\\n\"", ".", "format", "(", "tab_id", ",", "\n", "col_id", ",", "\n", "property_prefix", "+", "property", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.load_cache_result": [[127, 166], ["dict", "dict", "dict", "open", "json.loads", "range", "line.strip", "dict", "dict", "dict", "range", "range", "entities.append", "entities.append", "str", "len", "str", "str", "str", "str", "str"], "function", ["None"], ["", "", "", "", "", "def", "load_cache_result", "(", "log_fn", ")", ":", "\n", "    ", "col_entities", "=", "dict", "(", ")", "\n", "col_types", "=", "dict", "(", ")", "\n", "col_properties", "=", "dict", "(", ")", "\n", "with", "open", "(", "log_fn", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "out_tab", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "tab_id", "=", "out_tab", "[", "\"tab_id\"", "]", "\n", "predict_entities", "=", "out_tab", "[", "\"predict_entities\"", "]", "\n", "revisit_predict_entities", "=", "out_tab", "[", "\"revisit_predict_entities\"", "]", "\n", "tab_pred_type", "=", "out_tab", "[", "\"tab_pred_type\"", "]", "\n", "if", "\"fine_properties\"", "in", "out_tab", ":", "\n", "                ", "properties", "=", "out_tab", "[", "\"fine_properties\"", "]", "\n", "", "else", ":", "\n", "                ", "properties", "=", "out_tab", "[", "\"coarse_properties\"", "]", "\n", "", "row_size", "=", "out_tab", "[", "\"row_size\"", "]", "\n", "col_size", "=", "out_tab", "[", "\"col_size\"", "]", "\n", "if", "tab_id", "not", "in", "col_entities", ":", "\n", "                ", "col_entities", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "if", "tab_id", "not", "in", "col_types", ":", "\n", "                ", "col_types", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "if", "tab_id", "not", "in", "col_properties", ":", "\n", "                ", "col_properties", "[", "tab_id", "]", "=", "dict", "(", ")", "\n", "", "for", "j", "in", "range", "(", "col_size", ")", ":", "\n", "                ", "if", "j", "==", "0", ":", "\n", "                    ", "entities", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "row_size", ")", ":", "\n", "                        ", "wikidata_id", "=", "revisit_predict_entities", "[", "str", "(", "(", "i", ",", "j", ")", ")", "]", "[", "\"entity\"", "]", "\n", "entities", ".", "append", "(", "wikidata_id", ")", "\n", "", "", "else", ":", "\n", "                    ", "entities", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "row_size", ")", ":", "\n", "                        ", "wikidata_id", "=", "predict_entities", "[", "str", "(", "(", "i", ",", "j", ")", ")", "]", "[", "\"entity\"", "]", "\n", "entities", ".", "append", "(", "wikidata_id", ")", "\n", "", "", "col_entities", "[", "tab_id", "]", "[", "j", "]", "=", "entities", "\n", "col_types", "[", "tab_id", "]", "[", "j", "]", "=", "tab_pred_type", "[", "str", "(", "j", ")", "]", "[", "\"best_type\"", "]", "\n", "if", "str", "(", "j", ")", "in", "properties", "and", "len", "(", "properties", "[", "str", "(", "j", ")", "]", ")", ">", "0", ":", "\n", "                    ", "col_properties", "[", "tab_id", "]", "[", "j", "]", "=", "properties", "[", "str", "(", "j", ")", "]", "[", "0", "]", "[", "\"property\"", "]", "\n", "", "", "", "", "return", "col_entities", ",", "col_types", ",", "col_properties", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.Utils.utils_data.load_cache_result_for_analysis": [[168, 176], ["dict", "open", "json.loads", "line.strip"], "function", ["None"], ["", "def", "load_cache_result_for_analysis", "(", "log_fn", ")", ":", "\n", "    ", "log", "=", "dict", "(", ")", "\n", "with", "open", "(", "log_fn", ",", "encoding", "=", "'utf-8'", ",", "mode", "=", "'r'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "json_obj", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "tab_id", "=", "json_obj", "[", "\"tab_id\"", "]", "\n", "log", "[", "tab_id", "]", "=", "json_obj", "\n", "", "", "return", "log", "\n", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.overlap_all.evaluate_viterbi": [[17, 75], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "utils.ViterbiDecoder", "range", "sorted", "tuple", "torch.nn.functional.log_softmax", "utils.ViterbiDecoder.forward", "pred_label_list.extend", "len", "ValueError", "range", "results.keys", "logger.info", "len", "logits.detach", "batch[].detach().cpu().numpy", "numpy.append", "enumerate", "range", "len", "len", "ValueError", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "t.to", "batch[].detach().cpu().numpy", "out_label_list[].append", "batch[].detach().cpu", "batch[].detach().cpu", "batch[].detach", "batch[].detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], ["def", "evaluate_viterbi", "(", "labels", ",", "pad_token_label_id", ",", "eval_dataset", ",", "device", ")", ":", "\n", "    ", "eval_batch_size", "=", "32", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "eval_batch_size", "\n", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation with Viterbi Decoding *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", "%", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", "%", "eval_batch_size", ")", "\n", "\n", "viterbi_decoder", "=", "ViterbiDecoder", "(", "labels", ",", "pad_token_label_id", ",", "device", ")", "\n", "out_label_ids", "=", "None", "\n", "pred_label_list", "=", "[", "]", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "logits", "=", "batch", "[", "-", "1", "]", "\n", "\n", "# decode with viterbi", "\n", "log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "\n", "logits", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", "\n", ")", "# batch_size x max_seq_len x n_labels", "\n", "\n", "pred_labels", "=", "viterbi_decoder", ".", "forward", "(", "log_probs", ",", "batch", "[", "1", "]", ",", "batch", "[", "3", "]", ")", "\n", "pred_label_list", ".", "extend", "(", "pred_labels", ")", "\n", "\n", "if", "out_label_ids", "is", "None", ":", "\n", "            ", "out_label_ids", "=", "batch", "[", "3", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "out_label_ids", "=", "np", ".", "append", "(", "\n", "out_label_ids", ",", "batch", "[", "3", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", "\n", ")", "\n", "\n", "", "", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "out_label_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "if", "out_label_ids", ".", "shape", "[", "0", "]", "!=", "len", "(", "pred_label_list", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Num of examples doesn't match!\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "out_label_ids", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "out_label_ids", "[", "i", ",", "j", "]", "!=", "pad_token_label_id", ":", "\n", "                ", "out_label_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "out_label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "", "", "if", "len", "(", "out_label_list", "[", "i", "]", ")", "!=", "len", "(", "pred_label_list", "[", "i", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Sequence length doesn't match!\"", ")", "\n", "\n", "", "", "results", "=", "{", "\n", "\"precision\"", ":", "precision_score", "(", "out_label_list", ",", "pred_label_list", ")", "*", "100", ",", "\n", "\"recall\"", ":", "recall_score", "(", "out_label_list", ",", "pred_label_list", ")", "*", "100", ",", "\n", "\"f1\"", ":", "f1_score", "(", "out_label_list", ",", "pred_label_list", ")", "*", "100", ",", "\n", "}", "\n", "\n", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"{key} =  {results[key]}\"", ")", "\n", "\n", "", "return", "results", ",", "pred_label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.model.LanguageDiscriminatorTokenLevel.__init__": [[14, 23], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__"], ["\n", "    ", "def", "__init__", "(", "self", ",", "word_set_size", ",", "tag_to_id", ",", "word_embedding_dim", ",", "word_lstm_dim", ",", "word_lstm_bidirect", "=", "True", ",", "\n", "pre_word_embeds", "=", "None", ",", "char_embedding_dim", "=", "25", ",", "char_mode", "=", "CharEmbeddingSchema", ".", "CNN", ",", "\n", "char_lstm_dim", "=", "25", ",", "char_lstm_bidirect", "=", "True", ",", "char_cnn_win", "=", "3", ",", "char_cnn_output", "=", "25", ",", "\n", "char_to_id", "=", "None", ",", "use_gpu", "=", "False", ",", "dropout", "=", "0.5", ",", "use_crf", "=", "True", ",", "char_embed_dropout", "=", "False", ",", "\n", "inception_mode", "=", "1", ",", "enable_context", "=", "True", ")", ":", "\n", "# checked", "\n", "        ", "super", "(", "GRN_CRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_set_size", "=", "word_set_size", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.model.LanguageDiscriminatorTokenLevel.forward": [[24, 50], ["mask.bool.bool.bool", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.LanguageDiscriminatorTokenLevel.relu", "model.LanguageDiscriminatorTokenLevel.fc2", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.masked_select.view", "torch.masked_select.view", "torch.masked_select.view", "torch.masked_select.round", "torch.masked_select.round", "torch.masked_select.round", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "model.LanguageDiscriminatorTokenLevel.loss_fct", "model.LanguageDiscriminatorTokenLevel.fc1", "torch.masked_select.view", "torch.masked_select.view", "torch.masked_select.view", "torch.masked_select.view", "torch.masked_select.view", "torch.masked_select.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "int", "int", "torch.masked_select.size", "torch.masked_select.size", "torch.masked_select.size", "range", "range"], "methods", ["None"], ["self", ".", "tag_to_id", "=", "tag_to_id", "\n", "self", ".", "word_embedding_dim", "=", "word_embedding_dim", "\n", "self", ".", "word_lstm_dim", "=", "word_lstm_dim", "\n", "self", ".", "word_lstm_bidirect", "=", "word_lstm_bidirect", "\n", "self", ".", "char_embedding_dim", "=", "char_embedding_dim", "\n", "self", ".", "char_mode", "=", "char_mode", "\n", "self", ".", "char_lstm_dim", "=", "char_lstm_dim", "\n", "self", ".", "char_lstm_bidirect", "=", "char_lstm_bidirect", "\n", "self", ".", "char_cnn_win", "=", "char_cnn_win", "\n", "self", ".", "char_cnn_output", "=", "char_cnn_output", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "use_crf", "=", "use_crf", "\n", "self", ".", "tag_set_size", "=", "len", "(", "tag_to_id", ")", "\n", "self", ".", "char_embed_dropout", "=", "char_embed_dropout", "\n", "self", ".", "inception_mode", "=", "inception_mode", "\n", "self", ".", "enable_context", "=", "enable_context", "\n", "\n", "print", "(", "'char_mode: {0}, char_embedding_out: {1}, word_hidden_dim: {2}'", ".", "format", "\n", "(", "char_mode", ",", "char_cnn_output", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "CNN", "else", "\n", "(", "char_lstm_dim", "*", "(", "2", "if", "char_lstm_bidirect", "else", "1", ")", ")", ",", "\n", "word_lstm_dim", "*", "(", "2", "if", "word_lstm_bidirect", "else", "1", ")", ")", ")", "\n", "\n", "if", "char_embedding_dim", "is", "not", "None", ":", "\n", "            ", "self", ".", "char_embeds", "=", "nn", ".", "Embedding", "(", "len", "(", "char_to_id", ")", ",", "char_embedding_dim", ")", "\n", "init_embedding_", "(", "self", ".", "char_embeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.model.BertForTokenClassificationKD.forward": [[53, 128], ["model.BertForTokenClassificationKD.bert", "model.BertForTokenClassificationKD.dropout", "model.BertForTokenClassificationKD.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "attention_mask.view", "model.BertForTokenClassificationKD.view", "labels.view", "model.BertForTokenClassificationKD.view", "labels.view", "attention_mask.view", "labels.view", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "confidence.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "print", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "confidence.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.size", "confidence.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.view().size", "active_loss.size", "confidence.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.view", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "confidence.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "confidence.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.view", "confidence.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze"], "methods", ["None"], ["bidirectional", "=", "char_lstm_bidirect", ",", "batch_first", "=", "True", ")", "\n", "init_lstm_", "(", "self", ".", "char_lstm", ")", "\n", "", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "CNN", ":", "\n", "                ", "self", ".", "char_cnn", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "char_cnn_output", ",", "\n", "kernel_size", "=", "(", "char_cnn_win", ",", "char_embedding_dim", ")", ",", "\n", "padding", "=", "(", "char_cnn_win", "//", "2", ",", "0", ")", ")", "\n", "init_cnn_", "(", "self", ".", "char_cnn", ")", "\n", "\n", "", "", "self", ".", "word_embeds", "=", "nn", ".", "Embedding", "(", "word_set_size", ",", "word_embedding_dim", ")", "\n", "if", "pre_word_embeds", "is", "not", "None", ":", "\n", "            ", "self", ".", "pre_word_embeds", "=", "True", "\n", "self", ".", "word_embeds", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "pre_word_embeds", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pre_word_embeds", "=", "False", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "cnn_input_dim", "=", "(", "word_embedding_dim", "+", "char_lstm_dim", "*", "(", "2", "if", "char_lstm_bidirect", "else", "1", ")", ")", "if", "char_mode", "==", "CharEmbeddingSchema", ".", "LSTM", "else", "(", "word_embedding_dim", "+", "char_cnn_output", ")", "\n", "cnn_output_dim", "=", "word_lstm_dim", "*", "(", "2", "if", "word_lstm_bidirect", "else", "1", ")", "\n", "self", ".", "inception_cnn", "=", "InceptionCNN", "(", "in_channels", "=", "1", ",", "out_channels", "=", "cnn_output_dim", ",", "kernel_dim", "=", "cnn_input_dim", ",", "inception_mode", "=", "self", ".", "inception_mode", ")", "\n", "\n", "if", "self", ".", "inception_mode", "==", "1", ":", "\n", "            ", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_1", ")", "\n", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_3", ")", "\n", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_5", ")", "\n", "", "elif", "self", ".", "inception_mode", "==", "2", ":", "\n", "            ", "init_cnn_", "(", "self", ".", "inception_cnn", ".", "conv_3", ")", "\n", "", "elif", "self", ".", "inception_mode", "==", "0", ":", "\n", "            ", "cnn_output_dim", "=", "cnn_input_dim", "\n", "\n", "", "if", "self", ".", "enable_context", ":", "\n", "            ", "self", ".", "context_layer1", "=", "ContextLayer", "(", "cnn_output_dim", ",", "False", ",", "use_gpu", ")", "\n", "\n", "", "self", ".", "hidden2tag", "=", "nn", ".", "Linear", "(", "cnn_output_dim", ",", "self", ".", "tag_set_size", ")", "\n", "init_linear_", "(", "self", ".", "hidden2tag", ")", "\n", "\n", "if", "use_crf", ":", "\n", "            ", "self", ".", "transitions", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "tag_set_size", ",", "self", ".", "tag_set_size", ")", ")", "\n", "self", ".", "transitions", ".", "data", "[", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", ",", ":", "]", "=", "Constants", ".", "Invalid_Transition", "\n", "self", ".", "transitions", ".", "data", "[", ":", ",", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", "]", "=", "Constants", ".", "Invalid_Transition", "\n", "\n", "", "", "def", "_score_sentence", "(", "self", ",", "feats", ",", "tags", ",", "sentence_masks", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        checked\n        Get the CRF score for the ground-truth tags\n        :param feats: LSTM output, batch x max_seq x tag\n        :param tags: ground-truth tags, batch x max_seq\n        :param sentence_masks: binary (0,1) int matrix, batch x max_seq\n        :param device: device info\n        :return:\n        \"\"\"", "\n", "\n", "batch_size", ",", "max_seq_length", ",", "tag_num", "=", "feats", ".", "size", "(", ")", "\n", "\n", "# batch x max_seq", "\n", "tag_wise_score", "=", "torch", ".", "gather", "(", "feats", ",", "2", ",", "tags", ".", "view", "(", "batch_size", ",", "max_seq_length", ",", "1", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "pad_ones", "=", "torch", ".", "ones", "(", "(", "batch_size", ",", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "requires_grad", "=", "False", ")", "\n", "tag_start", "=", "pad_ones", "*", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_Start", "]", "\n", "tag_end", "=", "pad_ones", "*", "self", ".", "tag_to_id", "[", "Constants", ".", "Tag_End", "]", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "pad_ones", "=", "pad_ones", ".", "to", "(", "device", ")", "\n", "tag_start", "=", "tag_start", ".", "to", "(", "device", ")", "\n", "tag_end", "=", "tag_end", ".", "to", "(", "device", ")", "\n", "\n", "", "pad_start_tags", "=", "torch", ".", "cat", "(", "[", "tag_start", ",", "tags", "]", ",", "dim", "=", "1", ")", "\n", "pad_end_tags", "=", "torch", ".", "cat", "(", "[", "tags", ",", "tag_end", "]", ",", "dim", "=", "1", ")", "\n", "transition_masks", "=", "torch", ".", "cat", "(", "[", "pad_ones", ",", "sentence_masks", "]", ",", "dim", "=", "1", ")", "\n", "# batch x [max_seq+1]", "\n", "transition_score", "=", "self", ".", "transitions", "[", "pad_end_tags", ",", "pad_start_tags", "]", "\n", "\n", "invalid_sentence_masks", "=", "(", "1", "-", "sentence_masks", ")", ".", "byte", "(", ")", "\n", "invalid_transition_masks", "=", "(", "1", "-", "transition_masks", ")", ".", "byte", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.InputExample.__init__": [[21, 25], ["None"], "methods", ["None"], ["\n", "class", "InputExample", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.InputFeatures.__init__": [[28, 35], ["None"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.__init__": [[289, 299], ["len", "torch.zeros", "range", "range", "enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward": [[300, 348], ["logprobs.size", "range", "ValueError", "range", "torch.max", "best_label_id.item.item.item", "reversed", "best_path.reverse", "label_seqs.append", "len", "torch.max", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy().tolist", "back_pointers.append", "best_path.append", "len", "len", "ValueError", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy", "bptrs_t.cpu().numpy().tolist.cpu().numpy().tolist.cpu"], "methods", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.evaluate_viterbi": [[37, 126], ["utils.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "utils.ViterbiDecoder", "model.eval", "range", "logger.info", "sorted", "max", "len", "tuple", "torch.nn.functional.log_softmax", "utils.ViterbiDecoder.forward", "pred_label_list.extend", "len", "ValueError", "range", "results.keys", "logger.info", "torch.no_grad", "model", "tmp_eval_loss.item", "logits.detach", "inputs[].detach().cpu().numpy", "numpy.append", "enumerate", "range", "len", "len", "ValueError", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "t.to", "inputs[].detach().cpu().numpy", "out_label_list[].append", "inputs[].detach().cpu", "inputs[].detach().cpu", "inputs[].detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.ViterbiDecoder.forward"], ["self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n", "", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    A single set of features of data.\n\n    Args:\n        input_ids: Indices of input sequence tokens in the vocabulary.\n        attention_mask: Mask to avoid performing attention on padding token indices.\n            Mask values selected in ``[0, 1]``:\n            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n        label: Label corresponding to the input\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "label", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n", "", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "class", "DataProcessor", "(", "object", ")", ":", "\n", "    ", "\"\"\"Base class for data converters for sequence classification data sets.\"\"\"", "\n", "\n", "def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"Gets an example from a dict with tensorflow tensors\n\n        Args:\n            tensor_dict: Keys and values should match the corresponding Glue\n                tensorflow_dataset examples.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples": [[128, 180], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils.read_examples_from_file", "utils.convert_examples_to_features", "logger.info", "torch.save", "list().pop", "str", "bool", "bool", "bool", "list", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.read_examples_from_file", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.convert_examples_to_features", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.non_en_dataset": [[182, 199], ["tgt_langs.split", "torch.utils.data.ConcatDataset", "utils.load_and_cache_examples", "utils.get_shuffle_dataset", "datasets.append", "int", "len", "tgt_langs.split"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.load_and_cache_examples", "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_shuffle_dataset"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_shuffle_dataset": [[201, 218], ["random.shuffle", "min", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.utils.data.TensorDataset", "dataset.__len__", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "range", "dataset.__len__"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_loader_conll.DataLoaderCoNLL.__len__", "home.repos.pwc.inspect_result.microsoft_vert-papers.GRN-NER.data_loader_conll.DataLoaderCoNLL.__len__"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_optimizer_grouped_parameters": [[220, 253], ["logger.info", "model.named_parameters", "model.named_parameters", "any", "logger.info", "model.named_parameters", "model.named_parameters", "any", "any"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.write_prediction": [[255, 276], ["open", "open", "line.startswith", "writer.write", "writer.write", "logger.warning", "[].replace", "predictions[].pop", "line.split", "line.split", "line.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.shuffle_word_embedding": [[279, 286], ["random.shuffle", "torch.stack", "len", "len", "range", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.shuffle_input": [[350, 371], ["range", "torch.stack().to", "torch.stack().to", "seqs_id.size", "random.choice", "torch.Tensor", "torch.stack().to.append", "torch.stack().to.append", "torch.sum", "utils.shuffle_word_embedding", "torch.stack", "torch.stack", "seqs_id.size"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.shuffle_word_embedding"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.get_labels": [[373, 393], ["open", "f.read().splitlines", "f.read().splitlines.remove", "f.read"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.read_examples_from_file": [[396, 430], ["os.path.join", "open", "line.strip().replace.strip().replace", "examples.append", "line.strip().replace.startswith", "line.strip().replace.split", "words.append", "utils.InputExample", "line.strip().replace.strip", "examples.append", "len", "labels.append", "labels.append", "utils.InputExample", "splits[].replace"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.convert_examples_to_features": [[432, 541], ["enumerate", "zip", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "logger.info", "tokenizer.tokenize", "tokens.extend", "label_ids.extend", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "len", "len", "str", "str", "str", "str", "str", "len"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.microsoft_vert-papers.transformers.tokenization_utils.PreTrainedTokenizer.tokenize"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.torch_device": [[543, 552], ["logger.info", "torch.cuda.is_available", "torch.cuda.set_device", "torch.device", "torch.device"], "function", ["None"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.mkdir": [[554, 558], ["os.path.exists", "os.mkdir"], "function", ["home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.mkdir"], []], "home.repos.pwc.inspect_result.microsoft_vert-papers.AdvPicker.utils.set_seed": [[560, 567], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "str"], "function", ["None"], []]}