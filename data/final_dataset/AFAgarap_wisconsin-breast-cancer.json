{"home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_svm.parse_args": [[35, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.flask.train.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"SVM built using TensorFlow, for Wisconsin Breast Cancer Diagnostic Dataset\"", "\n", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "\"Arguments\"", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-c\"", ",", "\"--svm_c\"", ",", "required", "=", "True", ",", "type", "=", "int", ",", "help", "=", "\"Penalty parameter C of the SVM\"", "\n", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-n\"", ",", "\"--num_epochs\"", ",", "required", "=", "True", ",", "type", "=", "int", ",", "help", "=", "\"number of epochs\"", "\n", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-l\"", ",", "\n", "\"--log_path\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"path where to save the TensorBoard logs\"", ",", "\n", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-r\"", ",", "\n", "\"--result_path\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"path where to save the NumPy array consisting of the actual and predicted labels\"", ",", "\n", ")", "\n", "arguments", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "arguments", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_svm.main": [[64, 123], ["sklearn.preprocessing.StandardScaler().fit_transform", "sklearn.model_selection.train_test_split", "models.svm.SVM", "models.svm.SVM.train", "utils.plot_confusion_matrix", "print", "print", "print", "print", "print", "sklearn.datasets.load_breast_cancer", "sklearn.datasets.load_breast_cancer", "sklearn.preprocessing.StandardScaler"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.train", "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.utils.plot_confusion_matrix"], ["", "def", "main", "(", "arguments", ")", ":", "\n", "# load the features of the dataset", "\n", "    ", "features", "=", "datasets", ".", "load_breast_cancer", "(", ")", ".", "data", "\n", "\n", "# standardize the features", "\n", "features", "=", "StandardScaler", "(", ")", ".", "fit_transform", "(", "features", ")", "\n", "\n", "# get the number of features", "\n", "num_features", "=", "features", ".", "shape", "[", "1", "]", "\n", "\n", "# load the corresponding labels for the features", "\n", "labels", "=", "datasets", ".", "load_breast_cancer", "(", ")", ".", "target", "\n", "\n", "# transform the labels to {-1, +1}", "\n", "labels", "[", "labels", "==", "0", "]", "=", "-", "1", "\n", "\n", "# split the dataset to 70/30 partition: 70% train, 30% test", "\n", "train_features", ",", "test_features", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.3", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", "\n", "\n", "# slice the dataset as per the batch size", "\n", "train_features", "=", "train_features", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "train_labels", "=", "train_labels", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "test_features", "=", "test_features", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "test_labels", "=", "test_labels", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "\n", "# instantiate the SVM class", "\n", "model", "=", "SVM", "(", "\n", "alpha", "=", "LEARNING_RATE", ",", "\n", "batch_size", "=", "BATCH_SIZE", ",", "\n", "svm_c", "=", "arguments", ".", "svm_c", ",", "\n", "num_classes", "=", "NUM_CLASSES", ",", "\n", "num_features", "=", "num_features", ",", "\n", ")", "\n", "\n", "# train the instantiated model", "\n", "model", ".", "train", "(", "\n", "epochs", "=", "arguments", ".", "num_epochs", ",", "\n", "log_path", "=", "arguments", ".", "log_path", ",", "\n", "train_data", "=", "[", "train_features", ",", "train_labels", "]", ",", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", ",", "\n", "validation_data", "=", "[", "test_features", ",", "test_labels", "]", ",", "\n", "validation_size", "=", "test_features", ".", "shape", "[", "0", "]", ",", "\n", "result_path", "=", "arguments", ".", "result_path", ",", "\n", ")", "\n", "\n", "test_conf", ",", "test_accuracy", "=", "utils", ".", "plot_confusion_matrix", "(", "\n", "phase", "=", "\"testing\"", ",", "path", "=", "arguments", ".", "result_path", ",", "class_names", "=", "[", "\"benign\"", ",", "\"malignant\"", "]", "\n", ")", "\n", "\n", "print", "(", "\"True negatives : {}\"", ".", "format", "(", "test_conf", "[", "0", "]", "[", "0", "]", ")", ")", "\n", "print", "(", "\"False negatives : {}\"", ".", "format", "(", "test_conf", "[", "1", "]", "[", "0", "]", ")", ")", "\n", "print", "(", "\"True positives : {}\"", ".", "format", "(", "test_conf", "[", "1", "]", "[", "1", "]", ")", ")", "\n", "print", "(", "\"False positives : {}\"", ".", "format", "(", "test_conf", "[", "0", "]", "[", "1", "]", ")", ")", "\n", "print", "(", "\"Testing accuracy : {}\"", ".", "format", "(", "test_accuracy", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_linear_regression.main": [[33, 82], ["sklearn.datasets.load_breast_cancer", "sklearn.preprocessing.StandardScaler().fit_transform", "sklearn.model_selection.train_test_split", "models.linear_regression.LinearRegression", "models.linear_regression.LinearRegression.train", "sklearn.preprocessing.StandardScaler"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.train"], ["def", "main", "(", ")", ":", "\n", "    ", "dataset", "=", "datasets", ".", "load_breast_cancer", "(", ")", "\n", "\n", "features", "=", "dataset", ".", "data", "\n", "\n", "features", "=", "StandardScaler", "(", ")", ".", "fit_transform", "(", "features", ")", "\n", "\n", "num_features", "=", "features", ".", "shape", "[", "1", "]", "\n", "\n", "labels", "=", "dataset", ".", "target", "\n", "\n", "train_features", ",", "test_features", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.3", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", "\n", "\n", "# slice the dataset to be exact as per the batch size", "\n", "# e.g. train_size = 1898322, batch_size = 256", "\n", "# [:1898322-(1898322%256)] = [:1898240]", "\n", "# 1898322 // 256 = 7415; 7415 * 256 = 1898240", "\n", "train_features", "=", "train_features", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "train_labels", "=", "train_labels", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "\n", "# modify the size of the dataset to be passed on model.train()", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", "\n", "\n", "# slice the dataset to be exact as per the batch size", "\n", "test_features", "=", "test_features", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "test_labels", "=", "test_labels", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", "\n", "\n", "model", "=", "LinearRegression", "(", "\n", "alpha", "=", "LEARNING_RATE", ",", "\n", "batch_size", "=", "BATCH_SIZE", ",", "\n", "num_classes", "=", "NUM_CLASSES", ",", "\n", "sequence_length", "=", "num_features", ",", "\n", ")", "\n", "\n", "model", ".", "train", "(", "\n", "epochs", "=", "3000", ",", "\n", "log_path", "=", "\"./log_path/linear_regression/\"", ",", "\n", "train_data", "=", "[", "train_features", ",", "train_labels", "]", ",", "\n", "train_size", "=", "train_size", ",", "\n", "validation_data", "=", "[", "test_features", ",", "test_labels", "]", ",", "\n", "validation_size", "=", "test_size", ",", "\n", "result_path", "=", "\"./results/linear_regression/\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_gru_svm.main": [[39, 95], ["sklearn.datasets.load_breast_cancer", "sklearn.preprocessing.StandardScaler().fit_transform", "sklearn.model_selection.train_test_split", "models.gru_svm.GruSvm", "models.gru_svm.GruSvm.train", "sklearn.preprocessing.StandardScaler"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.train"], ["def", "main", "(", ")", ":", "\n", "    ", "dataset", "=", "datasets", ".", "load_breast_cancer", "(", ")", "\n", "\n", "features", "=", "dataset", ".", "data", "\n", "\n", "features", "=", "StandardScaler", "(", ")", ".", "fit_transform", "(", "features", ")", "\n", "\n", "num_features", "=", "features", ".", "shape", "[", "1", "]", "\n", "\n", "labels", "=", "dataset", ".", "target", "\n", "\n", "labels", "[", "labels", "==", "0", "]", "=", "-", "1", "\n", "\n", "train_features", ",", "test_features", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.3", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", "\n", "\n", "# slice the dataset to be exact as per the batch size", "\n", "# e.g. train_size = 1898322, batch_size = 256", "\n", "# [:1898322-(1898322%256)] = [:1898240]", "\n", "# 1898322 // 256 = 7415; 7415 * 256 = 1898240", "\n", "train_features", "=", "train_features", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "train_labels", "=", "train_labels", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "\n", "# modify the size of the dataset to be passed on model.train()", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", "\n", "\n", "# slice the dataset to be exact as per the batch size", "\n", "test_features", "=", "test_features", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "test_labels", "=", "test_labels", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", "\n", "\n", "model", "=", "GruSvm", "(", "\n", "alpha", "=", "LEARNING_RATE", ",", "\n", "batch_size", "=", "BATCH_SIZE", ",", "\n", "cell_size", "=", "CELL_SIZE", ",", "\n", "dropout_rate", "=", "DROPOUT_RATE", ",", "\n", "num_classes", "=", "NUM_CLASSES", ",", "\n", "sequence_length", "=", "num_features", ",", "\n", "svm_c", "=", "SVM_C", ",", "\n", ")", "\n", "\n", "model", ".", "train", "(", "\n", "checkpoint_path", "=", "\"./checkpoint_path/gru_svm/\"", ",", "\n", "log_path", "=", "\"./log_path/gru_svm/\"", ",", "\n", "model_name", "=", "\"gru_svm\"", ",", "\n", "epochs", "=", "3000", ",", "\n", "train_data", "=", "[", "train_features", ",", "train_labels", "]", ",", "\n", "train_size", "=", "train_size", ",", "\n", "validation_data", "=", "[", "test_features", ",", "test_labels", "]", ",", "\n", "validation_size", "=", "test_size", ",", "\n", "result_path", "=", "\"./results\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_logistic_regression.main": [[33, 84], ["sklearn.datasets.load_breast_cancer", "sklearn.preprocessing.StandardScaler().fit_transform", "sklearn.model_selection.train_test_split", "models.logistic_regression.LogisticRegression", "models.logistic_regression.LogisticRegression.train", "sklearn.preprocessing.StandardScaler"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.train"], ["def", "main", "(", ")", ":", "\n", "    ", "dataset", "=", "datasets", ".", "load_breast_cancer", "(", ")", "\n", "\n", "features", "=", "dataset", ".", "data", "\n", "\n", "features", "=", "StandardScaler", "(", ")", ".", "fit_transform", "(", "features", ")", "\n", "\n", "num_features", "=", "features", ".", "shape", "[", "1", "]", "\n", "\n", "labels", "=", "dataset", ".", "target", "\n", "\n", "train_features", ",", "test_features", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.3", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", "\n", "\n", "# slice the dataset to be exact as per the batch size", "\n", "# e.g. train_size = 1898322, batch_size = 256", "\n", "# [:1898322-(1898322%256)] = [:1898240]", "\n", "# 1898322 // 256 = 7415; 7415 * 256 = 1898240", "\n", "train_features", "=", "train_features", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "train_labels", "=", "train_labels", "[", ":", "train_size", "-", "(", "train_size", "%", "BATCH_SIZE", ")", "]", "\n", "\n", "# modify the size of the dataset to be passed on model.train()", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", "\n", "\n", "# slice the dataset to be exact as per the batch size", "\n", "test_features", "=", "test_features", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "test_labels", "=", "test_labels", "[", ":", "test_size", "-", "(", "test_size", "%", "BATCH_SIZE", ")", "]", "\n", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", "\n", "\n", "model", "=", "LogisticRegression", "(", "\n", "alpha", "=", "LEARNING_RATE", ",", "\n", "batch_size", "=", "BATCH_SIZE", ",", "\n", "num_classes", "=", "NUM_CLASSES", ",", "\n", "sequence_length", "=", "num_features", ",", "\n", ")", "\n", "\n", "model", ".", "train", "(", "\n", "checkpoint_path", "=", "\"./checkpoint_path/logistic_regression/\"", ",", "\n", "log_path", "=", "\"./log_path/logistic_regression/\"", ",", "\n", "model_name", "=", "\"logistic_regression\"", ",", "\n", "epochs", "=", "3000", ",", "\n", "train_data", "=", "[", "train_features", ",", "train_labels", "]", ",", "\n", "train_size", "=", "train_size", ",", "\n", "validation_data", "=", "[", "test_features", ",", "test_labels", "]", ",", "\n", "validation_size", "=", "test_size", ",", "\n", "result_path", "=", "\"./results/logistic_regression/\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.grid_search.validate_model": [[32, 43], ["sklearn.model_selection.GridSearchCV", "sklearn.model_selection.GridSearchCV.fit", "sklearn.model_selection.GridSearchCV.score"], "function", ["None"], ["def", "validate_model", "(", "model", ",", "parameter_set", ",", "train_data", ",", "test_data", ")", ":", "\n", "    ", "clf", "=", "GridSearchCV", "(", "estimator", "=", "model", ",", "param_grid", "=", "parameter_set", ",", "n_jobs", "=", "3", ",", "cv", "=", "10", ")", "\n", "\n", "clf", ".", "fit", "(", "train_data", "[", "0", "]", ",", "train_data", "[", "1", "]", ")", "\n", "\n", "grid_scores", "=", "clf", ".", "grid_scores_", "\n", "best_score", "=", "clf", ".", "best_score_", "\n", "best_params", "=", "clf", ".", "best_params_", "\n", "test_score", "=", "clf", ".", "score", "(", "test_data", "[", "0", "]", ",", "test_data", "[", "1", "]", ")", "\n", "\n", "return", "grid_scores", ",", "best_score", ",", "best_params", ",", "test_score", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.grid_search.main": [[45, 93], ["sklearn.datasets.load_breast_cancer", "sklearn.model_selection.train_test_split", "sklearn.svm.LinearSVC", "grid_search.validate_model", "print", "print", "print", "print", "sklearn.neural_network.MLPClassifier", "grid_search.validate_model", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.grid_search.validate_model", "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.grid_search.validate_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "dataset", "=", "datasets", ".", "load_breast_cancer", "(", ")", "\n", "features", "=", "dataset", ".", "data", "\n", "labels", "=", "dataset", ".", "target", "\n", "\n", "train_features", ",", "test_features", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.3", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "parameter_set", "=", "{", "\n", "\"loss\"", ":", "(", "\"hinge\"", ",", "\"squared_hinge\"", ")", ",", "\n", "\"C\"", ":", "[", "1", ",", "10", ",", "100", ",", "1000", ",", "5", ",", "50", ",", "500", ",", "5000", "]", ",", "\n", "}", "\n", "\n", "model", "=", "LinearSVC", "(", ")", "\n", "grid_scores", ",", "best_score", ",", "best_params", ",", "test_score", "=", "validate_model", "(", "\n", "model", "=", "model", ",", "\n", "parameter_set", "=", "parameter_set", ",", "\n", "train_data", "=", "[", "train_features", ",", "train_labels", "]", ",", "\n", "test_data", "=", "[", "test_features", ",", "test_labels", "]", ",", "\n", ")", "\n", "\n", "print", "(", "grid_scores", ")", "\n", "print", "(", "\"SVM best score: {}\"", ".", "format", "(", "best_score", ")", ")", "\n", "print", "(", "\"SVM best params : {}\"", ".", "format", "(", "best_params", ")", ")", "\n", "print", "(", "\"SVM test score : {}\"", ".", "format", "(", "test_score", ")", ")", "\n", "\n", "parameter_set", "=", "{", "\n", "\"activation\"", ":", "[", "\"identity\"", ",", "\"logistic\"", ",", "\"tanh\"", ",", "\"relu\"", "]", ",", "\n", "\"solver\"", ":", "[", "\"sgd\"", ",", "\"adam\"", "]", ",", "\n", "\"batch_size\"", ":", "[", "16", ",", "32", ",", "64", ",", "128", "]", ",", "\n", "\"hidden_layer_sizes\"", ":", "[", "(", "16", ",", ")", ",", "(", "32", ",", ")", ",", "(", "64", ",", ")", ",", "(", "128", ",", ")", "]", ",", "\n", "\"learning_rate_init\"", ":", "[", "1e-1", ",", "1e-2", "]", ",", "\n", "}", "\n", "\n", "model", "=", "MLPClassifier", "(", ")", "\n", "\n", "grid_scores", ",", "best_score", ",", "best_params", ",", "test_score", "=", "validate_model", "(", "\n", "model", "=", "model", ",", "\n", "parameter_set", "=", "parameter_set", ",", "\n", "train_data", "=", "[", "train_features", ",", "train_labels", "]", ",", "\n", "test_data", "=", "[", "test_features", ",", "test_labels", "]", ",", "\n", ")", "\n", "\n", "print", "(", "grid_scores", ")", "\n", "print", "(", "\"MLP best score: {}\"", ".", "format", "(", "best_score", ")", ")", "\n", "print", "(", "\"MLP best params : {}\"", ".", "format", "(", "best_params", ")", ")", "\n", "print", "(", "\"MLP test score : {}\"", ".", "format", "(", "test_score", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_nearest_neighbor.main": [[30, 47], ["sklearn.datasets.load_breast_cancer", "sklearn.preprocessing.StandardScaler().fit_transform", "sklearn.model_selection.train_test_split", "models.nearest_neighbor.NearestNeighbor", "models.nearest_neighbor.NearestNeighbor.predict", "sklearn.preprocessing.StandardScaler"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.nearest_neighbor.NearestNeighbor.predict"], ["def", "main", "(", ")", ":", "\n", "    ", "dataset", "=", "datasets", ".", "load_breast_cancer", "(", ")", "\n", "\n", "features", "=", "dataset", ".", "data", "\n", "labels", "=", "dataset", ".", "target", "\n", "\n", "num_features", "=", "features", ".", "shape", "[", "1", "]", "\n", "\n", "features", "=", "StandardScaler", "(", ")", ".", "fit_transform", "(", "features", ")", "\n", "\n", "train_features", ",", "test_features", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.3", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "model", "=", "NearestNeighbor", "(", "train_features", ",", "train_labels", ",", "num_features", ")", "\n", "\n", "model", ".", "predict", "(", "test_features", ",", "test_labels", ",", "result_path", "=", "\"./results/nearest_neighbor/\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.utils.list_files": [[31, 55], ["os.walk", "file_list.extend", "os.path.join"], "function", ["None"], ["def", "list_files", "(", "path", ")", ":", "\n", "    ", "\"\"\"Returns a list of files\n\n    Parameter\n    ---------\n    path : str\n      A string consisting of a path containing files.\n\n    Returns\n    -------\n    file_list : list\n      A list of the files present in the given directory\n\n    Examples\n    --------\n    >>> PATH = '/home/data'\n    >>> list_files(PATH)\n    >>> ['/home/data/file1', '/home/data/file2', '/home/data/file3']\n    \"\"\"", "\n", "\n", "file_list", "=", "[", "]", "\n", "for", "(", "dir_path", ",", "dir_names", ",", "file_names", ")", "in", "os", ".", "walk", "(", "path", ")", ":", "\n", "        ", "file_list", ".", "extend", "(", "os", ".", "path", ".", "join", "(", "dir_path", ",", "filename", ")", "for", "filename", "in", "file_names", ")", "\n", "", "return", "file_list", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.utils.plot_confusion_matrix": [[57, 138], ["utils.list_files", "numpy.array", "numpy.reshape", "print", "sklearn.metrics.confusion_matrix", "matplotlib.imshow", "matplotlib.title", "matplotlib.colorbar", "numpy.arange", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.tight_layout", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.show", "numpy.load", "numpy.append", "tensorflow.Session", "sess.run", "sess.run", "len", "print", "tensorflow.argmax", "tensorflow.argmax", "list_files.index", "list_files.__len__", "list_files.__len__", "list_files.index", "list_files.__len__"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.utils.list_files"], ["", "def", "plot_confusion_matrix", "(", "phase", ",", "path", ",", "class_names", ")", ":", "\n", "    ", "\"\"\"Plots the confusion matrix using matplotlib.\n\n    Parameter\n    ---------\n    phase : str\n      String value indicating for what phase is the confusion matrix, i.e. training/validation/testing\n    path : str\n      Directory where the predicted and actual label NPY files reside\n    class_names : str\n      List consisting of the class names for the labels\n\n    Returns\n    -------\n    conf : array, shape = [num_classes, num_classes]\n      Confusion matrix\n    accuracy : float\n      Predictive accuracy\n    \"\"\"", "\n", "\n", "# list all the results files", "\n", "files", "=", "list_files", "(", "path", "=", "path", ")", "\n", "\n", "labels", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "for", "file", "in", "files", ":", "\n", "        ", "labels_batch", "=", "np", ".", "load", "(", "file", ")", "\n", "labels", "=", "np", ".", "append", "(", "labels", ",", "labels_batch", ")", "\n", "\n", "if", "(", "files", ".", "index", "(", "file", ")", "/", "files", ".", "__len__", "(", ")", ")", "%", "0.2", "==", "0", ":", "\n", "            ", "print", "(", "\n", "\"Done appending {}% of {}\"", ".", "format", "(", "\n", "(", "files", ".", "index", "(", "file", ")", "/", "files", ".", "__len__", "(", ")", ")", "*", "100", ",", "files", ".", "__len__", "(", ")", "\n", ")", "\n", ")", "\n", "\n", "", "", "labels", "=", "np", ".", "reshape", "(", "labels", ",", "newshape", "=", "(", "labels", ".", "shape", "[", "0", "]", "//", "4", ",", "4", ")", ")", "\n", "\n", "print", "(", "\"Done appending NPY files.\"", ")", "\n", "\n", "# get the predicted labels", "\n", "predictions", "=", "labels", "[", ":", ",", ":", "2", "]", "\n", "\n", "# get the actual labels", "\n", "actual", "=", "labels", "[", ":", ",", "2", ":", "]", "\n", "\n", "# create a TensorFlow session", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "\n", "# decode the one-hot encoded labels to single integer", "\n", "        ", "predictions", "=", "sess", ".", "run", "(", "tf", ".", "argmax", "(", "predictions", ",", "1", ")", ")", "\n", "actual", "=", "sess", ".", "run", "(", "tf", ".", "argmax", "(", "actual", ",", "1", ")", ")", "\n", "\n", "# get the confusion matrix based on the actual and predicted labels", "\n", "", "conf", "=", "confusion_matrix", "(", "y_true", "=", "actual", ",", "y_pred", "=", "predictions", ")", "\n", "\n", "# create a confusion matrix plot", "\n", "plt", ".", "imshow", "(", "conf", ",", "cmap", "=", "plt", ".", "cm", ".", "Purples", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "\n", "# set the plot title", "\n", "plt", ".", "title", "(", "\"Confusion Matrix for {} Phase\"", ".", "format", "(", "phase", ")", ")", "\n", "\n", "# legend of intensity for the plot", "\n", "plt", ".", "colorbar", "(", ")", "\n", "\n", "tick_marks", "=", "np", ".", "arange", "(", "len", "(", "class_names", ")", ")", "\n", "plt", ".", "xticks", "(", "tick_marks", ",", "class_names", ",", "rotation", "=", "45", ")", "\n", "plt", ".", "yticks", "(", "tick_marks", ",", "class_names", ")", "\n", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "ylabel", "(", "\"Actual label\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Predicted label\"", ")", "\n", "\n", "# show the plot", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "# get the accuracy of the phase", "\n", "accuracy", "=", "(", "conf", "[", "0", "]", "[", "0", "]", "+", "conf", "[", "1", "]", "[", "1", "]", ")", "/", "labels", ".", "shape", "[", "0", "]", "\n", "\n", "# return the confusion matrix and the accuracy", "\n", "return", "conf", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.utils.get_statistical_measures": [[140, 166], ["numpy.array"], "function", ["None"], ["", "def", "get_statistical_measures", "(", "conf_matrix", ")", ":", "\n", "    ", "\"\"\"Returns an array of statistical measures\n\n    Parameter\n    ---------\n    conf_matrix : array\n      The confusion matrix\n\n    Returns\n    -------\n    statistical_measures : numpy.ndarray\n      The NumPy array containing the statistical measures\n    \"\"\"", "\n", "true_positive_rate", "=", "conf_matrix", "[", "1", "]", "[", "1", "]", "/", "(", "conf_matrix", "[", "1", "]", "[", "1", "]", "+", "conf_matrix", "[", "1", "]", "[", "0", "]", ")", "\n", "true_negative_rate", "=", "conf_matrix", "[", "0", "]", "[", "0", "]", "/", "(", "conf_matrix", "[", "0", "]", "[", "0", "]", "+", "conf_matrix", "[", "0", "]", "[", "1", "]", ")", "\n", "false_positive_rate", "=", "1", "-", "true_negative_rate", "\n", "false_negative_rate", "=", "1", "-", "true_positive_rate", "\n", "statistical_measures", "=", "np", ".", "array", "(", "\n", "[", "\n", "true_negative_rate", ",", "\n", "true_positive_rate", ",", "\n", "false_negative_rate", ",", "\n", "false_positive_rate", ",", "\n", "]", "\n", ")", "\n", "return", "statistical_measures", "\n", "", ""]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_mlp.parse_args": [[36, 60], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.flask.train.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"MLP written using TensorFlow, for Wisconsin Breast Cancer Diagnostic Dataset\"", "\n", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "\"Arguments\"", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-n\"", ",", "\"--num_epochs\"", ",", "required", "=", "True", ",", "type", "=", "int", ",", "help", "=", "\"number of epochs\"", "\n", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-l\"", ",", "\n", "\"--log_path\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"path where to save the TensorBoard logs\"", ",", "\n", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-r\"", ",", "\n", "\"--result_path\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"path where to save actual and predicted labels array\"", ",", "\n", ")", "\n", "arguments", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "arguments", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.None.main_mlp.main": [[62, 95], ["sklearn.preprocessing.StandardScaler().fit_transform", "sklearn.model_selection.train_test_split", "models.MLP.MLP", "models.MLP.MLP.train", "sklearn.datasets.load_breast_cancer", "sklearn.datasets.load_breast_cancer", "sklearn.preprocessing.StandardScaler"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.train"], ["", "def", "main", "(", "arguments", ")", ":", "\n", "# load the features of the dataset", "\n", "    ", "features", "=", "datasets", ".", "load_breast_cancer", "(", ")", ".", "data", "\n", "\n", "# standardize the features", "\n", "features", "=", "StandardScaler", "(", ")", ".", "fit_transform", "(", "features", ")", "\n", "\n", "# get the number of features", "\n", "num_features", "=", "features", ".", "shape", "[", "1", "]", "\n", "\n", "# load the labels for the features", "\n", "labels", "=", "datasets", ".", "load_breast_cancer", "(", ")", ".", "target", "\n", "\n", "train_features", ",", "test_features", ",", "train_labels", ",", "test_labels", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.30", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "model", "=", "MLP", "(", "\n", "alpha", "=", "LEARNING_RATE", ",", "\n", "batch_size", "=", "BATCH_SIZE", ",", "\n", "node_size", "=", "NUM_NODES", ",", "\n", "num_classes", "=", "NUM_CLASSES", ",", "\n", "num_features", "=", "num_features", ",", "\n", ")", "\n", "\n", "model", ".", "train", "(", "\n", "num_epochs", "=", "arguments", ".", "num_epochs", ",", "\n", "log_path", "=", "arguments", ".", "log_path", ",", "\n", "train_data", "=", "[", "train_features", ",", "train_labels", "]", ",", "\n", "train_size", "=", "train_features", ".", "shape", "[", "0", "]", ",", "\n", "test_data", "=", "[", "test_features", ",", "test_labels", "]", ",", "\n", "test_size", "=", "test_features", ".", "shape", "[", "0", "]", ",", "\n", "result_path", "=", "arguments", ".", "result_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.nearest_neighbor.NearestNeighbor.__init__": [[36, 59], ["tensorflow.sqrt", "tensorflow.arg_min", "tensorflow.name_scope", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.reduce_sum", "tensorflow.square"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "train_features", ",", "train_labels", ",", "sequence_length", ")", ":", "\n", "        ", "self", ".", "train_features", "=", "train_features", "\n", "self", ".", "train_labels", "=", "train_labels", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "            ", "xtr", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "sequence_length", "]", ")", "\n", "xte", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "sequence_length", "]", ")", "\n", "\n", "# L1-Norm", "\n", "# distance = tf.reduce_sum(tf.abs(tf.add(xtr, tf.negative(xte))), reduction_indices=1)", "\n", "\n", "# L2-Norm", "\n", "", "distance", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "xtr", "-", "xte", ")", ",", "reduction_indices", "=", "1", ")", ")", "\n", "\n", "prediction", "=", "tf", ".", "arg_min", "(", "distance", ",", "0", ")", "\n", "\n", "accuracy", "=", "0.0", "\n", "\n", "self", ".", "xtr", "=", "xtr", "\n", "self", ".", "xte", "=", "xte", "\n", "self", ".", "distance", "=", "distance", "\n", "self", ".", "prediction", "=", "prediction", "\n", "self", ".", "accuracy", "=", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.nearest_neighbor.NearestNeighbor.predict": [[60, 103], ["tensorflow.one_hot", "tensorflow.one_hot", "tensorflow.global_variables_initializer", "print", "tensorflow.Session", "sess.run", "sess.run", "range", "len", "sess.run", "print", "nearest_neighbor.NearestNeighbor.save_labels", "numpy.argmax", "numpy.argmax", "numpy.argmax", "numpy.argmax", "numpy.argmax", "numpy.argmax", "len"], "methods", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels"], ["", "def", "predict", "(", "self", ",", "test_features", ",", "test_labels", ",", "result_path", ")", ":", "\n", "\n", "        ", "train_labels", "=", "tf", ".", "one_hot", "(", "self", ".", "train_labels", ",", "depth", "=", "2", ",", "on_value", "=", "1", ",", "off_value", "=", "0", ")", "\n", "test_labels", "=", "tf", ".", "one_hot", "(", "test_labels", ",", "depth", "=", "2", ",", "on_value", "=", "1", ",", "off_value", "=", "0", ")", "\n", "\n", "init", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "# Start training", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "\n", "# Run the initializer", "\n", "            ", "sess", ".", "run", "(", "init", ")", "\n", "\n", "y_", ",", "y", "=", "sess", ".", "run", "(", "[", "test_labels", ",", "train_labels", "]", ")", "\n", "\n", "# loop over test data", "\n", "for", "index", "in", "range", "(", "len", "(", "test_features", ")", ")", ":", "\n", "\n", "                ", "feed_dict", "=", "{", "\n", "self", ".", "xtr", ":", "self", ".", "train_features", ",", "\n", "self", ".", "xte", ":", "test_features", "[", "index", ",", ":", "]", ",", "\n", "}", "\n", "\n", "nn_index", "=", "sess", ".", "run", "(", "self", ".", "prediction", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "print", "(", "\n", "\"Test [{}] Actual Class: {}, Predicted Class : {}\"", ".", "format", "(", "\n", "index", ",", "np", ".", "argmax", "(", "y_", "[", "index", "]", ")", ",", "np", ".", "argmax", "(", "y", "[", "nn_index", "]", ")", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "save_labels", "(", "\n", "predictions", "=", "np", ".", "argmax", "(", "y", "[", "nn_index", "]", ")", ",", "\n", "actual", "=", "np", ".", "argmax", "(", "y_", "[", "index", "]", ")", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "index", ",", "\n", "phase", "=", "\"testing\"", ",", "\n", ")", "\n", "\n", "if", "np", ".", "argmax", "(", "y", "[", "nn_index", "]", ")", "==", "np", ".", "argmax", "(", "y_", "[", "index", "]", ")", ":", "\n", "                    ", "self", ".", "accuracy", "+=", "1.0", "/", "len", "(", "test_features", ")", "\n", "\n", "", "", "", "print", "(", "\"Accuracy : {}\"", ".", "format", "(", "self", ".", "accuracy", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.nearest_neighbor.NearestNeighbor.save_labels": [[104, 134], ["numpy.array", "numpy.save", "os.path.exists", "os.mkdir", "os.path.join"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "save_labels", "(", "predictions", ",", "actual", ",", "result_path", ",", "step", ",", "phase", ")", ":", "\n", "        ", "\"\"\"Saves the actual and predicted labels to a NPY file\n\n        Parameter\n        ---------\n        predictions : int\n          The predicted label.\n        actual : int\n          The actual label.\n        result_path : str\n          The path where to save the concatenated actual and predicted labels.\n        step : int\n          The time step for the predicted and actual labels\n        phase : str\n          The phase for which the prediction is, i.e. training/validation/testing.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "result_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "result_path", ")", "\n", "\n", "# Concatenate the predicted and actual labels", "\n", "", "labels", "=", "np", ".", "array", "(", "[", "predictions", ",", "actual", "]", ")", "\n", "\n", "# save the labels array to NPY file", "\n", "np", ".", "save", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "\n", "result_path", ",", "\"{}-nearest_neighbor-{}.npy\"", ".", "format", "(", "phase", ",", "step", ")", "\n", ")", ",", "\n", "arr", "=", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.linear_regression.LinearRegression.__init__": [[34, 122], ["sys.stdout.write", "linear_regression.LinearRegression.__init__.__graph__"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "batch_size", ",", "num_classes", ",", "sequence_length", ")", ":", "\n", "        ", "\"\"\"Initialize the Linear Regression class\n\n        Parameter\n        ---------\n        alpha : float\n          The learning rate for the Linear Regression model.\n        batch_size : int\n          The number of batches to use for training/validation/testing.\n        num_classes : int\n          The number of classes in a dataset.\n        sequence_length : int\n          The number of features in a dataset.\n        \"\"\"", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "sequence_length", "=", "sequence_length", "\n", "\n", "def", "__graph__", "(", ")", ":", "\n", "\n", "            ", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "# [BATCH_SIZE, SEQUENCE_LENGTH]", "\n", "                ", "x_input", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "sequence_length", "]", ",", "name", "=", "\"x_input\"", "\n", ")", "\n", "\n", "# [BATCH_SIZE]", "\n", "y_input", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "uint8", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"y_input\"", ")", "\n", "\n", "# [BATCH_SIZE, NUM_CLASSES]", "\n", "y_onehot", "=", "tf", ".", "one_hot", "(", "\n", "indices", "=", "y_input", ",", "\n", "depth", "=", "self", ".", "num_classes", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "name", "=", "\"y_onehot\"", ",", "\n", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"training_ops\"", ")", ":", "\n", "                ", "with", "tf", ".", "name_scope", "(", "\"weights\"", ")", ":", "\n", "                    ", "weight", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "zeros", "(", "[", "self", ".", "sequence_length", ",", "self", ".", "num_classes", "]", ")", ",", "\n", "name", "=", "\"weight\"", ",", "\n", ")", "\n", "self", ".", "variable_summaries", "(", "weight", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"biases\"", ")", ":", "\n", "                    ", "bias", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "self", ".", "num_classes", "]", ")", ",", "name", "=", "\"bias\"", ")", "\n", "self", ".", "variable_summaries", "(", "bias", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"decision_function\"", ")", ":", "\n", "                    ", "output", "=", "tf", ".", "matmul", "(", "x_input", ",", "weight", ")", "+", "bias", "\n", "output", "=", "tf", ".", "identity", "(", "output", ",", "name", "=", "\"output\"", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"output\"", ",", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"mean_squared_loss\"", ")", ":", "\n", "                ", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "output", "-", "y_onehot", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "loss", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "alpha", ")", ".", "minimize", "(", "\n", "loss", "\n", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                ", "predicted_class", "=", "self", ".", "discretize", "(", "output", ")", "\n", "predicted_class", "=", "tf", ".", "identity", "(", "predicted_class", ",", "name", "=", "\"prediction\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"correct_prediction\"", ")", ":", "\n", "                    ", "correct", "=", "tf", ".", "equal", "(", "\n", "tf", ".", "argmax", "(", "predicted_class", ",", "1", ")", ",", "tf", ".", "argmax", "(", "y_onehot", ",", "1", ")", "\n", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                    ", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct", ",", "\"float\"", ")", ")", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\"accuracy\"", ",", "accuracy", ")", "\n", "\n", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "self", ".", "x_input", "=", "x_input", "\n", "self", ".", "y_input", "=", "y_input", "\n", "self", ".", "y_onehot", "=", "y_onehot", "\n", "self", ".", "output", "=", "output", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "train_op", "=", "train_op", "\n", "self", ".", "predicted_class", "=", "predicted_class", "\n", "self", ".", "accuracy", "=", "accuracy", "\n", "self", ".", "merged", "=", "merged", "\n", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n<log> Building graph...\"", ")", "\n", "__graph__", "(", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"</log>\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.linear_regression.LinearRegression.train": [[123, 260], ["tensorflow.group", "str", "tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "time.asctime", "os.path.join", "os.path.join", "tensorflow.Session", "sess.run", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "range", "print", "range", "print", "sess.run", "linear_regression.LinearRegression.save_labels", "print", "os._exit", "sess.run", "linear_regression.LinearRegression.save_labels", "sess.run", "print", "tensorflow.summary.FileWriter.add_summary", "sess.run", "print", "tensorflow.summary.FileWriter.add_summary"], "methods", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels", "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels"], ["", "def", "train", "(", "\n", "self", ",", "\n", "epochs", ",", "\n", "log_path", ",", "\n", "train_data", ",", "\n", "train_size", ",", "\n", "validation_data", ",", "\n", "validation_size", ",", "\n", "result_path", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Trains the Linear Regression model\n\n        Parameter\n        ---------\n        epochs : int\n          The number of passes through the entire dataset.\n        log_path : str\n          The directory where to save the TensorBoard logs.\n        train_data : numpy.ndarray\n          The numpy.ndarray to be used as the training dataset.\n        train_size : int\n          The number of data in `train_data`.\n        validation_data : numpy.ndarray\n          The numpy.ndarray to be used as the validation dataset.\n        validation_size : int\n          The number of data in `validation_data`.\n        result_path : str\n          The path where to save the NPY files consisting of the actual and predicted labels.\n        \"\"\"", "\n", "\n", "init_op", "=", "tf", ".", "group", "(", "\n", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "local_variables_initializer", "(", ")", "\n", ")", "\n", "\n", "timestamp", "=", "str", "(", "time", ".", "asctime", "(", ")", ")", "\n", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "log_path", ",", "timestamp", "+", "\"-training\"", ")", ",", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ",", "\n", ")", "\n", "test_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "log_path", ",", "timestamp", "+", "\"-testing\"", ")", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "try", ":", "\n", "                ", "for", "step", "in", "range", "(", "epochs", "*", "train_size", "//", "self", ".", "batch_size", ")", ":", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "train_size", "\n", "batch_train_data", "=", "train_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "batch_train_labels", "=", "train_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "batch_train_data", ",", "\n", "self", ".", "y_input", ":", "batch_train_labels", ",", "\n", "}", "\n", "\n", "summary", ",", "_", ",", "step_loss", ",", "predicted", ",", "actual", "=", "sess", ".", "run", "(", "\n", "[", "\n", "self", ".", "merged", ",", "\n", "self", ".", "train_op", ",", "\n", "self", ".", "loss", ",", "\n", "self", ".", "predicted_class", ",", "\n", "self", ".", "y_onehot", ",", "\n", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "\n", "if", "step", "%", "100", "==", "0", ":", "\n", "                        ", "train_accuracy", "=", "sess", ".", "run", "(", "self", ".", "accuracy", ",", "feed_dict", "=", "feed_dict", ")", "\n", "print", "(", "\n", "\"step [{}] train -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "step_loss", ",", "train_accuracy", "\n", ")", "\n", ")", "\n", "train_writer", ".", "add_summary", "(", "summary", "=", "summary", ",", "global_step", "=", "step", ")", "\n", "\n", "", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predicted", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "step", ",", "\n", "phase", "=", "\"training\"", ",", "\n", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "print", "(", "\"Training interrupted at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "os", ".", "_exit", "(", "1", ")", "\n", "", "finally", ":", "\n", "                ", "print", "(", "\"EOF -- training done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "for", "step", "in", "range", "(", "epochs", "*", "validation_size", "//", "self", ".", "batch_size", ")", ":", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "validation_size", "\n", "test_example_batch", "=", "validation_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "test_label_batch", "=", "validation_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "test_example_batch", ",", "\n", "self", ".", "y_input", ":", "test_label_batch", ",", "\n", "}", "\n", "\n", "test_summary", ",", "predicted", ",", "actual", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "merged", ",", "self", ".", "predicted_class", ",", "self", ".", "y_onehot", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "\n", "if", "step", "%", "100", "==", "0", "and", "step", ">", "0", ":", "\n", "                        ", "test_accuracy", ",", "test_loss", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "accuracy", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "print", "(", "\n", "\"step [{}] testing --- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "test_loss", ",", "test_accuracy", "\n", ")", "\n", ")", "\n", "\n", "test_writer", ".", "add_summary", "(", "summary", "=", "test_summary", ",", "global_step", "=", "step", ")", "\n", "\n", "", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predicted", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "step", ",", "\n", "phase", "=", "\"testing\"", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"EOF -- testing done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.linear_regression.LinearRegression.variable_summaries": [[261, 272], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.name_scope", "tensorflow.sqrt", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.reduce_mean", "tensorflow.square"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "variable_summaries", "(", "var", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"summaries\"", ")", ":", "\n", "            ", "mean", "=", "tf", ".", "reduce_mean", "(", "var", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"mean\"", ",", "mean", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"stddev\"", ")", ":", "\n", "                ", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "var", "-", "mean", ")", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"stddev\"", ",", "stddev", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"max\"", ",", "tf", ".", "reduce_max", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"min\"", ",", "tf", ".", "reduce_min", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"histogram\"", ",", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.linear_regression.LinearRegression.save_labels": [[273, 303], ["numpy.concatenate", "numpy.save", "os.path.exists", "os.mkdir", "os.path.join"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "save_labels", "(", "predictions", ",", "actual", ",", "result_path", ",", "step", ",", "phase", ")", ":", "\n", "        ", "\"\"\"Saves the actual and predicted labels to a NPY file\n\n        Parameter\n        ---------\n        predictions : numpy.ndarray\n          The NumPy array containing the predicted labels.\n        actual : numpy.ndarray\n          The NumPy array containing the actual labels.\n        result_path : str\n          The path where to save the concatenated actual and predicted labels.\n        step : int\n          The time step for the NumPy arrays.\n        phase : str\n          The phase for which the predictions is, i.e. training/validation/testing.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "result_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "result_path", ")", "\n", "\n", "# Concatenate the predicted and actual labels", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "(", "predictions", ",", "actual", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# save the labels array to NPY file", "\n", "np", ".", "save", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "\n", "result_path", ",", "\"{}-linear_regression-{}.npy\"", ".", "format", "(", "phase", ",", "step", ")", "\n", ")", ",", "\n", "arr", "=", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.linear_regression.LinearRegression.discretize": [[305, 323], ["tensorflow.cast"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "discretize", "(", "output", ")", ":", "\n", "        ", "\"\"\"Discretizes the predicted classes to [0, 1]\n\n        Parameter\n        ---------\n        output : numpy.ndarray\n          The NumPy array containing the predicted classes\n\n        Returns\n        -------\n        output : numpy.ndarray\n          The discretized predicted classes.\n        \"\"\"", "\n", "\n", "output", "=", "output", ">=", "0.5", "\n", "output", "=", "tf", ".", "cast", "(", "output", ",", "\"float\"", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.svm.SVM.__init__": [[33, 142], ["sys.stdout.write", "svm.SVM.__init__.__graph__"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "batch_size", ",", "svm_c", ",", "num_classes", ",", "num_features", ")", ":", "\n", "        ", "\"\"\"Initialize the SVM class\n\n        Parameter\n        ---------\n        alpha : float\n          The learning rate for the SVM model.\n        batch_size : int\n          Number of batches to use for training and testing.\n        svm_c : float\n          The SVM penalty parameter.\n        num_classes : int\n          Number of classes in a dataset.\n        num_features : int\n          Number of features in a dataset.\n        \"\"\"", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "svm_c", "=", "svm_c", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "num_features", "\n", "\n", "def", "__graph__", "(", ")", ":", "\n", "            ", "\"\"\"Building the inference graph\"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "# [BATCH_SIZE, NUM_FEATURES]", "\n", "                ", "x_input", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "num_features", "]", ",", "name", "=", "\"x_input\"", "\n", ")", "\n", "\n", "# [BATCH_SIZE]", "\n", "y_input", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "uint8", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"y_input\"", ")", "\n", "\n", "# [BATCH_SIZE, NUM_CLASSES]", "\n", "y_onehot", "=", "tf", ".", "one_hot", "(", "\n", "indices", "=", "y_input", ",", "\n", "depth", "=", "self", ".", "num_classes", ",", "\n", "on_value", "=", "1", ",", "\n", "off_value", "=", "-", "1", ",", "\n", "name", "=", "\"y_onehot\"", ",", "\n", ")", "\n", "\n", "", "learning_rate", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"learning_rate\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"training_ops\"", ")", ":", "\n", "                ", "with", "tf", ".", "name_scope", "(", "\"weights\"", ")", ":", "\n", "                    ", "weight", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "\"weights\"", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "\n", "[", "self", ".", "num_features", ",", "self", ".", "num_classes", "]", ",", "stddev", "=", "0.01", "\n", ")", ",", "\n", ")", "\n", "self", ".", "variable_summaries", "(", "weight", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"biases\"", ")", ":", "\n", "                    ", "bias", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "\"biases\"", ",", "\n", "initializer", "=", "tf", ".", "constant", "(", "[", "0.1", "]", ",", "shape", "=", "[", "self", ".", "num_classes", "]", ")", ",", "\n", ")", "\n", "self", ".", "variable_summaries", "(", "bias", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"Wx_plus_b\"", ")", ":", "\n", "                    ", "output", "=", "tf", ".", "matmul", "(", "x_input", ",", "weight", ")", "+", "bias", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"pre-activations\"", ",", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"svm\"", ")", ":", "\n", "                ", "regularization", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "weight", ")", ")", "\n", "hinge_loss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "square", "(", "\n", "tf", ".", "maximum", "(", "\n", "tf", ".", "zeros", "(", "[", "self", ".", "batch_size", ",", "self", ".", "num_classes", "]", ")", ",", "\n", "1", "-", "tf", ".", "cast", "(", "y_onehot", ",", "tf", ".", "float32", ")", "*", "output", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"loss\"", ")", ":", "\n", "                    ", "loss", "=", "regularization", "+", "self", ".", "svm_c", "*", "hinge_loss", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "loss", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ")", ".", "minimize", "(", "\n", "loss", "\n", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                ", "predicted_class", "=", "tf", ".", "sign", "(", "output", ")", "\n", "predicted_class", "=", "tf", ".", "identity", "(", "predicted_class", ",", "name", "=", "\"prediction\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"correct_prediction\"", ")", ":", "\n", "                    ", "correct", "=", "tf", ".", "equal", "(", "\n", "tf", ".", "argmax", "(", "predicted_class", ",", "1", ")", ",", "tf", ".", "argmax", "(", "y_onehot", ",", "1", ")", "\n", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                    ", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct", ",", "\"float\"", ")", ")", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\"accuracy\"", ",", "accuracy", ")", "\n", "\n", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "self", ".", "x_input", "=", "x_input", "\n", "self", ".", "y_input", "=", "y_input", "\n", "self", ".", "y_onehot", "=", "y_onehot", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "output", "=", "output", "\n", "self", ".", "predicted_class", "=", "predicted_class", "\n", "self", ".", "accuracy", "=", "accuracy", "\n", "self", ".", "merged", "=", "merged", "\n", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n<log> Building graph...\"", ")", "\n", "__graph__", "(", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"</log>\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.svm.SVM.train": [[143, 268], ["tensorflow.group", "str", "tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "time.asctime", "os.path.join", "tensorflow.Session", "sess.run", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "range", "print", "range", "print", "sess.run", "print", "os._exit", "sess.run", "svm.SVM.save_labels", "sess.run", "print", "tensorflow.summary.FileWriter.add_summary", "print", "tensorflow.summary.FileWriter.add_summary"], "methods", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels"], ["", "def", "train", "(", "\n", "self", ",", "\n", "epochs", ",", "\n", "log_path", ",", "\n", "train_data", ",", "\n", "train_size", ",", "\n", "validation_data", ",", "\n", "validation_size", ",", "\n", "result_path", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Trains the SVM model\n\n        Parameter\n        ---------\n        epochs : int\n          The number of passes through the entire dataset.\n        log_path : str\n          The directory where to save the TensorBoard logs.\n        train_data : numpy.ndarray\n          The numpy.ndarray to be used as the training dataset.\n        train_size : int\n          The number of data in `train_data`.\n        validation_data : numpy.ndarray\n          The numpy.ndarray to be used as the validation dataset.\n        validation_size : int\n          The number of data in `validation_data`.\n        result_path : str\n          The path where to save the NPY files consisting of the actual and predicted labels.\n        \"\"\"", "\n", "\n", "# initialize the variables", "\n", "init_op", "=", "tf", ".", "group", "(", "\n", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "local_variables_initializer", "(", ")", "\n", ")", "\n", "\n", "# get the current time and date", "\n", "timestamp", "=", "str", "(", "time", ".", "asctime", "(", ")", ")", "\n", "\n", "# event files to contain the TensorBoard log", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "log_path", "+", "timestamp", "+", "\"-training\"", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "test_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "log_path", ",", "timestamp", "+", "\"-testing\"", ")", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "try", ":", "\n", "                ", "for", "step", "in", "range", "(", "epochs", "*", "train_size", "//", "self", ".", "batch_size", ")", ":", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "train_size", "\n", "batch_train_data", "=", "train_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "batch_train_labels", "=", "train_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "batch_train_data", ",", "\n", "self", ".", "y_input", ":", "batch_train_labels", ",", "\n", "self", ".", "learning_rate", ":", "self", ".", "alpha", ",", "\n", "}", "\n", "\n", "summary", ",", "_", ",", "step_loss", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "merged", ",", "self", ".", "optimizer", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "if", "step", "%", "100", "==", "0", ":", "\n", "                        ", "train_accuracy", "=", "sess", ".", "run", "(", "self", ".", "accuracy", ",", "feed_dict", "=", "feed_dict", ")", "\n", "print", "(", "\n", "\"step[{}] train -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "step_loss", ",", "train_accuracy", "\n", ")", "\n", ")", "\n", "train_writer", ".", "add_summary", "(", "summary", "=", "summary", ",", "global_step", "=", "step", ")", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "print", "(", "\"Training interrupted at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "os", ".", "_exit", "(", "1", ")", "\n", "", "finally", ":", "\n", "                ", "print", "(", "\"EOF -- training done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "for", "step", "in", "range", "(", "epochs", "*", "validation_size", "//", "self", ".", "batch_size", ")", ":", "\n", "\n", "                    ", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "validation_data", "[", "0", "]", "[", ":", "self", ".", "batch_size", "]", ",", "\n", "self", ".", "y_input", ":", "validation_data", "[", "1", "]", "[", ":", "self", ".", "batch_size", "]", ",", "\n", "}", "\n", "\n", "(", "\n", "validation_summary", ",", "\n", "predictions", ",", "\n", "actual", ",", "\n", "validation_loss", ",", "\n", "validation_accuracy", ",", "\n", ")", "=", "sess", ".", "run", "(", "\n", "[", "\n", "self", ".", "merged", ",", "\n", "self", ".", "predicted_class", ",", "\n", "self", ".", "y_onehot", ",", "\n", "self", ".", "loss", ",", "\n", "self", ".", "accuracy", ",", "\n", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "\n", "if", "step", "%", "100", "==", "0", "and", "step", ">", "0", ":", "\n", "                        ", "print", "(", "\n", "\"step [{}] validation -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "validation_loss", ",", "validation_accuracy", "\n", ")", "\n", ")", "\n", "test_writer", ".", "add_summary", "(", "\n", "summary", "=", "validation_summary", ",", "global_step", "=", "step", "\n", ")", "\n", "\n", "", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predictions", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "step", ",", "\n", "phase", "=", "\"testing\"", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"EOF -- testing done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.svm.SVM.variable_summaries": [[269, 280], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.name_scope", "tensorflow.sqrt", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.reduce_mean", "tensorflow.square"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "variable_summaries", "(", "var", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"summaries\"", ")", ":", "\n", "            ", "mean", "=", "tf", ".", "reduce_mean", "(", "var", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"mean\"", ",", "mean", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"stddev\"", ")", ":", "\n", "                ", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "var", "-", "mean", ")", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"stddev\"", ",", "stddev", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"max\"", ",", "tf", ".", "reduce_max", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"min\"", ",", "tf", ".", "reduce_min", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"histogram\"", ",", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.svm.SVM.save_labels": [[281, 309], ["numpy.concatenate", "numpy.save", "os.path.exists", "os.mkdir", "os.path.join"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "save_labels", "(", "predictions", ",", "actual", ",", "result_path", ",", "step", ",", "phase", ")", ":", "\n", "        ", "\"\"\"Saves the actual and predicted labels to a NPY file\n\n        Parameter\n        ---------\n        predictions : numpy.ndarray\n          The NumPy array containing the predicted labels.\n        actual : numpy.ndarray\n          The NumPy array containing the actual labels.\n        result_path : str\n          The path where to save the concatenated actual and predicted labels.\n        step : int\n          The time step for the NumPy arrays.\n        phase : str\n          The phase for which the predictions is, i.e. training/validation/testing.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "result_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "result_path", ")", "\n", "\n", "# Concatenate the predicted and actual labels", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "(", "predictions", ",", "actual", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# save the labels array to NPY file", "\n", "np", ".", "save", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "result_path", ",", "\"{}-svm-{}.npy\"", ".", "format", "(", "phase", ",", "step", ")", ")", ",", "\n", "arr", "=", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.logistic_regression.LogisticRegression.__init__": [[34, 126], ["sys.stdout.write", "logistic_regression.LogisticRegression.__init__.__graph__"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "batch_size", ",", "num_classes", ",", "sequence_length", ")", ":", "\n", "        ", "\"\"\"Initialize the Logistic Regression class\n\n        Parameter\n        ---------\n        alpha : float\n          The learning rate for the Logistic Regression model.\n        batch_size : int\n          The number of batches to use for training/validation/testing.\n        num_classes : int\n          The number of classes in a dataset.\n        sequence_length : int\n          The number of features in a dataset.\n        \"\"\"", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "sequence_length", "=", "sequence_length", "\n", "\n", "def", "__graph__", "(", ")", ":", "\n", "# input placeholder for features (x) and labels (y)", "\n", "            ", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "# [BATCH_SIZE, SEQUENCE_LENGTH]", "\n", "                ", "x_input", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "sequence_length", "]", ",", "name", "=", "\"x_input\"", "\n", ")", "\n", "\n", "# [BATCH_SIZE]", "\n", "y_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "[", "None", "]", ",", "name", "=", "\"y_input\"", ")", "\n", "\n", "# [BATCH_SIZE, NUM_CLASSES]", "\n", "y_onehot", "=", "tf", ".", "one_hot", "(", "\n", "indices", "=", "y_input", ",", "\n", "depth", "=", "self", ".", "num_classes", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "name", "=", "\"y_onehot\"", ",", "\n", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"training_ops\"", ")", ":", "\n", "                ", "with", "tf", ".", "name_scope", "(", "\"weights\"", ")", ":", "\n", "                    ", "weight", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "zeros", "(", "[", "self", ".", "sequence_length", ",", "self", ".", "num_classes", "]", ")", ",", "\n", "name", "=", "\"weights\"", ",", "\n", ")", "\n", "self", ".", "variable_summaries", "(", "weight", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"biases\"", ")", ":", "\n", "                    ", "bias", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "self", ".", "num_classes", "]", ")", ",", "name", "=", "\"biases\"", ")", "\n", "self", ".", "variable_summaries", "(", "bias", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"decision_function\"", ")", ":", "\n", "                    ", "output", "=", "tf", ".", "matmul", "(", "x_input", ",", "weight", ")", "+", "bias", "\n", "output", "=", "tf", ".", "identity", "(", "output", ",", "name", "=", "\"logits\"", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"pre-activations\"", ",", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"cross_entropy_loss\"", ")", ":", "\n", "                ", "cross_entropy", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "y_onehot", ",", "logits", "=", "output", "\n", ")", "\n", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "cross_entropy", ")", "\n", "\n", "# train using SGD algorithm", "\n", "train_op", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "alpha", ")", ".", "minimize", "(", "\n", "cross_entropy", "\n", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                ", "predictions", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", "=", "output", ",", "name", "=", "\"softmax_predictions\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"correct_prediction\"", ")", ":", "\n", "# check if the actual labels and predicted labels match", "\n", "                    ", "correct", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "output", ",", "1", ")", ",", "tf", ".", "argmax", "(", "y_onehot", ",", "1", ")", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "# get the % of correct predictions", "\n", "                    ", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct", ",", "tf", ".", "float32", ")", ")", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\"accuracy\"", ",", "accuracy", ")", "\n", "\n", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "self", ".", "x_input", "=", "x_input", "\n", "self", ".", "y_input", "=", "y_input", "\n", "self", ".", "y_onehot", "=", "y_onehot", "\n", "self", ".", "output", "=", "output", "\n", "self", ".", "predictions", "=", "predictions", "\n", "self", ".", "cross_entropy", "=", "cross_entropy", "\n", "self", ".", "train_op", "=", "train_op", "\n", "self", ".", "accuracy_op", "=", "accuracy", "\n", "self", ".", "merged", "=", "merged", "\n", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n<log> Building graph...\"", ")", "\n", "__graph__", "(", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"</log>\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.logistic_regression.LogisticRegression.train": [[127, 294], ["tensorflow.train.Saver", "tensorflow.group", "str", "tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter", "os.path.exists", "os.mkdir", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "time.asctime", "tensorflow.Session", "sess.run", "tensorflow.train.get_checkpoint_state", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph.restore", "range", "print", "range", "print", "tensorflow.train.latest_checkpoint", "sess.run", "logistic_regression.LogisticRegression.save_labels", "print", "os._exit", "sess.run", "logistic_regression.LogisticRegression.save_labels", "sess.run", "print", "tensorflow.summary.FileWriter.add_summary", "tensorflow.train.import_meta_graph.save", "print", "tensorflow.summary.FileWriter.add_summary"], "methods", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels", "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels"], ["", "def", "train", "(", "\n", "self", ",", "\n", "checkpoint_path", ",", "\n", "log_path", ",", "\n", "model_name", ",", "\n", "epochs", ",", "\n", "train_data", ",", "\n", "train_size", ",", "\n", "validation_data", ",", "\n", "validation_size", ",", "\n", "result_path", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Trains the model\n\n        Parameter\n        ---------\n        checkpoint_path : str\n          The path where to save the trained model.\n        log_path : str\n          The path where to save the TensorBoard summaries.\n        model_name : str\n          The filename for the trained model.\n        epochs : int\n          The number of passes through the whole dataset.\n        train_data : numpy.ndarray\n          The NumPy array training dataset.\n        train_size : int\n          The size of `train_data`.\n        validation_data : numpy.ndarray\n          The NumPy array testing dataset.\n        validation_size : int\n          The size of `validation_data`.\n        result_path : str\n          The path where to save the actual and predicted classes array.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "checkpoint_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "path", "=", "checkpoint_path", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "10", ")", "\n", "\n", "init_op", "=", "tf", ".", "group", "(", "\n", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "local_variables_initializer", "(", ")", "\n", ")", "\n", "\n", "timestamp", "=", "str", "(", "time", ".", "asctime", "(", ")", ")", "\n", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "logdir", "=", "log_path", "+", "timestamp", "+", "\"-training\"", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "test_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "logdir", "=", "log_path", "+", "timestamp", "+", "\"-testing\"", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "checkpoint", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "checkpoint_path", ")", "\n", "\n", "if", "checkpoint", "and", "checkpoint", ".", "model_checkpoint_path", ":", "\n", "                ", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "\n", "checkpoint", ".", "model_checkpoint_path", "+", "\".meta\"", "\n", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_path", ")", ")", "\n", "\n", "", "try", ":", "\n", "                ", "for", "step", "in", "range", "(", "epochs", "*", "train_size", "//", "self", ".", "batch_size", ")", ":", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "train_size", "\n", "train_example_batch", "=", "train_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "train_label_batch", "=", "train_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "train_example_batch", ",", "\n", "self", ".", "y_input", ":", "train_label_batch", ",", "\n", "}", "\n", "\n", "summary", ",", "_", ",", "loss", ",", "predicted", ",", "actual", "=", "sess", ".", "run", "(", "\n", "[", "\n", "self", ".", "merged", ",", "\n", "self", ".", "train_op", ",", "\n", "self", ".", "cross_entropy", ",", "\n", "self", ".", "predictions", ",", "\n", "self", ".", "y_onehot", ",", "\n", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "if", "step", "%", "100", "==", "0", "and", "step", ">", "0", ":", "\n", "                        ", "train_loss", ",", "train_accuracy", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "cross_entropy", ",", "self", ".", "accuracy_op", "]", ",", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "print", "(", "\n", "\"step [{}] train -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "train_loss", ",", "train_accuracy", "\n", ")", "\n", ")", "\n", "\n", "train_writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "\n", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", "+", "model_name", ",", "global_step", "=", "step", ")", "\n", "\n", "", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predicted", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "step", ",", "\n", "phase", "=", "\"training\"", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "print", "(", "\"Training interrupted at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "os", ".", "_exit", "(", "1", ")", "\n", "", "finally", ":", "\n", "                ", "print", "(", "\"EOF -- Training done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "for", "step", "in", "range", "(", "epochs", "*", "validation_size", "//", "self", ".", "batch_size", ")", ":", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "validation_size", "\n", "test_example_batch", "=", "validation_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "test_label_batch", "=", "validation_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "test_example_batch", ",", "\n", "self", ".", "y_input", ":", "test_label_batch", ",", "\n", "}", "\n", "\n", "(", "\n", "test_summary", ",", "\n", "predicted", ",", "\n", "actual", ",", "\n", "test_loss", ",", "\n", "test_accuracy", ",", "\n", ")", "=", "sess", ".", "run", "(", "\n", "[", "\n", "self", ".", "merged", ",", "\n", "self", ".", "predictions", ",", "\n", "self", ".", "y_onehot", ",", "\n", "self", ".", "cross_entropy", ",", "\n", "self", ".", "accuracy_op", ",", "\n", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "\n", "if", "step", "%", "100", "==", "0", "and", "step", ">", "0", ":", "\n", "                        ", "print", "(", "\n", "\"step [{}] testing -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "test_loss", ",", "test_accuracy", "\n", ")", "\n", ")", "\n", "\n", "test_writer", ".", "add_summary", "(", "test_summary", ",", "step", ")", "\n", "\n", "", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predicted", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "step", ",", "\n", "phase", "=", "\"testing\"", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"EOF -- Testing done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.logistic_regression.LogisticRegression.variable_summaries": [[295, 306], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.name_scope", "tensorflow.sqrt", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.reduce_mean", "tensorflow.square"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "variable_summaries", "(", "var", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"summaries\"", ")", ":", "\n", "            ", "mean", "=", "tf", ".", "reduce_mean", "(", "var", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"mean\"", ",", "mean", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"stddev\"", ")", ":", "\n", "                ", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "var", "-", "mean", ")", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"stddev\"", ",", "stddev", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"max\"", ",", "tf", ".", "reduce_max", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"min\"", ",", "tf", ".", "reduce_min", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"histogram\"", ",", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.logistic_regression.LogisticRegression.save_labels": [[307, 337], ["numpy.concatenate", "numpy.save", "os.path.exists", "os.mkdir", "os.path.join"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "save_labels", "(", "predictions", ",", "actual", ",", "result_path", ",", "step", ",", "phase", ")", ":", "\n", "        ", "\"\"\"Saves the actual and predicted labels to a NPY file\n\n        Parameter\n        ---------\n        predictions : numpy.ndarray\n          The NumPy array containing the predicted labels.\n        actual : numpy.ndarray\n          The NumPy array containing the actual labels.\n        result_path : str\n          The path where to save the concatenated actual and predicted labels.\n        step : int\n          The time step for the NumPy arrays.\n        phase : str\n          The phase for which the predictions is, i.e. training/validation/testing.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "result_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "result_path", ")", "\n", "\n", "# Concatenate the predicted and actual labels", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "(", "predictions", ",", "actual", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# save the labels array to NPY file", "\n", "np", ".", "save", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "\n", "result_path", ",", "\"{}-logistic_regression-{}.npy\"", ".", "format", "(", "phase", ",", "step", ")", "\n", ")", ",", "\n", "arr", "=", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.gru_svm.GruSvm.__init__": [[37, 191], ["sys.stdout.write", "gru_svm.GruSvm.__init__.__graph__"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "alpha", ",", "\n", "batch_size", ",", "\n", "cell_size", ",", "\n", "dropout_rate", ",", "\n", "num_classes", ",", "\n", "sequence_length", ",", "\n", "svm_c", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize the GRU-SVM class\n\n        Parameter\n        ---------\n        alpha : float\n          The learning rate for the GRU+Softmax model.\n        batch_size : int\n          The number of batches to use for training/validation/testing.\n        cell_size : int\n          The size of cell state.\n        dropout_rate : float\n          The dropout rate to be used.\n        num_classes : int\n          The number of classes in a dataset.\n        sequence_length : int\n          The number of features in a dataset.\n        svm_c : float\n          The SVM penalty parameter C.\n        \"\"\"", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "cell_size", "=", "cell_size", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "sequence_length", "=", "sequence_length", "\n", "self", ".", "svm_c", "=", "svm_c", "\n", "\n", "def", "__graph__", "(", ")", ":", "\n", "            ", "\"\"\"Build the inference graph\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "# [BATCH_SIZE, SEQUENCE_LENGTH]", "\n", "                ", "x_input", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "uint8", ",", "shape", "=", "[", "None", ",", "self", ".", "sequence_length", "]", ",", "name", "=", "\"x_input\"", "\n", ")", "\n", "\n", "# [BATCH_SIZE, SEQUENCE_LENGTH, 10]", "\n", "x_onehot", "=", "tf", ".", "one_hot", "(", "\n", "indices", "=", "x_input", ",", "\n", "depth", "=", "10", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "name", "=", "\"x_onehot\"", ",", "\n", ")", "\n", "\n", "# [BATCH_SIZE]", "\n", "y_input", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "uint8", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"y_input\"", ")", "\n", "\n", "# [BATCH_SIZE, N_CLASSES]", "\n", "y_onehot", "=", "tf", ".", "one_hot", "(", "\n", "indices", "=", "y_input", ",", "\n", "depth", "=", "self", ".", "num_classes", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "-", "1.0", ",", "\n", "name", "=", "\"y_onehot\"", ",", "\n", ")", "\n", "\n", "", "state", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "cell_size", "]", ",", "name", "=", "\"initial_state\"", "\n", ")", "\n", "\n", "p_keep", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"p_keep\"", ")", "\n", "learning_rate", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"learning_rate\"", ")", "\n", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "GRUCell", "(", "self", ".", "cell_size", ")", "\n", "drop_cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "DropoutWrapper", "(", "cell", ",", "input_keep_prob", "=", "p_keep", ")", "\n", "\n", "# outputs: [BATCH_SIZE, SEQUENCE_LENGTH, CELL_SIZE]", "\n", "# states: [BATCH_SIZE, CELL_SIZE]", "\n", "outputs", ",", "states", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "drop_cell", ",", "x_onehot", ",", "initial_state", "=", "state", ",", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "states", "=", "tf", ".", "identity", "(", "states", ",", "name", "=", "\"H\"", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"final_training_ops\"", ")", ":", "\n", "                ", "with", "tf", ".", "name_scope", "(", "\"weights\"", ")", ":", "\n", "                    ", "weight", "=", "tf", ".", "get_variable", "(", "\n", "\"weights\"", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "\n", "[", "self", ".", "cell_size", ",", "self", ".", "num_classes", "]", ",", "stddev", "=", "0.01", "\n", ")", ",", "\n", ")", "\n", "self", ".", "variable_summaries", "(", "weight", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"biases\"", ")", ":", "\n", "                    ", "bias", "=", "tf", ".", "get_variable", "(", "\n", "\"biases\"", ",", "initializer", "=", "tf", ".", "constant", "(", "0.1", ",", "shape", "=", "[", "self", ".", "num_classes", "]", ")", "\n", ")", "\n", "self", ".", "variable_summaries", "(", "bias", ")", "\n", "", "hf", "=", "tf", ".", "transpose", "(", "outputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "last", "=", "tf", ".", "gather", "(", "hf", ",", "int", "(", "hf", ".", "get_shape", "(", ")", "[", "0", "]", ")", "-", "1", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"Wx_plus_b\"", ")", ":", "\n", "                    ", "output", "=", "tf", ".", "matmul", "(", "last", ",", "weight", ")", "+", "bias", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"pre-activations\"", ",", "output", ")", "\n", "\n", "# L2-SVM", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"svm\"", ")", ":", "\n", "                ", "regularization_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "weight", ")", ")", "\n", "hinge_loss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "square", "(", "\n", "tf", ".", "maximum", "(", "\n", "tf", ".", "zeros", "(", "[", "self", ".", "batch_size", ",", "self", ".", "num_classes", "]", ")", ",", "\n", "1", "-", "y_onehot", "*", "output", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"loss\"", ")", ":", "\n", "                    ", "loss", "=", "regularization_loss", "+", "self", ".", "svm_c", "*", "hinge_loss", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "loss", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ")", ".", "minimize", "(", "\n", "loss", "\n", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                ", "predicted_class", "=", "tf", ".", "sign", "(", "output", ")", "\n", "predicted_class", "=", "tf", ".", "identity", "(", "predicted_class", ",", "name", "=", "\"prediction\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"correct_prediction\"", ")", ":", "\n", "                    ", "correct", "=", "tf", ".", "equal", "(", "\n", "tf", ".", "argmax", "(", "predicted_class", ",", "1", ")", ",", "tf", ".", "argmax", "(", "y_onehot", ",", "1", ")", "\n", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                    ", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct", ",", "\"float\"", ")", ")", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\"accuracy\"", ",", "accuracy", ")", "\n", "\n", "# merge all the summaries collected from the TF graph", "\n", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "# set class properties", "\n", "self", ".", "x_input", "=", "x_input", "\n", "self", ".", "y_input", "=", "y_input", "\n", "self", ".", "y_onehot", "=", "y_onehot", "\n", "self", ".", "p_keep", "=", "p_keep", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "state", "=", "state", "\n", "self", ".", "states", "=", "states", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "predicted_class", "=", "predicted_class", "\n", "self", ".", "accuracy", "=", "accuracy", "\n", "self", ".", "merged", "=", "merged", "\n", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n<log> Building Graph...\"", ")", "\n", "__graph__", "(", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"</log>\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.gru_svm.GruSvm.train": [[192, 389], ["tensorflow.train.Saver", "numpy.zeros", "tensorflow.group", "str", "tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter", "os.path.exists", "os.mkdir", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "time.asctime", "tensorflow.Session", "sess.run", "tensorflow.train.get_checkpoint_state", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph.restore", "range", "print", "range", "print", "tensorflow.train.latest_checkpoint", "sess.run", "gru_svm.GruSvm.save_labels", "print", "os._exit", "sess.run", "gru_svm.GruSvm.save_labels", "sess.run", "print", "tensorflow.summary.FileWriter.add_summary", "tensorflow.train.import_meta_graph.save", "numpy.zeros", "tensorflow.summary.FileWriter.add_summary", "print"], "methods", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels", "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels"], ["", "def", "train", "(", "\n", "self", ",", "\n", "checkpoint_path", ",", "\n", "log_path", ",", "\n", "model_name", ",", "\n", "epochs", ",", "\n", "train_data", ",", "\n", "train_size", ",", "\n", "validation_data", ",", "\n", "validation_size", ",", "\n", "result_path", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Trains the model\n\n        Parameter\n        ---------\n        checkpoint_path : str\n          The path where to save the trained model.\n        log_path : str\n          The path where to save the TensorBoard summaries.\n        model_name : str\n          The filename for the trained model.\n        epochs : int\n          The number of passes through the whole dataset.\n        train_data : numpy.ndarray\n          The NumPy array training dataset.\n        train_size : int\n          The size of `train_data`.\n        validation_data : numpy.ndarray\n          The NumPy array testing dataset.\n        validation_size : int\n          The size of `validation_data`.\n        result_path : str\n          The path where to save the actual and predicted classes array.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "checkpoint_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "path", "=", "checkpoint_path", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "10", ")", "\n", "\n", "# initialize H (current_state) with values of zeros", "\n", "current_state", "=", "np", ".", "zeros", "(", "[", "self", ".", "batch_size", ",", "self", ".", "cell_size", "]", ")", "\n", "\n", "# variables initializer", "\n", "init_op", "=", "tf", ".", "group", "(", "\n", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "local_variables_initializer", "(", ")", "\n", ")", "\n", "\n", "# get the time tuple", "\n", "timestamp", "=", "str", "(", "time", ".", "asctime", "(", ")", ")", "\n", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "logdir", "=", "log_path", "+", "timestamp", "+", "\"-training\"", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "validation_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "logdir", "=", "log_path", "+", "timestamp", "+", "\"-validation\"", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "checkpoint", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "checkpoint_path", ")", "\n", "\n", "if", "checkpoint", "and", "checkpoint", ".", "model_checkpoint_path", ":", "\n", "                ", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "\n", "checkpoint", ".", "model_checkpoint_path", "+", "\".meta\"", "\n", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_path", ")", ")", "\n", "\n", "", "try", ":", "\n", "                ", "for", "step", "in", "range", "(", "epochs", "*", "train_size", "//", "self", ".", "batch_size", ")", ":", "\n", "\n", "# set the value for slicing", "\n", "# e.g. step = 0, batch_size = 256, train_size = 1898240", "\n", "# (0 * 256) % 1898240 = 0", "\n", "# [offset:(offset + batch_size)] = [0:256]", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "train_size", "\n", "train_example_batch", "=", "train_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "train_label_batch", "=", "train_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "# dictionary for key-value pair input for training", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "train_example_batch", ",", "\n", "self", ".", "y_input", ":", "train_label_batch", ",", "\n", "self", ".", "state", ":", "current_state", ",", "\n", "self", ".", "learning_rate", ":", "self", ".", "alpha", ",", "\n", "self", ".", "p_keep", ":", "self", ".", "dropout_rate", ",", "\n", "}", "\n", "\n", "train_summary", ",", "_", ",", "predictions", ",", "actual", ",", "next_state", "=", "sess", ".", "run", "(", "\n", "[", "\n", "self", ".", "merged", ",", "\n", "self", ".", "optimizer", ",", "\n", "self", ".", "predicted_class", ",", "\n", "self", ".", "y_onehot", ",", "\n", "self", ".", "states", ",", "\n", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "\n", "# Display training loss and accuracy every 100 steps and at step 0", "\n", "if", "step", "%", "100", "==", "0", ":", "\n", "# get train loss and accuracy", "\n", "                        ", "train_loss", ",", "train_accuracy", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "loss", ",", "self", ".", "accuracy", "]", ",", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "# display train loss and accuracy", "\n", "print", "(", "\n", "\"step [{}] train -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "train_loss", ",", "train_accuracy", "\n", ")", "\n", ")", "\n", "\n", "# write the train summary", "\n", "train_writer", ".", "add_summary", "(", "train_summary", ",", "step", ")", "\n", "\n", "# save the model at current step", "\n", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", "+", "model_name", ",", "global_step", "=", "step", ")", "\n", "\n", "", "current_state", "=", "next_state", "\n", "\n", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predictions", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "step", ",", "\n", "phase", "=", "\"training\"", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "print", "(", "\"Training interrupted at {}\"", ".", "format", "(", "step", ")", ")", "\n", "os", ".", "_exit", "(", "1", ")", "\n", "", "finally", ":", "\n", "                ", "print", "(", "\"EOF -- Training done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "for", "step", "in", "range", "(", "epochs", "*", "validation_size", "//", "self", ".", "batch_size", ")", ":", "\n", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "validation_size", "\n", "test_example_batch", "=", "validation_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "test_label_batch", "=", "validation_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "# dictionary for key-value pair input for validation", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "test_example_batch", ",", "\n", "self", ".", "y_input", ":", "test_label_batch", ",", "\n", "self", ".", "state", ":", "np", ".", "zeros", "(", "[", "self", ".", "batch_size", ",", "self", ".", "cell_size", "]", ")", ",", "\n", "self", ".", "p_keep", ":", "1.0", ",", "\n", "}", "\n", "\n", "(", "\n", "validation_summary", ",", "\n", "predictions", ",", "\n", "actual", ",", "\n", "validation_loss", ",", "\n", "validation_accuracy", ",", "\n", ")", "=", "sess", ".", "run", "(", "\n", "[", "\n", "self", ".", "merged", ",", "\n", "self", ".", "predicted_class", ",", "\n", "self", ".", "y_onehot", ",", "\n", "self", ".", "loss", ",", "\n", "self", ".", "accuracy", ",", "\n", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "\n", "# Display validation loss and accuracy every 100 steps", "\n", "if", "step", "%", "100", "==", "0", "and", "step", ">", "0", ":", "\n", "\n", "# add the validation summary", "\n", "                        ", "validation_writer", ".", "add_summary", "(", "validation_summary", ",", "step", ")", "\n", "\n", "# display validation loss and accuracy", "\n", "print", "(", "\n", "\"step [{}] validation -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "validation_loss", ",", "validation_accuracy", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predictions", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "step", "=", "step", ",", "\n", "phase", "=", "\"validation\"", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"EOF -- Testing done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.gru_svm.GruSvm.variable_summaries": [[390, 401], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.name_scope", "tensorflow.sqrt", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.reduce_mean", "tensorflow.square"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "variable_summaries", "(", "var", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"summaries\"", ")", ":", "\n", "            ", "mean", "=", "tf", ".", "reduce_mean", "(", "var", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"mean\"", ",", "mean", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"stddev\"", ")", ":", "\n", "                ", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "var", "-", "mean", ")", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"stddev\"", ",", "stddev", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"max\"", ",", "tf", ".", "reduce_max", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"min\"", ",", "tf", ".", "reduce_min", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"histogram\"", ",", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.gru_svm.GruSvm.save_labels": [[402, 430], ["numpy.concatenate", "numpy.save", "os.path.exists", "os.mkdir", "os.path.join"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "save_labels", "(", "predictions", ",", "actual", ",", "result_path", ",", "step", ",", "phase", ")", ":", "\n", "        ", "\"\"\"Saves the actual and predicted labels to a NPY file\n\n        Parameter\n        ---------\n        predictions : numpy.ndarray\n          The NumPy array containing the predicted labels.\n        actual : numpy.ndarray\n          The NumPy array containing the actual labels.\n        result_path : str\n          The path where to save the concatenated actual and predicted labels.\n        step : int\n          The time step for the NumPy arrays.\n        phase : str\n          The phase for which the predictions is, i.e. training/validation/testing.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "result_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "result_path", ")", "\n", "\n", "# Concatenate the predicted and actual labels", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "(", "predictions", ",", "actual", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# save the labels array to NPY file", "\n", "np", ".", "save", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "result_path", ",", "\"{}-gru_svm-{}.npy\"", ".", "format", "(", "phase", ",", "step", ")", ")", ",", "\n", "arr", "=", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.__init__": [[34, 167], ["sys.stdout.write", "MLP.MLP.__init__.__graph__"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "batch_size", ",", "node_size", ",", "num_classes", ",", "num_features", ")", ":", "\n", "        ", "\"\"\"Initialize the MLP model\n\n        Parameter\n        ---------\n        alpha : float\n          The learning rate to be used by the neural network.\n        batch_size : int\n          The number of batches to use for training/validation/testing.\n        node_size : int\n          The number of neurons in the neural network.\n        num_classes : int\n          The number of classes in a dataset.\n        num_features : int\n          The number of features in a dataset.\n        \"\"\"", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "node_size", "=", "node_size", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "num_features", "\n", "\n", "def", "__graph__", "(", ")", ":", "\n", "            ", "\"\"\"Build the inference graph\"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "# [BATCH_SIZE, NUM_FEATURES]", "\n", "                ", "x_input", "=", "tf", ".", "placeholder", "(", "\n", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "num_features", "]", ",", "name", "=", "\"x_input\"", "\n", ")", "\n", "\n", "# [BATCH_SIZE]", "\n", "y_input", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "uint8", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"y_input\"", ")", "\n", "\n", "# [BATCH_SIZE, NUM_CLASSES]", "\n", "y_onehot", "=", "tf", ".", "one_hot", "(", "\n", "indices", "=", "y_input", ",", "\n", "depth", "=", "self", ".", "num_classes", ",", "\n", "on_value", "=", "1", ",", "\n", "off_value", "=", "0", ",", "\n", "name", "=", "\"y_onehot\"", ",", "\n", ")", "\n", "\n", "", "learning_rate", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"learning_rate\"", ")", "\n", "\n", "first_hidden_layer", "=", "{", "\n", "\"weights\"", ":", "self", ".", "weight_variable", "(", "\n", "\"h1_w_layer\"", ",", "[", "self", ".", "num_features", ",", "self", ".", "node_size", "[", "0", "]", "]", "\n", ")", ",", "\n", "\"biases\"", ":", "self", ".", "bias_variable", "(", "\"h1_b_layer\"", ",", "[", "self", ".", "node_size", "[", "0", "]", "]", ")", ",", "\n", "}", "\n", "\n", "second_hidden_layer", "=", "{", "\n", "\"weights\"", ":", "self", ".", "weight_variable", "(", "\n", "\"h2_w_layer\"", ",", "[", "self", ".", "node_size", "[", "0", "]", ",", "self", ".", "node_size", "[", "1", "]", "]", "\n", ")", ",", "\n", "\"biases\"", ":", "self", ".", "bias_variable", "(", "\"h2_b_layer\"", ",", "[", "self", ".", "node_size", "[", "1", "]", "]", ")", ",", "\n", "}", "\n", "\n", "third_hidden_layer", "=", "{", "\n", "\"weights\"", ":", "self", ".", "weight_variable", "(", "\n", "\"h3_w_layer\"", ",", "[", "self", ".", "node_size", "[", "1", "]", ",", "self", ".", "node_size", "[", "2", "]", "]", "\n", ")", ",", "\n", "\"biases\"", ":", "self", ".", "bias_variable", "(", "\"h3_b_layer\"", ",", "[", "self", ".", "node_size", "[", "2", "]", "]", ")", ",", "\n", "}", "\n", "\n", "output_layer", "=", "{", "\n", "\"weights\"", ":", "self", ".", "weight_variable", "(", "\n", "\"output_w_layer\"", ",", "[", "self", ".", "node_size", "[", "2", "]", ",", "self", ".", "num_classes", "]", "\n", ")", ",", "\n", "\"biases\"", ":", "self", ".", "bias_variable", "(", "\"output_b_layer\"", ",", "[", "self", ".", "num_classes", "]", ")", ",", "\n", "}", "\n", "\n", "first_layer", "=", "(", "\n", "tf", ".", "matmul", "(", "x_input", ",", "first_hidden_layer", "[", "\"weights\"", "]", ")", "\n", "+", "first_hidden_layer", "[", "\"biases\"", "]", "\n", ")", "\n", "first_layer", "=", "tf", ".", "nn", ".", "relu", "(", "first_layer", ")", "\n", "\n", "second_layer", "=", "(", "\n", "tf", ".", "matmul", "(", "first_layer", ",", "second_hidden_layer", "[", "\"weights\"", "]", ")", "\n", "+", "second_hidden_layer", "[", "\"biases\"", "]", "\n", ")", "\n", "second_layer", "=", "tf", ".", "nn", ".", "relu", "(", "second_layer", ")", "\n", "\n", "third_layer", "=", "(", "\n", "tf", ".", "matmul", "(", "second_layer", ",", "third_hidden_layer", "[", "\"weights\"", "]", ")", "\n", "+", "third_hidden_layer", "[", "\"biases\"", "]", "\n", ")", "\n", "third_layer", "=", "tf", ".", "nn", ".", "relu", "(", "third_layer", ")", "\n", "\n", "output_layer", "=", "(", "\n", "tf", ".", "matmul", "(", "third_layer", ",", "output_layer", "[", "\"weights\"", "]", ")", "+", "output_layer", "[", "\"biases\"", "]", "\n", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"pre-activations\"", ",", "output_layer", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"loss\"", ")", ":", "\n", "                ", "loss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "output_layer", ",", "labels", "=", "y_onehot", "\n", ")", "\n", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"loss\"", ",", "loss", ")", "\n", "\n", "optimizer_op", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "\n", "learning_rate", "=", "learning_rate", "\n", ")", ".", "minimize", "(", "loss", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                ", "predicted_class", "=", "tf", ".", "nn", ".", "softmax", "(", "output_layer", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"correct_prediction\"", ")", ":", "\n", "                    ", "correct_prediction", "=", "tf", ".", "equal", "(", "\n", "tf", ".", "argmax", "(", "predicted_class", ",", "1", ")", ",", "tf", ".", "argmax", "(", "y_onehot", ",", "1", ")", "\n", ")", "\n", "", "with", "tf", ".", "name_scope", "(", "\"accuracy\"", ")", ":", "\n", "                    ", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "\"float\"", ")", ")", "\n", "", "", "tf", ".", "summary", ".", "scalar", "(", "\"accuracy\"", ",", "accuracy", ")", "\n", "\n", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "self", ".", "x_input", "=", "x_input", "\n", "self", ".", "y_input", "=", "y_input", "\n", "self", ".", "y_onehot", "=", "y_onehot", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "optimizer_op", "=", "optimizer_op", "\n", "self", ".", "predicted_class", "=", "predicted_class", "\n", "self", ".", "accuracy", "=", "accuracy", "\n", "self", ".", "merged", "=", "merged", "\n", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n<log> Building Graph...\"", ")", "\n", "__graph__", "(", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"</log>\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.train": [[168, 292], ["tensorflow.group", "str", "tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "time.asctime", "tensorflow.Session", "sess.run", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "range", "print", "range", "print", "sess.run", "print", "os._exit", "sess.run", "MLP.MLP.save_labels", "sess.run", "print", "tensorflow.summary.FileWriter.add_summary", "print", "tensorflow.summary.FileWriter.add_summary"], "methods", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels"], ["", "def", "train", "(", "\n", "self", ",", "\n", "num_epochs", ",", "\n", "log_path", ",", "\n", "train_data", ",", "\n", "train_size", ",", "\n", "test_data", ",", "\n", "test_size", ",", "\n", "result_path", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Trains the MLP model\n\n        Parameter\n        ---------\n        num_epochs : int\n          The number of passes over the entire dataset.\n        log_path : str\n          The path where to save the TensorBoard logs.\n        train_data : numpy.ndarray\n          The NumPy array to be used as training dataset.\n        train_size : int\n          The size of the `train_data`.\n        test_data : numpy.ndarray\n          The NumPy array to be used as testing dataset.\n        test_size : int\n          The size of the `test_data`.\n        \"\"\"", "\n", "\n", "# initialize the variables", "\n", "init_op", "=", "tf", ".", "group", "(", "\n", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "local_variables_initializer", "(", ")", "\n", ")", "\n", "\n", "timestamp", "=", "str", "(", "time", ".", "asctime", "(", ")", ")", "\n", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "log_path", "+", "timestamp", "+", "\"-training\"", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "test_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "log_path", "+", "timestamp", "+", "\"-test\"", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "try", ":", "\n", "                ", "for", "step", "in", "range", "(", "num_epochs", "*", "train_size", "//", "self", ".", "batch_size", ")", ":", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "train_size", "\n", "train_data_batch", "=", "train_data", "[", "0", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "train_label_batch", "=", "train_data", "[", "1", "]", "[", "\n", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "\n", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "train_data_batch", ",", "\n", "self", ".", "y_input", ":", "train_label_batch", ",", "\n", "self", ".", "learning_rate", ":", "self", ".", "alpha", ",", "\n", "}", "\n", "\n", "train_summary", ",", "_", ",", "step_loss", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "merged", ",", "self", ".", "optimizer_op", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "if", "step", "%", "100", "==", "0", "and", "step", ">", "0", ":", "\n", "                        ", "train_accuracy", "=", "sess", ".", "run", "(", "self", ".", "accuracy", ",", "feed_dict", "=", "feed_dict", ")", "\n", "print", "(", "\n", "\"step [{}] train -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "step_loss", ",", "train_accuracy", "\n", ")", "\n", ")", "\n", "train_writer", ".", "add_summary", "(", "train_summary", ",", "global_step", "=", "step", ")", "\n", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "print", "(", "\"KeyboardInterrupt at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "os", ".", "_exit", "(", "1", ")", "\n", "", "finally", ":", "\n", "                ", "print", "(", "\"EOF -- Training done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "for", "step", "in", "range", "(", "num_epochs", "*", "test_size", "//", "self", ".", "batch_size", ")", ":", "\n", "                    ", "offset", "=", "(", "step", "*", "self", ".", "batch_size", ")", "%", "test_size", "\n", "test_data_batch", "=", "test_data", "[", "0", "]", "[", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "]", "\n", "test_label_batch", "=", "test_data", "[", "1", "]", "[", "offset", ":", "(", "offset", "+", "self", ".", "batch_size", ")", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_input", ":", "test_data_batch", ",", "\n", "self", ".", "y_input", ":", "test_label_batch", ",", "\n", "}", "\n", "\n", "(", "\n", "test_summary", ",", "\n", "test_accuracy", ",", "\n", "test_loss", ",", "\n", "predictions", ",", "\n", "actual", ",", "\n", ")", "=", "sess", ".", "run", "(", "\n", "[", "\n", "self", ".", "merged", ",", "\n", "self", ".", "accuracy", ",", "\n", "self", ".", "loss", ",", "\n", "self", ".", "predicted_class", ",", "\n", "self", ".", "y_onehot", ",", "\n", "]", ",", "\n", "feed_dict", "=", "feed_dict", ",", "\n", ")", "\n", "\n", "if", "step", "%", "100", "==", "0", "and", "step", ">", "0", ":", "\n", "                        ", "print", "(", "\n", "\"step [{}] test -- loss : {}, accuracy : {}\"", ".", "format", "(", "\n", "step", ",", "test_loss", ",", "test_accuracy", "\n", ")", "\n", ")", "\n", "test_writer", ".", "add_summary", "(", "test_summary", ",", "step", ")", "\n", "\n", "", "self", ".", "save_labels", "(", "\n", "predictions", "=", "predictions", ",", "\n", "actual", "=", "actual", ",", "\n", "result_path", "=", "result_path", ",", "\n", "phase", "=", "\"testing\"", ",", "\n", "step", "=", "step", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"EOF -- Testing done at step {}\"", ".", "format", "(", "step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.weight_variable": [[293, 308], ["tensorflow.random_normal", "tensorflow.get_variable"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "weight_variable", "(", "name", ",", "shape", ")", ":", "\n", "        ", "\"\"\"Initialize weight variable\n\n        Parameter\n        ---------\n        shape : list\n          The shape of the initialized value.\n\n        Returns\n        -------\n        The created `tf.get_variable` for weights.\n        \"\"\"", "\n", "initial_value", "=", "tf", ".", "random_normal", "(", "shape", "=", "shape", ",", "stddev", "=", "0.01", ")", "\n", "return", "tf", ".", "get_variable", "(", "name", "=", "name", ",", "initializer", "=", "initial_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.bias_variable": [[309, 324], ["tensorflow.constant", "tensorflow.get_variable"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "bias_variable", "(", "name", ",", "shape", ")", ":", "\n", "        ", "\"\"\"Initialize bias variable\n\n        Parameter\n        ---------\n        shape : list\n          The shape of the initialized value.\n\n        Returns\n        -------\n        The created `tf.get_variable` for biases.\n        \"\"\"", "\n", "initial_value", "=", "tf", ".", "constant", "(", "[", "0.1", "]", ",", "shape", "=", "shape", ")", "\n", "return", "tf", ".", "get_variable", "(", "name", "=", "name", ",", "initializer", "=", "initial_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.variable_summaries": [[325, 336], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.name_scope", "tensorflow.sqrt", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.reduce_mean", "tensorflow.square"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "variable_summaries", "(", "var", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"summaries\"", ")", ":", "\n", "            ", "mean", "=", "tf", ".", "reduce_mean", "(", "var", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"mean\"", ",", "mean", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"stddev\"", ")", ":", "\n", "                ", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "var", "-", "mean", ")", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"stddev\"", ",", "stddev", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"max\"", ",", "tf", ".", "reduce_max", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"min\"", ",", "tf", ".", "reduce_min", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"histogram\"", ",", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.MLP.MLP.save_labels": [[337, 365], ["numpy.concatenate", "numpy.save", "os.path.exists", "os.mkdir", "os.path.join"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "save_labels", "(", "predictions", ",", "actual", ",", "result_path", ",", "phase", ",", "step", ")", ":", "\n", "        ", "\"\"\"Saves the actual and predicted labels to a NPY file\n\n        Parameter\n        ---------\n        predictions : numpy.ndarray\n          The NumPy array containing the predicted labels.\n        actual : numpy.ndarray\n          The NumPy array containing the actual labels.\n        result_path : str\n          The path where to save the concatenated actual and predicted labels.\n        step : int\n          The time step for the NumPy arrays.\n        phase : str\n          The phase for which the predictions is, i.e. training/validation/testing.\n        \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", "=", "result_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "result_path", ")", "\n", "\n", "# Concatenate the predicted and actual labels", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "(", "predictions", ",", "actual", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# save every labels array to NPY file", "\n", "np", ".", "save", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "result_path", ",", "\"{}-mlp-{}.npy\"", ".", "format", "(", "phase", ",", "step", ")", ")", ",", "\n", "arr", "=", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.flask.app.home": [[19, 23], ["app.route", "flask.render_template"], "function", ["None"], ["@", "app", ".", "route", "(", "\"/\"", ")", "\n", "def", "home", "(", ")", ":", "\n", "    ", "filename", "=", "\"http://0.0.0.0:5000/static/\"", "+", "\"class.png\"", "\n", "return", "render_template", "(", "\"index.html\"", ",", "class_finding", "=", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.flask.app.classify": [[25, 44], ["app.route", "text.split.strip", "text.split.split", "numpy.array", "keras.models.load_model", "numpy.argmax", "print", "flask.render_template", "keras.models.load_model.predict", "numpy.reshape"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.models.nearest_neighbor.NearestNeighbor.predict"], ["", "@", "app", ".", "route", "(", "\"/\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "classify", "(", ")", ":", "\n", "    ", "text", "=", "request", ".", "form", "[", "\"text\"", "]", "\n", "assert", "\",\"", "in", "text", ",", "\"FormatError: Please enter comma-separated features\"", "\n", "\n", "text", "=", "text", ".", "strip", "(", "\",\"", ")", "\n", "text", "=", "text", ".", "split", "(", "\",\"", ")", "\n", "data", "=", "np", ".", "array", "(", "text", ",", "np", ".", "int", ")", "\n", "\n", "model", "=", "load_model", "(", "\"dnn.h5\"", ")", "\n", "prediction", "=", "np", ".", "argmax", "(", "model", ".", "predict", "(", "np", ".", "reshape", "(", "data", ",", "(", "-", "1", ",", "data", ".", "shape", "[", "0", "]", ")", ")", ")", ")", "\n", "\n", "print", "(", "\"Prediction : {}\"", ".", "format", "(", "prediction", ")", ")", "\n", "\n", "class_finding", "=", "\"benign.png\"", "if", "prediction", "==", "0", "else", "\"malignant.png\"", "\n", "\n", "filename", "=", "\"http://0.0.0.0:5000/static/\"", "+", "class_finding", "\n", "\n", "return", "render_template", "(", "\"index.html\"", ",", "class_finding", "=", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.flask.train.parse_args": [[33, 41], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.flask.train.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"MLP for Breast Cancer Detection\"", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "\"Arguments\"", ")", "\n", "group", ".", "add_argument", "(", "\n", "\"-d\"", ",", "\"--dataset\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "help", "=", "\"the WDBC dataset\"", "\n", ")", "\n", "arguments", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "arguments", "\n", "\n"]], "home.repos.pwc.inspect_result.AFAgarap_wisconsin-breast-cancer.flask.train.main": [[43, 129], ["pandas.read_csv", "data.fillna.replace", "data.fillna.fillna", "numpy.array", "numpy.array", "sklearn.model_selection.train_test_split", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit", "sklearn.preprocessing.StandardScaler.transform", "sklearn.preprocessing.StandardScaler.transform", "keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.compile", "keras.models.Sequential.fit", "print", "keras.models.Sequential.save", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.models.Sequential.evaluate"], "function", ["None"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "# get the dataset filename from parse_args()", "\n", "    ", "dataset", "=", "args", ".", "dataset", "\n", "\n", "# names for the dataset features", "\n", "column_names", "=", "[", "\n", "\"Sample code number\"", ",", "\n", "\"Clump Thickness\"", ",", "\n", "\"Uniformity of Cell Size\"", ",", "\n", "\"Uniformity of Cell Shape\"", ",", "\n", "\"Marginal Adhesion\"", ",", "\n", "\"Single Epithelial Cell Size\"", ",", "\n", "\"Bare Nuclei\"", ",", "\n", "\"Bland Chromatin\"", ",", "\n", "\"Normal Nucleoli\"", ",", "\n", "\"Mitoses\"", ",", "\n", "\"Class\"", ",", "\n", "]", "\n", "\n", "# load the dataset", "\n", "data", "=", "pd", ".", "read_csv", "(", "dataset", ",", "names", "=", "column_names", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "# replace missing data with NaN", "\n", "data", "=", "data", ".", "replace", "(", "\"?\"", ",", "np", ".", "NaN", ")", "\n", "\n", "# replace NaN data with 0", "\n", "data", "=", "data", ".", "fillna", "(", "0", ")", "\n", "\n", "# get the dataset features", "\n", "features", "=", "np", ".", "array", "(", "data", ".", "iloc", "[", ":", ",", "0", ":", "10", "]", ",", "np", ".", "int", ")", "\n", "\n", "# get the feature labels", "\n", "labels", "=", "np", ".", "array", "(", "data", ".", "iloc", "[", ":", ",", "10", "]", ",", "np", ".", "int", ")", "\n", "\n", "# convert the benign label to 0", "\n", "labels", "[", "labels", "==", "2", "]", "=", "0", "\n", "\n", "# convert the malignant label to 1", "\n", "labels", "[", "labels", "==", "4", "]", "=", "1", "\n", "\n", "# split the dataset into 70/30 for training and testing dataset", "\n", "x_train", ",", "x_test", ",", "y_train", ",", "y_test", "=", "train_test_split", "(", "\n", "features", ",", "labels", ",", "test_size", "=", "0.30", ",", "stratify", "=", "labels", "\n", ")", "\n", "\n", "# standardize using StandardScaler", "\n", "scaler", "=", "StandardScaler", "(", ")", "\n", "\n", "# fit the scaler to train features", "\n", "scaler", ".", "fit", "(", "x_train", ")", "\n", "\n", "# standardize the features", "\n", "x_train", "=", "scaler", ".", "transform", "(", "x_train", ")", "\n", "x_test", "=", "scaler", ".", "transform", "(", "x_test", ")", "\n", "\n", "# define the keras DNN model", "\n", "model", "=", "Sequential", "(", ")", "\n", "\n", "# accept input with shape of features, use ReLU", "\n", "model", ".", "add", "(", "Dense", "(", "512", ",", "input_dim", "=", "features", ".", "shape", "[", "1", "]", ",", "activation", "=", "\"relu\"", ")", ")", "\n", "\n", "# add two hidden layers with ReLU", "\n", "model", ".", "add", "(", "Dense", "(", "512", ",", "activation", "=", "\"relu\"", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "512", ",", "activation", "=", "\"relu\"", ")", ")", "\n", "\n", "# add dropout layer", "\n", "model", ".", "add", "(", "Dropout", "(", "0.25", ")", ")", "\n", "\n", "# binary classifier using sigmoid", "\n", "model", ".", "add", "(", "Dense", "(", "1", ",", "activation", "=", "\"sigmoid\"", ")", ")", "\n", "\n", "# binary cross-entropy as loss function, and adam as optimizer", "\n", "model", ".", "compile", "(", "loss", "=", "\"binary_crossentropy\"", ",", "optimizer", "=", "\"adam\"", ",", "metrics", "=", "[", "\"accuracy\"", "]", ")", "\n", "\n", "# train the model by 32 epochs", "\n", "model", ".", "fit", "(", "x_train", ",", "y_train", ",", "epochs", "=", "32", ",", "verbose", "=", "1", ")", "\n", "\n", "# evaluate the trained model", "\n", "accuracy", "=", "model", ".", "evaluate", "(", "x_test", ",", "y_test", ")", "[", "1", "]", "\n", "\n", "# display evaluation accuracy", "\n", "print", "(", "\"Test accuracy : {}\"", ".", "format", "(", "accuracy", ")", ")", "\n", "\n", "# save the trained model", "\n", "model", ".", "save", "(", "\"dnn.h5\"", ")", "\n", "\n"]]}