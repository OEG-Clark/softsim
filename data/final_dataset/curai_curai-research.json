{"home.repos.pwc.inspect_result.curai_curai-research.medical-summarization-ML4H-2021.train_pegasus.prepare_dataset": [[36, 78], ["print", "summary.utils.data.datasets.SnippetDataset.from_json_file", "print", "random.seed", "random.sample", "datasets.append", "datasets.append", "len", "SnippetDataset.from_json_file.subset", "print", "datasets.append", "print", "len", "SnippetDataset.from_json_file.subset", "len", "len", "reversed", "len"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.from_json_file", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.subset", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.subset"], ["def", "prepare_dataset", "(", "samples", "=", "1000", ",", "seed", "=", "0", ",", "return_unused", "=", "False", ",", "unused_samples", "=", "-", "1", ")", ":", "\n", "    ", "'''\n    Prepares training and testing datasets for PEGASUS fine-tuning, with optional\n    parameters to return leftover samples - which can be used for sample selection\n    or pseudo-labeling.\n\n    Parameters:\n\n        samples (int): Number of samples to include in training dataset.\n        seed (int): Seed to shuffle samples with.\n        return_unused (bool): If true, will return samples not selected in the training set.\n        unused_samples (int): Used with return_unused set to true, returns specific number\n                                of samples in unused dataset. -1 returns all unused samples.\n\n    '''", "\n", "\n", "print", "(", "\"Preparing snippet datasets...\"", ")", "\n", "\n", "dataset_paths", "=", "[", "TRAIN_DATA_PATH", ",", "TEST_DATA_PATH", "]", "\n", "datasets", "=", "[", "]", "\n", "\n", "for", "dataset_path", "in", "dataset_paths", ":", "\n", "        ", "dataset", "=", "SnippetDataset", ".", "from_json_file", "(", "dataset_path", ")", "\n", "\n", "if", "dataset_path", "==", "TRAIN_DATA_PATH", ":", "\n", "            ", "print", "(", "f\"Setting seed to {seed}.\"", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "snippet_ids", "=", "random", ".", "sample", "(", "dataset", ".", "snippet_ids", ",", "len", "(", "dataset", ")", ")", "\n", "datasets", ".", "append", "(", "dataset", ".", "subset", "(", "snippet_ids", "[", ":", "samples", "]", ")", ")", "\n", "\n", "if", "return_unused", ":", "\n", "                ", "if", "unused_samples", ">", "len", "(", "dataset", ")", "-", "samples", ":", "\n", "                    ", "print", "(", "f\"Adjusting number of samples in unused/pseduo-labeled dataset to: {len(dataset) - samples}\"", ")", "\n", "unused_samples", "=", "len", "(", "dataset", ")", "-", "samples", "\n", "\n", "", "ids_to_return", "=", "snippet_ids", "[", "-", "unused_samples", ":", "]", "if", "unused_samples", "!=", "-", "1", "else", "snippet_ids", "[", "samples", ":", "]", "\n", "print", "(", "\"Ids to return: \"", ",", "len", "(", "ids_to_return", ")", ")", "\n", "datasets", ".", "append", "(", "dataset", ".", "subset", "(", "reversed", "(", "ids_to_return", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.medical-summarization-ML4H-2021.train_pegasus.prepare_unl_dataset": [[79, 90], ["summary.utils.data.datasets.SnippetDataset.from_json_file", "SnippetDataset.from_json_file.clean", "datasets.append"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.from_json_file", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.clean"], ["", "def", "prepare_unl_dataset", "(", "args", ")", ":", "\n", "    ", "dataset_paths", "=", "[", "UNLABELED_DATA_PATH", "]", "\n", "datasets", "=", "[", "]", "\n", "\n", "for", "dataset_path", "in", "dataset_paths", ":", "\n", "        ", "dataset", "=", "SnippetDataset", ".", "from_json_file", "(", "dataset_path", ")", "\n", "dataset", ".", "clean", "(", "filter_by_ratio", "=", "args", ".", "filter_unlabeled_by_ratio", ")", "\n", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "", "return", "datasets", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.medical-summarization-ML4H-2021.train_pegasus.parse_args": [[91, 113], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.parse_args"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.model.build_dataset.parse_args"], ["", "def", "parse_args", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--pretrained-model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Path or name of pre-trained model to pull PEGASUS from.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-samples\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "\"Number of samples to train on.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "6", ",", "help", "=", "\"Number of epochs for training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "\"Size of batch.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--accumulate-grad-batches\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "\"Number of batches to accumulate before computing update.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp-name\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Experiment name, used by WandB for experiment tracking.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--track\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"If true, WandB will track experiment.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "str", ",", "default", "=", "0", ",", "help", "=", "\"Random sampling seed.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--from-pseudo-label\"", ",", "type", "=", "str", ",", "choices", "=", "[", "'y'", ",", "'n'", "]", ",", "help", "=", "'Pseudo-labeled dataset path.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--pseudo-label-path\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Specify if overriding the path stored in last_pl_path.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pseudo-label-strategy\"", ",", "type", "=", "str", ",", "choices", "=", "[", "\"recall\"", ",", "\"sum_log_logits\"", "]", ",", "default", "=", "\"recall\"", ",", "help", "=", "\"Pseudo-label filtering strategy.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sum-log-logits-threshold\"", ",", "type", "=", "float", ",", "default", "=", "-", "0.1", ",", "help", "=", "\"Threshold for sum log logits pseudo-labeling selection.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--iteration\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Iteration if training in a loop.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label-unlabeled-set\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'Use unlabeled dataset for pseudo-labeling.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--filter-unlabeled-by-ratio\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Max ratio of unlabeled snippet to summary, -1 indicates no filtering.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sll-human-threshold-window\"", ",", "nargs", "=", "2", ",", "type", "=", "float", ",", "default", "=", "[", "0.0", ",", "0.0", "]", ",", "help", "=", "\"Range of sll threshold \"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "\"Dropout of model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sparse-training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Use FISH sparse training mask for PEGASUS.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.medical-summarization-ML4H-2021.train_pegasus.get_previous_model": [[114, 121], ["os.path.exists", "os.path.join", "FileNotFoundError", "open", "f.read", "os.path.join", "os.path.join", "os.getcwd"], "function", ["None"], ["", "def", "get_previous_model", "(", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"previous_model_checkpoint.txt\"", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"previous_model_checkpoint.txt\"", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "past_exp_name", "=", "f", ".", "read", "(", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"checkpoints\"", ",", "past_exp_name", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\"Previous model path not found.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.medical-summarization-ML4H-2021.train_pegasus.run_experiment": [[122, 293], ["torch.utils.tensorboard.SummaryWriter", "train_pegasus.prepare_dataset", "transformers.PegasusConfig.from_pretrained", "transformers.PegasusForConditionalGeneration.from_pretrained().to", "summary.pegasus.Trainer.train", "summary.pegasus.Trainer.evaluate", "set", "prepare_unl_dataset.subset", "summary.pegasus.Trainer.decode", "os.path.exists", "print", "wandb.init", "torch.cuda.is_available", "torch.cuda.is_available", "summary.utils.data.datasets.SnippetDataset.from_json_file", "SnippetDataset.from_json_file.clean", "print", "print", "len", "print", "SnippetDataset.from_json_file.get_source_json", "wandb.log", "train_pegasus.get_previous_model", "print", "summary.pegasus.Trainer", "train_pegasus.prepare_unl_dataset", "train_pegasus.prepare_dataset", "os.path.join", "os.remove", "open", "f.write", "os.remove", "open", "f.write", "os.path.join", "os.path.join", "os.path.isfile", "summary.utils.data.filters.SnippetFilter", "SnippetDataset.from_json_file.apply_snippet_filter", "train_dataset.add", "summary.utils.data.datasets.SnippetDataset.from_json_file", "SnippetDataset.from_json_file.clean", "SnippetDataset.from_json_file.get_ids_in_confidence_window", "train_pegasus.prepare_dataset", "len", "print", "wandb.log", "transformers.PegasusForConditionalGeneration.from_pretrained", "ids_to_pseudo_label.append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.getcwd", "vars", "open", "f.read", "summary.utils.data.filters.SnippetFilter", "SnippetDataset.from_json_file.apply_snippet_filter", "print", "train_dataset.add", "SnippetDataset.from_json_file.add", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.prepare_dataset", "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.train", "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.evaluate", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.subset", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder.decode", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.from_json_file", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.clean", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.get_source_json", "home.repos.pwc.inspect_result.curai_curai-research.medical-summarization-ML4H-2021.train_pegasus.get_previous_model", "home.repos.pwc.inspect_result.curai_curai-research.medical-summarization-ML4H-2021.train_pegasus.prepare_unl_dataset", "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.prepare_dataset", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.apply_snippet_filter", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.add", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.from_json_file", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.clean", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.get_ids_in_confidence_window", "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.prepare_dataset", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.apply_snippet_filter", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.add", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.add"], ["", "", "def", "run_experiment", "(", "args", ",", "experiment_name", ")", ":", "\n", "    ", "if", "args", ".", "track", ":", "\n", "        ", "import", "wandb", "\n", "run", "=", "wandb", ".", "init", "(", "\n", "project", "=", "'<project'", ",", "\n", "entity", "=", "\"<your_wandb_entity>\"", ",", "\n", "sync_tensorboard", "=", "True", ",", "\n", "config", "=", "vars", "(", "args", ")", ",", "\n", "name", "=", "experiment_name", ",", "\n", "save_code", "=", "True", ")", "\n", "\n", "", "writer", "=", "SummaryWriter", "(", "f\"runs/{experiment_name}\"", ")", "\n", "\n", "# Initialize Model", "\n", "device", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "train_dataset", ",", "test_dataset", "=", "prepare_dataset", "(", "samples", "=", "args", ".", "num_samples", ",", "seed", "=", "args", ".", "seed", ")", "\n", "filtered_dataset_json", "=", "None", "\n", "\n", "if", "args", ".", "from_pseudo_label", "==", "\"y\"", ":", "\n", "\n", "        ", "to_log", "=", "{", "}", "\n", "\n", "# Read in last pseudo-labeled dataset if overriding path is not path provided.", "\n", "if", "args", ".", "pseudo_label_path", "==", "\"\"", ":", "\n", "            ", "path_to_read", "=", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"last_pl_path.txt\"", ")", "\n", "with", "open", "(", "path_to_read", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "pseudo_label_path", "=", "f", ".", "read", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "assert", "os", ".", "path", ".", "isfile", "(", "args", ".", "pseudo_label_path", ")", ",", "f\"Provided pseudo label path {args.pseudo_label_path} is not valid. \"", "\n", "pseudo_label_path", "=", "args", ".", "pseudo_label_path", "\n", "to_log", "[", "\"pseudo-label-path\"", "]", "=", "pseudo_label_path", "\n", "\n", "", "dataset", "=", "SnippetDataset", ".", "from_json_file", "(", "pseudo_label_path", ",", "is_pseudo_label", "=", "True", ")", "\n", "dataset", ".", "clean", "(", "filter_by_ratio", "=", "args", ".", "filter_unlabeled_by_ratio", ")", "\n", "\n", "if", "args", ".", "pseudo_label_strategy", "==", "\"recall\"", ":", "\n", "# We filter out samples that have a concept and affirmation recall lower than 1.", "\n", "            ", "concept_recall_threshold", "=", "1.0", "\n", "affirmation_recall_threshold", "=", "1.0", "\n", "snippet_filter", "=", "SnippetFilter", "(", "\n", "concept_recall_threshold", "=", "concept_recall_threshold", ",", "\n", "affirmation_recall_threshold", "=", "affirmation_recall_threshold", ",", "\n", "keep_fixed", "=", "True", ")", "\n", "\n", "dataset", ".", "apply_snippet_filter", "(", "snippet_filter", ")", "\n", "assert", "dataset", "[", "dataset", ".", "snippet_ids", "[", "-", "1", "]", "]", ".", "concept_recall", ">=", "concept_recall_threshold", ",", "\"Sample not below threshold.\"", "\n", "assert", "dataset", "[", "dataset", ".", "snippet_ids", "[", "-", "1", "]", "]", ".", "affirmation_recall", ">=", "affirmation_recall_threshold", ",", "\"Sample not below threshold.\"", "\n", "\n", "", "elif", "args", ".", "pseudo_label_strategy", "==", "\"sum_log_logits\"", ":", "\n", "\n", "            ", "sum_log_logits_threshold", "=", "args", ".", "sum_log_logits_threshold", "\n", "snippet_filter", "=", "SnippetFilter", "(", "\n", "sum_log_logits_threshold", "=", "sum_log_logits_threshold", ",", "\n", "keep_fixed", "=", "True", ",", "\n", ")", "\n", "\n", "dataset", ".", "apply_snippet_filter", "(", "snippet_filter", ")", "\n", "print", "(", "dataset", "[", "dataset", ".", "snippet_ids", "[", "-", "1", "]", "]", ".", "predicted_summary_sum_log_logits", ")", "\n", "# assert dataset[dataset.snippet_ids[-1]].predicted_summary_sum_log_logits >= sum_log_logits_threshold", "\n", "\n", "", "print", "(", "f\"Length of train dataset before adding ids: {len(train_dataset)}.\"", ")", "\n", "print", "(", "f\"Adding {len(dataset)} ids to training set.\"", ")", "\n", "\n", "for", "snippet", "in", "dataset", ":", "\n", "            ", "train_dataset", ".", "add", "(", "snippet", ")", "\n", "\n", "", "to_log", "[", "\"num_pseudo_labeled_pts\"", "]", "=", "len", "(", "dataset", ")", "\n", "\n", "if", "not", "args", ".", "label_unlabeled_set", "and", "args", ".", "sll_human_threshold_window", "[", "1", "]", "is", "not", "0.0", ":", "\n", "            ", "hl_dataset", "=", "SnippetDataset", ".", "from_json_file", "(", "pseudo_label_path", ",", "is_pseudo_label", "=", "True", ")", "\n", "hl_dataset", ".", "clean", "(", "filter_by_ratio", "=", "args", ".", "filter_unlabeled_by_ratio", ")", "\n", "\n", "low", ",", "high", "=", "args", ".", "sll_human_threshold_window", "\n", "ids_to_add", "=", "hl_dataset", ".", "get_ids_in_confidence_window", "(", "low", ",", "high", ")", "\n", "full_dataset", ",", "_", "=", "prepare_dataset", "(", "samples", "=", "TRAIN_DATASET_MAX_SIZE", ",", "seed", "=", "args", ".", "seed", ")", "\n", "\n", "to_log", "[", "\"num_human_labeled_pts\"", "]", "=", "len", "(", "ids_to_add", ")", "\n", "\n", "for", "id", "in", "ids_to_add", ":", "\n", "\n", "                ", "train_dataset", ".", "add", "(", "full_dataset", "[", "id", "]", ")", "\n", "dataset", ".", "add", "(", "full_dataset", "[", "id", "]", ")", "\n", "\n", "", "print", "(", "f\"Adding {len(ids_to_add)} human labels to training set.\"", ")", "\n", "\n", "", "else", ":", "\n", "            ", "to_log", "[", "\"num_human_labeled_pts\"", "]", "=", "0", "\n", "\n", "", "if", "args", ".", "track", ":", "\n", "            ", "wandb", ".", "log", "(", "to_log", ")", "\n", "\n", "", "print", "(", "f\"After filtering, total train dataset is of size: {len(train_dataset)}\"", ")", "\n", "\n", "filtered_dataset_json", "=", "dataset", ".", "get_source_json", "(", "keep_only_existing_ids", "=", "True", ")", "\n", "\n", "for", "snippet_id", "in", "filtered_dataset_json", ":", "\n", "            ", "filtered_dataset_json", "[", "snippet_id", "]", "[", "\"fixed\"", "]", "=", "\"True\"", "\n", "\n", "", "", "if", "args", ".", "track", ":", "\n", "        ", "wandb", ".", "log", "(", "{", "\n", "\"num_training_pts\"", ":", "len", "(", "train_dataset", ")", ",", "\n", "}", ")", "\n", "\n", "", "model_name_or_path", "=", "get_previous_model", "(", ")", "if", "args", ".", "pretrained_model", "==", "\"from_previous\"", "else", "args", ".", "pretrained_model", "\n", "config", "=", "PegasusConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", "=", "model_name_or_path", ",", "dropout", "=", "args", ".", "dropout", ")", "\n", "model", "=", "PegasusForConditionalGeneration", ".", "from_pretrained", "(", "pretrained_model_name_or_path", "=", "model_name_or_path", ",", "config", "=", "config", ")", ".", "to", "(", "device", ")", "\n", "\n", "while", "len", "(", "train_dataset", ")", "*", "args", ".", "epochs", "/", "args", ".", "batch_size", "<", "200", ":", "\n", "        ", "args", ".", "epochs", "+=", "1", "\n", "print", "(", "f\"Increasing total number of epochs to {args.epochs} to ensure at least 200 steps. Curr: {len(train_dataset) * args.epochs / args.batch_size}, {len(train_dataset)}\"", ")", "\n", "\n", "", "if", "args", ".", "sparse_training", ":", "\n", "# Brief attempt at incorporating sparse updating to regularize network.", "\n", "        ", "pass", "\n", "# trainer = SparseUpdateTrainer(snippet_dataset=train_dataset, test_dataset=test_dataset, model=model, batch_size=args.batch_size,", "\n", "#         accumulate_grad_batches=args.accumulate_grad_batches, n_epochs=args.epochs, device=device, experiment_name=experiment_name, ", "\n", "#         writer=writer, is_tracking=args.track)", "\n", "# data_collator = SummaryCollate(trainer.tokenizer, trainer.source_max_length,", "\n", "#     trainer.target_max_length)", "\n", "# data_loader = data.DataLoader(trainer.dataset, batch_size=1,", "\n", "#     num_workers=trainer.num_workers, collate_fn=data_collator, shuffle=False,", "\n", "#     pin_memory=True)", "\n", "# mask = create_mask_gradient(model=trainer.model, train_dataset=data_loader, data_collator=data_collator, num_workers=trainer.num_workers, ", "\n", "#         num_samples=args.num_samples, keep_ratio=0.005, sample_type='label', grad_type='square')", "\n", "# trainer.mask = mask", "\n", "\n", "", "else", ":", "\n", "        ", "trainer", "=", "Trainer", "(", "snippet_dataset", "=", "train_dataset", ",", "test_dataset", "=", "test_dataset", ",", "model", "=", "model", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "accumulate_grad_batches", "=", "args", ".", "accumulate_grad_batches", ",", "n_epochs", "=", "args", ".", "epochs", ",", "device", "=", "device", ",", "experiment_name", "=", "experiment_name", ",", "\n", "writer", "=", "writer", ",", "is_tracking", "=", "args", ".", "track", ")", "\n", "\n", "\n", "", "trainer", ".", "train", "(", "checkpoint_save_path", "=", "f\"checkpoints/{experiment_name}\"", ")", "\n", "\n", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "# Pseudo-Labeling - Label all samples from the full dataset that were not in the train dataset.", "\n", "if", "args", ".", "label_unlabeled_set", ":", "\n", "        ", "full_dataset", "=", "prepare_unl_dataset", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "full_dataset", ",", "_", "=", "prepare_dataset", "(", "samples", "=", "TRAIN_DATASET_MAX_SIZE", ",", "seed", "=", "args", ".", "seed", ")", "\n", "\n", "", "train_dataset_ids", "=", "set", "(", "train_dataset", ".", "snippet_ids", ")", "\n", "ids_to_pseudo_label", "=", "[", "]", "\n", "\n", "for", "snippet", "in", "full_dataset", ":", "\n", "        ", "if", "snippet", ".", "uid", "not", "in", "train_dataset_ids", ":", "\n", "            ", "ids_to_pseudo_label", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "\n", "", "", "pseudo_label_dataset", "=", "full_dataset", ".", "subset", "(", "ids_to_pseudo_label", ")", "\n", "pseudo_label_save_path", "=", "f\"results/pegasus/decoded_{experiment_name}.json\"", "\n", "trainer", ".", "decode", "(", "pseudo_label_save_path", ",", "dataset", "=", "pseudo_label_dataset", ",", "existing_labels", "=", "filtered_dataset_json", ")", "\n", "\n", "# Save current experiment name as past model.", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"previous_model_checkpoint.txt\"", ")", ")", ":", "\n", "        ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"previous_model_checkpoint.txt\"", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"previous_model_checkpoint.txt\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "experiment_name", ")", "\n", "\n", "# Remove existing file and replace with new pseudo-label dataset path.", "\n", "", "if", "args", ".", "from_pseudo_label", "==", "\"y\"", ":", "\n", "        ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"last_pl_path.txt\"", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "ROOT", ",", "\"last_pl_path.txt\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "pseudo_label_save_path", ")", "\n", "\n", "", "print", "(", "\"Saved pseudo-labels to:\"", ",", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"last_pl_path.txt\"", ")", ")", "\n", "\n", "return", "pseudo_label_save_path", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.metric_utils.get_common_results_among_groups": [[4, 26], ["list", "print", "summary.utils.read_json", "all_datas.append", "summary.utils.read_json.items", "all_ids.append", "common_ids.intersection.intersection", "res_datas.append", "set", "summary.utils.subset_dict", "curr_ids.append", "len"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.read_json", "home.repos.pwc.inspect_result.curai_curai-research.utils.dict.subset_dict"], ["def", "get_common_results_among_groups", "(", "group_names", ")", ":", "\n", "    ", "all_datas", ",", "all_ids", "=", "[", "]", ",", "[", "]", "\n", "for", "group_name", "in", "group_names", ":", "\n", "        ", "data", "=", "read_json", "(", "f\"results/pegasus/{group_name}.json\"", ")", "\n", "all_datas", ".", "append", "(", "data", ")", "\n", "\n", "curr_ids", "=", "[", "]", "\n", "for", "snippet_id", ",", "data_pt", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "if", "\"predicted_summary\"", "in", "data_pt", ":", "\n", "               ", "curr_ids", ".", "append", "(", "snippet_id", ")", "\n", "", "", "all_ids", ".", "append", "(", "set", "(", "curr_ids", ")", ")", "\n", "\n", "", "common_ids", "=", "all_ids", "[", "0", "]", "\n", "for", "curr_ids", "in", "all_ids", ":", "\n", "        ", "common_ids", "=", "common_ids", ".", "intersection", "(", "curr_ids", ")", "\n", "", "common_ids", "=", "list", "(", "common_ids", ")", "\n", "print", "(", "f\"{len(common_ids)} in evaluation set\"", ")", "\n", "\n", "res_datas", "=", "[", "]", "\n", "for", "curr_data", "in", "all_datas", ":", "\n", "        ", "res_datas", ".", "append", "(", "subset_dict", "(", "curr_data", ",", "common_ids", ")", ")", "\n", "", "return", "res_datas", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.metric_utils.compute_metrics_for_all_groups": [[27, 43], ["zip", "results.items", "metrics.metrics_report.MetricsReport", "metrics.metrics_report.MetricsReport", "metrics.metrics_report.MetricsReport.to_json", "gold_summaries.append", "pred_summaries.append", "metrics.metrics_report.MetricsReport.to_json", "metrics.metrics_report.MetricsReport.to_json"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json", "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json", "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json"], ["", "def", "compute_metrics_for_all_groups", "(", "all_results", ",", "group_names", ",", "tag", "=", "\"\"", ")", ":", "\n", "    ", "auto_metrics", "=", "{", "}", "\n", "gold_metrics", "=", "{", "}", "\n", "for", "group", ",", "results", "in", "zip", "(", "group_names", ",", "all_results", ")", ":", "\n", "        ", "gold_summaries", ",", "pred_summaries", "=", "[", "]", ",", "[", "]", "\n", "for", "_", ",", "data_pt", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "gold_summary", "=", "data_pt", "[", "\"summary\"", "]", "\n", "pred_summary", "=", "data_pt", "[", "\"predicted_summary\"", "]", "\n", "\n", "gold_summaries", ".", "append", "(", "gold_summary", ")", "\n", "pred_summaries", ".", "append", "(", "pred_summary", ")", "\n", "", "report", "=", "MetricsReport", "(", "gold_summaries", ",", "pred_summaries", ")", "\n", "gold_report", "=", "MetricsReport", "(", "gold_summaries", ",", "gold_summaries", ")", "\n", "auto_metrics", "[", "group", "]", "=", "report", ".", "to_json", "(", "tag", "=", "tag", ")", "\n", "gold_metrics", "[", "group", "]", "=", "gold_report", ".", "to_json", "(", "tag", "=", "f\"{tag}.gold\"", ")", "if", "tag", "is", "not", "\"\"", "else", "gold_report", ".", "to_json", "(", "tag", "=", "\"gold\"", ")", "\n", "", "return", "auto_metrics", ",", "gold_metrics", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.utils.concept_affirmation_tagger.ConceptAffirmationTagger.__init__": [[11, 13], ["NegationTagger"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "negation_tagger", "=", "NegationTagger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.concept_affirmation_tagger.ConceptAffirmationTagger.get_affirmations": [[14, 36], ["concept_affirmation_tagger.ConceptAffirmationTagger.negation_tagger.get_negations"], "methods", ["None"], ["", "def", "get_affirmations", "(", "self", ",", "text", ",", "concepts", ")", ":", "\n", "        ", "\"\"\" \n        Entity linking on a given text\n\n        Parameters\n        ----------\n        text : str\n        concepts: list\n            List of knowledge base concepts\n\n        Returns\n        -------\n        affirmations : dict\n            Dict mapping concept to its negation in text\n        \"\"\"", "\n", "affirmations", "=", "{", "}", "\n", "for", "affirmation", "in", "self", ".", "negation_tagger", ".", "get_negations", "(", "text", ",", "\n", "concepts", ")", "[", "0", "]", ":", "\n", "            ", "concept", "=", "affirmation", "[", "\"name\"", "]", "\n", "negation", "=", "affirmation", "[", "\"negation\"", "]", "\n", "affirmations", "[", "concept", "]", "=", "negation", "\n", "", "return", "affirmations", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.utils.kb_concept_recognizer.KBConceptRecognizer.__init__": [[9, 11], ["EntityRecognizer"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "entity_recognizer", "=", "EntityRecognizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.kb_concept_recognizer.KBConceptRecognizer.get_concepts": [[12, 30], ["kb_concept_recognizer.KBConceptRecognizer.entity_recognizer.extract_entities"], "methods", ["None"], ["", "def", "get_concepts", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" \n        Entity linking on a given text\n\n        Parameters\n        ----------\n        text : str\n\n        Returns\n        -------\n        concepts : list\n            List of recognized concepts \n        \"\"\"", "\n", "concepts", "=", "[", "\n", "x", ".", "matched_name", "\n", "for", "x", "in", "self", ".", "entity_recognizer", ".", "extract_entities", "(", "text", ")", "\n", "]", "\n", "return", "concepts", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.utils.dict.AttrDict.__init__": [[5, 19], ["dict.__init__", "dict.AttrDict.keys", "dict.AttrDict.__init__.from_nested_dict"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "def", "from_nested_dict", "(", "data", ")", ":", "\n", "            ", "\"\"\"Construct nested AttrDicts from nested dictionaries\"\"\"", "\n", "if", "not", "isinstance", "(", "data", ",", "dict", ")", ":", "\n", "                ", "return", "data", "\n", "", "else", ":", "\n", "                ", "return", "AttrDict", "(", "{", "key", ":", "from_nested_dict", "(", "data", "[", "key", "]", ")", "\n", "for", "key", "in", "data", "}", ")", "\n", "\n", "", "", "super", "(", "AttrDict", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "__dict__", "=", "self", "\n", "\n", "for", "key", "in", "self", ".", "keys", "(", ")", ":", "\n", "            ", "self", "[", "key", "]", "=", "from_nested_dict", "(", "self", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.dict.intersect_freq_dicts": [[21, 31], ["list", "list", "min", "dict1.keys", "dict2.keys"], "function", ["None"], ["", "", "", "def", "intersect_freq_dicts", "(", "dict1", ",", "dict2", ")", ":", "\n", "    ", "\"\"\"Take the intersection of two frequency\n    dictionaries\"\"\"", "\n", "intersect_dict", "=", "{", "}", "\n", "all_keys", "=", "list", "(", "dict1", ".", "keys", "(", ")", ")", "+", "list", "(", "dict2", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "all_keys", ":", "\n", "        ", "if", "key", "not", "in", "dict1", "or", "key", "not", "in", "dict2", ":", "\n", "            ", "continue", "\n", "", "intersect_dict", "[", "key", "]", "=", "min", "(", "dict1", "[", "key", "]", ",", "dict2", "[", "key", "]", ")", "\n", "", "return", "intersect_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.dict.subset_dict": [[32, 36], ["None"], "function", ["None"], ["", "def", "subset_dict", "(", "all_dict", ",", "keys_subset", ")", ":", "\n", "    ", "\"\"\"Take a subset of dict given keys\"\"\"", "\n", "subset", "=", "{", "k", ":", "all_dict", "[", "k", "]", "for", "k", "in", "keys_subset", "}", "\n", "return", "subset", "\n", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.utils.time.get_est_time": [[5, 9], ["pytz.timezone", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "get_est_time", "(", ")", ":", "\n", "    ", "tz", "=", "timezone", "(", "'America/New_York'", ")", "\n", "time", "=", "datetime", ".", "now", "(", "tz", ")", ".", "strftime", "(", "\"%m.%d.%Y-%I:%M%p\"", ")", "\n", "return", "time", "\n", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.read_json": [[5, 9], ["open", "json.load"], "function", ["None"], ["def", "read_json", "(", "json_file", ")", ":", "\n", "    ", "with", "open", "(", "json_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.write_json": [[10, 16], ["pathlib.Path", "dir_name.mkdir", "open", "json.dump"], "function", ["None"], ["", "def", "write_json", "(", "data", ",", "out_file", ")", ":", "\n", "    ", "out_file", "=", "Path", "(", "out_file", ")", "\n", "dir_name", "=", "out_file", ".", "parents", "[", "0", "]", "\n", "dir_name", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "out_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "data", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.convergence.Convergence.__init__": [[18, 27], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "patience", "=", "7", ",", "verbose", "=", "False", ",", "tol", "=", "0", ",", "minimize", "=", "True", ")", ":", "\n", "        ", "self", ".", "patience", "=", "patience", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "minimize", "=", "minimize", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "best_score", "=", "None", "\n", "self", ".", "best_ckpt", "=", "None", "\n", "self", ".", "stop", "=", "False", "\n", "self", ".", "tol", "=", "tol", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.utils.convergence.Convergence.__call__": [[28, 51], ["print"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "conv_metric", ",", "ckpt", ")", ":", "\n", "        ", "\"\"\"Updates stop member variable based on convergence\n\n        Parameters\n        ----------\n        conv_metric : float\n            Metric which convergence is based upon\n        \"\"\"", "\n", "score", "=", "conv_metric", "if", "not", "self", ".", "minimize", "else", "-", "conv_metric", "\n", "\n", "if", "self", ".", "best_score", "is", "None", ":", "\n", "            ", "self", ".", "best_score", "=", "score", "\n", "self", ".", "best_ckpt", "=", "ckpt", "\n", "", "elif", "score", "<", "self", ".", "best_score", "+", "self", ".", "tol", ":", "\n", "            ", "self", ".", "counter", "+=", "1", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f'Stopping counter: {self.counter} out of {self.patience}'", ")", "\n", "", "if", "self", ".", "counter", ">=", "self", ".", "patience", ":", "\n", "                ", "self", ".", "stop", "=", "True", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "best_score", "=", "score", "\n", "self", ".", "best_ckpt", "=", "ckpt", "\n", "self", ".", "counter", "=", "0", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.__init__": [[21, 31], ["snippet_dataset.SnippetDataset.__init__", "set"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.__init__"], ["def", "__init__", "(", "self", ",", "chats", ",", "classify_history_gathering", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "[", "snippet", "for", "chat", "in", "chats", "\n", "for", "snippet", "in", "chat", ".", "snippets", "]", ",", "classify_history_gathering", ")", "\n", "\n", "self", ".", "chat_ids", "=", "set", "(", "[", "chat", ".", "uid", "for", "chat", "in", "chats", "]", ")", "\n", "\n", "self", ".", "_chats", "=", "chats", "\n", "self", ".", "_chats_data", "=", "{", "}", "\n", "for", "chat", "in", "chats", ":", "\n", "            ", "self", ".", "_chats_data", "[", "chat", ".", "uid", "]", "=", "chat", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.add": [[33, 38], ["chat_dataset.ChatDataset.chat_ids.add", "super().add"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.add", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.add"], ["", "", "def", "add", "(", "self", ",", "chat", ")", ":", "\n", "        ", "for", "snippet", "in", "chat", ".", "snippets", ":", "\n", "            ", "super", "(", ")", ".", "add", "(", "snippet", ")", "\n", "", "self", ".", "chat_ids", ".", "add", "(", "chat", ".", "uid", ")", "\n", "self", ".", "_chats_data", "[", "chat", ".", "uid", "]", "=", "chat", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.remove": [[39, 45], ["chat_dataset.ChatDataset._chats.remove", "chat_dataset.ChatDataset.chat_ids.remove", "super().remove"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove"], ["", "def", "remove", "(", "self", ",", "chat", ")", ":", "\n", "        ", "for", "snippet", "in", "chat", ".", "snippets", ":", "\n", "            ", "super", "(", ")", ".", "remove", "(", "snippet", ")", "\n", "", "self", ".", "_chats", ".", "remove", "(", "chat", ")", "\n", "self", ".", "chat_ids", ".", "remove", "(", "chat", ".", "uid", ")", "\n", "del", "self", ".", "_chats_data", "[", "chat", ".", "uid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.subset": [[46, 51], ["chat_dataset.ChatDataset", "chats.append"], "methods", ["None"], ["", "def", "subset", "(", "self", ",", "chat_ids", ")", ":", "\n", "        ", "chats", "=", "[", "]", "\n", "for", "chat_id", "in", "chat_ids", ":", "\n", "            ", "chats", ".", "append", "(", "self", ".", "_chats_data", "[", "chat_id", "]", ")", "\n", "", "return", "ChatDataset", "(", "chats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.to_json": [[52, 62], ["chat_dataset.ChatDataset._chats_data.items", "super().to_json", "chat_dataset.ChatDataset.update", "chat_dataset.ChatDataset._prepend_rfes_to_chats_snippets", "chat.to_json"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json", "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json"], ["", "def", "to_json", "(", "self", ",", "chat_format", "=", "False", ",", "rfes_as_snippet", "=", "False", ")", ":", "\n", "        ", "if", "chat_format", ":", "\n", "            ", "res", "=", "{", "}", "\n", "for", "chat_id", ",", "chat", "in", "self", ".", "_chats_data", ".", "items", "(", ")", ":", "\n", "                ", "res", ".", "update", "(", "chat", ".", "to_json", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "res", "=", "super", "(", ")", ".", "to_json", "(", ")", "\n", "if", "rfes_as_snippet", ":", "\n", "                ", "res", "=", "self", ".", "_prepend_rfes_to_chats_snippets", "(", "res", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.__len__": [[64, 66], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_chats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.__getitem__": [[67, 77], ["lookup_id.split"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "lookup_id", ")", ":", "\n", "        ", "if", "Text", ".", "UNDERSCORE", "in", "lookup_id", ":", "\n", "            ", "chat_id", ",", "snippet_id", "=", "lookup_id", ".", "split", "(", "Text", ".", "UNDERSCORE", ")", "\n", "if", "snippet_id", "==", "\"rfe\"", ":", "\n", "                ", "res", "=", "self", ".", "_chats_data", "[", "chat_id", "]", ".", "reason_for_encounter", "\n", "", "else", ":", "\n", "                ", "res", "=", "self", ".", "_snippets_data", "[", "lookup_id", "]", "\n", "", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "_chats_data", "[", "lookup_id", "]", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.__iter__": [[78, 81], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "chat", "in", "self", ".", "_chats", ":", "\n", "            ", "yield", "chat", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset.from_json_file": [[83, 91], ["file_io.read_json", "cls", "chat_dataset.ChatDataset._read_chat_formatted_json", "chat_dataset.ChatDataset._read_snippet_formatted_json"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.read_json", "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset._read_chat_formatted_json", "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset._read_snippet_formatted_json"], ["", "", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ",", "chat_format", "=", "False", ")", ":", "\n", "        ", "data", "=", "read_json", "(", "json_file", ")", "\n", "if", "chat_format", ":", "\n", "            ", "chats", "=", "self", ".", "_read_chat_formatted_json", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "chats", "=", "self", ".", "_read_snippet_formatted_json", "(", "data", ")", "\n", "", "return", "cls", "(", "chats", "=", "chats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset._read_chat_formatted_json": [[93, 106], ["data.items", "chat_data_pt.items", "chats.append", "types.chat.Chat.from_snippets", "snippets.append", "helpers.read_json_snippet"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.from_snippets", "home.repos.pwc.inspect_result.curai_curai-research.datasets.helpers.read_json_snippet"], ["", "def", "_read_chat_formatted_json", "(", "self", ",", "chats_json", ")", ":", "\n", "        ", "chats", "=", "[", "]", "\n", "for", "chat_id", ",", "chat_data_pt", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "snippets", "=", "[", "]", "\n", "for", "snippet_id", ",", "snippet_data_pt", "in", "chat_data_pt", ".", "items", "(", ")", ":", "\n", "                ", "if", "snippet_id", "==", "\"reason_for_encounter\"", ":", "\n", "                    ", "rfe", "=", "snippet_data_pt", "\n", "", "else", ":", "\n", "                    ", "snippets", ".", "append", "(", "read_json_snippet", "(", "snippet_id", ",", "\n", "snippet_data_pt", ")", ")", "\n", "", "", "chats", ".", "append", "(", "Chat", ".", "from_snippets", "(", "uid", "=", "chat_id", ",", "\n", "reason_for_encounter", "=", "rfe", ",", "snippets", "=", "snippets", ")", ")", "\n", "", "return", "chats", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.chat_dataset.ChatDataset._read_snippet_formatted_json": [[107, 124], ["data.items", "chats.append", "snippet_id.split", "types.chat.Chat.from_snippets", "snippets.append", "chats.append", "helpers.read_json_snippet", "types.chat.Chat.from_snippets"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.from_snippets", "home.repos.pwc.inspect_result.curai_curai-research.datasets.helpers.read_json_snippet", "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.from_snippets"], ["", "def", "_read_snippet_formatted_json", "(", "self", ",", "snippets_json", ")", ":", "\n", "        ", "chats", ",", "snippets", "=", "[", "]", ",", "[", "]", "\n", "prev_chat_id", "=", "None", "\n", "for", "snippet_id", ",", "data_pt", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "chat_id", ",", "snippet_num", "=", "snippet_id", ".", "split", "(", "Text", ".", "UNDERSCORE", ")", "\n", "if", "snippet_num", "==", "\"rfe\"", ":", "\n", "                ", "if", "prev_chat_id", "is", "not", "None", ":", "\n", "                    ", "chats", ".", "append", "(", "Chat", ".", "from_snippets", "(", "uid", "=", "chat_id", ",", "\n", "reason_for_encounter", "=", "rfe", ",", "snippets", "=", "snippets", ")", ")", "\n", "snippets", "=", "[", "]", "\n", "", "rfe", "=", "data_pt", "\n", "", "else", ":", "\n", "                ", "snippets", ".", "append", "(", "read_json_snippet", "(", "snippet_id", ",", "data_pt", ")", ")", "\n", "", "prev_chat_id", "=", "chat_id", "\n", "", "chats", ".", "append", "(", "Chat", ".", "from_snippets", "(", "uid", "=", "chat_id", ",", "\n", "reason_for_encounter", "=", "rfe", ",", "snippets", "=", "snippets", ")", ")", "\n", "return", "chats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.__init__": [[28, 35], ["snippet_dataset.SnippetDataset._filter_empty_summaries_with_no_tags"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_empty_summaries_with_no_tags"], ["def", "__init__", "(", "self", ",", "snippets", ",", "source_files", "=", "None", ")", ":", "\n", "        ", "self", ".", "_snippets", "=", "self", ".", "_filter_empty_summaries_with_no_tags", "(", "snippets", ")", "\n", "self", ".", "snippet_ids", "=", "[", "snippet", ".", "uid", "for", "snippet", "in", "self", ".", "_snippets", "]", "\n", "self", ".", "source_files", "=", "source_files", "\n", "self", ".", "_snippets_data", "=", "{", "}", "\n", "for", "snippet", "in", "self", ".", "_snippets", ":", "\n", "            ", "self", ".", "_snippets_data", "[", "snippet", ".", "uid", "]", "=", "snippet", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.add": [[39, 43], ["snippet_dataset.SnippetDataset._snippets.append", "snippet_dataset.SnippetDataset.snippet_ids.append"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "snippet", ")", ":", "\n", "        ", "self", ".", "_snippets", ".", "append", "(", "snippet", ")", "\n", "self", ".", "snippet_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "self", ".", "_snippets_data", "[", "snippet", ".", "uid", "]", "=", "snippet", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove": [[44, 48], ["snippet_dataset.SnippetDataset._snippets.remove", "snippet_dataset.SnippetDataset.snippet_ids.remove"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove"], ["", "def", "remove", "(", "self", ",", "snippet", ")", ":", "\n", "        ", "self", ".", "_snippets", ".", "remove", "(", "snippet", ")", "\n", "self", ".", "snippet_ids", ".", "remove", "(", "snippet", ".", "uid", ")", "\n", "del", "self", ".", "_snippets_data", "[", "snippet", ".", "uid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.subset": [[49, 54], ["snippet_dataset.SnippetDataset", "snippets.append"], "methods", ["None"], ["", "def", "subset", "(", "self", ",", "snippet_ids", ")", ":", "\n", "        ", "snippets", "=", "[", "]", "\n", "for", "snippet_id", "in", "snippet_ids", ":", "\n", "            ", "snippets", ".", "append", "(", "self", ".", "_snippets_data", "[", "snippet_id", "]", ")", "\n", "", "return", "SnippetDataset", "(", "snippets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.apply_snippet_filter": [[55, 105], ["set", "print", "snippet_dataset.SnippetDataset.get_fixed_snippets", "set", "snippet_dataset.SnippetDataset.subset", "print", "list.union", "list", "snippet_dataset.SnippetDataset.remove", "snippet_dataset.SnippetDataset.remove", "snippet_dataset.SnippetDataset._filter_sum_log_logits_threshold", "set", "snippet_dataset.SnippetDataset.add", "snippet_dataset.SnippetDataset._filter_affirmation_recall_threshold", "set", "len", "snippet_dataset.SnippetDataset._filter_concept_recall_threshold", "snippet_dataset.SnippetDataset._filter_only_speaker", "snippet_dataset.SnippetDataset._filter_response_types", "snippet_dataset.SnippetDataset._filter_tags", "snippet_dataset.SnippetDataset._filter_length", "snippet_dataset.SnippetDataset._filter_source"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.get_fixed_snippets", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.subset", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_sum_log_logits_threshold", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.add", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_affirmation_recall_threshold", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_concept_recall_threshold", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_only_speaker", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_response_types", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_tags", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_length", "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_source"], ["", "def", "apply_snippet_filter", "(", "self", ",", "snippet_filter", ",", "remove", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Applies a SnippetFilter\n\n        Parameters\n        ----------\n        snippet_filter : SnippetFilter\n        remove : bool\n            Whether to remove or keep things specified in\n            `snippet_filter`\n        \"\"\"", "\n", "if", "snippet_filter", ".", "keep_fixed", ":", "\n", "            ", "snippets_to_keep", "=", "self", ".", "get_fixed_snippets", "(", ")", "\n", "ids_to_keep", "=", "set", "(", "[", "snippet", ".", "uid", "for", "snippet", "in", "snippets_to_keep", "]", ")", "\n", "fixed_snippet_dataset", "=", "self", ".", "subset", "(", "ids_to_keep", ")", "\n", "\n", "for", "id", "in", "ids_to_keep", ":", "\n", "                ", "self", ".", "remove", "(", "self", ".", "_snippets_data", "[", "id", "]", ")", "\n", "", "print", "(", "f\"Number of fixed Ids: {len(ids_to_keep)}\"", ")", "\n", "\n", "", "else", ":", "\n", "            ", "ids_to_keep", "=", "[", "]", "\n", "\n", "", "bad_snippet_ids", "=", "set", "(", "\n", "self", ".", "_filter_length", "(", "snippet_filter", ".", "max_num_turns", ")", "+", "\n", "self", ".", "_filter_source", "(", "snippet_filter", ".", "source", ")", "+", "\n", "self", ".", "_filter_tags", "(", "snippet_filter", ".", "tags", ")", "+", "\n", "self", ".", "_filter_response_types", "(", "snippet_filter", ".", "response_types", ")", "+", "\n", "self", ".", "_filter_only_speaker", "(", "snippet_filter", ".", "only_speaker", ")", "+", "\n", "self", ".", "_filter_concept_recall_threshold", "(", "snippet_filter", ".", "concept_recall_threshold", ")", "+", "\n", "self", ".", "_filter_affirmation_recall_threshold", "(", "snippet_filter", ".", "affirmation_recall_threshold", ")", "+", "\n", "self", ".", "_filter_sum_log_logits_threshold", "(", "snippet_filter", ".", "sum_log_logits_threshold", ",", "ids_to_keep", ")", "\n", ")", "\n", "\n", "if", "snippet_filter", ".", "snippet_ids", "is", "not", "None", ":", "\n", "            ", "bad_snippet_ids", ".", "union", "(", "set", "(", "snippet_filter", ".", "snippet_ids", ")", ")", "\n", "\n", "", "if", "not", "remove", ":", "\n", "            ", "bad_snippet_ids", "=", "list", "(", "set", "(", "self", ".", "snippet_ids", ")", "-", "bad_snippet_ids", ")", "\n", "\n", "", "added", "=", "0", "\n", "for", "bad_id", "in", "bad_snippet_ids", ":", "\n", "            ", "self", ".", "remove", "(", "self", ".", "_snippets_data", "[", "bad_id", "]", ")", "\n", "added", "+=", "1", "\n", "", "print", "(", "f\"Removed {added} snippets.\"", ")", "\n", "\n", "# Re-add fixed snippets", "\n", "if", "snippet_filter", ".", "keep_fixed", ":", "\n", "            ", "for", "snippet", "in", "fixed_snippet_dataset", ":", "\n", "                ", "self", ".", "add", "(", "snippet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove_non_history_gathering": [[106, 111], ["snippet_dataset.SnippetDataset.snippet_ids.copy", "snippet_dataset.SnippetDataset.remove"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.remove"], ["", "", "", "def", "remove_non_history_gathering", "(", "self", ")", ":", "\n", "        ", "for", "snippet_id", "in", "self", ".", "snippet_ids", ".", "copy", "(", ")", ":", "\n", "            ", "snippet", "=", "self", ".", "_snippets_data", "[", "snippet_id", "]", "\n", "if", "not", "snippet", ".", "is_history_gathering", ":", "\n", "                ", "self", ".", "remove", "(", "snippet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.to_json": [[112, 117], ["snippet_dataset.SnippetDataset._snippets_data.items", "res.update", "snippet.to_json"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json"], ["", "", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "}", "\n", "for", "snippet_id", ",", "snippet", "in", "self", ".", "_snippets_data", ".", "items", "(", ")", ":", "\n", "            ", "res", ".", "update", "(", "snippet", ".", "to_json", "(", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.get_source_json": [[118, 137], ["json_data.update", "file_io.read_json", "snippet_ids_to_remove.append"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.read_json"], ["", "def", "get_source_json", "(", "self", ",", "keep_only_existing_ids", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "source_files", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "json_data", "=", "{", "}", "\n", "for", "source_file", "in", "self", ".", "source_files", ":", "\n", "            ", "json_data", ".", "update", "(", "read_json", "(", "source_file", ")", ")", "\n", "\n", "", "if", "keep_only_existing_ids", ":", "\n", "            ", "snippet_ids_to_remove", "=", "[", "]", "\n", "\n", "for", "snippet_id", "in", "json_data", ":", "\n", "                ", "if", "snippet_id", "not", "in", "self", ".", "snippet_ids", ":", "\n", "                    ", "snippet_ids_to_remove", ".", "append", "(", "snippet_id", ")", "\n", "\n", "", "", "for", "snippet_id", "in", "snippet_ids_to_remove", ":", "\n", "                ", "del", "json_data", "[", "snippet_id", "]", "\n", "\n", "", "", "return", "json_data", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.get_fixed_snippets": [[138, 141], ["snippet_dataset.SnippetDataset._snippets.copy"], "methods", ["None"], ["", "def", "get_fixed_snippets", "(", "self", ")", ":", "\n", "        ", "fixed_snippets", "=", "[", "snippet", "for", "snippet", "in", "self", ".", "_snippets", ".", "copy", "(", ")", "if", "snippet", ".", "fixed", "==", "\"True\"", "]", "\n", "return", "fixed_snippets", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.clean": [[142, 171], ["len", "numpy.unique", "set", "enumerate", "len", "print", "snippet_dataset.SnippetDataset.get_formatted", "numpy.asarray", "snippet_dataset.SnippetDataset.clean.to_remove"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.get_formatted"], ["", "def", "clean", "(", "self", ",", "filter_by_ratio", "=", "-", "1", ")", ":", "\n", "        ", "'''\n        Clean snippet dataset by running de-duplication on snippets, removing\n        snippets shorter than length 3.\n        '''", "\n", "\n", "uncleaned_dataset_length", "=", "len", "(", "self", ")", "\n", "\n", "formatted_snippets", "=", "[", "self", "[", "id", "]", ".", "get_formatted", "(", "text", "=", "True", ")", "for", "id", "in", "self", ".", "snippet_ids", "]", "\n", "_", ",", "unique_idxs", "=", "np", ".", "unique", "(", "np", ".", "asarray", "(", "formatted_snippets", ")", ",", "return_index", "=", "True", ")", "\n", "unique_idxs", "=", "set", "(", "unique_idxs", ")", "\n", "\n", "def", "to_remove", "(", "index", ",", "filter_by_ratio", "=", "-", "1", ")", "->", "bool", ":", "\n", "            ", "if", "index", "not", "in", "unique_idxs", ":", "\n", "                ", "return", "True", "\n", "", "elif", "len", "(", "formatted_snippets", "[", "index", "]", ".", "split", "(", "\" \"", ")", ")", "<=", "3", ":", "\n", "                ", "return", "True", "\n", "", "elif", "filter_by_ratio", ">", "0", "and", "len", "(", "formatted_snippets", "[", "index", "]", ")", ">=", "len", "(", "self", "[", "self", ".", "snippet_ids", "[", "index", "]", "]", ".", "summary", ")", "*", "filter_by_ratio", ":", "\n", "                ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n", "", "for", "index", ",", "id", "in", "enumerate", "(", "self", ".", "snippet_ids", ")", ":", "\n", "            ", "if", "to_remove", "(", "index", ",", "filter_by_ratio", "=", "filter_by_ratio", ")", ":", "\n", "                ", "self", ".", "remove", "(", "self", "[", "id", "]", ")", "\n", "\n", "", "", "cleaned_dataset_length", "=", "len", "(", "self", ")", "\n", "\n", "print", "(", "f\"Finished cleaning dataset. Old Length: {uncleaned_dataset_length}, New Length: {cleaned_dataset_length}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.get_ids_in_confidence_window": [[172, 198], ["snippets.sort", "int", "int", "print", "random.shuffle", "int", "len", "len", "len", "range", "len"], "methods", ["None"], ["", "def", "get_ids_in_confidence_window", "(", "self", ",", "low", ",", "high", ",", "is_descending", "=", "True", ")", ":", "\n", "        ", "'''\n        Given a percentile range, return the snippet ids in that percentile of confidence scores.\n        Default is to have confidence scores sorted in descending order.\n\n        Ex: low=0.05, high=0.20 - Returns snippets in between the top 5% and top 20% of confidence scores.\n        '''", "\n", "ids", "=", "[", "]", "\n", "snippets", "=", "[", "snippet", "for", "snippet", "in", "self", "if", "snippet", ".", "predicted_summary_sum_log_logits", "is", "not", "None", "]", "\n", "\n", "if", "low", "!=", "high", ":", "\n", "            ", "snippets", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "predicted_summary_sum_log_logits", ",", "reverse", "=", "is_descending", ")", "\n", "\n", "low_threshold_index", "=", "int", "(", "len", "(", "snippets", ")", "*", "low", ")", "\n", "high_threshold_index", "=", "int", "(", "len", "(", "snippets", ")", "*", "high", ")", "\n", "\n", "print", "(", "len", "(", "snippets", ")", ",", "low_threshold_index", ",", "high_threshold_index", ")", "\n", "\n", "ids", "=", "[", "snippets", "[", "index", "]", ".", "uid", "for", "index", "in", "range", "(", "low_threshold_index", ",", "high_threshold_index", ")", "]", "\n", "", "else", ":", "\n", "# Select random subset of labels across confidence distribution.", "\n", "            ", "random", ".", "shuffle", "(", "snippets", ")", "\n", "num_ids_to_take", "=", "int", "(", "len", "(", "snippets", ")", "*", "low", ")", "\n", "ids", "=", "[", "snippet", ".", "uid", "for", "snippet", "in", "snippets", "[", ":", "num_ids_to_take", "]", "]", "\n", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.__len__": [[201, 203], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_snippets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.__getitem__": [[204, 206], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "snippet_id", ")", ":", "\n", "        ", "return", "self", ".", "_snippets_data", "[", "snippet_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.__iter__": [[207, 210], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "snippet", "in", "self", ".", "_snippets", ":", "\n", "            ", "yield", "snippet", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.from_json_file": [[212, 226], ["cls", "isinstance", "print", "file_io.read_json", "file_io.read_json.items", "snippets.append", "helpers.read_json_snippet"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.read_json", "home.repos.pwc.inspect_result.curai_curai-research.datasets.helpers.read_json_snippet"], ["", "", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_files", ",", "is_pseudo_label", "=", "False", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "json_files", ",", "list", ")", ":", "\n", "            ", "json_files", "=", "[", "json_files", "]", "\n", "\n", "", "snippets", "=", "[", "]", "\n", "\n", "for", "json_file", "in", "json_files", ":", "\n", "            ", "print", "(", "f\"Reading snippet dataset from {json_file}\"", ")", "\n", "data", "=", "read_json", "(", "json_file", ")", "\n", "for", "snippet_id", ",", "data_pt", "in", "data", ".", "items", "(", ")", ":", "\n", "                ", "snippets", ".", "append", "(", "read_json_snippet", "(", "snippet_id", ",", "data_pt", ",", "is_pseudo_label", "=", "is_pseudo_label", ")", ")", "\n", "\n", "", "", "return", "cls", "(", "snippets", "=", "snippets", ",", "source_files", "=", "json_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset.from_dict": [[227, 239], ["cls", "isinstance", "dict.items", "snippets.append", "helpers.read_json_snippet"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.datasets.helpers.read_json_snippet"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "dicts", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "dicts", ",", "list", ")", ":", "\n", "            ", "dicts", "=", "[", "dicts", "]", "\n", "\n", "", "snippets", "=", "[", "]", "\n", "\n", "for", "dict", "in", "dicts", ":", "\n", "            ", "for", "snippet_id", ",", "data_pt", "in", "dict", ".", "items", "(", ")", ":", "\n", "                ", "snippets", ".", "append", "(", "read_json_snippet", "(", "snippet_id", ",", "data_pt", ")", ")", "\n", "\n", "", "", "return", "cls", "(", "snippets", "=", "snippets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_length": [[242, 249], ["len", "bad_ids.append"], "methods", ["None"], ["", "def", "_filter_length", "(", "self", ",", "max_num_turns", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "if", "max_num_turns", "is", "not", "None", ":", "\n", "            ", "for", "snippet", "in", "self", ":", "\n", "                ", "if", "len", "(", "snippet", ")", ">", "max_num_turns", ":", "\n", "                    ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "", "", "", "return", "bad_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_source": [[250, 257], ["bad_ids.append"], "methods", ["None"], ["", "def", "_filter_source", "(", "self", ",", "source", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "if", "source", "is", "not", "None", ":", "\n", "            ", "for", "snippet", "in", "self", ":", "\n", "                ", "if", "snippet", ".", "source", "is", "not", "None", "and", "snippet", ".", "source", "==", "source", ":", "\n", "                    ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "", "", "", "return", "bad_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_tags": [[258, 267], ["set", "any", "bad_ids.append"], "methods", ["None"], ["", "def", "_filter_tags", "(", "self", ",", "tags", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "if", "tags", "is", "not", "None", ":", "\n", "            ", "tags", "=", "set", "(", "tags", ")", "\n", "for", "snippet", "in", "self", ":", "\n", "                ", "if", "(", "snippet", ".", "tags", "is", "not", "None", "and", "\n", "any", "(", "x", "in", "tags", "for", "x", "in", "snippet", ".", "tags", ")", ")", ":", "\n", "                    ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "", "", "", "return", "bad_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_response_types": [[268, 277], ["set", "len", "bad_ids.append", "set().intersection", "set"], "methods", ["None"], ["", "def", "_filter_response_types", "(", "self", ",", "response_types", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "if", "response_types", "is", "not", "None", ":", "\n", "            ", "response_types", "=", "set", "(", "response_types", ")", "\n", "for", "snippet", "in", "self", ":", "\n", "                ", "if", "(", "len", "(", "set", "(", "snippet", ".", "response_types", ")", ".", "intersection", "(", "\n", "response_types", ")", ")", ">", "0", ")", ":", "\n", "                    ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "", "", "", "return", "bad_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_only_speaker": [[278, 287], ["set", "bad_ids.append", "len", "set.pop"], "methods", ["None"], ["", "def", "_filter_only_speaker", "(", "self", ",", "speaker", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "for", "snippet", "in", "self", ":", "\n", "            ", "snippet_speakers", "=", "set", "(", "[", "turn", ".", "speaker", "for", "turn", "in", "\n", "snippet", ".", "turns", "]", ")", "\n", "if", "(", "len", "(", "snippet_speakers", ")", "==", "1", "and", "\n", "speaker", "==", "snippet_speakers", ".", "pop", "(", ")", ")", ":", "\n", "                ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "", "", "return", "bad_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_empty_summaries_with_no_tags": [[288, 302], ["good_snippets.append", "good_snippets.append", "good_snippets.append", "len"], "methods", ["None"], ["", "def", "_filter_empty_summaries_with_no_tags", "(", "self", ",", "snippets", ")", ":", "\n", "        ", "good_snippets", "=", "[", "]", "\n", "for", "snippet", "in", "snippets", ":", "\n", "# unlabeled", "\n", "            ", "if", "snippet", ".", "summary", "is", "None", ":", "\n", "                ", "good_snippets", ".", "append", "(", "snippet", ")", "\n", "# labeled", "\n", "", "else", ":", "\n", "                ", "if", "snippet", ".", "summary", "==", "Text", ".", "EMPTY_STRING", ":", "\n", "                    ", "if", "snippet", ".", "tags", "is", "not", "None", "and", "len", "(", "snippet", ".", "tags", ")", "!=", "0", ":", "\n", "                        ", "good_snippets", ".", "append", "(", "snippet", ")", "\n", "", "", "else", ":", "\n", "                    ", "good_snippets", ".", "append", "(", "snippet", ")", "\n", "", "", "", "return", "good_snippets", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_concept_recall_threshold": [[303, 310], ["bad_ids.append"], "methods", ["None"], ["", "def", "_filter_concept_recall_threshold", "(", "self", ",", "threshold", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "if", "threshold", "is", "not", "None", ":", "\n", "            ", "for", "snippet", "in", "self", ":", "\n", "                ", "if", "snippet", ".", "concept_recall", "is", "not", "None", "and", "snippet", ".", "concept_recall", "<", "threshold", ":", "\n", "                    ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "", "", "", "return", "bad_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_affirmation_recall_threshold": [[311, 318], ["bad_ids.append"], "methods", ["None"], ["", "def", "_filter_affirmation_recall_threshold", "(", "self", ",", "threshold", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "if", "threshold", "is", "not", "None", ":", "\n", "            ", "for", "snippet", "in", "self", ":", "\n", "                ", "if", "snippet", ".", "affirmation_recall", "is", "not", "None", "and", "snippet", ".", "affirmation_recall", "<", "threshold", ":", "\n", "                    ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "", "", "", "return", "bad_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.snippet_dataset.SnippetDataset._filter_sum_log_logits_threshold": [[319, 334], ["snippets.sort", "int", "len", "bad_ids.append"], "methods", ["None"], ["", "def", "_filter_sum_log_logits_threshold", "(", "self", ",", "threshold", ",", "fixed_ids", ")", ":", "\n", "        ", "bad_ids", "=", "[", "]", "\n", "if", "threshold", "is", "not", "None", ":", "\n", "\n", "            ", "snippets", "=", "[", "snippet", "for", "snippet", "in", "self", "if", "snippet", ".", "predicted_summary_sum_log_logits", "is", "not", "None", "and", "snippet", ".", "uid", "not", "in", "fixed_ids", "]", "\n", "snippets", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "predicted_summary_sum_log_logits", ",", "reverse", "=", "True", ")", "\n", "\n", "threshold_index", "=", "int", "(", "len", "(", "snippets", ")", "*", "threshold", ")", "\n", "threshold_value", "=", "snippets", "[", "threshold_index", "]", ".", "predicted_summary_sum_log_logits", "\n", "\n", "for", "snippet", "in", "snippets", ":", "\n", "                ", "if", "snippet", ".", "predicted_summary_sum_log_logits", "<", "threshold_value", ":", "\n", "                    ", "bad_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "\n", "", "", "", "return", "bad_ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.datasets.helpers.read_json_snippet": [[5, 37], ["data_pt.get", "zip", "types.snippet.Snippet", "turns.append", "len", "turn_text.replace.replace", "turn_text.replace.replace", "types.turn.Turn", "data_pt.get"], "function", ["None"], ["def", "read_json_snippet", "(", "snippet_id", ",", "data_pt", ",", "is_pseudo_label", "=", "False", ")", ":", "\n", "    ", "\"\"\"Read a snippet in json format into a Snippet object\"\"\"", "\n", "turns", "=", "[", "]", "\n", "turn_texts", "=", "data_pt", "[", "\"snippet\"", "]", "\n", "response_types", "=", "data_pt", "[", "\"response_types\"", "]", "\n", "kb_concepts", "=", "data_pt", ".", "get", "(", "\"kb_concepts\"", ",", "[", "None", "]", "*", "len", "(", "turn_texts", ")", ")", "\n", "for", "turn_text", ",", "response_type", ",", "kb_concept", "in", "zip", "(", "turn_texts", ",", "\n", "response_types", ",", "kb_concepts", ")", ":", "\n", "        ", "if", "Text", ".", "PROFESSIONAL_PREFIX", "in", "turn_text", ":", "\n", "            ", "turn_text", "=", "turn_text", ".", "replace", "(", "Text", ".", "PROFESSIONAL_PREFIX", ",", "\n", "Text", ".", "EMPTY_STRING", ")", "\n", "speaker", "=", "Speakers", ".", "PROFESSIONAL", "\n", "", "else", ":", "\n", "            ", "turn_text", "=", "turn_text", ".", "replace", "(", "Text", ".", "CUSTOMER_PREFIX", ",", "\n", "Text", ".", "EMPTY_STRING", ")", "\n", "speaker", "=", "Speakers", ".", "CUSTOMER", "\n", "\n", "", "turns", ".", "append", "(", "Turn", "(", "text", "=", "turn_text", ",", "speaker", "=", "speaker", ",", "\n", "response_type", "=", "response_type", ",", "kb_concept", "=", "kb_concept", ")", ")", "\n", "", "summary", "=", "data_pt", "[", "'summary'", "]", "if", "not", "is_pseudo_label", "else", "data_pt", "[", "\"predicted_summary\"", "]", "\n", "concept_recall", "=", "data_pt", "[", "'concept_recall_w_snippet'", "]", "if", "'concept_recall_w_snippet'", "in", "data_pt", "else", "None", "\n", "affirmation_recall", "=", "data_pt", "[", "'affirmation_recall_w_snippet'", "]", "if", "'affirmation_recall_w_snippet'", "in", "data_pt", "else", "None", "\n", "predicted_summary_sum_log_logits", "=", "data_pt", "[", "'predicted_summary_sum_log_logits'", "]", "if", "'predicted_summary_sum_log_logits'", "in", "data_pt", "else", "None", "\n", "fixed", "=", "data_pt", "[", "'fixed'", "]", "if", "'fixed'", "in", "data_pt", "else", "\"False\"", "\n", "\n", "return", "Snippet", "(", "uid", "=", "snippet_id", ",", "turns", "=", "turns", ",", "\n", "is_history_gathering", "=", "data_pt", ".", "get", "(", "'is_history_gathering'", ")", ",", "\n", "tags", "=", "data_pt", "[", "'tags'", "]", ",", "summary", "=", "summary", ",", "\n", "source", "=", "data_pt", "[", "'source'", "]", ",", "concept_recall", "=", "concept_recall", ",", "\n", "affirmation_recall", "=", "affirmation_recall", ",", "\n", "predicted_summary_sum_log_logits", "=", "predicted_summary_sum_log_logits", ",", "\n", "fixed", "=", "fixed", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.constants.text.Text.process": [[25, 40], ["text.strip.strip.replace", "text.strip.strip.replace", "text.strip.strip.replace", "text.strip.strip.replace", "text.strip.strip.replace", "text.strip.strip.replace", "text.strip.strip.replace", "text.strip.strip.replace", "text.strip.strip.replace", "re.sub", "text.strip.strip.strip"], "methods", ["None"], ["@", "classmethod", "\n", "def", "process", "(", "cls", ",", "text", ")", ":", "\n", "        ", "text", "=", "text", ".", "replace", "(", "cls", ".", "NEW_LINE", ",", "cls", ".", "EMPTY_STRING", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "SLASH", ",", "cls", ".", "EMPTY_STRING", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "UNICODE_APOSTROPHE", ",", "cls", ".", "APOSTROPHE", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "UNICODE_DASH", ",", "cls", ".", "DASH", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "UNICODE_LEFT_QUOTE", ",", "cls", ".", "DOUBLE_QUOTE", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "UNICODE_OBJECT_REPLACEMENT", ",", "cls", ".", "EMPTY_STRING", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "UNICODE_REPLACEMENT", ",", "cls", ".", "EMPTY_STRING", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "UNICODE_RIGHT_QUOTE", ",", "cls", ".", "DOUBLE_QUOTE", ")", "\n", "text", "=", "text", ".", "replace", "(", "cls", ".", "UNICODE_SINGLE_QUOTE", ",", "cls", ".", "APOSTROPHE", ")", "\n", "\n", "text", "=", "re", ".", "sub", "(", "\"\\s+\"", ",", "cls", ".", "SPACE", ",", "text", ")", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.constants.text.Text.remove_neg_token": [[41, 44], ["text.replace"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "remove_neg_token", "(", "cls", ",", "text", ")", ":", "\n", "        ", "return", "text", ".", "replace", "(", "cls", ".", "NEG_TOKEN", "+", "cls", ".", "SPACE", ",", "cls", ".", "EMPTY_STRING", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.__init__": [[20, 30], ["chat.Chat._snippetize", "chat.Chat._trailing_ar_cust_turns_as_free_text"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat._snippetize", "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat._trailing_ar_cust_turns_as_free_text"], ["def", "__init__", "(", "self", ",", "uid", ",", "reason_for_encounter", ",", "turns", ",", "snippets", ")", ":", "\n", "        ", "self", ".", "uid", "=", "uid", "\n", "self", ".", "reason_for_encounter", "=", "reason_for_encounter", "\n", "self", ".", "turns", "=", "turns", "\n", "\n", "if", "snippets", "is", "None", ":", "\n", "            ", "self", ".", "snippets", "=", "self", ".", "_snippetize", "(", ")", "\n", "self", ".", "_trailing_ar_cust_turns_as_free_text", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "snippets", "=", "snippets", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.to_json": [[32, 37], ["res[].update", "snippet.to_json"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "self", ".", "uid", ":", "{", "\"reason_for_encounter\"", ":", "self", ".", "reason_for_encounter", "}", "}", "\n", "for", "snippet", "in", "self", ".", "snippets", ":", "\n", "            ", "res", "[", "self", ".", "uid", "]", ".", "update", "(", "snippet", ".", "to_json", "(", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.__repr__": [[40, 49], ["constants.Text.NEW_LINE.join", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "serialized", "=", "f\"Chat: {self.uid}{Text.NEW_LINE}\"", "\n", "serialized", "+=", "f\"RFE: {self.reason_for_encounter}{Text.NEW_LINE}\"", "\n", "if", "self", ".", "snippets", "is", "None", ":", "\n", "            ", "content", "=", "[", "str", "(", "turn", ")", "for", "turn", "in", "self", ".", "turns", "]", "\n", "", "else", ":", "\n", "            ", "content", "=", "[", "str", "(", "turn", ")", "for", "turn", "in", "self", ".", "snippets", "]", "\n", "", "serialized", "+=", "Text", ".", "NEW_LINE", ".", "join", "(", "content", ")", "\n", "return", "serialized", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "snippets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.from_turns": [[54, 58], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_turns", "(", "cls", ",", "uid", ",", "reason_for_encounter", ",", "turns", ")", ":", "\n", "        ", "return", "cls", "(", "uid", "=", "uid", ",", "reason_for_encounter", "=", "reason_for_encounter", ",", "\n", "turns", "=", "turns", ",", "snippets", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat.from_snippets": [[59, 63], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_snippets", "(", "cls", ",", "uid", ",", "reason_for_encounter", ",", "snippets", ")", ":", "\n", "        ", "return", "cls", "(", "uid", "=", "uid", ",", "reason_for_encounter", "=", "reason_for_encounter", ",", "\n", "snippets", "=", "snippets", ",", "turns", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat._trailing_ar_cust_turns_as_free_text": [[65, 107], ["set", "len", "enumerate", "turn_changes.append", "del_indices.update", "len", "range", "list", "range"], "methods", ["None"], ["", "def", "_trailing_ar_cust_turns_as_free_text", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Put trailing customer chat turns for an AR response\n        into original AR response free text\n        \"\"\"", "\n", "i", ",", "j", "=", "0", ",", "2", "\n", "turn_changes", ",", "del_indices", "=", "[", "]", ",", "set", "(", ")", "\n", "while", "i", "+", "1", "<", "len", "(", "self", ".", "turns", ")", ":", "\n", "            ", "curr_turn", ",", "next_turn", "=", "self", ".", "turns", "[", "i", "]", ",", "self", ".", "turns", "[", "i", "+", "1", "]", "\n", "\n", "prof_asks_ar_question", "=", "(", "curr_turn", ".", "speaker", "==", "Speakers", ".", "PROFESSIONAL", "\n", "and", "curr_turn", ".", "response_type", "!=", "ResponseTypes", ".", "CHAT", ")", "\n", "cust_answers_ar_question", "=", "(", "next_turn", ".", "speaker", "==", "Speakers", ".", "CUSTOMER", "\n", "and", "next_turn", ".", "response_type", "!=", "ResponseTypes", ".", "CHAT", ")", "\n", "\n", "if", "next_turn", ".", "response_type", "==", "ResponseTypes", ".", "AR_FT", ":", "\n", "                ", "free_text", "=", "next_turn", ".", "text", "\n", "", "else", ":", "\n", "                ", "free_text", "=", "next_turn", ".", "text", "+", "Text", ".", "PERIOD", "\n", "\n", "", "if", "prof_asks_ar_question", "and", "cust_answers_ar_question", ":", "\n", "                ", "init_j", "=", "j", "\n", "while", "(", "j", "<", "len", "(", "self", ".", "turns", ")", "and", "\n", "self", ".", "turns", "[", "j", "]", ".", "speaker", "==", "Speakers", ".", "CUSTOMER", "and", "\n", "self", ".", "turns", "[", "j", "]", ".", "response_type", "==", "ResponseTypes", ".", "CHAT", ")", ":", "\n", "                    ", "free_text", "+=", "' '", "+", "self", ".", "turns", "[", "j", "]", ".", "text", "+", "Text", ".", "PERIOD", "\n", "j", "+=", "1", "\n", "\n", "# Condense customer trailing chat text into free text portion", "\n", "# of AR question response", "\n", "", "if", "j", ">", "init_j", ":", "\n", "                    ", "turn_changes", ".", "append", "(", "(", "list", "(", "range", "(", "i", ",", "j", ")", ")", ",", "[", "i", ",", "i", "+", "1", "]", ")", ")", "\n", "self", ".", "turns", "[", "i", "+", "1", "]", ".", "text", "=", "free_text", "\n", "self", ".", "turns", "[", "i", "+", "1", "]", ".", "response_type", "=", "ResponseTypes", ".", "CHAT", "\n", "del_indices", ".", "update", "(", "range", "(", "init_j", ",", "j", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "j", "+=", "1", "\n", "", "i", "=", "j", "\n", "j", "=", "i", "+", "2", "\n", "\n", "", "self", ".", "turns", "=", "[", "turn", "for", "i", ",", "turn", "in", "enumerate", "(", "self", ".", "turns", ")", "\n", "if", "i", "not", "in", "del_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.chat.Chat._snippetize": [[108, 144], ["len", "content.append", "snippets.append", "content.append", "snippet.Snippet", "snippets.append", "len", "snippet.Snippet", "snippets.append", "len", "snippet.Snippet"], "methods", ["None"], ["", "def", "_snippetize", "(", "self", ")", ":", "\n", "        ", "\"\"\"Splits a chat into snippets\"\"\"", "\n", "i", ",", "count", "=", "0", ",", "0", "\n", "content", ",", "snippets", "=", "[", "]", ",", "[", "]", "\n", "prev_turn_is_cust", "=", "False", "\n", "while", "i", "<", "len", "(", "self", ".", "turns", ")", ":", "\n", "            ", "turn", "=", "self", ".", "turns", "[", "i", "]", "\n", "if", "turn", ".", "speaker", "==", "Speakers", ".", "PROFESSIONAL", ":", "\n", "# Professional AR Question", "\n", "                ", "if", "turn", ".", "response_type", "!=", "ResponseTypes", ".", "CHAT", ":", "\n", "                    ", "snippets", ".", "append", "(", "Snippet", "(", "f\"{self.uid}_{count}\"", ",", "\n", "[", "self", ".", "turns", "[", "i", "]", ",", "self", ".", "turns", "[", "i", "+", "1", "]", "]", ")", ")", "\n", "count", "+=", "1", "\n", "i", "+=", "1", "\n", "\n", "# Professional CHAT Response", "\n", "", "else", ":", "\n", "                    ", "if", "'?'", "in", "turn", ".", "text", "and", "len", "(", "content", ")", "!=", "0", ":", "\n", "                        ", "snippets", ".", "append", "(", "\n", "Snippet", "(", "f\"{self.uid}_{count}\"", ",", "content", ")", ")", "\n", "content", "=", "[", "]", "\n", "count", "+=", "1", "\n", "", "else", ":", "\n", "# Professional educational or acknowledgment", "\n", "                        ", "if", "prev_turn_is_cust", "and", "len", "(", "content", ")", "!=", "0", ":", "\n", "                            ", "snippets", ".", "append", "(", "\n", "Snippet", "(", "f\"{self.uid}_{count}\"", ",", "content", ")", ")", "\n", "content", "=", "[", "]", "\n", "count", "+=", "1", "\n", "", "", "content", ".", "append", "(", "turn", ")", "\n", "", "prev_turn_is_cust", "=", "False", "\n", "", "else", ":", "\n", "                ", "prev_turn_is_cust", "=", "True", "\n", "content", ".", "append", "(", "turn", ")", "\n", "", "i", "+=", "1", "\n", "", "return", "snippets", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.__init__": [[23, 46], ["constants.Text.process"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.constants.text.Text.process"], ["def", "__init__", "(", "\n", "self", ",", "uid", ",", "turns", ",", "is_history_gathering", "=", "None", ",", "\n", "tags", "=", "None", ",", "summary", "=", "None", ",", "source", "=", "None", ",", "concept_recall", "=", "None", ",", "\n", "affirmation_recall", "=", "None", ",", "predicted_summary_sum_log_logits", "=", "None", ",", "\n", "fixed", "=", "\"False\"", "\n", ")", ":", "\n", "        ", "self", ".", "uid", "=", "uid", "\n", "self", ".", "turns", "=", "turns", "\n", "self", ".", "is_history_gathering", "=", "is_history_gathering", "\n", "self", ".", "kb_concepts", "=", "[", "turn", ".", "kb_concept", "for", "turn", "in", "self", ".", "turns", "]", "\n", "self", ".", "response_types", "=", "[", "turn", ".", "response_type", "for", "turn", "in", "self", ".", "turns", "]", "\n", "\n", "self", ".", "tags", "=", "tags", "\n", "self", ".", "source", "=", "source", "\n", "if", "summary", "is", "not", "None", ":", "\n", "            ", "self", ".", "summary", "=", "Text", ".", "process", "(", "summary", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "summary", "=", "summary", "\n", "\n", "", "self", ".", "concept_recall", "=", "concept_recall", "\n", "self", ".", "affirmation_recall", "=", "affirmation_recall", "\n", "self", ".", "predicted_summary_sum_log_logits", "=", "predicted_summary_sum_log_logits", "\n", "self", ".", "fixed", "=", "fixed", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.get_formatted": [[48, 72], ["constants.Text.NEW_LINE.join", "constants.Text.NEW_LINE.join.append", "constants.Text.NEW_LINE.join.append", "str"], "methods", ["None"], ["", "def", "get_formatted", "(", "self", ",", "speaker_prefixes", "=", "False", ",", "text", "=", "False", ")", ":", "\n", "        ", "\"\"\" \n        Gets snippet in a formatted manner\n\n        Parameters\n        ----------\n        speaker_prefixes : bool\n            Whether to include speaker prefixes or not\n        text : bool\n            Whether to return a list of turns or text of turns\n\n        Returns\n        ----------\n        turns : list or str\n        \"\"\"", "\n", "turns", "=", "[", "]", "\n", "for", "turn", "in", "self", ".", "turns", ":", "\n", "            ", "if", "speaker_prefixes", ":", "\n", "                ", "turns", ".", "append", "(", "str", "(", "turn", ")", ")", "\n", "", "else", ":", "\n", "                ", "turns", ".", "append", "(", "turn", ".", "text", ")", "\n", "", "", "if", "text", ":", "\n", "            ", "turns", "=", "Text", ".", "NEW_LINE", ".", "join", "(", "turns", ")", "\n", "", "return", "turns", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.word_distribution_by_speaker": [[73, 93], ["numpy.array", "numpy.array.sum", "len", "turn.text.split"], "methods", ["None"], ["", "def", "word_distribution_by_speaker", "(", "self", ")", ":", "\n", "        ", "\"\"\" \n        Distribution of words by each speaker in a snippet\n\n        Returns\n        ----------\n        dist : np.array\n            First position is percentage of words by professional\n            and second position is percentage of words by customer\n        \"\"\"", "\n", "dist", "=", "[", "0.", ",", "0.", "]", "\n", "for", "turn", "in", "self", ".", "turns", ":", "\n", "            ", "n_words", "=", "len", "(", "turn", ".", "text", ".", "split", "(", ")", ")", "\n", "if", "turn", ".", "speaker", "==", "Speakers", ".", "PROFESSIONAL", ":", "\n", "                ", "dist", "[", "0", "]", "+=", "n_words", "\n", "", "else", ":", "\n", "                ", "dist", "[", "1", "]", "+=", "n_words", "\n", "", "", "dist", "=", "np", ".", "array", "(", "dist", ")", "\n", "dist", "/=", "dist", ".", "sum", "(", ")", "\n", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.to_json": [[94, 106], ["snippet.Snippet.get_formatted"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.get_formatted"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "self", ".", "uid", ":", "{", "}", "}", "\n", "res", "[", "self", ".", "uid", "]", "=", "{", "\n", "\"snippet\"", ":", "self", ".", "get_formatted", "(", "speaker_prefixes", "=", "True", ")", ",", "\n", "\"response_types\"", ":", "self", ".", "response_types", ",", "\n", "\"kb_concepts\"", ":", "self", ".", "kb_concepts", ",", "\n", "\"tags\"", ":", "self", ".", "tags", ",", "\n", "\"summary\"", ":", "self", ".", "summary", ",", "\n", "\"source\"", ":", "self", ".", "source", ",", "\n", "\"is_history_gathering\"", ":", "self", ".", "is_history_gathering", "\n", "}", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.__repr__": [[108, 119], ["constants.Text.NEW_LINE.join", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "if", "(", "self", ".", "is_history_gathering", "is", "not", "None", "and", "\n", "not", "self", ".", "is_history_gathering", ")", ":", "\n", "            ", "serialized", "=", "(", "f\"Snippet (Not History Gathering): \"", "\n", "f\"{self.uid}{Text.NEW_LINE}\"", ")", "\n", "", "else", ":", "\n", "            ", "serialized", "=", "(", "f\"-------- Snippet {self.uid} \"", "\n", "f\"--------{Text.NEW_LINE}\"", ")", "\n", "", "str_turns", "=", "[", "str", "(", "turn", ")", "for", "turn", "in", "self", ".", "turns", "]", "\n", "serialized", "+=", "Text", ".", "NEW_LINE", ".", "join", "(", "str_turns", ")", "\n", "return", "serialized", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.__len__": [[120, 122], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "turns", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.types.turn.Turn.__init__": [[15, 20], ["constants.Text.process"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.constants.text.Text.process"], ["def", "__init__", "(", "self", ",", "text", ",", "speaker", ",", "response_type", ",", "kb_concept", "=", "None", ")", ":", "\n", "        ", "self", ".", "text", "=", "Text", ".", "process", "(", "text", ")", "\n", "self", ".", "speaker", "=", "speaker", "\n", "self", ".", "response_type", "=", "response_type", "\n", "self", ".", "kb_concept", "=", "kb_concept", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.types.turn.Turn.__repr__": [[21, 27], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "speaker", "==", "Speakers", ".", "PROFESSIONAL", ":", "\n", "            ", "prefix", "=", "Text", ".", "PROFESSIONAL_PREFIX", "\n", "", "else", ":", "\n", "            ", "prefix", "=", "Text", ".", "CUSTOMER_PREFIX", "\n", "", "return", "f\"{prefix}{self.text}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.filters.snippet_filter.SnippetFilter.__init__": [[22, 39], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "max_num_turns", "=", "None", ",", "source", "=", "None", ",", "tags", "=", "None", ",", "\n", "response_types", "=", "None", ",", "snippet_ids", "=", "None", ",", "only_speaker", "=", "None", ",", "\n", "concept_recall_threshold", "=", "None", ",", "affirmation_recall_threshold", "=", "None", ",", "\n", "sum_log_logits_threshold", "=", "None", ",", "keep_fixed", "=", "False", ",", "sll_human_threshold_window", "=", "None", "\n", ")", ":", "\n", "        ", "self", ".", "max_num_turns", "=", "max_num_turns", "\n", "self", ".", "source", "=", "source", "\n", "self", ".", "tags", "=", "tags", "\n", "self", ".", "response_types", "=", "response_types", "\n", "self", ".", "snippet_ids", "=", "snippet_ids", "\n", "self", ".", "only_speaker", "=", "only_speaker", "\n", "self", ".", "concept_recall_threshold", "=", "concept_recall_threshold", "\n", "self", ".", "affirmation_recall_threshold", "=", "affirmation_recall_threshold", "\n", "self", ".", "sum_log_logits_threshold", "=", "sum_log_logits_threshold", "\n", "self", ".", "keep_fixed", "=", "keep_fixed", "\n", "self", ".", "sll_human_threshold_window", "=", "sll_human_threshold_window", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.__init__": [[41, 70], ["transformers.PegasusTokenizer.from_pretrained", "trainer.Trainer.init_train_data_loader", "trainer.Trainer.init_test_data_loader", "transformers.Adafactor", "transformers.optimization.get_adafactor_schedule", "summary.utils.KBConceptRecognizer", "summary.utils.ConceptAffirmationTagger", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "transformers.PegasusForConditionalGeneration.from_pretrained().to", "trainer.Trainer.model.parameters", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "transformers.PegasusForConditionalGeneration.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.init_train_data_loader", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.init_test_data_loader"], ["def", "__init__", "(", "\n", "self", ",", "snippet_dataset", ",", "test_dataset", "=", "None", ",", "model", "=", "None", ",", "batch_size", "=", "4", ",", "source_max_length", "=", "512", ",", "\n", "target_max_length", "=", "128", ",", "num_workers", "=", "4", ",", "device", "=", "\"cuda\"", ",", "\n", "accumulate_grad_batches", "=", "64", ",", "n_epochs", "=", "3", ",", "experiment_name", "=", "\"\"", ",", "writer", "=", "None", ",", "is_tracking", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "accumulate_grad_batches", "=", "accumulate_grad_batches", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "device", "=", "device", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "self", ".", "tokenizer", "=", "PegasusTokenizer", ".", "from_pretrained", "(", "self", ".", "MODEL_NAME", ")", "\n", "self", ".", "source_max_length", "=", "source_max_length", "\n", "self", ".", "target_max_length", "=", "target_max_length", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "train_snippet_dataset", "=", "snippet_dataset", "\n", "self", ".", "test_snippet_dataset", "=", "test_dataset", "\n", "\n", "self", ".", "init_train_data_loader", "(", ")", "\n", "self", ".", "init_test_data_loader", "(", ")", "\n", "\n", "self", ".", "model", "=", "PegasusForConditionalGeneration", ".", "from_pretrained", "(", "\n", "self", ".", "MODEL_NAME", ")", ".", "to", "(", "self", ".", "device", ")", "if", "model", "is", "None", "else", "model", "\n", "self", ".", "optimizer", "=", "Adafactor", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", "\n", "self", ".", "scheduler", "=", "get_adafactor_schedule", "(", "self", ".", "optimizer", ")", "\n", "self", ".", "experiment_name", "=", "experiment_name", "\n", "self", ".", "writer", "=", "writer", "if", "writer", "is", "not", "None", "else", "SummaryWriter", "(", "f\"runs/{self.experiment_name}\"", ")", "\n", "self", ".", "is_tracking", "=", "is_tracking", "\n", "self", ".", "entity_recognizer", "=", "KBConceptRecognizer", "(", ")", "\n", "self", ".", "affirmation_tagger", "=", "ConceptAffirmationTagger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.init_train_data_loader": [[71, 78], ["summary_dataset.SummaryDataset", "summary_dataset.SummaryCollate", "torch.DataLoader", "torch.DataLoader", "torch.DataLoader"], "methods", ["None"], ["", "def", "init_train_data_loader", "(", "self", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "SummaryDataset", "(", "self", ".", "train_snippet_dataset", ")", "\n", "data_collator", "=", "SummaryCollate", "(", "self", ".", "tokenizer", ",", "self", ".", "source_max_length", ",", "\n", "self", ".", "target_max_length", ")", "\n", "self", ".", "data_loader", "=", "data", ".", "DataLoader", "(", "self", ".", "dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "collate_fn", "=", "data_collator", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.init_test_data_loader": [[79, 89], ["summary_dataset.SummaryDataset", "summary_dataset.SummaryCollate", "torch.DataLoader", "torch.DataLoader", "torch.DataLoader"], "methods", ["None"], ["", "def", "init_test_data_loader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "test_snippet_dataset", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "test_dataset", "=", "SummaryDataset", "(", "self", ".", "test_snippet_dataset", ")", "\n", "data_collator", "=", "SummaryCollate", "(", "self", ".", "tokenizer", ",", "self", ".", "source_max_length", ",", "\n", "self", ".", "target_max_length", ")", "\n", "self", ".", "test_data_loader", "=", "data", ".", "DataLoader", "(", "self", ".", "test_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "collate_fn", "=", "data_collator", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.train": [[90, 95], ["range", "trainer.Trainer._train_epoch", "trainer.Trainer.model.save_pretrained"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._train_epoch"], ["", "def", "train", "(", "self", ",", "checkpoint_save_path", ",", "save_checkpoint", "=", "True", ")", ":", "\n", "        ", "for", "epoch_i", "in", "range", "(", "1", ",", "self", ".", "n_epochs", "+", "1", ")", ":", "\n", "            ", "self", ".", "_train_epoch", "(", "epoch_i", ")", "\n", "", "if", "save_checkpoint", ":", "\n", "            ", "self", ".", "model", ".", "save_pretrained", "(", "checkpoint_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._train_epoch": [[96, 133], ["tqdm.tqdm.tqdm", "trainer.Trainer.writer.add_scalar", "tqdm.tqdm.tqdm.write", "len", "print", "len", "enumerate", "trainer.Trainer._train_step", "trainer.Trainer.writer.add_scalar", "trainer.Trainer.item", "trainer.Trainer.backward", "len", "len", "trainer.Trainer.optimizer.step", "trainer.Trainer.optimizer.zero_grad", "tqdm.tqdm.tqdm.set_description"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.SparseUpdateTrainer._train_step"], ["", "", "def", "_train_epoch", "(", "self", ",", "epoch_i", ")", ":", "\n", "        ", "effective_batch_loss", "=", "0.", "\n", "avg_epoch_loss", "=", "0.", "\n", "\n", "# Make sure effective batch size is compatible with dataset size.", "\n", "while", "len", "(", "self", ".", "data_loader", ")", "<", "self", ".", "accumulate_grad_batches", "*", "self", ".", "batch_size", ":", "\n", "            ", "self", ".", "accumulate_grad_batches", "/=", "2", "\n", "print", "(", "f\"Adjusting effective batch size by changing accumulate_grad_batches to {self.accumulate_grad_batches}\"", ")", "\n", "\n", "", "assert", "self", ".", "accumulate_grad_batches", "*", "self", ".", "batch_size", "<", "len", "(", "self", ".", "data_loader", ")", "\n", "\n", "pbar", "=", "tqdm", "(", "enumerate", "(", "self", ".", "data_loader", ",", "start", "=", "1", ")", ",", "\n", "desc", "=", "f\"Epoch {epoch_i}\"", ",", "leave", "=", "True", ",", "total", "=", "len", "(", "self", ".", "data_loader", ")", ")", "\n", "for", "step_count", ",", "batch", "in", "pbar", ":", "\n", "            ", "batch_loss", "=", "self", ".", "_train_step", "(", "batch", ")", "\n", "batch_loss", "/=", "self", ".", "accumulate_grad_batches", "# norm for grad accumulation", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"charts/loss_step\"", ",", "batch_loss", ",", "step_count", ")", "\n", "effective_batch_loss", "+=", "batch_loss", ".", "item", "(", ")", "\n", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "\n", "if", "step_count", "%", "self", ".", "accumulate_grad_batches", "==", "0", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# self.writer.add_scalar(\"charts/lr\", self.scheduler.get_last_lr(), step_count)", "\n", "\n", "pbar", ".", "set_description", "(", "f\"Epoch {epoch_i} \"", "\n", "f\"| step_loss = {effective_batch_loss:.4f}\"", ")", "\n", "avg_epoch_loss", "+=", "effective_batch_loss", "\n", "effective_batch_loss", "=", "0.", "\n", "\n", "", "", "avg_epoch_loss", "/=", "len", "(", "self", ".", "data_loader", ".", "dataset", ")", "/", "(", "\n", "self", ".", "batch_size", "*", "self", ".", "accumulate_grad_batches", ")", "\n", "\n", "self", ".", "writer", ".", "add_scalar", "(", "\"charts/loss_epoch\"", ",", "avg_epoch_loss", ",", "epoch_i", ")", "\n", "pbar", ".", "write", "(", "f\"Epoch {epoch_i} \"", "\n", "f\"| avg_epoch_loss = {avg_epoch_loss:.4f}\"", ")", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._train_step": [[135, 149], ["trainer.Trainer._step", "batch[].to", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "lm_logits.view", "batch[].to.view"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._step"], ["", "def", "_train_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_step", "(", "batch", ")", "\n", "lm_logits", "=", "outputs", ".", "logits", "\n", "labels", "=", "batch", "[", "\"target_input_ids\"", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# print(lm_logits.size(), lm_logits.view(-1, lm_logits.shape[-1]).size(), labels.size(), labels.view(-1).size())", "\n", "# print(torch.min(lm_logits), torch.max(lm_logits))", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "labels", ".", "view", "(", "-", "1", ")", ",", "ignore_index", "=", "0", ")", "\n", "\n", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._step": [[150, 165], ["trainer.Trainer.shift_tokens_right().to", "trainer.Trainer.model", "trainer.Trainer.shift_tokens_right", "batch[].to", "batch[].to", "batch[].to"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.shift_tokens_right"], ["", "def", "_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "decoder_input_ids", "=", "self", ".", "shift_tokens_right", "(", "\n", "batch", "[", "\"target_input_ids\"", "]", ",", "pad_token_id", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "decoder_input_ids", "[", ":", ",", "0", "]", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "return", "self", ".", "model", "(", "\n", "input_ids", "=", "batch", "[", "\"source_input_ids\"", "]", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "attention_mask", "=", "batch", "[", "\"source_attention_mask\"", "]", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "batch", "[", "\"target_attention_mask\"", "]", ".", "to", "(", "\n", "self", ".", "device", ")", ",", "\n", "use_cache", "=", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._step_generate": [[167, 182], ["trainer.Trainer.shift_tokens_right().to", "trainer.Trainer.model.generate().cpu", "trainer.Trainer.shift_tokens_right", "trainer.Trainer.model.generate", "batch[].to", "batch[].to", "batch[].to"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.shift_tokens_right"], ["", "def", "_step_generate", "(", "self", ",", "batch", ")", ":", "\n", "        ", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "decoder_input_ids", "=", "self", ".", "shift_tokens_right", "(", "\n", "batch", "[", "\"target_input_ids\"", "]", ",", "pad_token_id", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "decoder_input_ids", "[", ":", ",", "0", "]", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n", "return", "self", ".", "model", ".", "generate", "(", "\n", "input_ids", "=", "batch", "[", "\"source_input_ids\"", "]", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "attention_mask", "=", "batch", "[", "\"source_attention_mask\"", "]", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "batch", "[", "\"target_attention_mask\"", "]", ".", "to", "(", "\n", "self", ".", "device", ")", ",", "\n", "num_beams", "=", "2", ",", "\n", "use_cache", "=", "True", ",", "\n", "repetition_penalty", "=", "2.0", "\n", ")", ".", "cpu", "(", ")", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.shift_tokens_right": [[184, 198], ["input_ids.clone", "input_ids.clone.masked_fill_", "input_ids.clone.gather().squeeze", "prev_output_tokens[].clone", "input_ids.clone.gather", "input_ids.clone.ne().sum", "input_ids.clone.ne"], "methods", ["None"], ["", "def", "shift_tokens_right", "(", "self", ",", "input_ids", ":", "torch", ".", "Tensor", ",", "pad_token_id", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n        \"\"\"", "\n", "prev_output_tokens", "=", "input_ids", ".", "clone", "(", ")", "\n", "assert", "pad_token_id", "is", "not", "None", ",", "\"self.model.config.pad_token_id has to be defined.\"", "\n", "# replace possible -100 values in labels by `pad_token_id`", "\n", "prev_output_tokens", ".", "masked_fill_", "(", "prev_output_tokens", "==", "-", "100", ",", "pad_token_id", ")", "\n", "index_of_eos", "=", "(", "prev_output_tokens", ".", "ne", "(", "pad_token_id", ")", ".", "sum", "(", "dim", "=", "1", ")", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "decoder_start_tokens", "=", "prev_output_tokens", ".", "gather", "(", "1", ",", "index_of_eos", ")", ".", "squeeze", "(", ")", "\n", "prev_output_tokens", "[", ":", ",", "1", ":", "]", "=", "prev_output_tokens", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "prev_output_tokens", "[", ":", ",", "0", "]", "=", "decoder_start_tokens", "\n", "\n", "return", "prev_output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.evaluate": [[199, 277], ["summary.pegasus.Decoder", "trainer.Trainer.evaluate._evaluate_dataset"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "\n", "        ", "def", "_evaluate_dataset", "(", "self", ",", "decoder", ",", "log_filename", ",", "metric_filename", ",", "dataset", ",", "tag", "=", "\"\"", ")", ":", "\n", "            ", "'''\n            Evaluate a dataset and compute metrics, with logging to wandb if self.is_tracking is True.\n            '''", "\n", "ids", ",", "summaries", ",", "scores", "=", "decoder", ".", "decode", "(", "f\"results/pegasus/{log_filename}.json\"", ",", "dataset", ")", "\n", "all_results", "=", "metric_utils", ".", "get_common_results_among_groups", "(", "[", "log_filename", "]", ")", "\n", "auto_metrics", ",", "gold_metrics", "=", "metric_utils", ".", "compute_metrics_for_all_groups", "(", "all_results", ",", "[", "log_filename", "]", ",", "tag", "=", "tag", ")", "\n", "write_json", "(", "auto_metrics", ",", "metric_filename", ")", "\n", "\n", "data", "=", "{", "\n", "\"snippet_id\"", ":", "ids", ",", "\n", "\"snippets\"", ":", "[", "snippet", ".", "get_formatted", "(", "text", "=", "True", ")", "for", "snippet", "in", "dataset", "]", ",", "\n", "\"gt_summary\"", ":", "[", "snippet", ".", "summary", "for", "snippet", "in", "dataset", "]", ",", "\n", "\"predicted_summary\"", ":", "summaries", ",", "\n", "\"confidence (sll)\"", ":", "scores", "\n", "}", "\n", "result_table", "=", "wandb", ".", "Table", "(", "dataframe", "=", "pd", ".", "DataFrame", "(", "data", "=", "data", ")", ")", "\n", "\n", "sum_log_logits_hist", "=", "go", ".", "Figure", "(", "data", "=", "[", "go", ".", "Histogram", "(", "x", "=", "scores", ")", "]", ")", "\n", "sum_log_logits_hist", ".", "update_layout", "(", "\n", "title_text", "=", "'Histogram of Predicted Summary\\'s Sum of Log Logits'", ",", "# title of plot", "\n", "xaxis_title_text", "=", "'Sum of Log Logits'", ",", "# xaxis label", "\n", "yaxis_title_text", "=", "'Count'", ",", "# yaxis label", "\n", "bargap", "=", "0.2", ",", "# gap between bars of adjacent location coordinates", "\n", "bargroupgap", "=", "0.1", "# gap between bars of the same location coordinates", "\n", ")", "\n", "\n", "if", "self", ".", "is_tracking", ":", "\n", "                ", "wandb", ".", "log", "(", "auto_metrics", "[", "log_filename", "]", ")", "\n", "wandb", ".", "log", "(", "gold_metrics", "[", "log_filename", "]", ")", "\n", "wandb", ".", "log", "(", "{", "\n", "f\"Dataset ({tag}) Evaluation\"", ":", "result_table", ",", "\n", "f\"Dataset ({tag}) Evaluation - Predicted Summary Confidence Histogram\"", ":", "wandb", ".", "Plotly", "(", "sum_log_logits_hist", ")", "\n", "}", ")", "\n", "\n", "", "", "def", "_get_concept_affirmation_recall_filtered_dataset", "(", "self", ")", ":", "\n", "            ", "'''\n            Get set of samples from self.test_snippet_dataset that have a concept and affirmation recall of 1.0 with \n            it's corresponding snippet. On the set of 501 test samples from the below path it results a set of 109 samples. \n            \"varun/naacl_paper/datasets/test_datasets/human-501.json\"\n            '''", "\n", "snippets", "=", "[", "self", ".", "test_snippet_dataset", "[", "snippet_id", "]", ".", "get_formatted", "(", "text", "=", "True", ")", "for", "snippet_id", "in", "self", ".", "test_snippet_dataset", ".", "snippet_ids", "]", "\n", "summaries", "=", "[", "self", ".", "test_snippet_dataset", "[", "snippet_id", "]", ".", "summary", "for", "snippet_id", "in", "self", ".", "test_snippet_dataset", ".", "snippet_ids", "]", "\n", "\n", "test_snippet_concepts", "=", "[", "self", ".", "entity_recognizer", ".", "get_concepts", "(", "snippet", ")", "for", "snippet", "in", "snippets", "]", "\n", "test_summary_concepts", "=", "[", "self", ".", "entity_recognizer", ".", "get_concepts", "(", "summary", ")", "for", "summary", "in", "summaries", "]", "\n", "test_concept_recall", "=", "[", "self", ".", "_compute_concept_recall", "(", "snippet_concepts", ",", "summary_concepts", ")", "for", "snippet_concepts", ",", "summary_concepts", "in", "zip", "(", "test_snippet_concepts", ",", "test_summary_concepts", ")", "]", "\n", "\n", "test_snippet_affirmations", "=", "[", "self", ".", "affirmation_tagger", ".", "get_affirmations", "(", "snippet", ",", "concepts", ")", "for", "snippet", ",", "concepts", "in", "zip", "(", "snippets", ",", "test_snippet_concepts", ")", "]", "\n", "test_summary_affirmations", "=", "[", "self", ".", "affirmation_tagger", ".", "get_affirmations", "(", "summary", ",", "concepts", ")", "for", "summary", ",", "concepts", "in", "zip", "(", "summaries", ",", "test_summary_concepts", ")", "]", "\n", "test_affirmation_recall", "=", "[", "self", ".", "_compute_affirmations_recall", "(", "snippet_affirmations", ",", "summary_affirmations", ")", "for", "snippet_affirmations", ",", "summary_affirmations", "in", "zip", "(", "test_snippet_affirmations", ",", "test_summary_affirmations", ")", "]", "\n", "\n", "filtered_ids", "=", "[", "snippet_id", "for", "index", ",", "snippet_id", "in", "enumerate", "(", "self", ".", "test_snippet_dataset", ".", "snippet_ids", ")", "if", "test_concept_recall", "[", "index", "]", ">=", "1.0", "and", "test_affirmation_recall", "[", "index", "]", ">=", "1.0", "]", "\n", "print", "(", "f\"Length of filtered Ids: {len(filtered_ids)}\"", ")", "\n", "\n", "filtered_test_snippet_dataset", "=", "self", ".", "test_snippet_dataset", ".", "subset", "(", "filtered_ids", ")", "\n", "\n", "return", "filtered_test_snippet_dataset", "\n", "\n", "\n", "", "decoder", "=", "Decoder", "(", "self", ".", "test_snippet_dataset", ",", "model", "=", "self", ".", "model", ",", "tokenizer", "=", "self", ".", "tokenizer", ")", "\n", "\n", "# Log test set metrics", "\n", "log_filename", "=", "f\"decoded_{self.experiment_name}\"", "\n", "metric_filename", "=", "f\"metrics/{self.experiment_name}_metrics.json\"", "\n", "_evaluate_dataset", "(", "self", ",", "decoder", ",", "log_filename", ",", "metric_filename", ",", "self", ".", "test_snippet_dataset", ")", "\n", "\n", "# Log train set metrics", "\n", "log_filename", "=", "f\"decoded_{self.experiment_name}_train\"", "\n", "metric_filename", "=", "f\"metrics/{self.experiment_name}_train_metrics.json\"", "\n", "_evaluate_dataset", "(", "self", ",", "decoder", ",", "log_filename", ",", "metric_filename", ",", "self", ".", "train_snippet_dataset", ",", "tag", "=", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.decode": [[285, 379], ["tqdm.tqdm.tqdm", "trainer.Trainer.test_snippet_dataset.to_json", "zip", "summary.utils.write_json", "trainer.Trainer.init_test_data_loader", "trainer.Trainer._decode_batch", "trainer.Trainer.test_snippet_dataset[].get_formatted", "trainer.Trainer.entity_recognizer.get_concepts", "trainer.Trainer.entity_recognizer.get_concepts", "trainer.Trainer.affirmation_tagger.get_affirmations", "trainer.Trainer.affirmation_tagger.get_affirmations", "trainer.Trainer._compute_concept_recall", "trainer.Trainer._compute_affirmations_recall", "float", "trainer.Trainer.update", "trainer.Trainer.keys", "wandb.Table", "wandb.log", "plotly.Figure", "plotly.Figure.update_layout", "plotly.Figure", "plotly.Figure.update_layout", "plotly.Figure", "plotly.Figure.update_layout", "wandb.log", "str", "str", "pandas.DataFrame", "wandb.Plotly", "wandb.Plotly", "wandb.Plotly", "plotly.Histogram", "plotly.Histogram", "plotly.Histogram"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json", "home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.write_json", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer.init_test_data_loader", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder._decode_batch", "home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.get_formatted", "home.repos.pwc.inspect_result.curai_curai-research.utils.kb_concept_recognizer.KBConceptRecognizer.get_concepts", "home.repos.pwc.inspect_result.curai_curai-research.utils.kb_concept_recognizer.KBConceptRecognizer.get_concepts", "home.repos.pwc.inspect_result.curai_curai-research.utils.concept_affirmation_tagger.ConceptAffirmationTagger.get_affirmations", "home.repos.pwc.inspect_result.curai_curai-research.utils.concept_affirmation_tagger.ConceptAffirmationTagger.get_affirmations", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._compute_concept_recall", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._compute_affirmations_recall"], ["", "def", "decode", "(", "self", ",", "result_save_path", ",", "dataset", "=", "None", ",", "existing_labels", "=", "None", ")", ":", "\n", "        ", "if", "dataset", "is", "not", "None", ":", "\n", "            ", "self", ".", "test_snippet_dataset", "=", "dataset", "\n", "self", ".", "init_test_data_loader", "(", ")", "\n", "\n", "", "all_snippet_ids", ",", "all_predictions", ",", "all_summary_sum_log_logits", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "self", ".", "test_data_loader", ",", "desc", "=", "\"Decoding\"", ",", "leave", "=", "True", ")", ":", "\n", "            ", "snippet_ids", ",", "batch_predictions", ",", "sequence_scores", "=", "self", ".", "_decode_batch", "(", "batch", ")", "\n", "all_snippet_ids", "+=", "snippet_ids", "\n", "all_predictions", "+=", "batch_predictions", "\n", "all_summary_sum_log_logits", "+=", "sequence_scores", "\n", "\n", "\n", "", "results", "=", "self", ".", "test_snippet_dataset", ".", "to_json", "(", ")", "\n", "for", "snippet_id", ",", "predicted_summary", ",", "summary_sum_log_logits", "in", "zip", "(", "all_snippet_ids", ",", "\n", "all_predictions", ",", "all_summary_sum_log_logits", ")", ":", "\n", "\n", "            ", "snippet", "=", "self", ".", "test_snippet_dataset", "[", "snippet_id", "]", ".", "get_formatted", "(", "text", "=", "True", ")", "\n", "summary", "=", "self", ".", "test_snippet_dataset", "[", "snippet_id", "]", ".", "summary", "\n", "results", "[", "snippet_id", "]", "[", "\"snippet_concepts\"", "]", "=", "self", ".", "entity_recognizer", ".", "get_concepts", "(", "snippet", ")", "\n", "\n", "results", "[", "snippet_id", "]", "[", "\"gt_summary\"", "]", "=", "summary", "\n", "# results[snippet_id][\"gt_summary_concepts\"] = self.entity_recognizer.get_concepts(summary)", "\n", "\n", "results", "[", "snippet_id", "]", "[", "\"predicted_summary\"", "]", "=", "predicted_summary", "\n", "results", "[", "snippet_id", "]", "[", "\"predicted_summary_concepts\"", "]", "=", "self", ".", "entity_recognizer", ".", "get_concepts", "(", "predicted_summary", ")", "\n", "\n", "snippet_affirmations", "=", "self", ".", "affirmation_tagger", ".", "get_affirmations", "(", "\n", "snippet", ",", "results", "[", "snippet_id", "]", "[", "\"snippet_concepts\"", "]", ")", "\n", "predicted_summary_affirmations", "=", "self", ".", "affirmation_tagger", ".", "get_affirmations", "(", "\n", "results", "[", "snippet_id", "]", "[", "\"predicted_summary\"", "]", ",", "results", "[", "snippet_id", "]", "[", "\"predicted_summary_concepts\"", "]", ")", "\n", "results", "[", "snippet_id", "]", "[", "\"snippet_affirmations\"", "]", "=", "snippet_affirmations", "\n", "results", "[", "snippet_id", "]", "[", "\"predicted_affirmations\"", "]", "=", "predicted_summary_affirmations", "\n", "results", "[", "snippet_id", "]", "[", "\"concept_recall_w_snippet\"", "]", "=", "self", ".", "_compute_concept_recall", "(", "results", "[", "snippet_id", "]", "[", "'snippet_concepts'", "]", ",", "results", "[", "snippet_id", "]", "[", "'predicted_summary_concepts'", "]", ")", "\n", "results", "[", "snippet_id", "]", "[", "\"affirmation_recall_w_snippet\"", "]", "=", "self", ".", "_compute_affirmations_recall", "(", "results", "[", "snippet_id", "]", "[", "\"snippet_affirmations\"", "]", ",", "results", "[", "snippet_id", "]", "[", "\"predicted_affirmations\"", "]", ")", "\n", "results", "[", "snippet_id", "]", "[", "\"predicted_summary_sum_log_logits\"", "]", "=", "float", "(", "summary_sum_log_logits", ")", "\n", "\n", "", "if", "existing_labels", "is", "not", "None", ":", "\n", "            ", "results", ".", "update", "(", "existing_labels", ")", "\n", "\n", "", "write_json", "(", "results", ",", "result_save_path", ")", "\n", "\n", "if", "self", ".", "is_tracking", ":", "\n", "            ", "snippet_ids", "=", "results", ".", "keys", "(", ")", "\n", "data", "=", "{", "\n", "\"snippet_id\"", ":", "snippet_ids", ",", "\n", "\"snippets\"", ":", "[", "results", "[", "id", "]", "[", "'snippet'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"summaries\"", ":", "[", "results", "[", "id", "]", "[", "'gt_summary'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"predicted_summary\"", ":", "[", "results", "[", "id", "]", "[", "'predicted_summary'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"predicted_summary_sum_log_logits\"", ":", "[", "results", "[", "id", "]", "[", "'predicted_summary_sum_log_logits'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"concept_recall_w_snippet\"", ":", "[", "results", "[", "id", "]", "[", "'concept_recall_w_snippet'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"affirmation_recall_w_snippet\"", ":", "[", "results", "[", "id", "]", "[", "'affirmation_recall_w_snippet'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"snippet_concepts\"", ":", "[", "results", "[", "id", "]", "[", "'snippet_concepts'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "# \"summary_concepts\": [results[id]['gt_summary_concepts'] for id in snippet_ids],", "\n", "\"predicted_summary_concepts\"", ":", "[", "results", "[", "id", "]", "[", "'predicted_summary_concepts'", "]", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"snippet_affirmations\"", ":", "[", "str", "(", "results", "[", "id", "]", "[", "'snippet_affirmations'", "]", ")", "for", "id", "in", "snippet_ids", "]", ",", "\n", "\"predicted_affirmations\"", ":", "[", "str", "(", "results", "[", "id", "]", "[", "'predicted_affirmations'", "]", ")", "for", "id", "in", "snippet_ids", "]", "\n", "}", "\n", "\n", "result_table", "=", "wandb", ".", "Table", "(", "dataframe", "=", "pd", ".", "DataFrame", "(", "data", "=", "data", ")", ")", "\n", "wandb", ".", "log", "(", "{", "\"Generated Pseudo-Labels\"", ":", "result_table", "}", ")", "\n", "\n", "concept_hist", "=", "go", ".", "Figure", "(", "data", "=", "[", "go", ".", "Histogram", "(", "x", "=", "data", "[", "'concept_recall_w_snippet'", "]", ")", "]", ")", "\n", "concept_hist", ".", "update_layout", "(", "\n", "title_text", "=", "'Histogram of Concept Recall between Predicted Summary and Snippet'", ",", "# title of plot", "\n", "xaxis_title_text", "=", "'Recall Score'", ",", "# xaxis label", "\n", "yaxis_title_text", "=", "'Count'", ",", "# yaxis label", "\n", "bargap", "=", "0.2", ",", "# gap between bars of adjacent location coordinates", "\n", "bargroupgap", "=", "0.1", "# gap between bars of the same location coordinates", "\n", ")", "\n", "\n", "affirmation_hist", "=", "go", ".", "Figure", "(", "data", "=", "[", "go", ".", "Histogram", "(", "x", "=", "data", "[", "'affirmation_recall_w_snippet'", "]", ")", "]", ")", "\n", "affirmation_hist", ".", "update_layout", "(", "\n", "title_text", "=", "'Histogram of Affirmation Recall between Predicted Summary and Snippet'", ",", "# title of plot", "\n", "xaxis_title_text", "=", "'Affirmation Score'", ",", "# xaxis label", "\n", "yaxis_title_text", "=", "'Count'", ",", "# yaxis label", "\n", "bargap", "=", "0.2", ",", "# gap between bars of adjacent location coordinates", "\n", "bargroupgap", "=", "0.1", "# gap between bars of the same location coordinates", "\n", ")", "\n", "\n", "sum_log_logits_hist", "=", "go", ".", "Figure", "(", "data", "=", "[", "go", ".", "Histogram", "(", "x", "=", "data", "[", "'predicted_summary_sum_log_logits'", "]", ")", "]", ")", "\n", "sum_log_logits_hist", ".", "update_layout", "(", "\n", "title_text", "=", "'Histogram of Predicted Summary\\'s Sum of Log Logits'", ",", "# title of plot", "\n", "xaxis_title_text", "=", "'Sum of Log Logits'", ",", "# xaxis label", "\n", "yaxis_title_text", "=", "'Count'", ",", "# yaxis label", "\n", "bargap", "=", "0.2", ",", "# gap between bars of adjacent location coordinates", "\n", "bargroupgap", "=", "0.1", "# gap between bars of the same location coordinates", "\n", ")", "\n", "\n", "wandb", ".", "log", "(", "{", "\"Concept Recall Histogram\"", ":", "wandb", ".", "Plotly", "(", "concept_hist", ")", ",", "\n", "\"Affirmation Recall Histogram\"", ":", "wandb", ".", "Plotly", "(", "affirmation_hist", ")", ",", "\n", "\"Predicted Summary's Sum of Log Logits Histogram\"", ":", "wandb", ".", "Plotly", "(", "sum_log_logits_hist", ")", "}", ")", "\n", "\n", "", "return", "all_snippet_ids", ",", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._compute_concept_recall": [[380, 385], ["set", "set", "set.intersection", "len", "len", "len"], "methods", ["None"], ["", "def", "_compute_concept_recall", "(", "self", ",", "gold_concepts", ",", "pred_concepts", ")", ":", "\n", "        ", "gold_concepts", "=", "set", "(", "gold_concepts", ")", "\n", "pred_concepts", "=", "set", "(", "pred_concepts", ")", "\n", "true_pos", "=", "gold_concepts", ".", "intersection", "(", "pred_concepts", ")", "\n", "return", "len", "(", "true_pos", ")", "/", "len", "(", "gold_concepts", ")", "if", "len", "(", "gold_concepts", ")", ">", "0", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._compute_affirmations_recall": [[386, 393], ["gold_affirmations.items", "pred_affirmations.get", "len", "len"], "methods", ["None"], ["", "def", "_compute_affirmations_recall", "(", "self", ",", "gold_affirmations", ",", "\n", "pred_affirmations", ")", ":", "\n", "        ", "true_pos", "=", "0", "\n", "for", "concept", ",", "negation", "in", "gold_affirmations", ".", "items", "(", ")", ":", "\n", "            ", "if", "pred_affirmations", ".", "get", "(", "concept", ",", "\"\"", ")", "==", "negation", ":", "\n", "                ", "true_pos", "+=", "1", "\n", "", "", "return", "true_pos", "/", "len", "(", "gold_affirmations", ")", "if", "len", "(", "gold_affirmations", ")", ">", "0", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._decode_batch": [[394, 417], ["batch[].to", "batch[].to", "trainer.Trainer.model.generate", "trainer.Trainer._ids_to_clean_text", "list", "generated_ids_dict[].cpu().numpy", "generated_ids_dict[].cpu"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder._ids_to_clean_text"], ["", "def", "_decode_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "encounter_ids", "=", "batch", "[", "'encounter_ids'", "]", "\n", "source_input_ids", "=", "batch", "[", "'source_input_ids'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "source_attention_mask", "=", "batch", "[", "'source_attention_mask'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "generated_ids_dict", "=", "self", ".", "model", ".", "generate", "(", "\n", "source_input_ids", ",", "\n", "decoder_start_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", ",", "\n", "attention_mask", "=", "source_attention_mask", ",", "\n", "use_cache", "=", "True", ",", "\n", "num_beams", "=", "4", ",", "\n", "max_length", "=", "150", ",", "\n", "repetition_penalty", "=", "2.5", ",", "\n", "no_repeat_ngram_size", "=", "2", ",", "\n", "early_stopping", "=", "True", ",", "\n", "min_length", "=", "0", ",", "\n", "return_dict_in_generate", "=", "True", ",", "\n", "output_scores", "=", "True", ",", "\n", ")", "\n", "\n", "batch_predictions", "=", "self", ".", "_ids_to_clean_text", "(", "generated_ids_dict", "[", "'sequences'", "]", ")", "\n", "sequence_scores", "=", "list", "(", "generated_ids_dict", "[", "'sequences_scores'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "return", "encounter_ids", ",", "batch_predictions", ",", "sequence_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._ids_to_clean_text": [[418, 424], ["trainer.Trainer.tokenizer.batch_decode", "list", "map"], "methods", ["None"], ["", "def", "_ids_to_clean_text", "(", "self", ",", "generated_ids", ")", ":", "\n", "        ", "gen_text", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "\n", "generated_ids", ",", "skip_special_tokens", "=", "True", ",", "\n", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "return", "list", "(", "map", "(", "str", ".", "strip", ",", "gen_text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.SparseUpdateTrainer.__init__": [[426, 429], ["trainer.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "mask", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.SparseUpdateTrainer._train_step": [[430, 449], ["trainer.SparseUpdateTrainer._step", "batch[].to", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "trainer.SparseUpdateTrainer.model.named_parameters", "lm_logits.view", "batch[].to.view", "trainer.SparseUpdateTrainer.mask[].to", "params.grad.data.copy_"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.Trainer._step"], ["", "def", "_train_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_step", "(", "batch", ")", "\n", "lm_logits", "=", "outputs", ".", "logits", "\n", "labels", "=", "batch", "[", "\"target_input_ids\"", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# print(lm_logits.size(), lm_logits.view(-1, lm_logits.shape[-1]).size(), labels.size(), labels.view(-1).size())", "\n", "# print(torch.min(lm_logits), torch.max(lm_logits))", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "labels", ".", "view", "(", "-", "1", ")", ",", "ignore_index", "=", "0", ")", "\n", "\n", "for", "name", ",", "params", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "device", "=", "params", ".", "device", "\n", "self", ".", "mask", "[", "name", "]", "=", "self", ".", "mask", "[", "name", "]", ".", "to", "(", "device", ")", "\n", "\n", "params", ".", "grad", ".", "data", ".", "copy_", "(", "params", ".", "grad", ".", "data", "*", "self", ".", "mask", "[", "name", "]", ".", "data", ")", "\n", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.calculate_the_importance_label": [[462, 504], ["model.named_parameters", "tqdm.tqdm", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "enumerate", "print", "inputs.pop", "inputs.items", "model", "loss.backward", "model.named_parameters", "model.zero_grad", "len", "isinstance", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "v.to", "grad_method"], "function", ["None"], ["", "", "def", "calculate_the_importance_label", "(", "model", ",", "data_loader", ",", "num_samples", ",", "cuda_device", ",", "grad_type", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        grad_type: (square or absolute) \n    \"\"\"", "\n", "gradients_dict", "=", "{", "}", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "gradients_dict", "[", "name", "]", "=", "torch", ".", "zeros_like", "(", "param", ")", ".", "to", "(", "cuda_device", ")", "\n", "\n", "", "if", "grad_type", "==", "\"absolute\"", ":", "\n", "        ", "grad_method", "=", "torch", ".", "abs", "\n", "", "elif", "grad_type", "==", "\"square\"", ":", "\n", "        ", "grad_method", "=", "torch", ".", "square", "\n", "\n", "", "pbar", "=", "tqdm", "(", "enumerate", "(", "data_loader", ",", "start", "=", "1", ")", ",", "\n", "desc", "=", "f\"Computing mask...\"", ",", "leave", "=", "True", ",", "total", "=", "len", "(", "data_loader", ")", ")", "\n", "\n", "for", "idx", ",", "inputs", "in", "pbar", ":", "\n", "        ", "print", "(", "idx", ")", "\n", "if", "idx", ">=", "num_samples", ":", "\n", "            ", "break", "\n", "\n", "# print(idx)", "\n", "\n", "", "inputs", ".", "pop", "(", "\"idx\"", ",", "None", ")", "\n", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "inputs", "[", "k", "]", "=", "v", ".", "to", "(", "cuda_device", ")", "\n", "\n", "", "", "return_dicts", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "loss", "=", "return_dicts", "[", "\"loss\"", "]", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "gradients_dict", "[", "name", "]", "+=", "grad_method", "(", "param", ".", "grad", ")", ".", "data", "\n", "\n", "", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "return", "gradients_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.calculate_the_importance_expect": [[505, 549], ["model.named_parameters", "enumerate", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "inputs.pop", "inputs.items", "model", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "range", "isinstance", "range", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "v.to", "loss.backward", "model.named_parameters", "model.zero_grad", "grad_method"], "function", ["None"], ["", "def", "calculate_the_importance_expect", "(", "model", ",", "data_loader", ",", "num_samples", ",", "cuda_device", ",", "grad_type", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        grad_type: (square or absolute) \n    \"\"\"", "\n", "gradients_dict", "=", "{", "}", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "gradients_dict", "[", "name", "]", "=", "torch", ".", "zeros_like", "(", "param", ")", ".", "to", "(", "cuda_device", ")", "\n", "\n", "", "if", "grad_type", "==", "\"absolute\"", ":", "\n", "        ", "grad_method", "=", "torch", ".", "abs", "\n", "", "elif", "grad_type", "==", "\"square\"", ":", "\n", "        ", "grad_method", "=", "torch", ".", "square", "\n", "\n", "", "for", "idx", ",", "inputs", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "if", "idx", ">=", "num_samples", ":", "\n", "            ", "break", "\n", "\n", "", "inputs", ".", "pop", "(", "\"idx\"", ",", "None", ")", "\n", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "inputs", "[", "k", "]", "=", "v", ".", "to", "(", "cuda_device", ")", "\n", "\n", "", "", "return_dicts", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "logits", "=", "return_dicts", "[", "\"logits\"", "]", "\n", "\n", "log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "-", "1", ")", "\n", "probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "-", "1", ")", "\n", "\n", "for", "b", "in", "range", "(", "logits", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "logits", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "loss", "=", "-", "log_probs", "[", "b", ",", "i", "]", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "\n", "prob", "=", "probs", "[", "b", ",", "i", "]", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "gradients_dict", "[", "name", "]", "+=", "(", "prob", "*", "grad_method", "(", "param", ".", "grad", ")", ")", ".", "data", "\n", "\n", "", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "", "return", "gradients_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.trainer.create_mask_gradient": [[550, 634], ["model.to", "torch.DataLoader", "importance_method", "importance_method.items", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "sizes.items", "mask_dict.update", "model.to", "mask_dict.items", "print", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.prod().item", "torch.prod().item", "torch.prod().item", "int", "torch.topk", "torch.topk", "torch.topk", "torch.zeros_like.long().sum", "len", "masks[].reshape().to", "len", "torch.prod().item", "torch.prod().item", "torch.prod().item", "list", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.ones_like().to", "torch.ones_like().to", "torch.ones_like().to", "torch.cat.append", "torch.prod", "torch.prod", "torch.prod", "model.parameters", "v.view", "torch.prod", "torch.prod", "torch.prod", "torch.zeros_like.long", "torch.tensor", "torch.tensor", "torch.tensor", "masks[].reshape", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "create_mask_gradient", "(", "model", ",", "train_dataset", ",", "data_collator", ",", "num_workers", ",", "num_samples", ",", "keep_ratio", ",", "sample_type", ",", "grad_type", ")", ":", "\n", "    ", "original_device", "=", "list", "(", "model", ".", "parameters", "(", ")", ")", "[", "0", "]", ".", "device", "\n", "cuda_device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "\n", "model", ".", "to", "(", "cuda_device", ")", "\n", "\n", "data_loader", "=", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "1", ",", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "data_collator", ",", "shuffle", "=", "True", ")", "\n", "\n", "if", "sample_type", "==", "\"label\"", ":", "\n", "        ", "importance_method", "=", "calculate_the_importance_label", "\n", "", "elif", "sample_type", "==", "\"expect\"", ":", "\n", "        ", "importance_method", "=", "calculate_the_importance_expect", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "gradients", "=", "importance_method", "(", "model", ",", "data_loader", ",", "num_samples", ",", "cuda_device", ",", "grad_type", ")", "\n", "\n", "# add sizes and aggregate tensors", "\n", "sizes", "=", "{", "}", "\n", "tensors", "=", "[", "]", "\n", "\n", "classifier_size", "=", "0", "\n", "all_params_size", "=", "0", "\n", "\n", "classifier_mask_dict", "=", "{", "}", "\n", "\n", "for", "k", ",", "v", "in", "gradients", ".", "items", "(", ")", ":", "\n", "# don't count classifier layer, they should be all trainable", "\n", "        ", "if", "\"classifier\"", "in", "k", ":", "\n", "            ", "classifier_size", "+=", "torch", ".", "prod", "(", "torch", ".", "tensor", "(", "v", ".", "shape", ")", ")", ".", "item", "(", ")", "\n", "classifier_mask_dict", "[", "k", "]", "=", "torch", ".", "ones_like", "(", "v", ")", ".", "to", "(", "original_device", ")", "\n", "", "else", ":", "\n", "            ", "sizes", "[", "k", "]", "=", "v", ".", "shape", "\n", "tensors", ".", "append", "(", "v", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "all_params_size", "+=", "torch", ".", "prod", "(", "torch", ".", "tensor", "(", "v", ".", "shape", ")", ")", ".", "item", "(", ")", "\n", "\n", "", "tensors", "=", "torch", ".", "cat", "(", "tensors", ",", "0", ")", "\n", "\n", "keep_num", "=", "int", "(", "all_params_size", "*", "keep_ratio", ")", "-", "classifier_size", "\n", "\n", "assert", "keep_num", ">", "0", "\n", "\n", "top_pos", "=", "torch", ".", "topk", "(", "tensors", ",", "keep_num", ")", "[", "1", "]", "\n", "\n", "masks", "=", "torch", ".", "zeros_like", "(", "tensors", ",", "device", "=", "cuda_device", ")", "\n", "\n", "masks", "[", "top_pos", "]", "=", "1", "\n", "\n", "assert", "masks", ".", "long", "(", ")", ".", "sum", "(", ")", "==", "len", "(", "top_pos", ")", "\n", "\n", "mask_dict", "=", "{", "}", "\n", "\n", "now_idx", "=", "0", "\n", "for", "k", ",", "v", "in", "sizes", ".", "items", "(", ")", ":", "\n", "        ", "end_idx", "=", "now_idx", "+", "torch", ".", "prod", "(", "torch", ".", "tensor", "(", "v", ")", ")", "\n", "mask_dict", "[", "k", "]", "=", "masks", "[", "now_idx", ":", "end_idx", "]", ".", "reshape", "(", "v", ")", ".", "to", "(", "original_device", ")", "\n", "now_idx", "=", "end_idx", "\n", "\n", "", "assert", "now_idx", "==", "len", "(", "masks", ")", "\n", "\n", "# Add the classifier's mask to mask_dict", "\n", "mask_dict", ".", "update", "(", "classifier_mask_dict", ")", "\n", "\n", "model", ".", "to", "(", "original_device", ")", "\n", "\n", "# Print the parameters for checking", "\n", "classifier_size", "=", "0", "\n", "all_params_size", "=", "0", "\n", "pretrain_weight_size", "=", "0", "\n", "\n", "for", "k", ",", "v", "in", "mask_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "\"classifier\"", "in", "k", ":", "\n", "            ", "classifier_size", "+=", "(", "v", "==", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "pretrain_weight_size", "+=", "(", "v", "==", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "all_params_size", "+=", "torch", ".", "prod", "(", "torch", ".", "tensor", "(", "v", ".", "shape", ")", ")", ".", "item", "(", ")", "\n", "\n", "", "print", "(", "pretrain_weight_size", ",", "classifier_size", ",", "all_params_size", ")", "\n", "print", "(", "f\"trainable parameters: {(pretrain_weight_size + classifier_size) / all_params_size * 100} %\"", ")", "\n", "\n", "return", "mask_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder.__init__": [[14, 37], ["decoder.Decoder.init_dataset", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "transformers.PegasusTokenizer.from_pretrained", "transformers.PegasusForConditionalGeneration.from_pretrained().to", "transformers.PegasusForConditionalGeneration.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder.init_dataset"], ["def", "__init__", "(", "\n", "self", ",", "snippet_dataset", ",", "model", "=", "None", ",", "tokenizer", "=", "None", ",", "num_beams", "=", "8", ",", "\n", "repetition_penalty", "=", "2.5", ",", "no_repeat_ngram_size", "=", "2", ",", "\n", "early_stopping", "=", "True", ",", "source_max_length", "=", "512", ",", "\n", "target_max_length", "=", "128", ",", "device", "=", "\"cuda\"", ",", "batch_size", "=", "8", ",", "\n", "num_workers", "=", "4", "\n", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "self", ".", "num_beams", "=", "num_beams", "\n", "self", ".", "repetition_penalty", "=", "repetition_penalty", "\n", "self", ".", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", "\n", "self", ".", "early_stopping", "=", "early_stopping", "\n", "self", ".", "target_max_length", "=", "target_max_length", "\n", "self", ".", "source_max_length", "=", "source_max_length", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "self", ".", "tokenizer", "=", "PegasusTokenizer", ".", "from_pretrained", "(", "\n", "self", ".", "MODEL_NAME", ")", "if", "tokenizer", "is", "None", "else", "tokenizer", "\n", "self", ".", "model", "=", "PegasusForConditionalGeneration", ".", "from_pretrained", "(", "\n", "self", ".", "MODEL_NAME", ")", ".", "to", "(", "self", ".", "device", ")", "if", "model", "is", "None", "else", "model", "\n", "\n", "self", ".", "init_dataset", "(", "snippet_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder.init_dataset": [[38, 47], ["isinstance", "summary_dataset.SummaryDataset", "summary_dataset.SummaryCollate", "torch.DataLoader", "torch.DataLoader"], "methods", ["None"], ["", "def", "init_dataset", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "SnippetDataset", ")", ",", "\"Please provide dataset as a SnippetDataset object.\"", "\n", "self", ".", "snippet_dataset", "=", "dataset", "\n", "self", ".", "dataset", "=", "SummaryDataset", "(", "self", ".", "snippet_dataset", ")", "\n", "data_collator", "=", "SummaryCollate", "(", "self", ".", "tokenizer", ",", "self", ".", "source_max_length", ",", "\n", "self", ".", "target_max_length", ")", "\n", "self", ".", "data_loader", "=", "data", ".", "DataLoader", "(", "self", ".", "dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "collate_fn", "=", "data_collator", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder.decode": [[48, 67], ["tqdm.tqdm.tqdm", "decoder.Decoder.snippet_dataset.to_json", "zip", "summary.utils.write_json", "decoder.Decoder.init_dataset", "decoder.Decoder._decode_batch", "float"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json", "home.repos.pwc.inspect_result.curai_curai-research.utils.file_io.write_json", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder.init_dataset", "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder._decode_batch"], ["", "def", "decode", "(", "self", ",", "results_path", ",", "dataset", "=", "None", ")", ":", "\n", "        ", "if", "dataset", "is", "not", "None", ":", "\n", "            ", "self", ".", "init_dataset", "(", "dataset", ")", "\n", "\n", "", "all_snippet_ids", ",", "all_predictions", ",", "all_summary_sum_log_logits", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "self", ".", "data_loader", ",", "desc", "=", "\"Decoding\"", ",", "leave", "=", "True", ")", ":", "\n", "            ", "snippet_ids", ",", "batch_predictions", ",", "sequence_scores", "=", "self", ".", "_decode_batch", "(", "batch", ")", "\n", "all_snippet_ids", "+=", "snippet_ids", "\n", "all_predictions", "+=", "batch_predictions", "\n", "all_summary_sum_log_logits", "+=", "sequence_scores", "\n", "\n", "", "results", "=", "self", ".", "snippet_dataset", ".", "to_json", "(", ")", "\n", "for", "snippet_id", ",", "predicted_summary", ",", "sequence_score", "in", "zip", "(", "all_snippet_ids", ",", "\n", "all_predictions", ",", "all_summary_sum_log_logits", ")", ":", "\n", "            ", "results", "[", "snippet_id", "]", "[", "\"predicted_summary\"", "]", "=", "predicted_summary", "\n", "results", "[", "snippet_id", "]", "[", "\"predicted_summary_sum_log_logits\"", "]", "=", "float", "(", "sequence_score", ")", "\n", "", "write_json", "(", "results", ",", "results_path", ")", "\n", "\n", "return", "all_snippet_ids", ",", "all_predictions", ",", "all_summary_sum_log_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder._decode_batch": [[88, 111], ["batch[].to", "batch[].to", "decoder.Decoder.model.generate", "decoder.Decoder._ids_to_clean_text", "list", "generated_ids_dict[].cpu().numpy", "generated_ids_dict[].cpu"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder._ids_to_clean_text"], ["", "def", "_decode_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "encounter_ids", "=", "batch", "[", "'encounter_ids'", "]", "\n", "source_input_ids", "=", "batch", "[", "'source_input_ids'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "source_attention_mask", "=", "batch", "[", "'source_attention_mask'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "generated_ids_dict", "=", "self", ".", "model", ".", "generate", "(", "\n", "source_input_ids", ",", "\n", "decoder_start_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", ",", "\n", "attention_mask", "=", "source_attention_mask", ",", "\n", "use_cache", "=", "True", ",", "\n", "num_beams", "=", "4", ",", "\n", "max_length", "=", "150", ",", "\n", "repetition_penalty", "=", "2.5", ",", "\n", "no_repeat_ngram_size", "=", "2", ",", "\n", "early_stopping", "=", "True", ",", "\n", "min_length", "=", "0", ",", "\n", "return_dict_in_generate", "=", "True", ",", "\n", "output_scores", "=", "True", ",", "\n", ")", "\n", "\n", "batch_predictions", "=", "self", ".", "_ids_to_clean_text", "(", "generated_ids_dict", "[", "'sequences'", "]", ")", "\n", "sequence_scores", "=", "list", "(", "generated_ids_dict", "[", "'sequences_scores'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "return", "encounter_ids", ",", "batch_predictions", ",", "sequence_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.decoder.Decoder._ids_to_clean_text": [[112, 118], ["decoder.Decoder.tokenizer.batch_decode", "list", "map"], "methods", ["None"], ["", "def", "_ids_to_clean_text", "(", "self", ",", "generated_ids", ")", ":", "\n", "        ", "gen_text", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "\n", "generated_ids", ",", "skip_special_tokens", "=", "True", ",", "\n", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "return", "list", "(", "map", "(", "str", ".", "strip", ",", "gen_text", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.summary_dataset.SummaryDataset.__init__": [[7, 16], ["summary_dataset.SummaryDataset.encounter_ids.append", "summary_dataset.SummaryDataset.sources.append", "utils.data.constants.Text.SPACE.join", "summary_dataset.SummaryDataset.targets.append", "summary_dataset.SummaryDataset.targets.append", "snippet.get_formatted", "utils.data.constants.Text.remove_neg_token"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.types.snippet.Snippet.get_formatted", "home.repos.pwc.inspect_result.curai_curai-research.constants.text.Text.remove_neg_token"], ["    ", "def", "__init__", "(", "self", ",", "snippet_dataset", ")", ":", "\n", "        ", "self", ".", "sources", ",", "self", ".", "targets", ",", "self", ".", "encounter_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "snippet", "in", "snippet_dataset", ":", "\n", "            ", "self", ".", "encounter_ids", ".", "append", "(", "snippet", ".", "uid", ")", "\n", "self", ".", "sources", ".", "append", "(", "Text", ".", "SPACE", ".", "join", "(", "snippet", ".", "get_formatted", "(", ")", ")", ")", "\n", "if", "snippet", ".", "summary", "is", "None", ":", "\n", "                ", "self", ".", "targets", ".", "append", "(", "Text", ".", "EMPTY_STRING", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "targets", ".", "append", "(", "Text", ".", "remove_neg_token", "(", "snippet", ".", "summary", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.summary_dataset.SummaryDataset.__len__": [[17, 19], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sources", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.summary_dataset.SummaryDataset.__getitem__": [[20, 23], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "(", "self", ".", "encounter_ids", "[", "index", "]", ",", "self", ".", "sources", "[", "index", "]", ",", "\n", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.summary_dataset.SummaryCollate.__init__": [[26, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "source_max_length", ",", "target_max_length", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "source_max_length", "=", "source_max_length", "\n", "self", ".", "target_max_length", "=", "target_max_length", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.pegasus.summary_dataset.SummaryCollate.__call__": [[31, 59], ["summary_dataset.SummaryCollate.tokenizer", "summary_dataset.SummaryCollate.tokenizer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "encounter_ids", "=", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", "\n", "sources", "=", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", "\n", "targets", "=", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", "\n", "\n", "#        batch_encoding = self.tokenizer.prepare_seq2seq_batch(", "\n", "#                sources,", "\n", "#                targets,", "\n", "#                max_length=self.source_max_length,", "\n", "#                max_target_length=self.target_max_length,", "\n", "#                padding=\"longest\",", "\n", "#                return_tensors=\"pt\"", "\n", "#        ).data", "\n", "#        batch_encoding[\"encounter_ids\"] = encounter_ids", "\n", "#        return batch_encoding", "\n", "\n", "sources", "=", "self", ".", "tokenizer", "(", "sources", ",", "padding", "=", "'longest'", ",", "\n", "max_length", "=", "self", ".", "source_max_length", ",", "return_tensors", "=", "'pt'", ",", "\n", "truncation", "=", "True", ")", "\n", "targets", "=", "self", ".", "tokenizer", "(", "targets", ",", "padding", "=", "'longest'", ",", "\n", "max_length", "=", "self", ".", "target_max_length", ",", "return_tensors", "=", "'pt'", ",", "\n", "truncation", "=", "True", ")", "\n", "return", "{", "\n", "'encounter_ids'", ":", "encounter_ids", ",", "\n", "'source_input_ids'", ":", "sources", "[", "'input_ids'", "]", ",", "\n", "'source_attention_mask'", ":", "sources", "[", "'attention_mask'", "]", ",", "\n", "'target_input_ids'", ":", "targets", "[", "'input_ids'", "]", ",", "\n", "'target_attention_mask'", ":", "targets", "[", "'attention_mask'", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.__init__": [[19, 28], ["summary.utils.KBConceptRecognizer", "summary.utils.ConceptAffirmationTagger", "rouge_score.rouge_scorer.RougeScorer", "metrics_report.MetricsReport._compute_metrics"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._compute_metrics"], ["def", "__init__", "(", "self", ",", "gold_summaries", ",", "predicted_summaries", ")", ":", "\n", "        ", "self", ".", "gold_summaries", "=", "gold_summaries", "\n", "self", ".", "predicted_summaries", "=", "predicted_summaries", "\n", "\n", "self", ".", "kb_concept_recognizer", "=", "KBConceptRecognizer", "(", ")", "\n", "self", ".", "concept_affirmation_tagger", "=", "ConceptAffirmationTagger", "(", ")", "\n", "self", ".", "rouge_scorer", "=", "rouge_scorer", ".", "RougeScorer", "(", "\n", "[", "\"rougeL\"", "]", ",", "use_stemmer", "=", "True", ")", "\n", "self", ".", "_compute_metrics", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport.to_json": [[29, 38], ["None"], "methods", ["None"], ["", "def", "to_json", "(", "self", ",", "tag", "=", "\"\"", ")", ":", "\n", "        ", "rouge_key", "=", "\"rouge\"", "if", "tag", "is", "\"\"", "else", "f\"rouge.{tag}\"", "\n", "concept_key", "=", "\"concept\"", "if", "tag", "is", "\"\"", "else", "f\"concept.{tag}\"", "\n", "affirmation_key", "=", "\"affirmation\"", "if", "tag", "is", "\"\"", "else", "f\"affirmation.{tag}\"", "\n", "\n", "return", "{", "\n", "rouge_key", ":", "self", ".", "rouge_metrics", ",", "\n", "concept_key", ":", "self", ".", "concept_metrics", ",", "\n", "affirmation_key", ":", "self", ".", "affirmation_metrics", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._compute_metrics": [[40, 75], ["zip", "numpy.array", "numpy.array", "numpy.array", "metrics_report.MetricsReport.rouge_scorer.score", "metrics_report.MetricsReport._get_confusions", "metrics_report.MetricsReport._compute_f1", "metrics_report.MetricsReport._compute_f1", "numpy.array.append", "numpy.array.append", "numpy.array.append", "numpy.array.mean", "numpy.array.std", "numpy.array.mean", "numpy.array.std", "numpy.array.mean", "numpy.array.std"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._get_confusions", "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._compute_f1", "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._compute_f1"], ["", "def", "_compute_metrics", "(", "self", ")", ":", "\n", "        ", "all_affirmation_f1s", ",", "all_concept_f1s", "=", "[", "]", ",", "[", "]", "\n", "all_rouge_f1s", "=", "[", "]", "\n", "for", "gold_summary", ",", "pred_summary", "in", "zip", "(", "self", ".", "gold_summaries", ",", "\n", "self", ".", "predicted_summaries", ")", ":", "\n", "            ", "rouge_metrics", "=", "self", ".", "rouge_scorer", ".", "score", "(", "gold_summary", ",", "\n", "pred_summary", ")", "\n", "concept_confusion", ",", "affirmation_confusion", "=", "self", ".", "_get_confusions", "(", "\n", "gold_summary", ",", "pred_summary", ")", "\n", "\n", "n_tp", ",", "n_fp", ",", "n_tn", ",", "n_fn", "=", "affirmation_confusion", "\n", "c_tp", ",", "c_fp", ",", "c_fn", "=", "concept_confusion", "\n", "affirmation_f1", "=", "self", ".", "_compute_f1", "(", "n_tp", ",", "n_fp", ",", "n_fn", ")", "\n", "concept_f1", "=", "self", ".", "_compute_f1", "(", "c_tp", ",", "c_fp", ",", "c_fn", ")", "\n", "\n", "rouge_l_f1", "=", "rouge_metrics", "[", "\"rougeL\"", "]", ".", "fmeasure", "\n", "all_affirmation_f1s", ".", "append", "(", "affirmation_f1", ")", "\n", "all_concept_f1s", ".", "append", "(", "concept_f1", ")", "\n", "all_rouge_f1s", ".", "append", "(", "rouge_l_f1", ")", "\n", "\n", "", "all_concept_f1s", "=", "np", ".", "array", "(", "all_concept_f1s", ")", "\n", "all_affirmation_f1s", "=", "np", ".", "array", "(", "all_affirmation_f1s", ")", "\n", "all_rouge_f1s", "=", "np", ".", "array", "(", "all_rouge_f1s", ")", "\n", "\n", "self", ".", "rouge_metrics", "=", "{", "\n", "\"f1\"", ":", "all_rouge_f1s", ".", "mean", "(", ")", ",", "\n", "\"std\"", ":", "all_rouge_f1s", ".", "std", "(", ")", ",", "\n", "}", "\n", "self", ".", "concept_metrics", "=", "{", "\n", "\"f1\"", ":", "all_concept_f1s", ".", "mean", "(", ")", ",", "\n", "\"std\"", ":", "all_concept_f1s", ".", "std", "(", ")", ",", "\n", "}", "\n", "self", ".", "affirmation_metrics", "=", "{", "\n", "\"f1\"", ":", "all_affirmation_f1s", ".", "mean", "(", ")", ",", "\n", "\"std\"", ":", "all_affirmation_f1s", ".", "std", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._get_confusions": [[77, 90], ["metrics_report.MetricsReport.kb_concept_recognizer.get_concepts", "metrics_report.MetricsReport.kb_concept_recognizer.get_concepts", "metrics_report.MetricsReport.concept_affirmation_tagger.get_affirmations", "metrics_report.MetricsReport.concept_affirmation_tagger.get_affirmations", "metrics_report.MetricsReport._concept_confusion", "metrics_report.MetricsReport._affirmations_confusion"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.utils.kb_concept_recognizer.KBConceptRecognizer.get_concepts", "home.repos.pwc.inspect_result.curai_curai-research.utils.kb_concept_recognizer.KBConceptRecognizer.get_concepts", "home.repos.pwc.inspect_result.curai_curai-research.utils.concept_affirmation_tagger.ConceptAffirmationTagger.get_affirmations", "home.repos.pwc.inspect_result.curai_curai-research.utils.concept_affirmation_tagger.ConceptAffirmationTagger.get_affirmations", "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._concept_confusion", "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._affirmations_confusion"], ["", "def", "_get_confusions", "(", "self", ",", "gold_summary", ",", "pred_summary", ")", ":", "\n", "        ", "gold_concepts", "=", "self", ".", "kb_concept_recognizer", ".", "get_concepts", "(", "gold_summary", ")", "\n", "pred_concepts", "=", "self", ".", "kb_concept_recognizer", ".", "get_concepts", "(", "pred_summary", ")", "\n", "gold_affirmations", "=", "self", ".", "concept_affirmation_tagger", ".", "get_affirmations", "(", "\n", "gold_summary", ",", "gold_concepts", ")", "\n", "pred_affirmations", "=", "self", ".", "concept_affirmation_tagger", ".", "get_affirmations", "(", "\n", "pred_summary", ",", "pred_concepts", ")", "\n", "\n", "concept_confusion", "=", "self", ".", "_concept_confusion", "(", "gold_concepts", ",", "\n", "pred_concepts", ")", "\n", "affirmation_confusion", "=", "self", ".", "_affirmations_confusion", "(", "\n", "gold_affirmations", ",", "pred_affirmations", ")", "\n", "return", "concept_confusion", ",", "affirmation_confusion", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._compute_f1": [[91, 107], ["None"], "methods", ["None"], ["", "def", "_compute_f1", "(", "self", ",", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "        ", "if", "tp", "+", "fp", "!=", "0", ":", "\n", "            ", "precision", "=", "tp", "/", "(", "tp", "+", "fp", ")", "\n", "", "else", ":", "\n", "            ", "precision", "=", "0.", "\n", "\n", "", "if", "tp", "+", "fn", "!=", "0", ":", "\n", "            ", "recall", "=", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "", "else", ":", "\n", "            ", "recall", "=", "0.", "\n", "\n", "", "if", "precision", "+", "recall", "!=", "0", ":", "\n", "            ", "f1", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "", "else", ":", "\n", "            ", "f1", "=", "0.", "\n", "", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._concept_confusion": [[108, 115], ["set", "set", "len", "len", "len", "set.intersection"], "methods", ["None"], ["", "def", "_concept_confusion", "(", "self", ",", "gold_concepts", ",", "pred_concepts", ")", ":", "\n", "        ", "gold_concepts", "=", "set", "(", "gold_concepts", ")", "\n", "pred_concepts", "=", "set", "(", "pred_concepts", ")", "\n", "tp", "=", "len", "(", "gold_concepts", ".", "intersection", "(", "pred_concepts", ")", ")", "\n", "fp", "=", "len", "(", "pred_concepts", "-", "gold_concepts", ")", "\n", "fn", "=", "len", "(", "gold_concepts", "-", "pred_concepts", ")", "\n", "return", "tp", ",", "fp", ",", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.metrics.metrics_report.MetricsReport._affirmations_confusion": [[116, 133], ["pred_affirmations.items"], "methods", ["None"], ["", "def", "_affirmations_confusion", "(", "self", ",", "gold_affirmations", ",", "pred_affirmations", ")", ":", "\n", "        ", "tp", ",", "fp", ",", "tn", ",", "fn", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "for", "concept", ",", "negation", "in", "pred_affirmations", ".", "items", "(", ")", ":", "\n", "            ", "if", "concept", "not", "in", "gold_affirmations", ":", "\n", "                ", "continue", "\n", "", "concept_agree", "=", "negation", "==", "gold_affirmations", "[", "concept", "]", "\n", "if", "concept_agree", ":", "\n", "                ", "if", "not", "negation", ":", "\n", "                    ", "tp", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "tn", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "if", "not", "negation", ":", "\n", "                    ", "fp", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "fn", "+=", "1", "\n", "", "", "", "return", "tp", ",", "fp", ",", "tn", ",", "fn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.ConversationDataset.__init__": [[97, 121], ["os.path.join", "os.path.exists", "logger.info", "logger.info", "df.iterrows", "logger.info", "str", "open", "pickle.load", "dialogpt.construct_conv", "dialogpt.ConversationDataset.examples.append", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.construct_conv"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "df", ",", "block_size", "=", "512", ")", ":", "\n", "\n", "        ", "block_size", "=", "block_size", "-", "(", "tokenizer", ".", "model_max_length", "-", "tokenizer", ".", "max_len_single_sentence", ")", "\n", "\n", "directory", "=", "args", ".", "cache_dir", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "directory", ",", "args", ".", "model_type", "+", "\"_cached_lm_\"", "+", "str", "(", "block_size", ")", "\n", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "                ", "self", ".", "examples", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "directory", ")", "\n", "\n", "self", ".", "examples", "=", "[", "]", "\n", "for", "_", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "                ", "conv", "=", "construct_conv", "(", "row", ",", "tokenizer", ")", "\n", "self", ".", "examples", ".", "append", "(", "conv", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "with", "open", "(", "cached_features_file", ",", "\"wb\"", ")", "as", "handle", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.ConversationDataset.__len__": [[122, 124], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.ConversationDataset.__getitem__": [[125, 127], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.parse_args": [[48, 83], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "bool", "distutils.util.strtobool", "distutils.util.strtobool", "distutils.util.strtobool", "distutils.util.strtobool", "distutils.util.strtobool", "distutils.util.strtobool", "distutils.util.strtobool", "distutils.util.strtobool", "distutils.util.strtobool"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.model.build_dataset.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset_artifact\"", ",", "default", "=", "\"dialogpt/dialogpt:latest\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "\"output-medium\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"gpt2\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "\"microsoft/DialoGPT-medium\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"microsoft/DialoGPT-medium\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"microsoft/DialoGPT-medium\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"cached\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--block_size\"", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "default", "=", "True", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "default", "=", "True", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "default", "=", "False", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--gradient_accumulation_steps\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "3e-4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_steps\"", ",", "default", "=", "2500", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_total_limit\"", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "default", "=", "False", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "default", "=", "False", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_output_dir\"", ",", "default", "=", "True", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_cache\"", ",", "default", "=", "True", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp16\"", ",", "default", "=", "False", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp16_opt_level\"", ",", "default", "=", "'O1'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--track\"", ",", "default", "=", "False", ",", "type", "=", "lambda", "x", ":", "bool", "(", "strtobool", "(", "x", ")", ")", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.prepare_dataset": [[86, 89], ["sklearn.model_selection.train_test_split"], "function", ["None"], ["def", "prepare_dataset", "(", "df", ")", ":", "\n", "    ", "trn_df", ",", "val_df", "=", "train_test_split", "(", "df", ",", "test_size", "=", "0.1", ")", "\n", "return", "trn_df", ",", "val_df", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.construct_conv": [[90, 95], ["list", "flatten", "reversed", "tokenizer.encode"], "function", ["None"], ["", "def", "construct_conv", "(", "row", ",", "tokenizer", ",", "eos", "=", "True", ")", ":", "\n", "    ", "flatten", "=", "lambda", "l", ":", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "conv", "=", "list", "(", "reversed", "(", "[", "tokenizer", ".", "encode", "(", "x", ")", "+", "[", "tokenizer", ".", "eos_token_id", "]", "for", "x", "in", "row", "if", "x", "]", ")", ")", "\n", "conv", "=", "flatten", "(", "conv", ")", "\n", "return", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.load_and_cache_examples": [[130, 132], ["dialogpt.ConversationDataset"], "function", ["None"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "df_trn", ",", "df_val", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "return", "ConversationDataset", "(", "tokenizer", ",", "args", ",", "df_val", "if", "evaluate", "else", "df_trn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.train": [[134, 310], ["torch.utils.data.DataLoader", "torch.nn.parallel.DistributedDataParallel.resize_token_embeddings", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "torch.utils.tensorboard.SummaryWriter", "torch.nn.utils.rnn.pad_sequence", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "hasattr", "len", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "torch.utils.tensorboard.SummaryWriter.close", "torch.nn.utils.rnn.pad_sequence", "os.path.join", "os.path.join", "torch.load", "torch.load", "torch.utils.tensorboard.SummaryWriter.add_scalar", "inputs.to.to", "labels.to.to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "logger.info", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "dialogpt.evaluate", "evaluate.items", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "torch.utils.tensorboard.SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.train", "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "df_val", ")", "->", "Tuple", "[", "int", ",", "float", "]", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "if", "tokenizer", ".", "_pad_token", "is", "None", ":", "\n", "            ", "return", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ")", "\n", "", "return", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "collate_fn", "=", "collate", ",", "drop_last", "=", "True", "\n", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "", "model", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "# add_special_tokens_(model, tokenizer)", "\n", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "global_step", "+=", "1", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"batch_size\"", ",", "inputs", ".", "shape", "[", "1", "]", ",", "global_step", ")", "\n", "if", "inputs", ".", "shape", "[", "1", "]", ">", "1024", ":", "continue", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "eval_steps", ">", "0", "and", "global_step", "%", "args", ".", "eval_steps", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Beginning evaluation...\"", ")", "\n", "# Log metrics", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "None", ",", "df_val", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "\n", "", "", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "# _rotate_checkpoints(args, checkpoint_prefix)", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.evaluate": [[313, 370], ["dialogpt.load_and_cache_examples", "os.makedirs", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.DataParallel", "len", "inputs.to.to", "labels.to.to", "torch.tensor", "open", "logger.info", "sorted", "torch.nn.utils.rnn.pad_sequence", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.dialogpt.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "df_trn", ",", "df_val", ",", "prefix", "=", "\"\"", ")", "->", "Dict", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "df_trn", ",", "df_val", ",", "evaluate", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "eval_output_dir", ",", "exist_ok", "=", "True", ")", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "if", "tokenizer", ".", "_pad_token", "is", "None", ":", "\n", "            ", "return", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ")", "\n", "", "return", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "collate", ",", "drop_last", "=", "True", "\n", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "lm_loss", "=", "outputs", "[", "0", "]", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", ",", "\n", "\"loss\"", ":", "eval_loss", "\n", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.1-dialogpt.utils.get_datetime_string": [[7, 15], ["datetime.datetime.now", "date.astimezone.astimezone", "date.astimezone.strftime", "pytz.timezone"], "function", ["None"], ["def", "get_datetime_string", "(", "date_format", "=", "\"%m_%d_%Y-%H_%M_%S\"", ")", "->", "str", ":", "\n", "    ", "'''\n    We'll use PST (California time) for our project timestamps\n    '''", "\n", "date", "=", "datetime", ".", "now", "(", "tz", "=", "pytz", ".", "utc", ")", "\n", "date", "=", "date", ".", "astimezone", "(", "timezone", "(", "'US/Pacific'", ")", ")", "\n", "pstDateTime", "=", "date", ".", "strftime", "(", "date_format", ")", "\n", "return", "pstDateTime", "\n", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.0-gpt3_paraphrasing.query_openai.extract": [[30, 48], ["range", "openai.Completion.create", "[].strip", "random.choice", "print", "range"], "function", ["None"], ["def", "extract", "(", "prompt", ",", "temp", "=", "0.65", ")", ":", "\n", "    ", "if", "TEST", ":", "\n", "        ", "return", "''", ".", "join", "(", "\n", "random", ".", "choice", "(", "string", ".", "ascii_lowercase", ")", "for", "i", "in", "range", "(", "10", ")", ")", "\n", "", "for", "_", "in", "range", "(", "4", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "api_result", "=", "openai", ".", "Completion", ".", "create", "(", "engine", "=", "\"davinci\"", ",", "\n", "stream", "=", "False", ",", "\n", "prompt", "=", "prompt", ",", "\n", "temperature", "=", "temp", ",", "\n", "max_tokens", "=", "80", ",", "\n", "stop", "=", "\"\\n\"", ")", "\n", "output", "=", "api_result", ".", "choices", "[", "0", "]", "[", "\"text\"", "]", ".", "strip", "(", ")", "\n", "return", "output", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "\n", "", "", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.0-gpt3_paraphrasing.query_openai.create_prompt": [[50, 68], ["train_df.sample", "all_prompts_formatted.append", "PROMPT_FORMAT.format", "PROMPT_FORMAT.format", "train_df.sample.iterrows"], "function", ["None"], ["", "def", "create_prompt", "(", "prompt_method", ",", "row", ")", ":", "\n", "    ", "to_take", "=", "10", "\n", "train_prompts", "=", "train_df", ".", "sample", "(", "to_take", ")", "\n", "\n", "all_prompts_formatted", "=", "[", "\n", "PROMPT_FORMAT", ".", "format", "(", "symptom", "=", "inst", "[", "\"Finding\"", "]", ",", "\n", "kb_q", "=", "inst", "[", "\"KB Question\"", "]", ",", "\n", "rephrased_q", "=", "inst", "[", "\"Rephrased\"", "]", ")", "\n", "for", "i", ",", "inst", "in", "train_prompts", ".", "iterrows", "(", ")", "\n", "]", "\n", "\n", "all_prompts_formatted", ".", "append", "(", "\n", "PROMPT_FORMAT", ".", "format", "(", "symptom", "=", "row", "[", "\"Finding\"", "]", ",", "\n", "kb_q", "=", "row", "[", "\"KB Question\"", "]", ",", "\n", "rephrased_q", "=", "\"\"", ")", ")", "\n", "\n", "return", "\"Rephrase the question asking if the patient has the given symptom\\n\"", "+", "\"\\n\"", ".", "join", "(", "\n", "all_prompts_formatted", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.0-gpt3_paraphrasing.query_openai.finding_in_prompt": [[70, 72], ["None"], "function", ["None"], ["", "def", "finding_in_prompt", "(", "symptom", ")", ":", "\n", "    ", "return", "symptom", "in", "[", "s", "[", "0", "]", "for", "s", "in", "train_df", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.0-gpt3_paraphrasing.query_openai.main": [[74, 112], ["already_generated_df[].unique", "list", "print", "test_df.iterrows", "generations.pop", "results.append", "print", "open", "json.dump", "print", "len", "query_openai.create_prompt", "query_openai.extract", "prompts.append", "generations.append", "set"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.0-gpt3_paraphrasing.query_openai.create_prompt", "home.repos.pwc.inspect_result.curai_curai-research.0-gpt3_paraphrasing.query_openai.extract"], ["", "def", "main", "(", ")", ":", "\n", "    ", "results", "=", "[", "]", "\n", "\n", "ignored", "=", "0", "\n", "already_generated_findings", "=", "already_generated_df", "[", "\"Finding\"", "]", ".", "unique", "(", ")", "\n", "for", "index_label", ",", "row", "in", "list", "(", "test_df", ".", "iterrows", "(", ")", ")", ":", "\n", "        ", "if", "row", "[", "\"Finding\"", "]", "in", "already_generated_findings", ":", "\n", "            ", "print", "(", "\"\\tAlready generated for\"", ",", "row", "[", "\"Finding\"", "]", ")", "\n", "ignored", "+=", "1", "\n", "continue", "\n", "\n", "# Keep generating until we get n distinct questions", "\n", "# We add the KB Question in initially because we want to count that as a 'duplicate'", "\n", "# generation also", "\n", "", "generations", "=", "[", "row", "[", "\"KB Question\"", "]", "]", "\n", "prompts", "=", "[", "]", "\n", "num_distinct_to_generate", "=", "5", "\n", "while", "len", "(", "set", "(", "generations", ")", "\n", ")", "<", "num_distinct_to_generate", "+", "1", ":", "# + 1 for the KB Question", "\n", "            ", "prompt", "=", "create_prompt", "(", "None", ",", "row", ")", "\n", "generation", "=", "extract", "(", "prompt", ")", "\n", "prompts", ".", "append", "(", "prompt", ")", "\n", "generations", ".", "append", "(", "generation", ")", "\n", "\n", "# Take the KB question back out", "\n", "", "generations", ".", "pop", "(", "0", ")", "\n", "results", ".", "append", "(", "{", "\n", "\"symptom\"", ":", "row", "[", "\"Finding\"", "]", ",", "\n", "\"prompts\"", ":", "prompts", ",", "\n", "\"kb_question\"", ":", "row", "[", "\"KB Question\"", "]", ",", "\n", "\"generation\"", ":", "generations", "\n", "}", ")", "\n", "\n", "print", "(", "f\"Completed prompt {index_label} ({row['Finding']})\"", ")", "\n", "\n", "", "print", "(", "\"Ignored\"", ",", "ignored", ")", "\n", "with", "open", "(", "\"output/gpt3_results.json\"", ",", "mode", "=", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.train.parse_args": [[27, 31], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.model.build_dataset.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset_artifact\"", ",", "default", "=", "\"dialogpt/dialogpt:latest\"", ",", "type", "=", "str", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.train.download_data": [[32, 52], ["wandb.init", "wandb.init.use_artifact", "run.use_artifact.download", "open", "pickle.load", "open", "pickle.load", "utils.get_datetime_string", "vars"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.model.utils.get_datetime_string"], ["", "def", "download_data", "(", "dataset_artifact", ")", ":", "\n", "    ", "experiment_name", "=", "f\"Train Model: {get_datetime_string()}\"", "\n", "train_filename", ",", "val_filename", "=", "\"dataset_train.pkl\"", ",", "\"dataset_val.pkl\"", "\n", "run", "=", "wandb", ".", "init", "(", "\n", "project", "=", "\"empathy-prediction\"", ",", "\n", "sync_tensorboard", "=", "True", ",", "\n", "config", "=", "vars", "(", "args", ")", ",", "# Automatically log all config vars", "\n", "name", "=", "experiment_name", ",", "\n", "save_code", "=", "False", ",", "\n", "job_type", "=", "\"train\"", ")", "\n", "artifact", "=", "run", ".", "use_artifact", "(", "dataset_artifact", ",", "type", "=", "'dataset'", ")", "\n", "artifact_dir", "=", "artifact", ".", "download", "(", ")", "\n", "dataset_path", "=", "f\"{artifact_dir}/\"", "\n", "\n", "with", "open", "(", "dataset_path", "+", "train_filename", ",", "'rb'", ")", "as", "handle", ":", "\n", "        ", "df_trn", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "with", "open", "(", "dataset_path", "+", "val_filename", ",", "'rb'", ")", "as", "handle", ":", "\n", "        ", "df_val", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "\n", "", "return", "df_trn", ",", "df_val", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.train.save_model": [[53, 60], ["wandb.Artifact", "wandb.Artifact.add_file", "wandb.run.log_artifact", "open", "pickle.dump"], "function", ["None"], ["", "def", "save_model", "(", "model", ",", "filename", "=", "\"model.pkl\"", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "mode", "=", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "model", ",", "f", ")", "\n", "\n", "", "model_artifact", "=", "wandb", ".", "Artifact", "(", "'model'", ",", "type", "=", "'model'", ")", "\n", "model_artifact", ".", "add_file", "(", "filename", ")", "\n", "wandb", ".", "run", ".", "log_artifact", "(", "model_artifact", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.EmbedTransform.__init__": [[11, 18], ["sentence_transformers.SentenceTransformer", "len", "print", "sentence_transformers.SentenceTransformer.encode"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "embedding_model", "=", "'paraphrase-mpnet-base-v2'", "\n", "model", "=", "SentenceTransformer", "(", "embedding_model", ")", "\n", "model", ".", "max_seq_length", "=", "512", "\n", "self", ".", "embedding_len", "=", "len", "(", "model", ".", "encode", "(", "\"test\"", ")", ")", "\n", "print", "(", "\"Embedding length:\"", ",", "self", ".", "embedding_len", ")", "\n", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.EmbedTransform.fit": [[19, 21], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.EmbedTransform.transform": [[22, 37], ["X.copy", "pandas.concat", "X[].progress_map", "pandas.DataFrame", "X_copy[].to_list", "range"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "X", ")", ":", "\n", "# Create the embeddings", "\n", "        ", "X_copy", "=", "X", ".", "copy", "(", ")", "\n", "for", "name", "in", "INPUT_FEATURES", ":", "\n", "            ", "X_copy", "[", "f\"{name}_emb\"", "]", "=", "X", "[", "name", "]", ".", "progress_map", "(", "self", ".", "model", ".", "encode", ")", "\n", "\n", "# Expand out and combine the embeddings into a single dataframe", "\n", "", "split_cols", "=", "[", "\n", "pd", ".", "DataFrame", "(", "X_copy", "[", "f\"{name}_emb\"", "]", ".", "to_list", "(", ")", ",", "columns", "=", "[", "f\"{name}_feat{i + 1}\"", "for", "i", "in", "range", "(", "self", ".", "embedding_len", ")", "]", ")", "\n", "for", "name", "in", "INPUT_FEATURES", "]", "\n", "\n", "# Concatenate them all into one giant 768 * 3 column wide DF", "\n", "concat", "=", "pd", ".", "concat", "(", "split_cols", ",", "axis", "=", "1", ")", "\n", "\n", "return", "concat", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.__init__": [[44, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n_components", "=", "20", ")", ":", "\n", "        ", "self", ".", "n_components", "=", "n_components", "\n", "self", ".", "pca_fit", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.fit": [[48, 51], ["sklearn.decomposition.PCA().fit", "sklearn.decomposition.PCA"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.fit"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "self", ".", "pca_fit", "=", "PCA", "(", "n_components", "=", "self", ".", "n_components", ",", "random_state", "=", "42", ")", ".", "fit", "(", "X", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.transform": [[52, 54], ["pipeline.MessagePCA.pca_fit.transform"], "methods", ["home.repos.pwc.inspect_result.curai_curai-research.model.pipeline.MessagePCA.transform"], ["", "def", "transform", "(", "self", ",", "X", ")", ":", "\n", "        ", "return", "self", ".", "pca_fit", ".", "transform", "(", "X", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.model.utils.get_datetime_string": [[7, 15], ["datetime.datetime.now", "date.astimezone.astimezone", "date.astimezone.strftime", "pytz.timezone"], "function", ["None"], ["def", "get_datetime_string", "(", "date_format", "=", "\"%m_%d_%Y-%H_%M_%S\"", ")", "->", "str", ":", "\n", "    ", "'''\n    We'll use PST (California time) for our project timestamps\n    '''", "\n", "date", "=", "datetime", ".", "now", "(", "tz", "=", "pytz", ".", "utc", ")", "\n", "date", "=", "date", ".", "astimezone", "(", "timezone", "(", "'US/Pacific'", ")", ")", "\n", "pstDateTime", "=", "date", ".", "strftime", "(", "date_format", ")", "\n", "return", "pstDateTime", "\n", "", ""]], "home.repos.pwc.inspect_result.curai_curai-research.model.build_dataset.parse_args": [[8, 12], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.curai_curai-research.model.build_dataset.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_path\"", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]]}