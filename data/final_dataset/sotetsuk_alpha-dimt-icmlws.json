{"home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.translate.reportScore": [[47, 51], ["print", "math.exp"], "function", ["None"], ["def", "reportScore", "(", "name", ",", "scoreTotal", ",", "wordsTotal", ")", ":", "\n", "    ", "print", "(", "\"%s AVG SCORE: %.4f, %s PPL: %.4f\"", "%", "(", "\n", "name", ",", "scoreTotal", "/", "wordsTotal", ",", "\n", "name", ",", "math", ".", "exp", "(", "-", "scoreTotal", "/", "wordsTotal", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.translate.addone": [[52, 56], ["None"], "function", ["None"], ["", "def", "addone", "(", "f", ")", ":", "\n", "    ", "for", "line", "in", "f", ":", "\n", "        ", "yield", "line", "\n", "", "yield", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.translate.main": [[57, 133], ["parser.parse_args", "onmt.Translator", "codecs.open", "translate.addone", "translate.reportScore", "torch.cuda.set_device", "codecs.open", "codecs.open", "onmt.Translator.translate", "sum", "sum", "range", "translate.reportScore", "tgtF.close", "line.split", "sum", "sum", "len", "codecs.open.write", "codecs.open.flush", "len", "len", "len", "print", "print", "print", "print", "tgtF.readline().split", "len", "srcSent.lower.lower", "print", "print", "print", "range", "tgtSent.lower.lower", "print", "tgtF.readline"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.translate.addone", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.translate.reportScore", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.translate", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.translate.reportScore"], ["", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "", "translator", "=", "onmt", ".", "Translator", "(", "opt", ")", "\n", "\n", "outF", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w'", ",", "'utf-8'", ")", "\n", "\n", "predScoreTotal", ",", "predWordsTotal", ",", "goldScoreTotal", ",", "goldWordsTotal", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "\n", "srcBatch", ",", "tgtBatch", "=", "[", "]", ",", "[", "]", "\n", "\n", "count", "=", "0", "\n", "\n", "tgtF", "=", "codecs", ".", "open", "(", "opt", ".", "tgt", ",", "'r'", ",", "'utf-8'", ")", "if", "opt", ".", "tgt", "else", "None", "\n", "for", "line", "in", "addone", "(", "codecs", ".", "open", "(", "opt", ".", "src", ",", "'r'", ",", "'utf-8'", ")", ")", ":", "\n", "\n", "        ", "if", "line", "is", "not", "None", ":", "\n", "            ", "srcTokens", "=", "line", ".", "split", "(", ")", "\n", "srcBatch", "+=", "[", "srcTokens", "]", "\n", "if", "tgtF", ":", "\n", "                ", "tgtTokens", "=", "tgtF", ".", "readline", "(", ")", ".", "split", "(", ")", "if", "tgtF", "else", "None", "\n", "tgtBatch", "+=", "[", "tgtTokens", "]", "\n", "\n", "", "if", "len", "(", "srcBatch", ")", "<", "opt", ".", "batch_size", ":", "\n", "                ", "continue", "\n", "", "", "else", ":", "\n", "# at the end of file, check last batch", "\n", "            ", "if", "len", "(", "srcBatch", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "predBatch", ",", "predScore", ",", "goldScore", "=", "translator", ".", "translate", "(", "srcBatch", ",", "tgtBatch", ")", "\n", "\n", "predScoreTotal", "+=", "sum", "(", "score", "[", "0", "]", "for", "score", "in", "predScore", ")", "\n", "predWordsTotal", "+=", "sum", "(", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "predBatch", ")", "\n", "if", "tgtF", "is", "not", "None", ":", "\n", "            ", "goldScoreTotal", "+=", "sum", "(", "goldScore", ")", "\n", "goldWordsTotal", "+=", "sum", "(", "len", "(", "x", ")", "for", "x", "in", "tgtBatch", ")", "\n", "\n", "", "for", "b", "in", "range", "(", "len", "(", "predBatch", ")", ")", ":", "\n", "            ", "count", "+=", "1", "\n", "outF", ".", "write", "(", "\" \"", ".", "join", "(", "predBatch", "[", "b", "]", "[", "0", "]", ")", "+", "'\\n'", ")", "\n", "outF", ".", "flush", "(", ")", "\n", "\n", "if", "opt", ".", "verbose", ":", "\n", "                ", "srcSent", "=", "' '", ".", "join", "(", "srcBatch", "[", "b", "]", ")", "\n", "if", "translator", ".", "tgt_dict", ".", "lower", ":", "\n", "                    ", "srcSent", "=", "srcSent", ".", "lower", "(", ")", "\n", "", "print", "(", "'SENT %d: %s'", "%", "(", "count", ",", "srcSent", ")", ")", "\n", "print", "(", "'PRED %d: %s'", "%", "(", "count", ",", "\" \"", ".", "join", "(", "predBatch", "[", "b", "]", "[", "0", "]", ")", ")", ")", "\n", "print", "(", "\"PRED SCORE: %.4f\"", "%", "predScore", "[", "b", "]", "[", "0", "]", ")", "\n", "\n", "if", "tgtF", "is", "not", "None", ":", "\n", "                    ", "tgtSent", "=", "' '", ".", "join", "(", "tgtBatch", "[", "b", "]", ")", "\n", "if", "translator", ".", "tgt_dict", ".", "lower", ":", "\n", "                        ", "tgtSent", "=", "tgtSent", ".", "lower", "(", ")", "\n", "", "print", "(", "'GOLD %d: %s '", "%", "(", "count", ",", "tgtSent", ")", ")", "\n", "print", "(", "\"GOLD SCORE: %.4f\"", "%", "goldScore", "[", "b", "]", ")", "\n", "\n", "", "if", "opt", ".", "n_best", ">", "1", ":", "\n", "                    ", "print", "(", "'\\nBEST HYP:'", ")", "\n", "for", "n", "in", "range", "(", "opt", ".", "n_best", ")", ":", "\n", "                        ", "print", "(", "\"[%.4f] %s\"", "%", "(", "predScore", "[", "b", "]", "[", "n", "]", ",", "\" \"", ".", "join", "(", "predBatch", "[", "b", "]", "[", "n", "]", ")", ")", ")", "\n", "\n", "", "", "print", "(", "''", ")", "\n", "\n", "", "", "srcBatch", ",", "tgtBatch", "=", "[", "]", ",", "[", "]", "\n", "\n", "", "reportScore", "(", "'PRED'", ",", "predScoreTotal", ",", "predWordsTotal", ")", "\n", "if", "tgtF", ":", "\n", "        ", "reportScore", "(", "'GOLD'", ",", "goldScoreTotal", ",", "goldWordsTotal", ")", "\n", "\n", "", "if", "tgtF", ":", "\n", "        ", "tgtF", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.eval": [[166, 184], ["model.eval", "range", "model.train", "len", "model", "onmt.memoryEfficientLoss", "targets.data.ne().sum", "targets.data.ne"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.eval", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.memoryEfficientLoss"], ["def", "eval", "(", "model", ",", "criterion", ",", "data", ")", ":", "\n", "    ", "total_loss", "=", "0", "\n", "total_words", "=", "0", "\n", "total_num_correct", "=", "0", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "        ", "batch", "=", "data", "[", "i", "]", "[", ":", "2", "]", "# exclude original indices", "\n", "outputs", "=", "model", "(", "batch", ")", "\n", "targets", "=", "batch", "[", "1", "]", "[", "1", ":", "]", "# exclude <s> from targets", "\n", "loss", ",", "_", ",", "num_correct", "=", "onmt", ".", "memoryEfficientLoss", "(", "\n", "outputs", ",", "targets", ",", "model", ".", "generator", ",", "criterion", ",", "opt", ".", "max_generator_batches", ",", "eval", "=", "True", ")", "\n", "total_loss", "+=", "loss", "\n", "total_num_correct", "+=", "num_correct", "\n", "total_words", "+=", "targets", ".", "data", ".", "ne", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "return", "total_loss", "/", "total_words", ",", "total_num_correct", "/", "total_words", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.trainModel": [[186, 340], ["print", "sys.stdout.flush", "model.train", "onmt.NMTCriterion", "time.time", "[].size", "onmt.AlphaCriterion", "torch.randperm", "torch.randperm", "time.time", "range", "print", "math.exp", "print", "print", "train.eval", "math.exp", "print", "print", "train.translate", "float", "print", "scores.append", "optim.dev_decay", "model.state_dict", "model.generator.state_dict", "print", "torch.save", "torch.save", "[].size", "trainData.shuffle", "len", "len", "model.zero_grad", "model", "model.backward", "optim.step", "targets.data.ne().sum", "sum", "train.trainModel.trainEpoch"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.NMTCriterion", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.AlphaCriterion", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.eval", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.translate", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.dev_decay", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.ISDataset.shuffle", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.step"], ["", "def", "trainModel", "(", "model", ",", "trainData", ",", "validData", ",", "dataset", ",", "optim", ")", ":", "\n", "    ", "print", "(", "model", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# define criterion of each GPU", "\n", "criterion", "=", "onmt", ".", "NMTCriterion", "(", "dataset", "[", "'dicts'", "]", "[", "'tgt'", "]", ".", "size", "(", ")", ",", "opt", ".", "cuda", ")", "\n", "if", "opt", ".", "raml_alpha", ":", "\n", "        ", "train_criterion", "=", "onmt", ".", "AlphaCriterion", "(", "dataset", "[", "'dicts'", "]", "[", "'tgt'", "]", ".", "size", "(", ")", ",", "opt", ".", "cuda", ")", "\n", "", "else", ":", "\n", "        ", "train_criterion", "=", "criterion", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "def", "trainEpoch", "(", "epoch", ")", ":", "\n", "\n", "        ", "if", "opt", ".", "extra_shuffle", "and", "epoch", ">", "opt", ".", "curriculum", ":", "\n", "            ", "trainData", ".", "shuffle", "(", ")", "\n", "\n", "# shuffle mini batch order", "\n", "", "batchOrder", "=", "torch", ".", "randperm", "(", "len", "(", "trainData", ")", ")", "\n", "\n", "total_loss", ",", "total_words", ",", "total_num_correct", "=", "0", ",", "0", ",", "0", "\n", "report_loss", ",", "report_tgt_words", ",", "report_src_words", ",", "report_num_correct", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "importance_list", "=", "[", "]", "\n", "p_sample_efficiency_list", "=", "[", "]", "\n", "q_sample_efficiency_list", "=", "[", "]", "\n", "pq_sample_efficiency_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "trainData", ")", ")", ":", "\n", "\n", "            ", "batchIdx", "=", "batchOrder", "[", "i", "]", "if", "epoch", ">", "opt", ".", "curriculum", "else", "i", "\n", "batch", "=", "trainData", "[", "batchIdx", "]", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", "(", "batch", "[", ":", "2", "]", ")", "# exclude original indices", "\n", "targets", "=", "batch", "[", "1", "]", "[", "1", ":", "]", "# exclude <s> from targets", "\n", "if", "opt", ".", "raml_alpha", ":", "\n", "                ", "rewards", "=", "batch", "[", "-", "2", "]", "\n", "proposed_weights", "=", "batch", "[", "-", "1", "]", "\n", "loss", ",", "gradOutput", ",", "num_correct", ",", "_importance_list", ",", "_p_sample_efficiency_list", ",", "_q_sample_efficiency_list", ",", "_pq_sample_efficiency_list", "=", "onmt", ".", "alpha_loss", "(", "\n", "outputs", ",", "targets", ",", "model", ".", "generator", ",", "train_criterion", ",", "opt", ".", "max_generator_batches", ",", "\n", "rewards", ",", "proposed_weights", ",", "opt", ".", "tau", ",", "alpha", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss", ",", "gradOutput", ",", "num_correct", "=", "onmt", ".", "memoryEfficientLoss", "(", "\n", "outputs", ",", "targets", ",", "model", ".", "generator", ",", "train_criterion", ",", "opt", ".", "max_generator_batches", ")", "\n", "\n", "", "outputs", ".", "backward", "(", "gradOutput", ")", "\n", "\n", "# update the parameters", "\n", "optim", ".", "step", "(", ")", "\n", "\n", "num_words", "=", "targets", ".", "data", ".", "ne", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", "\n", "report_loss", "+=", "loss", "\n", "report_num_correct", "+=", "num_correct", "\n", "report_tgt_words", "+=", "num_words", "\n", "report_src_words", "+=", "sum", "(", "batch", "[", "0", "]", "[", "1", "]", ")", "\n", "total_loss", "+=", "loss", "\n", "total_num_correct", "+=", "num_correct", "\n", "total_words", "+=", "num_words", "\n", "if", "opt", ".", "raml_alpha", ":", "\n", "                ", "importance_list", "+=", "_importance_list", "\n", "p_sample_efficiency_list", "+=", "_p_sample_efficiency_list", "\n", "q_sample_efficiency_list", "+=", "_q_sample_efficiency_list", "\n", "pq_sample_efficiency_list", "+=", "_pq_sample_efficiency_list", "\n", "", "if", "i", "%", "opt", ".", "log_interval", "==", "-", "1", "%", "opt", ".", "log_interval", ":", "\n", "                ", "print", "(", "\"Epoch %2d, %5d/%5d; acc: %6.2f; ppl: %6.2f; %3.0f src tok/s; %3.0f tgt tok/s; %6.0f s elapsed\"", "%", "\n", "(", "epoch", ",", "i", "+", "1", ",", "len", "(", "trainData", ")", ",", "\n", "report_num_correct", "/", "report_tgt_words", "*", "100", ",", "\n", "math", ".", "exp", "(", "report_loss", "/", "report_tgt_words", ")", ",", "\n", "report_src_words", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", ",", "\n", "report_tgt_words", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "report_loss", "=", "report_tgt_words", "=", "report_src_words", "=", "report_num_correct", "=", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "", "return", "total_loss", "/", "total_words", ",", "total_num_correct", "/", "total_words", ",", "importance_list", ",", "p_sample_efficiency_list", ",", "q_sample_efficiency_list", ",", "pq_sample_efficiency_list", "\n", "\n", "", "epoch", "=", "0", "\n", "while", "True", ":", "\n", "        ", "epoch", "+=", "1", "\n", "print", "(", "''", ")", "\n", "\n", "#  (1) train for one epoch on the training set", "\n", "if", "opt", ".", "raml_alpha", ":", "\n", "            ", "train_loss", ",", "train_acc", ",", "train_importance_list", ",", "p_sample_efficiency_list", ",", "q_sample_efficiency_list", ",", "pq_sample_efficiency_list", "=", "trainEpoch", "(", "epoch", ")", "\n", "train_importance_list", "=", "np", ".", "array", "(", "train_importance_list", ")", "\n", "p_sample_efficiency_list", "=", "np", ".", "array", "(", "p_sample_efficiency_list", ")", "\n", "q_sample_efficiency_list", "=", "np", ".", "array", "(", "q_sample_efficiency_list", ")", "\n", "pq_sample_efficiency_list", "=", "np", ".", "array", "(", "pq_sample_efficiency_list", ")", "\n", "# print('Train importance mean: %g' % train_importance_list.mean())", "\n", "# print('Train importance std: %g' % train_importance_list.std())", "\n", "# print('P Sample efficiency mean: %g' % p_sample_efficiency_list.mean())", "\n", "# print('P Sample efficiency std: %g' % p_sample_efficiency_list.std())", "\n", "# print('Q Sample efficiency mean: %g' % q_sample_efficiency_list.mean())", "\n", "# print('Q Sample efficiency std: %g' % q_sample_efficiency_list.std())", "\n", "# print('PQ-mix Sample efficiency mean: %g' % pq_sample_efficiency_list.mean())", "\n", "# print('PQ-mix Sample efficiency std: %g' % pq_sample_efficiency_list.std())", "\n", "", "else", ":", "\n", "            ", "train_loss", ",", "train_acc", ",", "importance_list", ",", "_", ",", "_", ",", "_", "=", "trainEpoch", "(", "epoch", ")", "\n", "", "train_ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", "\n", "print", "(", "'Train perplexity: %g'", "%", "train_ppl", ")", "\n", "print", "(", "'Train accuracy: %g'", "%", "(", "train_acc", "*", "100", ")", ")", "\n", "\n", "#  (2) evaluate on the validation set", "\n", "valid_loss", ",", "valid_acc", "=", "eval", "(", "model", ",", "criterion", ",", "validData", ")", "\n", "valid_ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", "\n", "print", "(", "'Validation perplexity: %g'", "%", "valid_ppl", ")", "\n", "print", "(", "'Validation accuracy: %g'", "%", "(", "valid_acc", "*", "100", ")", ")", "\n", "\n", "bleu", "=", "translate", "(", "model", ",", "opt", ".", "valid_src", ",", "opt", ".", "valid_tgt", ",", "dataset", "[", "'dicts'", "]", "[", "'src'", "]", ",", "dataset", "[", "'dicts'", "]", "[", "'tgt'", "]", ",", "beam_size", "=", "1", ")", "\n", "valid_bleu", "=", "float", "(", "bleu", ".", "split", "(", "' '", ")", "[", "2", "]", "[", ":", "-", "1", "]", ")", "\n", "print", "(", "\"Valid BLEU score: {}\"", ".", "format", "(", "valid_bleu", ")", ")", "\n", "test_bleu", "=", "0.0", "\n", "if", "valid_bleu", ">", "max_valid", "[", "0", "]", ":", "\n", "            ", "bleu", "=", "translate", "(", "model", ",", "opt", ".", "test_src", ",", "opt", ".", "test_tgt", ",", "dataset", "[", "'dicts'", "]", "[", "'src'", "]", ",", "dataset", "[", "'dicts'", "]", "[", "'tgt'", "]", ",", "beam_size", "=", "1", ")", "\n", "test_bleu", "=", "float", "(", "bleu", ".", "split", "(", "' '", ")", "[", "2", "]", "[", ":", "-", "1", "]", ")", "\n", "print", "(", "\"Test BLEU score: {}\"", ".", "format", "(", "test_bleu", ")", ")", "\n", "\n", "max_epoch", "[", "0", "]", "=", "epoch", "\n", "max_valid", "[", "0", "]", "=", "valid_bleu", "\n", "max_test", "[", "0", "]", "=", "test_bleu", "\n", "print", "(", "\"Max vlidation bleu score updated!\"", ")", "\n", "best_msg", "=", "\"[BEST] Max Valid BLEU, Test BLEU: {}, {} @epoch {}\"", ".", "format", "(", "max_valid", "[", "0", "]", ",", "max_test", "[", "0", "]", ",", "max_epoch", "[", "0", "]", ")", "+", "' model: %s_acc_%.2f_ppl_%.2f_e%d.pt'", "%", "(", "opt", ".", "save_model", ",", "100", "*", "valid_acc", ",", "valid_ppl", ",", "epoch", ")", "\n", "print", "(", "best_msg", ")", "\n", "", "scores", ".", "append", "(", "(", "epoch", ",", "valid_bleu", ",", "test_bleu", ")", ")", "\n", "\n", "#  (3) update the learning rate", "\n", "decayed", "=", "optim", ".", "dev_decay", "(", "valid_bleu", ")", "\n", "if", "opt", ".", "raml_alpha", "and", "decayed", ":", "\n", "            ", "alpha", "[", "0", "]", "+=", "opt", ".", "alpha_increase", "\n", "if", "alpha", "[", "0", "]", ">", "opt", ".", "alpha_max", ":", "\n", "                ", "alpha", "[", "0", "]", "=", "opt", ".", "alpha_max", "\n", "", "print", "(", "\"Update alpha to {} @epoch {}\"", ".", "format", "(", "alpha", "[", "0", "]", ",", "epoch", ")", ")", "\n", "\n", "", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "model", ".", "generator", ".", "state_dict", "(", ")", "\n", "#  (4) drop a checkpoint", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n", "'dicts'", ":", "dataset", "[", "'dicts'", "]", ",", "\n", "'opt'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'optim'", ":", "optim", "\n", "}", "\n", "print", "(", "'%s_acc_%.2f_ppl_%.2f_e%d.pt'", "%", "(", "opt", ".", "save_model", ",", "100", "*", "valid_acc", ",", "valid_ppl", ",", "epoch", ")", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "\n", "'%s_acc_%.2f_ppl_%.2f_e%d.pt'", "%", "(", "opt", ".", "save_model", ",", "100", "*", "valid_acc", ",", "valid_ppl", ",", "epoch", ")", ")", "\n", "\n", "if", "epoch", ">", "opt", ".", "epochs", "and", "epoch", ">=", "max_epoch", "[", "0", "]", "+", "5", ":", "\n", "            ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.translate": [[341, 392], ["onmt.Translator", "codecs.open", "codecs.open", "train.translate.addone"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.translate.addone"], ["", "", "", "def", "translate", "(", "model", ",", "src", ",", "tgt", ",", "src_dict", ",", "tgt_dict", ",", "beam_size", "=", "10", ")", ":", "\n", "    ", "opt", ".", "beam_size", "=", "beam_size", "\n", "opt", ".", "n_best", "=", "1", "\n", "opt", ".", "replace_unk", "=", "True", "\n", "\n", "def", "addone", "(", "f", ")", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "yield", "line", "\n", "", "yield", "None", "\n", "\n", "", "translator", "=", "onmt", ".", "Translator", "(", "opt", ",", "model", ",", "src_dict", ",", "tgt_dict", ")", "\n", "\n", "srcBatch", ",", "tgtBatch", "=", "[", "]", ",", "[", "]", "\n", "\n", "tgtF", "=", "codecs", ".", "open", "(", "tgt", ",", "'r'", ",", "'utf-8'", ")", "\n", "pred_list", "=", "[", "]", "\n", "out_name", "=", "'tmp/'", "+", "opt", ".", "save_model", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "+", "'.tmp'", "\n", "out", "=", "codecs", ".", "open", "(", "out_name", ",", "'w'", ",", "'utf-8'", ")", "\n", "for", "line", "in", "addone", "(", "codecs", ".", "open", "(", "src", ",", "'r'", ",", "'utf-8'", ")", ")", ":", "\n", "\n", "        ", "if", "line", "is", "not", "None", ":", "\n", "            ", "srcTokens", "=", "line", ".", "split", "(", ")", "\n", "srcBatch", "+=", "[", "srcTokens", "]", "\n", "tgtTokens", "=", "tgtF", ".", "readline", "(", ")", ".", "split", "(", ")", "\n", "tgtBatch", "+=", "[", "tgtTokens", "]", "\n", "\n", "if", "len", "(", "srcBatch", ")", "<", "opt", ".", "batch_size", ":", "\n", "                ", "continue", "\n", "", "", "else", ":", "\n", "# at the end of file, check last batch", "\n", "            ", "if", "len", "(", "srcBatch", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "predBatch", ",", "_", ",", "_", "=", "translator", ".", "translate", "(", "srcBatch", ",", "tgtBatch", ")", "\n", "pred_list", "+=", "predBatch", "\n", "\n", "srcBatch", ",", "tgtBatch", "=", "[", "]", ",", "[", "]", "\n", "\n", "", "for", "pred", "in", "pred_list", ":", "\n", "        ", "out", ".", "write", "(", "' '", ".", "join", "(", "pred", "[", "0", "]", ")", "+", "'\\n'", ")", "\n", "\n", "", "tgtF", ".", "close", "(", ")", "\n", "out", ".", "close", "(", ")", "\n", "\n", "bleu_results", "=", "subprocess", ".", "Popen", "(", "'perl -X multi-bleu.perl '", "+", "tgt", "+", "' < '", "+", "out_name", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "shell", "=", "True", ")", ".", "stdout", ".", "readline", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "decoder", ".", "attn", ".", "applyMask", "(", "None", ")", "\n", "\n", "return", "str", "(", "bleu_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.main": [[394, 497], ["print", "torch.load", "torch.load", "onmt.Dataset", "onmt.Dataset", "print", "print", "print", "print", "onmt.Models.Encoder", "onmt.Models.Decoder", "torch.Sequential", "onmt.Models.NMTModel", "onmt.Optim.set_parameters", "sum", "print", "train.trainModel", "print", "print", "print", "print", "torch.load", "torch.load", "print", "print", "print", "onmt.HammingDistanceSampler", "onmt.ISDataset", "torch.Linear", "torch.LogSoftmax", "print", "onmt.Models.NMTModel.load_state_dict", "nn.Sequential.load_state_dict", "print", "onmt.Models.NMTModel.load_state_dict", "nn.Sequential.load_state_dict", "onmt.Models.NMTModel.cuda", "nn.Sequential.cuda", "onmt.Models.NMTModel.cpu", "nn.Sequential.cpu", "onmt.Models.NMTModel.parameters", "onmt.Models.Encoder.load_pretrained_vectors", "onmt.Models.Decoder.load_pretrained_vectors", "onmt.Optim", "print", "print", "onmt.Models.NMTModel.parameters", "onmt.Optim.optimizer.load_state_dict", "print", "len", "dicts[].size", "p.data.uniform_", "checkpoint[].optimizer.state_dict", "p.nelement", "dicts[].size", "dicts[].size", "onmt.Models.NMTModel.parameters", "[].size"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.set_parameters", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.trainModel", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Decoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Decoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "print", "(", "\"Loading data from '%s'\"", "%", "opt", ".", "data", ")", "\n", "\n", "dataset", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "\n", "dict_checkpoint", "=", "opt", ".", "train_from", "if", "opt", ".", "train_from", "else", "opt", ".", "train_from_state_dict", "\n", "if", "dict_checkpoint", ":", "\n", "        ", "print", "(", "'Loading dicts from checkpoint at %s'", "%", "dict_checkpoint", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "dict_checkpoint", ")", "\n", "dataset", "[", "'dicts'", "]", "=", "checkpoint", "[", "'dicts'", "]", "\n", "\n", "", "trainData", "=", "onmt", ".", "Dataset", "(", "dataset", "[", "'train'", "]", "[", "'src'", "]", ",", "\n", "dataset", "[", "'train'", "]", "[", "'tgt'", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "cuda", ")", "\n", "validData", "=", "onmt", ".", "Dataset", "(", "dataset", "[", "'valid'", "]", "[", "'src'", "]", ",", "\n", "dataset", "[", "'valid'", "]", "[", "'tgt'", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "cuda", ",", "\n", "volatile", "=", "True", ")", "\n", "\n", "if", "opt", ".", "raml_alpha", ":", "\n", "        ", "print", "(", "\"Use RAML(alpha) ...\"", ")", "\n", "print", "(", "\"tau: {}\"", ".", "format", "(", "opt", ".", "tau", ")", ")", "\n", "print", "(", "\"alpha: {}\"", ".", "format", "(", "opt", ".", "alpha", ")", ")", "\n", "sampler", "=", "onmt", ".", "HammingDistanceSampler", "(", "temperature", "=", "opt", ".", "tau", ",", "max_len", "=", "55", ",", "voc_min", "=", "4", ",", "voc_max", "=", "dataset", "[", "'dicts'", "]", "[", "'tgt'", "]", ".", "size", "(", ")", "-", "4", ")", "\n", "trainData", "=", "onmt", ".", "ISDataset", "(", "trainData", ",", "sampler", ")", "\n", "\n", "", "dicts", "=", "dataset", "[", "'dicts'", "]", "\n", "print", "(", "' * vocabulary size. source = %d; target = %d'", "%", "\n", "(", "dicts", "[", "'src'", "]", ".", "size", "(", ")", ",", "dicts", "[", "'tgt'", "]", ".", "size", "(", ")", ")", ")", "\n", "print", "(", "' * number of training sentences. %d'", "%", "\n", "len", "(", "dataset", "[", "'train'", "]", "[", "'src'", "]", ")", ")", "\n", "print", "(", "' * maximum batch size. %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "print", "(", "'Building model...'", ")", "\n", "\n", "encoder", "=", "onmt", ".", "Models", ".", "Encoder", "(", "opt", ",", "dicts", "[", "'src'", "]", ")", "\n", "decoder", "=", "onmt", ".", "Models", ".", "Decoder", "(", "opt", ",", "dicts", "[", "'tgt'", "]", ")", "\n", "\n", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "dicts", "[", "'tgt'", "]", ".", "size", "(", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", ")", ")", "\n", "\n", "model", "=", "onmt", ".", "Models", ".", "NMTModel", "(", "encoder", ",", "decoder", ")", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading model from checkpoint at %s'", "%", "opt", ".", "train_from", ")", "\n", "chk_model", "=", "checkpoint", "[", "'model'", "]", "\n", "generator_state_dict", "=", "checkpoint", "[", "'generator'", "]", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "chk_model", "if", "'generator'", "not", "in", "k", "}", "\n", "model", ".", "load_state_dict", "(", "model_state_dict", ")", "\n", "generator", ".", "load_state_dict", "(", "generator_state_dict", ")", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "\n", "", "if", "opt", ".", "train_from_state_dict", ":", "\n", "        ", "print", "(", "'Loading model from checkpoint at %s'", "%", "opt", ".", "train_from_state_dict", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "\n", "", "if", "opt", ".", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "generator", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "cpu", "(", ")", "\n", "generator", ".", "cpu", "(", ")", "\n", "\n", "", "model", ".", "generator", "=", "generator", "\n", "\n", "if", "not", "opt", ".", "train_from_state_dict", "and", "not", "opt", ".", "train_from", ":", "\n", "        ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "opt", ".", "param_init", ",", "opt", ".", "param_init", ")", "\n", "\n", "", "encoder", ".", "load_pretrained_vectors", "(", "opt", ")", "\n", "decoder", ".", "load_pretrained_vectors", "(", "opt", ")", "\n", "\n", "optim", "=", "onmt", ".", "Optim", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", "\n", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Loading optimizer from checkpoint:'", ")", "\n", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "optim", ".", "lr", "=", "opt", ".", "learning_rate", "\n", "optim", ".", "start_decay_at", "=", "opt", ".", "start_decay_at", "\n", "optim", ".", "lr_decay", "=", "opt", ".", "learning_rate_decay", "\n", "optim", ".", "start_decay", "=", "False", "\n", "print", "(", "optim", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "opt", ".", "train_from", "or", "opt", ".", "train_from_state_dict", ":", "\n", "        ", "optim", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optim'", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "\n", "", "nParams", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'* number of parameters: %d'", "%", "nParams", ")", "\n", "\n", "trainModel", "(", "model", ",", "trainData", ",", "validData", ",", "dataset", ",", "optim", ")", "\n", "print", "(", "\"\\nBest: Valid BLEU: {}, Test BLEU: {} @epoch {}\\n\"", ".", "format", "(", "max_valid", "[", "0", "]", ",", "max_test", "[", "0", "]", ",", "max_epoch", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Epoch, Valid BLEU, Test BLEU\"", ")", "\n", "print", "(", "\"-\"", "*", "30", ")", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "epoch", ",", "valid_bleu", ",", "test_bleu", "=", "score", "\n", "print", "(", "\"{}: {}, {}\"", ".", "format", "(", "epoch", ",", "valid_bleu", ",", "test_bleu", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.makeVocabulary": [[53, 68], ["onmt.Dict", "vocab.prune.size", "vocab.prune.prune", "print", "codecs.open", "f.readlines", "sent.split", "vocab.prune.add", "vocab.prune.size"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.prune", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.add", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["def", "makeVocabulary", "(", "filename", ",", "size", ")", ":", "\n", "    ", "vocab", "=", "onmt", ".", "Dict", "(", "[", "onmt", ".", "Constants", ".", "PAD_WORD", ",", "onmt", ".", "Constants", ".", "UNK_WORD", ",", "\n", "onmt", ".", "Constants", ".", "BOS_WORD", ",", "onmt", ".", "Constants", ".", "EOS_WORD", "]", ",", "lower", "=", "opt", ".", "lower", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "filename", ",", "'r'", ",", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "sent", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "for", "word", "in", "sent", ".", "split", "(", ")", ":", "\n", "                ", "vocab", ".", "add", "(", "word", ")", "\n", "\n", "", "", "", "originalSize", "=", "vocab", ".", "size", "(", ")", "\n", "vocab", "=", "vocab", ".", "prune", "(", "size", ")", "\n", "print", "(", "'Created dictionary of size %d (pruned from %d)'", "%", "\n", "(", "vocab", ".", "size", "(", ")", ",", "originalSize", ")", ")", "\n", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.initVocabulary": [[70, 89], ["print", "print", "onmt.Dict", "onmt.Dict.loadFile", "print", "print", "preprocess.makeVocabulary", "str", "onmt.Dict.size"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.loadFile", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.makeVocabulary", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "initVocabulary", "(", "name", ",", "dataFile", ",", "vocabFile", ",", "vocabSize", ")", ":", "\n", "\n", "    ", "vocab", "=", "None", "\n", "if", "vocabFile", "is", "not", "None", ":", "\n", "# If given, load existing word dictionary.", "\n", "        ", "print", "(", "'Reading '", "+", "name", "+", "' vocabulary from \\''", "+", "vocabFile", "+", "'\\'...'", ")", "\n", "vocab", "=", "onmt", ".", "Dict", "(", ")", "\n", "vocab", ".", "loadFile", "(", "vocabFile", ")", "\n", "print", "(", "'Loaded '", "+", "str", "(", "vocab", ".", "size", "(", ")", ")", "+", "' '", "+", "name", "+", "' words'", ")", "\n", "\n", "", "if", "vocab", "is", "None", ":", "\n", "# If a dictionary is still missing, generate it.", "\n", "        ", "print", "(", "'Building '", "+", "name", "+", "' vocabulary...'", ")", "\n", "genWordVocab", "=", "makeVocabulary", "(", "dataFile", ",", "vocabSize", ")", "\n", "\n", "vocab", "=", "genWordVocab", "\n", "\n", "", "print", "(", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.saveVocabulary": [[91, 94], ["print", "vocab.writeFile"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.writeFile"], ["", "def", "saveVocabulary", "(", "name", ",", "vocab", ",", "file", ")", ":", "\n", "    ", "print", "(", "'Saving '", "+", "name", "+", "' vocabulary to \\''", "+", "file", "+", "'\\'...'", ")", "\n", "vocab", ".", "writeFile", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.makeData": [[96, 153], ["print", "codecs.open", "codecs.open", "zip", "codecs.open.close", "codecs.open.close", "print", "torch.sort", "print", "src_line.split", "tgt_line.split", "print", "torch.randperm", "torch.Tensor", "print", "len", "print", "print", "print", "len", "len", "srcDicts.convertToIdx", "tgtDicts.convertToIdx", "len", "len"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.convertToIdx", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.convertToIdx"], ["", "def", "makeData", "(", "srcFile", ",", "tgtFile", ",", "srcDicts", ",", "tgtDicts", ")", ":", "\n", "    ", "src", ",", "tgt", "=", "[", "]", ",", "[", "]", "\n", "sizes", "=", "[", "]", "\n", "count", ",", "ignored", "=", "0", ",", "0", "\n", "\n", "print", "(", "'Processing %s & %s ...'", "%", "(", "srcFile", ",", "tgtFile", ")", ")", "\n", "srcF", "=", "codecs", ".", "open", "(", "srcFile", ",", "'r'", ",", "'utf-8'", ")", "\n", "tgtF", "=", "codecs", ".", "open", "(", "tgtFile", ",", "'r'", ",", "'utf-8'", ")", "\n", "\n", "for", "src_line", ",", "tgt_line", "in", "zip", "(", "srcF", ",", "tgtF", ")", ":", "\n", "        ", "srcWords", "=", "src_line", ".", "split", "(", ")", "\n", "tgtWords", "=", "tgt_line", ".", "split", "(", ")", "\n", "\n", "if", "not", "srcWords", "or", "not", "tgtWords", ":", "\n", "            ", "if", "srcWords", "and", "not", "tgtWords", "or", "not", "srcWords", "and", "tgtWords", ":", "\n", "                ", "print", "(", "'WARNING: source and target do not have the same number of sentences'", ")", "\n", "print", "(", "\"src: \"", "+", "src_line", ")", "\n", "print", "(", "\"tgt: \"", "+", "tgt_line", ")", "\n", "", "continue", "\n", "\n", "", "if", "len", "(", "srcWords", ")", "<=", "opt", ".", "seq_length", "and", "len", "(", "tgtWords", ")", "<=", "opt", ".", "seq_length", ":", "\n", "\n", "            ", "src", "+=", "[", "srcDicts", ".", "convertToIdx", "(", "srcWords", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ")", "]", "\n", "tgt", "+=", "[", "tgtDicts", ".", "convertToIdx", "(", "tgtWords", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ",", "\n", "onmt", ".", "Constants", ".", "BOS_WORD", ",", "\n", "onmt", ".", "Constants", ".", "EOS_WORD", ")", "]", "\n", "\n", "sizes", "+=", "[", "len", "(", "srcWords", ")", "]", "\n", "", "else", ":", "\n", "            ", "ignored", "+=", "1", "\n", "\n", "", "count", "+=", "1", "\n", "\n", "if", "count", "%", "opt", ".", "report_every", "==", "0", ":", "\n", "            ", "print", "(", "'... %d sentences prepared'", "%", "count", ")", "\n", "\n", "", "", "srcF", ".", "close", "(", ")", "\n", "tgtF", ".", "close", "(", ")", "\n", "\n", "if", "opt", ".", "shuffle", "==", "1", ":", "\n", "        ", "print", "(", "'... shuffling sentences'", ")", "\n", "perm", "=", "torch", ".", "randperm", "(", "len", "(", "src", ")", ")", "\n", "src", "=", "[", "src", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "tgt", "=", "[", "tgt", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "sizes", "=", "[", "sizes", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "\n", "", "print", "(", "'... sorting sentences by size'", ")", "\n", "_", ",", "perm", "=", "torch", ".", "sort", "(", "torch", ".", "Tensor", "(", "sizes", ")", ")", "\n", "src", "=", "[", "src", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "tgt", "=", "[", "tgt", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "\n", "print", "(", "'Prepared %d sentences (%d ignored due to length == 0 or > %d)'", "%", "\n", "(", "len", "(", "src", ")", ",", "ignored", ",", "opt", ".", "seq_length", ")", ")", "\n", "\n", "return", "src", ",", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.main": [[155, 184], ["preprocess.initVocabulary", "preprocess.initVocabulary", "print", "preprocess.makeData", "print", "preprocess.makeData", "print", "torch.save", "preprocess.saveVocabulary", "preprocess.saveVocabulary"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.initVocabulary", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.initVocabulary", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.makeData", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.makeData", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.saveVocabulary", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.preprocess.saveVocabulary"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "dicts", "=", "{", "}", "\n", "dicts", "[", "'src'", "]", "=", "initVocabulary", "(", "'source'", ",", "opt", ".", "train_src", ",", "opt", ".", "src_vocab", ",", "\n", "opt", ".", "src_vocab_size", ")", "\n", "dicts", "[", "'tgt'", "]", "=", "initVocabulary", "(", "'target'", ",", "opt", ".", "train_tgt", ",", "opt", ".", "tgt_vocab", ",", "\n", "opt", ".", "tgt_vocab_size", ")", "\n", "\n", "print", "(", "'Preparing training ...'", ")", "\n", "train", "=", "{", "}", "\n", "train", "[", "'src'", "]", ",", "train", "[", "'tgt'", "]", "=", "makeData", "(", "opt", ".", "train_src", ",", "opt", ".", "train_tgt", ",", "\n", "dicts", "[", "'src'", "]", ",", "dicts", "[", "'tgt'", "]", ")", "\n", "\n", "print", "(", "'Preparing validation ...'", ")", "\n", "valid", "=", "{", "}", "\n", "valid", "[", "'src'", "]", ",", "valid", "[", "'tgt'", "]", "=", "makeData", "(", "opt", ".", "valid_src", ",", "opt", ".", "valid_tgt", ",", "\n", "dicts", "[", "'src'", "]", ",", "dicts", "[", "'tgt'", "]", ")", "\n", "\n", "if", "opt", ".", "src_vocab", "is", "None", ":", "\n", "        ", "saveVocabulary", "(", "'source'", ",", "dicts", "[", "'src'", "]", ",", "opt", ".", "save_data", "+", "'.src.dict'", ")", "\n", "", "if", "opt", ".", "tgt_vocab", "is", "None", ":", "\n", "        ", "saveVocabulary", "(", "'target'", ",", "dicts", "[", "'tgt'", "]", ",", "opt", ".", "save_data", "+", "'.tgt.dict'", ")", "\n", "\n", "\n", "", "print", "(", "'Saving data to \\''", "+", "opt", ".", "save_data", "+", "'.train.pt\\'...'", ")", "\n", "save_data", "=", "{", "'dicts'", ":", "dicts", ",", "\n", "'train'", ":", "train", ",", "\n", "'valid'", ":", "valid", "}", "\n", "torch", ".", "save", "(", "save_data", ",", "opt", ".", "save_data", "+", "'.train.pt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.AlphaLoss.__init__": [[11, 15], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "weight", "=", "None", ")", ":", "\n", "        ", "super", "(", "AlphaLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "weight", "# weight for imbalance # of class or PAD class", "\n", "self", ".", "use_cuda", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.AlphaLoss.forward": [[16, 64], ["numpy.zeros", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "nll.sum().squeeze.sum().squeeze.sum().squeeze", "nll.sum().squeeze.sum().squeeze.view", "nll.sum().squeeze.sum().squeeze.size", "nll.sum().squeeze.sum().squeeze.sum().squeeze", "numpy.exp", "numpy.exp", "torch.autograd.Variable", "torch.autograd.Variable", "weighted_log_likelihood.sum", "list", "list", "list", "log_q_weights.size", "log_outputs.size", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "lossfun.AlphaLoss.weight.unsqueeze().expand().float", "mask.cuda.cuda.cuda", "cls_weight.cuda.cuda.cuda", "nll.sum().squeeze.sum().squeeze.data.cpu", "numpy.exp.sum", "numpy.exp.sum", "numpy.power", "numpy.power", "proposed_weights.sum", "alpha_weights.cuda.cuda.sum", "alpha_weights.cuda.cuda.cuda", "list", "nll.sum().squeeze.sum().squeeze.sum", "nll.sum().squeeze.sum().squeeze.sum", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "alpha_weights.cuda.cuda.data.cpu", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "numpy.arange", "targets.cpu().data.numpy().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "lossfun.AlphaLoss.weight.unsqueeze().expand", "log_outputs.size", "targets.cpu().data.numpy", "lossfun.AlphaLoss.weight.unsqueeze", "targets.cpu"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "log_outputs", ",", "targets", ",", "proposed_weights", ",", "log_q_weights", ",", "alpha", ",", "rewards", ")", ":", "\n", "        ", "\"\"\"Return weighted negative log likelihood loss\n\n        :param log_outputs: seq_len * batch_size x voc_size\n        :param targets: seq_len * batch_size\n        :param q_weights: batch_size\n        \"\"\"", "\n", "batch_size", "=", "log_q_weights", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "mask", "=", "np", ".", "zeros", "(", "log_outputs", ".", "size", "(", ")", ")", "\n", "mask", "[", "np", ".", "arange", "(", "mask", ".", "shape", "[", "0", "]", ")", ",", "targets", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "]", "=", "1.", "\n", "mask", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "mask", ")", ".", "float", "(", ")", ")", "\n", "cls_weight", "=", "Variable", "(", "self", ".", "weight", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "log_outputs", ".", "size", "(", ")", ")", ".", "float", "(", ")", ")", "\n", "\n", "# cuda TODO(sotestuk): fix to use more elegant way", "\n", "if", "self", ".", "use_cuda", ":", "\n", "            ", "mask", "=", "mask", ".", "cuda", "(", ")", "\n", "cls_weight", "=", "cls_weight", ".", "cuda", "(", ")", "\n", "\n", "", "nll", "=", "-", "log_outputs", "*", "cls_weight", "*", "mask", "# seq_len * batch_size x voc_size", "\n", "nll", "=", "nll", ".", "sum", "(", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "# seq_len * batch_size", "\n", "nll", "=", "nll", ".", "view", "(", "-", "1", ",", "batch_size", ")", "# seq_len x batch_size", "\n", "seq_len", "=", "nll", ".", "size", "(", "0", ")", "\n", "nll", "=", "nll", ".", "sum", "(", "dim", "=", "0", ")", ".", "squeeze", "(", ")", "# batch_size", "\n", "\n", "log_p_weights", "=", "-", "nll", ".", "data", ".", "cpu", "(", ")", "\n", "p", "=", "np", ".", "exp", "(", "log_p_weights", "/", "seq_len", ")", "\n", "p", "=", "p", "/", "p", ".", "sum", "(", ")", "\n", "q", "=", "np", ".", "exp", "(", "log_q_weights", ")", "\n", "q", "=", "q", "/", "q", ".", "sum", "(", ")", "\n", "alpha_weights", "=", "np", ".", "power", "(", "p", ",", "alpha", ")", "*", "np", ".", "power", "(", "q", ",", "(", "1", "-", "alpha", ")", ")", "\n", "proposed_weights", "=", "proposed_weights", "/", "proposed_weights", ".", "sum", "(", ")", "# proposal weight is normalized for mini-batch", "\n", "alpha_weights", "=", "proposed_weights", "*", "alpha_weights", "\n", "alpha_weights", "=", "alpha_weights", "/", "alpha_weights", ".", "sum", "(", ")", "\n", "alpha_weights", "=", "Variable", "(", "alpha_weights", ",", "requires_grad", "=", "False", ")", "\n", "\n", "if", "self", ".", "use_cuda", ":", "\n", "            ", "alpha_weights", "=", "alpha_weights", ".", "cuda", "(", ")", "\n", "\n", "", "weighted_log_likelihood", "=", "nll", "*", "alpha_weights", "*", "batch_size", "# rescale to the same scale as ML loss by * batch_size", "\n", "loss", "=", "weighted_log_likelihood", ".", "sum", "(", ")", "\n", "\n", "# calculate sample efficiency", "\n", "p_sample_efficiency_list", "=", "list", "(", "p", "*", "torch", ".", "FloatTensor", "(", "rewards", ")", ")", "\n", "q_sample_efficiency_list", "=", "list", "(", "q", "*", "torch", ".", "FloatTensor", "(", "rewards", ")", ")", "\n", "pq_sample_efficiency_list", "=", "list", "(", "alpha_weights", ".", "data", ".", "cpu", "(", ")", "*", "torch", ".", "FloatTensor", "(", "rewards", ")", ")", "\n", "\n", "return", "loss", ",", "list", "(", "torch", ".", "exp", "(", "log_p_weights", "-", "log_q_weights", ")", ")", ",", "p_sample_efficiency_list", ",", "q_sample_efficiency_list", ",", "pq_sample_efficiency_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.AlphaCriterion": [[66, 74], ["torch.ones", "torch.ones", "lossfun.AlphaLoss", "AlphaLoss.cuda"], "function", ["None"], ["", "", "def", "AlphaCriterion", "(", "vocabSize", ",", "gpus", ")", ":", "\n", "    ", "weight", "=", "torch", ".", "ones", "(", "vocabSize", ")", "\n", "weight", "[", "Constants", ".", "PAD", "]", "=", "0", "\n", "crit", "=", "AlphaLoss", "(", "weight", ")", "\n", "if", "gpus", ":", "\n", "        ", "crit", ".", "cuda", "(", ")", "\n", "crit", ".", "use_cuda", "=", "True", "\n", "", "return", "crit", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.NMTCriterion": [[76, 83], ["torch.ones", "torch.ones", "torch.NLLLoss", "nn.NLLLoss.cuda"], "function", ["None"], ["", "def", "NMTCriterion", "(", "vocabSize", ",", "gpus", ")", ":", "\n", "    ", "weight", "=", "torch", ".", "ones", "(", "vocabSize", ")", "\n", "weight", "[", "Constants", ".", "PAD", "]", "=", "0", "\n", "crit", "=", "nn", ".", "NLLLoss", "(", "weight", ",", "size_average", "=", "False", ")", "\n", "if", "gpus", ":", "\n", "        ", "crit", ".", "cuda", "(", ")", "\n", "", "return", "crit", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.memoryEfficientLoss": [[85, 122], ["torch.autograd.Variable", "torch.autograd.Variable.size", "torch.split", "torch.split", "torch.split", "torch.split", "enumerate", "zip", "out_t.view.view", "generator", "crit", "pred_t.data.eq().masked_select().sum", "out_t.view.size", "targ_t.view", "generator.max", "crit.div().backward", "pred_t.data.eq().masked_select", "crit.div", "pred_t.data.eq", "targ_t.ne"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "memoryEfficientLoss", "(", "outputs", ",", "targets", ",", "generator", ",", "crit", ",", "max_generator_batches", ",", "eval", "=", "False", ")", ":", "\n", "    ", "\"\"\"Memory efficient loss.\n\n    :param outputs: seq_len x batch_size x logits_size\n    :param targets: seq_len x batch_size\n    :param generator:\n    :param crit:\n    :param max_generator_batches:\n    :param eval:\n    :return:\n    \"\"\"", "\n", "# compute generations one piece at a time", "\n", "num_correct", ",", "loss", "=", "0", ",", "0", "\n", "outputs", "=", "Variable", "(", "outputs", ".", "data", ",", "requires_grad", "=", "(", "not", "eval", ")", ",", "volatile", "=", "eval", ")", "# seq_len x batch_size x logits_size", "\n", "\n", "batch_size", "=", "outputs", ".", "size", "(", "1", ")", "\n", "outputs_split", "=", "torch", ".", "split", "(", "outputs", ",", "max_generator_batches", ")", "\n", "targets_split", "=", "torch", ".", "split", "(", "targets", ",", "max_generator_batches", ")", "\n", "for", "i", ",", "(", "out_t", ",", "targ_t", ")", "in", "enumerate", "(", "zip", "(", "outputs_split", ",", "targets_split", ")", ")", ":", "\n", "# out_t = seq_len x batch_size x logits_size", "\n", "# targ_t = seq_len x batch_size", "\n", "\n", "        ", "out_t", "=", "out_t", ".", "view", "(", "-", "1", ",", "out_t", ".", "size", "(", "2", ")", ")", "# seq_len * batch_size x logits_size", "\n", "scores_t", "=", "generator", "(", "out_t", ")", "# seq_len * batch_size x voc_size", "\n", "\n", "loss_t", "=", "crit", "(", "scores_t", ",", "targ_t", ".", "view", "(", "-", "1", ")", ")", "# scholar (1-d)", "\n", "\n", "pred_t", "=", "scores_t", ".", "max", "(", "1", ")", "[", "1", "]", "# seq_len * batch_size x 1", "\n", "\n", "num_correct_t", "=", "pred_t", ".", "data", ".", "eq", "(", "targ_t", ".", "data", ")", ".", "masked_select", "(", "targ_t", ".", "ne", "(", "Constants", ".", "PAD", ")", ".", "data", ")", ".", "sum", "(", ")", "\n", "num_correct", "+=", "num_correct_t", "\n", "loss", "+=", "loss_t", ".", "data", "[", "0", "]", "\n", "if", "not", "eval", ":", "\n", "            ", "loss_t", ".", "div", "(", "batch_size", ")", ".", "backward", "(", ")", "\n", "\n", "", "", "grad_output", "=", "None", "if", "outputs", ".", "grad", "is", "None", "else", "outputs", ".", "grad", ".", "data", "\n", "return", "loss", ",", "grad_output", ",", "num_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.lossfun.alpha_loss": [[124, 171], ["torch.autograd.Variable", "torch.autograd.Variable.size", "torch.split", "torch.split", "torch.split", "torch.split", "enumerate", "zip", "out_t.view.view", "generator", "torch.FloatTensor", "torch.FloatTensor", "crit", "pred_t.data.eq().masked_select().sum", "out_t.view.size", "torch.FloatTensor", "torch.FloatTensor", "targ_t.view", "generator.max", "loss_t.div().backward", "pred_t.data.eq().masked_select", "loss_t.div", "pred_t.data.eq", "targ_t.ne"], "function", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "alpha_loss", "(", "outputs", ",", "targets", ",", "generator", ",", "crit", ",", "max_generator_batches", ",", "rewards", ",", "proposed_weights", ",", "tau", ",", "alpha", ",", "eval", "=", "False", ")", ":", "\n", "    ", "\"\"\"Loss function of proposed method.\n\n    :param outputs: seq_len x batch_size x logits_size\n    :param targets: seq_len x batch_size\n    :param generator:\n    :param crit:\n    :param max_generator_batches:\n    :param eval:\n    :return:\n    \"\"\"", "\n", "# compute generations one piece at a time", "\n", "num_correct", ",", "loss", "=", "0", ",", "0", "\n", "outputs", "=", "Variable", "(", "outputs", ".", "data", ",", "requires_grad", "=", "(", "not", "eval", ")", ",", "volatile", "=", "eval", ")", "# seq_len x batch_size x logits_size", "\n", "\n", "batch_size", "=", "outputs", ".", "size", "(", "1", ")", "\n", "outputs_split", "=", "torch", ".", "split", "(", "outputs", ",", "max_generator_batches", ")", "\n", "targets_split", "=", "torch", ".", "split", "(", "targets", ",", "max_generator_batches", ")", "\n", "\n", "# TODO(sotetsuk): fix to calculate at once", "\n", "importance_list", "=", "[", "]", "\n", "p_sample_efficiency_list", "=", "[", "]", "\n", "q_sample_efficiency_list", "=", "[", "]", "\n", "pq_sample_efficiency_list", "=", "[", "]", "\n", "for", "i", ",", "(", "out_t", ",", "targ_t", ")", "in", "enumerate", "(", "zip", "(", "outputs_split", ",", "targets_split", ")", ")", ":", "\n", "        ", "out_t", "=", "out_t", ".", "view", "(", "-", "1", ",", "out_t", ".", "size", "(", "2", ")", ")", "# seq_len * batch_size x logits_size", "\n", "scores_t", "=", "generator", "(", "out_t", ")", "# seq_len * batch_size x voc_size", "\n", "\n", "proposed_weights", "=", "torch", ".", "FloatTensor", "(", "proposed_weights", ")", "\n", "log_q_weights", "=", "torch", ".", "FloatTensor", "(", "rewards", ")", "/", "tau", "\n", "\n", "loss_t", ",", "importance_t", ",", "p_sample_efficiency_t", ",", "q_sample_efficiency_t", ",", "pq_sample_efficiency_t", "=", "crit", "(", "scores_t", ",", "targ_t", ".", "view", "(", "-", "1", ")", ",", "proposed_weights", ",", "log_q_weights", ",", "alpha", ",", "rewards", ")", "# scholar (1-d)", "\n", "\n", "pred_t", "=", "scores_t", ".", "max", "(", "1", ")", "[", "1", "]", "# seq_len * batch_size x 1", "\n", "\n", "num_correct_t", "=", "pred_t", ".", "data", ".", "eq", "(", "targ_t", ".", "data", ")", ".", "masked_select", "(", "targ_t", ".", "ne", "(", "Constants", ".", "PAD", ")", ".", "data", ")", ".", "sum", "(", ")", "\n", "num_correct", "+=", "num_correct_t", "\n", "loss", "+=", "loss_t", ".", "data", "[", "0", "]", "\n", "importance_list", "+=", "importance_t", "\n", "p_sample_efficiency_list", "+=", "p_sample_efficiency_t", "\n", "q_sample_efficiency_list", "+=", "q_sample_efficiency_t", "\n", "pq_sample_efficiency_list", "+=", "pq_sample_efficiency_t", "\n", "if", "not", "eval", ":", "\n", "            ", "loss_t", ".", "div", "(", "batch_size", ")", ".", "backward", "(", ")", "\n", "\n", "", "", "grad_output", "=", "None", "if", "outputs", ".", "grad", "is", "None", "else", "outputs", ".", "grad", ".", "data", "\n", "return", "loss", ",", "grad_output", ",", "num_correct", ",", "importance_list", ",", "p_sample_efficiency_list", ",", "q_sample_efficiency_list", ",", "pq_sample_efficiency_list", "\n", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Encoder.__init__": [[10, 25], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "dicts.size"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "        ", "self", ".", "layers", "=", "opt", ".", "layers", "\n", "self", ".", "num_directions", "=", "2", "if", "opt", ".", "brnn", "else", "1", "\n", "assert", "opt", ".", "rnn_size", "%", "self", ".", "num_directions", "==", "0", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "//", "self", ".", "num_directions", "\n", "input_size", "=", "opt", ".", "word_vec_size", "\n", "\n", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "\n", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "input_size", ",", "self", ".", "hidden_size", ",", "\n", "num_layers", "=", "opt", ".", "layers", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "bidirectional", "=", "opt", ".", "brnn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Encoder.load_pretrained_vectors": [[26, 30], ["torch.load", "torch.load", "torch.load", "torch.load", "Models.Encoder.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "pre_word_vecs_enc", "is", "not", "None", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "opt", ".", "pre_word_vecs_enc", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Encoder.forward": [[31, 40], ["isinstance", "Models.Encoder.rnn", "isinstance", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Models.Encoder.word_lut", "Models.Encoder.word_lut", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "emb", "=", "pack", "(", "self", ".", "word_lut", "(", "input", "[", "0", "]", ")", ",", "input", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "emb", "=", "self", ".", "word_lut", "(", "input", ")", "\n", "", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "emb", ",", "hidden", ")", "\n", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "", "return", "hidden_t", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.StackedLSTM.__init__": [[43, 52], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "Models.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.StackedLSTM.forward": [[53, 68], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "Models.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Decoder.__init__": [[72, 88], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "Models.StackedLSTM", "onmt.modules.GlobalAttention", "torch.Dropout", "torch.Dropout", "dicts.size"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "        ", "self", ".", "layers", "=", "opt", ".", "layers", "\n", "self", ".", "input_feed", "=", "opt", ".", "input_feed", "\n", "input_size", "=", "opt", ".", "word_vec_size", "\n", "if", "self", ".", "input_feed", ":", "\n", "            ", "input_size", "+=", "opt", ".", "rnn_size", "\n", "\n", "", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "\n", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "self", ".", "rnn", "=", "StackedLSTM", "(", "opt", ".", "layers", ",", "input_size", ",", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ")", "\n", "self", ".", "attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "opt", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "opt", ".", "dropout", ")", "\n", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Decoder.load_pretrained_vectors": [[89, 93], ["torch.load", "torch.load", "torch.load", "torch.load", "Models.Decoder.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "pre_word_vecs_dec", "is", "not", "None", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "opt", ".", "pre_word_vecs_dec", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.Decoder.forward": [[94, 114], ["Models.Decoder.word_lut", "Models.Decoder.split", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat.squeeze", "torch.cat.squeeze", "Models.Decoder.rnn", "Models.Decoder.attn", "Models.Decoder.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "context.t"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "context", ",", "init_output", ")", ":", "\n", "        ", "emb", "=", "self", ".", "word_lut", "(", "input", ")", "\n", "\n", "# n.b. you can increase performance if you compute W_ih * x for all", "\n", "# iterations in parallel, but that's only possible if", "\n", "# self.input_feed=False", "\n", "outputs", "=", "[", "]", "\n", "output", "=", "init_output", "\n", "for", "emb_t", "in", "emb", ".", "split", "(", "1", ")", ":", "\n", "            ", "emb_t", "=", "emb_t", ".", "squeeze", "(", "0", ")", "\n", "if", "self", ".", "input_feed", ":", "\n", "                ", "emb_t", "=", "torch", ".", "cat", "(", "[", "emb_t", ",", "output", "]", ",", "1", ")", "\n", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb_t", ",", "hidden", ")", "\n", "output", ",", "attn", "=", "self", ".", "attn", "(", "output", ",", "context", ".", "t", "(", ")", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "outputs", "+=", "[", "output", "]", "\n", "\n", "", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "return", "outputs", ",", "hidden", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel.__init__": [[118, 122], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel.make_init_decoder_output": [[123, 127], ["context.size", "torch.autograd.Variable", "torch.autograd.Variable", "context.data.new().zero_", "context.data.new"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "make_init_decoder_output", "(", "self", ",", "context", ")", ":", "\n", "        ", "batch_size", "=", "context", ".", "size", "(", "1", ")", "\n", "h_size", "=", "(", "batch_size", ",", "self", ".", "decoder", ".", "hidden_size", ")", "\n", "return", "Variable", "(", "context", ".", "data", ".", "new", "(", "*", "h_size", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel._fix_enc_hidden": [[128, 137], ["h.view().transpose().contiguous().view", "h.size", "h.view().transpose().contiguous", "h.size", "h.size", "h.view().transpose", "h.view", "h.size", "h.size", "h.size"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "_fix_enc_hidden", "(", "self", ",", "h", ")", ":", "\n", "#  the encoder hidden is  (layers*directions) x batch x dim", "\n", "#  we need to convert it to layers x batch x (directions*dim)", "\n", "        ", "if", "self", ".", "encoder", ".", "num_directions", "==", "2", ":", "\n", "            ", "return", "h", ".", "view", "(", "h", ".", "size", "(", "0", ")", "//", "2", ",", "2", ",", "h", ".", "size", "(", "1", ")", ",", "h", ".", "size", "(", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "h", ".", "size", "(", "0", ")", "//", "2", ",", "h", ".", "size", "(", "1", ")", ",", "h", ".", "size", "(", "2", ")", "*", "2", ")", "\n", "", "else", ":", "\n", "            ", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel.forward": [[138, 150], ["Models.NMTModel.encoder", "Models.NMTModel.make_init_decoder_output", "Models.NMTModel.decoder", "Models.NMTModel._fix_enc_hidden", "Models.NMTModel._fix_enc_hidden"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel.make_init_decoder_output", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel._fix_enc_hidden", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel._fix_enc_hidden"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "src", "=", "input", "[", "0", "]", "\n", "tgt", "=", "input", "[", "1", "]", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "enc_hidden", ",", "context", "=", "self", ".", "encoder", "(", "src", ")", "\n", "init_output", "=", "self", ".", "make_init_decoder_output", "(", "context", ")", "\n", "\n", "enc_hidden", "=", "(", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", "[", "0", "]", ")", ",", "\n", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", "[", "1", "]", ")", ")", "\n", "\n", "out", ",", "dec_hidden", ",", "_attn", "=", "self", ".", "decoder", "(", "tgt", ",", "enc_hidden", ",", "context", ",", "init_output", ")", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.__init__": [[8, 44], ["Translator.Translator.model.eval", "torch.load", "torch.load", "torch.load", "torch.load", "onmt.Models.Encoder", "onmt.Models.Decoder", "onmt.Models.NMTModel", "torch.Sequential", "torch.Sequential", "onmt.Models.NMTModel.load_state_dict", "torch.Sequential.load_state_dict", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax", "onmt.Models.NMTModel.cuda", "torch.Sequential.cuda", "onmt.Models.NMTModel.cpu", "torch.Sequential.cpu", "tgt_dict.size"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.None.train.eval", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model", "=", "None", ",", "src_dict", "=", "None", ",", "tgt_dict", "=", "None", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "opt", ".", "cuda", "else", "torch", "\n", "\n", "if", "model", "is", "None", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "src_dict", "=", "checkpoint", "[", "'dicts'", "]", "[", "'src'", "]", "\n", "tgt_dict", "=", "checkpoint", "[", "'dicts'", "]", "[", "'tgt'", "]", "\n", "\n", "encoder", "=", "onmt", ".", "Models", ".", "Encoder", "(", "model_opt", ",", "src_dict", ")", "\n", "decoder", "=", "onmt", ".", "Models", ".", "Decoder", "(", "model_opt", ",", "tgt_dict", ")", "\n", "model", "=", "onmt", ".", "Models", ".", "NMTModel", "(", "encoder", ",", "decoder", ")", "\n", "\n", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "tgt_dict", ".", "size", "(", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", ")", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "\n", "if", "opt", ".", "cuda", ":", "\n", "                ", "model", ".", "cuda", "(", ")", "\n", "generator", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "cpu", "(", ")", "\n", "generator", ".", "cpu", "(", ")", "\n", "\n", "", "model", ".", "generator", "=", "generator", "\n", "\n", "", "self", ".", "src_dict", "=", "src_dict", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.buildData": [[45, 57], ["onmt.Dataset", "Translator.Translator.src_dict.convertToIdx", "Translator.Translator.tgt_dict.convertToIdx"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.convertToIdx", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.convertToIdx"], ["", "def", "buildData", "(", "self", ",", "srcBatch", ",", "goldBatch", ")", ":", "\n", "        ", "srcData", "=", "[", "self", ".", "src_dict", ".", "convertToIdx", "(", "b", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ")", "for", "b", "in", "srcBatch", "]", "\n", "tgtData", "=", "None", "\n", "if", "goldBatch", ":", "\n", "            ", "tgtData", "=", "[", "self", ".", "tgt_dict", ".", "convertToIdx", "(", "b", ",", "\n", "onmt", ".", "Constants", ".", "UNK_WORD", ",", "\n", "onmt", ".", "Constants", ".", "BOS_WORD", ",", "\n", "onmt", ".", "Constants", ".", "EOS_WORD", ")", "for", "b", "in", "goldBatch", "]", "\n", "\n", "", "return", "onmt", ".", "Dataset", "(", "srcData", ",", "tgtData", ",", "\n", "self", ".", "opt", ".", "batch_size", ",", "self", ".", "opt", ".", "cuda", ",", "volatile", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.buildTargetTokens": [[58, 67], ["Translator.Translator.tgt_dict.convertToLabels", "range", "len", "attn[].max"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.convertToLabels"], ["", "def", "buildTargetTokens", "(", "self", ",", "pred", ",", "src", ",", "attn", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "tgt_dict", ".", "convertToLabels", "(", "pred", ",", "onmt", ".", "Constants", ".", "EOS", ")", "\n", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "# EOS", "\n", "if", "self", ".", "opt", ".", "replace_unk", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "onmt", ".", "Constants", ".", "UNK_WORD", ":", "\n", "                    ", "_", ",", "maxIndex", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src", "[", "maxIndex", "[", "0", "]", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.translateBatch": [[68, 193], ["srcBatch[].size", "Translator.Translator.model.encoder", "updateActive.size", "srcBatch.data.eq().t", "updateActive.data.new().zero_", "torch.autograd.Variable", "torch.autograd.Variable", "Translator.Translator.model.make_init_decoder_output", "srcBatch.data.eq().t().unsqueeze().repeat", "list", "range", "range", "Translator.Translator.model._fix_enc_hidden", "Translator.Translator.model._fix_enc_hidden", "isinstance", "Translator.Translator.model.make_init_decoder_output", "Translator.Translator.model.decoder.apply", "Translator.Translator.model.make_init_decoder_output", "Translator.Translator.model.decoder", "zip", "updateActive.data.repeat", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "onmt.Beam", "range", "Translator.Translator.model.decoder.apply", "torch.stack().t().contiguous().view", "torch.stack().t().contiguous().view", "torch.stack().t().contiguous().view", "torch.stack().t().contiguous().view", "Translator.Translator.model.decoder", "updateActive.squeeze", "Translator.Translator.model.generator.forward", "Translator.Translator.view().transpose().contiguous", "attn.view().transpose().contiguous.view().transpose().contiguous.view().transpose().contiguous", "range", "Translator.Translator.tt.LongTensor", "Translator.Translator.translateBatch.updateActive"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel.make_init_decoder_output", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel._fix_enc_hidden", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel._fix_enc_hidden", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel.make_init_decoder_output", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Models.NMTModel.make_init_decoder_output", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.forward"], ["", "def", "translateBatch", "(", "self", ",", "srcBatch", ",", "tgtBatch", ")", ":", "\n", "        ", "batchSize", "=", "srcBatch", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "beamSize", "=", "self", ".", "opt", ".", "beam_size", "\n", "\n", "#  (1) run the encoder on the src", "\n", "encStates", ",", "context", "=", "self", ".", "model", ".", "encoder", "(", "srcBatch", ")", "\n", "srcBatch", "=", "srcBatch", "[", "0", "]", "# drop the lengths needed for encoder", "\n", "\n", "rnnSize", "=", "context", ".", "size", "(", "2", ")", "\n", "encStates", "=", "(", "self", ".", "model", ".", "_fix_enc_hidden", "(", "encStates", "[", "0", "]", ")", ",", "\n", "self", ".", "model", ".", "_fix_enc_hidden", "(", "encStates", "[", "1", "]", ")", ")", "\n", "\n", "#  This mask is applied to the attention model inside the decoder", "\n", "#  so that the attention ignores source padding", "\n", "padMask", "=", "srcBatch", ".", "data", ".", "eq", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "t", "(", ")", "\n", "def", "applyContextMask", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "onmt", ".", "modules", ".", "GlobalAttention", ")", ":", "\n", "                ", "m", ".", "applyMask", "(", "padMask", ")", "\n", "\n", "#  (2) if a target is specified, compute the 'goldScore'", "\n", "#  (i.e. log likelihood) of the target under the model", "\n", "", "", "goldScores", "=", "context", ".", "data", ".", "new", "(", "batchSize", ")", ".", "zero_", "(", ")", "\n", "if", "tgtBatch", "is", "not", "None", ":", "\n", "            ", "decStates", "=", "encStates", "\n", "decOut", "=", "self", ".", "model", ".", "make_init_decoder_output", "(", "context", ")", "\n", "self", ".", "model", ".", "decoder", ".", "apply", "(", "applyContextMask", ")", "\n", "initOutput", "=", "self", ".", "model", ".", "make_init_decoder_output", "(", "context", ")", "\n", "\n", "decOut", ",", "decStates", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "tgtBatch", "[", ":", "-", "1", "]", ",", "decStates", ",", "context", ",", "initOutput", ")", "\n", "for", "dec_t", ",", "tgt_t", "in", "zip", "(", "decOut", ",", "tgtBatch", "[", "1", ":", "]", ".", "data", ")", ":", "\n", "                ", "gen_t", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_t", ")", "\n", "tgt_t", "=", "tgt_t", ".", "unsqueeze", "(", "1", ")", "\n", "scores", "=", "gen_t", ".", "data", ".", "gather", "(", "1", ",", "tgt_t", ")", "\n", "scores", ".", "masked_fill_", "(", "tgt_t", ".", "eq", "(", "onmt", ".", "Constants", ".", "PAD", ")", ",", "0", ")", "\n", "goldScores", "+=", "scores", "\n", "\n", "#  (3) run the decoder to generate sentences, using beam search", "\n", "\n", "# Expand tensors for each beam.", "\n", "", "", "context", "=", "Variable", "(", "context", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", "\n", "decStates", "=", "(", "Variable", "(", "encStates", "[", "0", "]", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", ",", "\n", "Variable", "(", "encStates", "[", "1", "]", ".", "data", ".", "repeat", "(", "1", ",", "beamSize", ",", "1", ")", ")", ")", "\n", "\n", "beam", "=", "[", "onmt", ".", "Beam", "(", "beamSize", ",", "self", ".", "opt", ".", "cuda", ")", "for", "k", "in", "range", "(", "batchSize", ")", "]", "\n", "\n", "decOut", "=", "self", ".", "model", ".", "make_init_decoder_output", "(", "context", ")", "\n", "\n", "padMask", "=", "srcBatch", ".", "data", ".", "eq", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "t", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "beamSize", ",", "1", ",", "1", ")", "\n", "\n", "batchIdx", "=", "list", "(", "range", "(", "batchSize", ")", ")", "\n", "remainingSents", "=", "batchSize", "\n", "for", "i", "in", "range", "(", "self", ".", "opt", ".", "max_sent_length", ")", ":", "\n", "\n", "            ", "self", ".", "model", ".", "decoder", ".", "apply", "(", "applyContextMask", ")", "\n", "\n", "# Prepare decoder input.", "\n", "input", "=", "torch", ".", "stack", "(", "[", "b", ".", "getCurrentState", "(", ")", "for", "b", "in", "beam", "\n", "if", "not", "b", ".", "done", "]", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "decOut", ",", "decStates", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "Variable", "(", "input", ",", "volatile", "=", "True", ")", ",", "decStates", ",", "context", ",", "decOut", ")", "\n", "# decOut: 1 x (beam*batch) x numWords", "\n", "decOut", "=", "decOut", ".", "squeeze", "(", "0", ")", "\n", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "decOut", ")", "\n", "\n", "# batch x beam x numWords", "\n", "wordLk", "=", "out", ".", "view", "(", "beamSize", ",", "remainingSents", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "attn", "=", "attn", ".", "view", "(", "beamSize", ",", "remainingSents", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "active", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batchSize", ")", ":", "\n", "                ", "if", "beam", "[", "b", "]", ".", "done", ":", "\n", "                    ", "continue", "\n", "\n", "", "idx", "=", "batchIdx", "[", "b", "]", "\n", "if", "not", "beam", "[", "b", "]", ".", "advance", "(", "wordLk", ".", "data", "[", "idx", "]", ",", "attn", ".", "data", "[", "idx", "]", ")", ":", "\n", "                    ", "active", "+=", "[", "b", "]", "\n", "\n", "", "for", "decState", "in", "decStates", ":", "# iterate over h, c", "\n", "# layers x beam*sent x dim", "\n", "                    ", "sentStates", "=", "decState", ".", "view", "(", "\n", "-", "1", ",", "beamSize", ",", "remainingSents", ",", "decState", ".", "size", "(", "2", ")", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "sentStates", ".", "data", ".", "copy_", "(", "\n", "sentStates", ".", "data", ".", "index_select", "(", "1", ",", "beam", "[", "b", "]", ".", "getCurrentOrigin", "(", ")", ")", ")", "\n", "\n", "", "", "if", "not", "active", ":", "\n", "                ", "break", "\n", "\n", "# in this section, the sentences that are still active are", "\n", "# compacted so that the decoder is not run on completed sentences", "\n", "", "activeIdx", "=", "self", ".", "tt", ".", "LongTensor", "(", "[", "batchIdx", "[", "k", "]", "for", "k", "in", "active", "]", ")", "\n", "batchIdx", "=", "{", "beam", ":", "idx", "for", "idx", ",", "beam", "in", "enumerate", "(", "active", ")", "}", "\n", "\n", "def", "updateActive", "(", "t", ")", ":", "\n", "# select only the remaining active sentences", "\n", "                ", "view", "=", "t", ".", "data", ".", "view", "(", "-", "1", ",", "remainingSents", ",", "rnnSize", ")", "\n", "newSize", "=", "list", "(", "t", ".", "size", "(", ")", ")", "\n", "newSize", "[", "-", "2", "]", "=", "newSize", "[", "-", "2", "]", "*", "len", "(", "activeIdx", ")", "//", "remainingSents", "\n", "return", "Variable", "(", "view", ".", "index_select", "(", "1", ",", "activeIdx", ")", ".", "view", "(", "*", "newSize", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "", "decStates", "=", "(", "updateActive", "(", "decStates", "[", "0", "]", ")", ",", "updateActive", "(", "decStates", "[", "1", "]", ")", ")", "\n", "decOut", "=", "updateActive", "(", "decOut", ")", "\n", "context", "=", "updateActive", "(", "context", ")", "\n", "padMask", "=", "padMask", ".", "index_select", "(", "1", ",", "activeIdx", ")", "\n", "\n", "remainingSents", "=", "len", "(", "active", ")", "\n", "\n", "#  (4) package everything up", "\n", "\n", "", "allHyp", ",", "allScores", ",", "allAttn", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "n_best", "=", "self", ".", "opt", ".", "n_best", "\n", "\n", "for", "b", "in", "range", "(", "batchSize", ")", ":", "\n", "            ", "scores", ",", "ks", "=", "beam", "[", "b", "]", ".", "sortBest", "(", ")", "\n", "\n", "allScores", "+=", "[", "scores", "[", ":", "n_best", "]", "]", "\n", "valid_attn", "=", "srcBatch", ".", "data", "[", ":", ",", "b", "]", ".", "ne", "(", "onmt", ".", "Constants", ".", "PAD", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "hyps", ",", "attn", "=", "zip", "(", "*", "[", "beam", "[", "b", "]", ".", "getHyp", "(", "k", ")", "for", "k", "in", "ks", "[", ":", "n_best", "]", "]", ")", "\n", "attn", "=", "[", "a", ".", "index_select", "(", "1", ",", "valid_attn", ")", "for", "a", "in", "attn", "]", "\n", "allHyp", "+=", "[", "hyps", "]", "\n", "allAttn", "+=", "[", "attn", "]", "\n", "\n", "", "return", "allHyp", ",", "allScores", ",", "allAttn", ",", "goldScores", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.translate": [[194, 212], ["Translator.Translator.buildData", "Translator.Translator.translateBatch", "range", "list", "src[].size", "predBatch.append", "zip", "Translator.Translator.buildTargetTokens", "sorted", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.buildData", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.translateBatch", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Translator.Translator.buildTargetTokens"], ["", "def", "translate", "(", "self", ",", "srcBatch", ",", "goldBatch", ")", ":", "\n", "#  (1) convert words to indexes", "\n", "        ", "dataset", "=", "self", ".", "buildData", "(", "srcBatch", ",", "goldBatch", ")", "\n", "src", ",", "tgt", ",", "indices", "=", "dataset", "[", "0", "]", "\n", "\n", "#  (2) translate", "\n", "pred", ",", "predScore", ",", "attn", ",", "goldScore", "=", "self", ".", "translateBatch", "(", "src", ",", "tgt", ")", "\n", "pred", ",", "predScore", ",", "attn", ",", "goldScore", "=", "list", "(", "zip", "(", "*", "sorted", "(", "zip", "(", "pred", ",", "predScore", ",", "attn", ",", "goldScore", ",", "indices", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "[", ":", "-", "1", "]", "\n", "\n", "#  (3) convert indexes to words", "\n", "predBatch", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "src", "[", "0", "]", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "predBatch", ".", "append", "(", "\n", "[", "self", ".", "buildTargetTokens", "(", "pred", "[", "b", "]", "[", "n", "]", ",", "srcBatch", "[", "b", "]", ",", "attn", "[", "b", "]", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "opt", ".", "n_best", ")", "]", "\n", ")", "\n", "\n", "", "return", "predBatch", ",", "predScore", ",", "goldScore", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.set_parameters": [[8, 20], ["list", "torch.SGD", "torch.SGD", "torch.Adagrad", "torch.Adagrad", "torch.Adadelta", "torch.Adadelta", "torch.Adam", "torch.Adam", "RuntimeError"], "methods", ["None"], ["    ", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "list", "(", "params", ")", "# careful: params may be a generator", "\n", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.__init__": [[21, 31], ["None"], "methods", ["None"], ["", "", "def", "__init__", "(", "self", ",", "method", ",", "lr", ",", "max_grad_norm", ",", "lr_decay", "=", "1", ",", "start_decay_at", "=", "None", ")", ":", "\n", "        ", "self", ".", "last_ppl", "=", "None", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_at", "=", "start_decay_at", "\n", "self", ".", "start_decay", "=", "False", "\n", "self", ".", "max_valid_score", "=", "-", "1.", "\n", "self", ".", "turn_alpha_anneal", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.step": [[32, 37], ["Optim.Optim.optimizer.step", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "# Compute gradients norm.", "\n", "        ", "if", "self", ".", "max_grad_norm", ":", "\n", "            ", "clip_grad_norm", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.updateLearningRate": [[39, 51], ["print"], "methods", ["None"], ["", "def", "updateLearningRate", "(", "self", ",", "ppl", ",", "epoch", ")", ":", "\n", "        ", "if", "self", ".", "start_decay_at", "is", "not", "None", "and", "epoch", ">=", "self", ".", "start_decay_at", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n", "", "if", "self", ".", "last_ppl", "is", "not", "None", "and", "ppl", ">", "self", ".", "last_ppl", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n", "\n", "", "if", "self", ".", "start_decay", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "lr", "*", "self", ".", "lr_decay", "\n", "print", "(", "\"Decaying learning rate to %g\"", "%", "self", ".", "lr", ")", "\n", "\n", "", "self", ".", "last_ppl", "=", "ppl", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Optim.Optim.dev_decay": [[52, 61], ["max", "print"], "methods", ["None"], ["", "def", "dev_decay", "(", "self", ",", "valid_score", ")", ":", "\n", "        ", "if", "valid_score", ">", "self", ".", "max_valid_score", ":", "\n", "            ", "self", ".", "max_valid_score", "=", "valid_score", "\n", "return", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "lr", "=", "max", "(", "self", ".", "lr", "*", "self", ".", "lr_decay", ",", "0.05", ")", "\n", "print", "(", "\"Validation score was not improved. Decay lr to {}\"", ".", "format", "(", "self", ".", "lr", ")", ")", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.Sampler.__init__": [[11, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.Sampler.sample": [[14, 17], ["None"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "tgt_data", ")", ":", "\n", "        ", "\"\"\"Return augmented tgt_data, rewards, and weights of proposed distribution\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.Sampler.reward": [[18, 21], ["None"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "y", ",", "y_ast", ",", "score", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return reward of (y, y*)\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.HammingDistanceSampler.__init__": [[25, 58], ["sampler.Sampler.__init__", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "temperature", ",", "max_len", ",", "voc_min", ",", "voc_max", ")", ":", "\n", "        ", "\"\"\"Sampling augmented target sentences and importance weights.\n\n        EXAMPLE\n        -------\n        >>> edit_sampler = HammingDistanceSampler(0.5, 10, 0, 9)\n        >>> tgt_data = [torch.LongTensor([0, 3, 5, 4, 3]), torch.LongTensor([2, 5, 1, 3, 9]), torch.LongTensor([2, 0, 1, 4, 5])]\n        >>> augmented_tgt_data, rewards, proposed_weights = edit_sampler.sample(tgt_data, [2, 3, 4])\n        >>> for s in tgt_data:\n        ...     print(s)\n        >>> for s in augmented_tgt_data:\n        ...     print(s)\n        >>> for r in rewards:\n        ...     print(r)\n        >>> for p in proposed_weights:\n        ...     print(p)\n\n        ARGUMENTS\n        ---------\n        voc_min: minimum index of vocabulary (inclusive)\n        voc_max: maximum index of vocabulary (inclusive)\n\n        \"\"\"", "\n", "super", "(", "HammingDistanceSampler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "voc_min", "=", "voc_min", "\n", "self", ".", "voc_max", "=", "voc_max", "\n", "self", ".", "voc_size", "=", "voc_max", "-", "voc_min", "+", "1", "\n", "self", ".", "edit_frac", "=", "0.2", "\n", "\n", "p", "=", "np", ".", "ones", "(", "(", "self", ".", "max_len", "+", "1", ",", "self", ".", "max_len", ")", ")", "# p[len_target, n_edit] = values of proposal distributions", "\n", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.HammingDistanceSampler.sample": [[59, 110], ["enumerate", "len", "int", "proposal_weights.append", "list", "enumerate", "float", "rewards.append", "new_tgt_data.append", "len", "len", "numpy.random.choice", "sampler.HammingDistanceSampler.reward", "torch.LongTensor", "numpy.random.choice", "new_tgt.append", "new_tgt.append", "int", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.BLEUSampler.reward"], ["", "def", "sample", "(", "self", ",", "tgt_data", ",", "edit_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"Augment tgt_data and return importance sampling weight\n\n        ARGS\n        ----\n        tgt_data: list of Torch.LongTensor\n        edit_list: specify the edit length for each sample (especially for debug)\n\n        Types of augmentation include: - deletion\n        \"\"\"", "\n", "\n", "if", "edit_list", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "edit_list", ")", "==", "len", "(", "tgt_data", ")", "\n", "\n", "", "new_tgt_data", "=", "[", "]", "\n", "rewards", "=", "[", "]", "\n", "proposal_weights", "=", "[", "]", "\n", "for", "i", ",", "tgt", "in", "enumerate", "(", "tgt_data", ")", ":", "\n", "            ", "len_tgt", "=", "len", "(", "tgt", ")", "\n", "max_edit", "=", "int", "(", "len_tgt", "*", "self", ".", "edit_frac", ")", "# in this study, we define max_edit as length of sentence", "\n", "\n", "# define edit distance for this tgt sentence", "\n", "if", "edit_list", "is", "not", "None", ":", "\n", "                ", "e", "=", "edit_list", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "e", "=", "np", ".", "random", ".", "choice", "(", "max_edit", "+", "1", ",", "1", ")", "[", "0", "]", "# choose from {0, ..., max_edit}", "\n", "\n", "# get proposal weights", "\n", "", "proposal_weights", ".", "append", "(", "self", ".", "p", "[", "len_tgt", ",", "e", "]", ")", "\n", "\n", "# execute augmentation", "\n", "n_substitutions", "=", "e", "\n", "# substitutions", "\n", "substituted_ixs", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "len_tgt", ",", "n_substitutions", ",", "replace", "=", "False", ")", ")", "\n", "new_tgt", "=", "[", "]", "\n", "for", "j", ",", "t", "in", "enumerate", "(", "tgt", ")", ":", "\n", "                ", "if", "j", "in", "substituted_ixs", ":", "\n", "                    ", "new_token", "=", "t", "\n", "while", "new_token", "==", "t", ":", "\n", "                        ", "new_token", "=", "int", "(", "np", ".", "random", ".", "choice", "(", "self", ".", "voc_size", ",", "1", ")", "[", "0", "]", ")", "+", "self", ".", "voc_min", "\n", "", "new_tgt", ".", "append", "(", "new_token", ")", "\n", "", "else", ":", "\n", "                    ", "new_tgt", ".", "append", "(", "t", ")", "\n", "\n", "# store the corresponding reward", "\n", "", "", "reward", "=", "float", "(", "self", ".", "reward", "(", "tgt", ",", "new_tgt", ",", "e", ")", ")", "\n", "rewards", ".", "append", "(", "reward", ")", "\n", "\n", "new_tgt_data", ".", "append", "(", "torch", ".", "LongTensor", "(", "new_tgt", ")", ")", "\n", "\n", "", "return", "new_tgt_data", ",", "rewards", ",", "proposal_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.HammingDistanceSampler.reward": [[111, 121], ["None"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "y", ",", "y_ast", ",", "score", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return minus of edit distance.\n\n        :param y:\n        :param y_ast:\n        :param score: edit distance\n        :return:\n        \"\"\"", "\n", "if", "score", "is", "not", "None", ":", "\n", "            ", "return", "-", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.BLEUSampler.__init__": [[127, 156], ["sampler.Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "edit_cand", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ")", ":", "\n", "        ", "\"\"\"Sampling augmented target sentences and importance weights.\n\n        EXAMPLE\n        -------\n        >>> sampler = BLEUSampler()\n        >>> tgt_data = [torch.LongTensor([0, 3, 5, 4, 3]), torch.LongTensor([2, 5, 1, 3, 9, 3]), torch.LongTensor([2, 0, 1, 4, 5])]\n        >>> augmented_tgt_data, rewards, weight = sampler.sample(tgt_data, [2, 2, 1])\n        >>> for s in tgt_data:\n        ...     print(s.size())\n        torch.Size([5])\n        torch.Size([6])\n        torch.Size([5])\n        >>> for s in augmented_tgt_data:\n        ...     print(s.size())\n        torch.Size([3])\n        torch.Size([4])\n        torch.Size([4])\n        >>> for r in rewards:\n        ...     print(r)\n        >>> for w in weight:\n        ...     print(w)\n        1.0\n        1.0\n        1.0\n\n        \"\"\"", "\n", "super", "(", "BLEUSampler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "edit_cand", "=", "edit_cand", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.BLEUSampler.sample": [[157, 198], ["enumerate", "len", "max", "numpy.random.choice", "enumerate", "float", "rewards.append", "new_tgt_data.append", "len", "len", "min", "new_tgt.append", "sampler.BLEUSampler.reward", "torch.LongTensor", "numpy.random.choice", "range", "len"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.BLEUSampler.reward"], ["", "def", "sample", "(", "self", ",", "tgt_data", ",", "edit_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"Augment tgt_data and return importance sampling weight\n\n        ARGS\n        ----\n        tgt_data: list of Torch.LongTensor\n        edit_list: specify the edit length for each sample (especially for debug)\n\n        Types of augmentation include:\n          - deletion\n        \"\"\"", "\n", "\n", "if", "edit_list", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "edit_list", ")", "==", "len", "(", "tgt_data", ")", "\n", "\n", "", "new_tgt_data", "=", "[", "]", "\n", "rewards", "=", "[", "]", "\n", "for", "i", ",", "tgt", "in", "enumerate", "(", "tgt_data", ")", ":", "\n", "# Define edit distance for this tgt sentence", "\n", "            ", "if", "edit_list", "is", "not", "None", ":", "\n", "                ", "e", "=", "edit_list", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "e", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "edit_cand", ",", "1", ")", "[", "0", "]", "\n", "\n", "# Execute augmentation", "\n", "", "len_seq", "=", "len", "(", "tgt", ")", "\n", "e", "=", "max", "(", "min", "(", "len_seq", "-", "1", ",", "e", ")", ",", "0", ")", "\n", "deleted_ixs", "=", "np", ".", "random", ".", "choice", "(", "len_seq", ",", "e", ",", "replace", "=", "False", ")", "\n", "new_tgt", "=", "[", "]", "\n", "for", "j", ",", "t", "in", "enumerate", "(", "tgt", ")", ":", "\n", "                ", "if", "j", "in", "deleted_ixs", ":", "\n", "                    ", "continue", "\n", "", "new_tgt", ".", "append", "(", "t", ")", "\n", "\n", "# Store the corresponding reward", "\n", "", "reward", "=", "float", "(", "self", ".", "reward", "(", "tgt", ",", "new_tgt", ")", ")", "\n", "rewards", ".", "append", "(", "reward", ")", "\n", "\n", "new_tgt_data", ".", "append", "(", "torch", ".", "LongTensor", "(", "new_tgt", ")", ")", "\n", "\n", "", "return", "new_tgt_data", ",", "rewards", ",", "[", "1.", "for", "_", "in", "range", "(", "len", "(", "rewards", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.BLEUSampler.reward": [[199, 211], ["nltk.translate.bleu_score.sentence_bleu"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "y", ",", "y_ast", ")", ":", "\n", "        ", "\"\"\"return BLEU score\n\n        EXAMPLE\n        -------\n        >>> sampler = BLEUSampler()\n        >>> sampler.reward([\"This\", \"is\", \"a\", \"pen\", \".\"], [\"This\", \"are\", \"a\", \"pen\", \".\"])\n        0.6042750794713536\n\n        \"\"\"", "\n", "blue_score", "=", "nltk", ".", "translate", ".", "bleu_score", ".", "sentence_bleu", "(", "[", "y_ast", "]", ",", "y", ")", "\n", "return", "blue_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.__init__": [[6, 20], ["type", "Dict.Dict.loadFile", "Dict.Dict.addSpecials"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.loadFile", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.addSpecials"], ["    ", "def", "__init__", "(", "self", ",", "data", "=", "None", ",", "lower", "=", "False", ")", ":", "\n", "        ", "self", ".", "idxToLabel", "=", "{", "}", "\n", "self", ".", "labelToIdx", "=", "{", "}", "\n", "self", ".", "frequencies", "=", "{", "}", "\n", "self", ".", "lower", "=", "lower", "\n", "\n", "# Special entries will not be pruned.", "\n", "self", ".", "special", "=", "[", "]", "\n", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "if", "type", "(", "data", ")", "==", "str", ":", "\n", "                ", "self", ".", "loadFile", "(", "data", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "addSpecials", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size": [[21, 23], ["len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idxToLabel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.loadFile": [[25, 31], ["codecs.open", "line.split", "int", "Dict.Dict.add"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.add"], ["", "def", "loadFile", "(", "self", ",", "filename", ")", ":", "\n", "        ", "for", "line", "in", "codecs", ".", "open", "(", "filename", ",", "'r'", ",", "'utf-8'", ")", ":", "\n", "            ", "fields", "=", "line", ".", "split", "(", ")", "\n", "label", "=", "fields", "[", "0", "]", "\n", "idx", "=", "int", "(", "fields", "[", "1", "]", ")", "\n", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.writeFile": [[33, 40], ["file.close", "codecs.open", "range", "Dict.Dict.size", "file.write"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "", "def", "writeFile", "(", "self", ",", "filename", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "filename", ",", "'w'", ",", "'utf-8'", ")", "as", "file", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "size", "(", ")", ")", ":", "\n", "                ", "label", "=", "self", ".", "idxToLabel", "[", "i", "]", "\n", "file", ".", "write", "(", "'%s %d\\n'", "%", "(", "label", ",", "i", ")", ")", "\n", "\n", "", "", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.lookup": [[41, 47], ["key.lower"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "key", ",", "default", "=", "None", ")", ":", "\n", "        ", "key", "=", "key", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "key", "\n", "try", ":", "\n", "            ", "return", "self", ".", "labelToIdx", "[", "key", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.getLabel": [[48, 53], ["None"], "methods", ["None"], ["", "", "def", "getLabel", "(", "self", ",", "idx", ",", "default", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "idxToLabel", "[", "idx", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.addSpecial": [[55, 58], ["Dict.Dict.add"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.add"], ["", "", "def", "addSpecial", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "idx", "=", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "self", ".", "special", "+=", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.addSpecials": [[60, 63], ["Dict.Dict.addSpecial"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.addSpecial"], ["", "def", "addSpecials", "(", "self", ",", "labels", ")", ":", "\n", "        ", "for", "label", "in", "labels", ":", "\n", "            ", "self", ".", "addSpecial", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.add": [[65, 84], ["label.lower", "len"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "label", "=", "label", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "label", "\n", "if", "idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "idxToLabel", "[", "idx", "]", "=", "label", "\n", "self", ".", "labelToIdx", "[", "label", "]", "=", "idx", "\n", "", "else", ":", "\n", "            ", "if", "label", "in", "self", ".", "labelToIdx", ":", "\n", "                ", "idx", "=", "self", ".", "labelToIdx", "[", "label", "]", "\n", "", "else", ":", "\n", "                ", "idx", "=", "len", "(", "self", ".", "idxToLabel", ")", "\n", "self", ".", "idxToLabel", "[", "idx", "]", "=", "label", "\n", "self", ".", "labelToIdx", "[", "label", "]", "=", "idx", "\n", "\n", "", "", "if", "idx", "not", "in", "self", ".", "frequencies", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "+=", "1", "\n", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.prune": [[86, 106], ["torch.Tensor", "torch.sort", "Dict.Dict", "Dict.Dict.size", "Dict.addSpecial", "Dict.add", "range", "len"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.addSpecial", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.add"], ["", "def", "prune", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "size", ">=", "self", ".", "size", "(", ")", ":", "\n", "            ", "return", "self", "\n", "\n", "# Only keep the `size` most frequent entries.", "\n", "", "freq", "=", "torch", ".", "Tensor", "(", "\n", "[", "self", ".", "frequencies", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "frequencies", ")", ")", "]", ")", "\n", "_", ",", "idx", "=", "torch", ".", "sort", "(", "freq", ",", "0", ",", "True", ")", "\n", "\n", "newDict", "=", "Dict", "(", ")", "\n", "newDict", ".", "lower", "=", "self", ".", "lower", "\n", "\n", "# Add special entries in all cases.", "\n", "for", "i", "in", "self", ".", "special", ":", "\n", "            ", "newDict", ".", "addSpecial", "(", "self", ".", "idxToLabel", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "idx", "[", ":", "size", "]", ":", "\n", "            ", "newDict", ".", "add", "(", "self", ".", "idxToLabel", "[", "i", "]", ")", "\n", "\n", "", "return", "newDict", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.convertToIdx": [[109, 122], ["Dict.Dict.lookup", "torch.LongTensor", "Dict.Dict.lookup", "Dict.Dict.lookup", "Dict.Dict.lookup"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.lookup", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.lookup", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.lookup", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.lookup"], ["", "def", "convertToIdx", "(", "self", ",", "labels", ",", "unkWord", ",", "bosWord", "=", "None", ",", "eosWord", "=", "None", ")", ":", "\n", "        ", "vec", "=", "[", "]", "\n", "\n", "if", "bosWord", "is", "not", "None", ":", "\n", "            ", "vec", "+=", "[", "self", ".", "lookup", "(", "bosWord", ")", "]", "\n", "\n", "", "unk", "=", "self", ".", "lookup", "(", "unkWord", ")", "\n", "vec", "+=", "[", "self", ".", "lookup", "(", "label", ",", "default", "=", "unk", ")", "for", "label", "in", "labels", "]", "\n", "\n", "if", "eosWord", "is", "not", "None", ":", "\n", "            ", "vec", "+=", "[", "self", ".", "lookup", "(", "eosWord", ")", "]", "\n", "\n", "", "return", "torch", ".", "LongTensor", "(", "vec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.convertToLabels": [[124, 133], ["Dict.Dict.getLabel"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.getLabel"], ["", "def", "convertToLabels", "(", "self", ",", "idx", ",", "stop", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "\n", "for", "i", "in", "idx", ":", "\n", "            ", "labels", "+=", "[", "self", ".", "getLabel", "(", "i", ")", "]", "\n", "if", "i", "==", "stop", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset.__init__": [[17, 29], ["math.ceil", "len", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "srcData", ",", "tgtData", ",", "batchSize", ",", "cuda", ",", "volatile", "=", "False", ")", ":", "\n", "        ", "self", ".", "src", "=", "srcData", "\n", "if", "tgtData", ":", "\n", "            ", "self", ".", "tgt", "=", "tgtData", "\n", "assert", "(", "len", "(", "self", ".", "src", ")", "==", "len", "(", "self", ".", "tgt", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tgt", "=", "None", "\n", "", "self", ".", "cuda", "=", "cuda", "\n", "\n", "self", ".", "batchSize", "=", "batchSize", "\n", "self", ".", "numBatches", "=", "math", ".", "ceil", "(", "len", "(", "self", ".", "src", ")", "/", "batchSize", ")", "\n", "self", ".", "volatile", "=", "volatile", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset._batchify": [[30, 43], ["max", "data[].new().fill_", "range", "x.size", "len", "data[].size", "out[].narrow().copy_", "data[].new", "len", "out[].narrow"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "_batchify", "(", "self", ",", "data", ",", "align_right", "=", "False", ",", "include_lengths", "=", "False", ")", ":", "\n", "        ", "lengths", "=", "[", "x", ".", "size", "(", "0", ")", "for", "x", "in", "data", "]", "\n", "max_length", "=", "max", "(", "lengths", ")", "\n", "out", "=", "data", "[", "0", "]", ".", "new", "(", "len", "(", "data", ")", ",", "max_length", ")", ".", "fill_", "(", "onmt", ".", "Constants", ".", "PAD", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "            ", "data_length", "=", "data", "[", "i", "]", ".", "size", "(", "0", ")", "\n", "offset", "=", "max_length", "-", "data_length", "if", "align_right", "else", "0", "\n", "out", "[", "i", "]", ".", "narrow", "(", "0", ",", "offset", ",", "data_length", ")", ".", "copy_", "(", "data", "[", "i", "]", ")", "\n", "\n", "", "if", "include_lengths", ":", "\n", "            ", "return", "out", ",", "lengths", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset.__getitem__": [[44, 75], ["Dataset.Dataset._batchify", "range", "zip", "Dataset.Dataset._batchify", "len", "zip", "zip", "zip", "zip", "torch.stack().t().contiguous", "torch.autograd.Variable", "Dataset.Dataset.__getitem__.wrap"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset._batchify", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset._batchify"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "assert", "index", "<", "self", ".", "numBatches", ",", "\"%d > %d\"", "%", "(", "index", ",", "self", ".", "numBatches", ")", "\n", "srcBatch", ",", "lengths", "=", "self", ".", "_batchify", "(", "\n", "self", ".", "src", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ",", "\n", "align_right", "=", "False", ",", "include_lengths", "=", "True", ")", "\n", "\n", "if", "self", ".", "tgt", ":", "\n", "            ", "tgtBatch", "=", "self", ".", "_batchify", "(", "\n", "self", ".", "tgt", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ")", "\n", "", "else", ":", "\n", "            ", "tgtBatch", "=", "None", "\n", "\n", "# within batch sorting by decreasing length for variable length rnns", "\n", "", "indices", "=", "range", "(", "len", "(", "srcBatch", ")", ")", "\n", "batch", "=", "zip", "(", "indices", ",", "srcBatch", ")", "if", "tgtBatch", "is", "None", "else", "zip", "(", "indices", ",", "srcBatch", ",", "tgtBatch", ")", "\n", "batch", ",", "lengths", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "batch", ",", "lengths", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ")", "\n", "if", "tgtBatch", "is", "None", ":", "\n", "            ", "indices", ",", "srcBatch", "=", "zip", "(", "*", "batch", ")", "\n", "", "else", ":", "\n", "            ", "indices", ",", "srcBatch", ",", "tgtBatch", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "", "def", "wrap", "(", "b", ")", ":", "\n", "            ", "if", "b", "is", "None", ":", "\n", "                ", "return", "b", "\n", "", "b", "=", "torch", ".", "stack", "(", "b", ",", "0", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                ", "b", "=", "b", ".", "cuda", "(", ")", "\n", "", "b", "=", "Variable", "(", "b", ",", "volatile", "=", "self", ".", "volatile", ")", "\n", "return", "b", "\n", "\n", "", "return", "(", "wrap", "(", "srcBatch", ")", ",", "lengths", ")", ",", "wrap", "(", "tgtBatch", ")", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset.__len__": [[76, 78], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "numBatches", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset.shuffle": [[79, 82], ["list", "zip", "zip", "torch.randperm", "len"], "methods", ["None"], ["", "def", "shuffle", "(", "self", ")", ":", "\n", "        ", "data", "=", "list", "(", "zip", "(", "self", ".", "src", ",", "self", ".", "tgt", ")", ")", "\n", "self", ".", "src", ",", "self", ".", "tgt", "=", "zip", "(", "*", "[", "data", "[", "i", "]", "for", "i", "in", "torch", ".", "randperm", "(", "len", "(", "data", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.ISDataset.__init__": [[87, 102], ["len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "sampler", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "sampler", "=", "sampler", "\n", "\n", "self", ".", "src", "=", "self", ".", "dataset", ".", "src", "\n", "if", "self", ".", "dataset", ".", "tgt", ":", "\n", "            ", "self", ".", "tgt", "=", "self", ".", "dataset", ".", "tgt", "\n", "assert", "(", "len", "(", "self", ".", "src", ")", "==", "len", "(", "self", ".", "tgt", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tgt", "=", "None", "\n", "", "self", ".", "cuda", "=", "self", ".", "dataset", ".", "cuda", "\n", "\n", "self", ".", "batchSize", "=", "self", ".", "dataset", ".", "batchSize", "\n", "self", ".", "numBatches", "=", "self", ".", "dataset", ".", "numBatches", "\n", "self", ".", "volatile", "=", "self", ".", "dataset", ".", "volatile", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.ISDataset.__getitem__": [[103, 148], ["Dataset.ISDataset.dataset._batchify", "range", "zip", "Dataset.ISDataset.sampler.sample", "Dataset.ISDataset.dataset._batchify", "len", "zip", "zip", "zip", "zip", "torch.stack().t().contiguous", "torch.autograd.Variable", "Dataset.ISDataset.__getitem__.wrap"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset._batchify", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.sampler.BLEUSampler.sample", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.Dataset._batchify"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a batch.\n\n        EXAMPLE\n        -------\n        >>> src = [torch.LongTensor([0, 1, 2]), torch.LongTensor([3, 4, 5]), torch.LongTensor([6, 7, 8])]\n        >>> tgt = [torch.LongTensor([0, 1, 2]), torch.LongTensor([3, 4, 5]), torch.LongTensor([6, 7, 8])]\n        >>> dataset = Dataset(src, tgt, 2, [])\n        >>> sampler = onmt.EditDistanceSampler([0])\n        >>> aug_dataset = ISDataset(dataset, sampler)\n        >>> src, tgt, indices, rewards, proposed_weights = aug_dataset[0]\n        \"\"\"", "\n", "assert", "index", "<", "self", ".", "numBatches", ",", "\"%d > %d\"", "%", "(", "index", ",", "self", ".", "numBatches", ")", "\n", "srcBatch", ",", "lengths", "=", "self", ".", "dataset", ".", "_batchify", "(", "\n", "self", ".", "src", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ",", "\n", "align_right", "=", "False", ",", "include_lengths", "=", "True", ")", "\n", "\n", "if", "self", ".", "tgt", ":", "\n", "            ", "tgtBatch", ",", "rewards", ",", "proposed_weights", "=", "self", ".", "sampler", ".", "sample", "(", "self", ".", "tgt", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ")", "\n", "tgtBatch", "=", "self", ".", "dataset", ".", "_batchify", "(", "tgtBatch", ")", "\n", "", "else", ":", "\n", "            ", "tgtBatch", "=", "None", "\n", "rewards", "=", "None", "\n", "proposed_weights", "=", "None", "\n", "\n", "# within batch sorting by decreasing length for variable length rnns", "\n", "", "indices", "=", "range", "(", "len", "(", "srcBatch", ")", ")", "\n", "batch", "=", "zip", "(", "indices", ",", "srcBatch", ")", "if", "tgtBatch", "is", "None", "else", "zip", "(", "indices", ",", "srcBatch", ",", "tgtBatch", ",", "rewards", ",", "proposed_weights", ")", "\n", "batch", ",", "lengths", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "batch", ",", "lengths", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ")", "\n", "if", "tgtBatch", "is", "None", ":", "\n", "            ", "indices", ",", "srcBatch", "=", "zip", "(", "*", "batch", ")", "\n", "", "else", ":", "\n", "            ", "indices", ",", "srcBatch", ",", "tgtBatch", ",", "rewards", ",", "proposed_weights", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "", "def", "wrap", "(", "b", ")", ":", "\n", "            ", "if", "b", "is", "None", ":", "\n", "                ", "return", "b", "\n", "", "b", "=", "torch", ".", "stack", "(", "b", ",", "0", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                ", "b", "=", "b", ".", "cuda", "(", ")", "\n", "", "b", "=", "Variable", "(", "b", ",", "volatile", "=", "self", ".", "volatile", ")", "\n", "return", "b", "\n", "\n", "", "return", "(", "wrap", "(", "srcBatch", ")", ",", "lengths", ")", ",", "wrap", "(", "tgtBatch", ")", ",", "indices", ",", "rewards", ",", "proposed_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.ISDataset.__len__": [[149, 151], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "numBatches", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.ISDataset.shuffle": [[152, 154], ["Dataset.ISDataset.dataset.shuffle"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dataset.ISDataset.shuffle"], ["", "def", "shuffle", "(", "self", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "shuffle", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.importance_sampling.uniform_weights": [[5, 23], ["torch.ones", "torch.ones.sum"], "function", ["None"], ["def", "uniform_weights", "(", "n_sample", ")", ":", "\n", "    ", "\"\"\"Return uniform weights (almost for debug).\n\n    EXAMPLE\n    -------\n    >>> weights = uniform_weights(3)\n    >>> print(weights)\n    <BLANKLINE>\n     0.3333\n     0.3333\n     0.3333\n    [torch.FloatTensor of size 3]\n    <BLANKLINE>\n\n    :return:\n    \"\"\"", "\n", "weights", "=", "torch", ".", "ones", "(", "n_sample", ")", "\n", "return", "weights", "/", "weights", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.importance_sampling.raml_weights": [[25, 46], ["numpy.exp", "torch.from_numpy", "weights.sum"], "function", ["None"], ["", "def", "raml_weights", "(", "rewards", ",", "proposed_weights", ",", "tau", ")", ":", "\n", "    ", "\"\"\"Return exp-scaled weights.\n\n    EXAMPLE\n    -------\n    >>> rewards = np.array([0, -1, -1])\n    >>> proposed_weights = np.array([1., 1., 1.])\n    >>> weights = raml_weights(rewards, proposed_weights, 1.0)\n    >>> weights.sum()\n    1.0\n\n    :param rewards:\n    :param proposed_weights:\n    :return:\n    \"\"\"", "\n", "\n", "exp_rewards", "=", "np", ".", "exp", "(", "rewards", "/", "tau", ")", "\n", "weights", "=", "exp_rewards", "*", "proposed_weights", "\n", "weights", "=", "weights", "/", "weights", ".", "sum", "(", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "weights", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.__init__": [[20, 39], ["Beam.Beam.tt.FloatTensor().zero_", "Beam.Beam.tt.LongTensor().fill_", "Beam.Beam.tt.FloatTensor", "Beam.Beam.tt.LongTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "cuda", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "done", "=", "False", "\n", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prevKs", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "nextYs", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", ".", "fill_", "(", "onmt", ".", "Constants", ".", "PAD", ")", "]", "\n", "self", ".", "nextYs", "[", "0", "]", "[", "0", "]", "=", "onmt", ".", "Constants", ".", "BOS", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.getCurrentState": [[41, 43], ["None"], "methods", ["None"], ["", "def", "getCurrentState", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "nextYs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.getCurrentOrigin": [[45, 47], ["None"], "methods", ["None"], ["", "def", "getCurrentOrigin", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "prevKs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.advance": [[57, 84], ["wordLk.size", "beamLk.view", "beamLk.view.topk", "Beam.Beam.prevKs.append", "Beam.Beam.nextYs.append", "Beam.Beam.attn.append", "len", "attnOut.index_select", "Beam.Beam.scores.unsqueeze().expand_as", "Beam.Beam.scores.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "advance", "(", "self", ",", "wordLk", ",", "attnOut", ")", ":", "\n", "\n", "        ", "numWords", "=", "wordLk", ".", "size", "(", "1", ")", "\n", "\n", "# Sum the previous scores.", "\n", "if", "len", "(", "self", ".", "prevKs", ")", ">", "0", ":", "\n", "            ", "beamLk", "=", "wordLk", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "wordLk", ")", "\n", "", "else", ":", "\n", "            ", "beamLk", "=", "wordLk", "[", "0", "]", "\n", "\n", "", "flatBeamLk", "=", "beamLk", ".", "view", "(", "-", "1", ")", "\n", "\n", "bestScores", ",", "bestScoresId", "=", "flatBeamLk", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "True", ",", "True", ")", "\n", "self", ".", "scores", "=", "bestScores", "\n", "\n", "# bestScoresId is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prevK", "=", "bestScoresId", "/", "numWords", "\n", "self", ".", "prevKs", ".", "append", "(", "prevK", ")", "\n", "self", ".", "nextYs", ".", "append", "(", "bestScoresId", "-", "prevK", "*", "numWords", ")", "\n", "self", ".", "attn", ".", "append", "(", "attnOut", ".", "index_select", "(", "0", ",", "prevK", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS.", "\n", "if", "self", ".", "nextYs", "[", "-", "1", "]", "[", "0", "]", "==", "onmt", ".", "Constants", ".", "EOS", ":", "\n", "            ", "self", ".", "done", "=", "True", "\n", "\n", "", "return", "self", ".", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.sortBest": [[85, 87], ["torch.sort"], "methods", ["None"], ["", "def", "sortBest", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "sort", "(", "self", ".", "scores", ",", "0", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.getBest": [[89, 92], ["Beam.Beam.sortBest"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.sortBest"], ["", "def", "getBest", "(", "self", ")", ":", "\n", "        ", "scores", ",", "ids", "=", "self", ".", "sortBest", "(", ")", "\n", "return", "scores", "[", "1", "]", ",", "ids", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Beam.Beam.getHyp": [[103, 112], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "getHyp", "(", "self", ",", "k", ")", ":", "\n", "        ", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "# print(len(self.prevKs), len(self.nextYs), len(self.attn))", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prevKs", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "nextYs", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prevKs", "[", "j", "]", "[", "k", "]", "\n", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__": [[28, 35], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "sm", "=", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.applyMask": [[36, 38], ["None"], "methods", ["None"], ["", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.modules.GlobalAttention.GlobalAttention.forward": [[39, 59], ["GlobalAttention.GlobalAttention.linear_in().unsqueeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "GlobalAttention.GlobalAttention.sm", "GlobalAttention.GlobalAttention.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "GlobalAttention.GlobalAttention.tanh", "GlobalAttention.GlobalAttention.data.masked_fill_", "GlobalAttention.GlobalAttention.size", "GlobalAttention.GlobalAttention.size", "GlobalAttention.GlobalAttention.linear_out", "GlobalAttention.GlobalAttention.linear_in", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "float"], "methods", ["home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size", "home.repos.pwc.inspect_result.sotetsuk_alpha-dimt-icmlws.onmt.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ")", ":", "\n", "        ", "\"\"\"\n        input: batch x dim\n        context: batch x sourceL x dim\n        \"\"\"", "\n", "targetT", "=", "self", ".", "linear_in", "(", "input", ")", ".", "unsqueeze", "(", "2", ")", "# batch x dim x 1", "\n", "\n", "# Get attention", "\n", "attn", "=", "torch", ".", "bmm", "(", "context", ",", "targetT", ")", ".", "squeeze", "(", "2", ")", "# batch x sourceL", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "attn", "=", "self", ".", "sm", "(", "attn", ")", "\n", "attn3", "=", "attn", ".", "view", "(", "attn", ".", "size", "(", "0", ")", ",", "1", ",", "attn", ".", "size", "(", "1", ")", ")", "# batch x 1 x sourceL", "\n", "\n", "weightedContext", "=", "torch", ".", "bmm", "(", "attn3", ",", "context", ")", ".", "squeeze", "(", "1", ")", "# batch x dim", "\n", "contextCombined", "=", "torch", ".", "cat", "(", "(", "weightedContext", ",", "input", ")", ",", "1", ")", "\n", "\n", "contextOutput", "=", "self", ".", "tanh", "(", "self", ".", "linear_out", "(", "contextCombined", ")", ")", "\n", "\n", "return", "contextOutput", ",", "attn", "\n", "", "", ""]]}