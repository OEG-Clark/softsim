{"home.repos.pwc.inspect_result.spitis_mrl.None.conftest.pytest_addoption": [[4, 7], ["parser.addoption"], "function", ["None"], ["def", "pytest_addoption", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "addoption", "(", "\n", "\"--runslow\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ",", "help", "=", "\"run slow tests\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.None.conftest.pytest_configure": [[10, 12], ["config.addinivalue_line"], "function", ["None"], ["", "def", "pytest_configure", "(", "config", ")", ":", "\n", "    ", "config", ".", "addinivalue_line", "(", "\"markers\"", ",", "\"slow: mark test as slow to run\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.None.conftest.pytest_collection_modifyitems": [[14, 22], ["config.getoption", "pytest.mark.skip", "item.add_marker"], "function", ["None"], ["", "def", "pytest_collection_modifyitems", "(", "config", ",", "items", ")", ":", "\n", "    ", "if", "config", ".", "getoption", "(", "\"--runslow\"", ")", ":", "\n", "# --runslow given in cli: do not skip slow tests", "\n", "        ", "return", "\n", "", "skip_slow", "=", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"need --runslow option to run\"", ")", "\n", "for", "item", "in", "items", ":", "\n", "        ", "if", "\"slow\"", "in", "item", ".", "keywords", ":", "\n", "            ", "item", ".", "add_marker", "(", "skip_slow", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_bulk.AttrDict.__getattr__": [[21, 26], ["dict.__getitem__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__getitem__"], ["def", "__getattr__", "(", "self", ",", "key", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "return", "dict", ".", "__getitem__", "(", "self", ",", "key", ")", "\n", "", "except", "KeyError", ":", "\n", "      ", "raise", "AttributeError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_bulk.smooth_reward_curve": [[27, 34], ["int", "numpy.ceil", "numpy.convolve", "numpy.convolve", "numpy.ones", "numpy.ones_like", "numpy.ones", "len"], "function", ["None"], ["", "", "", "def", "smooth_reward_curve", "(", "x", ",", "y", ")", ":", "\n", "   ", "halfwidth", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "x", ")", "/", "60", ")", ")", "# Halfwidth of our smoothing convolution", "\n", "k", "=", "halfwidth", "\n", "xsmoo", "=", "x", "\n", "ysmoo", "=", "np", ".", "convolve", "(", "y", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "mode", "=", "'same'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "\n", "mode", "=", "'same'", ")", "\n", "return", "xsmoo", ",", "ysmoo", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_bulk.fix_point": [[35, 57], ["numpy.insert", "numpy.insert", "int", "range", "len", "fx.append", "fy.append", "max", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "fix_point", "(", "x", ",", "y", ",", "interval", ")", ":", "\n", "  ", "\"\"\"What does this do?\"\"\"", "\n", "np", ".", "insert", "(", "x", ",", "0", ",", "0", ")", "\n", "np", ".", "insert", "(", "y", ",", "0", ",", "0", ")", "\n", "\n", "fx", ",", "fy", "=", "[", "]", ",", "[", "]", "\n", "pointer", "=", "0", "\n", "ninterval", "=", "int", "(", "max", "(", "x", ")", "/", "interval", "+", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "ninterval", ")", ":", "\n", "    ", "tmpx", "=", "interval", "*", "i", "\n", "\n", "while", "pointer", "+", "1", "<", "len", "(", "x", ")", "and", "tmpx", ">", "x", "[", "pointer", "+", "1", "]", ":", "\n", "      ", "pointer", "+=", "1", "\n", "\n", "", "if", "pointer", "+", "1", "<", "len", "(", "x", ")", ":", "\n", "      ", "alpha", "=", "(", "y", "[", "pointer", "+", "1", "]", "-", "y", "[", "pointer", "]", ")", "/", "(", "x", "[", "pointer", "+", "1", "]", "-", "x", "[", "pointer", "]", ")", "\n", "tmpy", "=", "y", "[", "pointer", "]", "+", "alpha", "*", "(", "tmpx", "-", "x", "[", "pointer", "]", ")", "\n", "fx", ".", "append", "(", "tmpx", ")", "\n", "fy", ".", "append", "(", "tmpy", ")", "\n", "\n", "", "", "return", "fx", ",", "fy", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_bulk.load_data": [[58, 95], ["glob.glob", "list", "os.path.join", "numpy.loadtxt", "zip", "sorted.append", "sorted", "plot_bulk.fix_point", "zip", "data.append", "result.append", "plot_bulk.smooth_reward_curve", "scipy.signal.medfilt", "numpy.array", "numpy.array", "plot_bulk.load_data.process_data"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.fix_point", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.smooth_reward_curve"], ["", "def", "load_data", "(", "indir", ",", "smooth", ",", "bin_size", ")", ":", "\n", "  ", "datas", "=", "[", "]", "\n", "infiles", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "indir", ",", "'*.csv'", ")", ")", "\n", "# datas_goal = []", "\n", "\n", "for", "inf", "in", "infiles", ":", "\n", "    ", "data", "=", "[", "]", "\n", "data_csv", "=", "np", ".", "loadtxt", "(", "inf", ",", "delimiter", "=", "\",\"", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "1", ",", "2", "]", ")", "\n", "for", "sec", ",", "acc", "in", "zip", "(", "data_csv", "[", ":", ",", "0", "]", ",", "data_csv", "[", ":", ",", "1", "]", ")", ":", "\n", "      ", "data", ".", "append", "(", "[", "sec", ",", "acc", "]", ")", "\n", "", "datas", ".", "append", "(", "data", ")", "\n", "\n", "", "def", "process_data", "(", "datas", ")", ":", "\n", "    ", "datas", "=", "sorted", "(", "datas", ",", "key", "=", "lambda", "d_entry", ":", "d_entry", "[", "0", "]", ")", "\n", "result", "=", "[", "]", "\n", "timesteps", "=", "0", "\n", "for", "data", "in", "datas", ":", "\n", "      ", "result", ".", "append", "(", "[", "timesteps", ",", "data", "[", "-", "1", "]", "]", ")", "\n", "timesteps", "=", "data", "[", "0", "]", "\n", "\n", "", "x", ",", "y", "=", "np", ".", "array", "(", "result", ")", "[", ":", ",", "0", "]", ",", "np", ".", "array", "(", "result", ")", "[", ":", ",", "1", "]", "\n", "\n", "if", "smooth", "==", "1", ":", "\n", "      ", "x", ",", "y", "=", "smooth_reward_curve", "(", "x", ",", "y", ")", "\n", "\n", "", "if", "smooth", "==", "2", ":", "\n", "      ", "y", "=", "medfilt", "(", "y", ",", "kernel_size", "=", "9", ")", "\n", "\n", "", "x", ",", "y", "=", "fix_point", "(", "x", ",", "y", ",", "bin_size", ")", "\n", "return", "[", "x", ",", "y", "]", "\n", "\n", "# if goal:", "\n", "#   return list(zip(*tuple([process_data(data_goal[goal]) for data_goal in datas_goal])))", "\n", "\n", "# else:", "\n", "\n", "", "return", "list", "(", "zip", "(", "*", "(", "process_data", "(", "data", ")", "for", "data", "in", "datas", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_bulk.load": [[96, 123], ["zip", "os.path.join", "plot_bulk.load_data", "result.append", "len", "min", "range", "numpy.mean", "numpy.mean", "numpy.std", "numpy.array().reshape", "numpy.array().reshape", "numpy.zeros", "len", "numpy.array", "numpy.array", "numpy.array", "len", "len", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.load_data", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "load", "(", "indir", ",", "names", ",", "labels", ",", "smooth", ",", "bin_size", ")", ":", "\n", "  ", "result", "=", "[", "]", "\n", "\n", "for", "name", ",", "label", "in", "zip", "(", "names", ",", "labels", ")", ":", "\n", "    ", "d", "=", "os", ".", "path", ".", "join", "(", "indir", ",", "name", ")", "\n", "tmpx", ",", "tmpy", "=", "[", "]", ",", "[", "]", "\n", "\n", "tx", ",", "ty", "=", "load_data", "(", "d", ",", "smooth", ",", "bin_size", ")", "\n", "tmpx", "+=", "tx", "\n", "tmpy", "+=", "ty", "\n", "\n", "if", "len", "(", "tmpx", ")", ">", "1", ":", "\n", "      ", "length", "=", "min", "(", "[", "len", "(", "t", ")", "for", "t", "in", "tmpx", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tmpx", ")", ")", ":", "\n", "        ", "tmpx", "[", "i", "]", "=", "tmpx", "[", "i", "]", "[", ":", "length", "]", "\n", "tmpy", "[", "i", "]", "=", "tmpy", "[", "i", "]", "[", ":", "length", "]", "\n", "\n", "", "x", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "tmpx", ")", ",", "axis", "=", "0", ")", "\n", "y_mean", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "tmpy", ")", ",", "axis", "=", "0", ")", "\n", "y_std", "=", "np", ".", "std", "(", "np", ".", "array", "(", "tmpy", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "tmpx", ")", ".", "reshape", "(", "-", "1", ")", "\n", "y_mean", "=", "np", ".", "array", "(", "tmpy", ")", ".", "reshape", "(", "-", "1", ")", "\n", "y_std", "=", "np", ".", "zeros", "(", "len", "(", "y_mean", ")", ")", "\n", "\n", "", "result", ".", "append", "(", "[", "label", ",", "x", ",", "y_mean", ",", "y_std", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_bulk.plot": [[125, 185], ["matplotlib.figure", "seaborn.despine", "plot_bulk.load", "enumerate", "numpy.arange", "matplotlib.xticks", "hasattr", "matplotlib.ylim", "matplotlib.xlim", "matplotlib.legend", "matplotlib.title", "matplotlib.tight_layout", "matplotlib.savefig", "print", "numpy.sum", "int", "matplotlib.plot", "lines.append", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.yticks", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.fill_between", "list", "max", "max", "ignore_even", "list", "list", "enumerate", "ignore_even", "enumerate", "float", "float"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "plot", "(", "args", ")", ":", "\n", "  ", "plt", ".", "figure", "(", "figsize", "=", "(", "4", ",", "3", ")", ",", "dpi", "=", "300", ")", "\n", "sns", ".", "despine", "(", "left", "=", "True", ",", "bottom", "=", "True", ")", "\n", "datas", "=", "load", "(", "args", ".", "source", ",", "args", ".", "names", ",", "args", ".", "labels", ",", "args", ".", "smooth", ",", "args", ".", "bin_size", ")", "\n", "for", "ignore_string", "in", "args", ".", "ignore_strings", ":", "\n", "    ", "datas", "=", "[", "d", "for", "d", "in", "datas", "if", "not", "ignore_string", "in", "d", "[", "0", "]", "]", "\n", "", "lines", "=", "[", "]", "\n", "max_y", "=", "args", ".", "max_y", "\n", "min_y", "=", "args", ".", "min_y", "\n", "max_x", "=", "args", ".", "max_x", "\n", "min_x", "=", "1e10", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "datas", ")", ":", "\n", "    ", "label", ",", "x", ",", "y_mean", ",", "y_std", "=", "data", "\n", "color", "=", "args", ".", "colors", "[", "i", "]", "\n", "if", "np", ".", "sum", "(", "y_std", ")", ":", "\n", "      ", "y_upper", "=", "y_mean", "+", "y_std", "\n", "y_lower", "=", "y_mean", "-", "y_std", "\n", "plt", ".", "fill_between", "(", "\n", "x", ",", "list", "(", "y_lower", ")", ",", "list", "(", "y_upper", ")", ",", "interpolate", "=", "True", ",", "facecolor", "=", "color", ",", "linewidth", "=", "0.0", ",", "alpha", "=", "0.2", "\n", ")", "\n", "", "linestyle", "=", "args", ".", "line_styles", "[", "i", "]", "\n", "marker", "=", "args", ".", "markers", "[", "i", "]", "\n", "markersize", "=", "args", ".", "markersizes", "[", "i", "]", "\n", "markevery", "=", "int", "(", "max_x", "/", "500", ")", "\n", "line", "=", "plt", ".", "plot", "(", "x", ",", "list", "(", "y_mean", ")", ",", "linewidth", "=", "2.0", ",", "label", "=", "label", ",", "color", "=", "color", ",", "markersize", "=", "markersize", ",", "marker", "=", "marker", ",", "markevery", "=", "markevery", ",", "linestyle", "=", "linestyle", ")", "\n", "lines", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "if", "max", "(", "x", ")", "<", "min_x", ":", "\n", "      ", "min_x", "=", "max", "(", "x", ")", "\n", "\n", "\n", "", "", "xticks", "=", "np", ".", "arange", "(", "0", ",", "max_x", "+", "1", ",", "max_x", "//", "8", ")", "\n", "ignore_even", "=", "lambda", "s", ",", "i", ":", "s", "if", "i", "%", "2", "==", "0", "else", "''", "\n", "if", "'Millions'", "in", "args", ".", "xlabel", ":", "\n", "    ", "xlabels", "=", "[", "ignore_even", "(", "'{:0.2f}'", ".", "format", "(", "float", "(", "x", ")", "/", "100000000.", "*", "args", ".", "time_steps_per_episode", ")", ".", "rstrip", "(", "'0'", ")", ".", "rstrip", "(", "'.'", ")", ",", "\n", "i", ")", "for", "i", ",", "x", "in", "enumerate", "(", "xticks", ")", "]", "\n", "", "elif", "'Thousands'", "in", "args", ".", "xlabel", ":", "\n", "    ", "xlabels", "=", "[", "ignore_even", "(", "'{:0.2f}'", ".", "format", "(", "float", "(", "x", ")", "/", "100000.", "*", "args", ".", "time_steps_per_episode", ")", ".", "rstrip", "(", "'0'", ")", ".", "rstrip", "(", "'.'", ")", ",", "\n", "i", ")", "for", "i", ",", "x", "in", "enumerate", "(", "xticks", ")", "]", "\n", "#xlabels[-1] += 'M'", "\n", "", "plt", ".", "xticks", "(", "xticks", ",", "xlabels", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "if", "args", ".", "xlabel", "is", "None", ":", "\n", "    ", "plt", ".", "xlabel", "(", "'Placeholder'", ",", "fontsize", "=", "args", ".", "label_size", ",", "color", "=", "'white'", ")", "\n", "", "else", ":", "\n", "    ", "plt", ".", "xlabel", "(", "args", ".", "xlabel", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "\n", "", "if", "hasattr", "(", "args", ",", "'y_values'", ")", ":", "\n", "    ", "plt", ".", "yticks", "(", "args", ".", "y_values", ",", "args", ".", "y_labels", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "", "if", "args", ".", "ylabel", "is", "None", ":", "\n", "    ", "plt", ".", "ylabel", "(", "''", ")", "\n", "", "else", ":", "\n", "    ", "plt", ".", "ylabel", "(", "args", ".", "ylabel", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "\n", "", "plt", ".", "ylim", "(", "min_y", ",", "max_y", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "max_x", ")", "\n", "plt", ".", "legend", "(", "fancybox", "=", "True", ",", "framealpha", "=", "0.7", ",", "loc", "=", "args", ".", "legend_loc", ",", "fontsize", "=", "args", ".", "legend_size", ",", "frameon", "=", "True", ",", "facecolor", "=", "'white'", ",", "borderaxespad", "=", "1.", ")", "\n", "plt", ".", "title", "(", "args", ".", "title", ",", "fontsize", "=", "args", ".", "title_size", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "0.0", ")", "# Make room for the xlabel", "\n", "plt", ".", "savefig", "(", "args", ".", "output", ",", "format", "=", "'png'", ",", "dpi", "=", "600", ")", "# Need to do savefig before plt.show() otherwise PDF file will be blank", "\n", "print", "(", "\"DONE {}\"", ".", "format", "(", "args", ".", "output", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_tensorboard.smooth_reward_curve": [[16, 23], ["int", "numpy.ceil", "numpy.convolve", "numpy.convolve", "numpy.ones", "numpy.ones_like", "numpy.ones", "len"], "function", ["None"], ["def", "smooth_reward_curve", "(", "x", ",", "y", ")", ":", "\n", "   ", "halfwidth", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "x", ")", "/", "60", ")", ")", "# Halfwidth of our smoothing convolution", "\n", "k", "=", "halfwidth", "\n", "xsmoo", "=", "x", "\n", "ysmoo", "=", "np", ".", "convolve", "(", "y", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "mode", "=", "'same'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "\n", "mode", "=", "'same'", ")", "\n", "return", "xsmoo", ",", "ysmoo", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_tensorboard.fix_point": [[24, 46], ["numpy.insert", "numpy.insert", "int", "range", "len", "fx.append", "fy.append", "max", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "fix_point", "(", "x", ",", "y", ",", "interval", ")", ":", "\n", "  ", "\"\"\"What does this do?\"\"\"", "\n", "np", ".", "insert", "(", "x", ",", "0", ",", "0", ")", "\n", "np", ".", "insert", "(", "y", ",", "0", ",", "0", ")", "\n", "\n", "fx", ",", "fy", "=", "[", "]", ",", "[", "]", "\n", "pointer", "=", "0", "\n", "ninterval", "=", "int", "(", "max", "(", "x", ")", "/", "interval", "+", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "ninterval", ")", ":", "\n", "    ", "tmpx", "=", "interval", "*", "i", "\n", "\n", "while", "pointer", "+", "1", "<", "len", "(", "x", ")", "and", "tmpx", ">", "x", "[", "pointer", "+", "1", "]", ":", "\n", "      ", "pointer", "+=", "1", "\n", "\n", "", "if", "pointer", "+", "1", "<", "len", "(", "x", ")", ":", "\n", "      ", "alpha", "=", "(", "y", "[", "pointer", "+", "1", "]", "-", "y", "[", "pointer", "]", ")", "/", "(", "x", "[", "pointer", "+", "1", "]", "-", "x", "[", "pointer", "]", ")", "\n", "tmpy", "=", "y", "[", "pointer", "]", "+", "alpha", "*", "(", "tmpx", "-", "x", "[", "pointer", "]", ")", "\n", "fx", ".", "append", "(", "tmpx", ")", "\n", "fy", ".", "append", "(", "tmpy", ")", "\n", "\n", "", "", "return", "fx", ",", "fy", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_tensorboard.load_data": [[47, 84], ["glob.glob", "list", "os.path.join", "numpy.loadtxt", "zip", "sorted.append", "sorted", "plot_tensorboard.fix_point", "zip", "data.append", "result.append", "plot_tensorboard.smooth_reward_curve", "scipy.signal.medfilt", "numpy.array", "numpy.array", "plot_tensorboard.load_data.process_data"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.fix_point", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.smooth_reward_curve"], ["", "def", "load_data", "(", "indir", ",", "smooth", ",", "bin_size", ")", ":", "\n", "  ", "datas", "=", "[", "]", "\n", "infiles", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "indir", ",", "'*.csv'", ")", ")", "\n", "# datas_goal = []", "\n", "\n", "for", "inf", "in", "infiles", ":", "\n", "    ", "data", "=", "[", "]", "\n", "data_csv", "=", "np", ".", "loadtxt", "(", "inf", ",", "delimiter", "=", "\",\"", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "1", ",", "2", "]", ")", "\n", "for", "sec", ",", "acc", "in", "zip", "(", "data_csv", "[", ":", ",", "0", "]", ",", "data_csv", "[", ":", ",", "1", "]", ")", ":", "\n", "      ", "data", ".", "append", "(", "[", "sec", ",", "acc", "]", ")", "\n", "", "datas", ".", "append", "(", "data", ")", "\n", "\n", "", "def", "process_data", "(", "datas", ")", ":", "\n", "    ", "datas", "=", "sorted", "(", "datas", ",", "key", "=", "lambda", "d_entry", ":", "d_entry", "[", "0", "]", ")", "\n", "result", "=", "[", "]", "\n", "timesteps", "=", "0", "\n", "for", "data", "in", "datas", ":", "\n", "      ", "result", ".", "append", "(", "[", "timesteps", ",", "data", "[", "-", "1", "]", "]", ")", "\n", "timesteps", "=", "data", "[", "0", "]", "\n", "\n", "", "x", ",", "y", "=", "np", ".", "array", "(", "result", ")", "[", ":", ",", "0", "]", ",", "np", ".", "array", "(", "result", ")", "[", ":", ",", "1", "]", "\n", "\n", "if", "smooth", "==", "1", ":", "\n", "      ", "x", ",", "y", "=", "smooth_reward_curve", "(", "x", ",", "y", ")", "\n", "\n", "", "if", "smooth", "==", "2", ":", "\n", "      ", "y", "=", "medfilt", "(", "y", ",", "kernel_size", "=", "9", ")", "\n", "\n", "", "x", ",", "y", "=", "fix_point", "(", "x", ",", "y", ",", "bin_size", ")", "\n", "return", "[", "x", ",", "y", "]", "\n", "\n", "# if goal:", "\n", "#   return list(zip(*tuple([process_data(data_goal[goal]) for data_goal in datas_goal])))", "\n", "\n", "# else:", "\n", "\n", "", "return", "list", "(", "zip", "(", "*", "(", "process_data", "(", "data", ")", "for", "data", "in", "datas", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_tensorboard.load": [[85, 114], ["sorted", "glob.glob", "plot_tensorboard.load_data", "result.append", "os.path.join", "os.path.isdir", "d.strip().split", "len", "min", "range", "numpy.mean", "numpy.mean", "numpy.std", "numpy.array().reshape", "numpy.array().reshape", "numpy.zeros", "len", "numpy.array", "numpy.array", "numpy.array", "len", "d.strip", "len", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.load_data", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "load", "(", "indir", ",", "smooth", ",", "bin_size", ")", ":", "\n", "  ", "result", "=", "[", "]", "\n", "\n", "for", "d", "in", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "indir", ",", "'*'", ")", ")", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "isdir", "(", "d", ")", ":", "\n", "      ", "continue", "\n", "", "tmpx", ",", "tmpy", "=", "[", "]", ",", "[", "]", "\n", "label", "=", "d", ".", "strip", "(", "'/'", ")", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "\n", "tx", ",", "ty", "=", "load_data", "(", "d", ",", "smooth", ",", "bin_size", ")", "\n", "tmpx", "+=", "tx", "\n", "tmpy", "+=", "ty", "\n", "\n", "if", "len", "(", "tmpx", ")", ">", "1", ":", "\n", "      ", "length", "=", "min", "(", "[", "len", "(", "t", ")", "for", "t", "in", "tmpx", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tmpx", ")", ")", ":", "\n", "        ", "tmpx", "[", "i", "]", "=", "tmpx", "[", "i", "]", "[", ":", "length", "]", "\n", "tmpy", "[", "i", "]", "=", "tmpy", "[", "i", "]", "[", ":", "length", "]", "\n", "\n", "", "x", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "tmpx", ")", ",", "axis", "=", "0", ")", "\n", "y_mean", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "tmpy", ")", ",", "axis", "=", "0", ")", "\n", "y_std", "=", "np", ".", "std", "(", "np", ".", "array", "(", "tmpy", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "tmpx", ")", ".", "reshape", "(", "-", "1", ")", "\n", "y_mean", "=", "np", ".", "array", "(", "tmpy", ")", ".", "reshape", "(", "-", "1", ")", "\n", "y_std", "=", "np", ".", "zeros", "(", "len", "(", "y_mean", ")", ")", "\n", "\n", "", "result", ".", "append", "(", "[", "label", ",", "x", ",", "y_mean", ",", "y_std", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.plot_tensorboard.plot": [[154, 207], ["matplotlib.figure", "seaborn.despine", "plot_tensorboard.load", "enumerate", "hasattr", "matplotlib.xticks", "matplotlib.ylim", "matplotlib.xlim", "matplotlib.legend", "matplotlib.title", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.show", "matplotlib.draw", "numpy.sum", "lines.append", "matplotlib.yticks", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.fill_between", "matplotlib.plot", "matplotlib.plot", "max", "max", "list", "list", "list", "list"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot"], ["def", "plot", "(", "args", ")", ":", "\n", "  ", "plt", ".", "figure", "(", "figsize", "=", "(", "4", ",", "3.5", ")", ",", "dpi", "=", "200", ")", "\n", "sns", ".", "despine", "(", "left", "=", "True", ",", "bottom", "=", "True", ")", "\n", "datas", "=", "load", "(", "args", ".", "source", ",", "args", ".", "smooth", ",", "args", ".", "bin_size", ")", "\n", "lines", "=", "[", "]", "\n", "max_y", "=", "args", ".", "max_y", "\n", "min_y", "=", "args", ".", "min_y", "\n", "max_x", "=", "args", ".", "max_x", "\n", "min_x", "=", "1e10", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "datas", ")", ":", "\n", "    ", "label", ",", "x", ",", "y_mean", ",", "y_std", "=", "data", "\n", "color", "=", "COLORS", "[", "i", "]", "\n", "if", "np", ".", "sum", "(", "y_std", ")", ":", "\n", "      ", "y_upper", "=", "y_mean", "+", "y_std", "\n", "y_lower", "=", "y_mean", "-", "y_std", "\n", "plt", ".", "fill_between", "(", "\n", "x", ",", "list", "(", "y_lower", ")", ",", "list", "(", "y_upper", ")", ",", "interpolate", "=", "True", ",", "facecolor", "=", "color", ",", "linewidth", "=", "0.0", ",", "alpha", "=", "0.3", "\n", ")", "\n", "", "if", "args", ".", "line_styles", "is", "not", "None", ":", "\n", "      ", "linestyle", "=", "args", ".", "line_styles", "[", "i", "]", "\n", "#if i % 2 == 1:", "\n", "#  line = plt.plot(x, list(y_mean), linewidth=1.0, label=label, color=color, markersize=8.0, marker=\"*\", markevery=int(max_x/500), linestyle=linestyle)", "\n", "#else:", "\n", "line", "=", "plt", ".", "plot", "(", "x", ",", "list", "(", "y_mean", ")", ",", "linewidth", "=", "1.0", ",", "label", "=", "label", ",", "color", "=", "color", ",", "linestyle", "=", "linestyle", ")", "\n", "", "else", ":", "\n", "      ", "line", "=", "plt", ".", "plot", "(", "x", ",", "list", "(", "y_mean", ")", ",", "label", "=", "label", ",", "color", "=", "color", ")", "\n", "", "lines", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "if", "max", "(", "x", ")", "<", "min_x", ":", "\n", "      ", "min_x", "=", "max", "(", "x", ")", "\n", "\n", "", "", "if", "hasattr", "(", "args", ",", "'y_values'", ")", ":", "\n", "    ", "plt", ".", "yticks", "(", "args", ".", "y_values", ",", "args", ".", "y_labels", ")", "\n", "\n", "", "plt", ".", "xticks", "(", "args", ".", "x_values", ",", "args", ".", "x_labels", ")", "\n", "if", "args", ".", "xlabel", "is", "None", ":", "\n", "    ", "plt", ".", "xlabel", "(", "'Epoch'", ")", "\n", "", "else", ":", "\n", "    ", "plt", ".", "xlabel", "(", "args", ".", "xlabel", ")", "\n", "\n", "", "if", "args", ".", "ylabel", "is", "None", ":", "\n", "    ", "plt", ".", "ylabel", "(", "'Success Rate'", ")", "\n", "", "else", ":", "\n", "    ", "plt", ".", "ylabel", "(", "args", ".", "ylabel", ")", "\n", "\n", "", "plt", ".", "ylim", "(", "min_y", ",", "max_y", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "max_x", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "args", ".", "legend_loc", ",", "prop", "=", "{", "'size'", ":", "args", ".", "legend_size", "}", ")", "\n", "plt", ".", "title", "(", "args", ".", "title", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "0.0", ")", "# Make room for the xlabel", "\n", "plt", ".", "savefig", "(", "args", ".", "output", ",", "format", "=", "'pdf'", ",", "dpi", "=", "100", ")", "# Need to do savefig before plt.show() otherwise PDF file will be blank", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "draw", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.results.exportTB.exitWithUsage": [[37, 47], ["print", "print", "print", "print", "print", "print", "print", "print", "sys.exit"], "function", ["None"], ["", "def", "exitWithUsage", "(", ")", ":", "\n", "\t", "print", "(", "' '", ")", "\n", "print", "(", "'Usage:'", ")", "\n", "print", "(", "'   python exportTB.py <output-folder> <output-path-to-csv> <summaries>'", ")", "\n", "print", "(", "'Inputs:'", ")", "\n", "print", "(", "'   <logfolder>              - Path to log folder.'", ")", "\n", "print", "(", "'   <output-folder>          - Path to output folder.'", ")", "\n", "print", "(", "'   <tags>                   - Comma separated list of tags to save'", ")", "\n", "print", "(", "' '", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.AttrDict.__getattr__": [[21, 26], ["dict.__getitem__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__getitem__"], ["def", "__getattr__", "(", "self", ",", "key", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "return", "dict", ".", "__getitem__", "(", "self", ",", "key", ")", "\n", "", "except", "KeyError", ":", "\n", "      ", "raise", "AttributeError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.smooth_reward_curve": [[27, 34], ["int", "numpy.ceil", "numpy.convolve", "numpy.convolve", "numpy.ones", "numpy.ones_like", "numpy.ones", "len"], "function", ["None"], ["", "", "", "def", "smooth_reward_curve", "(", "x", ",", "y", ")", ":", "\n", "   ", "halfwidth", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "x", ")", "/", "60", ")", ")", "# Halfwidth of our smoothing convolution", "\n", "k", "=", "halfwidth", "\n", "xsmoo", "=", "x", "\n", "ysmoo", "=", "np", ".", "convolve", "(", "y", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "mode", "=", "'same'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "\n", "mode", "=", "'same'", ")", "\n", "return", "xsmoo", ",", "ysmoo", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.fix_point": [[35, 57], ["numpy.insert", "numpy.insert", "int", "range", "len", "fx.append", "fy.append", "max", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "fix_point", "(", "x", ",", "y", ",", "interval", ")", ":", "\n", "  ", "\"\"\"What does this do?\"\"\"", "\n", "np", ".", "insert", "(", "x", ",", "0", ",", "0", ")", "\n", "np", ".", "insert", "(", "y", ",", "0", ",", "0", ")", "\n", "\n", "fx", ",", "fy", "=", "[", "]", ",", "[", "]", "\n", "pointer", "=", "0", "\n", "ninterval", "=", "int", "(", "max", "(", "x", ")", "/", "interval", "+", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "ninterval", ")", ":", "\n", "    ", "tmpx", "=", "interval", "*", "i", "\n", "\n", "while", "pointer", "+", "1", "<", "len", "(", "x", ")", "and", "tmpx", ">", "x", "[", "pointer", "+", "1", "]", ":", "\n", "      ", "pointer", "+=", "1", "\n", "\n", "", "if", "pointer", "+", "1", "<", "len", "(", "x", ")", ":", "\n", "      ", "alpha", "=", "(", "y", "[", "pointer", "+", "1", "]", "-", "y", "[", "pointer", "]", ")", "/", "(", "x", "[", "pointer", "+", "1", "]", "-", "x", "[", "pointer", "]", ")", "\n", "tmpy", "=", "y", "[", "pointer", "]", "+", "alpha", "*", "(", "tmpx", "-", "x", "[", "pointer", "]", ")", "\n", "fx", ".", "append", "(", "tmpx", ")", "\n", "fy", ".", "append", "(", "tmpy", ")", "\n", "\n", "", "", "return", "fx", ",", "fy", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.load_data": [[58, 95], ["glob.glob", "list", "os.path.join", "numpy.loadtxt", "zip", "sorted.append", "sorted", "plot_bulk.fix_point", "zip", "data.append", "result.append", "plot_bulk.smooth_reward_curve", "scipy.signal.medfilt", "numpy.array", "numpy.array", "plot_bulk.load_data.process_data"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.fix_point", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.smooth_reward_curve"], ["", "def", "load_data", "(", "indir", ",", "smooth", ",", "bin_size", ")", ":", "\n", "  ", "datas", "=", "[", "]", "\n", "infiles", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "indir", ",", "'*.csv'", ")", ")", "\n", "# datas_goal = []", "\n", "\n", "for", "inf", "in", "infiles", ":", "\n", "    ", "data", "=", "[", "]", "\n", "data_csv", "=", "np", ".", "loadtxt", "(", "inf", ",", "delimiter", "=", "\",\"", ",", "skiprows", "=", "1", ",", "usecols", "=", "[", "1", ",", "2", "]", ")", "\n", "for", "sec", ",", "acc", "in", "zip", "(", "data_csv", "[", ":", ",", "0", "]", ",", "data_csv", "[", ":", ",", "1", "]", ")", ":", "\n", "      ", "data", ".", "append", "(", "[", "sec", ",", "acc", "]", ")", "\n", "", "datas", ".", "append", "(", "data", ")", "\n", "\n", "", "def", "process_data", "(", "datas", ")", ":", "\n", "    ", "datas", "=", "sorted", "(", "datas", ",", "key", "=", "lambda", "d_entry", ":", "d_entry", "[", "0", "]", ")", "\n", "result", "=", "[", "]", "\n", "timesteps", "=", "0", "\n", "for", "data", "in", "datas", ":", "\n", "      ", "result", ".", "append", "(", "[", "timesteps", ",", "data", "[", "-", "1", "]", "]", ")", "\n", "timesteps", "=", "data", "[", "0", "]", "\n", "\n", "", "x", ",", "y", "=", "np", ".", "array", "(", "result", ")", "[", ":", ",", "0", "]", ",", "np", ".", "array", "(", "result", ")", "[", ":", ",", "1", "]", "\n", "\n", "if", "smooth", "==", "1", ":", "\n", "      ", "x", ",", "y", "=", "smooth_reward_curve", "(", "x", ",", "y", ")", "\n", "\n", "", "if", "smooth", "==", "2", ":", "\n", "      ", "y", "=", "medfilt", "(", "y", ",", "kernel_size", "=", "9", ")", "\n", "\n", "", "x", ",", "y", "=", "fix_point", "(", "x", ",", "y", ",", "bin_size", ")", "\n", "return", "[", "x", ",", "y", "]", "\n", "\n", "# if goal:", "\n", "#   return list(zip(*tuple([process_data(data_goal[goal]) for data_goal in datas_goal])))", "\n", "\n", "# else:", "\n", "\n", "", "return", "list", "(", "zip", "(", "*", "(", "process_data", "(", "data", ")", "for", "data", "in", "datas", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.load": [[96, 123], ["zip", "os.path.join", "plot_bulk.load_data", "result.append", "len", "min", "range", "numpy.mean", "numpy.mean", "numpy.std", "numpy.array().reshape", "numpy.array().reshape", "numpy.zeros", "len", "numpy.array", "numpy.array", "numpy.array", "len", "len", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.load_data", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "load", "(", "indir", ",", "names", ",", "labels", ",", "smooth", ",", "bin_size", ")", ":", "\n", "  ", "result", "=", "[", "]", "\n", "\n", "for", "name", ",", "label", "in", "zip", "(", "names", ",", "labels", ")", ":", "\n", "    ", "d", "=", "os", ".", "path", ".", "join", "(", "indir", ",", "name", ")", "\n", "tmpx", ",", "tmpy", "=", "[", "]", ",", "[", "]", "\n", "\n", "tx", ",", "ty", "=", "load_data", "(", "d", ",", "smooth", ",", "bin_size", ")", "\n", "tmpx", "+=", "tx", "\n", "tmpy", "+=", "ty", "\n", "\n", "if", "len", "(", "tmpx", ")", ">", "1", ":", "\n", "      ", "length", "=", "min", "(", "[", "len", "(", "t", ")", "for", "t", "in", "tmpx", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tmpx", ")", ")", ":", "\n", "        ", "tmpx", "[", "i", "]", "=", "tmpx", "[", "i", "]", "[", ":", "length", "]", "\n", "tmpy", "[", "i", "]", "=", "tmpy", "[", "i", "]", "[", ":", "length", "]", "\n", "\n", "", "x", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "tmpx", ")", ",", "axis", "=", "0", ")", "\n", "y_mean", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "tmpy", ")", ",", "axis", "=", "0", ")", "\n", "y_std", "=", "np", ".", "std", "(", "np", ".", "array", "(", "tmpy", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "      ", "x", "=", "np", ".", "array", "(", "tmpx", ")", ".", "reshape", "(", "-", "1", ")", "\n", "y_mean", "=", "np", ".", "array", "(", "tmpy", ")", ".", "reshape", "(", "-", "1", ")", "\n", "y_std", "=", "np", ".", "zeros", "(", "len", "(", "y_mean", ")", ")", "\n", "\n", "", "result", ".", "append", "(", "[", "label", ",", "x", ",", "y_mean", ",", "y_std", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.example.plot_bulk.plot": [[125, 185], ["matplotlib.figure", "seaborn.despine", "plot_bulk.load", "enumerate", "numpy.arange", "matplotlib.xticks", "hasattr", "matplotlib.ylim", "matplotlib.xlim", "matplotlib.legend", "matplotlib.title", "matplotlib.tight_layout", "matplotlib.savefig", "print", "numpy.sum", "int", "matplotlib.plot", "lines.append", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.yticks", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.fill_between", "list", "max", "max", "ignore_even", "list", "list", "enumerate", "ignore_even", "enumerate", "float", "float"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "plot", "(", "args", ")", ":", "\n", "  ", "plt", ".", "figure", "(", "figsize", "=", "(", "4", ",", "3", ")", ",", "dpi", "=", "300", ")", "\n", "sns", ".", "despine", "(", "left", "=", "True", ",", "bottom", "=", "True", ")", "\n", "datas", "=", "load", "(", "args", ".", "source", ",", "args", ".", "names", ",", "args", ".", "labels", ",", "args", ".", "smooth", ",", "args", ".", "bin_size", ")", "\n", "for", "ignore_string", "in", "args", ".", "ignore_strings", ":", "\n", "    ", "datas", "=", "[", "d", "for", "d", "in", "datas", "if", "not", "ignore_string", "in", "d", "[", "0", "]", "]", "\n", "", "lines", "=", "[", "]", "\n", "max_y", "=", "args", ".", "max_y", "\n", "min_y", "=", "args", ".", "min_y", "\n", "max_x", "=", "args", ".", "max_x", "\n", "min_x", "=", "1e10", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "datas", ")", ":", "\n", "    ", "label", ",", "x", ",", "y_mean", ",", "y_std", "=", "data", "\n", "color", "=", "args", ".", "colors", "[", "i", "]", "\n", "if", "np", ".", "sum", "(", "y_std", ")", ":", "\n", "      ", "y_upper", "=", "y_mean", "+", "y_std", "\n", "y_lower", "=", "y_mean", "-", "y_std", "\n", "plt", ".", "fill_between", "(", "\n", "x", ",", "list", "(", "y_lower", ")", ",", "list", "(", "y_upper", ")", ",", "interpolate", "=", "True", ",", "facecolor", "=", "color", ",", "linewidth", "=", "0.0", ",", "alpha", "=", "0.2", "\n", ")", "\n", "", "linestyle", "=", "args", ".", "line_styles", "[", "i", "]", "\n", "marker", "=", "args", ".", "markers", "[", "i", "]", "\n", "markersize", "=", "args", ".", "markersizes", "[", "i", "]", "\n", "markevery", "=", "int", "(", "max_x", "/", "500", ")", "\n", "line", "=", "plt", ".", "plot", "(", "x", ",", "list", "(", "y_mean", ")", ",", "linewidth", "=", "2.0", ",", "label", "=", "label", ",", "color", "=", "color", ",", "markersize", "=", "markersize", ",", "marker", "=", "marker", ",", "markevery", "=", "markevery", ",", "linestyle", "=", "linestyle", ")", "\n", "lines", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "if", "max", "(", "x", ")", "<", "min_x", ":", "\n", "      ", "min_x", "=", "max", "(", "x", ")", "\n", "\n", "\n", "", "", "xticks", "=", "np", ".", "arange", "(", "0", ",", "max_x", "+", "1", ",", "max_x", "//", "8", ")", "\n", "ignore_even", "=", "lambda", "s", ",", "i", ":", "s", "if", "i", "%", "2", "==", "0", "else", "''", "\n", "if", "'Millions'", "in", "args", ".", "xlabel", ":", "\n", "    ", "xlabels", "=", "[", "ignore_even", "(", "'{:0.2f}'", ".", "format", "(", "float", "(", "x", ")", "/", "100000000.", "*", "args", ".", "time_steps_per_episode", ")", ".", "rstrip", "(", "'0'", ")", ".", "rstrip", "(", "'.'", ")", ",", "\n", "i", ")", "for", "i", ",", "x", "in", "enumerate", "(", "xticks", ")", "]", "\n", "", "elif", "'Thousands'", "in", "args", ".", "xlabel", ":", "\n", "    ", "xlabels", "=", "[", "ignore_even", "(", "'{:0.2f}'", ".", "format", "(", "float", "(", "x", ")", "/", "100000.", "*", "args", ".", "time_steps_per_episode", ")", ".", "rstrip", "(", "'0'", ")", ".", "rstrip", "(", "'.'", ")", ",", "\n", "i", ")", "for", "i", ",", "x", "in", "enumerate", "(", "xticks", ")", "]", "\n", "#xlabels[-1] += 'M'", "\n", "", "plt", ".", "xticks", "(", "xticks", ",", "xlabels", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "if", "args", ".", "xlabel", "is", "None", ":", "\n", "    ", "plt", ".", "xlabel", "(", "'Placeholder'", ",", "fontsize", "=", "args", ".", "label_size", ",", "color", "=", "'white'", ")", "\n", "", "else", ":", "\n", "    ", "plt", ".", "xlabel", "(", "args", ".", "xlabel", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "\n", "", "if", "hasattr", "(", "args", ",", "'y_values'", ")", ":", "\n", "    ", "plt", ".", "yticks", "(", "args", ".", "y_values", ",", "args", ".", "y_labels", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "", "if", "args", ".", "ylabel", "is", "None", ":", "\n", "    ", "plt", ".", "ylabel", "(", "''", ")", "\n", "", "else", ":", "\n", "    ", "plt", ".", "ylabel", "(", "args", ".", "ylabel", ",", "fontsize", "=", "args", ".", "label_size", ")", "\n", "\n", "", "plt", ".", "ylim", "(", "min_y", ",", "max_y", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "max_x", ")", "\n", "plt", ".", "legend", "(", "fancybox", "=", "True", ",", "framealpha", "=", "0.7", ",", "loc", "=", "args", ".", "legend_loc", ",", "fontsize", "=", "args", ".", "legend_size", ",", "frameon", "=", "True", ",", "facecolor", "=", "'white'", ",", "borderaxespad", "=", "1.", ")", "\n", "plt", ".", "title", "(", "args", ".", "title", ",", "fontsize", "=", "args", ".", "title_size", ")", "\n", "plt", ".", "tight_layout", "(", "pad", "=", "0.0", ")", "# Make room for the xlabel", "\n", "plt", ".", "savefig", "(", "args", ".", "output", ",", "format", "=", "'png'", ",", "dpi", "=", "600", ")", "# Need to do savefig before plt.show() otherwise PDF file will be blank", "\n", "print", "(", "\"DONE {}\"", ".", "format", "(", "args", ".", "output", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.experiments.train.main": [[12, 196], ["merge_args_into_config", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_interop_threads", "torch.set_num_interop_threads", "make_agent_name", "experiments.mega.make_env.make_env", "EnvModule", "EnvModule", "config.update", "ContinuousActionNoise", "mrl.config_to_agent", "max", "min", "min", "args.env.lower", "GoalEnvAchieved", "dict", "RawKernelDensity", "RawKernelDensity", "RawKernelDensity", "args.noise_type.lower", "args.noise_type.lower", "args.alg.lower", "DDPG", "args.alg.lower", "PytorchModel", "PytorchModel", "PytorchModel", "GoalEnvReward", "os.path.exists", "print", "mrl.config_to_agent.load", "numpy.mean", "mrl.config_to_agent.logger.log_color", "range", "numpy.round", "numpy.round", "args.alg.lower", "FirstVisitDoneWrapper", "FirstVisitDoneWrapper", "args.env.lower", "CuriosityAlphaMixtureModule", "DensityAchievedGoalCuriosity", "ConstantSchedule", "args.alg.lower", "TD3", "args.alg.lower", "PytorchModel", "args.alg.lower", "PytorchModel", "StochasticActorPolicy", "NeighborReward", "PytorchModel", "ValueError", "os.path.join", "mrl.config_to_agent.load_from_checkpoint", "mrl.config_to_agent.eval_mode", "mrl.config_to_agent.train", "mrl.config_to_agent.eval_mode", "range", "int", "time.time", "mrl.config_to_agent.train", "numpy.mean", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.logger.log_color", "print", "mrl.config_to_agent.save", "mp.cpu_count", "env1", "eval_env1", "StandardTrain", "EpisodicEval", "ActorPolicy", "Logger", "Normalizer", "OnlineHERBuffer", "args.alg.lower", "SAC", "Critic", "Actor", "Critic", "print", "env.reset", "env.render", "mrl.config_to_agent.eval", "numpy.random.choice", "numpy.arange", "mrl.config_to_agent.logger.add_embedding", "mrl.config_to_agent.logger.add_embedding", "mrl.config_to_agent.logger.add_embedding", "mrl.config_to_agent.save_checkpoint", "MeanStdNormalizer", "args.alg.lower", "DQN", "QValuePolicy", "LinearSchedule", "FCBody", "FCBody", "FCBody", "Critic", "StochasticActor", "FCBody", "time.sleep", "mrl.config_to_agent.policy", "env.step", "env.render", "print", "len", "max", "len", "ag_buffer.get_batch", "ag_buffer.get_batch", "bg_buffer.get_batch", "mrl.config_to_agent.eval", "make_activ", "make_activ", "make_activ", "FCBody", "FCBody", "min", "time.time", "make_activ", "make_activ", "len", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.merge_args_into_config", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_agent_name", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.load_from_checkpoint", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.save_checkpoint", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "# 4. Update the config with args, and make the agent name. ", "\n", "  ", "if", "args", ".", "num_envs", "is", "None", ":", "\n", "    ", "import", "multiprocessing", "as", "mp", "\n", "args", ".", "num_envs", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "1", ")", "\n", "", "merge_args_into_config", "(", "args", ",", "config", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "8", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "8", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "if", "config", ".", "gamma", "<", "1.", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "(", "1", "/", "(", "1", "-", "config", ".", "gamma", ")", ")", ",", "2", ")", ",", "0.", ")", "\n", "if", "config", ".", "gamma", "==", "1", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "args", ".", "env_max_step", "-", "5", ",", "2", ")", ",", "0.", ")", "\n", "if", "args", ".", "sparse_reward_shaping", "or", "'sac'", "in", "args", ".", "alg", ".", "lower", "(", ")", ":", "\n", "    ", "config", ".", "clip_target_range", "=", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ")", "\n", "\n", "", "config", ".", "agent_name", "=", "make_agent_name", "(", "config", ",", "[", "'env'", ",", "'alg'", ",", "'tb'", ",", "'seed'", "]", ",", "prefix", "=", "args", ".", "prefix", ")", "\n", "\n", "# 6. Setup environments & add them to config, so modules can refer to them if need be", "\n", "env", ",", "eval_env", "=", "make_env", "(", "args", ")", "\n", "if", "args", ".", "first_visit_done", ":", "\n", "    ", "env1", ",", "eval_env1", "=", "env", ",", "eval_env", "\n", "env", "=", "lambda", ":", "FirstVisitDoneWrapper", "(", "env1", "(", ")", ")", "# Terminates the training episode on \"done\"", "\n", "eval_env", "=", "lambda", ":", "FirstVisitDoneWrapper", "(", "eval_env1", "(", ")", ")", "\n", "", "if", "args", ".", "first_visit_succ", ":", "\n", "    ", "config", ".", "first_visit_succ", "=", "True", "# Continues the training episode on \"done\", but counts it as if \"done\" (gamma = 0)", "\n", "", "if", "'dictpush'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "config", ".", "modalities", "=", "[", "'gripper'", ",", "'object'", ",", "'relative'", "]", "\n", "if", "'reach'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "      ", "config", ".", "goal_modalities", "=", "[", "'gripper_goal'", ",", "'object_goal'", "]", "\n", "", "else", ":", "\n", "      ", "config", ".", "goal_modalities", "=", "[", "'desired_goal'", "]", "\n", "", "config", ".", "achieved_goal", "=", "GoalEnvAchieved", "(", ")", "\n", "", "config", ".", "train_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "args", ".", "num_envs", ",", "seed", "=", "args", ".", "seed", ",", "modalities", "=", "config", ".", "modalities", ",", "goal_modalities", "=", "config", ".", "goal_modalities", ")", "\n", "config", ".", "eval_env", "=", "EnvModule", "(", "eval_env", ",", "num_envs", "=", "args", ".", "num_eval_envs", ",", "name", "=", "'eval_env'", ",", "seed", "=", "args", ".", "seed", "+", "1138", ",", "modalities", "=", "config", ".", "modalities", ",", "goal_modalities", "=", "config", ".", "goal_modalities", ")", "\n", "\n", "# 7. Setup / add modules to the config", "\n", "\n", "# Base Modules", "\n", "config", ".", "update", "(", "\n", "dict", "(", "\n", "trainer", "=", "StandardTrain", "(", ")", ",", "\n", "evaluation", "=", "EpisodicEval", "(", ")", ",", "\n", "policy", "=", "ActorPolicy", "(", ")", ",", "\n", "logger", "=", "Logger", "(", ")", ",", "\n", "state_normalizer", "=", "Normalizer", "(", "MeanStdNormalizer", "(", ")", ")", ",", "\n", "replay", "=", "OnlineHERBuffer", "(", ")", ",", "\n", ")", ")", "\n", "\n", "# Goal Selection Modules", "\n", "if", "args", ".", "ag_curiosity", "is", "not", "None", ":", "\n", "    ", "config", ".", "ag_kde", "=", "RawKernelDensity", "(", "'ag'", ",", "optimize_every", "=", "4", ",", "samples", "=", "2000", ",", "kernel", "=", "args", ".", "kde_kernel", ",", "bandwidth", "=", "args", ".", "bandwidth", ",", "log_entropy", "=", "True", ")", "\n", "config", ".", "dg_kde", "=", "RawKernelDensity", "(", "'dg'", ",", "optimize_every", "=", "500", ",", "samples", "=", "5000", ",", "kernel", "=", "'tophat'", ",", "bandwidth", "=", "0.2", ")", "\n", "config", ".", "ag_kde_tophat", "=", "RawKernelDensity", "(", "'ag'", ",", "optimize_every", "=", "100", ",", "samples", "=", "5000", ",", "kernel", "=", "'tophat'", ",", "bandwidth", "=", "0.2", ",", "tag", "=", "'_tophat'", ")", "\n", "if", "args", ".", "transition_to_dg", ":", "\n", "      ", "config", ".", "alpha_curiosity", "=", "CuriosityAlphaMixtureModule", "(", ")", "\n", "\n", "", "use_qcutoff", "=", "not", "args", ".", "no_cutoff", "\n", "\n", "if", "args", ".", "ag_curiosity", "==", "'minkde'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "\n", "\n", "# Action Noise Modules", "\n", "", "", "if", "args", ".", "noise_type", ".", "lower", "(", ")", "==", "'gaussian'", ":", "noise_type", "=", "GaussianProcess", "\n", "if", "args", ".", "noise_type", ".", "lower", "(", ")", "==", "'ou'", ":", "noise_type", "=", "OrnsteinUhlenbeckProcess", "\n", "config", ".", "action_noise", "=", "ContinuousActionNoise", "(", "noise_type", ",", "std", "=", "ConstantSchedule", "(", "args", ".", "action_noise", ")", ")", "\n", "\n", "# Algorithm Modules", "\n", "if", "args", ".", "alg", ".", "lower", "(", ")", "==", "'ddpg'", ":", "\n", "    ", "config", ".", "algorithm", "=", "DDPG", "(", ")", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'td3'", ":", "\n", "    ", "config", ".", "algorithm", "=", "TD3", "(", ")", "\n", "config", ".", "target_network_update_freq", "*=", "2", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'sac'", ":", "\n", "    ", "config", ".", "algorithm", "=", "SAC", "(", ")", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'dqn'", ":", "\n", "    ", "config", ".", "algorithm", "=", "DQN", "(", ")", "\n", "config", ".", "policy", "=", "QValuePolicy", "(", ")", "\n", "config", ".", "qvalue_lr", "=", "config", ".", "critic_lr", "\n", "config", ".", "qvalue_weight_decay", "=", "config", ".", "actor_weight_decay", "\n", "config", ".", "double_q", "=", "True", "\n", "config", ".", "random_action_prob", "=", "LinearSchedule", "(", "1.0", ",", "config", ".", "eexplore", ",", "1e5", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n", "# 7. Actor/Critic Networks", "\n", "", "e", "=", "config", ".", "eval_env", "\n", "if", "args", ".", "alg", ".", "lower", "(", ")", "==", "'dqn'", ":", "\n", "    ", "config", ".", "qvalue", "=", "PytorchModel", "(", "'qvalue'", ",", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "Identity", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "e", ".", "action_dim", ")", ")", "\n", "", "else", ":", "\n", "    ", "config", ".", "actor", "=", "PytorchModel", "(", "'actor'", ",", "\n", "lambda", ":", "Actor", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "Identity", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "e", ".", "action_dim", ",", "e", ".", "max_action", ")", ")", "\n", "config", ".", "critic", "=", "PytorchModel", "(", "'critic'", ",", "\n", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "nn", ".", "Identity", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "1", ")", ")", "\n", "if", "args", ".", "alg", ".", "lower", "(", ")", "in", "[", "'td3'", ",", "'sac'", "]", ":", "\n", "      ", "config", ".", "critic2", "=", "PytorchModel", "(", "'critic2'", ",", "\n", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "nn", ".", "Identity", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "1", ")", ")", "\n", "", "if", "args", ".", "alg", ".", "lower", "(", ")", "==", "'sac'", ":", "\n", "      ", "del", "config", ".", "actor", "\n", "config", ".", "actor", "=", "PytorchModel", "(", "'actor'", ",", "lambda", ":", "StochasticActor", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "Identity", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "\n", "e", ".", "action_dim", ",", "e", ".", "max_action", ",", "log_std_bounds", "=", "(", "-", "20", ",", "2", ")", ")", ")", "\n", "del", "config", ".", "policy", "\n", "config", ".", "policy", "=", "StochasticActorPolicy", "(", ")", "\n", "\n", "# 8. Reward modules", "\n", "", "", "if", "args", ".", "reward_module", "==", "'env'", ":", "\n", "    ", "config", ".", "goal_reward", "=", "GoalEnvReward", "(", ")", "\n", "", "elif", "args", ".", "reward_module", "==", "'intrinsic'", ":", "\n", "    ", "config", ".", "goal_reward", "=", "NeighborReward", "(", ")", "\n", "config", ".", "neighbor_embedding_network", "=", "PytorchModel", "(", "'neighbor_embedding_network'", ",", "lambda", ":", "FCBody", "(", "e", ".", "goal_dim", ",", "(", "256", ",", "256", ")", ")", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unsupported reward module: {}'", ".", "format", "(", "args", ".", "reward_module", ")", ")", "\n", "\n", "", "if", "config", ".", "eval_env", ".", "goal_env", ":", "\n", "    ", "if", "not", "(", "args", ".", "first_visit_done", "or", "args", ".", "first_visit_succ", ")", ":", "\n", "      ", "config", ".", "never_done", "=", "True", "# NOTE: This is important in the standard Goal environments, which are never done", "\n", "\n", "# 9. Make the agent", "\n", "", "", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "if", "args", ".", "checkpoint_dir", "is", "not", "None", ":", "\n", "# If a checkpoint has been initialized load it.", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "'INITIALIZED'", ")", ")", ":", "\n", "      ", "agent", ".", "load_from_checkpoint", "(", "args", ".", "checkpoint_dir", ")", "\n", "\n", "# 10.A Vizualize a trained agent", "\n", "", "", "if", "args", ".", "visualize_trained_agent", ":", "\n", "    ", "print", "(", "\"Loading agent at epoch {}\"", ".", "format", "(", "0", ")", ")", "\n", "agent", ".", "load", "(", "'checkpoint'", ")", "\n", "\n", "if", "args", ".", "intrinsic_visualization", ":", "\n", "      ", "agent", ".", "eval_mode", "(", ")", "\n", "agent", ".", "train", "(", "10000", ",", "render", "=", "True", ",", "dont_optimize", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "      ", "agent", ".", "eval_mode", "(", ")", "\n", "env", "=", "agent", ".", "eval_env", "\n", "\n", "for", "_", "in", "range", "(", "10000", ")", ":", "\n", "        ", "print", "(", "\"NEW EPISODE\"", ")", "\n", "state", "=", "env", ".", "reset", "(", ")", "\n", "env", ".", "render", "(", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "          ", "time", ".", "sleep", "(", "0.02", ")", "\n", "action", "=", "agent", ".", "policy", "(", "state", ")", "\n", "state", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "env", ".", "render", "(", ")", "\n", "print", "(", "reward", "[", "0", "]", ")", "\n", "\n", "# 10.B Or run the training loop", "\n", "", "", "", "", "else", ":", "\n", "    ", "ag_buffer", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "bg_buffer", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_bg", "\n", "\n", "# EVALUATE", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "30", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Initial test reward (30 eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "      ", "t", "=", "time", ".", "time", "(", ")", "\n", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ")", "\n", "\n", "# VIZUALIZE GOALS", "\n", "if", "args", ".", "save_embeddings", ":", "\n", "        ", "sample_idxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "ag_buffer", ")", ",", "size", "=", "min", "(", "len", "(", "ag_buffer", ")", ",", "args", ".", "epoch_len", ")", ",", "replace", "=", "False", ")", "\n", "last_idxs", "=", "np", ".", "arange", "(", "max", "(", "0", ",", "len", "(", "ag_buffer", ")", "-", "args", ".", "epoch_len", ")", ",", "len", "(", "ag_buffer", ")", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'rand_ags'", ",", "ag_buffer", ".", "get_batch", "(", "sample_idxs", ")", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'last_ags'", ",", "ag_buffer", ".", "get_batch", "(", "last_idxs", ")", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'last_bgs'", ",", "bg_buffer", ".", "get_batch", "(", "last_idxs", ")", ")", "\n", "\n", "# EVALUATE", "\n", "", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "30", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Test reward (30 eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n", "print", "(", "\"Saving agent at epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "agent", ".", "save", "(", "'checkpoint'", ")", "\n", "\n", "# Also save to checkpoint if a checkpoint_dir is specified.", "\n", "if", "args", ".", "checkpoint_dir", "is", "not", "None", ":", "\n", "        ", "agent", ".", "save_checkpoint", "(", "args", ".", "checkpoint_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.benchmarks.train_mujoco.main": [[14, 40], ["OldReplayBuffer", "torch.set_num_threads", "torch.set_num_interop_threads", "mrl.config_to_agent", "max", "numpy.mean", "mrl.config_to_agent.logger.log_color", "range", "min", "min", "int", "time.time", "mrl.config_to_agent.train", "numpy.mean", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.logger.log_color", "print", "mrl.config_to_agent.save", "mrl.config_to_agent.eval", "mrl.config_to_agent.eval", "time.time"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save"], ["def", "main", "(", "config", ",", "args", ")", ":", "\n", "\n", "# use the old replay buffer, since it adds experience to buffer immediately and don't need HER", "\n", "  ", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "OldReplayBuffer", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "num_eps", "=", "max", "(", "args", ".", "num_eval_envs", "*", "3", ",", "10", ")", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "f'Initial test reward ({num_eps} eps):'", ",", "f'{res:.2f}'", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "    ", "t", "=", "time", ".", "time", "(", ")", "\n", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ")", "\n", "\n", "# EVALUATE", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "f'Test reward ({num_eps} eps):'", ",", "f'{res:.2f}'", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n", "print", "(", "f\"Saving agent at epoch {epoch}\"", ")", "\n", "agent", ".", "save", "(", "'checkpoint'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.benchmarks.train_her.main": [[17, 78], ["merge_args_into_config", "make_agent_name", "config.update", "torch.set_num_threads", "torch.set_num_interop_threads", "EnvModule", "EnvModule", "PytorchModel", "PytorchModel", "mrl.config_to_agent", "max", "numpy.mean", "mrl.config_to_agent.logger.log_color", "range", "max", "dict", "min", "min", "gym.envs.registry.env_specs.get", "gym.make", "int", "time.time", "mrl.config_to_agent.train", "numpy.mean", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.logger.log_color", "print", "mrl.config_to_agent.save", "numpy.round", "numpy.round", "Actor", "Critic", "mrl.config_to_agent.eval", "mp.cpu_count", "StandardTrain", "EpisodicEval", "ActorPolicy", "Logger", "Normalizer", "OnlineHERBuffer", "ContinuousActionNoise", "DDPG", "FCBody", "FCBody", "mrl.config_to_agent.eval", "MeanStdNormalizer", "time.time", "ConstantSchedule"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.merge_args_into_config", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_agent_name", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save"], ["def", "main", "(", "args", ")", ":", "\n", "  ", "if", "args", ".", "num_envs", "is", "None", ":", "\n", "    ", "import", "multiprocessing", "as", "mp", "\n", "args", ".", "num_envs", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "1", ")", "\n", "\n", "# hard code num_eval envs...", "\n", "", "args", ".", "num_eval_envs", "=", "args", ".", "num_envs", "\n", "\n", "merge_args_into_config", "(", "args", ",", "config", ")", "\n", "\n", "if", "config", ".", "gamma", "<", "1.", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "(", "1", "/", "(", "1", "-", "config", ".", "gamma", ")", ")", ",", "2", ")", ",", "0.", ")", "\n", "if", "config", ".", "gamma", "==", "1", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "args", ".", "env_max_step", "-", "5", ",", "2", ")", ",", "0.", ")", "\n", "\n", "config", ".", "agent_name", "=", "make_agent_name", "(", "config", ",", "[", "'env'", ",", "'her'", ",", "'seed'", ",", "'tb'", "]", ",", "prefix", "=", "args", ".", "prefix", ")", "\n", "\n", "# 5. Setup / add basic modules to the config", "\n", "config", ".", "update", "(", "\n", "dict", "(", "trainer", "=", "StandardTrain", "(", ")", ",", "\n", "evaluation", "=", "EpisodicEval", "(", ")", ",", "\n", "policy", "=", "ActorPolicy", "(", ")", ",", "\n", "logger", "=", "Logger", "(", ")", ",", "\n", "state_normalizer", "=", "Normalizer", "(", "MeanStdNormalizer", "(", ")", ")", ",", "\n", "replay", "=", "OnlineHERBuffer", "(", ")", ",", "\n", "action_noise", "=", "ContinuousActionNoise", "(", "GaussianProcess", ",", "std", "=", "ConstantSchedule", "(", "args", ".", "action_noise", ")", ")", ",", "\n", "algorithm", "=", "DDPG", "(", ")", ")", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "assert", "gym", ".", "envs", ".", "registry", ".", "env_specs", ".", "get", "(", "args", ".", "env", ")", "is", "not", "None", "\n", "env", "=", "lambda", ":", "gym", ".", "make", "(", "args", ".", "env", ")", "\n", "\n", "config", ".", "module_train_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "config", ".", "num_envs", ",", "seed", "=", "config", ".", "seed", ")", "\n", "config", ".", "module_eval_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "config", ".", "num_eval_envs", ",", "name", "=", "'eval_env'", ",", "seed", "=", "config", ".", "seed", "+", "1138", ")", "\n", "\n", "e", "=", "config", ".", "module_eval_env", "\n", "config", ".", "actor", "=", "PytorchModel", "(", "\n", "'actor'", ",", "lambda", ":", "Actor", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ")", ",", "e", ".", "action_dim", ",", "e", ".", "max_action", ")", ")", "\n", "config", ".", "critic", "=", "PytorchModel", "(", "\n", "'critic'", ",", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ")", ",", "1", ")", ")", "\n", "\n", "if", "e", ".", "goal_env", ":", "\n", "    ", "config", ".", "never_done", "=", "True", "# NOTE: This is important in the standard Goal environments, which are never done", "\n", "\n", "", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "num_eps", "=", "max", "(", "args", ".", "num_eval_envs", "*", "3", ",", "10", ")", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "f'Initial test reward ({num_eps} eps):'", ",", "f'{res:.2f}'", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "    ", "t", "=", "time", ".", "time", "(", ")", "\n", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ")", "\n", "\n", "# EVALUATE", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "f'Test reward ({num_eps} eps):'", ",", "f'{res:.2f}'", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n", "print", "(", "f\"Saving agent at epoch {epoch}\"", ")", "\n", "agent", ".", "save", "(", "'checkpoint'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.batch_rl.collect_policies.main": [[39, 84], ["OldReplayBuffer", "torch.set_num_threads", "torch.set_num_interop_threads", "mrl.config_to_agent", "max", "numpy.mean", "mrl.config_to_agent.logger.log_color", "range", "min", "min", "int", "time.time", "mrl.config_to_agent.train", "numpy.mean", "mrl.config_to_agent.logger.log_color", "int", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.eval", "numpy.mean", "print", "print", "mrl.config_to_agent.save", "print", "mrl.config_to_agent.load", "print", "max", "mrl.config_to_agent.eval", "len", "numpy.mean", "print", "print", "print", "mrl.config_to_agent.save", "print", "mrl.config_to_agent.load", "print", "max", "time.time"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["def", "main", "(", "config", ",", "args", ")", ":", "\n", "\n", "# use the old replay buffer, since it adds experience to buffer immediately and don't need HER", "\n", "  ", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "OldReplayBuffer", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "num_eps", "=", "max", "(", "args", ".", "num_eval_envs", "*", "3", ",", "10", ")", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "f'Initial test reward ({num_eps} eps):'", ",", "f'{res:.2f}'", ")", "\n", "\n", "max_perf", "=", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "    ", "t", "=", "time", ".", "time", "(", ")", "\n", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ")", "\n", "\n", "# EVALUATE", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Test reward ({} eps): {:.2f}'", ".", "format", "(", "len", "(", "res", ")", ",", "np", ".", "mean", "(", "res", ")", ")", ")", "\n", "res", "=", "int", "(", "np", ".", "mean", "(", "res", ")", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n", "if", "CHECKPOINT_DICT", "[", "args", ".", "env", "]", "and", "(", "res", ">", "CHECKPOINT_DICT", "[", "args", ".", "env", "]", "[", "0", "]", ")", ":", "\n", "      ", "CHECKPOINT_DICT", "[", "args", ".", "env", "]", "=", "CHECKPOINT_DICT", "[", "args", ".", "env", "]", "[", "1", ":", "]", "\n", "print", "(", "\"**********\"", ")", "\n", "print", "(", "\"Saving agent at epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "agent", ".", "save", "(", "f'performance_{res}'", ")", "\n", "print", "(", "\"Reloading agent to confirm it works...\"", ")", "\n", "agent", ".", "load", "(", "f'performance_{res}'", ")", "\n", "print", "(", "\"**********\"", ")", "\n", "max_perf", "=", "max", "(", "max_perf", ",", "res", ")", "\n", "", "elif", "res", ">", "max_perf", ":", "\n", "      ", "print", "(", "\"**********\"", ")", "\n", "print", "(", "\"NEW MAX PERFORMANCE!\"", ")", "\n", "print", "(", "\"Saving agent at epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "agent", ".", "save", "(", "'performance_MAX'", ")", "\n", "print", "(", "\"Reloading agent to confirm it works...\"", ")", "\n", "agent", ".", "load", "(", "'performance_MAX'", ")", "\n", "print", "(", "\"**********\"", ")", "\n", "max_perf", "=", "max", "(", "max_perf", ",", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.batch_rl.policy_to_buffer.main": [[22, 64], ["OldReplayBuffer", "torch.set_num_threads", "torch.set_num_interop_threads", "mrl.config_to_agent", "os.path.exists", "mrl.config_to_agent.module_dict.values", "mrl.config_to_agent.logger.log_color", "range", "print", "numpy.mean", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.save", "min", "min", "open", "pickle.load", "mrl.config_to_agent.eval", "int", "time.time", "mrl.config_to_agent.logger.log_color", "int", "mrl.config_to_agent.logger.log_color", "os.path.join", "print", "module.load", "len", "numpy.mean", "mrl.config_to_agent.train", "mrl.config_to_agent.eval_mode", "mrl.config_to_agent.train", "mrl.config_to_agent.eval", "numpy.mean", "len", "numpy.mean", "time.time"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode"], ["def", "main", "(", "config", ",", "args", ")", ":", "\n", "\n", "# use the old replay buffer, since it adds experience to buffer immediately and don't need HER", "\n", "  ", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "OldReplayBuffer", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "# LOAD THE AGENT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "args", ".", "load_folder", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "load_folder", ",", "'config.pickle'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "    ", "agent", ".", "config", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "for", "module", "in", "agent", ".", "module_dict", ".", "values", "(", ")", ":", "\n", "# DONT LOAD THE REPLAY BUFFER", "\n", "    ", "if", "module", ".", "module_name", "is", "not", "'replay_buffer'", ":", "\n", "      ", "print", "(", "\"Loading module {}\"", ".", "format", "(", "module", ".", "module_name", ")", ")", "\n", "module", ".", "load", "(", "args", ".", "load_folder", ")", "\n", "\n", "", "", "res", "=", "agent", ".", "eval", "(", "num_episodes", "=", "5", ")", ".", "rewards", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Initial test reward ({} eps): {:.2f}'", ".", "format", "(", "len", "(", "res", ")", ",", "np", ".", "mean", "(", "res", ")", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "    ", "t", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "collect_policy_type", "==", "'exploratory'", ":", "\n", "      ", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ",", "dont_optimize", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "agent", ".", "eval_mode", "(", ")", "\n", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ",", "dont_optimize", "=", "True", ",", "dont_train", "=", "True", ")", "\n", "\n", "# EVALUATE", "\n", "", "res", "=", "agent", ".", "eval", "(", "num_episodes", "=", "5", ")", ".", "rewards", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Test reward ({} eps): {:.2f}'", ".", "format", "(", "len", "(", "res", ")", ",", "np", ".", "mean", "(", "res", ")", ")", ")", "\n", "res", "=", "int", "(", "np", ".", "mean", "(", "res", ")", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n", "", "print", "(", "\"Saving agent at epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "avg_perf", "=", "(", "np", ".", "mean", "(", "agent", ".", "replay_buffer", ".", "buffer", ".", "items", "[", "'reward'", "]", ".", "data", ")", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'TOTAL PERFORMANCE: {:.2f}'", ".", "format", "(", "avg_perf", ")", ")", "\n", "agent", ".", "save", "(", "'checkpoint'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.batch_rl.train_batchrl.load_replay_buffer": [[36, 54], ["gym.make", "gym.make.get_dataset", "gym.make.close", "agent.replay_buffer.buffer.add_batch", "agent.replay_buffer.load", "[].reshape", "[].reshape"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["def", "load_replay_buffer", "(", "agent", ",", "load_path", "=", "None", ")", ":", "\n", "  ", "if", "agent", ".", "config", ".", "other_args", "[", "'env'", "]", "in", "DATASET_NAMES", ":", "\n", "    ", "dummy_env", "=", "gym", ".", "make", "(", "agent", ".", "config", ".", "other_args", "[", "'env'", "]", ")", "\n", "dataset", "=", "dummy_env", ".", "get_dataset", "(", ")", "\n", "dummy_env", ".", "close", "(", ")", "\n", "\n", "dataset", "=", "(", "\n", "dataset", "[", "'observations'", "]", "[", ":", "-", "1", "]", ",", "\n", "dataset", "[", "'actions'", "]", "[", ":", "-", "1", "]", ",", "\n", "dataset", "[", "'rewards'", "]", "[", ":", "-", "1", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "\n", "dataset", "[", "'observations'", "]", "[", "1", ":", "]", ",", "\n", "dataset", "[", "'terminals'", "]", "[", ":", "-", "1", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "\n", ")", "\n", "\n", "agent", ".", "replay_buffer", ".", "buffer", ".", "add_batch", "(", "*", "dataset", ")", "\n", "", "else", ":", "\n", "    ", "assert", "load_path", "is", "not", "None", "\n", "agent", ".", "replay_buffer", ".", "load", "(", "load_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.batch_rl.train_batchrl.main": [[55, 88], ["OldReplayBuffer", "torch.set_num_threads", "torch.set_num_interop_threads", "mrl.config_to_agent", "train_batchrl.load_replay_buffer", "numpy.mean", "mrl.config_to_agent.logger.log_color", "range", "min", "min", "int", "time.time", "mrl.config_to_agent.train_mode", "range", "mrl.config_to_agent.eval_mode", "numpy.mean", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.eval", "mrl.config_to_agent.algorithm._optimize", "mrl.config_to_agent.eval", "time.time"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.batch_rl.train_batchrl.load_replay_buffer", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.train_mode", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize"], ["", "", "def", "main", "(", "config", ",", "args", ")", ":", "\n", "\n", "# use the old replay buffer, since it adds experience to buffer immediately and don't need HER", "\n", "  ", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "OldReplayBuffer", "(", ")", "\n", "\n", "# dont use state normalizer", "\n", "del", "config", ".", "module_state_normalizer", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "# create agent", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "# load the offline data", "\n", "load_replay_buffer", "(", "agent", ",", "args", ".", "buffer_load_path", ")", "\n", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "10", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Initial test reward (10 eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "    ", "t", "=", "time", ".", "time", "(", ")", "\n", "agent", ".", "train_mode", "(", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "epoch_len", ")", ":", "\n", "      ", "agent", ".", "config", ".", "env_steps", "+=", "1", "# logger uses env_steps to decide when to write scalars.  ", "\n", "agent", ".", "algorithm", ".", "_optimize", "(", ")", "\n", "", "agent", ".", "eval_mode", "(", ")", "\n", "\n", "# EVALUATE", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "10", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Test reward (10 eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.RewardModel.__init__": [[16, 28], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "optimize_every", "=", "5", ",", "batch_size", "=", "2000", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      model: MLP that takes (s, a, ns) and regresses vs reward (1 dim)\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "'reward_model'", ",", "required_agent_modules", "=", "[", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "optimizer", "=", "None", "\n", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.RewardModel._setup": [[29, 32], ["sandy_module.RewardModel.model.to", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "sandy_module.RewardModel.model.parameters"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ",", "weight_decay", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.RewardModel._optimize": [[33, 53], ["len", "sandy_module.RewardModel.replay_buffer.buffer.sample", "numpy.concatenate", "sandy_module.RewardModel.torch", "sandy_module.RewardModel.torch", "sandy_module.RewardModel.model", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "sandy_module.RewardModel.optimizer.zero_grad", "torch.mse_loss.backward", "sandy_module.RewardModel.optimizer.step", "float", "sandy_module.RewardModel.numpy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "self", ".", "replay_buffer", ")", ":", "\n", "      ", "sample", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", "=", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "sample", "[", "2", "]", ",", "sample", "[", "3", "]", "\n", "\n", "sas", "=", "np", ".", "concatenate", "(", "(", "states", ",", "actions", ",", "next_states", ")", ",", "1", ")", "\n", "sas", "=", "self", ".", "torch", "(", "sas", ")", "\n", "rewards", "=", "self", ".", "torch", "(", "rewards", ")", "\n", "\n", "pred", "=", "self", ".", "model", "(", "sas", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "rewards", ",", "pred", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "return", "float", "(", "self", ".", "numpy", "(", "loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.RewardModel.compute_reward": [[54, 58], ["numpy.concatenate", "sandy_module.RewardModel.torch", "sandy_module.RewardModel.numpy", "sandy_module.RewardModel.model"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "def", "compute_reward", "(", "self", ",", "s", ",", "a", ",", "ns", ")", ":", "\n", "    ", "sas", "=", "np", ".", "concatenate", "(", "(", "s", ",", "a", ",", "ns", ")", ",", "1", ")", "\n", "sas", "=", "self", ".", "torch", "(", "sas", ")", "\n", "return", "self", ".", "numpy", "(", "self", ".", "model", "(", "sas", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.RewardModel.save": [[59, 65], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "sandy_module.RewardModel.model.state_dict", "sandy_module.RewardModel.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'model_state_dict'", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "'opt_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.RewardModel.load": [[66, 72], ["os.path.join", "os.path.exists", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "sandy_module.RewardModel.model.load_state_dict", "sandy_module.RewardModel.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "      ", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state_dict'", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'opt_state_dict'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.PongClassifierRewardModel.__init__": [[78, 90], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "256", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      model: MLP that takes (s, a, ns) and does cross entropy loss vs reward (3 dim)\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "'reward_model'", ",", "required_agent_modules", "=", "[", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "optimizer", "=", "None", "\n", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.PongClassifierRewardModel._setup": [[91, 94], ["sandy_module.PongClassifierRewardModel.model.to", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "sandy_module.PongClassifierRewardModel.model.parameters"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ",", "weight_decay", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.PongClassifierRewardModel._optimize": [[95, 116], ["len", "sandy_module.PongClassifierRewardModel.replay_buffer.buffer.sample", "numpy.concatenate", "sandy_module.PongClassifierRewardModel.torch", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "sandy_module.PongClassifierRewardModel.model", "sandy_module.PongClassifierRewardModel.optimizer.zero_grad", "loss.backward", "sandy_module.PongClassifierRewardModel.optimizer.step", "float", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "sandy_module.PongClassifierRewardModel.numpy", "torch.round().to", "torch.round().to", "torch.round().to", "torch.round().to", "torch.round().to", "torch.round().to", "torch.round().to", "torch.round().to", "torch.round().to", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "sandy_module.PongClassifierRewardModel.torch"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "self", ".", "replay_buffer", ")", ":", "\n", "      ", "sample", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", "=", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "sample", "[", "2", "]", ",", "sample", "[", "3", "]", "\n", "\n", "sas", "=", "np", ".", "concatenate", "(", "(", "states", ",", "actions", ",", "next_states", ")", ",", "1", ")", "\n", "sas", "=", "self", ".", "torch", "(", "sas", ")", "\n", "rewards", "=", "torch", ".", "squeeze", "(", "torch", ".", "round", "(", "self", ".", "torch", "(", "rewards", ")", ")", ".", "to", "(", "torch", ".", "long", ")", "+", "1", ",", "1", ")", "\n", "\n", "pred", "=", "self", ".", "model", "(", "sas", ")", "\n", "\n", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "(", "pred", ",", "rewards", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "return", "float", "(", "self", ".", "numpy", "(", "loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.PongClassifierRewardModel.compute_reward": [[117, 121], ["numpy.concatenate", "sandy_module.PongClassifierRewardModel.torch", "[].astype", "numpy.argmax", "sandy_module.PongClassifierRewardModel.numpy", "sandy_module.PongClassifierRewardModel.model"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "def", "compute_reward", "(", "self", ",", "s", ",", "a", ",", "ns", ")", ":", "\n", "    ", "sas", "=", "np", ".", "concatenate", "(", "(", "s", ",", "a", ",", "ns", ")", ",", "1", ")", "\n", "sas", "=", "self", ".", "torch", "(", "sas", ")", "\n", "return", "np", ".", "argmax", "(", "self", ".", "numpy", "(", "self", ".", "model", "(", "sas", ")", ")", ",", "-", "1", ")", "[", ":", ",", "None", "]", ".", "astype", "(", "np", ".", "float32", ")", "-", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.PongClassifierRewardModel.save": [[122, 128], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "sandy_module.PongClassifierRewardModel.model.state_dict", "sandy_module.PongClassifierRewardModel.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'model_state_dict'", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "'opt_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.PongClassifierRewardModel.load": [[129, 135], ["os.path.join", "os.path.exists", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "sandy_module.PongClassifierRewardModel.model.load_state_dict", "sandy_module.PongClassifierRewardModel.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "      ", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state_dict'", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'opt_state_dict'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.CodaAttentionBasedMask.__init__": [[141, 153], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "optimize_every", "=", "5", ",", "batch_size", "=", "2000", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      model: SimpleStackedAttention Model\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "'coda_attention_model'", ",", "required_agent_modules", "=", "[", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "optimizer", "=", "None", "\n", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.CodaAttentionBasedMask._setup": [[154, 158], ["sandy_module.CodaAttentionBasedMask.model.to", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "isinstance", "isinstance", "sandy_module.CodaAttentionBasedMask.model.parameters"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "CodaBuffer", ")", "or", "isinstance", "(", "self", ".", "replay_buffer", ",", "CodaOldBuffer", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "3e-4", ",", "weight_decay", "=", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.CodaAttentionBasedMask._optimize": [[159, 194], ["sandy_module.CodaAttentionBasedMask.replay_buffer.buffer.sample", "mrl.utils.misc.batch_block_diag", "sandy_module.CodaAttentionBasedMask.torch", "sandy_module.CodaAttentionBasedMask.torch", "sandy_module.CodaAttentionBasedMask.model.forward_with_mask", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "sandy_module.CodaAttentionBasedMask.optimizer.zero_grad", "torch.mse_loss.backward", "sandy_module.CodaAttentionBasedMask.optimizer.step", "float", "len", "mrl.utils.misc.batch_block_diag_many", "mrl.utils.misc.batch_block_diag_many", "mrl.utils.misc.batch_block_diag_many", "sandy_module.CodaAttentionBasedMask.numpy", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "self", ".", "replay_buffer", ")", ">", "config", ".", "min_experience_to_train_coda_attn", ":", "\n", "      ", "sample", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "states", ",", "actions", ",", "next_states", "=", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "sample", "[", "3", "]", "\n", "# Convert states to the correct format", "\n", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_state_dims", ":", "\n", "        ", "state_slots", "=", "[", "states", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_state_dims", "]", "\n", "states", "=", "batch_block_diag_many", "(", "*", "state_slots", ")", "\n", "next_state_slots", "=", "[", "next_states", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_state_dims", "]", "\n", "next_states", "=", "batch_block_diag_many", "(", "*", "next_state_slots", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "slot_action_dims", "is", "not", "None", ":", "\n", "        ", "action_slots", "=", "[", "actions", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_action_dims", "]", "\n", "actions", "=", "batch_block_diag_many", "(", "*", "action_slots", ")", "\n", "", "elif", "len", "(", "actions", ".", "shape", ")", "==", "2", ":", "\n", "        ", "actions", "=", "actions", "[", ":", ",", "None", "]", "\n", "\n", "", "sa", "=", "batch_block_diag", "(", "states", ",", "actions", ")", "\n", "\n", "sa", "=", "self", ".", "torch", "(", "sa", ")", "\n", "next_states", "=", "self", ".", "torch", "(", "next_states", ")", "\n", "\n", "pred", ",", "mask", "=", "self", ".", "model", ".", "forward_with_mask", "(", "sa", ")", "\n", "pred", "=", "pred", "[", ":", ",", ":", "-", "actions", ".", "shape", "[", "1", "]", "]", "\n", "\n", "loss", "=", "F", ".", "mse_loss", "(", "next_states", ",", "pred", ")", "# + torch.sqrt(mask).mean()*1e-5", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "return", "float", "(", "self", ".", "numpy", "(", "loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.CodaAttentionBasedMask.forward": [[195, 222], ["mrl.utils.misc.batch_block_diag", "sandy_module.CodaAttentionBasedMask.torch", "sandy_module.CodaAttentionBasedMask.model.forward_with_mask", "sandy_module.CodaAttentionBasedMask.numpy", "mrl.utils.misc.batch_block_diag_many", "mrl.utils.misc.batch_block_diag_many", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many"], ["", "", "def", "forward", "(", "self", ",", "states", ",", "actions", ")", ":", "\n", "    ", "\"\"\"1-step forward prediction; operates on raw states/actions\"\"\"", "\n", "# Convert states to the correct format", "\n", "config", "=", "self", ".", "config", "\n", "\n", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_state_dims", ":", "\n", "      ", "state_slots", "=", "[", "states", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_state_dims", "]", "\n", "states", "=", "batch_block_diag_many", "(", "*", "state_slots", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "slot_action_dims", "is", "not", "None", ":", "\n", "      ", "action_slots", "=", "[", "actions", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_action_dims", "]", "\n", "actions", "=", "batch_block_diag_many", "(", "*", "action_slots", ")", "\n", "", "elif", "len", "(", "actions", ".", "shape", ")", "==", "2", ":", "\n", "      ", "actions", "=", "actions", "[", ":", ",", "None", "]", "\n", "\n", "", "sa", "=", "batch_block_diag", "(", "states", ",", "actions", ")", "\n", "\n", "sa", "=", "self", ".", "torch", "(", "sa", ")", "\n", "\n", "pred", ",", "_", "=", "self", ".", "model", ".", "forward_with_mask", "(", "sa", ")", "\n", "\n", "next_states", "=", "self", ".", "numpy", "(", "pred", ")", "\n", "\n", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_state_dims", ":", "\n", "      ", "next_states", "=", "next_states", "[", ":", ",", "self", ".", "replay_buffer", ".", "invert_batch_block_diag_mask", "[", "0", "]", ",", "self", ".", "replay_buffer", ".", "invert_batch_block_diag_mask", "[", "1", "]", "]", "\n", "\n", "", "return", "next_states", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.CodaAttentionBasedMask.get_mask": [[223, 238], ["mrl.utils.misc.batch_block_diag", "sandy_module.CodaAttentionBasedMask.torch", "sandy_module.CodaAttentionBasedMask.model.forward_with_mask", "sandy_module.CodaAttentionBasedMask.numpy", "numpy.eye", "sandy_module.CodaAttentionBasedMask.transpose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "get_mask", "(", "self", ",", "s", ",", "a", ",", "THRESH", ")", ":", "\n", "    ", "\"\"\"Note that states, actions are already reshaped to (batch, num_components, in_features) here.\"\"\"", "\n", "sa", "=", "batch_block_diag", "(", "s", ",", "a", ")", "\n", "sa", "=", "self", ".", "torch", "(", "sa", ")", "\n", "\n", "# Mask here will be batch x num_components x num_components, but last column is garbage", "\n", "_", ",", "mask", "=", "self", ".", "model", ".", "forward_with_mask", "(", "sa", ")", "\n", "\n", "mask", "[", ":", ",", ":", ",", "-", "a", ".", "shape", "[", "1", "]", ":", "]", "=", "0", "# set action columns to 0", "\n", "mask", "=", "self", ".", "numpy", "(", "mask", ")", "\n", "mask", "+=", "np", ".", "eye", "(", "mask", ".", "shape", "[", "1", "]", ")", "[", "None", "]", "\n", "\n", "mask", "=", "(", "(", "mask", "+", "mask", ".", "transpose", "(", "0", ",", "2", ",", "1", ")", ")", "/", "2.", ")", "\n", "\n", "return", "(", "mask", ">", "THRESH", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.CodaAttentionBasedMask.save": [[239, 245], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "sandy_module.CodaAttentionBasedMask.model.state_dict", "sandy_module.CodaAttentionBasedMask.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'model_state_dict'", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "'opt_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.CodaAttentionBasedMask.load": [[246, 252], ["os.path.join", "os.path.exists", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "sandy_module.CodaAttentionBasedMask.model.load_state_dict", "sandy_module.CodaAttentionBasedMask.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "      ", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state_dict'", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'opt_state_dict'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MBPOModel.__init__": [[258, 271], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "model_fn", ",", "optimize_every", "=", "5", ",", "batch_size", "=", "2000", ",", "ensemble_size", "=", "7", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      model_fn: Should be a constructor for an MLP that outputs [mean, std], so 2 x output_dims.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "'coda_attention_model'", ",", "required_agent_modules", "=", "[", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "optimizer", "=", "None", "\n", "self", ".", "model_fn", "=", "model_fn", "\n", "self", ".", "ensemble_size", "=", "ensemble_size", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MBPOModel._setup": [[272, 278], ["sum", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "isinstance", "isinstance", "sandy_module.MBPOModel.model_fn().to", "range", "list", "sandy_module.MBPOModel.model_fn", "model.parameters"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "CodaBuffer", ")", "or", "isinstance", "(", "self", ".", "replay_buffer", ",", "CodaOldBuffer", ")", "\n", "\n", "self", ".", "models", "=", "[", "self", ".", "model_fn", "(", ")", ".", "to", "(", "self", ".", "config", ".", "device", ")", "for", "_", "in", "range", "(", "self", ".", "ensemble_size", ")", "]", "\n", "params", "=", "sum", "(", "[", "list", "(", "model", ".", "parameters", "(", ")", ")", "for", "model", "in", "self", ".", "models", "]", ",", "[", "]", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "1e-3", ",", "weight_decay", "=", "5e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MBPOModel._optimize": [[279, 302], ["sandy_module.MBPOModel.replay_buffer.buffer.sample", "numpy.concatenate", "sandy_module.MBPOModel.torch", "sandy_module.MBPOModel.torch", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "sandy_module.MBPOModel.optimizer.zero_grad", "loss.backward", "sandy_module.MBPOModel.optimizer.step", "float", "len", "torch.softplus", "torch.softplus", "torch.softplus", "sandy_module.MBPOModel.numpy", "m", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "self", ".", "replay_buffer", ")", ">", "config", ".", "min_experience_to_train_coda_attn", ":", "\n", "      ", "sample", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "states", ",", "actions", ",", "next_states", "=", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "sample", "[", "3", "]", "\n", "\n", "sa", "=", "np", ".", "concatenate", "(", "(", "states", ",", "actions", ")", ",", "-", "1", ")", "\n", "sa", "=", "self", ".", "torch", "(", "sa", ")", "\n", "next_states", "=", "self", ".", "torch", "(", "next_states", ")", "\n", "\n", "res", "=", "torch", ".", "stack", "(", "[", "m", "(", "sa", ")", "for", "m", "in", "self", ".", "models", "]", ")", "# ensemble_size x batch x 2*output", "\n", "preds", ",", "log_sigmasqs", "=", "torch", ".", "chunk", "(", "res", ",", "2", ",", "2", ")", "\n", "sigmasqs", "=", "F", ".", "softplus", "(", "log_sigmasqs", ")", "+", "1e-6", "\n", "\n", "loss", "=", "(", "(", "preds", "-", "next_states", "[", "None", "]", ")", "**", "2", "/", "(", "2", "*", "sigmasqs", ")", "+", "0.5", "*", "torch", ".", "log", "(", "sigmasqs", ")", ")", ".", "mean", "(", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "return", "float", "(", "self", ".", "numpy", "(", "loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MBPOModel.forward": [[303, 319], ["sandy_module.MBPOModel.torch", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "numpy.concatenate().transpose", "numpy.concatenate", "torch.softplus", "torch.softplus", "torch.softplus", "sandy_module.MBPOModel.numpy", "m", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "numpy.concatenate", "numpy.arange", "numpy.random.randint", "len", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "def", "forward", "(", "self", ",", "states", ",", "actions", ")", ":", "\n", "    ", "\"\"\"1-step forward prediction; operates on raw states/actions\"\"\"", "\n", "# Convert states to the correct format", "\n", "config", "=", "self", ".", "config", "\n", "\n", "sa", "=", "self", ".", "torch", "(", "np", ".", "concatenate", "(", "(", "states", ",", "actions", ")", ",", "-", "1", ")", ")", "\n", "res", "=", "torch", ".", "stack", "(", "[", "m", "(", "sa", ")", "for", "m", "in", "self", ".", "models", "]", ")", "# ensemble_size x batch x 2*output", "\n", "preds", ",", "log_sigmasqs", "=", "torch", ".", "chunk", "(", "res", ",", "2", ",", "2", ")", "\n", "sigmasqs", "=", "F", ".", "softplus", "(", "log_sigmasqs", ")", "+", "1e-6", "\n", "sigmas", "=", "torch", ".", "sqrt", "(", "sigmasqs", ")", "\n", "next_state_dists", "=", "Normal", "(", "preds", ",", "sigmas", ")", "\n", "next_states", "=", "next_state_dists", ".", "rsample", "(", ")", "# ensemble_size x batch x output", "\n", "next_states", "=", "[", "self", ".", "numpy", "(", "ns", ")", "for", "ns", "in", "torch", ".", "chunk", "(", "next_states", ",", "self", ".", "ensemble_size", ",", "0", ")", "]", "\n", "next_states", "=", "np", ".", "concatenate", "(", "next_states", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "next_states", "=", "next_states", "[", "np", ".", "arange", "(", "len", "(", "next_states", ")", ")", ",", "np", ".", "random", ".", "randint", "(", "self", ".", "ensemble_size", ",", "size", "=", "len", "(", "next_states", ")", ")", "]", "\n", "return", "next_states", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MBPOModel.get_mask": [[320, 322], ["None"], "methods", ["None"], ["", "def", "get_mask", "(", "self", ",", "s", ",", "a", ",", "THRESH", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MBPOModel.save": [[323, 325], ["None"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MBPOModel.load": [[326, 328], ["None"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleMLP.__init__": [[333, 340], ["torch.Module.__init__", "zip", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "layer_list", "=", "[", "]", "\n", "for", "i", ",", "o", "in", "zip", "(", "layers", "[", ":", "-", "1", "]", ",", "layers", "[", "1", ":", "]", ")", ":", "\n", "      ", "layer_list", "+=", "[", "nn", ".", "Linear", "(", "i", ",", "o", ")", ",", "nn", ".", "ReLU", "(", ")", "]", "\n", "", "layer_list", "=", "layer_list", "[", ":", "-", "1", "]", "\n", "self", ".", "f", "=", "nn", ".", "Sequential", "(", "*", "layer_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleMLP.forward": [[341, 343], ["sandy_module.SimpleMLP.f"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "f", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleAttn.__init__": [[349, 357], ["torch.Module.__init__", "sandy_module.SimpleMLP", "sandy_module.SimpleMLP", "tuple"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "embed_layers", ",", "attn_layers", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "embed_layers", "[", "0", "]", "==", "attn_layers", "[", "0", "]", ")", "\n", "\n", "attn_layers", "=", "tuple", "(", "attn_layers", "[", ":", "-", "1", "]", ")", "+", "(", "2", "*", "attn_layers", "[", "-", "1", "]", ",", ")", "\n", "\n", "self", ".", "embed", "=", "SimpleMLP", "(", "embed_layers", ")", "\n", "self", ".", "KQ", "=", "SimpleMLP", "(", "attn_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleAttn.forward": [[358, 360], ["sandy_module.SimpleAttn.forward_with_mask"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "forward_with_mask", "(", "x", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleAttn.forward_with_mask": [[361, 368], ["sandy_module.SimpleAttn.embed", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.bmm", "sandy_module.SimpleAttn.KQ", "Q.bmm", "K.transpose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax"], ["", "def", "forward_with_mask", "(", "self", ",", "x", ")", ":", "\n", "    ", "embs", "=", "self", ".", "embed", "(", "x", ")", "\n", "K", ",", "Q", "=", "torch", ".", "chunk", "(", "self", ".", "KQ", "(", "x", ")", ",", "chunks", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "A", "=", "F", ".", "softmax", "(", "Q", ".", "bmm", "(", "K", ".", "transpose", "(", "1", ",", "2", ")", ")", ",", "2", ")", "\n", "\n", "output", "=", "A", ".", "bmm", "(", "embs", ")", "# + embs", "\n", "return", "output", ",", "A", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MultipleSimpleAttn.__init__": [[371, 374], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "sandy_module.SimpleAttn", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "embed_layers", ",", "attn_layers", ",", "num_simple_attn", "=", "1", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attns", "=", "nn", ".", "ModuleList", "(", "[", "SimpleAttn", "(", "embed_layers", ",", "attn_layers", ")", "for", "i", "in", "range", "(", "num_simple_attn", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MultipleSimpleAttn.forward": [[375, 377], ["sandy_module.MultipleSimpleAttn.forward_with_mask"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "forward_with_mask", "(", "x", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.MultipleSimpleAttn.forward_with_mask": [[378, 389], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "attn.forward_with_mask", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "forward_with_mask", "(", "self", ",", "x", ")", ":", "\n", "    ", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "attn", "in", "self", ".", "attns", ":", "\n", "      ", "o", ",", "m", "=", "attn", ".", "forward_with_mask", "(", "x", ")", "\n", "outputs", ".", "append", "(", "o", ")", "\n", "masks", ".", "append", "(", "m", ")", "\n", "\n", "", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "masks", "=", "torch", ".", "stack", "(", "masks", ")", "\n", "\n", "return", "torch", ".", "mean", "(", "outputs", ",", "dim", "=", "0", ")", ",", "torch", ".", "mean", "(", "masks", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.__init__": [[393, 407], ["torch.Module.__init__", "range", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "sandy_module.MultipleSimpleAttn", "blocks.append", "sandy_module.MultipleSimpleAttn"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "num_attn_blocks", "=", "2", ",", "num_hidden_layers", "=", "2", ",", "num_hidden_units", "=", "512", ",", "num_heads", "=", "1", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "layers1", "=", "(", "in_features", ",", ")", "+", "(", "num_hidden_units", ",", ")", "*", "(", "num_hidden_layers", "-", "1", ")", "\n", "layers2", "=", "(", "num_hidden_units", ",", ")", "*", "num_hidden_layers", "\n", "\n", "blocks", "=", "[", "MultipleSimpleAttn", "(", "layers1", ",", "layers1", ",", "num_simple_attn", "=", "num_heads", ")", "]", "\n", "for", "block", "in", "range", "(", "num_attn_blocks", "-", "1", ")", ":", "\n", "      ", "blocks", ".", "append", "(", "MultipleSimpleAttn", "(", "layers2", ",", "layers2", ",", "num_simple_attn", "=", "num_heads", ")", ")", "\n", "\n", "", "output_projection", "=", "nn", ".", "Linear", "(", "num_hidden_units", ",", "out_features", ")", "\n", "self", ".", "f", "=", "nn", ".", "Sequential", "(", "*", "blocks", ",", "output_projection", ")", "\n", "\n", "self", ".", "in_features", "=", "in_features", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward": [[408, 416], ["sandy_module.SimpleStackedAttn.f"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      x with shape (batch, num_components, in_features)\n    Returns:\n      y with shape (batch, num_components, out_features)  \n    \"\"\"", "\n", "return", "self", ".", "f", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask": [[417, 436], ["[].repeat", "module.size", "type", "module.forward_with_mask", "mask.bmm.bmm.bmm", "module", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "m.transpose", "module.size"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.size", "home.repos.pwc.inspect_result.spitis_mrl.coda.sandy_module.SimpleStackedAttn.forward_with_mask", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.size"], ["", "def", "forward_with_mask", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      x with shape (batch, num_components, in_features)\n    Returns:\n      y with shape (batch, num_components, out_features)\n      mask with shape (batch, num_components, num_components)\n    \"\"\"", "\n", "\n", "mask", "=", "torch", ".", "eye", "(", "x", ".", "size", "(", "1", ")", ",", "device", "=", "x", ".", "device", ")", "[", "None", "]", ".", "repeat", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "\n", "for", "module", "in", "self", ".", "f", ":", "\n", "      ", "if", "type", "(", "module", ")", "in", "[", "SimpleAttn", ",", "MultipleSimpleAttn", "]", ":", "\n", "        ", "x", ",", "m", "=", "module", ".", "forward_with_mask", "(", "x", ")", "\n", "mask", "=", "mask", ".", "bmm", "(", "m", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "module", "(", "x", ")", "\n", "\n", "", "", "return", "x", ",", "mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_true_abstract_mask_spriteworld": [[15, 21], ["copy.deepcopy", "config[].step", "[].render"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["def", "get_true_abstract_mask_spriteworld", "(", "sprites", ",", "config", ",", "action", "=", "(", "0.5", ",", "0.5", ")", ")", ":", "\n", "  ", "\"\"\"Returns a mask with iteractions for next transition given true sprites.\n  E.g., returns [[1,0,0],[0,1,0],[0,0,1]] for 3 sprites\"\"\"", "\n", "sprites1", "=", "copy", ".", "deepcopy", "(", "sprites", ")", "\n", "config", "[", "'action_space'", "]", ".", "step", "(", "action", ",", "sprites1", ")", "\n", "return", "config", "[", "'renderers'", "]", "[", "'mask_abstract'", "]", ".", "render", "(", "sprites1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.batch_get_heuristic_mask_fetchpush_": [[22, 33], ["numpy.ones", "numpy.array", "numpy.where", "numpy.linalg.norm"], "function", ["None"], ["", "def", "batch_get_heuristic_mask_fetchpush_", "(", "s", ",", "a", ")", ":", "\n", "  ", "\"\"\" heuristic mask for disentangled fetch \"\"\"", "\n", "grip_poses", "=", "s", "[", ":", ",", "0", ",", ":", "3", "]", "\n", "obj_poses", "=", "s", "[", ":", ",", "1", ",", "10", ":", "13", "]", "\n", "\n", "entangled", "=", "np", ".", "linalg", ".", "norm", "(", "grip_poses", "-", "obj_poses", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "[", ":", ",", "None", "]", "<", "0.1", "\n", "\n", "entangled_mask", "=", "np", ".", "ones", "(", "(", "1", ",", "3", ",", "3", ")", ")", "\n", "disentangled_mask", "=", "np", ".", "array", "(", "[", "[", "[", "1", ",", "0", ",", "1", "]", ",", "[", "0", ",", "1", ",", "0", "]", ",", "[", "1", ",", "0", ",", "1", "]", "]", "]", ")", "\n", "\n", "return", "np", ".", "where", "(", "entangled", ",", "entangled_mask", ",", "disentangled_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.batch_get_heuristic_mask_fetchpush": [[34, 42], ["numpy.stack", "numpy.linalg.norm", "numpy.pad", "enumerate"], "function", ["None"], ["", "def", "batch_get_heuristic_mask_fetchpush", "(", "s", ",", "a", ")", ":", "\n", "  ", "poses", "=", "np", ".", "stack", "(", "[", "s", "[", ":", ",", "i", ",", "h", "]", "for", "i", ",", "h", "in", "enumerate", "(", "FETCH_HEURISTIC_IDXS", "[", ":", "s", ".", "shape", "[", "1", "]", "]", ")", "]", ",", "1", ")", "# batch x n_state_comps x 3", "\n", "dists", "=", "np", ".", "linalg", ".", "norm", "(", "poses", "[", ":", ",", "None", "]", "-", "poses", "[", ":", ",", ":", ",", "None", "]", ",", "axis", "=", "-", "1", ")", "# batch x n_state_comps x n_state_comps", "\n", "entangled", "=", "(", "dists", "<", "0.1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "entangled", "=", "np", ".", "pad", "(", "entangled", ",", "(", "(", "0", ",", "0", ")", ",", "(", "0", ",", "1", ")", ",", "(", "0", ",", "1", ")", ")", ")", "# add action dim", "\n", "entangled", "[", ":", ",", "-", "1", ",", "0", "]", "=", "1.", "# entangle action with gripper", "\n", "\n", "return", "entangled", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_default_mask": [[44, 52], ["numpy.ones", "len", "a.reshape", "len", "len"], "function", ["None"], ["", "def", "get_default_mask", "(", "s", ",", "a", ")", ":", "\n", "  ", "\"\"\" assumes set-based s and a... so shape should be (n_componenents, *component_shape) \"\"\"", "\n", "if", "len", "(", "a", ".", "shape", ")", "==", "1", ":", "\n", "    ", "a", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "", "mask_dim", "=", "len", "(", "s", ")", "+", "len", "(", "a", ")", "\n", "mask_shape", "=", "(", "mask_dim", ",", "mask_dim", ")", "\n", "return", "np", ".", "ones", "(", "mask_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.batch_get_default_mask": [[53, 64], ["numpy.ones", "len", "a.reshape", "len"], "function", ["None"], ["", "def", "batch_get_default_mask", "(", "s", ",", "a", ")", ":", "\n", "  ", "\"\"\" Batch version of get default mask \"\"\"", "\n", "s_shape", "=", "s", ".", "shape", "\n", "a_shape", "=", "a", ".", "shape", "\n", "if", "len", "(", "a_shape", ")", "==", "2", ":", "\n", "    ", "assert", "len", "(", "a_shape", ")", ">", "1", "\n", "a", ".", "reshape", "(", "-", "1", ",", "1", ",", "a_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "mask_dim", "=", "s_shape", "[", "1", "]", "+", "a_shape", "[", "1", "]", "\n", "mask_shape", "=", "(", "s_shape", "[", "0", "]", ",", "mask_dim", ",", "mask_dim", ")", "\n", "return", "np", ".", "ones", "(", "mask_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_cc_from_mask": [[68, 80], ["scipy.sparse.csgraph.connected_components", "numpy.where", "range"], "function", ["None"], ["", "def", "get_cc_from_mask", "(", "mask", ")", ":", "\n", "  ", "\"\"\"\n  Converts a mask into a list of CC indices tuples.\n  E.g., if mask is [[1,0,0,0],[0,1,0,0],[0,0,1,1],[0,0,1,1]],\n  this will return [array([0]), array([1]), array([2, 3])]\n  \n  Note that the mask should be a square, so in case we have (s, a) x (s2,),\n  we should first dummy a2 columns to form a square mask. \n  \"\"\"", "\n", "ccs", "=", "connected_components", "(", "mask", ")", "\n", "num_ccs", ",", "cc_idxs", "=", "ccs", "\n", "return", "[", "np", ".", "where", "(", "cc_idxs", "==", "i", ")", "[", "0", "]", "for", "i", "in", "range", "(", "num_ccs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.powerset": [[81, 84], ["list", "list", "range", "itertools.chain.from_iterable", "itertools.combinations", "range"], "function", ["None"], ["", "def", "powerset", "(", "n", ")", ":", "\n", "  ", "xs", "=", "list", "(", "range", "(", "n", ")", ")", "\n", "return", "list", "(", "chain", ".", "from_iterable", "(", "combinations", "(", "xs", ",", "n", ")", "for", "n", "in", "range", "(", "n", "+", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.reduce_cc_list_by_union": [[85, 95], ["len", "numpy.random.choice", "numpy.union1d", "range", "len", "len"], "function", ["None"], ["", "def", "reduce_cc_list_by_union", "(", "cc_list", ",", "max_ccs", ")", ":", "\n", "  ", "\"\"\"Takes a cc list that is too long and merges some components to bring it\n  to max_ccs\"\"\"", "\n", "while", "len", "(", "cc_list", ")", ">", "max_ccs", ":", "\n", "    ", "i", ",", "j", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "1", ",", "len", "(", "cc_list", ")", "-", "1", ")", ",", "2", ",", "replace", "=", "False", ")", "\n", "if", "(", "j", "==", "0", ")", "or", "(", "j", "==", "len", "(", "cc_list", ")", "-", "1", ")", ":", "\n", "      ", "continue", "# don't want to delete the base", "\n", "", "cc_list", "[", "i", "]", "=", "np", ".", "union1d", "(", "cc_list", "[", "i", "]", ",", "cc_list", "[", "j", "]", ")", "\n", "del", "cc_list", "[", "j", "]", "\n", "", "return", "cc_list", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.disentangled_components": [[96, 105], ["coda_generic.powerset", "set", "len", "res.append", "map", "functools.reduce().astype", "functools.reduce", "numpy.array"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.powerset", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "disentangled_components", "(", "cc_lst", ")", ":", "\n", "  ", "\"\"\"Converts connected component list into a list of disentangled subsets\n  of the indices.\n  \"\"\"", "\n", "subsets", "=", "powerset", "(", "len", "(", "cc_lst", ")", ")", "\n", "res", "=", "[", "]", "\n", "for", "subset", "in", "subsets", ":", "\n", "    ", "res", ".", "append", "(", "reduce", "(", "np", ".", "union1d", ",", "[", "cc_lst", "[", "i", "]", "for", "i", "in", "subset", "]", ",", "np", ".", "array", "(", "[", "]", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", ")", "\n", "", "return", "set", "(", "map", "(", "tuple", ",", "res", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_dcs_from_mask": [[106, 109], ["coda_generic.get_cc_from_mask", "coda_generic.disentangled_components", "coda_generic.reduce_cc_list_by_union"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_cc_from_mask", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.disentangled_components", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.reduce_cc_list_by_union"], ["", "def", "get_dcs_from_mask", "(", "mask", ",", "max_ccs", "=", "6", ")", ":", "\n", "  ", "cc", "=", "get_cc_from_mask", "(", "mask", ")", "\n", "return", "disentangled_components", "(", "reduce_cc_list_by_union", "(", "cc", ",", "max_ccs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.transitions_and_masks_to_proposals": [[110, 165], ["coda_generic.get_dcs_from_mask", "coda_generic.get_dcs_from_mask", "list", "random.shuffle", "set", "get_dcs_from_mask.intersection", "len", "range", "list", "list", "numpy.zeros_like", "numpy.zeros_like", "res.append", "len", "set", "tuple"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_dcs_from_mask", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_dcs_from_mask", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "transitions_and_masks_to_proposals", "(", "t1", ",", "\n", "t2", ",", "\n", "m1", ",", "\n", "m2", ",", "\n", "max_samples", "=", "10", ",", "\n", "max_ccs", "=", "6", ")", ":", "\n", "  ", "\"\"\" \n  assumes set-based s and a... so shape should be (n_components, *component_shape)\n  Takes two transitions with their masks, and combines them\n  using connected-component relabeling to form proposals\n\n  Returns a list of tuples of ((s1, a1, s2) proposal, disconnected_component_idxs).\n  \"\"\"", "\n", "sa1", ",", "s21", "=", "t1", "\n", "sa2", ",", "s22", "=", "t2", "\n", "\n", "# get_dcs_from_mask should return a set of tuples of indices, inc. the empty tuple", "\n", "# where the subgraph represented by each tuple is disconnected from the result of ", "\n", "# the graph. Note that mask should be square, so columns corresp. to action idxs are ", "\n", "# dummy columns.", "\n", "#", "\n", "# E.g., if mask is [[1,0,0,0],[0,1,0,0],[0,0,1,1],[0,0,1,1]],", "\n", "# this function should return:", "\n", "#   set([ (,), (0,), (1,), (0,1), (2, 3), (0, 2, 3), (1, 2, 3), (0, 1, 2, 3)  ])", "\n", "\n", "dc1", "=", "get_dcs_from_mask", "(", "m1", ",", "max_ccs", ")", "\n", "dc2", "=", "get_dcs_from_mask", "(", "m2", ",", "max_ccs", ")", "\n", "\n", "# get shared connected components in random order", "\n", "shared_dc", "=", "list", "(", "dc1", ".", "intersection", "(", "dc2", ")", ")", "\n", "random", ".", "shuffle", "(", "shared_dc", ")", "\n", "\n", "# subsample shared_dc down to max_samples", "\n", "if", "len", "(", "shared_dc", ")", ">", "max_samples", ":", "\n", "    ", "shared_dc", "=", "shared_dc", "[", ":", "max_samples", "]", "\n", "\n", "", "all_idxs", "=", "set", "(", "range", "(", "len", "(", "sa1", ")", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "dc", "in", "shared_dc", ":", "\n", "    ", "not_dc", "=", "list", "(", "all_idxs", "-", "set", "(", "dc", ")", ")", "\n", "dc", "=", "list", "(", "dc", ")", "# (0, 2)", "\n", "\n", "proposed_sa", "=", "np", ".", "zeros_like", "(", "sa1", ")", "\n", "proposed_s2", "=", "np", ".", "zeros_like", "(", "sa1", ")", "\n", "\n", "proposed_sa", "[", "dc", "]", "=", "sa1", "[", "dc", "]", "\n", "proposed_sa", "[", "not_dc", "]", "=", "sa2", "[", "not_dc", "]", "\n", "proposed_s2", "[", "dc", "]", "=", "s21", "[", "dc", "]", "\n", "proposed_s2", "[", "not_dc", "]", "=", "s22", "[", "not_dc", "]", "\n", "\n", "proposed_t", "=", "(", "proposed_sa", ",", "proposed_s2", ")", "\n", "res", ".", "append", "(", "(", "proposed_t", ",", "tuple", "(", "dc", ")", ")", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.relabel_independent_transitions_spriteworld": [[167, 223], ["len", "custom_get_mask", "custom_get_mask", "coda_generic.transitions_and_masks_to_proposals", "copy.deepcopy", "len", "mrl.utils.misc.batch_block_diag", "mrl.utils.misc.batch_block_diag", "mrl.utils.misc.batch_block_diag", "mrl.utils.misc.batch_block_diag", "len", "custom_get_mask", "coda_generic.get_cc_from_mask", "coda_generic.disentangled_components", "s1_1.reshape", "a_1.reshape", "s2_1.reshape", "a_1.reshape", "s1_2.reshape", "a_2.reshape", "s2_2.reshape", "a_2.reshape", "tuple", "res.append", "copy.deepcopy", "ps1[].flatten", "reward_fn", "ps2[].flatten", "ps2[].flatten"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.transitions_and_masks_to_proposals", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.get_cc_from_mask", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.disentangled_components", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "relabel_independent_transitions_spriteworld", "(", "t1", ",", "\n", "sprites1", ",", "\n", "t2", ",", "\n", "sprites2", ",", "\n", "config", ",", "\n", "reward_fn", "=", "lambda", "_", ":", "0", ",", "\n", "total_samples", "=", "10", ",", "\n", "flattened", "=", "True", ",", "\n", "custom_get_mask", "=", "None", ",", "\n", "max_ccs", "=", "6", ")", ":", "\n", "  ", "\"\"\"\n  Same as old fn, but using new refactored bits -- to make sure it works\n  \"\"\"", "\n", "assert", "flattened", "\n", "\n", "s1_1", ",", "a_1", ",", "_", ",", "s2_1", "=", "t1", "\n", "s1_2", ",", "a_2", ",", "_", ",", "s2_2", "=", "t2", "\n", "\n", "num_sprites", "=", "len", "(", "sprites1", ")", "\n", "num_feats", "=", "len", "(", "s1_1", ")", "//", "num_sprites", "\n", "\n", "t1", "=", "(", "batch_block_diag", "(", "s1_1", ".", "reshape", "(", "num_sprites", ",", "num_feats", ")", ",", "a_1", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ",", "\n", "batch_block_diag", "(", "s2_1", ".", "reshape", "(", "num_sprites", ",", "num_feats", ")", ",", "a_1", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "t2", "=", "(", "batch_block_diag", "(", "s1_2", ".", "reshape", "(", "num_sprites", ",", "num_feats", ")", ",", "a_2", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ",", "\n", "batch_block_diag", "(", "s2_2", ".", "reshape", "(", "num_sprites", ",", "num_feats", ")", ",", "a_2", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "\n", "m1", "=", "custom_get_mask", "(", "sprites1", ",", "config", ",", "a_1", ")", "\n", "m2", "=", "custom_get_mask", "(", "sprites2", ",", "config", ",", "a_2", ")", "\n", "\n", "proposals_and_dcs", "=", "transitions_and_masks_to_proposals", "(", "t1", ",", "t2", ",", "m1", ",", "m2", ",", "total_samples", ",", "max_ccs", ")", "\n", "\n", "res", "=", "[", "]", "\n", "psprites", "=", "copy", ".", "deepcopy", "(", "sprites2", ")", "\n", "for", "proposal", ",", "dc", "in", "proposals_and_dcs", ":", "\n", "    ", "psa1", ",", "psa2", "=", "proposal", "\n", "ps1", "=", "psa1", "[", ":", "-", "1", "]", "\n", "pa", "=", "psa1", "[", "-", "1", ":", "]", "\n", "ps2", "=", "psa2", "[", ":", "-", "1", "]", "\n", "\n", "action_idx", "=", "len", "(", "ps1", ")", "\n", "for", "idx", "in", "dc", ":", "\n", "      ", "if", "idx", "!=", "action_idx", ":", "\n", "        ", "psprites", "[", "idx", "]", "=", "copy", ".", "deepcopy", "(", "sprites1", "[", "idx", "]", ")", "\n", "\n", "# Now we also need to check if the proposal is valid", "\n", "", "", "pm", "=", "custom_get_mask", "(", "psprites", ",", "config", ",", "pa", "[", "0", ",", "num_feats", ":", "]", ")", "\n", "pcc", "=", "get_cc_from_mask", "(", "pm", ")", "\n", "pdc", "=", "disentangled_components", "(", "pcc", ")", "\n", "\n", "if", "tuple", "(", "dc", ")", "in", "pdc", ":", "\n", "      ", "res", ".", "append", "(", "(", "ps1", "[", ":", ",", ":", "num_feats", "]", ".", "flatten", "(", ")", ",", "\n", "pa", "[", "0", ",", "num_feats", ":", "]", ",", "\n", "reward_fn", "(", "ps2", "[", ":", ",", ":", "num_feats", "]", ".", "flatten", "(", ")", ")", ",", "\n", "ps2", "[", ":", ",", ":", "num_feats", "]", ".", "flatten", "(", ")", ")", ")", "\n", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.relabel_spriteworld": [[225, 227], ["coda_generic.relabel_independent_transitions_spriteworld"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.relabel_independent_transitions_spriteworld"], ["", "def", "relabel_spriteworld", "(", "args", ")", ":", "\n", "  ", "return", "relabel_independent_transitions_spriteworld", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.relabel_generic": [[228, 230], ["coda_generic.transitions_and_masks_to_proposals"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.transitions_and_masks_to_proposals"], ["", "def", "relabel_generic", "(", "args", ")", ":", "\n", "  ", "return", "transitions_and_masks_to_proposals", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.enlarge_dataset_spriteworld": [[231, 259], ["len", "numpy.array().T.reshape", "numpy.random.choice", "sum", "len", "copy.deepcopy", "args.append", "copy.deepcopy", "copy.deepcopy", "multiprocessing.Pool", "pool.map", "coda_generic.relabel_spriteworld", "numpy.array", "min", "numpy.meshgrid", "numpy.arange", "numpy.arange", "multiprocessing.cpu_count"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.relabel_spriteworld"], ["", "def", "enlarge_dataset_spriteworld", "(", "data", ",", "sprites", ",", "config", ",", "num_pairs", ",", "relabel_samples_per_pair", ",", "flattened", "=", "True", ",", "\n", "custom_get_mask", "=", "None", ",", "pool", "=", "True", ",", "max_cpus", "=", "16", ")", ":", "\n", "  ", "data_len", "=", "len", "(", "data", ")", "\n", "all_idx_pairs", "=", "np", ".", "array", "(", "np", ".", "meshgrid", "(", "np", ".", "arange", "(", "data_len", ")", ",", "np", ".", "arange", "(", "data_len", ")", ")", ")", ".", "T", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "chosen_idx_pairs_idxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "all_idx_pairs", ")", ",", "num_pairs", ")", "\n", "chosen_idx_pairs", "=", "all_idx_pairs", "[", "chosen_idx_pairs_idxs", "]", "\n", "reward_fn", "=", "config", "[", "'task'", "]", ".", "reward_of_vector_repr", "\n", "\n", "config", "=", "{", "\n", "'action_space'", ":", "copy", ".", "deepcopy", "(", "config", "[", "'action_space'", "]", ")", ",", "\n", "'renderers'", ":", "{", "\n", "'mask'", ":", "copy", ".", "deepcopy", "(", "config", "[", "'renderers'", "]", "[", "'mask'", "]", ")", ",", "\n", "'mask_abstract'", ":", "copy", ".", "deepcopy", "(", "config", "[", "'renderers'", "]", "[", "'mask_abstract'", "]", ")", "\n", "}", "\n", "}", "\n", "args", "=", "[", "]", "\n", "for", "(", "i", ",", "j", ")", "in", "chosen_idx_pairs", ":", "\n", "    ", "args", ".", "append", "(", "\n", "(", "data", "[", "i", "]", ",", "sprites", "[", "i", "]", ",", "data", "[", "j", "]", ",", "sprites", "[", "j", "]", ",", "config", ",", "reward_fn", ",", "relabel_samples_per_pair", ",", "flattened", ",", "custom_get_mask", ")", ")", "\n", "\n", "", "if", "pool", ":", "\n", "    ", "with", "mp", ".", "Pool", "(", "min", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "max_cpus", ")", ")", "as", "pool", ":", "\n", "      ", "reses", "=", "pool", ".", "map", "(", "relabel_spriteworld", ",", "args", ")", "\n", "", "", "else", ":", "\n", "    ", "reses", "=", "[", "relabel_spriteworld", "(", "_args", ")", "for", "_args", "in", "args", "]", "\n", "", "reses", "=", "sum", "(", "reses", ",", "[", "]", ")", "\n", "\n", "return", "reses", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.enlarge_dataset_generic": [[260, 353], ["batch_get_mask", "set", "numpy.random.randint", "numpy.random.randint", "list", "list", "map_fn", "sum", "numpy.array", "numpy.array", "numpy.array", "batch_get_mask", "map_fn", "enumerate", "multiprocessing.Pool", "len", "zip", "zip", "np.array.append", "new_a1s.squeeze.append", "np.array.append", "dcs.append", "len", "zip", "new_a1s.squeeze.squeeze", "mp.Pool.close", "mp.Pool.join", "min", "tuple", "mrl.utils.misc.batch_block_diag", "mrl.utils.misc.batch_block_diag", "mrl.utils.misc.batch_block_diag", "mrl.utils.misc.batch_block_diag", "zip", "mp.Pool.close", "mp.Pool.join", "valid_idxs.append", "list", "multiprocessing.cpu_count", "range"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "enlarge_dataset_generic", "(", "states", ",", "actions", ",", "next_states", ",", "num_pairs", ",", "relabel_samples_per_pair", ",", "\n", "batch_get_mask", "=", "batch_get_heuristic_mask_fetchpush", ",", "pool", "=", "True", ",", "max_cpus", "=", "16", ",", "add_bad_dcs", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  This does random coda on generic data, using the following types:\n\n  Inputs:\n    states, next_states: [batch, n_components, state_feats]             # NOTE: assumes 1d state feats\n    actions: [batch, action_feats] or [batch, n_components, action_feats]\n    custom_get_mask: (batch_states, batched_actions) -> [batch_dim, state_feats + action_feats, state_feats + action_feats]\n\n  Returns:\n    (new_states, new_actions, new_next_states) with same shapes as inputs (except batch_dim)\n  \"\"\"", "\n", "if", "pool", ":", "\n", "    ", "mp_pool", "=", "mp", ".", "Pool", "(", "min", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "max_cpus", ")", ")", "\n", "map_fn", "=", "mp_pool", ".", "map", "\n", "", "else", ":", "\n", "    ", "map_fn", "=", "map", "\n", "\n", "", "data_len", ",", "n_state_components", ",", "n_state_feats", "=", "states", ".", "shape", "\n", "squeeze_on_return", "=", "False", "\n", "if", "len", "(", "actions", ".", "shape", ")", "==", "2", ":", "\n", "    ", "n_action_components", "=", "1", "\n", "squeeze_on_return", "=", "True", "\n", "actions", "=", "actions", "[", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "    ", "n_action_components", "=", "actions", ".", "shape", "[", "1", "]", "\n", "\n", "", "masks", "=", "batch_get_mask", "(", "states", ",", "actions", ")", "\n", "\n", "assert", "masks", ".", "shape", "[", "1", "]", "==", "masks", ".", "shape", "[", "2", "]", "==", "n_state_components", "+", "n_action_components", "\n", "\n", "bad_dcs", "=", "set", "(", "[", "(", ")", ",", "tuple", "(", "list", "(", "range", "(", "n_state_components", "+", "n_action_components", ")", ")", ")", "]", ")", "\n", "\n", "Is", "=", "np", ".", "random", ".", "randint", "(", "data_len", ",", "size", "=", "(", "num_pairs", ",", ")", ")", "\n", "Js", "=", "np", ".", "random", ".", "randint", "(", "data_len", ",", "size", "=", "(", "num_pairs", ",", ")", ")", "\n", "\n", "t1s", "=", "list", "(", "zip", "(", "batch_block_diag", "(", "states", "[", "Is", "]", ",", "actions", "[", "Is", "]", ")", ",", "batch_block_diag", "(", "next_states", "[", "Is", "]", ",", "actions", "[", "Is", "]", ")", ")", ")", "\n", "t2s", "=", "list", "(", "zip", "(", "batch_block_diag", "(", "states", "[", "Js", "]", ",", "actions", "[", "Js", "]", ")", ",", "batch_block_diag", "(", "next_states", "[", "Js", "]", ",", "actions", "[", "Js", "]", ")", ")", ")", "\n", "\n", "m1s", "=", "masks", "[", "Is", "]", "\n", "m2s", "=", "masks", "[", "Js", "]", "\n", "\n", "args", "=", "[", "(", "t1", ",", "t2", ",", "m1", ",", "m2", ",", "relabel_samples_per_pair", ")", "for", "t1", ",", "t2", ",", "m1", ",", "m2", "in", "zip", "(", "t1s", ",", "t2s", ",", "m1s", ",", "m2s", ")", "]", "\n", "\n", "proposals_and_dcs", "=", "map_fn", "(", "relabel_generic", ",", "args", ")", "\n", "proposals_and_dcs", "=", "sum", "(", "proposals_and_dcs", ",", "[", "]", ")", "# [((sa1, sa2), dc), ... ]", "\n", "\n", "new_s1s", "=", "[", "]", "\n", "new_a1s", "=", "[", "]", "\n", "new_s2s", "=", "[", "]", "\n", "dcs", "=", "[", "]", "\n", "\n", "for", "(", "sa1", ",", "sa2", ")", ",", "dc", "in", "proposals_and_dcs", ":", "\n", "    ", "if", "(", "not", "add_bad_dcs", ")", "and", "(", "dc", "in", "bad_dcs", ")", ":", "\n", "      ", "continue", "\n", "", "new_s1s", ".", "append", "(", "sa1", "[", ":", "n_state_components", ",", ":", "n_state_feats", "]", ")", "\n", "new_a1s", ".", "append", "(", "sa1", "[", "n_state_components", ":", ",", "n_state_feats", ":", "]", ")", "\n", "new_s2s", ".", "append", "(", "sa2", "[", ":", "n_state_components", ",", ":", "n_state_feats", "]", ")", "\n", "dcs", ".", "append", "(", "dc", ")", "\n", "\n", "\n", "", "new_s1s", "=", "np", ".", "array", "(", "new_s1s", ")", "\n", "new_a1s", "=", "np", ".", "array", "(", "new_a1s", ")", "\n", "new_s2s", "=", "np", ".", "array", "(", "new_s2s", ")", "\n", "\n", "if", "not", "len", "(", "new_s1s", ")", ":", "\n", "    ", "if", "pool", ":", "\n", "      ", "mp_pool", ".", "close", "(", ")", "\n", "mp_pool", ".", "join", "(", ")", "\n", "", "return", "(", "new_s1s", ",", "new_a1s", ",", "new_s2s", ")", "\n", "\n", "", "masks", "=", "batch_get_mask", "(", "new_s1s", ",", "new_a1s", ")", "\n", "pdcs", "=", "map_fn", "(", "get_dcs_from_mask", ",", "masks", ")", "\n", "\n", "# Now verify that proposals are valid", "\n", "valid_idxs", "=", "[", "]", "\n", "for", "i", ",", "(", "pdc", ",", "dc", ")", "in", "enumerate", "(", "zip", "(", "pdcs", ",", "dcs", ")", ")", ":", "\n", "    ", "if", "dc", "in", "pdc", ":", "\n", "      ", "valid_idxs", ".", "append", "(", "i", ")", "\n", "\n", "", "", "new_s1s", "=", "new_s1s", "[", "valid_idxs", "]", "\n", "new_a1s", "=", "new_a1s", "[", "valid_idxs", "]", "\n", "new_s2s", "=", "new_s2s", "[", "valid_idxs", "]", "\n", "\n", "if", "squeeze_on_return", ":", "\n", "    ", "new_a1s", "=", "new_a1s", ".", "squeeze", "(", "1", ")", "\n", "\n", "", "if", "pool", ":", "\n", "    ", "mp_pool", ".", "close", "(", ")", "\n", "mp_pool", ".", "join", "(", ")", "\n", "\n", "", "return", "(", "new_s1s", ",", "new_a1s", ",", "new_s2s", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer.__init__": [[17, 58], ["mrl.replays.online_her_buffer.OnlineHERBuffer.__init__", "NotImplementedError", "SpriteMaker"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "\n", "module_name", "=", "'replay_buffer'", ",", "\n", "max_coda_ratio", "=", "0.5", ",", "\n", "make_coda_data_every", "=", "1000", ",", "\n", "num_coda_source_transitions", "=", "5000", ",", "\n", "num_coda_source_pairs", "=", "2000", ",", "\n", "coda_samples_per_pair", "=", "5", ",", "\n", "coda_buffer_size", "=", "None", ",", "\n", "coda_on_goal_components", "=", "False", ",", "\n", "add_bad_dcs", "=", "False", ",", "\n", "spriteworld_config", "=", "None", ",", "\n", "reward_fn", "=", "None", ",", "# used for non-Spriteworld", "\n", "num_procs", "=", "8", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      max_coda_ratio: maximum ratio of coda:real data when sampling from the buffer\n      make_coda_data_every: how often to make coda data\n      num_coda_source_transitions: how many random pairs from the main buffer we should use to make coda samples\n      num_coda_source_pairs: using sampled transitions, how many source pairs should we form for doing CODA on?\n      coda_samples_per_pair: with each source pair, how many coda samples should we make? # NOTE: these are deduplicated, so it's upper bound\n      spriteworld_config: config for the spriteworld env\n      num_procs: num cpus to use for generating coda sample\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_coda_ratio", "=", "max_coda_ratio", "\n", "self", ".", "make_coda_data_every", "=", "make_coda_data_every", "\n", "self", ".", "num_coda_source_transitions", "=", "num_coda_source_transitions", "\n", "self", ".", "num_coda_source_pairs", "=", "num_coda_source_pairs", "\n", "self", ".", "coda_samples_per_pair", "=", "coda_samples_per_pair", "\n", "self", ".", "coda_buffer", "=", "None", "\n", "self", ".", "coda_buffer_size", "=", "coda_buffer_size", "\n", "self", ".", "add_bad_dcs", "=", "add_bad_dcs", "\n", "self", ".", "num_procs", "=", "num_procs", "\n", "self", ".", "reward_fn", "=", "reward_fn", "\n", "self", ".", "coda_on_goal_components", "=", "coda_on_goal_components", "\n", "\n", "self", ".", "spriteworld_config", "=", "spriteworld_config", "# NONE == This is not Spriteworld", "\n", "if", "spriteworld_config", "is", "not", "None", ":", "\n", "      ", "raise", "NotImplementedError", "(", "'not supported by public CoDA Code'", ")", "\n", "assert", "self", ".", "reward_fn", "is", "None", "\n", "self", ".", "state_to_sprites", "=", "SpriteMaker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer._setup": [[59, 93], ["super()._setup", "mrl.replays.core.replay_buffer.ReplayBuffer", "type", "enumerate", "enumerate", "coda_module.CodaBuffer.invert_batch_block_diag_mask[].append", "coda_module.CodaBuffer.invert_batch_block_diag_mask[].append", "coda_module.CodaBuffer.invert_batch_block_diag_mask_actions[].append", "coda_module.CodaBuffer.invert_batch_block_diag_mask_actions[].append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Keeps an separate, internal coda_buffer with coda experiences\n    \"\"\"", "\n", "\n", "super", "(", ")", ".", "_setup", "(", ")", "\n", "\n", "env", "=", "self", ".", "env", "\n", "if", "type", "(", "env", ".", "observation_space", ")", "==", "gym", ".", "spaces", ".", "Dict", ":", "\n", "      ", "observation_space", "=", "env", ".", "observation_space", ".", "spaces", "[", "\"observation\"", "]", "\n", "", "else", ":", "\n", "      ", "observation_space", "=", "env", ".", "observation_space", "\n", "\n", "", "items", "=", "[", "(", "\"state\"", ",", "observation_space", ".", "shape", ")", ",", "\n", "(", "\"action\"", ",", "env", ".", "action_space", ".", "shape", ")", ",", "(", "\"reward\"", ",", "(", "1", ",", ")", ")", ",", "\n", "(", "\"next_state\"", ",", "observation_space", ".", "shape", ")", ",", "(", "\"done\"", ",", "(", "1", ",", ")", ")", "]", "\n", "\n", "self", ".", "coda_buffer", "=", "Buffer", "(", "self", ".", "coda_buffer_size", "or", "self", ".", "size", ",", "items", ")", "\n", "\n", "assert", "self", ".", "config", ".", "never_done", "# TODO: Make this work in general case", "\n", "\n", "if", "not", "self", ".", "config", ".", "slot_based_state", "and", "self", ".", "config", ".", "slot_state_dims", ":", "\n", "      ", "self", ".", "invert_batch_block_diag_mask", "=", "(", "[", "]", ",", "[", "]", ")", "\n", "for", "i", ",", "state_dims", "in", "enumerate", "(", "self", ".", "config", ".", "slot_state_dims", ")", ":", "\n", "        ", "for", "state_dim", "in", "state_dims", ":", "\n", "          ", "self", ".", "invert_batch_block_diag_mask", "[", "0", "]", ".", "append", "(", "i", ")", "\n", "self", ".", "invert_batch_block_diag_mask", "[", "1", "]", ".", "append", "(", "state_dim", ")", "\n", "\n", "", "", "", "if", "self", ".", "config", ".", "slot_action_dims", ":", "\n", "      ", "self", ".", "invert_batch_block_diag_mask_actions", "=", "(", "[", "]", ",", "[", "]", ")", "\n", "for", "i", ",", "action_dims", "in", "enumerate", "(", "self", ".", "config", ".", "slot_action_dims", ")", ":", "\n", "        ", "for", "action_dim", "in", "action_dims", ":", "\n", "          ", "self", ".", "invert_batch_block_diag_mask_actions", "[", "0", "]", ".", "append", "(", "i", ")", "\n", "self", ".", "invert_batch_block_diag_mask_actions", "[", "1", "]", ".", "append", "(", "action_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer._optimize": [[95, 160], ["coda_module.CodaBuffer.buffer.sample", "experiments.coda.coda_generic.enlarge_dataset_generic", "numpy.ones", "numpy.zeros", "coda_module.CodaBuffer.coda_buffer.add_batch", "hasattr", "coda_module.CodaBuffer._optimize_spriteworld", "mrl.utils.misc.batch_block_diag_many", "mrl.utils.misc.batch_block_diag_many", "mrl.utils.misc.batch_block_diag_many", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.enlarge_dataset_generic", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer._optimize_spriteworld", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many"], ["", "", "", "", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Populates the internal coda_buffer using samples from the real buffer. \n    \"\"\"", "\n", "config", "=", "self", ".", "config", "\n", "if", "not", "(", "len", "(", "self", ")", "and", "config", ".", "opt_steps", "%", "self", ".", "make_coda_data_every", "==", "0", ")", ":", "\n", "      ", "return", "\n", "\n", "# return if too early", "\n", "", "if", "hasattr", "(", "self", ",", "'coda_attention_model'", ")", "and", "len", "(", "self", ")", "<", "config", ".", "min_experience_to_train_coda_attn", "+", "5000", ":", "\n", "      ", "return", "\n", "\n", "", "if", "self", ".", "spriteworld_config", "is", "not", "None", ":", "\n", "      ", "return", "self", ".", "_optimize_spriteworld", "(", ")", "\n", "\n", "", "sample", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "num_coda_source_transitions", ")", "\n", "states", ",", "actions", ",", "next_states", "=", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "sample", "[", "3", "]", "\n", "\n", "#og_state_set = set([tuple(s.flatten().round(2)) for s in states])", "\n", "\n", "# Convert states to the correct format", "\n", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_state_dims", ":", "\n", "      ", "state_slots", "=", "[", "states", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_state_dims", "]", "\n", "states", "=", "batch_block_diag_many", "(", "*", "state_slots", ")", "\n", "next_state_slots", "=", "[", "next_states", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_state_dims", "]", "\n", "next_states", "=", "batch_block_diag_many", "(", "*", "next_state_slots", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "slot_action_dims", ":", "\n", "      ", "action_slots", "=", "[", "actions", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_action_dims", "]", "\n", "actions", "=", "batch_block_diag_many", "(", "*", "action_slots", ")", "\n", "\n", "", "new_s1s", ",", "new_a1s", ",", "new_s2s", "=", "enlarge_dataset_generic", "(", "\n", "states", ",", "actions", ",", "next_states", ",", "\n", "self", ".", "num_coda_source_pairs", ",", "\n", "self", ".", "coda_samples_per_pair", ",", "\n", "batch_get_mask", "=", "self", ".", "get_coda_mask", ",", "\n", "pool", "=", "True", ",", "\n", "max_cpus", "=", "self", ".", "num_procs", ",", "\n", "add_bad_dcs", "=", "self", ".", "add_bad_dcs", ")", "\n", "\n", "if", "not", "len", "(", "new_s1s", ")", ":", "\n", "      ", "return", "\n", "\n", "", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_state_dims", ":", "\n", "      ", "new_s1s", "=", "new_s1s", "[", ":", ",", "self", ".", "invert_batch_block_diag_mask", "[", "0", "]", ",", "self", ".", "invert_batch_block_diag_mask", "[", "1", "]", "]", "\n", "new_s2s", "=", "new_s2s", "[", ":", ",", "self", ".", "invert_batch_block_diag_mask", "[", "0", "]", ",", "self", ".", "invert_batch_block_diag_mask", "[", "1", "]", "]", "\n", "\n", "", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_action_dims", ":", "\n", "      ", "new_a1s", "=", "new_a1s", "[", ":", ",", "self", ".", "invert_batch_block_diag_mask_actions", "[", "0", "]", ",", "self", ".", "invert_batch_block_diag_mask_actions", "[", "1", "]", "]", "\n", "\n", "#remove duplicates of original data", "\n", "#valid_idxs = []", "\n", "#for i, s in enumerate(new_s1s):", "\n", "# if not (tuple(s.flatten().round(2)) in og_state_set):", "\n", "#   valid_idxs.append(i)", "\n", "#", "\n", "#new_s1s = new_s1s[valid_idxs]", "\n", "#new_a1s = new_a1s[valid_idxs]", "\n", "#new_s2s = new_s2s[valid_idxs]", "\n", "\n", "", "assert", "config", ".", "never_done", "\n", "r", "=", "np", ".", "ones", "(", "(", "len", "(", "new_s1s", ")", ",", "1", ")", ")", "\n", "d", "=", "np", ".", "zeros", "(", "(", "len", "(", "new_s1s", ")", ",", "1", ")", ")", "\n", "\n", "self", ".", "coda_buffer", ".", "add_batch", "(", "new_s1s", ",", "new_a1s", ",", "r", ",", "new_s2s", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer._optimize_spriteworld": [[161, 200], ["super().sample", "zip", "set", "experiments.coda.coda_generic.enlarge_dataset_spriteworld", "r.reshape.reshape.reshape", "numpy.zeros_like", "coda_module.CodaBuffer.coda_buffer.add_batch", "sprites_for_base_data.append", "set.append", "sars_data.append", "numpy.array", "coda_module.CodaBuffer.state_to_sprites", "tuple", "zip", "s.round", "tuple", "s.round"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.enlarge_dataset_spriteworld", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_optimize_spriteworld", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Populates the internal coda_buffer using samples from the real buffer. \n    \"\"\"", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "_", "=", "super", "(", ")", ".", "sample", "(", "self", ".", "num_coda_source_transitions", ",", "to_torch", "=", "False", ")", "\n", "\n", "sprites_for_base_data", "=", "[", "]", "# TODO this is spriteworld specific", "\n", "og_state_set", "=", "[", "]", "\n", "sars_data", "=", "[", "]", "\n", "\n", "for", "s", ",", "a", ",", "r", ",", "s2", "in", "zip", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ")", ":", "\n", "      ", "sprites_for_base_data", ".", "append", "(", "self", ".", "state_to_sprites", "(", "s", ")", ")", "# TODO this is spriteworld specific", "\n", "og_state_set", ".", "append", "(", "tuple", "(", "s", ".", "round", "(", "2", ")", ")", ")", "\n", "sars_data", ".", "append", "(", "(", "s", ",", "(", "a", "+", "1.", ")", "/", "2.", ",", "r", ",", "s2", ")", ")", "# TODO the action part is spriteworld specific", "\n", "\n", "", "og_state_set", "=", "set", "(", "og_state_set", ")", "\n", "\n", "coda_data", "=", "enlarge_dataset_spriteworld", "(", "\n", "sars_data", ",", "\n", "sprites_for_base_data", ",", "\n", "self", ".", "spriteworld_config", ",", "# TODO this is spriteworld specific", "\n", "self", ".", "num_coda_source_pairs", ",", "\n", "self", ".", "coda_samples_per_pair", ",", "\n", "flattened", "=", "True", ",", "\n", "custom_get_mask", "=", "self", ".", "get_coda_mask", ",", "\n", "pool", "=", "True", ",", "\n", "max_cpus", "=", "self", ".", "num_procs", ")", "\n", "\n", "# remove duplicates of original data", "\n", "# TODO the action part in next line is spriteworld specific", "\n", "coda_data", "=", "[", "(", "s", ",", "(", "a", "*", "2", ")", "-", "1.", ",", "r", ",", "s2", ")", "for", "s", ",", "a", ",", "r", ",", "s2", "in", "coda_data", "if", "not", "tuple", "(", "s", ".", "round", "(", "2", ")", ")", "in", "og_state_set", "]", "\n", "s", ",", "a", ",", "r", ",", "s2", "=", "[", "np", ".", "array", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "coda_data", ")", "]", "\n", "r", "=", "r", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "assert", "self", ".", "config", ".", "never_done", "\n", "d", "=", "np", ".", "zeros_like", "(", "r", ")", "\n", "\n", "assert", "not", "self", ".", "goal_space", "# Don't use goal space with sprite world. ", "\n", "self", ".", "coda_buffer", ".", "add_batch", "(", "s", ",", "a", ",", "r", ",", "s2", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer.sample": [[201, 225], ["min", "numpy.random.multinomial", "coda_module.CodaBuffer.sample_coda", "super().sample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "super().sample", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer.sample_coda", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "sample", "(", "self", ",", "batch_size", ",", "to_torch", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Samples both from real buffer and from coda buffer and concatenates results.\n    \"\"\"", "\n", "assert", "(", "to_torch", ")", "\n", "\n", "coda_ratio", "=", "min", "(", "len", "(", "self", ".", "coda_buffer", ")", "/", "(", "len", "(", "self", ")", "+", "len", "(", "self", ".", "coda_buffer", ")", ")", ",", "self", ".", "max_coda_ratio", ")", "\n", "\n", "if", "coda_ratio", "<", "0.01", ":", "\n", "      ", "return", "super", "(", ")", ".", "sample", "(", "batch_size", ")", "\n", "\n", "", "coda_batch_size", ",", "real_batch_size", "=", "np", ".", "random", ".", "multinomial", "(", "batch_size", ",", "[", "coda_ratio", ",", "1.", "-", "coda_ratio", "]", ")", "\n", "\n", "coda_states", ",", "coda_actions", ",", "coda_rewards", ",", "coda_next_states", ",", "coda_gammas", "=", "self", ".", "sample_coda", "(", "coda_batch_size", ")", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", "=", "super", "(", ")", ".", "sample", "(", "real_batch_size", ")", "\n", "\n", "\n", "states", "=", "torch", ".", "cat", "(", "(", "states", ",", "coda_states", ")", ",", "0", ")", "\n", "actions", "=", "torch", ".", "cat", "(", "(", "actions", ",", "coda_actions", ")", ",", "0", ")", "\n", "rewards", "=", "torch", ".", "cat", "(", "(", "rewards", ",", "coda_rewards", ")", ",", "0", ")", "\n", "next_states", "=", "torch", ".", "cat", "(", "(", "next_states", ",", "coda_next_states", ")", ",", "0", ")", "\n", "gammas", "=", "torch", ".", "cat", "(", "(", "gammas", ",", "coda_gammas", ")", ",", "0", ")", "\n", "\n", "return", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer.sample_coda": [[226, 284], ["coda_module.CodaBuffer.coda_buffer.sample", "numpy.all", "hasattr", "hasattr", "numpy.logical_not", "numpy.random.randint", "dg_buffer.get_batch", "numpy.random.randint", "ag_buffer.get_batch", "numpy.concatenate", "coda_module.CodaBuffer.reward_fn", "coda_module.CodaBuffer.done_fn", "coda_module.CodaBuffer.state_normalizer().astype", "coda_module.CodaBuffer.state_normalizer().astype", "len", "len", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "coda_module.CodaBuffer.reward_fn", "coda_module.CodaBuffer.torch", "coda_module.CodaBuffer.torch", "coda_module.CodaBuffer.torch", "coda_module.CodaBuffer.torch", "coda_module.CodaBuffer.torch", "numpy.random.shuffle", "coda_module.CodaBuffer.state_normalizer", "coda_module.CodaBuffer.state_normalizer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch"], ["", "def", "sample_coda", "(", "self", ",", "batch_size", ",", "to_torch", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Samples from coda_buffer (no real data).\n    \"\"\"", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", "=", "self", ".", "coda_buffer", ".", "sample", "(", "batch_size", ")", "\n", "\n", "assert", "np", ".", "all", "(", "np", ".", "logical_not", "(", "dones", ")", ")", "\n", "\n", "# Reward relabeling", "\n", "if", "self", ".", "goal_space", "is", "not", "None", ":", "\n", "      ", "assert", "self", ".", "reward_fn", "is", "not", "None", "\n", "\n", "dg_buffer", "=", "self", ".", "buffer", ".", "BUFF", ".", "buffer_dg", "\n", "dg_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "dg_buffer", ")", ",", "size", "=", "(", "batch_size", "//", "2", ",", ")", ")", "\n", "dgs", "=", "dg_buffer", ".", "get_batch", "(", "dg_idxs", ")", "\n", "\n", "ag_buffer", "=", "self", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "ag_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "ag_buffer", ")", ",", "size", "=", "(", "batch_size", "-", "batch_size", "//", "2", ",", ")", ")", "\n", "ags", "=", "ag_buffer", ".", "get_batch", "(", "ag_idxs", ")", "\n", "\n", "goals", "=", "np", ".", "concatenate", "(", "(", "dgs", ",", "ags", ")", ",", "axis", "=", "0", ")", "\n", "\n", "if", "self", ".", "coda_on_goal_components", ":", "\n", "        ", "goal_components", "=", "[", "goals", "[", ":", ",", "i", "]", "for", "i", "in", "self", ".", "config", ".", "slot_goal_dims", "]", "\n", "[", "np", ".", "random", ".", "shuffle", "(", "g", ")", "for", "g", "in", "goal_components", "]", "\n", "goals", "=", "np", ".", "concatenate", "(", "goal_components", ",", "axis", "=", "1", ")", "\n", "\n", "", "rewards", "=", "self", ".", "reward_fn", "(", "states", ",", "actions", ",", "next_states", ",", "goals", ")", "\n", "\n", "if", "self", ".", "config", ".", "slot_based_state", ":", "\n", "# TODO: For now, we flatten according to config.slot_state_dims", "\n", "        ", "I", ",", "J", "=", "self", ".", "config", ".", "slot_state_dims", "\n", "states", "=", "np", ".", "concatenate", "(", "(", "states", "[", ":", ",", "I", ",", "J", "]", ",", "goals", ")", ",", "-", "1", ")", "\n", "next_states", "=", "np", ".", "concatenate", "(", "(", "next_states", "[", ":", ",", "I", ",", "J", "]", ",", "goals", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "states", "=", "np", ".", "concatenate", "(", "(", "states", ",", "goals", ")", ",", "-", "1", ")", "\n", "next_states", "=", "np", ".", "concatenate", "(", "(", "next_states", ",", "goals", ")", ",", "-", "1", ")", "\n", "\n", "", "", "elif", "self", ".", "reward_fn", "is", "not", "None", ":", "\n", "      ", "rewards", "=", "self", ".", "reward_fn", "(", "states", ",", "actions", ",", "next_states", ")", "\n", "\n", "", "else", ":", "\n", "# This is spriteworld and things have already been relabeled", "\n", "      ", "assert", "self", ".", "spriteworld_config", "is", "not", "None", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'done_fn'", ")", ":", "\n", "      ", "dones", "=", "self", ".", "done_fn", "(", "states", ",", "actions", ",", "next_states", ")", "\n", "\n", "", "gammas", "=", "self", ".", "config", ".", "gamma", "*", "(", "1", "-", "dones", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "states", "=", "self", ".", "state_normalizer", "(", "states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "next_states", "=", "self", ".", "state_normalizer", "(", "next_states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "to_torch", ":", "\n", "      ", "return", "(", "self", ".", "torch", "(", "states", ")", ",", "self", ".", "torch", "(", "actions", ")", ",", "self", ".", "torch", "(", "rewards", ")", ",", "self", ".", "torch", "(", "next_states", ")", ",", "self", ".", "torch", "(", "gammas", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer.save": [[285, 294], ["coda_module.CodaBuffer.buffer._get_state", "coda_module.CodaBuffer.coda_buffer._get_state", "open", "pickle.dump", "open", "pickle.dump", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state", "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "if", "self", ".", "config", ".", "save_replay_buf", "or", "self", ".", "save_buffer", ":", "\n", "      ", "state", "=", "self", ".", "buffer", ".", "_get_state", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "state", ",", "f", ")", "\n", "\n", "", "state", "=", "self", ".", "coda_buffer", ".", "_get_state", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", "+", "'_coda'", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "state", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaBuffer.load": [[295, 319], ["os.path.join", "os.path.exists", "os.path.join", "os.path.exists", "coda_module.CodaBuffer.buffer._set_state", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.coda_buffer._set_state", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "coda_module.CodaBuffer.logger.log_color", "open", "pickle.load", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "load_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "      ", "with", "open", "(", "load_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "buffer", ".", "_set_state", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'cyan'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'yellow'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "\n", "", "load_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", "+", "'_coda'", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "      ", "with", "open", "(", "load_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "coda_buffer", ".", "_set_state", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Coda buffer is not being loaded / was not saved.'", ",", "color", "=", "'cyan'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Coda buffer is not being loaded / was not saved.'", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Coda buffer is not being loaded / was not saved.'", ",", "color", "=", "'yellow'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer.__init__": [[326, 366], ["mrl.replays.old_replay_buffer.OldReplayBuffer.__init__", "SpriteMaker"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "\n", "module_name", "=", "'replay_buffer'", ",", "\n", "max_coda_ratio", "=", "0.5", ",", "\n", "make_coda_data_every", "=", "1000", ",", "\n", "num_coda_source_transitions", "=", "5000", ",", "\n", "num_coda_source_pairs", "=", "2000", ",", "\n", "coda_samples_per_pair", "=", "5", ",", "\n", "coda_buffer_size", "=", "None", ",", "\n", "coda_on_goal_components", "=", "False", ",", "\n", "add_bad_dcs", "=", "False", ",", "\n", "spriteworld_config", "=", "None", ",", "\n", "reward_fn", "=", "None", ",", "# used for non-Spriteworld", "\n", "num_procs", "=", "8", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      max_coda_ratio: maximum ratio of coda:real data when sampling from the buffer\n      make_coda_data_every: how often to make coda data\n      num_coda_source_transitions: how many random pairs from the main buffer we should use to make coda samples\n      num_coda_source_pairs: using sampled transitions, how many source pairs should we form for doing CODA on?\n      coda_samples_per_pair: with each source pair, how many coda samples should we make? # NOTE: these are deduplicated, so it's upper bound\n      spriteworld_config: config for the spriteworld env\n      num_procs: num cpus to use for generating coda sample\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_coda_ratio", "=", "max_coda_ratio", "\n", "self", ".", "make_coda_data_every", "=", "make_coda_data_every", "\n", "self", ".", "num_coda_source_transitions", "=", "num_coda_source_transitions", "\n", "self", ".", "num_coda_source_pairs", "=", "num_coda_source_pairs", "\n", "self", ".", "coda_samples_per_pair", "=", "coda_samples_per_pair", "\n", "self", ".", "coda_buffer", "=", "None", "\n", "self", ".", "coda_buffer_size", "=", "coda_buffer_size", "\n", "self", ".", "add_bad_dcs", "=", "add_bad_dcs", "\n", "self", ".", "num_procs", "=", "num_procs", "\n", "self", ".", "reward_fn", "=", "reward_fn", "\n", "self", ".", "coda_on_goal_components", "=", "coda_on_goal_components", "\n", "\n", "self", ".", "spriteworld_config", "=", "spriteworld_config", "# NONE == This is not Spriteworld", "\n", "if", "spriteworld_config", "is", "not", "None", ":", "\n", "      ", "assert", "self", ".", "reward_fn", "is", "None", "\n", "self", ".", "state_to_sprites", "=", "SpriteMaker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer._setup": [[367, 402], ["super()._setup", "mrl.replays.core.replay_buffer.ReplayBuffer", "type", "enumerate", "enumerate", "coda_module.CodaOldBuffer.invert_batch_block_diag_mask[].append", "coda_module.CodaOldBuffer.invert_batch_block_diag_mask[].append", "coda_module.CodaOldBuffer.invert_batch_block_diag_mask_actions[].append", "coda_module.CodaOldBuffer.invert_batch_block_diag_mask_actions[].append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Keeps an separate, internal coda_buffer with coda experiences\n    \"\"\"", "\n", "\n", "super", "(", ")", ".", "_setup", "(", ")", "\n", "\n", "env", "=", "self", ".", "env", "\n", "if", "type", "(", "env", ".", "observation_space", ")", "==", "gym", ".", "spaces", ".", "Dict", ":", "\n", "      ", "observation_space", "=", "env", ".", "observation_space", ".", "spaces", "[", "\"observation\"", "]", "\n", "", "else", ":", "\n", "      ", "observation_space", "=", "env", ".", "observation_space", "\n", "\n", "", "items", "=", "[", "(", "\"state\"", ",", "observation_space", ".", "shape", ")", ",", "\n", "(", "\"action\"", ",", "env", ".", "action_space", ".", "shape", ")", ",", "(", "\"reward\"", ",", "(", "1", ",", ")", ")", ",", "\n", "(", "\"next_state\"", ",", "observation_space", ".", "shape", ")", ",", "(", "\"done\"", ",", "(", "1", ",", ")", ")", "]", "\n", "\n", "self", ".", "coda_buffer", "=", "Buffer", "(", "self", ".", "coda_buffer_size", "or", "self", ".", "size", ",", "items", ")", "\n", "\n", "assert", "self", ".", "config", ".", "never_done", "# TODO: Make this work in general case", "\n", "\n", "\n", "if", "not", "self", ".", "config", ".", "slot_based_state", "and", "self", ".", "config", ".", "slot_state_dims", ":", "\n", "      ", "self", ".", "invert_batch_block_diag_mask", "=", "(", "[", "]", ",", "[", "]", ")", "\n", "for", "i", ",", "state_dims", "in", "enumerate", "(", "self", ".", "config", ".", "slot_state_dims", ")", ":", "\n", "        ", "for", "state_dim", "in", "state_dims", ":", "\n", "          ", "self", ".", "invert_batch_block_diag_mask", "[", "0", "]", ".", "append", "(", "i", ")", "\n", "self", ".", "invert_batch_block_diag_mask", "[", "1", "]", ".", "append", "(", "state_dim", ")", "\n", "\n", "", "", "", "if", "self", ".", "config", ".", "slot_action_dims", ":", "\n", "      ", "self", ".", "invert_batch_block_diag_mask_actions", "=", "(", "[", "]", ",", "[", "]", ")", "\n", "for", "i", ",", "action_dims", "in", "enumerate", "(", "self", ".", "config", ".", "slot_action_dims", ")", ":", "\n", "        ", "for", "action_dim", "in", "action_dims", ":", "\n", "          ", "self", ".", "invert_batch_block_diag_mask_actions", "[", "0", "]", ".", "append", "(", "i", ")", "\n", "self", ".", "invert_batch_block_diag_mask_actions", "[", "1", "]", ".", "append", "(", "action_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer._optimize": [[403, 468], ["coda_module.CodaOldBuffer.buffer.sample", "experiments.coda.coda_generic.enlarge_dataset_generic", "numpy.ones", "numpy.zeros", "coda_module.CodaOldBuffer.coda_buffer.add_batch", "hasattr", "coda_module.CodaOldBuffer._optimize_spriteworld", "mrl.utils.misc.batch_block_diag_many", "mrl.utils.misc.batch_block_diag_many", "mrl.utils.misc.batch_block_diag_many", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.enlarge_dataset_generic", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer._optimize_spriteworld", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many"], ["", "", "", "", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Populates the internal coda_buffer using samples from the real buffer. \n    \"\"\"", "\n", "config", "=", "self", ".", "config", "\n", "if", "not", "(", "len", "(", "self", ")", "and", "config", ".", "opt_steps", "%", "self", ".", "make_coda_data_every", "==", "0", ")", ":", "\n", "      ", "return", "\n", "\n", "# return if too early", "\n", "", "if", "hasattr", "(", "self", ",", "'coda_attention_model'", ")", "and", "len", "(", "self", ")", "<", "config", ".", "min_experience_to_train_coda_attn", "+", "5000", ":", "\n", "      ", "return", "\n", "\n", "", "if", "self", ".", "spriteworld_config", "is", "not", "None", ":", "\n", "      ", "return", "self", ".", "_optimize_spriteworld", "(", ")", "\n", "\n", "", "sample", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "num_coda_source_transitions", ")", "\n", "states", ",", "actions", ",", "next_states", "=", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "sample", "[", "3", "]", "\n", "\n", "#og_state_set = set([tuple(s.flatten().round(2)) for s in states])", "\n", "\n", "# Convert states to the correct format", "\n", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_state_dims", ":", "\n", "      ", "state_slots", "=", "[", "states", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_state_dims", "]", "\n", "states", "=", "batch_block_diag_many", "(", "*", "state_slots", ")", "\n", "next_state_slots", "=", "[", "next_states", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_state_dims", "]", "\n", "next_states", "=", "batch_block_diag_many", "(", "*", "next_state_slots", ")", "\n", "\n", "", "if", "config", ".", "slot_action_dims", ":", "\n", "      ", "action_slots", "=", "[", "actions", "[", ":", ",", "s", "]", "[", ":", ",", "None", "]", "for", "s", "in", "config", ".", "slot_action_dims", "]", "\n", "actions", "=", "batch_block_diag_many", "(", "*", "action_slots", ")", "\n", "\n", "", "new_s1s", ",", "new_a1s", ",", "new_s2s", "=", "enlarge_dataset_generic", "(", "\n", "states", ",", "actions", ",", "next_states", ",", "\n", "self", ".", "num_coda_source_pairs", ",", "\n", "self", ".", "coda_samples_per_pair", ",", "\n", "batch_get_mask", "=", "self", ".", "get_coda_mask", ",", "\n", "pool", "=", "True", ",", "\n", "max_cpus", "=", "self", ".", "num_procs", ",", "\n", "add_bad_dcs", "=", "self", ".", "add_bad_dcs", ")", "\n", "\n", "if", "not", "len", "(", "new_s1s", ")", ":", "\n", "      ", "return", "\n", "\n", "", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_state_dims", ":", "\n", "      ", "new_s1s", "=", "new_s1s", "[", ":", ",", "self", ".", "invert_batch_block_diag_mask", "[", "0", "]", ",", "self", ".", "invert_batch_block_diag_mask", "[", "1", "]", "]", "\n", "new_s2s", "=", "new_s2s", "[", ":", ",", "self", ".", "invert_batch_block_diag_mask", "[", "0", "]", ",", "self", ".", "invert_batch_block_diag_mask", "[", "1", "]", "]", "\n", "\n", "", "if", "not", "config", ".", "slot_based_state", "and", "config", ".", "slot_action_dims", ":", "\n", "      ", "new_a1s", "=", "new_a1s", "[", ":", ",", "self", ".", "invert_batch_block_diag_mask_actions", "[", "0", "]", ",", "self", ".", "invert_batch_block_diag_mask_actions", "[", "1", "]", "]", "\n", "\n", "#remove duplicates of original data", "\n", "#valid_idxs = []", "\n", "#for i, s in enumerate(new_s1s):", "\n", "# if not (tuple(s.flatten().round(2)) in og_state_set):", "\n", "#   valid_idxs.append(i)", "\n", "#", "\n", "#new_s1s = new_s1s[valid_idxs]", "\n", "#new_a1s = new_a1s[valid_idxs]", "\n", "#new_s2s = new_s2s[valid_idxs]", "\n", "\n", "", "assert", "config", ".", "never_done", "\n", "r", "=", "np", ".", "ones", "(", "(", "len", "(", "new_s1s", ")", ",", "1", ")", ")", "\n", "d", "=", "np", ".", "zeros", "(", "(", "len", "(", "new_s1s", ")", ",", "1", ")", ")", "\n", "\n", "self", ".", "coda_buffer", ".", "add_batch", "(", "new_s1s", ",", "new_a1s", ",", "r", ",", "new_s2s", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer._optimize_spriteworld": [[469, 508], ["super().sample", "zip", "set", "experiments.coda.coda_generic.enlarge_dataset_spriteworld", "r.reshape.reshape.reshape", "numpy.zeros_like", "coda_module.CodaOldBuffer.coda_buffer.add_batch", "sprites_for_base_data.append", "set.append", "sars_data.append", "numpy.array", "coda_module.CodaOldBuffer.state_to_sprites", "tuple", "zip", "s.round", "tuple", "s.round"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_generic.enlarge_dataset_spriteworld", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_optimize_spriteworld", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Populates the internal coda_buffer using samples from the real buffer. \n    \"\"\"", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "_", "=", "super", "(", ")", ".", "sample", "(", "self", ".", "num_coda_source_transitions", ",", "to_torch", "=", "False", ")", "\n", "\n", "sprites_for_base_data", "=", "[", "]", "# TODO this is spriteworld specific", "\n", "og_state_set", "=", "[", "]", "\n", "sars_data", "=", "[", "]", "\n", "\n", "for", "s", ",", "a", ",", "r", ",", "s2", "in", "zip", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ")", ":", "\n", "      ", "sprites_for_base_data", ".", "append", "(", "self", ".", "state_to_sprites", "(", "s", ")", ")", "# TODO this is spriteworld specific", "\n", "og_state_set", ".", "append", "(", "tuple", "(", "s", ".", "round", "(", "2", ")", ")", ")", "\n", "sars_data", ".", "append", "(", "(", "s", ",", "(", "a", "+", "1.", ")", "/", "2.", ",", "r", ",", "s2", ")", ")", "# TODO the action part is spriteworld specific", "\n", "\n", "", "og_state_set", "=", "set", "(", "og_state_set", ")", "\n", "\n", "coda_data", "=", "enlarge_dataset_spriteworld", "(", "\n", "sars_data", ",", "\n", "sprites_for_base_data", ",", "\n", "self", ".", "spriteworld_config", ",", "# TODO this is spriteworld specific", "\n", "self", ".", "num_coda_source_pairs", ",", "\n", "self", ".", "coda_samples_per_pair", ",", "\n", "flattened", "=", "True", ",", "\n", "custom_get_mask", "=", "self", ".", "get_coda_mask", ",", "\n", "pool", "=", "True", ",", "\n", "max_cpus", "=", "self", ".", "num_procs", ")", "\n", "\n", "# remove duplicates of original data", "\n", "# TODO the action part in next line is spriteworld specific", "\n", "coda_data", "=", "[", "(", "s", ",", "(", "a", "*", "2", ")", "-", "1.", ",", "r", ",", "s2", ")", "for", "s", ",", "a", ",", "r", ",", "s2", "in", "coda_data", "if", "not", "tuple", "(", "s", ".", "round", "(", "2", ")", ")", "in", "og_state_set", "]", "\n", "s", ",", "a", ",", "r", ",", "s2", "=", "[", "np", ".", "array", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "coda_data", ")", "]", "\n", "r", "=", "r", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "assert", "self", ".", "config", ".", "never_done", "\n", "d", "=", "np", ".", "zeros_like", "(", "r", ")", "\n", "\n", "assert", "not", "self", ".", "goal_space", "# Don't use goal space with sprite world. ", "\n", "self", ".", "coda_buffer", ".", "add_batch", "(", "s", ",", "a", ",", "r", ",", "s2", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer.sample": [[509, 533], ["min", "numpy.random.multinomial", "coda_module.CodaOldBuffer.sample_coda", "super().sample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "super().sample", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer.sample_coda", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "sample", "(", "self", ",", "batch_size", ",", "to_torch", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Samples both from real buffer and from coda buffer and concatenates results.\n    \"\"\"", "\n", "assert", "(", "to_torch", ")", "\n", "\n", "coda_ratio", "=", "min", "(", "len", "(", "self", ".", "coda_buffer", ")", "/", "(", "len", "(", "self", ")", "+", "len", "(", "self", ".", "coda_buffer", ")", ")", ",", "self", ".", "max_coda_ratio", ")", "\n", "\n", "if", "coda_ratio", "<", "0.01", ":", "\n", "      ", "return", "super", "(", ")", ".", "sample", "(", "batch_size", ")", "\n", "\n", "", "coda_batch_size", ",", "real_batch_size", "=", "np", ".", "random", ".", "multinomial", "(", "batch_size", ",", "[", "coda_ratio", ",", "1.", "-", "coda_ratio", "]", ")", "\n", "\n", "coda_states", ",", "coda_actions", ",", "coda_rewards", ",", "coda_next_states", ",", "coda_gammas", "=", "self", ".", "sample_coda", "(", "coda_batch_size", ")", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", "=", "super", "(", ")", ".", "sample", "(", "real_batch_size", ")", "\n", "\n", "\n", "states", "=", "torch", ".", "cat", "(", "(", "states", ",", "coda_states", ")", ",", "0", ")", "\n", "actions", "=", "torch", ".", "cat", "(", "(", "actions", ",", "coda_actions", ")", ",", "0", ")", "\n", "rewards", "=", "torch", ".", "cat", "(", "(", "rewards", ",", "coda_rewards", ")", ",", "0", ")", "\n", "next_states", "=", "torch", ".", "cat", "(", "(", "next_states", ",", "coda_next_states", ")", ",", "0", ")", "\n", "gammas", "=", "torch", ".", "cat", "(", "(", "gammas", ",", "coda_gammas", ")", ",", "0", ")", "\n", "\n", "return", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer.sample_coda": [[534, 592], ["coda_module.CodaOldBuffer.coda_buffer.sample", "numpy.all", "hasattr", "hasattr", "numpy.logical_not", "numpy.random.randint", "dg_buffer.get_batch", "numpy.random.randint", "ag_buffer.get_batch", "numpy.concatenate", "coda_module.CodaOldBuffer.reward_fn", "coda_module.CodaOldBuffer.done_fn", "coda_module.CodaOldBuffer.state_normalizer().astype", "coda_module.CodaOldBuffer.state_normalizer().astype", "len", "len", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "coda_module.CodaOldBuffer.reward_fn", "coda_module.CodaOldBuffer.torch", "coda_module.CodaOldBuffer.torch", "coda_module.CodaOldBuffer.torch", "coda_module.CodaOldBuffer.torch", "coda_module.CodaOldBuffer.torch", "numpy.random.shuffle", "coda_module.CodaOldBuffer.state_normalizer", "coda_module.CodaOldBuffer.state_normalizer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch"], ["", "def", "sample_coda", "(", "self", ",", "batch_size", ",", "to_torch", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Samples from coda_buffer (no real data).\n    \"\"\"", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", "=", "self", ".", "coda_buffer", ".", "sample", "(", "batch_size", ")", "\n", "\n", "assert", "np", ".", "all", "(", "np", ".", "logical_not", "(", "dones", ")", ")", "\n", "\n", "# Reward relabeling", "\n", "if", "self", ".", "goal_space", "is", "not", "None", ":", "\n", "      ", "assert", "self", ".", "reward_fn", "is", "not", "None", "\n", "\n", "dg_buffer", "=", "self", ".", "buffer", ".", "BUFF", ".", "buffer_dg", "\n", "dg_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "dg_buffer", ")", ",", "size", "=", "(", "batch_size", "//", "2", ",", ")", ")", "\n", "dgs", "=", "dg_buffer", ".", "get_batch", "(", "dg_idxs", ")", "\n", "\n", "ag_buffer", "=", "self", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "ag_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "ag_buffer", ")", ",", "size", "=", "(", "batch_size", "-", "batch_size", "//", "2", ",", ")", ")", "\n", "ags", "=", "ag_buffer", ".", "get_batch", "(", "ag_idxs", ")", "\n", "\n", "goals", "=", "np", ".", "concatenate", "(", "(", "dgs", ",", "ags", ")", ",", "axis", "=", "0", ")", "\n", "\n", "if", "self", ".", "coda_on_goal_components", ":", "\n", "        ", "goal_components", "=", "[", "goals", "[", ":", ",", "i", "]", "for", "i", "in", "self", ".", "config", ".", "slot_goal_dims", "]", "\n", "[", "np", ".", "random", ".", "shuffle", "(", "g", ")", "for", "g", "in", "goal_components", "]", "\n", "goals", "=", "np", ".", "concatenate", "(", "goal_components", ",", "axis", "=", "1", ")", "\n", "\n", "", "rewards", "=", "self", ".", "reward_fn", "(", "states", ",", "actions", ",", "next_states", ",", "goals", ")", "\n", "\n", "if", "self", ".", "config", ".", "slot_based_state", ":", "\n", "# TODO: For now, we flatten according to config.slot_state_dims", "\n", "        ", "I", ",", "J", "=", "self", ".", "config", ".", "slot_state_dims", "\n", "states", "=", "np", ".", "concatenate", "(", "(", "states", "[", ":", ",", "I", ",", "J", "]", ",", "goals", ")", ",", "-", "1", ")", "\n", "next_states", "=", "np", ".", "concatenate", "(", "(", "next_states", "[", ":", ",", "I", ",", "J", "]", ",", "goals", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "states", "=", "np", ".", "concatenate", "(", "(", "states", ",", "goals", ")", ",", "-", "1", ")", "\n", "next_states", "=", "np", ".", "concatenate", "(", "(", "next_states", ",", "goals", ")", ",", "-", "1", ")", "\n", "\n", "", "", "elif", "self", ".", "reward_fn", "is", "not", "None", ":", "\n", "      ", "rewards", "=", "self", ".", "reward_fn", "(", "states", ",", "actions", ",", "next_states", ")", "\n", "\n", "", "else", ":", "\n", "# This is spriteworld and things have already been relabeled", "\n", "      ", "assert", "self", ".", "spriteworld_config", "is", "not", "None", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'done_fn'", ")", ":", "\n", "      ", "dones", "=", "self", ".", "done_fn", "(", "states", ",", "actions", ",", "next_states", ")", "\n", "\n", "", "gammas", "=", "self", ".", "config", ".", "gamma", "*", "(", "1", "-", "dones", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "states", "=", "self", ".", "state_normalizer", "(", "states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "next_states", "=", "self", ".", "state_normalizer", "(", "next_states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "to_torch", ":", "\n", "      ", "return", "(", "self", ".", "torch", "(", "states", ")", ",", "self", ".", "torch", "(", "actions", ")", ",", "self", ".", "torch", "(", "rewards", ")", ",", "self", ".", "torch", "(", "next_states", ")", ",", "self", ".", "torch", "(", "gammas", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer.save": [[593, 602], ["coda_module.CodaOldBuffer.buffer._get_state", "coda_module.CodaOldBuffer.coda_buffer._get_state", "open", "pickle.dump", "open", "pickle.dump", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state", "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "if", "self", ".", "config", ".", "save_replay_buf", "or", "self", ".", "save_buffer", ":", "\n", "      ", "state", "=", "self", ".", "buffer", ".", "_get_state", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "state", ",", "f", ")", "\n", "\n", "", "state", "=", "self", ".", "coda_buffer", ".", "_get_state", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", "+", "'_coda'", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "state", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.coda_module.CodaOldBuffer.load": [[603, 627], ["os.path.join", "os.path.exists", "os.path.join", "os.path.exists", "coda_module.CodaOldBuffer.buffer._set_state", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.coda_buffer._set_state", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "coda_module.CodaOldBuffer.logger.log_color", "open", "pickle.load", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "load_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "      ", "with", "open", "(", "load_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "buffer", ".", "_set_state", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'cyan'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'yellow'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "\n", "", "load_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", "+", "'_coda'", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "      ", "with", "open", "(", "load_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "coda_buffer", ".", "_set_state", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Coda buffer is not being loaded / was not saved.'", ",", "color", "=", "'cyan'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Coda buffer is not being loaded / was not saved.'", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Coda buffer is not being loaded / was not saved.'", ",", "color", "=", "'yellow'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.coda.train_coda.make_disentangled_fetch_env": [[27, 45], ["numpy.concatenate().astype", "numpy.arange", "envstr.lower", "gym.make", "gym.wrappers.TimeLimit", "envstr.lower", "gym.make", "numpy.concatenate", "envs.customfetch.custom_fetch.DisentangledFetchPushEnv", "gym.wrappers.TimeLimit", "envstr.lower", "envs.customfetch.custom_fetch.DisentangledFetchSlideEnv", "envs.customfetch.custom_fetch.DisentangledFetchPickAndPlaceEnv", "gym.wrappers.TimeLimit", "gym.wrappers.TimeLimit", "numpy.zeros", "numpy.ones", "envs.customfetch.custom_fetch.DisentangledFetchSlideEnv", "envs.customfetch.custom_fetch.DisentangledFetchSlideEnv"], "function", ["None"], ["def", "make_disentangled_fetch_env", "(", "envstr", ")", ":", "\n", "  ", "if", "'push'", "in", "envstr", ".", "lower", "(", ")", ":", "\n", "    ", "env", "=", "lambda", ":", "TimeLimit", "(", "DisentangledFetchPushEnv", "(", ")", ",", "50", ")", "\n", "eval_env", "=", "env", "\n", "dummy_env", "=", "gym", ".", "make", "(", "'FetchPush-v1'", ")", "\n", "", "elif", "'pick'", "in", "envstr", ".", "lower", "(", ")", ":", "\n", "    ", "env", "=", "lambda", ":", "TimeLimit", "(", "DisentangledFetchPickAndPlaceEnv", "(", ")", ",", "50", ")", "\n", "eval_env", "=", "env", "\n", "dummy_env", "=", "gym", ".", "make", "(", "'FetchPickAndPlace-v1'", ")", "\n", "", "elif", "'slide'", "in", "envstr", ".", "lower", "(", ")", ":", "\n", "    ", "env", "=", "lambda", ":", "TimeLimit", "(", "DisentangledFetchSlideEnv", "(", ")", ",", "50", ")", "\n", "eval_env", "=", "lambda", ":", "TimeLimit", "(", "DisentangledFetchSlideEnv", "(", ")", ",", "50", ")", "\n", "dummy_env", "=", "DisentangledFetchSlideEnv", "(", ")", "\n", "\n", "", "I", "=", "np", ".", "concatenate", "(", "(", "np", ".", "zeros", "(", "10", ")", ",", "np", ".", "ones", "(", "12", ")", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "J", "=", "np", ".", "arange", "(", "22", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "state_dims", "=", "(", "I", ",", "J", ")", "\n", "return", "env", ",", "eval_env", ",", "dummy_env", ",", "state_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.coda.train_coda.main": [[47, 250], ["merge_args_into_config", "make_agent_name", "config.update", "torch.set_num_threads", "torch.set_num_interop_threads", "EnvModule", "EnvModule", "PytorchModel", "PytorchModel", "mrl.config_to_agent", "max", "dict", "min", "min", "gym.envs.registry.env_specs.get", "type", "hasattr", "len", "experiments.coda.coda_module.CodaBuffer", "os.path.exists", "print", "mrl.config_to_agent.load", "mrl.config_to_agent.eval_mode", "env.reset", "range", "max", "numpy.mean", "mrl.config_to_agent.logger.log_color", "range", "numpy.round", "numpy.round", "args.envstr.lower", "train_coda.make_disentangled_fetch_env", "gym.make", "Actor", "Critic", "os.path.join", "mrl.config_to_agent.load_from_checkpoint", "env.render", "time.sleep", "mrl.config_to_agent.policy", "env.step", "env.render", "print", "int", "time.time", "mrl.config_to_agent.train", "numpy.mean", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.logger.log_color", "print", "mrl.config_to_agent.save", "multiprocessing.cpu_count", "StandardTrain", "EpisodicEval", "ActorPolicy", "Logger", "Normalizer", "OnlineHERBuffer", "ContinuousActionNoise", "DDPG", "args.envstr.lower", "int", "envs.customfetch.custom_fetch.SlideNEnv", "FCBody", "FCBody", "min", "mrl.config_to_agent.eval", "numpy.random.choice", "numpy.arange", "s1_buff.get_batch", "numpy.concatenate", "mrl.config_to_agent.logger.add_embedding", "s2_buff.get_batch", "numpy.concatenate", "mrl.config_to_agent.logger.add_embedding", "s1_coda.get_batch", "numpy.concatenate", "mrl.config_to_agent.logger.add_embedding", "s2_coda.get_batch", "numpy.concatenate", "mrl.config_to_agent.logger.add_embedding", "s1_buff.get_batch", "numpy.concatenate", "mrl.config_to_agent.logger.add_embedding", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.save_checkpoint", "MeanStdNormalizer", "numpy.arange", "envs.customfetch.custom_fetch.PushNEnv.compute_reward", "args.envstr.lower().replace", "envs.customfetch.custom_fetch.SlideNEnv", "envs.customfetch.custom_fetch.SlideNEnv", "experiments.coda.sandy_module.SimpleStackedAttn", "experiments.coda.sandy_module.CodaAttentionBasedMask", "args.envstr.lower", "int", "envs.customfetch.custom_fetch.PushNEnv", "functools.partial", "NotImplementedError", "len", "max", "len", "mrl.config_to_agent.eval", "len", "ConstantSchedule", "numpy.arange", "range", "envs.customfetch.custom_fetch.PushNEnv.compute_reward", "args.envstr.lower().replace", "envs.customfetch.custom_fetch.PushNEnv", "envs.customfetch.custom_fetch.PushNEnv", "min", "time.time", "args.envstr.lower", "envs.customfetch.custom_fetch.PushNEnv.compute_reward", "len", "len", "args.envstr.lower"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.merge_args_into_config", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_agent_name", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.coda.train_coda.make_disentangled_fetch_env", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.load_from_checkpoint", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.save_checkpoint", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "  ", "if", "args", ".", "num_envs", "is", "None", ":", "\n", "    ", "import", "multiprocessing", "as", "mp", "\n", "args", ".", "num_envs", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "1", ")", "\n", "\n", "# hard code num_eval envs...", "\n", "", "args", ".", "num_eval_envs", "=", "args", ".", "num_envs", "\n", "\n", "merge_args_into_config", "(", "args", ",", "config", ")", "\n", "config", ".", "min_experience_to_train_coda_attn", "=", "args", ".", "min_experience_to_train_coda_attn", "\n", "if", "config", ".", "gamma", "<", "1.", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "(", "1", "/", "(", "1", "-", "config", ".", "gamma", ")", ")", ",", "2", ")", ",", "0.", ")", "\n", "if", "config", ".", "gamma", "==", "1", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "args", ".", "env_max_step", "-", "5", ",", "2", ")", ",", "0.", ")", "\n", "\n", "config", ".", "agent_name", "=", "make_agent_name", "(", "config", ",", "[", "\n", "'envstr'", ",", "'alg'", ",", "'her'", ",", "'relabel_type'", ",", "'seed'", ",", "'tb'", ",", "'max_coda_ratio'", ",", "'coda_every'", ",", "'coda_source_pairs'", ",", "\n", "'batch_size'", ",", "'optimize_every'", "\n", "]", ",", "\n", "prefix", "=", "args", ".", "prefix", ")", "\n", "\n", "# 5. Setup / add basic modules to the config", "\n", "config", ".", "update", "(", "\n", "dict", "(", "trainer", "=", "StandardTrain", "(", ")", ",", "\n", "evaluation", "=", "EpisodicEval", "(", ")", ",", "\n", "policy", "=", "ActorPolicy", "(", ")", ",", "\n", "logger", "=", "Logger", "(", ")", ",", "\n", "state_normalizer", "=", "Normalizer", "(", "MeanStdNormalizer", "(", ")", ")", ",", "\n", "replay", "=", "OnlineHERBuffer", "(", ")", ",", "\n", "action_noise", "=", "ContinuousActionNoise", "(", "GaussianProcess", ",", "std", "=", "ConstantSchedule", "(", "args", ".", "action_noise", ")", ")", ",", "\n", "algorithm", "=", "DDPG", "(", ")", ")", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "4", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "if", "gym", ".", "envs", ".", "registry", ".", "env_specs", ".", "get", "(", "args", ".", "envstr", ")", "is", "not", "None", ":", "\n", "    ", "args", ".", "env", "=", "args", ".", "envstr", "\n", "dummy_env_config", "=", "None", "\n", "reward_fn", "=", "None", "\n", "", "elif", "'disentangled'", "in", "args", ".", "envstr", ".", "lower", "(", ")", ":", "\n", "    ", "args", ".", "env", ",", "args", ".", "eval_env", ",", "dummy_env", ",", "state_dims", "=", "make_disentangled_fetch_env", "(", "args", ".", "envstr", ")", "\n", "config", ".", "slot_state_dims", "=", "[", "np", ".", "arange", "(", "10", ")", "]", "+", "[", "10", "+", "12", "*", "i", "+", "np", ".", "arange", "(", "12", ")", "for", "i", "in", "range", "(", "1", ")", "]", "\n", "config", ".", "slot_action_dims", "=", "None", "\n", "dummy_env_config", "=", "None", "\n", "reward_fn", "=", "lambda", "s", ",", "a", ",", "ns", ",", "g", ":", "dummy_env", ".", "compute_reward", "(", "ns", "[", ":", ",", "10", ":", "13", "]", ",", "g", ",", "None", ")", "[", ":", ",", "None", "]", "\n", "\n", "", "elif", "'slide'", "in", "args", ".", "envstr", ".", "lower", "(", ")", ":", "\n", "    ", "n", "=", "int", "(", "args", ".", "envstr", ".", "lower", "(", ")", ".", "replace", "(", "'slide'", ",", "''", ")", ")", "\n", "args", ".", "env", "=", "lambda", ":", "SlideNEnv", "(", "n", "=", "n", ",", "distance_threshold", "=", "args", ".", "train_dt", ")", "\n", "args", ".", "eval_env", "=", "lambda", ":", "SlideNEnv", "(", "n", "=", "n", ")", "\n", "dummy_env_config", "=", "None", "\n", "dummy_env", "=", "SlideNEnv", "(", "n", "=", "n", ")", "\n", "reward_fn", "=", "lambda", "s", ",", "a", ",", "ns", ",", "g", ":", "dummy_env", ".", "compute_reward", "(", "ns", "[", ":", ",", "dummy_env", ".", "ag_dims", "]", ",", "g", ",", "None", ")", "[", ":", ",", "None", "]", "\n", "config", ".", "slot_state_dims", "=", "dummy_env", ".", "disentangled_idxs", "\n", "config", ".", "slot_action_dims", "=", "None", "\n", "config", ".", "slot_goal_dims", "=", "dummy_env", ".", "disentangled_goal_idxs", "\n", "\n", "if", "args", ".", "relabel_type", "==", "'online_attn'", ":", "\n", "      ", "model", "=", "SimpleStackedAttn", "(", "10", "+", "12", "*", "n", "+", "4", ",", "\n", "10", "+", "12", "*", "n", ",", "\n", "num_attn_blocks", "=", "2", ",", "\n", "num_hidden_layers", "=", "2", ",", "\n", "num_hidden_units", "=", "128", ",", "\n", "num_heads", "=", "5", ")", "\n", "config", ".", "mask_module", "=", "CodaAttentionBasedMask", "(", "model", "=", "model", ",", "optimize_every", "=", "2", ",", "batch_size", "=", "512", ")", "\n", "", "", "elif", "'push'", "in", "args", ".", "envstr", ".", "lower", "(", ")", ":", "\n", "    ", "n", "=", "int", "(", "args", ".", "envstr", ".", "lower", "(", ")", ".", "replace", "(", "'push'", ",", "''", ")", ")", "\n", "args", ".", "env", "=", "lambda", ":", "PushNEnv", "(", "n", "=", "n", ",", "distance_threshold", "=", "args", ".", "train_dt", ")", "\n", "args", ".", "eval_env", "=", "lambda", ":", "PushNEnv", "(", "n", "=", "n", ")", "\n", "dummy_env_config", "=", "None", "\n", "dummy_env", "=", "PushNEnv", "(", "n", "=", "n", ")", "\n", "reward_fn", "=", "lambda", "s", ",", "a", ",", "ns", ",", "g", ":", "dummy_env", ".", "compute_reward", "(", "ns", "[", ":", ",", "dummy_env", ".", "ag_dims", "]", ",", "g", ",", "None", ")", "[", ":", ",", "None", "]", "\n", "config", ".", "slot_state_dims", "=", "dummy_env", ".", "disentangled_idxs", "\n", "config", ".", "slot_goal_dims", "=", "dummy_env", ".", "disentangled_goal_idxs", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n", "", "if", "type", "(", "args", ".", "env", ")", "is", "str", ":", "\n", "    ", "env", "=", "lambda", ":", "gym", ".", "make", "(", "args", ".", "env", ")", "\n", "", "else", ":", "\n", "    ", "env", "=", "args", ".", "env", "\n", "\n", "", "config", ".", "module_train_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "config", ".", "num_envs", ",", "seed", "=", "config", ".", "seed", ")", "\n", "config", ".", "module_eval_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "config", ".", "num_eval_envs", ",", "name", "=", "'eval_env'", ",", "seed", "=", "config", ".", "seed", "+", "1138", ")", "\n", "\n", "e", "=", "config", ".", "module_eval_env", "\n", "if", "config", ".", "slot_based_state", "and", "hasattr", "(", "config", ",", "'slot_state_dims'", ")", ":", "\n", "    ", "e", ".", "state_dim", "=", "len", "(", "config", ".", "slot_state_dims", "[", "0", "]", ")", "\n", "", "config", ".", "actor", "=", "PytorchModel", "(", "\n", "'actor'", ",", "lambda", ":", "Actor", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ")", ",", "e", ".", "action_dim", ",", "e", ".", "max_action", ")", ")", "\n", "config", ".", "critic", "=", "PytorchModel", "(", "\n", "'critic'", ",", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ")", ",", "1", ")", ")", "\n", "\n", "if", "e", ".", "goal_env", ":", "\n", "    ", "config", ".", "never_done", "=", "True", "# NOTE: This is important in the standard Goal environments, which are never done", "\n", "\n", "# add Coda buffer if using Coda", "\n", "", "if", "args", ".", "relabel_type", "is", "not", "None", ":", "\n", "    ", "del", "config", ".", "replay", "\n", "config", ".", "module_replay", "=", "CodaBuffer", "(", "max_coda_ratio", "=", "args", ".", "max_coda_ratio", ",", "\n", "make_coda_data_every", "=", "args", ".", "coda_every", ",", "\n", "num_coda_source_transitions", "=", "20000", ",", "\n", "num_coda_source_pairs", "=", "args", ".", "coda_source_pairs", ",", "\n", "coda_samples_per_pair", "=", "args", ".", "coda_samples_per_pair", ",", "\n", "coda_buffer_size", "=", "args", ".", "coda_buffer_size", ",", "\n", "add_bad_dcs", "=", "args", ".", "add_bad_dcs", ",", "\n", "coda_on_goal_components", "=", "args", ".", "coda_on_goal_components", ",", "\n", "spriteworld_config", "=", "dummy_env_config", ",", "\n", "reward_fn", "=", "reward_fn", ",", "\n", "num_procs", "=", "min", "(", "args", ".", "num_envs", ",", "4", ")", ")", "\n", "\n", "", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "# set up get_coda_mask function", "\n", "if", "args", ".", "relabel_type", "is", "not", "None", ":", "\n", "    ", "if", "args", ".", "relabel_type", "==", "'ground_truth'", ":", "\n", "      ", "agent", ".", "get_coda_mask", "=", "get_true_abstract_mask_spriteworld", "\n", "", "elif", "args", ".", "relabel_type", "==", "'push_heuristic'", ":", "\n", "      ", "agent", ".", "get_coda_mask", "=", "batch_get_heuristic_mask_fetchpush", "\n", "", "elif", "args", ".", "relabel_type", "==", "'online_attn'", ":", "\n", "      ", "agent", ".", "get_coda_mask", "=", "partial", "(", "agent", ".", "coda_attention_model", ".", "get_mask", ",", "THRESH", "=", "args", ".", "thresh", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "", "if", "args", ".", "checkpoint_dir", "is", "not", "None", ":", "\n", "# If a checkpoint has been initialized load it.", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "'INITIALIZED'", ")", ")", ":", "\n", "      ", "agent", ".", "load_from_checkpoint", "(", "args", ".", "checkpoint_dir", ")", "\n", "\n", "", "", "if", "args", ".", "visualize_trained_agent", ":", "\n", "    ", "print", "(", "\"Loading agent at epoch {}\"", ".", "format", "(", "0", ")", ")", "\n", "agent", ".", "load", "(", "'checkpoint'", ")", "\n", "\n", "agent", ".", "eval_mode", "(", ")", "\n", "env", "=", "agent", ".", "eval_env", "\n", "state", "=", "env", ".", "reset", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "1000000", ")", ":", "\n", "      ", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "0.02", ")", "\n", "action", "=", "agent", ".", "policy", "(", "state", ")", "\n", "state", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "env", ".", "render", "(", ")", "\n", "print", "(", "reward", "[", "0", "]", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "    ", "if", "args", ".", "save_embeddings", ":", "\n", "      ", "s1_buff", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_state", "\n", "s2_buff", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_next_state", "\n", "s1_coda", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'state'", "]", "\n", "s2_coda", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'next_state'", "]", "\n", "\n", "", "num_eps", "=", "max", "(", "args", ".", "num_eval_envs", "*", "3", ",", "10", ")", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "f'Initial test reward ({num_eps} eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "      ", "t", "=", "time", ".", "time", "(", ")", "\n", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ")", "\n", "\n", "# VIZUALIZE GOALS", "\n", "if", "args", ".", "save_embeddings", ":", "\n", "        ", "idxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "s1_buff", ")", ",", "size", "=", "min", "(", "len", "(", "s1_buff", ")", ",", "1000", ")", ",", "replace", "=", "False", ")", "\n", "last_idxs", "=", "np", ".", "arange", "(", "max", "(", "0", ",", "len", "(", "s1_buff", ")", "-", "args", ".", "epoch_len", ")", ",", "len", "(", "s1_buff", ")", ")", "\n", "\n", "rands1", "=", "s1_buff", ".", "get_batch", "(", "idxs", ")", "\n", "rands1", "=", "np", ".", "concatenate", "(", "(", "rands1", "[", ":", ",", "0", ",", ":", "3", "]", ",", "rands1", "[", ":", ",", "1", ",", "10", ":", "13", "]", ")", ",", "1", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'rand_s1s'", ",", "rands1", ")", "\n", "\n", "rands1", "=", "s2_buff", ".", "get_batch", "(", "idxs", ")", "\n", "rands1", "=", "np", ".", "concatenate", "(", "(", "rands1", "[", ":", ",", "0", ",", ":", "3", "]", ",", "rands1", "[", ":", ",", "1", ",", "10", ":", "13", "]", ")", ",", "1", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'rand_s2s'", ",", "rands1", ")", "\n", "\n", "rands1", "=", "s1_coda", ".", "get_batch", "(", "idxs", ")", "\n", "rands1", "=", "np", ".", "concatenate", "(", "(", "rands1", "[", ":", ",", "0", ",", ":", "3", "]", ",", "rands1", "[", ":", ",", "1", ",", "10", ":", "13", "]", ")", ",", "1", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'rand_coda1s'", ",", "rands1", ")", "\n", "\n", "rands1", "=", "s2_coda", ".", "get_batch", "(", "idxs", ")", "\n", "rands1", "=", "np", ".", "concatenate", "(", "(", "rands1", "[", ":", ",", "0", ",", ":", "3", "]", ",", "rands1", "[", ":", ",", "1", ",", "10", ":", "13", "]", ")", ",", "1", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'rand_coda2s'", ",", "rands1", ")", "\n", "\n", "rands1", "=", "s1_buff", ".", "get_batch", "(", "last_idxs", ")", "\n", "rands1", "=", "np", ".", "concatenate", "(", "(", "rands1", "[", ":", ",", "0", ",", ":", "3", "]", ",", "rands1", "[", ":", ",", "1", ",", "10", ":", "13", "]", ")", ",", "1", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'last_s1s'", ",", "rands1", ")", "\n", "\n", "# EVALUATE", "\n", "", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "num_eps", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "f'Test reward ({num_eps} eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n", "if", "args", ".", "relabel_type", "is", "not", "None", ":", "\n", "        ", "agent", ".", "logger", ".", "log_color", "(", "'Coda buffer size:'", ",", "len", "(", "agent", ".", "replay_buffer", ".", "coda_buffer", ")", ")", "\n", "\n", "", "print", "(", "\"Saving agent at epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "agent", ".", "save", "(", "'checkpoint'", ")", "\n", "\n", "# Also save to checkpoint if a checkpoint_dir is specified.", "\n", "if", "args", ".", "checkpoint_dir", "is", "not", "None", ":", "\n", "        ", "agent", ".", "save_checkpoint", "(", "args", ".", "checkpoint_dir", ")", "\n", "\n", "# Quit if env_steps > max_steps (since epoch counter starts anew once we reload from checkpoint)", "\n", "", "if", "agent", ".", "config", ".", "env_steps", ">", "args", ".", "max_steps", ":", "\n", "        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_experiment.run_pong_experiment": [[8, 38], ["experiments.coda.pong.collect_real_data.collect_real_data", "experiments.coda.pong.train_batchrl_agent.train_batchrl_agent", "experiments.coda.pong.make_mbpo_data.make_dyna_data", "experiments.coda.pong.make_dyna_data.make_dyna_data", "experiments.coda.pong.make_coda_data.make_coda_data", "experiments.coda.pong.make_coda_data.make_coda_data", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.collect_real_data.collect_real_data", "home.repos.pwc.inspect_result.spitis_mrl.pong.train_batchrl_agent.train_batchrl_agent", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.make_dyna_data", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.make_dyna_data", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.make_coda_data", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.make_coda_data"], ["def", "run_pong_experiment", "(", "args", ")", ":", "\n", "  ", "dataset", "=", "collect_real_data", "(", "args", ".", "num_real_samples", ",", "seed", "=", "args", ".", "seed", ",", "noise_level", "=", "args", ".", "noise_level", ")", "\n", "reward_fn", "=", "None", "\n", "amt_real_data", "=", "None", "\n", "\n", "if", "args", ".", "num_mbpo_samples", ">", "0", ":", "\n", "\n", "    ", "if", "args", ".", "use_3x_coda_to_train_mbpo", ":", "\n", "# First expand the dataset using CoDA so can train a better MBPO model", "\n", "      ", "dataset", "=", "make_coda_data", "(", "dataset", ",", "3", "*", "args", ".", "num_real_samples", ",", "seed", "=", "args", ".", "seed", "+", "123", ")", "\n", "\n", "", "dataset", ",", "reward_fn", "=", "make_mbpo_data", "(", "dataset", ",", "args", ".", "num_mbpo_samples", ",", "args", ".", "num_step_rollouts", ",", "seed", "=", "args", ".", "seed", ")", "\n", "\n", "if", "args", ".", "use_3x_coda_to_train_mbpo", ":", "\n", "# But take out the original CoDA data---we will remake it after the MBPO data is made", "\n", "      ", "dataset", "=", "[", "np", ".", "concatenate", "(", "(", "x", "[", ":", "args", ".", "num_real_samples", "]", ",", "x", "[", "4", "*", "args", ".", "num_real_samples", ":", "4", "*", "args", ".", "num_real_samples", "+", "args", ".", "num_mbpo_samples", "]", ")", ")", "for", "x", "in", "dataset", "]", "\n", "\n", "", "amt_real_data", "=", "args", ".", "num_real_samples", "\n", "\n", "", "if", "args", ".", "num_dyna_samples", ">", "0", ":", "\n", "    ", "assert", "args", ".", "num_coda_samples", "==", "0", "\n", "assert", "args", ".", "num_mbpo_samples", "==", "0", "\n", "dataset", "=", "make_dyna_data", "(", "dataset", ",", "args", ".", "num_dyna_samples", ",", "args", ".", "num_step_rollouts", ",", "seed", "=", "args", ".", "seed", ")", "\n", "", "else", ":", "\n", "    ", "dataset", "=", "make_coda_data", "(", "dataset", ",", "args", ".", "num_coda_samples", ",", "seed", "=", "args", ".", "seed", ",", "amt_real_data", "=", "amt_real_data", ",", "reward_fn", "=", "reward_fn", ")", "\n", "\n", "", "mbpo", "=", "args", ".", "num_mbpo_samples", "if", "not", "args", ".", "use_3x_coda_to_train_mbpo", "else", "0", "\n", "c3xm", "=", "args", ".", "num_mbpo_samples", "if", "args", ".", "use_3x_coda_to_train_mbpo", "else", "0", "\n", "\n", "train_batchrl_agent", "(", "dataset", ",", "f'batchrl_real{args.num_real_samples}_coda{args.num_coda_samples}_dyna{args.num_dyna_samples}_mbpo{mbpo}_c3xm{c3xm}_roll{args.num_step_rollouts}_noise{args.noise_level}_{args.tag}'", ",", "num_steps", "=", "args", ".", "num_steps", ",", "seed", "=", "args", ".", "seed", ",", "results_folder", "=", "args", ".", "parent_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_mbpo_data.blockPrint": [[15, 17], ["open"], "function", ["None"], ["def", "blockPrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "open", "(", "os", ".", "devnull", ",", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_mbpo_data.enablePrint": [[18, 20], ["None"], "function", ["None"], ["", "def", "enablePrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "sys", ".", "__stdout__", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_mbpo_data.make_env": [[21, 23], ["experiments.coda.pong.pong_env.CustomPong"], "function", ["None"], ["", "def", "make_env", "(", ")", ":", "\n", "  ", "return", "CustomPong", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_mbpo_data.ground_truth_compute_reward": [[24, 38], ["numpy.zeros_like", "np.zeros_like.reshape"], "function", ["None"], ["", "def", "ground_truth_compute_reward", "(", "s", ",", "a", ",", "ns", ")", ":", "\n", "  ", "p0x", "=", "ns", "[", ":", ",", "0", "]", "\n", "p1x", "=", "ns", "[", ":", ",", "4", "]", "\n", "bx", "=", "ns", "[", ":", ",", "8", "]", "\n", "\n", "absbx", "=", "bx", "*", "2.1", "\n", "absp0x", "=", "p0x", "*", "0.3", "-", "1.3", "\n", "absp1x", "=", "p1x", "*", "0.3", "+", "1.3", "\n", "\n", "r", "=", "np", ".", "zeros_like", "(", "p0x", ")", "\n", "\n", "r", "[", "absbx", ">=", "absp1x", "]", "=", "1.", "\n", "r", "[", "absbx", "<=", "absp0x", "]", "=", "-", "1.", "\n", "return", "r", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_mbpo_data.make_dyna_data": [[39, 140], ["print", "make_mbpo_data.blockPrint", "make_sac_agent", "experiments.coda.coda_module.CodaOldBuffer", "MBPOModel", "mrl.config_to_agent", "PongClassifierRewardModel", "mrl.config_to_agent.set_module", "make_mbpo_data.enablePrint", "print", "mrl.config_to_agent.replay_buffer.buffer.add_batch", "print", "tqdm.tqdm", "print", "print", "min", "print", "print", "len", "spinning_up_sac_config", "SimpleMLP", "SimpleMLP", "range", "attn_losses.append", "rew_losses.append", "numpy.mean", "len", "make_mbpo_data.sample_dyna_batch", "mrl.config_to_agent.replay_buffer.coda_buffer.add_batch", "len", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "AttrDict", "mrl.config_to_agent.coda_attention_model._optimize", "mrl.config_to_agent.reward_module._optimize", "mrl.config_to_agent.replay_buffer.buffer.sample", "numpy.mean", "print", "range", "attn_losses.append", "mrl.config_to_agent.coda_attention_model._optimize"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.blockPrint", "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_sac_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.set_module", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.enablePrint", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_sac_config", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.sample_dyna_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize"], ["", "def", "make_dyna_data", "(", "real_dataset", ",", "dyna_data", ",", "num_step_rollouts", "=", "5", ",", "seed", "=", "0", ")", ":", "\n", "  ", "dataset", "=", "real_dataset", "\n", "if", "dyna_data", "==", "0", ":", "\n", "    ", "print", "(", "\"Did not make any Dyna data!\"", ")", "\n", "return", "real_dataset", "\n", "\n", "", "assert", "len", "(", "dataset", "[", "0", "]", ")", ">=", "10000", ",", "\"Need at least 10K real samples!\"", "\n", "\n", "print", "(", "\"Making a dummy agent... \"", ",", "end", "=", "''", ")", "\n", "\n", "blockPrint", "(", ")", "\n", "\n", "config", "=", "make_sac_agent", "(", "spinning_up_sac_config", "(", ")", ",", "args", "=", "AttrDict", "(", "\n", "parent_folder", "=", "'/tmp/make_coda_data'", ",", "\n", "env", "=", "make_env", ",", "\n", "alg", "=", "'sac'", ",", "\n", "layers", "=", "(", "128", ",", "128", ")", ",", "\n", "tb", "=", "''", ",", "\n", "replay_size", "=", "1100000", ",", "\n", "seed", "=", "seed", "\n", ")", ",", "agent_name_attrs", "=", "[", "'alg'", ",", "'seed'", ",", "'tb'", "]", ")", "\n", "del", "config", ".", "module_state_normalizer", "\n", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "CodaOldBuffer", "(", "\n", "max_coda_ratio", "=", "0.5", ",", "\n", "num_coda_source_transitions", "=", "5000", ",", "\n", "num_coda_source_pairs", "=", "1000", ",", "\n", "coda_samples_per_pair", "=", "2", ",", "\n", "coda_buffer_size", "=", "1250000", ",", "\n", "add_bad_dcs", "=", "False", ")", "\n", "\n", "config", ".", "slot_state_dims", "=", "[", "[", "0", ",", "1", ",", "2", ",", "3", "]", ",", "[", "4", ",", "5", ",", "6", ",", "7", "]", ",", "[", "8", ",", "9", ",", "10", ",", "11", "]", "]", "\n", "config", ".", "slot_action_dims", "=", "[", "[", "0", ",", "1", "]", "]", "\n", "model_fn", "=", "lambda", ":", "SimpleMLP", "(", "(", "12", "+", "2", ",", "200", ",", "200", ",", "200", ",", "200", ",", "24", ")", ")", "\n", "config", ".", "mask_module", "=", "MBPOModel", "(", "model_fn", "=", "model_fn", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "256", ")", "\n", "\n", "config", ".", "never_done", "=", "True", "\n", "config", ".", "min_experience_to_train_coda_attn", "=", "0", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "reward_module", "=", "PongClassifierRewardModel", "(", "SimpleMLP", "(", "(", "12", "+", "2", "+", "12", ",", "128", ",", "3", ")", ")", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "512", ")", "\n", "agent", ".", "set_module", "(", "'reward_module'", ",", "reward_module", ")", "\n", "\n", "enablePrint", "(", ")", "\n", "print", "(", "\"OK!\"", ")", "\n", "\n", "\"\"\"Add the real dataset\"\"\"", "\n", "agent", ".", "replay_buffer", ".", "buffer", ".", "add_batch", "(", "*", "dataset", ")", "\n", "\n", "\"\"\"Train the attention model\"\"\"", "\n", "attn_losses", ",", "rew_losses", "=", "[", "]", ",", "[", "]", "\n", "print", "(", "\"Training attention model...\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "2000", ")", ")", ":", "\n", "    ", "attn_losses", ".", "append", "(", "agent", ".", "coda_attention_model", ".", "_optimize", "(", ")", ")", "\n", "rew_losses", ".", "append", "(", "agent", ".", "reward_module", ".", "_optimize", "(", ")", ")", "\n", "\n", "", "\"\"\"Now train it to a decent loss...\"\"\"", "\n", "assert", "np", ".", "mean", "(", "rew_losses", "[", "-", "10", ":", "]", ")", "<", "0.1", "\n", "i", "=", "0", "\n", "while", "True", ":", "\n", "    ", "try", ":", "\n", "      ", "assert", "np", ".", "mean", "(", "attn_losses", "[", "-", "10", ":", "]", ")", "<", "TARGET_LOSS_LEVEL", "\n", "break", "\n", "", "except", ":", "\n", "      ", "i", "+=", "1", "\n", "if", "i", ">", "1000", ":", "\n", "        ", "assert", "False", ",", "\"failed to train the model... =(\"", "\n", "", "print", "(", "\".\"", ",", "end", "=", "''", ")", "\n", "for", "_", "in", "range", "(", "1000", ")", ":", "\n", "        ", "attn_losses", ".", "append", "(", "agent", ".", "coda_attention_model", ".", "_optimize", "(", ")", ")", "\n", "", "", "", "print", "(", "\"Done training the model! \"", ")", "\n", "\n", "\"\"\"Now let's make some Dyna data\"\"\"", "\n", "print", "(", "\"Making Dyna data...\"", ")", "\n", "model_fn", "=", "agent", ".", "coda_attention_model", ".", "forward", "\n", "reward_fn", "=", "agent", ".", "reward_module", ".", "compute_reward", "\n", "\n", "while", "len", "(", "agent", ".", "replay_buffer", ".", "coda_buffer", ")", "<", "dyna_data", ":", "\n", "    ", "states", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "sample", "(", "1000", ")", "[", "0", "]", "\n", "batch", "=", "sample_dyna_batch", "(", "states", ",", "agent", ".", "env", ".", "action_space", ",", "num_step_rollouts", ",", "model_fn", ",", "reward_fn", ")", "\n", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "add_batch", "(", "*", "batch", ")", "\n", "\n", "", "s", ",", "a", ",", "r", ",", "ns", ",", "d", "=", "dataset", "\n", "\n", "DYNASIZE", "=", "min", "(", "dyna_data", ",", "len", "(", "agent", ".", "replay_buffer", ".", "coda_buffer", ")", ")", "\n", "coda_s", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'state'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_a", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'action'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_r", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'reward'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_ns", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'next_state'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_d", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'done'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "\n", "dataset", "=", "(", "\n", "np", ".", "concatenate", "(", "(", "s", ",", "coda_s", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "a", ",", "coda_a", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "r", ",", "coda_r", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "ns", ",", "coda_ns", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "d", ",", "coda_d", ")", ")", "\n", ")", "\n", "\n", "print", "(", "f'Successfully made {DYNASIZE} dyna samples!'", ")", "\n", "return", "dataset", ",", "reward_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_mbpo_data.get_random_actions": [[141, 146], ["numpy.array", "res.append", "action_space.sample"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "get_random_actions", "(", "states", ",", "action_space", ")", ":", "\n", "  ", "res", "=", "[", "]", "\n", "for", "s", "in", "states", ":", "\n", "    ", "res", ".", "append", "(", "action_space", ".", "sample", "(", ")", ")", "\n", "", "return", "np", ".", "array", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_mbpo_data.sample_dyna_batch": [[147, 170], ["range", "list", "make_mbpo_data.get_random_actions", "model_fn", "reward_fn", "numpy.zeros_like", "s.append", "a.append", "r.append", "ns.append", "d.append", "map"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.get_random_actions", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "sample_dyna_batch", "(", "init_states", ",", "action_space", ",", "num_steps", ",", "model_fn", ",", "reward_fn", ")", ":", "\n", "  ", "s", "=", "[", "]", "\n", "a", "=", "[", "]", "\n", "r", "=", "[", "]", "\n", "ns", "=", "[", "]", "\n", "d", "=", "[", "]", "\n", "\n", "states", "=", "init_states", "\n", "for", "i", "in", "range", "(", "num_steps", ")", ":", "\n", "    ", "actions", "=", "get_random_actions", "(", "states", ",", "action_space", ")", "\n", "next_states", "=", "model_fn", "(", "states", ",", "actions", ")", "\n", "rewards", "=", "reward_fn", "(", "states", ",", "actions", ",", "next_states", ")", "\n", "dones", "=", "np", ".", "zeros_like", "(", "rewards", ")", "\n", "\n", "s", ".", "append", "(", "states", ")", "\n", "a", ".", "append", "(", "actions", ")", "\n", "r", ".", "append", "(", "rewards", ")", "\n", "ns", ".", "append", "(", "next_states", ")", "\n", "d", ".", "append", "(", "dones", ")", "\n", "\n", "states", "=", "next_states", "\n", "\n", "", "return", "list", "(", "map", "(", "np", ".", "concatenate", ",", "(", "s", ",", "a", ",", "r", ",", "ns", ",", "d", ")", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.pong.RoboschoolPong_v0_2017may1.SmallReactivePolicy.__init__": [[9, 13], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ob_space", ",", "ac_space", ")", ":", "\n", "        ", "assert", "weights_dense1_w", ".", "shape", "==", "(", "ob_space", ".", "shape", "[", "0", "]", ",", "64", ")", "\n", "assert", "weights_dense2_w", ".", "shape", "==", "(", "64", ",", "32", ")", "\n", "assert", "weights_final_w", ".", "shape", "==", "(", "32", ",", "ac_space", ".", "shape", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.RoboschoolPong_v0_2017may1.SmallReactivePolicy.act": [[14, 20], ["RoboschoolPong_v0_2017may1.relu", "RoboschoolPong_v0_2017may1.relu", "numpy.dot", "numpy.dot", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.pong.RoboschoolPong_v0_2017may1.relu", "home.repos.pwc.inspect_result.spitis_mrl.pong.RoboschoolPong_v0_2017may1.relu"], ["", "def", "act", "(", "self", ",", "ob", ")", ":", "\n", "        ", "x", "=", "ob", "\n", "x", "=", "relu", "(", "np", ".", "dot", "(", "x", ",", "weights_dense1_w", ")", "+", "weights_dense1_b", ")", "\n", "x", "=", "relu", "(", "np", ".", "dot", "(", "x", ",", "weights_dense2_w", ")", "+", "weights_dense2_b", ")", "\n", "x", "=", "np", ".", "dot", "(", "x", ",", "weights_final_w", ")", "+", "weights_final_b", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.RoboschoolPong_v0_2017may1.relu": [[4, 6], ["numpy.maximum"], "function", ["None"], ["def", "relu", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "maximum", "(", "x", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.train_batchrl_agent.blockPrint": [[10, 12], ["open"], "function", ["None"], ["def", "blockPrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "open", "(", "os", ".", "devnull", ",", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.train_batchrl_agent.enablePrint": [[13, 15], ["None"], "function", ["None"], ["", "def", "enablePrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "sys", ".", "__stdout__", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.train_batchrl_agent.make_env": [[16, 18], ["experiments.coda.pong.pong_env.CustomPong"], "function", ["None"], ["", "def", "make_env", "(", ")", ":", "\n", "  ", "return", "CustomPong", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.train_batchrl_agent.train_batchrl_agent": [[19, 67], ["print", "train_batchrl_agent.blockPrint", "make_td3_agent", "OldReplayBuffer", "mrl.config_to_agent", "mrl.config_to_agent.replay_buffer.buffer.add_batch", "train_batchrl_agent.enablePrint", "tqdm.tqdm", "mrl.config_to_agent.save", "print", "print", "make_td3_agent", "numpy.mean", "range", "range", "AttrDict", "mrl.config_to_agent.train_mode", "mrl.config_to_agent.algorithm._optimize", "mrl.config_to_agent.eval_mode", "numpy.mean", "numpy.mean", "mrl.config_to_agent.eval", "int", "int", "mrl.config_to_agent.eval"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.blockPrint", "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_td3_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.enablePrint", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_td3_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.train_mode", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode"], ["", "def", "train_batchrl_agent", "(", "dataset", ",", "agent_tag", ",", "num_steps", "=", "120000", ",", "results_folder", "=", "'/tmp/pong_results'", ",", "seed", "=", "0", ",", "num_eval_eps", "=", "10", ")", ":", "\n", "  ", "print", "(", "\"Training off-policy agent in batch mode on the dataset...\"", ")", "\n", "blockPrint", "(", ")", "\n", "\n", "config", "=", "make_td3_agent", "(", "make_td3_agent", "(", ")", ",", "args", "=", "AttrDict", "(", "\n", "parent_folder", "=", "results_folder", ",", "\n", "env", "=", "make_env", ",", "\n", "max_steps", "=", "int", "(", "1e6", ")", ",", "\n", "replay_size", "=", "int", "(", "1.6e6", ")", ",", "\n", "alg", "=", "'td3'", ",", "\n", "layers", "=", "(", "128", ",", "128", ")", ",", "\n", "tb", "=", "agent_tag", ",", "\n", "actor_lr", "=", "3e-4", ",", "\n", "critic_lr", "=", "3e-4", ",", "\n", "epoch_len", "=", "2500", ",", "\n", "batch_size", "=", "1000", ",", "\n", "clip_target_range", "=", "(", "-", "50", ",", "50", ")", ",", "\n", "num_envs", "=", "10", ",", "\n", "num_eval_envs", "=", "10", ",", "\n", "optimize_every", "=", "1", ",", "\n", "gamma", "=", "0.98", ",", "\n", "seed", "=", "seed", "\n", ")", ",", "agent_name_attrs", "=", "[", "'alg'", ",", "'seed'", ",", "'tb'", "]", ")", "\n", "\n", "del", "config", ".", "module_state_normalizer", "\n", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "OldReplayBuffer", "(", ")", "\n", "config", ".", "never_done", "=", "True", "\n", "config", ".", "min_experience_to_train_coda_attn", "=", "0", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "agent", ".", "replay_buffer", ".", "buffer", ".", "add_batch", "(", "*", "dataset", ")", "\n", "\n", "enablePrint", "(", ")", "\n", "\n", "res", "=", "[", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_eval_eps", ")", ".", "rewards", ")", "]", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "num_steps", "//", "1000", ")", ")", ":", "\n", "    ", "for", "_", "in", "range", "(", "1000", ")", ":", "\n", "      ", "agent", ".", "train_mode", "(", ")", "\n", "agent", ".", "config", ".", "env_steps", "+=", "1", "\n", "agent", ".", "algorithm", ".", "_optimize", "(", ")", "\n", "agent", ".", "eval_mode", "(", ")", "\n", "", "res", "+=", "[", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_eval_eps", ")", ".", "rewards", ")", "]", "\n", "\n", "", "agent", ".", "save", "(", ")", "\n", "\n", "print", "(", "\"Done training agent!\"", ")", "\n", "print", "(", "\"Average score over final 10 epochs: {}\"", ".", "format", "(", "np", ".", "mean", "(", "res", "[", "-", "10", ":", "]", ")", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.__init__": [[14, 19], ["roboschool.scene_abstract.Scene.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "Scene", ".", "__init__", "(", "self", ",", "gravity", "=", "9.8", ",", "timestep", "=", "0.0165", "/", "4", ",", "frame_skip", "=", "4", ")", "\n", "self", ".", "score_left", "=", "0", "\n", "self", ".", "score_right", "=", "0", "\n", "self", ".", "ball_x", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.actor_introduce": [[20, 22], ["None"], "methods", ["None"], ["", "def", "actor_introduce", "(", "self", ",", "robot", ")", ":", "\n", "    ", "i", "=", "robot", ".", "player_n", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.episode_restart": [[23, 58], ["roboschool.scene_abstract.Scene.episode_restart", "pong_env.PongScene.cpp_world.load_mjcf", "pong_env.PongScene.p0y.reset_current_position", "pong_env.PongScene.p1y.reset_current_position", "pong_env.PongScene.ballx.set_motor_torque", "pong_env.PongScene.bally.set_motor_torque", "roboschool.scene_abstract.cpp_household.Pose", "roboschool.scene_abstract.cpp_household.Pose.set_xyz", "pong_env.PongScene.cpp_world.load_thingy", "pong_env.PongScene.cpp_world.new_camera_free_float", "pong_env.PongScene.restart_from_center", "os.path.join", "pong_env.PongScene.np_random.uniform", "pong_env.PongScene.np_random.uniform", "r.query_position", "os.path.join", "os.path.dirname", "print", "os.path.dirname", "print", "pong_env.PongScene.np_random.randint"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.episode_restart", "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.restart_from_center"], ["", "def", "episode_restart", "(", "self", ")", ":", "\n", "    ", "Scene", ".", "episode_restart", "(", "self", ")", "\n", "self", ".", "mjcf", "=", "self", ".", "cpp_world", ".", "load_mjcf", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"models_robot/roboschool_pong.xml\"", ")", ")", "\n", "dump", "=", "0", "\n", "for", "r", "in", "self", ".", "mjcf", ":", "\n", "      ", "if", "dump", ":", "print", "(", "\"ROBOT '%s'\"", "%", "r", ".", "root_part", ".", "name", ")", "\n", "for", "part", "in", "r", ".", "parts", ":", "\n", "        ", "if", "dump", ":", "print", "(", "\"\\tPART '%s'\"", "%", "part", ".", "name", ")", "\n", "#if part.name==self.robot_name:", "\n", "", "for", "j", "in", "r", ".", "joints", ":", "\n", "        ", "if", "j", ".", "name", "==", "\"p0x\"", ":", "self", ".", "p0x", "=", "j", "\n", "if", "j", ".", "name", "==", "\"p0y\"", ":", "self", ".", "p0y", "=", "j", "\n", "if", "j", ".", "name", "==", "\"p1x\"", ":", "self", ".", "p1x", "=", "j", "\n", "if", "j", ".", "name", "==", "\"p1y\"", ":", "self", ".", "p1y", "=", "j", "\n", "if", "j", ".", "name", "==", "\"ballx\"", ":", "self", ".", "ballx", "=", "j", "\n", "if", "j", ".", "name", "==", "\"bally\"", ":", "self", ".", "bally", "=", "j", "\n", "\n", "", "", "self", ".", "p0y", ".", "reset_current_position", "(", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "0.9", ",", "high", "=", "+", "0.9", ")", ",", "0.", ")", "\n", "self", ".", "p1y", ".", "reset_current_position", "(", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "0.9", ",", "high", "=", "+", "0.9", ")", ",", "0.", ")", "\n", "\n", "self", ".", "ballx", ".", "set_motor_torque", "(", "0.0", ")", "\n", "self", ".", "bally", ".", "set_motor_torque", "(", "0.0", ")", "\n", "for", "r", "in", "self", ".", "mjcf", ":", "\n", "      ", "r", ".", "query_position", "(", ")", "\n", "", "fpose", "=", "cpp_household", ".", "Pose", "(", ")", "\n", "fpose", ".", "set_xyz", "(", "0", ",", "0", ",", "-", "0.04", ")", "\n", "self", ".", "field", "=", "self", ".", "cpp_world", ".", "load_thingy", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"models_outdoor/stadium/pong1.obj\"", ")", ",", "\n", "fpose", ",", "1.0", ",", "0", ",", "0xFFFFFF", ",", "True", ")", "\n", "self", ".", "camera", "=", "self", ".", "cpp_world", ".", "new_camera_free_float", "(", "self", ".", "VIDEO_W", ",", "self", ".", "VIDEO_H", ",", "\"video_camera\"", ")", "\n", "self", ".", "camera_itertia", "=", "0", "\n", "self", ".", "frame", "=", "0", "\n", "self", ".", "jstate_for_frame", "=", "-", "1", "\n", "self", ".", "score_left", "=", "0", "\n", "self", ".", "score_right", "=", "0", "\n", "self", ".", "restart_from_center", "(", "self", ".", "players_count", "==", "1", "or", "self", ".", "np_random", ".", "randint", "(", "2", ")", "==", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.restart_from_center": [[59, 68], ["pong_env.PongScene.ballx.reset_current_position", "pong_env.PongScene.bally.reset_current_position", "pong_env.PongScene.np_random.uniform", "pong_env.PongScene.np_random.uniform", "pong_env.PongScene.np_random.uniform", "pong_env.PongScene.np_random.uniform", "pong_env.PongScene.np_random.uniform"], "methods", ["None"], ["", "def", "restart_from_center", "(", "self", ",", "leftwards", ")", ":", "\n", "    ", "self", ".", "ballx", ".", "reset_current_position", "(", "0", ",", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "2.0", ",", "high", "=", "2.5", ")", "*", "(", "-", "1", "if", "leftwards", "else", "+", "1", ")", ")", "\n", "self", ".", "bally", ".", "reset_current_position", "(", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "0.9", ",", "high", "=", "+", "0.9", ")", ",", "\n", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "2", ",", "high", "=", "+", "2", ")", ")", "\n", "self", ".", "timeout", "=", "self", ".", "TIMEOUT", "\n", "self", ".", "timeout_dir", "=", "(", "-", "1", "if", "leftwards", "else", "+", "1", ")", "\n", "self", ".", "bounce_n", "=", "0", "\n", "self", ".", "trainer_x", "=", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "0.9", ",", "high", "=", "+", "0.9", ")", "\n", "self", ".", "trainer_y", "=", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "0.9", ",", "high", "=", "+", "0.9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.global_step": [[69, 99], ["roboschool.scene_abstract.Scene.global_step", "pong_env.PongScene.ballx.current_position", "pong_env.PongScene.bally.current_position", "pong_env.PongScene.p1x.set_servo_target", "pong_env.PongScene.p1y.set_servo_target", "pong_env.PongScene.bally.reset_current_position", "pong_env.PongScene.ballx.reset_current_position", "pong_env.PongScene.bally.reset_current_position", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.global_step"], ["", "def", "global_step", "(", "self", ")", ":", "\n", "    ", "self", ".", "frame", "+=", "1", "\n", "\n", "if", "not", "self", ".", "multiplayer", ":", "\n", "# Trainer", "\n", "      ", "self", ".", "p1x", ".", "set_servo_target", "(", "self", ".", "trainer_x", ",", "0.02", ",", "0.02", ",", "4", ")", "\n", "self", ".", "p1y", ".", "set_servo_target", "(", "self", ".", "trainer_y", ",", "0.02", ",", "0.02", ",", "4", ")", "\n", "\n", "", "Scene", ".", "global_step", "(", "self", ")", "\n", "\n", "self", ".", "ball_x", ",", "ball_vx", "=", "self", ".", "ballx", ".", "current_position", "(", ")", "\n", "self", ".", "ball_y", ",", "ball_vy", "=", "self", ".", "bally", ".", "current_position", "(", ")", "\n", "\n", "if", "np", ".", "abs", "(", "self", ".", "ball_y", ")", ">", "1.0", "and", "self", ".", "ball_y", "*", "ball_vy", ">", "0", ":", "\n", "      ", "self", ".", "bally", ".", "reset_current_position", "(", "self", ".", "ball_y", ",", "-", "ball_vy", ")", "\n", "\n", "", "if", "np", ".", "abs", "(", "self", ".", "ball_x", ")", ">", "2.0", "and", "self", ".", "ball_x", "*", "ball_vx", ">", "0", ":", "\n", "      ", "self", ".", "ballx", ".", "reset_current_position", "(", "self", ".", "ball_x", ",", "0.", ")", "\n", "self", ".", "bally", ".", "reset_current_position", "(", "self", ".", "ball_y", ",", "0.", ")", "\n", "\n", "", "if", "ball_vx", "*", "self", ".", "timeout_dir", "<", "0", ":", "\n", "      ", "if", "self", ".", "timeout_dir", "<", "0", ":", "\n", "        ", "self", ".", "score_left", "+=", "0.01", "*", "np", ".", "abs", "(", "ball_vx", ")", "# hint for early learning: hit the ball!", "\n", "", "else", ":", "\n", "        ", "self", ".", "score_right", "+=", "0.01", "*", "np", ".", "abs", "(", "ball_vx", ")", "\n", "", "self", ".", "timeout_dir", "*=", "-", "1", "\n", "self", ".", "timeout", "=", "150", "\n", "self", ".", "bounce_n", "+=", "1", "\n", "", "else", ":", "\n", "      ", "self", ".", "timeout", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.global_state": [[115, 124], ["numpy.array().flatten", "numpy.clip", "numpy.array", "numpy.array().flatten.current_relative_position"], "methods", ["None"], ["", "", "def", "global_state", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "frame", "==", "self", ".", "jstate_for_frame", ":", "\n", "      ", "return", "self", ".", "jstate", "\n", "", "self", ".", "jstate_for_frame", "=", "self", ".", "frame", "\n", "j", "=", "np", ".", "array", "(", "[", "\n", "j", ".", "current_relative_position", "(", ")", "for", "j", "in", "[", "self", ".", "p0x", ",", "self", ".", "p0y", ",", "self", ".", "p1x", ",", "self", ".", "p1y", ",", "self", ".", "ballx", ",", "self", ".", "bally", "]", "\n", "]", ")", ".", "flatten", "(", ")", "\n", "self", ".", "jstate", "=", "np", ".", "clip", "(", "j", ",", "-", "1.", ",", "1.", ")", "\n", "return", "self", ".", "jstate", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.HUD": [[127, 134], ["pong_env.PongScene.cpp_world.test_window_history_advance", "pong_env.PongScene.cpp_world.test_window_observations", "pong_env.PongScene.cpp_world.test_window_actions", "pong_env.PongScene.cpp_world.test_window_score", "pong_env.PongScene.camera.test_window_score", "s.tolist", "a.tolist"], "methods", ["None"], ["def", "HUD", "(", "self", ",", "a", ",", "s", ")", ":", "\n", "    ", "self", ".", "cpp_world", ".", "test_window_history_advance", "(", ")", "\n", "self", ".", "cpp_world", ".", "test_window_observations", "(", "s", ".", "tolist", "(", ")", ")", "\n", "self", ".", "cpp_world", ".", "test_window_actions", "(", "a", ".", "tolist", "(", ")", ")", "\n", "s", "=", "\"%04i TIMEOUT%3i %0.2f:%0.2f\"", "%", "(", "self", ".", "frame", ",", "self", ".", "timeout", ",", "self", ".", "score_left", ",", "self", ".", "score_right", ")", "\n", "self", ".", "cpp_world", ".", "test_window_score", "(", "s", ")", "\n", "self", ".", "camera", ".", "test_window_score", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.camera_adjust": [[135, 139], ["pong_env.PongScene.camera.move_and_look_at"], "methods", ["None"], ["", "def", "camera_adjust", "(", "self", ")", ":", "\n", "    ", "self", ".", "camera_itertia", "*=", "0.9", "\n", "self", ".", "camera_itertia", "+=", "0.1", "*", "0.05", "*", "self", ".", "ball_x", "\n", "self", ".", "camera", ".", "move_and_look_at", "(", "0", ",", "-", "1.0", ",", "1.5", ",", "self", ".", "camera_itertia", ",", "-", "0.1", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.__init__": [[155, 166], ["numpy.ones", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "pong_env.CustomPong.seed", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "scene", "=", "None", "\n", "action_dim", "=", "2", "\n", "obs_dim", "=", "12", "\n", "high", "=", "np", ".", "ones", "(", "[", "action_dim", "]", ")", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "high", ",", "high", ")", "\n", "high", "=", "np", ".", "inf", "*", "np", ".", "ones", "(", "[", "obs_dim", "]", ")", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "high", ",", "high", ")", "\n", "self", ".", "seed", "(", ")", "\n", "self", ".", "current_step", "=", "0", "\n", "self", ".", "done_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.create_single_player_scene": [[167, 172], ["pong_env.PongScene"], "methods", ["None"], ["", "def", "create_single_player_scene", "(", "self", ")", ":", "\n", "    ", "self", ".", "player_n", "=", "0", "\n", "s", "=", "PongScene", "(", ")", "\n", "s", ".", "np_random", "=", "self", ".", "np_random", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.seed": [[173, 176], ["gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "gym.utils.seeding.np_random"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "    ", "self", ".", "np_random", ",", "seed", "=", "gym", ".", "utils", ".", "seeding", ".", "np_random", "(", "seed", ")", "\n", "return", "[", "seed", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.reset": [[177, 186], ["pong_env.CustomPong.calc_state", "pong_env.CustomPong.create_single_player_scene", "pong_env.CustomPong.scene.episode_restart"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.calc_state", "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.create_single_player_scene", "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.episode_restart"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "scene", "is", "None", ":", "\n", "      ", "self", ".", "scene", "=", "self", ".", "create_single_player_scene", "(", ")", "\n", "", "if", "not", "self", ".", "scene", ".", "multiplayer", ":", "\n", "      ", "self", ".", "scene", ".", "episode_restart", "(", ")", "\n", "", "s", "=", "self", ".", "calc_state", "(", ")", "\n", "self", ".", "current_step", "=", "0", "\n", "self", ".", "done_step", "=", "0", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.calc_state": [[187, 196], ["pong_env.CustomPong.scene.global_state", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.global_state"], ["", "def", "calc_state", "(", "self", ")", ":", "\n", "    ", "j", "=", "self", ".", "scene", ".", "global_state", "(", ")", "\n", "if", "self", ".", "player_n", "==", "1", ":", "\n", "#                    [  0,1,  2,3,   4, 5, 6,7,  8,9,10,11]", "\n", "#                    [p0x,v,p0y,v, p1x,v,p1y,v, bx,v,by,v]", "\n", "      ", "signflip", "=", "np", ".", "array", "(", "[", "-", "1", ",", "-", "1", ",", "1", ",", "1", ",", "-", "1", ",", "-", "1", ",", "1", ",", "1", ",", "-", "1", ",", "-", "1", ",", "1", ",", "1", "]", ")", "\n", "reorder", "=", "np", ".", "array", "(", "[", "4", ",", "5", ",", "6", ",", "7", ",", "0", ",", "1", ",", "2", ",", "3", ",", "8", ",", "9", ",", "10", ",", "11", "]", ")", "\n", "j", "=", "(", "j", "*", "signflip", ")", "[", "reorder", "]", "\n", "", "return", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.apply_action": [[197, 206], ["numpy.isfinite().all", "numpy.clip", "pong_env.CustomPong.scene.p0x.set_target_speed", "pong_env.CustomPong.scene.p0y.set_target_speed", "pong_env.CustomPong.scene.p1x.set_target_speed", "pong_env.CustomPong.scene.p1y.set_target_speed", "numpy.isfinite", "float", "float", "float", "float"], "methods", ["None"], ["", "def", "apply_action", "(", "self", ",", "a", ")", ":", "\n", "    ", "assert", "(", "np", ".", "isfinite", "(", "a", ")", ".", "all", "(", ")", ")", "\n", "a", "=", "np", ".", "clip", "(", "a", ",", "-", "1", ",", "+", "1", ")", "\n", "if", "self", ".", "player_n", "==", "0", ":", "\n", "      ", "self", ".", "scene", ".", "p0x", ".", "set_target_speed", "(", "3", "*", "float", "(", "a", "[", "0", "]", ")", ",", "0.05", ",", "7", ")", "\n", "self", ".", "scene", ".", "p0y", ".", "set_target_speed", "(", "3", "*", "float", "(", "a", "[", "1", "]", ")", ",", "0.05", ",", "7", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "scene", ".", "p1x", ".", "set_target_speed", "(", "-", "3", "*", "float", "(", "a", "[", "0", "]", ")", ",", "0.05", ",", "7", ")", "\n", "self", ".", "scene", ".", "p1y", ".", "set_target_speed", "(", "3", "*", "float", "(", "a", "[", "1", "]", ")", ",", "0.05", ",", "7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.step": [[207, 230], ["pong_env.CustomPong.calc_state", "pong_env.CustomPong.compute_reward", "pong_env.CustomPong.apply_action", "pong_env.CustomPong.scene.global_step", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.calc_state", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.apply_action", "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.global_step"], ["", "", "def", "step", "(", "self", ",", "a", ")", ":", "\n", "    ", "if", "not", "self", ".", "scene", ".", "multiplayer", ":", "\n", "      ", "self", ".", "apply_action", "(", "a", ")", "\n", "self", ".", "scene", ".", "global_step", "(", ")", "\n", "\n", "", "state", "=", "self", ".", "calc_state", "(", ")", "\n", "reward", "=", "self", ".", "compute_reward", "(", "state", ")", "\n", "done", "=", "False", "\n", "\n", "self", ".", "current_step", "+=", "1", "\n", "if", "np", ".", "abs", "(", "reward", ")", ">", "0.95", ":", "\n", "      ", "self", ".", "done_step", "+=", "1", "\n", "\n", "", "info", "=", "{", "}", "\n", "if", "(", "self", ".", "current_step", ">=", "250", ")", "or", "(", "self", ".", "done_step", ">=", "10", ")", ":", "\n", "      ", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "done", "=", "True", "\n", "if", "reward", ">", "0.95", ":", "\n", "        ", "info", "[", "'is_success'", "]", "=", "True", "\n", "", "else", ":", "\n", "        ", "info", "[", "'is_success'", "]", "=", "False", "\n", "\n", "", "", "return", "state", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.compute_reward": [[231, 242], ["None"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "next_state", ")", ":", "\n", "    ", "p0x", ",", "p1x", ",", "bx", "=", "next_state", "[", "[", "0", ",", "4", ",", "8", "]", "]", "\n", "absbx", "=", "bx", "*", "2.1", "\n", "absp0x", "=", "p0x", "*", "0.3", "-", "1.3", "\n", "absp1x", "=", "p1x", "*", "0.3", "+", "1.3", "\n", "\n", "if", "absbx", ">=", "absp1x", ":", "\n", "      ", "return", "1.", "\n", "", "elif", "absbx", "<=", "absp0x", ":", "\n", "      ", "return", "-", "1.", "\n", "", "return", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.CustomPong.render": [[243, 253], ["pong_env.CustomPong.scene.cpp_world.test_window", "pong_env.CustomPong.scene.camera_adjust", "pong_env.CustomPong.scene.camera.render", "numpy.fromstring().reshape", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.pong.pong_env.PongScene.camera_adjust", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "    ", "if", "mode", "==", "\"human\"", ":", "\n", "      ", "return", "self", ".", "scene", ".", "cpp_world", ".", "test_window", "(", ")", "\n", "", "elif", "mode", "==", "\"rgb_array\"", ":", "\n", "      ", "self", ".", "scene", ".", "camera_adjust", "(", ")", "\n", "rgb", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "scene", ".", "camera", ".", "render", "(", "False", ",", "False", ",", "False", ")", "# render_depth, render_labeling, print_timing)", "\n", "rendered_rgb", "=", "np", ".", "fromstring", "(", "rgb", ",", "dtype", "=", "np", ".", "uint8", ")", ".", "reshape", "(", "(", "self", ".", "VIDEO_H", ",", "self", ".", "VIDEO_W", ",", "3", ")", ")", "\n", "return", "rendered_rgb", "\n", "", "else", ":", "\n", "      ", "assert", "(", "0", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.pong.collect_real_data.collect_real_data": [[10, 52], ["print", "experiments.coda.pong.pong_env.CustomPong", "numpy.random.seed", "experiments.coda.pong.pong_env.CustomPong.seed", "experiments.coda.pong.RoboschoolPong_v0_2017may1.SmallReactivePolicy", "experiments.coda.pong.pong_env.CustomPong.reset", "tqdm.tqdm", "numpy.array", "numpy.array", "numpy.array().reshape", "numpy.array", "numpy.zeros_like", "print", "gym.spaces.Box", "range", "experiments.coda.pong.pong_env.CustomPong.step", "np.array.append", "np.array.append", "np.array().reshape.append", "np.array.append", "numpy.ones", "numpy.random.random", "experiments.coda.pong.RoboschoolPong_v0_2017may1.SmallReactivePolicy.act", "experiments.coda.pong.pong_env.CustomPong.action_space.sample", "experiments.coda.pong.pong_env.CustomPong.reset", "numpy.array", "numpy.ones", "numpy.concatenate", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.pong.RoboschoolPong_v0_2017may1.SmallReactivePolicy.act", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["def", "collect_real_data", "(", "datasize", ",", "seed", "=", "0", ",", "noise_level", "=", "0.7", ")", ":", "\n", "\n", "  ", "print", "(", "\"Collecting real data...\"", ")", "\n", "states", "=", "[", "]", "\n", "actions", "=", "[", "]", "\n", "rewards", "=", "[", "]", "\n", "next_states", "=", "[", "]", "\n", "dones", "=", "[", "]", "\n", "\n", "e", "=", "CustomPong", "(", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "e", ".", "seed", "(", "seed", ")", "\n", "pi", "=", "Pol1", "(", "spaces", ".", "Box", "(", "np", ".", "ones", "(", "(", "13", ",", ")", ")", "*", "-", "1", ",", "np", ".", "ones", "(", "(", "13", ",", ")", ")", ")", ",", "e", ".", "action_space", ")", "\n", "\n", "state", "=", "e", ".", "reset", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "datasize", ")", ")", ":", "\n", "    ", "if", "np", ".", "random", ".", "random", "(", ")", ">", "noise_level", ":", "\n", "      ", "action", "=", "pi", ".", "act", "(", "np", ".", "concatenate", "(", "(", "state", ",", "[", "0", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "action", "=", "e", ".", "action_space", ".", "sample", "(", ")", "\n", "", "next_state", ",", "r", ",", "done", ",", "_", "=", "e", ".", "step", "(", "action", ")", "\n", "\n", "#e.render()", "\n", "states", ".", "append", "(", "state", ")", "\n", "actions", ".", "append", "(", "action", ")", "\n", "rewards", ".", "append", "(", "r", ")", "\n", "next_states", ".", "append", "(", "next_state", ")", "\n", "if", "done", ":", "\n", "      ", "state", "=", "e", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "      ", "state", "=", "next_state", "\n", "\n", "", "", "states", "=", "np", ".", "array", "(", "states", ")", "\n", "actions", "=", "np", ".", "array", "(", "actions", ")", "\n", "rewards", "=", "np", ".", "array", "(", "rewards", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "next_states", "=", "np", ".", "array", "(", "next_states", ")", "\n", "dones", "=", "np", ".", "zeros_like", "(", "rewards", ")", "\n", "dataset", "=", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", ")", "\n", "\n", "print", "(", "f'Successfully collected {len(dataset[0])} real samples!'", ")", "\n", "return", "dataset", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.blockPrint": [[12, 14], ["open"], "function", ["None"], ["def", "blockPrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "open", "(", "os", ".", "devnull", ",", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.enablePrint": [[15, 17], ["None"], "function", ["None"], ["", "def", "enablePrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "sys", ".", "__stdout__", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.make_env": [[18, 20], ["experiments.coda.pong.pong_env.CustomPong"], "function", ["None"], ["", "def", "make_env", "(", ")", ":", "\n", "  ", "return", "CustomPong", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.ground_truth_compute_reward": [[21, 35], ["numpy.zeros_like", "np.zeros_like.reshape"], "function", ["None"], ["", "def", "ground_truth_compute_reward", "(", "s", ",", "a", ",", "ns", ")", ":", "\n", "  ", "p0x", "=", "ns", "[", ":", ",", "0", "]", "\n", "p1x", "=", "ns", "[", ":", ",", "4", "]", "\n", "bx", "=", "ns", "[", ":", ",", "8", "]", "\n", "\n", "absbx", "=", "bx", "*", "2.1", "\n", "absp0x", "=", "p0x", "*", "0.3", "-", "1.3", "\n", "absp1x", "=", "p1x", "*", "0.3", "+", "1.3", "\n", "\n", "r", "=", "np", ".", "zeros_like", "(", "p0x", ")", "\n", "\n", "r", "[", "absbx", ">=", "absp1x", "]", "=", "1.", "\n", "r", "[", "absbx", "<=", "absp0x", "]", "=", "-", "1.", "\n", "return", "r", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.make_dyna_data": [[36, 125], ["print", "make_dyna_data.blockPrint", "make_sac_agent", "experiments.coda.coda_module.CodaOldBuffer", "experiments.coda.sandy_module.SimpleStackedAttn", "experiments.coda.sandy_module.CodaAttentionBasedMask", "mrl.config_to_agent", "experiments.coda.sandy_module.PongClassifierRewardModel", "mrl.config_to_agent.set_module", "make_dyna_data.enablePrint", "print", "mrl.config_to_agent.replay_buffer.buffer.add_batch", "print", "tqdm.tqdm", "print", "min", "print", "print", "len", "spinning_up_sac_config", "experiments.coda.sandy_module.SimpleMLP", "range", "attn_losses.append", "rew_losses.append", "numpy.mean", "numpy.mean", "len", "make_dyna_data.sample_dyna_batch", "mrl.config_to_agent.replay_buffer.coda_buffer.add_batch", "len", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "AttrDict", "mrl.config_to_agent.coda_attention_model._optimize", "mrl.config_to_agent.reward_module._optimize", "mrl.config_to_agent.replay_buffer.buffer.sample"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.blockPrint", "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_sac_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.set_module", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.enablePrint", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_sac_config", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.sample_dyna_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "make_dyna_data", "(", "real_dataset", ",", "dyna_data", ",", "num_step_rollouts", "=", "5", ",", "seed", "=", "0", ")", ":", "\n", "  ", "dataset", "=", "real_dataset", "\n", "if", "dyna_data", "==", "0", ":", "\n", "    ", "print", "(", "\"Did not make any Dyna data!\"", ")", "\n", "return", "real_dataset", "\n", "\n", "", "assert", "len", "(", "dataset", "[", "0", "]", ")", ">=", "10000", ",", "\"Need at least 10K real samples!\"", "\n", "\n", "print", "(", "\"Making a dummy agent... \"", ",", "end", "=", "''", ")", "\n", "\n", "blockPrint", "(", ")", "\n", "\n", "config", "=", "make_sac_agent", "(", "spinning_up_sac_config", "(", ")", ",", "args", "=", "AttrDict", "(", "\n", "parent_folder", "=", "'/tmp/make_coda_data'", ",", "\n", "env", "=", "make_env", ",", "\n", "alg", "=", "'sac'", ",", "\n", "layers", "=", "(", "128", ",", "128", ")", ",", "\n", "tb", "=", "''", ",", "\n", "replay_size", "=", "500000", ",", "\n", "seed", "=", "seed", "\n", ")", ",", "agent_name_attrs", "=", "[", "'alg'", ",", "'seed'", ",", "'tb'", "]", ")", "\n", "del", "config", ".", "module_state_normalizer", "\n", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "CodaOldBuffer", "(", "\n", "max_coda_ratio", "=", "0.5", ",", "\n", "num_coda_source_transitions", "=", "5000", ",", "\n", "num_coda_source_pairs", "=", "1000", ",", "\n", "coda_samples_per_pair", "=", "2", ",", "\n", "coda_buffer_size", "=", "1250000", ",", "\n", "add_bad_dcs", "=", "False", ")", "\n", "\n", "config", ".", "slot_state_dims", "=", "[", "[", "0", ",", "1", ",", "2", ",", "3", "]", ",", "[", "4", ",", "5", ",", "6", ",", "7", "]", ",", "[", "8", ",", "9", ",", "10", ",", "11", "]", "]", "\n", "config", ".", "slot_action_dims", "=", "[", "[", "0", ",", "1", "]", "]", "\n", "model", "=", "SimpleStackedAttn", "(", "14", ",", "12", ",", "num_attn_blocks", "=", "2", ",", "num_hidden_layers", "=", "3", ",", "num_hidden_units", "=", "256", ",", "num_heads", "=", "1", ")", "\n", "config", ".", "mask_module", "=", "CodaAttentionBasedMask", "(", "model", "=", "model", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "256", ")", "\n", "\n", "config", ".", "never_done", "=", "True", "\n", "config", ".", "min_experience_to_train_coda_attn", "=", "0", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "reward_module", "=", "PongClassifierRewardModel", "(", "SimpleMLP", "(", "(", "12", "+", "2", "+", "12", ",", "128", ",", "3", ")", ")", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "512", ")", "\n", "agent", ".", "set_module", "(", "'reward_module'", ",", "reward_module", ")", "\n", "\n", "enablePrint", "(", ")", "\n", "print", "(", "\"OK!\"", ")", "\n", "\n", "\"\"\"Add the real dataset\"\"\"", "\n", "agent", ".", "replay_buffer", ".", "buffer", ".", "add_batch", "(", "*", "dataset", ")", "\n", "\n", "\"\"\"Train the attention model\"\"\"", "\n", "attn_losses", ",", "rew_losses", "=", "[", "]", ",", "[", "]", "\n", "print", "(", "\"Training attention model...\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "2000", ")", ")", ":", "\n", "    ", "attn_losses", ".", "append", "(", "agent", ".", "coda_attention_model", ".", "_optimize", "(", ")", ")", "\n", "rew_losses", ".", "append", "(", "agent", ".", "reward_module", ".", "_optimize", "(", ")", ")", "\n", "\n", "", "\"\"\"Make sure it trained OK\"\"\"", "\n", "assert", "np", ".", "mean", "(", "attn_losses", "[", "-", "10", ":", "]", ")", "<", "0.005", "\n", "assert", "np", ".", "mean", "(", "rew_losses", "[", "-", "10", ":", "]", ")", "<", "0.1", "\n", "\n", "\"\"\"Now let's make some Dyna data\"\"\"", "\n", "print", "(", "\"Making Dyna data...\"", ")", "\n", "model_fn", "=", "agent", ".", "coda_attention_model", ".", "forward", "\n", "reward_fn", "=", "agent", ".", "reward_module", ".", "compute_reward", "\n", "\n", "while", "len", "(", "agent", ".", "replay_buffer", ".", "coda_buffer", ")", "<", "dyna_data", ":", "\n", "    ", "states", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "sample", "(", "1000", ")", "[", "0", "]", "\n", "batch", "=", "sample_dyna_batch", "(", "states", ",", "agent", ".", "env", ".", "action_space", ",", "num_step_rollouts", ",", "model_fn", ",", "reward_fn", ")", "\n", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "add_batch", "(", "*", "batch", ")", "\n", "\n", "", "s", ",", "a", ",", "r", ",", "ns", ",", "d", "=", "dataset", "\n", "\n", "DYNASIZE", "=", "min", "(", "dyna_data", ",", "len", "(", "agent", ".", "replay_buffer", ".", "coda_buffer", ")", ")", "\n", "coda_s", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'state'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_a", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'action'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_r", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'reward'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_ns", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'next_state'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "coda_d", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'done'", "]", ".", "data", "[", ":", "DYNASIZE", "]", "\n", "\n", "dataset", "=", "(", "\n", "np", ".", "concatenate", "(", "(", "s", ",", "coda_s", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "a", ",", "coda_a", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "r", ",", "coda_r", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "ns", ",", "coda_ns", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "d", ",", "coda_d", ")", ")", "\n", ")", "\n", "\n", "print", "(", "f'Successfully made {DYNASIZE} dyna samples!'", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.get_random_actions": [[126, 131], ["numpy.array", "res.append", "action_space.sample"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "get_random_actions", "(", "states", ",", "action_space", ")", ":", "\n", "  ", "res", "=", "[", "]", "\n", "for", "s", "in", "states", ":", "\n", "    ", "res", ".", "append", "(", "action_space", ".", "sample", "(", ")", ")", "\n", "", "return", "np", ".", "array", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.sample_dyna_batch": [[132, 155], ["range", "list", "make_dyna_data.get_random_actions", "model_fn", "reward_fn", "numpy.zeros_like", "s.append", "a.append", "r.append", "ns.append", "d.append", "map"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.make_dyna_data.get_random_actions", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "sample_dyna_batch", "(", "init_states", ",", "action_space", ",", "num_steps", ",", "model_fn", ",", "reward_fn", ")", ":", "\n", "  ", "s", "=", "[", "]", "\n", "a", "=", "[", "]", "\n", "r", "=", "[", "]", "\n", "ns", "=", "[", "]", "\n", "d", "=", "[", "]", "\n", "\n", "states", "=", "init_states", "\n", "for", "i", "in", "range", "(", "num_steps", ")", ":", "\n", "    ", "actions", "=", "get_random_actions", "(", "states", ",", "action_space", ")", "\n", "next_states", "=", "model_fn", "(", "states", ",", "actions", ")", "\n", "rewards", "=", "reward_fn", "(", "states", ",", "actions", ",", "next_states", ")", "\n", "dones", "=", "np", ".", "zeros_like", "(", "rewards", ")", "\n", "\n", "s", ".", "append", "(", "states", ")", "\n", "a", ".", "append", "(", "actions", ")", "\n", "r", ".", "append", "(", "rewards", ")", "\n", "ns", ".", "append", "(", "next_states", ")", "\n", "d", ".", "append", "(", "dones", ")", "\n", "\n", "states", "=", "next_states", "\n", "\n", "", "return", "list", "(", "map", "(", "np", ".", "concatenate", ",", "(", "s", ",", "a", ",", "r", ",", "ns", ",", "d", ")", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.blockPrint": [[12, 14], ["open"], "function", ["None"], ["def", "blockPrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "open", "(", "os", ".", "devnull", ",", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.enablePrint": [[15, 17], ["None"], "function", ["None"], ["", "def", "enablePrint", "(", ")", ":", "\n", "    ", "sys", ".", "stdout", "=", "sys", ".", "__stdout__", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.make_env": [[18, 20], ["experiments.coda.pong.pong_env.CustomPong"], "function", ["None"], ["", "def", "make_env", "(", ")", ":", "\n", "  ", "return", "CustomPong", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.ground_truth_compute_reward": [[21, 35], ["numpy.zeros_like", "np.zeros_like.reshape"], "function", ["None"], ["", "def", "ground_truth_compute_reward", "(", "s", ",", "a", ",", "ns", ")", ":", "\n", "  ", "p0x", "=", "ns", "[", ":", ",", "0", "]", "\n", "p1x", "=", "ns", "[", ":", ",", "4", "]", "\n", "bx", "=", "ns", "[", ":", ",", "8", "]", "\n", "\n", "absbx", "=", "bx", "*", "2.1", "\n", "absp0x", "=", "p0x", "*", "0.3", "-", "1.3", "\n", "absp1x", "=", "p1x", "*", "0.3", "+", "1.3", "\n", "\n", "r", "=", "np", ".", "zeros_like", "(", "p0x", ")", "\n", "\n", "r", "[", "absbx", ">=", "absp1x", "]", "=", "1.", "\n", "r", "[", "absbx", "<=", "absp0x", "]", "=", "-", "1.", "\n", "return", "r", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.make_coda_data": [[36, 145], ["print", "make_coda_data.blockPrint", "make_sac_agent", "experiments.coda.coda_module.CodaOldBuffer", "experiments.coda.sandy_module.SimpleStackedAttn", "experiments.coda.sandy_module.CodaAttentionBasedMask", "mrl.config_to_agent", "experiments.coda.sandy_module.PongClassifierRewardModel", "mrl.config_to_agent.set_module", "make_coda_data.enablePrint", "print", "print", "tqdm.tqdm", "print", "partial", "mrl.config_to_agent.replay_buffer._optimize", "len", "tqdm.tqdm", "min", "zip", "numpy.concatenate", "print", "print", "len", "spinning_up_sac_config", "experiments.coda.sandy_module.SimpleMLP", "mrl.config_to_agent.replay_buffer.buffer.add_batch", "mrl.config_to_agent.replay_buffer.buffer.add_batch", "range", "attn_losses.append", "rew_losses.append", "numpy.mean", "numpy.mean", "mrl.config_to_agent.replay_buffer.buffer.add_batch", "range", "mrl.config_to_agent.replay_buffer._optimize", "len", "numpy.array_split", "numpy.array_split", "numpy.array_split", "np.concatenate.append", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "AttrDict", "mrl.config_to_agent.coda_attention_model._optimize", "mrl.config_to_agent.reward_module._optimize", "mrl.config_to_agent.replay_buffer.reward_fn", "int"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.blockPrint", "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_sac_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.set_module", "home.repos.pwc.inspect_result.spitis_mrl.pong.make_coda_data.enablePrint", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_sac_config", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize"], ["", "def", "make_coda_data", "(", "real_dataset", ",", "coda_data", ",", "seed", "=", "0", ",", "amt_real_data", "=", "None", ",", "reward_fn", "=", "None", ")", ":", "\n", "  ", "dataset", "=", "real_dataset", "\n", "if", "coda_data", "==", "0", ":", "\n", "    ", "print", "(", "\"Did not make any Coda data!\"", ")", "\n", "return", "real_dataset", "\n", "\n", "", "assert", "len", "(", "dataset", "[", "0", "]", ")", ">=", "10000", ",", "\"Need at least 10K real samples!\"", "\n", "\n", "print", "(", "\"Making a dummy agent... \"", ",", "end", "=", "''", ")", "\n", "\n", "blockPrint", "(", ")", "\n", "\n", "config", "=", "make_sac_agent", "(", "spinning_up_sac_config", "(", ")", ",", "args", "=", "AttrDict", "(", "\n", "parent_folder", "=", "'/tmp/make_coda_data'", ",", "\n", "env", "=", "make_env", ",", "\n", "alg", "=", "'sac'", ",", "\n", "layers", "=", "(", "128", ",", "128", ")", ",", "\n", "tb", "=", "''", ",", "\n", "replay_size", "=", "500000", ",", "\n", "seed", "=", "seed", "\n", ")", ",", "agent_name_attrs", "=", "[", "'alg'", ",", "'seed'", ",", "'tb'", "]", ")", "\n", "del", "config", ".", "module_state_normalizer", "\n", "del", "config", ".", "module_replay", "\n", "config", ".", "module_replay", "=", "CodaOldBuffer", "(", "\n", "max_coda_ratio", "=", "0.5", ",", "\n", "num_coda_source_transitions", "=", "5000", ",", "\n", "num_coda_source_pairs", "=", "1000", ",", "\n", "coda_samples_per_pair", "=", "2", ",", "\n", "coda_buffer_size", "=", "1250000", ",", "\n", "add_bad_dcs", "=", "False", ")", "\n", "\n", "config", ".", "slot_state_dims", "=", "[", "[", "0", ",", "1", ",", "2", ",", "3", "]", ",", "[", "4", ",", "5", ",", "6", ",", "7", "]", ",", "[", "8", ",", "9", ",", "10", ",", "11", "]", "]", "\n", "config", ".", "slot_action_dims", "=", "[", "[", "0", ",", "1", "]", "]", "\n", "model", "=", "SimpleStackedAttn", "(", "14", ",", "12", ",", "num_attn_blocks", "=", "2", ",", "num_hidden_layers", "=", "3", ",", "num_hidden_units", "=", "256", ",", "num_heads", "=", "1", ")", "\n", "config", ".", "mask_module", "=", "CodaAttentionBasedMask", "(", "model", "=", "model", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "256", ")", "\n", "\n", "config", ".", "never_done", "=", "True", "\n", "config", ".", "min_experience_to_train_coda_attn", "=", "0", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "reward_module", "=", "PongClassifierRewardModel", "(", "SimpleMLP", "(", "(", "12", "+", "2", "+", "12", ",", "128", ",", "3", ")", ")", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "512", ")", "\n", "agent", ".", "set_module", "(", "'reward_module'", ",", "reward_module", ")", "\n", "\n", "enablePrint", "(", ")", "\n", "print", "(", "\"OK!\"", ")", "\n", "\n", "\"\"\"Add the real dataset\"\"\"", "\n", "if", "amt_real_data", "is", "None", ":", "\n", "    ", "agent", ".", "replay_buffer", ".", "buffer", ".", "add_batch", "(", "*", "dataset", ")", "\n", "", "else", ":", "\n", "    ", "agent", ".", "replay_buffer", ".", "buffer", ".", "add_batch", "(", "*", "[", "x", "[", ":", "amt_real_data", "]", "for", "x", "in", "dataset", "]", ")", "\n", "\n", "", "\"\"\"Train the attention model on real data only\"\"\"", "\n", "attn_losses", ",", "rew_losses", "=", "[", "]", ",", "[", "]", "\n", "print", "(", "\"Training attention model...\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "2000", ")", ")", ":", "\n", "    ", "attn_losses", ".", "append", "(", "agent", ".", "coda_attention_model", ".", "_optimize", "(", ")", ")", "\n", "rew_losses", ".", "append", "(", "agent", ".", "reward_module", ".", "_optimize", "(", ")", ")", "\n", "\n", "", "\"\"\"Make sure it trained OK\"\"\"", "\n", "assert", "np", ".", "mean", "(", "attn_losses", "[", "-", "10", ":", "]", ")", "<", "0.005", "\n", "assert", "np", ".", "mean", "(", "rew_losses", "[", "-", "10", ":", "]", ")", "<", "0.1", "\n", "\n", "\"\"\"Add the extra (MBPO) data before applying CoDA\"\"\"", "\n", "if", "amt_real_data", "is", "not", "None", ":", "\n", "    ", "agent", ".", "replay_buffer", ".", "buffer", ".", "add_batch", "(", "*", "[", "x", "[", "amt_real_data", ":", "]", "for", "x", "in", "dataset", "]", ")", "\n", "\n", "", "\"\"\"Now let's make some Coda data\"\"\"", "\n", "print", "(", "\"Making Coda data...\"", ")", "\n", "from", "functools", "import", "partial", "\n", "agent", ".", "get_coda_mask", "=", "partial", "(", "agent", ".", "coda_attention_model", ".", "get_mask", ",", "THRESH", "=", "0.02", ")", "\n", "if", "reward_fn", "is", "None", ":", "\n", "    ", "agent", ".", "replay_buffer", ".", "reward_fn", "=", "agent", ".", "reward_module", ".", "compute_reward", "\n", "", "else", ":", "\n", "    ", "agent", ".", "replay_buffer", ".", "reward_fn", "=", "reward_fn", "\n", "\n", "# Do one step to see how much Coda data is made", "\n", "", "agent", ".", "replay_buffer", ".", "_optimize", "(", ")", "\n", "delta", "=", "len", "(", "agent", ".", "replay_buffer", ".", "coda_buffer", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "int", "(", "coda_data", "+", "15000", ")", "//", "delta", ")", ")", ":", "\n", "    ", "agent", ".", "replay_buffer", ".", "_optimize", "(", ")", "\n", "\n", "\n", "", "s", ",", "a", ",", "r", ",", "ns", ",", "d", "=", "dataset", "\n", "\n", "CODASIZE", "=", "min", "(", "coda_data", ",", "len", "(", "agent", ".", "replay_buffer", ".", "coda_buffer", ")", ")", "\n", "coda_s", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'state'", "]", ".", "data", "[", ":", "CODASIZE", "]", "\n", "coda_a", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'action'", "]", ".", "data", "[", ":", "CODASIZE", "]", "\n", "coda_ns", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'next_state'", "]", ".", "data", "[", ":", "CODASIZE", "]", "\n", "coda_d", "=", "agent", ".", "replay_buffer", ".", "coda_buffer", ".", "items", "[", "'done'", "]", ".", "data", "[", ":", "CODASIZE", "]", "\n", "\n", "# Manually relabel reward since coda buffer doesn't do it until you sample", "\n", "# In 20 sections just to make sure it doesn't blow the memory.", "\n", "coda_r", "=", "[", "]", "\n", "for", "x", ",", "y", ",", "z", "in", "zip", "(", "np", ".", "array_split", "(", "coda_s", ",", "20", ")", ",", "np", ".", "array_split", "(", "coda_a", ",", "20", ")", ",", "np", ".", "array_split", "(", "coda_ns", ",", "20", ")", ")", ":", "\n", "    ", "coda_r", ".", "append", "(", "agent", ".", "replay_buffer", ".", "reward_fn", "(", "x", ",", "y", ",", "z", ")", ")", "\n", "", "coda_r", "=", "np", ".", "concatenate", "(", "coda_r", ",", "0", ")", "\n", "\n", "dataset", "=", "(", "\n", "np", ".", "concatenate", "(", "(", "s", ",", "coda_s", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "a", ",", "coda_a", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "r", ",", "coda_r", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "ns", ",", "coda_ns", ")", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "d", ",", "coda_d", ")", ")", "\n", ")", "\n", "\n", "print", "(", "f'Successfully made {CODASIZE} coda samples!'", ")", "\n", "return", "dataset", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_latex_table.parse_title": [[7, 16], ["csv_filename.split", "res.append", "res.append", "[].split", "f.split"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["def", "parse_title", "(", "csv_filename", ",", "items", "=", "[", "'seed'", ",", "'real'", ",", "'coda'", ",", "'noise'", ",", "'dyna'", ",", "'roll'", ",", "'mbpo'", ",", "'c3xm'", "]", ")", ":", "\n", "  ", "f", "=", "csv_filename", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "res", "=", "[", "]", "\n", "for", "item", "in", "items", ":", "\n", "    ", "if", "item", "in", "f", ":", "\n", "      ", "res", ".", "append", "(", "f", ".", "split", "(", "item", ")", "[", "-", "1", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "      ", "res", ".", "append", "(", "None", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.pong.make_latex_table.make_latex_table": [[17, 79], ["glob.glob", "collections.defaultdict", "make_latex_table.parse_title", "pandas.read_csv", "[].append", "max", "zip", "print", "collections.defaultdict", "int", "int", "int", "int", "int", "[].mean", "len", "means.append", "stds.append", "int", "int", "len", "numpy.mean().round", "range", "numpy.std().round", "numpy.array", "resampled_means.append", "int", "numpy.mean", "numpy.mean", "numpy.std", "sklearn.utils.resample"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.pong.make_latex_table.parse_title", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "make_latex_table", "(", "args", ")", ":", "\n", "  ", "csvs", "=", "glob", ".", "glob", "(", "f'{args.results_folder}/**/*Success.csv'", ")", "\n", "\n", "results", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "list", ")", ")", "\n", "for", "csv", "in", "csvs", ":", "\n", "    ", "seed", ",", "real", ",", "coda", ",", "_", ",", "dyna", ",", "roll", ",", "mbpo", ",", "c3xm", "=", "parse_title", "(", "csv", ")", "\n", "coda_to_real_ratio", "=", "int", "(", "coda", ")", "//", "int", "(", "real", ")", "\n", "csv", "=", "pandas", ".", "read_csv", "(", "csv", ")", "\n", "dyna", "=", "dyna", "and", "int", "(", "dyna", ")", "\n", "mbpo", "=", "mbpo", "and", "int", "(", "mbpo", ")", "\n", "c3xm", "=", "c3xm", "and", "int", "(", "c3xm", ")", "\n", "if", "c3xm", ":", "\n", "      ", "mbpo", "=", "c3xm", "\n", "", "if", "dyna", ":", "\n", "      ", "coda_to_real_ratio", "=", "f'{coda_to_real_ratio}_{roll}'", "\n", "", "if", "mbpo", ":", "\n", "      ", "mbpo_to_real_ratio", "=", "int", "(", "mbpo", ")", "//", "int", "(", "real", ")", "\n", "if", "c3xm", ":", "\n", "        ", "coda_to_real_ratio", "=", "f'{coda_to_real_ratio}_{mbpo_to_real_ratio}_{roll}_c3'", "\n", "", "else", ":", "\n", "        ", "coda_to_real_ratio", "=", "f'{coda_to_real_ratio}_{mbpo_to_real_ratio}_{roll}'", "\n", "", "", "BASE", "=", "500", "\n", "results", "[", "real", "]", "[", "coda_to_real_ratio", "]", ".", "append", "(", "csv", "[", "'Test/Success'", "]", "[", "BASE", "-", "20", ":", "BASE", "]", ".", "mean", "(", ")", ")", "\n", "\n", "", "for", "datasize", "in", "[", "'25000'", ",", "'50000'", ",", "'75000'", ",", "'100000'", ",", "'150000'", ",", "'250000'", "]", ":", "\n", "    ", "hphantom", "=", "''", "\n", "if", "len", "(", "datasize", ")", "==", "5", ":", "\n", "      ", "hphantom", "=", "'\\hphantom{0}'", "\n", "", "s", "=", "[", "f'${hphantom}{int(datasize)//1000}$'", ",", "'&'", "]", "\n", "# 0_1 : Dyna 1 step", "\n", "# 0_1_1 : MBPO 1 step", "\n", "# 0_1_5 : MBPO 5 step", "\n", "# 3_1_1 : CODA+MBPO 1 step", "\n", "# 3_1_5 : CODA+MBPO 5 step", "\n", "#for coda_to_real_ratio in [0, 1, 3, 5]:", "\n", "means", "=", "[", "]", "\n", "stds", "=", "[", "]", "\n", "#for coda_to_real_ratio in [0, 1, 3, 5, '0_1_5', '0_1_5_c3']:", "\n", "for", "coda_to_real_ratio", "in", "[", "0", ",", "'0_1'", ",", "'0_1_5'", ",", "1", ",", "2", ",", "3", ",", "5", ",", "'3_1_5'", "]", ":", "\n", "      ", "values", "=", "results", "[", "datasize", "]", "[", "coda_to_real_ratio", "]", "\n", "if", "len", "(", "values", ")", "not", "in", "[", "5", ",", "10", "]", ":", "# TODO If more/less than 10 seeds are run, change this. ", "\n", "        ", "mean", "=", "-", "1", "\n", "std", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "values", "=", "np", ".", "array", "(", "values", ")", "*", "100", "\n", "mean", "=", "(", "np", ".", "mean", "(", "values", ")", ")", ".", "round", "(", "1", ")", "\n", "# BOOTSTRAP THE STANDARD ERROR", "\n", "resampled_means", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "          ", "resampled_means", ".", "append", "(", "np", ".", "mean", "(", "resample", "(", "values", ")", ")", ")", "\n", "", "std", "=", "np", ".", "std", "(", "resampled_means", ")", ".", "round", "(", "1", ")", "\n", "", "hphantom", "=", "''", "\n", "#if len(str(std).split('.')[0]) == 1:", "\n", "#  hphantom='\\hphantom{0}'", "\n", "means", ".", "append", "(", "mean", ")", "\n", "stds", ".", "append", "(", "std", ")", "\n", "", "max_mean", "=", "max", "(", "means", ")", "\n", "for", "(", "mean", ",", "std", ")", "in", "zip", "(", "means", ",", "stds", ")", ":", "\n", "      ", "m", "=", "f'\\mybm{{{mean}}}'", "if", "mean", "==", "max_mean", "else", "mean", "\n", "s", "+=", "[", "f'${m} \\pm {hphantom}{std}$ '", ",", "'&'", "]", "\n", "", "s", "=", "s", "[", ":", "-", "1", "]", "+", "[", "'\\\\\\\\'", "]", "\n", "print", "(", "*", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mega.make_env.make_env": [[18, 177], ["numpy.array", "float", "gym.envs.registry.env_specs.get", "gym.make", "args.env.lower", "float", "gym.wrappers.TimeLimit", "gym.wrappers.TimeLimit", "args.env.lower", "args.per_dim_threshold.split", "envs.customfetch.custom_fetch.DictPushAndReach", "envs.customfetch.custom_fetch.DictPushAndReach", "gym.wrappers.TimeLimit", "gym.wrappers.TimeLimit", "args.env.lower", "envs.customfetch.custom_fetch.DictPush", "envs.customfetch.custom_fetch.DictPush", "envs.sibrivalry.toy_maze.PointMaze2D", "envs.sibrivalry.toy_maze.PointMaze2D", "args.env.lower", "envs.sibrivalry.toy_maze.SimpleMazeEnv", "envs.sibrivalry.toy_maze.SimpleMazeEnv", "args.env.lower", "make_moat_env", "make_moat_env", "args.env.lower", "args.env.lower", "args.env.lower", "envs.sibrivalry.ant_maze.AntMazeEnv", "envs.sibrivalry.ant_maze.AntMazeEnv", "args.env.lower", "envs.sibrivalry.ant_maze.AntMazeEnv", "envs.sibrivalry.ant_maze.AntMazeEnv", "args.env.lower", "envs.goalgan.ant_maze.AntMazeEnv", "envs.goalgan.ant_maze.AntMazeEnv", "envs.sibrivalry.ant_maze.AntMazeEnv", "envs.sibrivalry.ant_maze.AntMazeEnv", "envs.sibrivalry.ant_maze.AntMazeEnv", "envs.sibrivalry.ant_maze.AntMazeEnv", "args.env.split", "max", "args.env.lower", "args.env.lower", "args.env.lower", "mode.split", "HandEnv", "HandObjectDict.keys", "args.env.lower", "args.env.split", "max", "args.eval_env.lower", "gym.make", "gym.make", "envs.customfetch.custom_hand.HandReachFullEnv", "gym.make", "args.env.lower", "float", "float", "envs.customfetch.custom_fetch.PushRight", "envs.customfetch.custom_fetch.PushLeft", "args.env.lower", "float", "envs.customfetch.custom_fetch.PushRight", "envs.customfetch.custom_fetch.PushRight", "args.env.lower", "envs.customfetch.custom_fetch.PushLeft", "envs.customfetch.custom_fetch.PushRight", "args.env.lower", "envs.customfetch.custom_fetch.PushLeft", "envs.customfetch.custom_fetch.PushLeft", "args.env.lower", "envs.customfetch.custom_fetch.FetchHookSweepAllEnv", "envs.customfetch.custom_fetch.FetchHookSweepAllEnv", "args.env.lower", "args.env.split", "envs.customfetch.custom_fetch.FetchHookSweepAllEnv", "envs.customfetch.custom_fetch.FetchHookSweepAllEnv", "external.lower", "internal.lower", "env.lower", "Env", "Env", "external.lower", "internal.lower", "env.lower", "external.lower", "internal.lower", "env.lower", "external.lower", "internal.lower", "env.lower", "int", "external.lower", "env.lower().replace", "env.lower", "int", "ValueError", "external.lower", "env.lower().replace", "env.lower", "env.lower"], "function", ["None"], ["def", "make_env", "(", "args", ")", ":", "\n", "  ", "if", "','", "in", "args", ".", "per_dim_threshold", ":", "\n", "    ", "per_dim_threshold", "=", "np", ".", "array", "(", "[", "float", "(", "t", ")", "for", "t", "in", "args", ".", "per_dim_threshold", ".", "split", "(", "','", ")", "]", ")", "\n", "", "else", ":", "\n", "    ", "per_dim_threshold", "=", "float", "(", "args", ".", "per_dim_threshold", ")", "\n", "\n", "", "if", "gym", ".", "envs", ".", "registry", ".", "env_specs", ".", "get", "(", "args", ".", "env", ")", "is", "not", "None", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "gym", ".", "make", "(", "args", ".", "env", ")", "\n", "eval_env_fn", "=", "env_fn", "\n", "", "elif", "'dictpushandreach'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "TimeLimit", "(", "DictPushAndReach", "(", ")", ",", "50", ")", "\n", "eval_env_fn", "=", "lambda", ":", "TimeLimit", "(", "DictPushAndReach", "(", ")", ",", "50", ")", "\n", "", "elif", "'dictpush'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "TimeLimit", "(", "DictPush", "(", ")", ",", "50", ")", "\n", "eval_env_fn", "=", "lambda", ":", "TimeLimit", "(", "DictPush", "(", ")", ",", "50", ")", "\n", "", "elif", "'pointmaze'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "PointMaze2D", "(", ")", "\n", "eval_env_fn", "=", "lambda", ":", "PointMaze2D", "(", "test", "=", "True", ")", "\n", "", "elif", "'simplemaze'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "SimpleMazeEnv", "(", ")", "\n", "eval_env_fn", "=", "lambda", ":", "SimpleMazeEnv", "(", "test", "=", "True", ")", "\n", "", "elif", "'moat'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "make_moat_env", "(", "slow_factor", "=", "args", ".", "slow_factor", ")", "\n", "eval_env_fn", "=", "lambda", ":", "make_moat_env", "(", "slow_factor", "=", "args", ".", "slow_factor", ")", "\n", "", "elif", "'antmaze'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "if", "'hiro'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntMaze-HIRO'", ",", "eval", "=", "False", ")", "\n", "eval_env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntMaze-HIRO'", ",", "eval", "=", "True", ")", "\n", "", "elif", "'gg'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "GGAntMaze", "(", "eval", "=", "False", ")", "\n", "eval_env_fn", "=", "lambda", ":", "GGAntMaze", "(", "eval", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntMaze-SR'", ",", "eval", "=", "False", ")", "\n", "eval_env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntMaze-SR'", ",", "eval", "=", "True", ")", "\n", "", "", "elif", "'antpush'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntPush'", ",", "eval", "=", "False", ")", "\n", "eval_env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntPush'", ",", "eval", "=", "True", ")", "\n", "", "elif", "'antfall'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntFall'", ",", "eval", "=", "False", ")", "\n", "eval_env_fn", "=", "lambda", ":", "AntMazeEnv", "(", "variant", "=", "'AntFall'", ",", "eval", "=", "True", ")", "\n", "", "elif", "(", "'pen_'", "in", "args", ".", "env", ".", "lower", "(", ")", ")", "or", "(", "'block_'", "in", "args", ".", "env", ".", "lower", "(", ")", ")", "or", "(", "'egg_'", "in", "args", ".", "env", ".", "lower", "(", ")", ")", ":", "\n", "# The environment name is of the form: {block,pen,egg}_{full,rotate-{z,parallel,xyz}}_{dist_thres}_{rot_thres}", "\n", "    ", "env_type", ",", "mode", ",", "dt", ",", "rt", "=", "args", ".", "env", ".", "split", "(", "'_'", ")", "\n", "\n", "if", "mode", "==", "\"full\"", ":", "\n", "      ", "target_pos", "=", "'random'", "\n", "target_rot", "=", "'xyz'", "\n", "mode_str", "=", "\"Full\"", "\n", "", "else", ":", "\n", "      ", "assert", "(", "\"rotate\"", "in", "mode", ")", "\n", "mode_str", "=", "\"Rotate\"", "\n", "target_pos", "=", "'ignore'", "\n", "_", ",", "target_rot", "=", "mode", ".", "split", "(", "'-'", ")", "\n", "assert", "(", "target_rot", "in", "[", "'z'", ",", "'parallel'", ",", "'xyz'", ",", "''", "]", ")", "\n", "mode_str", "=", "\"Rotate{}\"", ".", "format", "(", "RotationDict", "[", "target_rot", "]", ")", "# Some hand env don't specify the rotation type", "\n", "# if target_rot == '', set this to 'xyz'", "\n", "if", "target_rot", "==", "''", ":", "\n", "        ", "target_rot", "=", "'xyz'", "\n", "\n", "", "", "if", "env_type", "==", "'block'", ":", "\n", "      ", "HandEnv", "=", "HandBlockEnv", "\n", "", "elif", "env_type", "==", "'pen'", ":", "\n", "      ", "HandEnv", "=", "HandPenEnv", "\n", "", "elif", "env_type", "==", "'egg'", ":", "\n", "      ", "HandEnv", "=", "HandEggEnv", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "\n", "\n", "", "max_step", "=", "max", "(", "args", ".", "env_max_step", ",", "100", ")", "\n", "env_fn", "=", "lambda", ":", "HandEnv", "(", "max_step", "=", "max_step", ",", "distance_threshold", "=", "float", "(", "dt", ")", ",", "rotation_threshold", "=", "float", "(", "rt", ")", ",", "target_position", "=", "target_pos", ",", "target_rotation", "=", "target_rot", ")", "\n", "assert", "(", "env_type", "in", "HandObjectDict", ".", "keys", "(", ")", ")", "\n", "gym_env_str", "=", "\"HandManipulate{}{}-v0\"", ".", "format", "(", "HandObjectDict", "[", "env_type", "]", ",", "mode_str", ")", "\n", "if", "args", ".", "eval_env", "and", "args", ".", "eval_env", ".", "lower", "(", ")", "!=", "'none'", ":", "\n", "      ", "eval_env_fn", "=", "lambda", ":", "gym", ".", "make", "(", "args", ".", "eval_env", ")", "\n", "", "else", ":", "\n", "      ", "eval_env_fn", "=", "lambda", ":", "gym", ".", "make", "(", "gym_env_str", ")", "\n", "\n", "", "", "elif", "(", "'handreach_'", "in", "args", ".", "env", ".", "lower", "(", ")", ")", ":", "\n", "    ", "env_type", ",", "dt", "=", "args", ".", "env", ".", "split", "(", "'_'", ")", "\n", "max_step", "=", "max", "(", "args", ".", "env_max_step", ",", "50", ")", "\n", "env_fn", "=", "lambda", ":", "HandReachFullEnv", "(", "max_step", "=", "max_step", ",", "distance_threshold", "=", "float", "(", "dt", ")", ")", "\n", "eval_env_fn", "=", "lambda", ":", "gym", ".", "make", "(", "'HandReach-v0'", ")", "\n", "", "elif", "args", ".", "env", ".", "lower", "(", ")", "==", "'pushright_pushleft'", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "PushRight", "(", ")", "\n", "eval_env_fn", "=", "lambda", ":", "PushLeft", "(", ")", "\n", "", "elif", "args", ".", "env", ".", "lower", "(", ")", "==", "'pushright_pushright'", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "PushRight", "(", ")", "\n", "eval_env_fn", "=", "lambda", ":", "PushRight", "(", ")", "\n", "", "elif", "args", ".", "env", ".", "lower", "(", ")", "==", "'pushleft_pushright'", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "PushLeft", "(", ")", "\n", "eval_env_fn", "=", "lambda", ":", "PushRight", "(", ")", "\n", "", "elif", "args", ".", "env", ".", "lower", "(", ")", "==", "'pushleft_pushleft'", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "PushLeft", "(", ")", "\n", "eval_env_fn", "=", "lambda", ":", "PushLeft", "(", ")", "\n", "", "elif", "args", ".", "env", ".", "lower", "(", ")", "==", "'sweep2'", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "FetchHookSweepAllEnv", "(", "place_two", "=", "True", ")", "\n", "eval_env_fn", "=", "lambda", ":", "FetchHookSweepAllEnv", "(", "place_two", "=", "True", ")", "\n", "", "elif", "args", ".", "env", ".", "lower", "(", ")", "==", "'sweep'", ":", "\n", "      ", "env_fn", "=", "lambda", ":", "FetchHookSweepAllEnv", "(", "smaller_state", "=", "True", ",", "place_two", "=", "True", ",", "place_random", "=", "False", ")", "\n", "eval_env_fn", "=", "lambda", ":", "FetchHookSweepAllEnv", "(", "smaller_state", "=", "True", ",", "place_two", "=", "True", ",", "place_random", "=", "False", ")", "\n", "", "else", ":", "\n", "    ", "env", ",", "external", ",", "internal", "=", "args", ".", "env", ".", "split", "(", "'_'", ")", "\n", "if", "external", ".", "lower", "(", ")", "==", "'all'", ":", "\n", "      ", "external", "=", "GoalType", ".", "ALL", "\n", "", "elif", "external", ".", "lower", "(", ")", "==", "'objgrip'", ":", "\n", "      ", "external", "=", "GoalType", ".", "OBJ_GRIP", "\n", "", "elif", "external", ".", "lower", "(", ")", "==", "'objspeed'", ":", "\n", "      ", "external", "=", "GoalType", ".", "OBJSPEED", "\n", "", "elif", "external", ".", "lower", "(", ")", "==", "'objspeedrot'", ":", "\n", "      ", "external", "=", "GoalType", ".", "OBJSPEED2", "\n", "", "elif", "external", ".", "lower", "(", ")", "==", "'obj'", ":", "\n", "      ", "external", "=", "GoalType", ".", "OBJ", "\n", "", "elif", "external", ".", "lower", "(", ")", "==", "'grip'", ":", "\n", "      ", "external", "=", "GoalType", ".", "GRIP", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "\n", "\n", "", "if", "internal", ".", "lower", "(", ")", "==", "'all'", ":", "\n", "      ", "raise", "ValueError", "\n", "", "elif", "internal", ".", "lower", "(", ")", "==", "'objgrip'", ":", "\n", "      ", "internal", "=", "GoalType", ".", "OBJ_GRIP", "\n", "", "elif", "internal", ".", "lower", "(", ")", "==", "'obj'", ":", "\n", "      ", "internal", "=", "GoalType", ".", "OBJ", "\n", "", "elif", "internal", ".", "lower", "(", ")", "==", "'grip'", ":", "\n", "      ", "internal", "=", "GoalType", ".", "GRIP", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "\n", "\n", "", "n_blocks", "=", "0", "\n", "range_min", "=", "None", "# For pickplace", "\n", "range_max", "=", "None", "# For pickplace", "\n", "if", "env", ".", "lower", "(", ")", "==", "'push'", ":", "\n", "      ", "Env", "=", "PushEnv", "\n", "", "elif", "env", ".", "lower", "(", ")", "==", "'slide'", ":", "\n", "      ", "Env", "=", "SlideEnv", "\n", "", "elif", "env", ".", "lower", "(", ")", "==", "'pickplace'", ":", "\n", "      ", "Env", "=", "PickPlaceEnv", "\n", "n_blocks", "=", "args", ".", "pp_in_air_percentage", "# THIS IS THE \"IN_AIR_PERCENTAGE\"", "\n", "range_min", "=", "args", ".", "pp_min_air", "# THIS IS THE MINIMUM_AIR", "\n", "range_max", "=", "args", ".", "pp_max_air", "# THIS IS THE MINIMUM_AIR", "\n", "", "elif", "'stack'", "in", "env", ".", "lower", "(", ")", ":", "\n", "      ", "Env", "=", "StackEnv", "\n", "n_blocks", "=", "int", "(", "env", ".", "lower", "(", ")", ".", "replace", "(", "'stack'", ",", "''", ")", ")", "\n", "", "elif", "'slide'", "in", "env", ".", "lower", "(", ")", ":", "\n", "      ", "Env", "=", "SlideNEnv", "\n", "n_blocks", "=", "int", "(", "env", ".", "lower", "(", ")", ".", "replace", "(", "'slide'", ",", "''", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Invalid environment\"", ")", "\n", "\n", "\n", "", "env_fn", "=", "lambda", ":", "Env", "(", "max_step", "=", "args", ".", "env_max_step", ",", "internal_goal", "=", "internal", ",", "external_goal", "=", "external", ",", "mode", "=", "args", ".", "reward_mode", ",", "\n", "per_dim_threshold", "=", "per_dim_threshold", ",", "hard", "=", "args", ".", "hard", ",", "distance_threshold", "=", "args", ".", "train_dt", ",", "n", "=", "n_blocks", ",", "\n", "range_min", "=", "range_min", ",", "range_max", "=", "range_max", ")", "\n", "\n", "eval_env_fn", "=", "lambda", ":", "Env", "(", "max_step", "=", "50", ",", "internal_goal", "=", "internal", ",", "\n", "external_goal", "=", "external", ",", "mode", "=", "args", ".", "reward_mode", ",", "compute_reward_with_internal", "=", "args", ".", "test_with_internal", ",", "\n", "hard", "=", "args", ".", "hard", ",", "n", "=", "n_blocks", ",", "range_min", "=", "range_min", ",", "range_max", "=", "range_max", ")", "\n", "", "return", "env_fn", ",", "eval_env_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.mega.train_mega.SweepSafetyInterest.__init__": [[15, 19], ["mrl.Module.__init__", "numpy.array", "numpy.array", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'ag_interest'", ",", "required_agent_modules", "=", "[", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "lower_bounds", "=", "np", ".", "array", "(", "[", "1.35", ",", "0.55", ",", "0.415", ",", "1.35", ",", "0.55", ",", "0.415", "]", ")", "\n", "self", ".", "upper_bounds", "=", "np", ".", "array", "(", "[", "2.35", ",", "0.95", ",", "0.8", ",", "2.35", ",", "0.95", ",", "0.8", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mega.train_mega.SweepSafetyInterest.ready": [[20, 23], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "ready", "(", "self", ")", ":", "\n", "    ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mega.train_mega.SweepSafetyInterest.evaluate_log_interest": [[24, 35], ["ags.reshape", "numpy.logical_and", "numpy.all().astype.reshape", "numpy.all().astype", "numpy.all"], "methods", ["None"], ["", "def", "evaluate_log_interest", "(", "self", ",", "ags", ")", ":", "\n", "# baseline is approx. avg density of demo ags == to scale the interest to \"max_interest_factor\"", "\n", "    ", "shaped_ags", "=", "ags", ".", "reshape", "(", "-", "1", ",", "6", ")", "\n", "above_lower_bound", "=", "shaped_ags", ">", "self", ".", "lower_bounds", "\n", "below_upper_bound", "=", "shaped_ags", "<", "self", ".", "upper_bounds", "\n", "in_bounds", "=", "np", ".", "logical_and", "(", "above_lower_bound", ",", "below_upper_bound", ")", "\n", "in_bounds", "=", "in_bounds", ".", "reshape", "(", "ags", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "in_bounds", "=", "np", ".", "all", "(", "in_bounds", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "interest", "=", "(", "in_bounds", "-", "1.", ")", "*", "1e6", "\n", "\n", "return", "interest", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mega.train_mega.main": [[41, 272], ["merge_args_into_config", "make_agent_name", "config.update", "ContinuousActionNoise", "experiments.mega.make_env.make_env", "EnvModule", "EnvModule", "mrl.config_to_agent", "max", "dict", "EntropyPrioritizedOnlineHERBuffer", "train_mega.SweepSafetyInterest", "RawKernelDensity", "RawKernelDensity", "RawKernelDensity", "args.noise_type.lower", "args.noise_type.lower", "args.alg.lower", "DDPG", "args.alg.lower", "PytorchModel", "PytorchModel", "PytorchModel", "PytorchModel", "GoalEnvReward", "print", "mrl.config_to_agent.load", "numpy.round", "numpy.round", "CuriosityAlphaMixtureModule", "RandomNetworkDensity", "FlowDensity", "QAchievedGoalCuriosity", "ConstantSchedule", "args.alg.lower", "TD3", "FirstVisitDoneWrapper", "FirstVisitDoneWrapper", "args.alg.lower", "PytorchModel", "NeighborReward", "PytorchModel", "ValueError", "mrl.config_to_agent.eval_mode", "mrl.config_to_agent.train", "mrl.config_to_agent.eval_mode", "range", "print", "mrl.config_to_agent.load", "mrl.config_to_agent.eval_mode", "print", "numpy.mean", "mrl.config_to_agent.logger.log_color", "range", "mp.cpu_count", "StandardTrain", "EpisodicEval", "ActorPolicy", "Logger", "Normalizer", "OnlineHERBuffer", "QAchievedGoalCuriosity", "args.alg.lower", "DQN", "QValuePolicy", "LinearSchedule", "env1", "eval_env1", "Critic", "Actor", "Critic", "Critic", "print", "env.reset", "env.render", "len", "print", "env.reset", "print", "open", "pickle.dump", "int", "time.time", "mrl.config_to_agent.train", "numpy.mean", "mrl.config_to_agent.logger.log_color", "mrl.config_to_agent.logger.log_color", "print", "mrl.config_to_agent.save", "MeanStdNormalizer", "DensityAchievedGoalCuriosity", "FCBody", "FCBody", "FCBody", "Critic", "FCBody", "FCBody", "time.sleep", "mrl.config_to_agent.policy", "env.step", "env.render", "print", "len", "raw_env._get_obs", "mrl.config_to_agent.policy", "env.step", "collected_exps.append", "os.path.join", "mrl.config_to_agent.eval", "numpy.random.choice", "numpy.arange", "mrl.config_to_agent.logger.add_embedding", "mrl.config_to_agent.logger.add_embedding", "mrl.config_to_agent.logger.add_embedding", "DensityAchievedGoalCuriosity", "make_activ", "make_activ", "make_activ", "FCBody", "make_activ", "numpy.random.random", "mrl.config_to_agent.action_noise", "raw_env._get_obs", "len", "max", "len", "ag_buffer.get_batch", "ag_buffer.get_batch", "bg_buffer.get_batch", "mrl.config_to_agent.eval", "DensityAchievedGoalCuriosity", "make_activ", "min", "time.time", "DensityAchievedGoalCuriosity", "len", "len", "DensityAchievedGoalCuriosity", "DensityAchievedGoalCuriosity", "GoalSuccessPredictor", "SuccessAchievedGoalCuriosity", "RawKernelDensity", "RawJointKernelDensity", "EntropyGainScoringGoalCuriosity"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.merge_args_into_config", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_agent_name", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "# 4. Update the config with args, and make the agent name. ", "\n", "  ", "if", "args", ".", "num_envs", "is", "None", ":", "\n", "    ", "import", "multiprocessing", "as", "mp", "\n", "args", ".", "num_envs", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "1", ")", "\n", "\n", "", "merge_args_into_config", "(", "args", ",", "config", ")", "\n", "\n", "if", "config", ".", "gamma", "<", "1.", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "(", "1", "/", "(", "1", "-", "config", ".", "gamma", ")", ")", ",", "2", ")", ",", "0.", ")", "\n", "if", "config", ".", "gamma", "==", "1", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "args", ".", "env_max_step", "-", "5", ",", "2", ")", ",", "0.", ")", "\n", "\n", "if", "args", ".", "sparse_reward_shaping", ":", "\n", "    ", "config", ".", "clip_target_range", "=", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ")", "\n", "\n", "", "config", ".", "agent_name", "=", "make_agent_name", "(", "config", ",", "[", "'env'", ",", "'alg'", ",", "'her'", ",", "'layers'", ",", "'seed'", ",", "'tb'", ",", "'ag_curiosity'", ",", "'eexplore'", ",", "'first_visit_succ'", ",", "'dg_score_multiplier'", ",", "'alpha'", "]", ",", "prefix", "=", "args", ".", "prefix", ")", "\n", "\n", "# 5. Setup / add basic modules to the config", "\n", "config", ".", "update", "(", "\n", "dict", "(", "\n", "trainer", "=", "StandardTrain", "(", ")", ",", "\n", "evaluation", "=", "EpisodicEval", "(", ")", ",", "\n", "policy", "=", "ActorPolicy", "(", ")", ",", "\n", "logger", "=", "Logger", "(", ")", ",", "\n", "state_normalizer", "=", "Normalizer", "(", "MeanStdNormalizer", "(", ")", ")", ",", "\n", "replay", "=", "OnlineHERBuffer", "(", ")", ",", "\n", ")", ")", "\n", "\n", "config", ".", "prioritized_mode", "=", "args", ".", "prioritized_mode", "\n", "if", "config", ".", "prioritized_mode", "==", "'mep'", ":", "\n", "    ", "config", ".", "prioritized_replay", "=", "EntropyPrioritizedOnlineHERBuffer", "(", ")", "\n", "\n", "", "if", "args", ".", "sweep_safety_interest", ":", "\n", "    ", "assert", "'sweep'", "in", "args", ".", "env", "\n", "config", ".", "ag_interest", "=", "SweepSafetyInterest", "(", ")", "\n", "\n", "", "if", "not", "args", ".", "no_ag_kde", ":", "\n", "    ", "config", ".", "ag_kde", "=", "RawKernelDensity", "(", "'ag'", ",", "optimize_every", "=", "1", ",", "samples", "=", "10000", ",", "kernel", "=", "args", ".", "kde_kernel", ",", "bandwidth", "=", "args", ".", "bandwidth", ",", "log_entropy", "=", "True", ")", "\n", "", "if", "args", ".", "ag_curiosity", "is", "not", "None", ":", "\n", "    ", "config", ".", "dg_kde", "=", "RawKernelDensity", "(", "'dg'", ",", "optimize_every", "=", "500", ",", "samples", "=", "10000", ",", "kernel", "=", "'tophat'", ",", "bandwidth", "=", "0.2", ")", "\n", "config", ".", "ag_kde_tophat", "=", "RawKernelDensity", "(", "'ag'", ",", "optimize_every", "=", "100", ",", "samples", "=", "10000", ",", "kernel", "=", "'tophat'", ",", "bandwidth", "=", "0.2", ",", "tag", "=", "'_tophat'", ")", "\n", "if", "args", ".", "transition_to_dg", ":", "\n", "      ", "config", ".", "alpha_curiosity", "=", "CuriosityAlphaMixtureModule", "(", ")", "\n", "", "if", "'rnd'", "in", "args", ".", "ag_curiosity", ":", "\n", "      ", "config", ".", "ag_rnd", "=", "RandomNetworkDensity", "(", "'ag'", ")", "\n", "", "if", "'flow'", "in", "args", ".", "ag_curiosity", ":", "\n", "      ", "config", ".", "ag_flow", "=", "FlowDensity", "(", "'ag'", ")", "\n", "\n", "", "use_qcutoff", "=", "not", "args", ".", "no_cutoff", "\n", "\n", "if", "args", ".", "ag_curiosity", "==", "'minq'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "QAchievedGoalCuriosity", "(", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'randq'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "QAchievedGoalCuriosity", "(", "max_steps", "=", "args", ".", "env_max_step", ",", "randomize", "=", "True", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'minkde'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'minrnd'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "'ag_rnd'", ",", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'minflow'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "'ag_flow'", ",", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'randkde'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "alpha", "=", "args", ".", "alpha", ",", "max_steps", "=", "args", ".", "env_max_step", ",", "randomize", "=", "True", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'randrnd'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "'ag_rnd'", ",", "alpha", "=", "args", ".", "alpha", ",", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'randflow'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "'ag_flow'", ",", "alpha", "=", "args", ".", "alpha", ",", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'goaldisc'", ":", "\n", "      ", "config", ".", "success_predictor", "=", "GoalSuccessPredictor", "(", "batch_size", "=", "args", ".", "succ_bs", ",", "history_length", "=", "args", ".", "succ_hl", ",", "optimize_every", "=", "args", ".", "succ_oe", ")", "\n", "config", ".", "ag_curiosity", "=", "SuccessAchievedGoalCuriosity", "(", "max_steps", "=", "args", ".", "env_max_step", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "elif", "args", ".", "ag_curiosity", "==", "'entropygainscore'", ":", "\n", "      ", "config", ".", "bg_kde", "=", "RawKernelDensity", "(", "'bg'", ",", "optimize_every", "=", "args", ".", "env_max_step", ",", "samples", "=", "10000", ",", "kernel", "=", "args", ".", "kde_kernel", ",", "bandwidth", "=", "args", ".", "bandwidth", ",", "log_entropy", "=", "True", ")", "\n", "config", ".", "bgag_kde", "=", "RawJointKernelDensity", "(", "[", "'bg'", ",", "'ag'", "]", ",", "optimize_every", "=", "args", ".", "env_max_step", ",", "samples", "=", "10000", ",", "kernel", "=", "args", ".", "kde_kernel", ",", "bandwidth", "=", "args", ".", "bandwidth", ",", "log_entropy", "=", "True", ")", "\n", "config", ".", "ag_curiosity", "=", "EntropyGainScoringGoalCuriosity", "(", "max_steps", "=", "args", ".", "env_max_step", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "\n", "\n", "", "", "if", "args", ".", "noise_type", ".", "lower", "(", ")", "==", "'gaussian'", ":", "noise_type", "=", "GaussianProcess", "\n", "if", "args", ".", "noise_type", ".", "lower", "(", ")", "==", "'ou'", ":", "noise_type", "=", "OrnsteinUhlenbeckProcess", "\n", "config", ".", "action_noise", "=", "ContinuousActionNoise", "(", "noise_type", ",", "std", "=", "ConstantSchedule", "(", "args", ".", "action_noise", ")", ")", "\n", "\n", "if", "args", ".", "alg", ".", "lower", "(", ")", "==", "'ddpg'", ":", "\n", "    ", "config", ".", "algorithm", "=", "DDPG", "(", ")", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'td3'", ":", "\n", "    ", "config", ".", "algorithm", "=", "TD3", "(", ")", "\n", "config", ".", "target_network_update_freq", "*=", "2", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'dqn'", ":", "\n", "    ", "config", ".", "algorithm", "=", "DQN", "(", ")", "\n", "config", ".", "policy", "=", "QValuePolicy", "(", ")", "\n", "config", ".", "qvalue_lr", "=", "config", ".", "critic_lr", "\n", "config", ".", "qvalue_weight_decay", "=", "config", ".", "actor_weight_decay", "\n", "config", ".", "double_q", "=", "True", "\n", "config", ".", "random_action_prob", "=", "LinearSchedule", "(", "1.0", ",", "config", ".", "eexplore", ",", "1e5", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n", "# 6. Setup / add the environments and networks (which depend on the environment) to the config", "\n", "", "env", ",", "eval_env", "=", "make_env", "(", "args", ")", "\n", "if", "args", ".", "first_visit_done", ":", "\n", "    ", "env1", ",", "eval_env1", "=", "env", ",", "eval_env", "\n", "env", "=", "lambda", ":", "FirstVisitDoneWrapper", "(", "env1", "(", ")", ")", "\n", "eval_env", "=", "lambda", ":", "FirstVisitDoneWrapper", "(", "eval_env1", "(", ")", ")", "\n", "", "if", "args", ".", "first_visit_succ", ":", "\n", "    ", "config", ".", "first_visit_succ", "=", "True", "\n", "\n", "", "config", ".", "train_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "args", ".", "num_envs", ",", "seed", "=", "args", ".", "seed", ")", "\n", "config", ".", "eval_env", "=", "EnvModule", "(", "eval_env", ",", "num_envs", "=", "args", ".", "num_eval_envs", ",", "name", "=", "'eval_env'", ",", "seed", "=", "args", ".", "seed", "+", "1138", ")", "\n", "\n", "e", "=", "config", ".", "eval_env", "\n", "if", "args", ".", "alg", ".", "lower", "(", ")", "==", "'dqn'", ":", "\n", "    ", "config", ".", "qvalue", "=", "PytorchModel", "(", "'qvalue'", ",", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "e", ".", "action_dim", ")", ")", "\n", "", "else", ":", "\n", "    ", "config", ".", "actor", "=", "PytorchModel", "(", "'actor'", ",", "\n", "lambda", ":", "Actor", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "e", ".", "action_dim", ",", "e", ".", "max_action", ")", ")", "\n", "config", ".", "critic", "=", "PytorchModel", "(", "'critic'", ",", "\n", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "1", ")", ")", "\n", "if", "args", ".", "alg", ".", "lower", "(", ")", "==", "'td3'", ":", "\n", "      ", "config", ".", "critic2", "=", "PytorchModel", "(", "'critic2'", ",", "\n", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "1", ")", ")", "\n", "\n", "", "", "if", "args", ".", "ag_curiosity", "==", "'goaldisc'", ":", "\n", "    ", "config", ".", "goal_discriminator", "=", "PytorchModel", "(", "'goal_discriminator'", ",", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "nn", ".", "LayerNorm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "1", ")", ")", "\n", "\n", "", "if", "args", ".", "reward_module", "==", "'env'", ":", "\n", "    ", "config", ".", "goal_reward", "=", "GoalEnvReward", "(", ")", "\n", "", "elif", "args", ".", "reward_module", "==", "'intrinsic'", ":", "\n", "    ", "config", ".", "goal_reward", "=", "NeighborReward", "(", ")", "\n", "config", ".", "neighbor_embedding_network", "=", "PytorchModel", "(", "'neighbor_embedding_network'", ",", "\n", "lambda", ":", "FCBody", "(", "e", ".", "goal_dim", ",", "(", "256", ",", "256", ")", ")", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unsupported reward module: {}'", ".", "format", "(", "args", ".", "reward_module", ")", ")", "\n", "\n", "", "if", "config", ".", "eval_env", ".", "goal_env", ":", "\n", "    ", "if", "not", "(", "args", ".", "first_visit_done", "or", "args", ".", "first_visit_succ", ")", ":", "\n", "      ", "config", ".", "never_done", "=", "True", "# NOTE: This is important in the standard Goal environments, which are never done", "\n", "\n", "\n", "# 7. Make the agent and run the training loop.", "\n", "", "", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "if", "args", ".", "visualize_trained_agent", ":", "\n", "    ", "print", "(", "\"Loading agent at epoch {}\"", ".", "format", "(", "0", ")", ")", "\n", "agent", ".", "load", "(", "'checkpoint'", ")", "\n", "\n", "if", "args", ".", "intrinsic_visualization", ":", "\n", "      ", "agent", ".", "eval_mode", "(", ")", "\n", "agent", ".", "train", "(", "10000", ",", "render", "=", "True", ",", "dont_optimize", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "      ", "agent", ".", "eval_mode", "(", ")", "\n", "env", "=", "agent", ".", "eval_env", "\n", "\n", "for", "_", "in", "range", "(", "10000", ")", ":", "\n", "        ", "print", "(", "\"NEW EPISODE\"", ")", "\n", "state", "=", "env", ".", "reset", "(", ")", "\n", "env", ".", "render", "(", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "          ", "time", ".", "sleep", "(", "0.02", ")", "\n", "action", "=", "agent", ".", "policy", "(", "state", ")", "\n", "state", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "env", ".", "render", "(", ")", "\n", "print", "(", "reward", "[", "0", "]", ")", "\n", "", "", "", "", "elif", "args", ".", "collect_noisy_expert", ":", "\n", "    ", "print", "(", "\"Loading agent at epoch {}\"", ".", "format", "(", "0", ")", ")", "\n", "agent", ".", "load", "(", "'checkpoint'", ")", "\n", "agent", ".", "eval_mode", "(", ")", "\n", "env", "=", "agent", ".", "eval_env", "\n", "raw_env", "=", "agent", ".", "eval_env", ".", "env", ".", "envs", "[", "0", "]", "\n", "\n", "collected_exps", "=", "[", "]", "# will be tuples of (s, a, s', r, d)", "\n", "\n", "while", "(", "len", "(", "collected_exps", ")", "<", "500000", ")", ":", "\n", "      ", "print", "(", "len", "(", "collected_exps", ")", ")", "\n", "state", "=", "env", ".", "reset", "(", ")", "\n", "\n", "raw_env", ".", "smaller_state", "=", "True", "\n", "state1", "=", "raw_env", ".", "_get_obs", "(", ")", "[", "'observation'", "]", "\n", "raw_env", ".", "smaller_state", "=", "False", "\n", "\n", "#env.render()", "\n", "done", "=", "False", "\n", "n_steps", "=", "0", "\n", "while", "n_steps", "<", "50", ":", "\n", "        ", "n_steps", "+=", "1", "\n", "action", "=", "agent", ".", "policy", "(", "state", ",", ")", "\n", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "          ", "action", "=", "agent", ".", "action_noise", "(", "action", ")", "\n", "", "next_state", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "#env.render()", "\n", "\n", "raw_env", ".", "smaller_state", "=", "True", "\n", "next_state1", "=", "raw_env", ".", "_get_obs", "(", ")", "[", "'observation'", "]", "\n", "raw_env", ".", "smaller_state", "=", "False", "\n", "\n", "collected_exps", ".", "append", "(", "(", "state1", ",", "action", ",", "next_state1", ",", "reward", ",", "done", ")", ")", "\n", "state", "=", "next_state", "\n", "state1", "=", "next_state1", "\n", "", "print", "(", "[", "i", "[", "'is_success'", "]", "for", "i", "in", "info", "]", ")", "\n", "\n", "", "import", "pickle", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "agent", ".", "config", ".", "parent_folder", ",", "'noisy_expert_buffer1.pickle'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "collected_exps", ",", "f", ")", "\n", "", "print", "(", "'done & saved!'", ")", "\n", "\n", "", "else", ":", "\n", "    ", "ag_buffer", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "bg_buffer", "=", "agent", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_bg", "\n", "\n", "# EVALUATE", "\n", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "30", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Initial test reward (30 eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "max_steps", "//", "args", ".", "epoch_len", ")", ")", ":", "\n", "      ", "t", "=", "time", ".", "time", "(", ")", "\n", "agent", ".", "train", "(", "num_steps", "=", "args", ".", "epoch_len", ")", "\n", "\n", "# VIZUALIZE GOALS", "\n", "if", "args", ".", "save_embeddings", ":", "\n", "        ", "sample_idxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "ag_buffer", ")", ",", "size", "=", "min", "(", "len", "(", "ag_buffer", ")", ",", "args", ".", "epoch_len", ")", ",", "replace", "=", "False", ")", "\n", "last_idxs", "=", "np", ".", "arange", "(", "max", "(", "0", ",", "len", "(", "ag_buffer", ")", "-", "args", ".", "epoch_len", ")", ",", "len", "(", "ag_buffer", ")", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'rand_ags'", ",", "ag_buffer", ".", "get_batch", "(", "sample_idxs", ")", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'last_ags'", ",", "ag_buffer", ".", "get_batch", "(", "last_idxs", ")", ")", "\n", "agent", ".", "logger", ".", "add_embedding", "(", "'last_bgs'", ",", "bg_buffer", ".", "get_batch", "(", "last_idxs", ")", ")", "\n", "\n", "# EVALUATE", "\n", "", "res", "=", "np", ".", "mean", "(", "agent", ".", "eval", "(", "num_episodes", "=", "30", ")", ".", "rewards", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Test reward (30 eps):'", ",", "'{:.2f}'", ".", "format", "(", "res", ")", ")", "\n", "agent", ".", "logger", ".", "log_color", "(", "'Epoch time:'", ",", "'{:.2f}'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ",", "color", "=", "'yellow'", ")", "\n", "\n", "print", "(", "\"Saving agent at epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "agent", ".", "save", "(", "'checkpoint'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.__init__": [[41, 79], ["os.path.join", "os.path.exists", "agent_base.flatten_modules", "mrl.utils.misc.AttrDict", "config.get", "print", "os.makedirs", "setattr", "agent_base.Agent._register_module", "agent_base.Agent.load", "print", "agent_base.Agent.save", "mrl.utils.misc.short_timestamp"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.flatten_modules", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent._register_module", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.short_timestamp"], ["def", "__init__", "(", "\n", "self", ",", "\n", "module_list", ":", "Iterable", ",", "# list of mrl.Modules (possibly nested)", "\n", "config", ":", "AttrDict", ")", ":", "# hyperparameters and module settings", "\n", "\n", "    ", "self", ".", "config", "=", "config", "\n", "parent_folder", "=", "config", ".", "parent_folder", "\n", "assert", "parent_folder", ",", "\"Setting the agent's parent folder is required!\"", "\n", "self", ".", "agent_name", "=", "config", ".", "get", "(", "'agent_name'", ")", "or", "'agent_'", "+", "short_timestamp", "(", ")", "\n", "self", ".", "agent_folder", "=", "os", ".", "path", ".", "join", "(", "parent_folder", ",", "self", ".", "agent_name", ")", "\n", "load_agent", "=", "False", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "agent_folder", ")", ":", "\n", "      ", "print", "(", "'Detected existing agent! Loading agent from checkpoint...'", ")", "\n", "load_agent", "=", "True", "\n", "", "else", ":", "\n", "      ", "os", ".", "makedirs", "(", "self", ".", "agent_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "self", ".", "_process_experience_registry", "=", "[", "]", "# set of modules which define _process_experience", "\n", "self", ".", "_optimize_registry", "=", "[", "]", "# set of modules which define _optimize", "\n", "self", ".", "config", ".", "env_steps", "=", "0", "\n", "self", ".", "config", ".", "opt_steps", "=", "0", "\n", "\n", "module_list", "=", "flatten_modules", "(", "module_list", ")", "\n", "self", ".", "module_dict", "=", "AttrDict", "(", ")", "\n", "for", "module", "in", "module_list", ":", "\n", "      ", "assert", "module", ".", "module_name", "\n", "setattr", "(", "self", ",", "module", ".", "module_name", ",", "module", ")", "\n", "self", ".", "module_dict", "[", "module", ".", "module_name", "]", "=", "module", "\n", "", "for", "module", "in", "module_list", ":", "\n", "      ", "self", ".", "_register_module", "(", "module", ")", "\n", "\n", "", "self", ".", "training", "=", "True", "\n", "\n", "if", "load_agent", ":", "\n", "      ", "self", ".", "load", "(", ")", "\n", "print", "(", "'Successfully loaded saved agent!'", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.train_mode": [[80, 83], ["None"], "methods", ["None"], ["", "", "def", "train_mode", "(", "self", ")", ":", "\n", "    ", "\"\"\"Set agent to train mode; exploration / use dropout / etc. As in Pytorch.\"\"\"", "\n", "self", ".", "training", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode": [[84, 87], ["None"], "methods", ["None"], ["", "def", "eval_mode", "(", "self", ")", ":", "\n", "    ", "\"\"\"Set agent to eval mode; act deterministically / don't use dropout / etc.\"\"\"", "\n", "self", ".", "training", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.process_experience": [[88, 95], ["hasattr", "module._process_experience"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity._process_experience"], ["", "def", "process_experience", "(", "self", ",", "experience", ":", "AttrDict", ")", ":", "\n", "    ", "\"\"\"Calls the _process_experience function of each relevant module\n    (typically, these will include a replay buffer and one or more logging modules)\"\"\"", "\n", "self", ".", "config", ".", "env_steps", "+=", "self", ".", "env", ".", "num_envs", "if", "hasattr", "(", "self", ",", "'env'", ")", "else", "1", "\n", "\n", "for", "module", "in", "self", ".", "_process_experience_registry", ":", "\n", "      ", "module", ".", "_process_experience", "(", "experience", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.optimize": [[96, 102], ["module._optimize"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize"], ["", "", "def", "optimize", "(", "self", ")", ":", "\n", "    ", "\"\"\"Calls the _optimize function of each relevant module\n    (typically, this will be the main algorithm; but may include others)\"\"\"", "\n", "self", ".", "config", ".", "opt_steps", "+=", "1", "\n", "for", "module", "in", "self", ".", "_optimize_registry", ":", "\n", "      ", "module", ".", "_optimize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent._register_module": [[103, 121], ["module.verify_agent_compatibility", "module._setup", "module.new_task", "hasattr", "hasattr", "agent_base.Agent._process_experience_registry.append", "agent_base.Agent._optimize_registry.append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.verify_agent_compatibility", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.new_task", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "def", "_register_module", "(", "self", ",", "module", ")", ":", "\n", "    ", "\"\"\"\n    Provides module with a reference to agent so that modules can interact; e.g., \n    allows agent's policy to reference the value function.\n\n    Then, calls each module's _setup and verify methods to _setup the module and\n    verify that agent has all required modules.\n    \"\"\"", "\n", "self", ".", "module_dict", "[", "module", ".", "module_name", "]", "=", "module", "\n", "\n", "module", ".", "agent", "=", "self", "\n", "module", ".", "verify_agent_compatibility", "(", ")", "\n", "module", ".", "_setup", "(", ")", "\n", "module", ".", "new_task", "(", ")", "\n", "if", "hasattr", "(", "module", ",", "'_process_experience'", ")", ":", "\n", "      ", "self", ".", "_process_experience_registry", ".", "append", "(", "module", ")", "\n", "", "if", "hasattr", "(", "module", ",", "'_optimize'", ")", ":", "\n", "      ", "self", ".", "_optimize_registry", ".", "append", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.set_module": [[122, 128], ["setattr", "agent_base.Agent._register_module"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent._register_module"], ["", "", "def", "set_module", "(", "self", ",", "module_name", ",", "module", ")", ":", "\n", "    ", "\"\"\"\n    Sets a module (can be used to switch environments / policies)\n    \"\"\"", "\n", "setattr", "(", "self", ",", "module_name", ",", "module", ")", "\n", "self", ".", "_register_module", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.save": [[129, 147], ["os.path.join", "agent_base.Agent.module_dict.values", "os.path.exists", "os.makedirs", "module.save", "open", "pickle.dump", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save"], ["", "def", "save", "(", "self", ",", "subfolder", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    The state of all stateful modules is saved to the agent's folder.\n    The agent itself is NOT saved, and should be (1) rebuilt, and (2) restored using self.load().\n    Subfolder can be used to save various checkpoints of same agent.\n    \"\"\"", "\n", "save_folder", "=", "self", ".", "agent_folder", "\n", "subfolder", "=", "subfolder", "or", "'checkpoint'", "\n", "save_folder", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "subfolder", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_folder", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "save_folder", ")", "\n", "\n", "", "for", "module", "in", "self", ".", "module_dict", ".", "values", "(", ")", ":", "\n", "      ", "module", ".", "save", "(", "save_folder", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "'config.pickle'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "self", ".", "config", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.load": [[148, 164], ["os.path.join", "os.path.exists", "agent_base.Agent.module_dict.values", "open", "pickle.load", "print", "module.load", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "def", "load", "(", "self", ",", "subfolder", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Restores state of stateful modules from the agent's folder[/subfolder].\n    \"\"\"", "\n", "save_folder", "=", "self", ".", "agent_folder", "\n", "subfolder", "=", "subfolder", "or", "'checkpoint'", "\n", "save_folder", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "subfolder", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "save_folder", ")", ",", "\"load path does not exist!\"", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "'config.pickle'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "      ", "self", ".", "config", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "for", "module", "in", "self", ".", "module_dict", ".", "values", "(", ")", ":", "\n", "      ", "print", "(", "\"Loading module {}\"", ".", "format", "(", "module", ".", "module_name", ")", ")", "\n", "module", ".", "load", "(", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.save_checkpoint": [[165, 227], ["os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "agent_base.Agent.module_dict.values", "glob.glob", "os.path.exists", "os.makedirs", "open", "f.write", "os.path.join", "os.path.join", "os.path.exists", "module.save", "open", "pickle.dump", "os.path.join", "os.path.isfile", "open", "f.write", "os.path.join", "os.path.exists", "os.path.getmtime", "os.path.getmtime", "os.remove", "os.path.join", "shutil.copy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "", "def", "save_checkpoint", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"\n    Saves agent together with its buffer regardless of save buffer.\n    Keeps 2 saves in the in folder in case the job is killed and last\n    checkpoint is corrupted.\n\n    NOTE: You should call agent.save to save to the main folder BEFORE calling this.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "checkpoint_dir", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'INITIALIZED'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "'INITIALIZED'", ")", "\n", "\n", "", "subfolder1", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'1'", ")", "\n", "subfolder2", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'2'", ")", "\n", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "subfolder1", ",", "'checkpoint'", ")", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "subfolder2", ",", "'checkpoint'", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "done1", "=", "os", ".", "path", ".", "join", "(", "subfolder1", ",", "'DONE'", ")", "\n", "done2", "=", "os", ".", "path", ".", "join", "(", "subfolder2", ",", "'DONE'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "done1", ")", ":", "\n", "      ", "savedir", "=", "subfolder1", "\n", "done_file", "=", "done1", "\n", "", "elif", "not", "os", ".", "path", ".", "exists", "(", "done2", ")", ":", "\n", "      ", "savedir", "=", "subfolder2", "\n", "done_file", "=", "done2", "\n", "", "else", ":", "\n", "      ", "modtime1", "=", "os", ".", "path", ".", "getmtime", "(", "done1", ")", "\n", "modtime2", "=", "os", ".", "path", ".", "getmtime", "(", "done2", ")", "\n", "if", "modtime1", "<", "modtime2", ":", "\n", "        ", "savedir", "=", "subfolder1", "\n", "done_file", "=", "done1", "\n", "", "else", ":", "\n", "        ", "savedir", "=", "subfolder2", "\n", "done_file", "=", "done2", "\n", "\n", "", "os", ".", "remove", "(", "done_file", ")", "\n", "\n", "", "savedir_checkpoint", "=", "os", ".", "path", ".", "join", "(", "savedir", ",", "'checkpoint'", ")", "\n", "# First save all modules, including replay buffer", "\n", "old_save_replay_buf", "=", "self", ".", "config", ".", "save_replay_buf", "\n", "self", ".", "config", ".", "save_replay_buf", "=", "True", "\n", "for", "module", "in", "self", ".", "module_dict", ".", "values", "(", ")", ":", "\n", "      ", "module", ".", "save", "(", "savedir_checkpoint", ")", "\n", "", "self", ".", "config", ".", "save_replay_buf", "=", "old_save_replay_buf", "\n", "\n", "# Now save the config also", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "savedir_checkpoint", ",", "'config.pickle'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "self", ".", "config", ",", "f", ")", "\n", "\n", "# Now copy over the config and results files from the agent_folder", "\n", "", "files_and_folders", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "agent_folder", ",", "'*'", ")", ")", "\n", "for", "file_or_folder", "in", "files_and_folders", ":", "\n", "      ", "if", "os", ".", "path", ".", "isfile", "(", "file_or_folder", ")", ":", "\n", "        ", "shutil", ".", "copy", "(", "file_or_folder", ",", "savedir", ")", "\n", "\n", "# Finally, print the DONE file.", "\n", "", "", "with", "open", "(", "done_file", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "'DONE'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.load_from_checkpoint": [[228, 265], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "agent_base.Agent.module_dict.values", "glob.glob", "os.path.exists", "os.path.exists", "open", "pickle.load", "print", "module.load", "os.path.join", "os.path.isfile", "os.path.exists", "os.path.getmtime", "os.path.getmtime", "os.path.join", "shutil.copy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "", "def", "load_from_checkpoint", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"\n    This loads an agent from a checkpoint_dir to which it was saved using the `save_checkpoint` method.\n    \"\"\"", "\n", "subfolder1", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'1'", ")", "\n", "subfolder2", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'2'", ")", "\n", "done1", "=", "os", ".", "path", ".", "join", "(", "subfolder1", ",", "'DONE'", ")", "\n", "done2", "=", "os", ".", "path", ".", "join", "(", "subfolder2", ",", "'DONE'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "done1", ")", ":", "\n", "      ", "assert", "os", ".", "path", ".", "exists", "(", "done2", ")", "\n", "savedir", "=", "subfolder2", "\n", "", "elif", "not", "os", ".", "path", ".", "exists", "(", "done2", ")", ":", "\n", "      ", "savedir", "=", "subfolder1", "\n", "", "else", ":", "\n", "      ", "modtime1", "=", "os", ".", "path", ".", "getmtime", "(", "done1", ")", "\n", "modtime2", "=", "os", ".", "path", ".", "getmtime", "(", "done2", ")", "\n", "if", "modtime1", ">", "modtime2", ":", "\n", "        ", "savedir", "=", "subfolder1", "\n", "", "else", ":", "\n", "        ", "savedir", "=", "subfolder2", "\n", "\n", "", "", "savedir_checkpoint", "=", "os", ".", "path", ".", "join", "(", "savedir", ",", "'checkpoint'", ")", "\n", "\n", "# First load the agent", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "savedir_checkpoint", ",", "'config.pickle'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "      ", "self", ".", "config", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "for", "module", "in", "self", ".", "module_dict", ".", "values", "(", ")", ":", "\n", "      ", "print", "(", "\"Loading module {}\"", ".", "format", "(", "module", ".", "module_name", ")", ")", "\n", "module", ".", "load", "(", "savedir_checkpoint", ")", "\n", "\n", "# Then copy over the config and results file to the agent_folder", "\n", "", "files_and_folders", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "savedir", ",", "'*'", ")", ")", "\n", "for", "file_or_folder", "in", "files_and_folders", ":", "\n", "      ", "if", "os", ".", "path", ".", "isfile", "(", "file_or_folder", ")", ":", "\n", "        ", "shutil", ".", "copy", "(", "file_or_folder", ",", "self", ".", "agent_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch": [[267, 275], ["isinstance", "torch.FloatTensor().to", "torch.LongTensor().to", "torch.FloatTensor", "torch.BoolTensor().to", "torch.LongTensor", "torch.BoolTensor"], "methods", ["None"], ["", "", "", "def", "torch", "(", "self", ",", "x", ",", "type", "=", "torch", ".", "float", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "return", "x", "\n", "elif", "type", "==", "torch", ".", "float", ":", "\n", "      ", "return", "torch", ".", "FloatTensor", "(", "x", ")", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "", "elif", "type", "==", "torch", ".", "long", ":", "\n", "      ", "return", "torch", ".", "LongTensor", "(", "x", ")", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "", "elif", "type", "==", "torch", ".", "bool", ":", "\n", "      ", "return", "torch", ".", "BoolTensor", "(", "x", ")", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy": [[276, 278], ["x.cpu().detach().numpy", "x.cpu().detach", "x.cpu"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "def", "numpy", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "x", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.__init__": [[292, 301], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "module_name", ":", "str", ",", "\n", "required_agent_modules", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "locals", ":", "Optional", "[", "dict", "]", "=", "None", ")", ":", "\n", "    ", "self", ".", "module_name", "=", "module_name", "# Required", "\n", "self", ".", "config_spec", "=", "locals", "# Optionally used to log arguments to each module (Called by Logger)", "\n", "if", "required_agent_modules", "is", "not", "None", ":", "\n", "      ", "self", ".", "required_agent_modules", "=", "required_agent_modules", "\n", "", "else", ":", "\n", "      ", "self", ".", "required_agent_modules", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.__getattr__": [[302, 305], ["getattr"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "    ", "\"\"\"Attribute access passes through to agent when local attribute does not exist\"\"\"", "\n", "return", "getattr", "(", "self", ".", "agent", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.verify_agent_compatibility": [[306, 312], ["hasattr", "hasattr"], "methods", ["None"], ["", "def", "verify_agent_compatibility", "(", "self", ")", ":", "\n", "    ", "\"\"\"Called by agent to verify that module has everything it needs\"\"\"", "\n", "assert", "self", ".", "module_name", "is", "not", "None", "\n", "assert", "hasattr", "(", "self", ",", "'agent'", ")", "\n", "for", "module", "in", "self", ".", "required_agent_modules", ":", "\n", "      ", "assert", "hasattr", "(", "self", ".", "agent", ",", "module", ")", ",", "'Agent is missing module {}'", ".", "format", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._setup": [[313, 316], ["None"], "methods", ["None"], ["", "", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "\"\"\"Called after self.agent is set to do any required _setup with other modules\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.new_task": [[317, 320], ["None"], "methods", ["None"], ["", "def", "new_task", "(", "self", ")", ":", "\n", "    ", "\"\"\"Called during _setup, and also by trainig loop if there is a task switch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.save": [[321, 325], ["None"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "\"\"\"Saves module state (note: reference to agent not available). Only some modules \n    have state that is worth saving (e.g., replays or models)\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.load": [[326, 329], ["None"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "\"\"\"Restores individual module state\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props": [[330, 335], ["open", "pickle.dump", "os.path.join"], "methods", ["None"], ["", "def", "_save_props", "(", "self", ",", "prop_names", ":", "List", "[", "str", "]", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "\"\"\"Convenience method for saving module attributes\"\"\"", "\n", "prop_dict", "=", "{", "prop", ":", "self", ".", "__dict__", "[", "prop", "]", "for", "prop", "in", "prop_names", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}_props.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "prop_dict", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props": [[336, 342], ["pickle.load.items", "open", "pickle.load", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "def", "_load_props", "(", "self", ",", "prop_names", ":", "List", "[", "str", "]", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "\"\"\"Convenience method for loading module attributes\"\"\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}_props.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "      ", "prop_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "for", "k", ",", "v", "in", "prop_dict", ".", "items", "(", ")", ":", "\n", "      ", "self", ".", "__dict__", "[", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module.__str__": [[343, 345], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.FunctionModule.__init__": [[384, 387], ["agent_base.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "function", ":", "Callable", ",", "name", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "name", "or", "function", ".", "__name__", ",", "required_agent_modules", "=", "[", "]", ")", "\n", "self", ".", "function", "=", "function", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.FunctionModule.__call__": [[388, 390], ["agent_base.FunctionModule.function"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "function", "(", "*", "args", ",", "**", "kwargs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent": [[347, 357], ["mrl.utils.misc.AttrDict", "config_dict.items", "agent_base.Agent", "agent_base.is_module_or_or_module_list", "agent_base.flatten_modules"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.is_module_or_or_module_list", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.flatten_modules"], ["", "", "def", "config_to_agent", "(", "config_dict", ":", "dict", ")", ":", "\n", "  ", "module_list", "=", "[", "]", "\n", "config", "=", "AttrDict", "(", ")", "\n", "for", "k", ",", "v", "in", "config_dict", ".", "items", "(", ")", ":", "\n", "    ", "if", "is_module_or_or_module_list", "(", "v", ")", ":", "\n", "      ", "module_list", "+=", "flatten_modules", "(", "v", ")", "\n", "", "else", ":", "\n", "      ", "config", "[", "k", "]", "=", "v", "\n", "\n", "", "", "return", "Agent", "(", "module_list", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.is_module_or_or_module_list": [[359, 368], ["isinstance", "isinstance", "isinstance", "agent_base.is_module_or_or_module_list", "next", "iter"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.is_module_or_or_module_list"], ["", "def", "is_module_or_or_module_list", "(", "item", ")", ":", "\n", "  ", "if", "isinstance", "(", "item", ",", "Module", ")", ":", "\n", "    ", "return", "True", "\n", "", "elif", "isinstance", "(", "item", ",", "Iterable", ")", ":", "\n", "    ", "if", "isinstance", "(", "item", ",", "str", ")", ":", "\n", "      ", "return", "False", "\n", "", "return", "is_module_or_or_module_list", "(", "next", "(", "iter", "(", "item", ")", ")", ")", "\n", "", "else", ":", "\n", "    ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.flatten_modules": [[370, 377], ["isinstance", "agent_base.flatten_modules"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.flatten_modules"], ["", "", "def", "flatten_modules", "(", "module_list", ":", "Union", "[", "Iterable", ",", "Module", "]", ")", ":", "\n", "  ", "res", "=", "[", "]", "\n", "if", "isinstance", "(", "module_list", ",", "Module", ")", ":", "\n", "    ", "return", "[", "module_list", "]", "\n", "", "for", "module", "in", "module_list", ":", "\n", "    ", "res", "+=", "flatten_modules", "(", "module", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.GELU.forward": [[20, 22], ["torch.gelu", "torch.gelu", "torch.gelu"], "methods", ["None"], ["  ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "    ", "return", "F", ".", "gelu", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.MLP.__init__": [[39, 58], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "len", "zip", "list", "tuple", "torch.Linear", "torch.Linear", "torch.Linear", "list.append", "list.append", "map", "torch.Linear", "torch.Linear", "torch.Linear", "list.append", "activ", "list.append", "norm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", "=", "1", ",", "hidden_sizes", "=", "(", "256", ",", "256", ")", ",", "norm", "=", "nn", ".", "Identity", ",", "activ", "=", "nn", ".", "ReLU", ",", "drop_prob", "=", "0.", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "\n", "layer_sizes", "=", "(", "input_size", ",", ")", "+", "tuple", "(", "hidden_sizes", ")", "+", "(", "output_size", ",", ")", "\n", "if", "len", "(", "layer_sizes", ")", "==", "2", ":", "\n", "      ", "layers", "=", "[", "nn", ".", "Linear", "(", "layer_sizes", "[", "0", "]", ",", "layer_sizes", "[", "1", "]", ",", "bias", "=", "False", ")", "]", "\n", "", "else", ":", "\n", "      ", "layers", "=", "[", "]", "\n", "for", "dim_in", ",", "dim_out", "in", "zip", "(", "layer_sizes", "[", ":", "-", "1", "]", ",", "layer_sizes", "[", "1", ":", "]", ")", ":", "\n", "        ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "dim_in", ",", "dim_out", ")", ")", "\n", "if", "norm", "not", "in", "[", "None", ",", "nn", ".", "Identity", "]", ":", "\n", "          ", "layers", ".", "append", "(", "norm", "(", "dim_out", ")", ")", "\n", "", "layers", ".", "append", "(", "activ", "(", ")", ")", "\n", "if", "drop_prob", ">", "0.", ":", "\n", "          ", "layers", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "drop_prob", ")", ")", "\n", "", "", "layers", "=", "layers", "[", ":", "-", "(", "1", "+", "(", "norm", "not", "in", "[", "None", ",", "nn", ".", "Identity", "]", ")", "+", "(", "drop_prob", ">", "0", ")", ")", "]", "\n", "layers", "=", "list", "(", "map", "(", "layer_init", ",", "layers", ")", ")", "\n", "", "self", ".", "f", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.MLP.forward": [[59, 61], ["networks.MLP.f"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "f", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.NatureConvBody.__init__": [[68, 85], ["torch.Module.__init__", "list", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm", "activ", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm", "activ", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm", "activ", "torch.modules.Flatten", "torch.modules.Flatten", "torch.modules.Flatten", "torch.Linear", "torch.Linear", "torch.Linear", "norm", "activ", "map"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "in_channels", "=", "4", ",", "feature_dim", "=", "512", ",", "norm", "=", "nn", ".", "Identity", ",", "activ", "=", "GELU", ")", ":", "\n", "    ", "\"\"\"Default in_channels is 4 because that is how many B/W Atari frames we stack\"\"\"", "\n", "super", "(", "NatureConvBody", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_dim", "=", "feature_dim", "\n", "layers", "=", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "32", ",", "kernel_size", "=", "8", ",", "stride", "=", "4", ")", ",", "\n", "norm", "(", "32", ")", ",", "activ", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "norm", "(", "64", ")", ",", "activ", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "norm", "(", "64", ")", ",", "activ", "(", ")", ",", "\n", "nn", ".", "modules", ".", "Flatten", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "7", "*", "7", "*", "64", ",", "feature_dim", ")", ",", "\n", "norm", "(", "feature_dim", ")", ",", "activ", "(", ")", ",", "\n", "]", "\n", "layers", "=", "list", "(", "map", "(", "layer_init", ",", "layers", ")", ")", "\n", "self", ".", "f", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.NatureConvBody.forward": [[86, 88], ["networks.NatureConvBody.f"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "f", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.FCBody.__init__": [[91, 105], ["torch.Module.__init__", "zip", "torch.Sequential", "torch.Sequential", "torch.Sequential", "tuple", "list", "torch.Linear", "torch.Linear", "torch.Linear", "norm", "activ", "map"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "input_size", ",", "layer_sizes", "=", "(", "256", ",", "256", ")", ",", "norm", "=", "nn", ".", "Identity", ",", "activ", "=", "GELU", ",", "use_layer_init", "=", "True", ")", ":", "\n", "    ", "super", "(", "FCBody", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_dim", "=", "layer_sizes", "[", "-", "1", "]", "\n", "\n", "layer_sizes", "=", "(", "input_size", ",", ")", "+", "tuple", "(", "layer_sizes", ")", "\n", "layers", "=", "[", "]", "\n", "for", "dim_in", ",", "dim_out", "in", "zip", "(", "layer_sizes", "[", ":", "-", "1", "]", ",", "layer_sizes", "[", "1", ":", "]", ")", ":", "\n", "      ", "layers", "+=", "[", "\n", "nn", ".", "Linear", "(", "dim_in", ",", "dim_out", ")", ",", "\n", "norm", "(", "dim_out", ")", ",", "activ", "(", ")", ",", "\n", "]", "\n", "", "if", "use_layer_init", ":", "\n", "      ", "layers", "=", "list", "(", "map", "(", "layer_init", ",", "layers", ")", ")", "\n", "", "self", ".", "f", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.FCBody.forward": [[106, 108], ["networks.FCBody.f"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "f", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.Actor.__init__": [[117, 122], ["torch.Module.__init__", "networks.layer_init", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.layer_init"], ["def", "__init__", "(", "self", ",", "body", ":", "nn", ".", "Module", ",", "action_dim", ":", "int", ",", "max_action", ":", "float", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "body", "=", "body", "\n", "self", ".", "fc", "=", "layer_init", "(", "nn", ".", "Linear", "(", "self", ".", "body", ".", "feature_dim", ",", "action_dim", ")", ",", "w_scale", "=", "0.1", ")", "\n", "self", ".", "max_action", "=", "max_action", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.Actor.forward": [[123, 125], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "networks.Actor.fc", "networks.Actor.body"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "max_action", "*", "torch", ".", "tanh", "(", "self", ".", "fc", "(", "self", ".", "body", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.StochasticActor.__init__": [[128, 135], ["torch.Module.__init__", "networks.layer_init", "numpy.log", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.layer_init"], ["def", "__init__", "(", "self", ",", "body", ":", "nn", ".", "Module", ",", "action_dim", ":", "int", ",", "max_action", ":", "float", ",", "log_std_bounds", "=", "(", "-", "20", ",", "2", ")", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "body", "=", "body", "\n", "self", ".", "fc", "=", "layer_init", "(", "nn", ".", "Linear", "(", "self", ".", "body", ".", "feature_dim", ",", "action_dim", "*", "2", ")", ",", "w_scale", "=", "0.1", ")", "\n", "self", ".", "max_action", "=", "max_action", "\n", "self", ".", "min_log_std", ",", "self", ".", "max_log_std", "=", "log_std_bounds", "\n", "self", ".", "log2", "=", "np", ".", "log", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.StochasticActor.forward": [[136, 152], ["networks.StochasticActor.fc", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "networks.StochasticActor.body", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob().sum", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "mu_and_log_std", "=", "self", ".", "fc", "(", "self", ".", "body", "(", "x", ")", ")", "\n", "mu", ",", "log_std", "=", "torch", ".", "chunk", "(", "mu_and_log_std", ",", "2", ",", "-", "1", ")", "\n", "\n", "action", "=", "mu", "\n", "logp_action", "=", "None", "\n", "if", "self", ".", "training", ":", "\n", "      ", "log_std", "=", "torch", ".", "clamp", "(", "log_std", ",", "self", ".", "min_log_std", ",", "self", ".", "max_log_std", ")", "\n", "std", "=", "torch", ".", "exp", "(", "log_std", ")", "\n", "action_distribution", "=", "Normal", "(", "mu", ",", "std", ")", "\n", "action", "=", "action_distribution", ".", "rsample", "(", ")", "\n", "logp_action", "=", "action_distribution", ".", "log_prob", "(", "action", ")", ".", "sum", "(", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "logp_action", "-=", "(", "2", "*", "(", "self", ".", "log2", "-", "action", "-", "F", ".", "softplus", "(", "-", "2", "*", "action", ")", ")", ")", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "action", "=", "torch", ".", "tanh", "(", "action", ")", "\n", "return", "self", ".", "max_action", "*", "action", ",", "logp_action", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.Critic.__init__": [[158, 165], ["torch.Module.__init__", "networks.layer_init", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.layer_init"], ["def", "__init__", "(", "self", ",", "body", ":", "nn", ".", "Module", ",", "output_dim", ":", "int", ",", "use_layer_init", ":", "bool", "=", "True", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "body", "=", "body", "\n", "if", "use_layer_init", ":", "\n", "      ", "self", ".", "fc", "=", "layer_init", "(", "nn", ".", "Linear", "(", "self", ".", "body", ".", "feature_dim", ",", "output_dim", ")", ",", "w_scale", "=", "0.1", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "body", ".", "feature_dim", ",", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.Critic.forward": [[166, 168], ["networks.Critic.fc", "networks.Critic.body", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "*", "x", ")", ":", "\n", "    ", "return", "self", ".", "fc", "(", "self", ".", "body", "(", "torch", ".", "cat", "(", "x", ",", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.DuelingNet.__init__": [[170, 175], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "action_dim", ",", "body", ")", ":", "\n", "    ", "super", "(", "DuelingNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_value", "=", "nn", ".", "Linear", "(", "body", ".", "feature_dim", ",", "1", ")", "\n", "self", ".", "fc_advantage", "=", "nn", ".", "Linear", "(", "body", ".", "feature_dim", ",", "action_dim", ")", "\n", "self", ".", "body", "=", "body", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.DuelingNet.forward": [[176, 182], ["networks.DuelingNet.body", "networks.DuelingNet.fc_value", "networks.DuelingNet.fc_advantage", "networks.DuelingNet.expand_as", "networks.DuelingNet.mean().expand_as", "networks.DuelingNet.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "phi", "=", "self", ".", "body", "(", "x", ")", "\n", "value", "=", "self", ".", "fc_value", "(", "phi", ")", "\n", "advantange", "=", "self", ".", "fc_advantage", "(", "phi", ")", "\n", "q", "=", "value", ".", "expand_as", "(", "advantange", ")", "+", "(", "advantange", "-", "advantange", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", ".", "expand_as", "(", "advantange", ")", ")", "\n", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.CategoricalNet.__init__": [[187, 193], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ",", "num_atoms", ",", "body", ")", ":", "\n", "    ", "super", "(", "CategoricalNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_categorical", "=", "nn", ".", "Linear", "(", "body", ".", "feature_dim", ",", "action_dim", "*", "num_atoms", ")", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "num_atoms", "=", "num_atoms", "\n", "self", ".", "body", "=", "body", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.CategoricalNet.forward": [[194, 200], ["networks.CategoricalNet.body", "networks.CategoricalNet.fc_categorical().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "networks.CategoricalNet.fc_categorical"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "phi", "=", "self", ".", "body", "(", "x", ")", "\n", "pre_prob", "=", "self", ".", "fc_categorical", "(", "phi", ")", ".", "view", "(", "(", "-", "1", ",", "self", ".", "action_dim", ",", "self", ".", "num_atoms", ")", ")", "\n", "prob", "=", "F", ".", "softmax", "(", "pre_prob", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "pre_prob", ",", "dim", "=", "-", "1", ")", "\n", "return", "prob", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.QuantileNet.__init__": [[205, 211], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ",", "num_quantiles", ",", "body", ")", ":", "\n", "    ", "super", "(", "QuantileNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_quantiles", "=", "nn", ".", "Linear", "(", "body", ".", "feature_dim", ",", "action_dim", "*", "num_quantiles", ")", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "num_quantiles", "=", "num_quantiles", "\n", "self", ".", "body", "=", "body", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.QuantileNet.forward": [[212, 217], ["networks.QuantileNet.body", "networks.QuantileNet.fc_quantiles", "quantiles.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "phi", "=", "self", ".", "body", "(", "x", ")", "\n", "quantiles", "=", "self", ".", "fc_quantiles", "(", "phi", ")", "\n", "quantiles", "=", "quantiles", ".", "view", "(", "(", "-", "1", ",", "self", ".", "action_dim", ",", "self", ".", "num_quantiles", ")", ")", "\n", "return", "quantiles", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.MixtureDensityNetwork.__init__": [[233, 237], ["torch.Module.__init__", "networks.CategoricalNetwork", "networks.MixtureDiagNormalNetwork"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "pi_body", ":", "nn", ".", "Module", ",", "normal_body", ":", "nn", ".", "Module", ",", "output_dim", ":", "int", ",", "n_components", ":", "int", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pi_network", "=", "CategoricalNetwork", "(", "pi_body", ",", "n_components", ")", "\n", "self", ".", "normal_network", "=", "MixtureDiagNormalNetwork", "(", "normal_body", ",", "output_dim", ",", "n_components", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.MixtureDensityNetwork.forward": [[238, 240], ["networks.MixtureDensityNetwork.pi_network", "networks.MixtureDensityNetwork.normal_network"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "pi_network", "(", "x", ")", ",", "self", ".", "normal_network", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.MixtureDensityNetwork.loss": [[241, 247], ["networks.MixtureDensityNetwork.forward", "normal.log_prob", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "y.unsqueeze().expand_as", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "y.unsqueeze", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "loss", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "    ", "pi", ",", "normal", "=", "self", ".", "forward", "(", "x", ")", "\n", "loglik", "=", "normal", ".", "log_prob", "(", "y", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "normal", ".", "loc", ")", ")", "\n", "loglik", "=", "torch", ".", "sum", "(", "loglik", ",", "dim", "=", "2", ")", "\n", "loss", "=", "-", "torch", ".", "logsumexp", "(", "torch", ".", "log", "(", "pi", ".", "probs", ")", "+", "loglik", ",", "dim", "=", "1", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.MixtureDiagNormalNetwork.__init__": [[249, 254], ["torch.Module.__init__", "networks.layer_init", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.layer_init"], ["  ", "def", "__init__", "(", "self", ",", "body", ":", "nn", ".", "Module", ",", "output_dim", ":", "int", ",", "n_components", ":", "int", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "body", "=", "body", "\n", "self", ".", "n_components", "=", "n_components", "\n", "self", ".", "fc", "=", "layer_init", "(", "nn", ".", "Linear", "(", "self", ".", "body", ".", "feature_dim", ",", "2", "*", "output_dim", "*", "n_components", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.MixtureDiagNormalNetwork.forward": [[255, 261], ["networks.MixtureDiagNormalNetwork.fc", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "networks.MixtureDiagNormalNetwork.body", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "params", "=", "self", ".", "fc", "(", "self", ".", "body", "(", "x", ")", ")", "\n", "mean", ",", "sd", "=", "torch", ".", "split", "(", "params", ",", "params", ".", "shape", "[", "1", "]", "//", "2", ",", "dim", "=", "1", ")", "\n", "mean", "=", "torch", ".", "stack", "(", "mean", ".", "split", "(", "mean", ".", "shape", "[", "1", "]", "//", "self", ".", "n_components", ",", "1", ")", ")", "\n", "sd", "=", "torch", ".", "stack", "(", "sd", ".", "split", "(", "sd", ".", "shape", "[", "1", "]", "//", "self", ".", "n_components", ",", "1", ")", ")", "\n", "return", "Normal", "(", "mean", ".", "transpose", "(", "0", ",", "1", ")", ",", "torch", ".", "exp", "(", "sd", ")", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.CategoricalNetwork.__init__": [[263, 267], ["torch.Module.__init__", "networks.layer_init", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.layer_init"], ["  ", "def", "__init__", "(", "self", ",", "body", ":", "nn", ".", "Module", ",", "n_components", ":", "int", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "body", "=", "body", "\n", "self", ".", "fc", "=", "layer_init", "(", "nn", ".", "Linear", "(", "self", ".", "body", ".", "feature_dim", ",", "n_components", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.CategoricalNetwork.forward": [[268, 271], ["networks.CategoricalNetwork.fc", "torch.distributions.OneHotCategorical", "torch.distributions.OneHotCategorical", "torch.distributions.OneHotCategorical", "networks.CategoricalNetwork.body"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "params", "=", "self", ".", "fc", "(", "self", ".", "body", "(", "x", ")", ")", "\n", "return", "OneHotCategorical", "(", "logits", "=", "params", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.utils.networks.layer_init": [[12, 18], ["hasattr", "torch.init.orthogonal_", "layer.weight.data.mul_", "torch.init.constant_", "len"], "function", ["None"], ["def", "layer_init", "(", "layer", ",", "w_scale", "=", "1.0", ")", ":", "\n", "  ", "if", "hasattr", "(", "layer", ",", "'weight'", ")", "and", "len", "(", "layer", ".", "weight", ".", "shape", ")", ">", "1", ":", "\n", "    ", "nn", ".", "init", ".", "orthogonal_", "(", "layer", ".", "weight", ".", "data", ")", "\n", "layer", ".", "weight", ".", "data", ".", "mul_", "(", "w_scale", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", ".", "data", ",", "0", ")", "\n", "", "return", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.Loss.__init__": [[8, 11], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "prior", ")", ":", "\n", "        ", "super", "(", "Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "prior", "=", "prior", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.Loss.__call__": [[12, 15], ["realnvp.Loss.prior.log_prob"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "z", ",", "sum_log_det_jacobians", ")", ":", "\n", "        ", "log_p", "=", "self", ".", "prior", ".", "log_prob", "(", "z", ")", "\n", "return", "-", "(", "log_p", "+", "sum_log_det_jacobians", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.__init__": [[18, 42], ["torch.Module.__init__", "range", "torch.Sequential().to", "torch.Sequential().to", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "realnvp.RealNVP.parameters", "torch.distributions.MultivariateNormal", "torch.distributions.MultivariateNormal", "torch.distributions.MultivariateNormal", "torch.distributions.MultivariateNormal", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "realnvp.CouplingLayer", "realnvp.CouplingLayer", "torch.Sequential", "torch.Sequential", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "prior", "=", "None", ",", "input_channel", "=", "2", ",", "lr", "=", "1e-3", ",", "num_layer_pairs", "=", "3", ",", "dev", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "dev", "is", "None", ":", "\n", "          ", "self", ".", "dev", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "", "else", ":", "\n", "          ", "self", ".", "dev", "=", "dev", "\n", "\n", "", "layers", "=", "[", "]", "\n", "\n", "self", ".", "input_channel", "=", "input_channel", "\n", "\n", "for", "_", "in", "range", "(", "num_layer_pairs", ")", ":", "\n", "          ", "layers", "+=", "[", "CouplingLayer", "(", "\"01\"", ",", "self", ".", "input_channel", ")", ",", "\n", "CouplingLayer", "(", "\"10\"", ",", "self", ".", "input_channel", ")", "]", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", ".", "to", "(", "self", ".", "dev", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "if", "prior", "is", "None", ":", "\n", "            ", "self", ".", "prior", "=", "torch", ".", "distributions", ".", "MultivariateNormal", "(", "torch", ".", "zeros", "(", "input_channel", ")", ".", "to", "(", "self", ".", "dev", ")", ",", "\n", "torch", ".", "eye", "(", "input_channel", ")", ".", "to", "(", "self", ".", "dev", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "prior", "=", "prior", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.forward": [[43, 59], ["x.new_zeros", "x.size", "layer", "list", "layer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.size"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "reverse", "=", "False", ")", ":", "\n", "        ", "if", "not", "reverse", ":", "\n", "            ", "sum_log_det_jacobians", "=", "x", ".", "new_zeros", "(", "x", ".", "size", "(", "0", ")", ")", "\n", "\n", "z", "=", "x", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "              ", "z", ",", "log_det_jacobians", "=", "layer", "(", "z", ",", "reverse", ")", "\n", "sum_log_det_jacobians", "+=", "log_det_jacobians", "\n", "\n", "", "return", "z", ",", "sum_log_det_jacobians", "\n", "", "else", ":", "\n", "            ", "output", "=", "x", "\n", "for", "layer", "in", "list", "(", "self", ".", "layers", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "              ", "output", "=", "layer", "(", "output", ",", "reverse", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.fit": [[60, 75], ["isinstance", "realnvp.Loss", "range", "torch.from_numpy().to.to", "torch.from_numpy().to.to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "realnvp.RealNVP.train", "realnvp.RealNVP.", "Loss.", "realnvp.RealNVP.optimizer.zero_grad", "Loss.backward", "realnvp.RealNVP.optimizer.step", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "", "def", "fit", "(", "self", ",", "data", ",", "epochs", "=", "10", ")", ":", "\n", "        ", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "data", "=", "data", ".", "to", "(", "self", ".", "dev", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "to", "(", "self", ".", "dev", ")", "\n", "", "loss_log_det_jacobians", "=", "Loss", "(", "self", ".", "prior", ")", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "            ", "self", ".", "train", "(", ")", "\n", "\n", "z", ",", "sum_log_det_jacobian", "=", "self", "(", "data", ")", "\n", "loss", "=", "loss_log_det_jacobians", "(", "z", ",", "sum_log_det_jacobian", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.sample": [[76, 80], ["realnvp.RealNVP.prior.sample", "realnvp.RealNVP.", "realnvp.RealNVP.detach().cpu().numpy", "realnvp.RealNVP.detach().cpu", "realnvp.RealNVP.detach"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "def", "sample", "(", "self", ",", "num_samples", "=", "1000", ")", ":", "\n", "        ", "z", "=", "self", ".", "prior", ".", "sample", "(", "(", "num_samples", ",", ")", ")", "\n", "x", "=", "self", "(", "z", ",", "reverse", "=", "True", ")", "\n", "return", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples": [[81, 91], ["realnvp.RealNVP.", "realnvp.RealNVP.prior.log_prob", "log_px.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "log_px.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "log_px.detach().cpu().numpy.detach().cpu().numpy.detach"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "score_samples", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", ",", "sum_log_det_jacobian", "=", "self", "(", "torch", ".", "from_numpy", "(", "x", ")", ".", "to", "(", "self", ".", "dev", ")", ")", "\n", "\n", "log_pz", "=", "self", ".", "prior", ".", "log_prob", "(", "z", ")", "\n", "\n", "log_px", "=", "log_pz", "+", "sum_log_det_jacobian", "\n", "\n", "log_px", "=", "log_px", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "log_px", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.CouplingLayer.__init__": [[94, 110], ["torch.Module.__init__", "realnvp.Function_s_t", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mask_type", ",", "input_channel", ",", "dev", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "function_s_t", "=", "Function_s_t", "(", "input_channel", ")", "\n", "self", ".", "mask_type", "=", "mask_type", "\n", "self", ".", "input_channel", "=", "input_channel", "\n", "\n", "if", "dev", "is", "None", ":", "\n", "          ", "self", ".", "dev", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "", "else", ":", "\n", "          ", "self", ".", "dev", "=", "dev", "\n", "\n", "", "d", "=", "self", ".", "input_channel", "//", "2", "\n", "if", "'01'", "in", "self", ".", "mask_type", ":", "\n", "            ", "self", ".", "mask", "=", "torch", ".", "tensor", "(", "[", "[", "0.0", "]", "*", "d", "+", "(", "self", ".", "input_channel", "-", "d", ")", "*", "[", "1.0", "]", "]", ")", ".", "to", "(", "self", ".", "dev", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "mask", "=", "torch", ".", "tensor", "(", "[", "[", "1.0", "]", "*", "d", "+", "(", "self", ".", "input_channel", "-", "d", ")", "*", "[", "0.0", "]", "]", ")", ".", "to", "(", "self", ".", "dev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.CouplingLayer.forward": [[111, 136], ["realnvp.CouplingLayer.function_s_t", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "realnvp.CouplingLayer.function_s_t", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "reverse", "=", "False", ")", ":", "\n", "\n", "        ", "if", "not", "reverse", ":", "\n", "# masked half of x", "\n", "            ", "x1", "=", "x", "*", "self", ".", "mask", "\n", "s", ",", "t", "=", "self", ".", "function_s_t", "(", "x1", ",", "self", ".", "mask", ")", "\n", "\n", "# z_1:d = x_1:d", "\n", "# z_d+1:D = exp(s(x_1:d)) * x_d+1:D + m(x_1:d)", "\n", "y", "=", "x1", "+", "(", "(", "-", "self", ".", "mask", "+", "1.0", ")", "*", "(", "x", "*", "torch", ".", "exp", "(", "s", ")", "+", "t", ")", ")", "\n", "\n", "# calculation of jacobians", "\n", "log_det_jacobian", "=", "torch", ".", "sum", "(", "s", ",", "1", ")", "\n", "\n", "return", "y", ",", "log_det_jacobian", "\n", "", "else", ":", "\n", "# masked half of y", "\n", "            ", "x1", "=", "x", "*", "self", ".", "mask", "\n", "s", ",", "t", "=", "self", ".", "function_s_t", "(", "x1", ",", "self", ".", "mask", ")", "\n", "\n", "# x_1:d = z_1:d", "\n", "# x_d+1:D = z_d+1:D - m(z_1:d) * exp(-s(z_1:d))", "\n", "y", "=", "x1", "+", "(", "-", "self", ".", "mask", "+", "1.0", ")", "*", "(", "(", "x", "-", "t", ")", "*", "torch", ".", "exp", "(", "-", "s", ")", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.Function_s_t.__init__": [[141, 155], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_channel", ",", "channel", "=", "256", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_channel", "=", "input_channel", "\n", "layers", "=", "[", "]", "\n", "\n", "layers", "+=", "[", "\n", "nn", ".", "Linear", "(", "input_channel", ",", "channel", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "channel", ",", "channel", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "channel", ",", "input_channel", "*", "2", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "w_scale", "=", "torch", ".", "rand", "(", "1", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.Function_s_t.forward": [[156, 169], ["realnvp.Function_s_t.model", "torch.Tanh", "torch.Tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "\n", "#######################################", "\n", "# scale function : first half dimension", "\n", "# translation function : second half dimension", "\n", "#######################################", "\n", "s", "=", "x", "[", ":", ",", ":", "self", ".", "input_channel", "]", "*", "(", "-", "mask", "+", "1", ")", "\n", "t", "=", "x", "[", ":", ",", "self", ".", "input_channel", ":", "]", "*", "(", "-", "mask", "+", "1", ")", "\n", "\n", "s", "=", "nn", ".", "Tanh", "(", ")", "(", "s", ")", "\n", "\n", "return", "s", ",", "t", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.RandomProcess.reset_states": [[17, 19], ["None"], "methods", ["None"], ["  ", "def", "reset_states", "(", "self", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.GaussianProcess.__init__": [[22, 25], ["ConstantSchedule"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "size", ",", "std", "=", "ConstantSchedule", "(", "0.2", ")", ")", ":", "\n", "    ", "self", ".", "size", "=", "size", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.GaussianProcess.sample": [[26, 28], ["numpy.random.randn", "random_process.GaussianProcess.std"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "    ", "return", "np", ".", "random", ".", "randn", "(", "*", "self", ".", "size", ")", "*", "self", ".", "std", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.OrnsteinUhlenbeckProcess.__init__": [[31, 41], ["ConstantSchedule", "random_process.OrnsteinUhlenbeckProcess.reset_states"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.OrnsteinUhlenbeckProcess.reset_states"], ["  ", "def", "__init__", "(", "self", ",", "size", ",", "std", "=", "ConstantSchedule", "(", "0.2", ")", ",", "theta", "=", ".15", ",", "dt", "=", "1e-2", ",", "x0", "=", "None", ",", "reset_every", "=", "50", ")", ":", "\n", "    ", "self", ".", "theta", "=", "theta", "\n", "self", ".", "mu", "=", "0", "\n", "self", ".", "std", "=", "std", "\n", "self", ".", "dt", "=", "dt", "\n", "self", ".", "x0", "=", "x0", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "reset_states", "(", ")", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "reset_every", "=", "reset_every", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.OrnsteinUhlenbeckProcess.sample": [[42, 50], ["random_process.OrnsteinUhlenbeckProcess.reset_states", "numpy.random.randn", "random_process.OrnsteinUhlenbeckProcess.std", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.OrnsteinUhlenbeckProcess.reset_states"], ["", "def", "sample", "(", "self", ")", ":", "\n", "    ", "self", ".", "steps", "+=", "1", "\n", "if", "self", ".", "steps", "%", "self", ".", "reset_every", "==", "0", ":", "\n", "      ", "self", ".", "reset_states", "(", ")", "\n", "", "x", "=", "self", ".", "x_prev", "+", "self", ".", "theta", "*", "(", "self", ".", "mu", "-", "self", ".", "x_prev", ")", "*", "self", ".", "dt", "+", "self", ".", "std", "(", ")", "*", "np", ".", "sqrt", "(", "\n", "self", ".", "dt", ")", "*", "np", ".", "random", ".", "randn", "(", "*", "self", ".", "size", ")", "\n", "self", ".", "x_prev", "=", "x", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.random_process.OrnsteinUhlenbeckProcess.reset_states": [[51, 53], ["numpy.zeros"], "methods", ["None"], ["", "def", "reset_states", "(", "self", ")", ":", "\n", "    ", "self", ".", "x_prev", "=", "self", ".", "x0", "if", "self", ".", "x0", "is", "not", "None", "else", "np", ".", "zeros", "(", "self", ".", "size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.__init__": [[12, 37], ["torch.nn.Module.__init__", "zip", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "zip", "vae.VAE.decoder.pop", "torch.nn.Sequential", "vae.VAE.encoder.append", "vae.VAE.encoder.append", "vae.VAE.decoder.append", "vae.VAE.decoder.append", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["  ", "def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", "=", "256", ",", "latent_dim", "=", "64", ",", "num_hidden", "=", "2", ")", ":", "\n", "    ", "super", "(", "VAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "latent_dim", "=", "latent_dim", "\n", "self", ".", "num_hidden", "=", "2", "\n", "\n", "layer_sizes", "=", "[", "input_dim", "]", "+", "[", "hidden_dim", "]", "*", "num_hidden", "\n", "self", ".", "encoder", "=", "[", "]", "\n", "for", "i", ",", "o", "in", "zip", "(", "layer_sizes", "[", ":", "-", "1", "]", ",", "layer_sizes", "[", "1", ":", "]", ")", ":", "\n", "      ", "self", ".", "encoder", ".", "append", "(", "nn", ".", "Linear", "(", "i", ",", "o", ")", ")", "\n", "self", ".", "encoder", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "encoder", ")", "\n", "\n", "self", ".", "mu", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "latent_dim", ")", "\n", "self", ".", "sigma", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "latent_dim", ")", "\n", "\n", "layer_sizes", "=", "[", "latent_dim", "]", "+", "[", "hidden_dim", "]", "*", "num_hidden", "+", "[", "input_dim", "]", "\n", "self", ".", "decoder", "=", "[", "]", "\n", "for", "i", ",", "o", "in", "zip", "(", "layer_sizes", "[", ":", "-", "1", "]", ",", "layer_sizes", "[", "1", ":", "]", ")", ":", "\n", "      ", "self", ".", "decoder", ".", "append", "(", "nn", ".", "Linear", "(", "i", ",", "o", ")", ")", "\n", "self", ".", "decoder", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "self", ".", "decoder", ".", "pop", "(", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.encode": [[38, 41], ["vae.VAE.encoder", "vae.VAE.mu", "vae.VAE.sigma"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "    ", "h", "=", "self", ".", "encoder", "(", "x", ")", "\n", "return", "self", ".", "mu", "(", "h", ")", ",", "self", ".", "sigma", "(", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.reparameterize": [[42, 46], ["torch.exp", "torch.randn_like"], "methods", ["None"], ["", "def", "reparameterize", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "    ", "std", "=", "torch", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "mu", "+", "eps", "*", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.decode": [[47, 49], ["vae.VAE.decoder"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "z", ")", ":", "\n", "    ", "return", "self", ".", "decoder", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.forward": [[50, 54], ["vae.VAE.encode", "vae.VAE.reparameterize", "vae.VAE.decode"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.encode", "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.reparameterize", "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.VAE.decode"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "mu", ",", "logvar", "=", "self", ".", "encode", "(", "x", ")", "\n", "z", "=", "self", ".", "reparameterize", "(", "mu", ",", "logvar", ")", "\n", "return", "self", ".", "decode", "(", "z", ")", ",", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.vae.vae_loss_function": [[57, 67], ["torch.sum", "torch.sum", "logvar.exp", "mu.pow"], "function", ["None"], ["", "", "def", "vae_loss_function", "(", "recon_x", ",", "x", ",", "mu", ",", "logvar", ")", ":", "\n", "    ", "MSE", "=", "torch", ".", "sum", "(", "(", "recon_x", "-", "x", ")", "**", "2", ",", "-", "1", ")", "\n", "\n", "# see Appendix B from VAE paper:", "\n", "# Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014", "\n", "# https://arxiv.org/abs/1312.6114", "\n", "# 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)", "\n", "KLD", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "logvar", "-", "mu", ".", "pow", "(", "2", ")", "-", "logvar", ".", "exp", "(", ")", ",", "-", "1", ")", "\n", "\n", "return", "(", "MSE", "+", "KLD", ")", ".", "mean", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.AttrDict.__init__": [[41, 44], ["dict.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "dict", ".", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "__dict__", "=", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.AttrDict.copy": [[45, 51], ["type", "isinstance", "v.copy", "misc.AttrDict.items"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "copy", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n        Provides a \"deep\" copy of all unbroken chains of types AttrDict, but\n        shallow copies otherwise, (e.g. numpy arrays are NOT copied).\n        \"\"\"", "\n", "return", "type", "(", "self", ")", "(", "**", "{", "k", ":", "v", ".", "copy", "(", ")", "if", "isinstance", "(", "v", ",", "AttrDict", ")", "else", "v", "for", "k", ",", "v", "in", "self", ".", "items", "(", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.AnnotatedAttrDict.__init__": [[58, 71], ["dict", "dict.items", "misc.AttrDict.__init__", "hasattr", "len", "type"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "argdict", "=", "dict", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "valuedict", "=", "{", "}", "\n", "annotationdict", "=", "{", "}", "\n", "for", "k", ",", "va", "in", "argdict", ".", "items", "(", ")", ":", "\n", "      ", "if", "hasattr", "(", "va", ",", "'__len__'", ")", "and", "len", "(", "va", ")", "==", "2", "and", "type", "(", "va", "[", "1", "]", ")", "==", "str", ":", "\n", "        ", "v", ",", "a", "=", "va", "\n", "valuedict", "[", "k", "]", "=", "v", "\n", "annotationdict", "[", "k", "]", "=", "a", "\n", "", "else", ":", "\n", "        ", "valuedict", "[", "k", "]", "=", "va", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "self", ",", "**", "valuedict", ")", "\n", "self", ".", "annotationdict", "=", "annotationdict", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.AnnotatedAttrDict.get_annotation": [[72, 74], ["misc.AnnotatedAttrDict.annotationdict.get"], "methods", ["None"], ["", "def", "get_annotation", "(", "self", ",", "key", ")", ":", "\n", "    ", "return", "self", ".", "annotationdict", ".", "get", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.set_global_seeds": [[13, 31], ["numpy.random.seed", "random.seed", "hasattr", "hasattr", "gym.spaces.prng.seed", "tf.random.set_seed", "hasattr", "tf.compat.v1.set_random_seed", "tf.set_random_seed"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["", "def", "set_global_seeds", "(", "seed", ")", ":", "\n", "  ", "\"\"\"\n    set the seed for python random, tensorflow, numpy and gym spaces\n\n    :param seed: (int) the seed\n    \"\"\"", "\n", "if", "tf", "is", "not", "None", ":", "\n", "    ", "if", "hasattr", "(", "tf", ".", "random", ",", "'set_seed'", ")", ":", "\n", "      ", "tf", ".", "random", ".", "set_seed", "(", "seed", ")", "\n", "", "elif", "hasattr", "(", "tf", ".", "compat", ",", "'v1'", ")", ":", "\n", "      ", "tf", ".", "compat", ".", "v1", ".", "set_random_seed", "(", "seed", ")", "\n", "", "else", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "# prng was removed in latest gym version", "\n", "if", "hasattr", "(", "gym", ".", "spaces", ",", "'prng'", ")", ":", "\n", "    ", "gym", ".", "spaces", ".", "prng", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.soft_update": [[76, 81], ["torch.no_grad", "zip", "target.parameters", "src.parameters", "target_param.data.mul_", "target_param.data.add_"], "function", ["None"], ["", "", "def", "soft_update", "(", "target", ",", "src", ",", "factor", ")", ":", "\n", "  ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "src", ".", "parameters", "(", ")", ")", ":", "\n", "      ", "target_param", ".", "data", ".", "mul_", "(", "1.0", "-", "factor", ")", "\n", "target_param", ".", "data", ".", "add_", "(", "factor", "*", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.short_timestamp": [[82, 86], ["datetime.datetime.now"], "function", ["None"], ["", "", "", "def", "short_timestamp", "(", ")", ":", "\n", "  ", "\"\"\"Returns string with timestamp\"\"\"", "\n", "import", "datetime", "\n", "return", "'{:%m%d%H%M%S}'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state": [[88, 93], ["isinstance", "numpy.concatenate"], "function", ["None"], ["", "def", "flatten_state", "(", "state", ",", "modalities", "=", "[", "'observation'", ",", "'desired_goal'", "]", ")", ":", "\n", "#TODO: handle image modalities", "\n", "  ", "if", "isinstance", "(", "state", ",", "dict", ")", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "state", "[", "m", "]", "for", "m", "in", "modalities", "]", ",", "-", "1", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.add_config_args": [[95, 106], ["config.items", "type", "argparser.add_argument", "type", "argparser.add_argument", "type", "config.get_annotation", "config.get_annotation"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.AnnotatedAttrDict.get_annotation", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.AnnotatedAttrDict.get_annotation"], ["", "def", "add_config_args", "(", "argparser", ",", "config", ":", "AnnotatedAttrDict", ")", ":", "\n", "  ", "\"\"\"TODO: Make this add more types of args automatically?  \"\"\"", "\n", "for", "k", ",", "v", "in", "config", ".", "items", "(", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "if", "type", "(", "v", ")", "in", "(", "str", ",", "int", ",", "float", ")", ":", "\n", "        ", "argparser", ".", "add_argument", "(", "'--'", "+", "k", ",", "default", "=", "v", ",", "type", "=", "type", "(", "v", ")", ",", "help", "=", "config", ".", "get_annotation", "(", "k", ")", ")", "\n", "", "elif", "type", "(", "v", ")", "==", "bool", ":", "\n", "        ", "argparser", ".", "add_argument", "(", "'--'", "+", "k", ",", "default", "=", "v", ",", "type", "=", "str2bool", ",", "help", "=", "config", ".", "get_annotation", "(", "k", ")", ")", "\n", "", "", "except", ":", "\n", "      ", "pass", "\n", "", "", "return", "argparser", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.str2bool": [[108, 117], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "  ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "    ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "    ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "    ", "return", "False", "\n", "", "else", ":", "\n", "    ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.merge_args_into_config": [[119, 132], ["args.__dict__.items", "isinstance"], "function", ["None"], ["", "", "def", "merge_args_into_config", "(", "args", ",", "config", ":", "AttrDict", ")", ":", "\n", "  ", "config", ".", "parent_folder", "=", "args", ".", "parent_folder", "\n", "\n", "other_args", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "args", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "    ", "if", "k", "in", "config", ":", "\n", "      ", "config", "[", "k", "]", "=", "v", "\n", "", "elif", "not", "isinstance", "(", "v", ",", "LambdaType", ")", ":", "\n", "      ", "other_args", "[", "k", "]", "=", "v", "\n", "\n", "", "", "config", ".", "other_args", "=", "other_args", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_agent_name": [[134, 147], ["set", "misc.shorten_attr", "set.add", "str", "ValueError", "str"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.shorten_attr", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add"], ["", "def", "make_agent_name", "(", "config", ",", "attr_list", ",", "prefix", "=", "'agent'", ")", ":", "\n", "  ", "agent_name", "=", "prefix", "\n", "attr_set", "=", "set", "(", ")", "\n", "for", "attr", "in", "attr_list", ":", "\n", "    ", "s", "=", "shorten_attr", "(", "attr", ",", "attr_set", ")", "\n", "attr_set", ".", "add", "(", "s", ")", "\n", "if", "attr", "in", "config", ":", "\n", "      ", "agent_name", "+=", "'_'", "+", "s", "+", "str", "(", "config", "[", "attr", "]", ")", "\n", "", "elif", "attr", "in", "config", ".", "other_args", ":", "\n", "      ", "agent_name", "+=", "'_'", "+", "s", "+", "'-'", "+", "str", "(", "config", ".", "other_args", "[", "attr", "]", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "'Attribute {} not found in config!'", ".", "format", "(", "attr", ")", ")", "\n", "", "", "return", "agent_name", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.shorten_attr": [[149, 154], ["misc.shorten_attr"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.shorten_attr"], ["", "def", "shorten_attr", "(", "attr", ",", "set", ",", "proposed_len", "=", "5", ")", ":", "\n", "  ", "short", "=", "attr", "[", ":", "proposed_len", "]", "\n", "if", "short", "in", "set", ":", "\n", "    ", "return", "shorten_attr", "(", "attr", ",", "set", ",", "proposed_len", "+", "1", ")", "\n", "", "return", "short", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.softmax": [[156, 198], ["numpy.atleast_2d", "numpy.exp", "numpy.sum", "next", "float", "numpy.max", "len", "p.flatten.flatten", "enumerate"], "function", ["None"], ["", "def", "softmax", "(", "X", ",", "theta", "=", "1.0", ",", "axis", "=", "-", "1", ")", ":", "\n", "  ", "\"\"\"\n    Compute the softmax of each element along an axis of X.\n\n    Parameters\n    ----------\n    X: ND-Array. Probably should be floats.\n    theta (optional): float parameter, used as a multiplier\n        prior to exponentiation. Default = 1.0\n    axis (optional): axis to compute values along. Default is the\n        first non-singleton axis.\n\n    Returns an array the same size as X. The result will sum to 1\n    along the specified axis.\n    \"\"\"", "\n", "\n", "# make X at least 2d", "\n", "y", "=", "np", ".", "atleast_2d", "(", "X", ")", "\n", "\n", "# find axis", "\n", "if", "axis", "is", "None", ":", "\n", "    ", "axis", "=", "next", "(", "j", "[", "0", "]", "for", "j", "in", "enumerate", "(", "y", ".", "shape", ")", "if", "j", "[", "1", "]", ">", "1", ")", "\n", "\n", "# multiply y against the theta parameter,", "\n", "", "y", "=", "y", "*", "float", "(", "theta", ")", "\n", "\n", "# subtract the max for numerical stability", "\n", "y", "=", "y", "-", "np", ".", "max", "(", "y", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "\n", "\n", "# exponentiate y", "\n", "y", "=", "np", ".", "exp", "(", "y", ")", "\n", "\n", "# take the sum along the specified axis", "\n", "ax_sum", "=", "np", ".", "sum", "(", "y", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "\n", "\n", "# finally: divide elementwise", "\n", "p", "=", "y", "/", "ax_sum", "\n", "\n", "# flatten if X was 1D", "\n", "if", "len", "(", "X", ".", "shape", ")", "==", "1", ":", "p", "=", "p", ".", "flatten", "(", ")", "\n", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ": [[199, 209], ["activ_name.lower", "activ_name.lower", "activ_name.lower"], "function", ["None"], ["", "def", "make_activ", "(", "activ_name", ")", ":", "\n", "  ", "if", "activ_name", ".", "lower", "(", ")", "==", "'relu'", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "ReLU", "\n", "", "elif", "activ_name", ".", "lower", "(", ")", "==", "'gelu'", ":", "\n", "    ", "from", "mrl", ".", "utils", ".", "networks", "import", "GELU", "\n", "return", "GELU", "\n", "", "elif", "activ_name", ".", "lower", "(", ")", "==", "'tanh'", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "Tanh", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag": [[211, 232], ["numpy.zeros", "len", "scipy.linalg.block_diag", "len", "len"], "function", ["None"], ["", "", "def", "batch_block_diag", "(", "a", ",", "b", ")", ":", "\n", "  ", "\"\"\" \n  This does what scipy.linalg.block_diag does but in batch mode and with only 2 array\n  https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.linalg.block_diag.html\n  \"\"\"", "\n", "a_shape", "=", "a", ".", "shape", "\n", "b_shape", "=", "b", ".", "shape", "\n", "\n", "if", "len", "(", "a_shape", ")", "==", "2", ":", "\n", "    ", "return", "block_diag", "(", "a", ",", "b", ")", "\n", "\n", "", "assert", "len", "(", "a_shape", ")", "==", "3", "\n", "assert", "len", "(", "b_shape", ")", "==", "3", "\n", "\n", "assert", "a_shape", "[", "0", "]", "==", "b_shape", "[", "0", "]", "# the batch dimension", "\n", "\n", "res", "=", "np", ".", "zeros", "(", "(", "a_shape", "[", "0", "]", ",", "a_shape", "[", "1", "]", "+", "b_shape", "[", "1", "]", ",", "a_shape", "[", "2", "]", "+", "b_shape", "[", "2", "]", ")", ")", "\n", "res", "[", ":", ",", ":", "a_shape", "[", "1", "]", ",", ":", "a_shape", "[", "2", "]", "]", "=", "a", "\n", "res", "[", ":", ",", "a_shape", "[", "1", "]", ":", ",", "a_shape", "[", "2", "]", ":", "]", "=", "b", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.batch_block_diag_many": [[233, 250], ["numpy.array", "numpy.zeros", "enumerate", "len", "scipy.linalg.block_diag", "shapes[].sum", "shapes[].sum"], "function", ["None"], ["", "def", "batch_block_diag_many", "(", "*", "arrs", ")", ":", "\n", "  ", "shapes", "=", "np", ".", "array", "(", "[", "a", ".", "shape", "for", "a", "in", "arrs", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "if", "len", "(", "shapes", "[", "0", "]", ")", "==", "2", ":", "\n", "    ", "return", "block_diag", "(", "*", "arrs", ")", "\n", "\n", "# shapes is now 2D: num_arrs x 3", "\n", "\n", "", "res", "=", "np", ".", "zeros", "(", "(", "shapes", "[", "0", "]", "[", "0", "]", ",", "shapes", "[", ":", ",", "1", "]", ".", "sum", "(", ")", ",", "shapes", "[", ":", ",", "2", "]", ".", "sum", "(", ")", ")", ")", "\n", "\n", "r", ",", "c", "=", "0", ",", "0", "\n", "for", "i", ",", "(", "batch", ",", "rr", ",", "cc", ")", "in", "enumerate", "(", "shapes", ")", ":", "\n", "      ", "res", "[", ":", ",", "r", ":", "r", "+", "rr", ",", "c", ":", "c", "+", "cc", "]", "=", "arrs", "[", "i", "]", "\n", "r", "+=", "rr", "\n", "c", "+=", "cc", "\n", "\n", "", "return", "res", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.utils.schedule.ConstantSchedule.__init__": [[13, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "val", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.schedule.ConstantSchedule.__call__": [[16, 18], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "steps", "=", "1", ")", ":", "\n", "        ", "return", "self", ".", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.schedule.LinearSchedule.__init__": [[20, 31], ["float"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "start", ",", "end", "=", "None", ",", "steps", "=", "None", ")", ":", "\n", "        ", "if", "end", "is", "None", ":", "\n", "            ", "end", "=", "start", "\n", "steps", "=", "1", "\n", "", "self", ".", "inc", "=", "(", "end", "-", "start", ")", "/", "float", "(", "steps", ")", "\n", "self", ".", "current", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "if", "end", ">", "start", ":", "\n", "            ", "self", ".", "bound", "=", "min", "\n", "", "else", ":", "\n", "            ", "self", ".", "bound", "=", "max", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.utils.schedule.LinearSchedule.__call__": [[32, 36], ["schedule.LinearSchedule.bound"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "steps", "=", "1", ")", ":", "\n", "        ", "val", "=", "self", ".", "current", "\n", "self", ".", "current", "=", "self", ".", "bound", "(", "self", ".", "current", "+", "self", ".", "inc", "*", "steps", ",", "self", ".", "end", ")", "\n", "return", "val", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_frame_stack.VecFrameStack.__init__": [[15, 24], ["numpy.repeat", "numpy.repeat", "numpy.zeros", "gym.spaces.Box", "mrl.utils.vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "n_stack", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "self", ".", "n_stack", "=", "n_stack", "\n", "wrapped_obs_space", "=", "venv", ".", "observation_space", "\n", "low", "=", "np", ".", "repeat", "(", "wrapped_obs_space", ".", "low", ",", "self", ".", "n_stack", ",", "axis", "=", "-", "1", ")", "\n", "high", "=", "np", ".", "repeat", "(", "wrapped_obs_space", ".", "high", ",", "self", ".", "n_stack", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "stackedobs", "=", "np", ".", "zeros", "(", "(", "venv", ".", "num_envs", ",", ")", "+", "low", ".", "shape", ",", "low", ".", "dtype", ")", "\n", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "venv", ".", "observation_space", ".", "dtype", ")", "\n", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ",", "observation_space", "=", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_frame_stack.VecFrameStack.step_wait": [[25, 33], ["vec_frame_stack.VecFrameStack.venv.step_wait", "numpy.roll", "enumerate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.step_wait"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "observations", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "stackedobs", "=", "np", ".", "roll", "(", "self", ".", "stackedobs", ",", "shift", "=", "-", "observations", ".", "shape", "[", "-", "1", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "i", ",", "done", "in", "enumerate", "(", "dones", ")", ":", "\n", "            ", "if", "done", ":", "\n", "                ", "self", ".", "stackedobs", "[", "i", "]", "=", "0", "\n", "", "", "self", ".", "stackedobs", "[", "...", ",", "-", "observations", ".", "shape", "[", "-", "1", "]", ":", "]", "=", "observations", "\n", "return", "self", ".", "stackedobs", ",", "rewards", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_frame_stack.VecFrameStack.reset": [[34, 42], ["vec_frame_stack.VecFrameStack.venv.reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        \"\"\"", "\n", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "stackedobs", "[", "...", "]", "=", "0", "\n", "self", ".", "stackedobs", "[", "...", ",", "-", "obs", ".", "shape", "[", "-", "1", "]", ":", "]", "=", "obs", "\n", "return", "self", ".", "stackedobs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_frame_stack.VecFrameStack.close": [[43, 45], ["vec_frame_stack.VecFrameStack.venv.close"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "venv", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.__init__": [[52, 84], ["len", "zip", "subproc_vec_env.SubprocVecEnv.remotes[].send", "subproc_vec_env.SubprocVecEnv.remotes[].recv", "isinstance", "mrl.utils.vec_env.VecEnv.__init__", "multiprocessing.Process", "process.start", "remote.close", "tuple", "len", "zip", "hasattr", "observation_space.spaces.keys", "multiprocessing.Pipe", "range", "mrl.utils.vec_env.CloudpickleWrapper"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close"], ["def", "__init__", "(", "self", ",", "env_fns", ")", ":", "\n", "    ", "self", ".", "waiting", "=", "False", "\n", "self", ".", "closed", "=", "False", "\n", "n_envs", "=", "len", "(", "env_fns", ")", "\n", "\n", "self", ".", "remotes", ",", "self", ".", "work_remotes", "=", "zip", "(", "*", "[", "Pipe", "(", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", ")", "\n", "self", ".", "processes", "=", "[", "\n", "Process", "(", "target", "=", "_worker", ",", "args", "=", "(", "work_remote", ",", "remote", ",", "CloudpickleWrapper", "(", "env_fn", ")", ")", ")", "\n", "for", "(", "work_remote", ",", "remote", ",", "env_fn", ")", "in", "zip", "(", "self", ".", "work_remotes", ",", "self", ".", "remotes", ",", "env_fns", ")", "\n", "]", "\n", "for", "process", "in", "self", ".", "processes", ":", "\n", "      ", "process", ".", "daemon", "=", "True", "# if the main process crashes, we should not cause things to hang", "\n", "process", ".", "start", "(", ")", "\n", "", "for", "remote", "in", "self", ".", "work_remotes", ":", "\n", "      ", "remote", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "remotes", "[", "0", "]", ".", "send", "(", "(", "'get_spaces'", ",", "None", ")", ")", "\n", "observation_space", ",", "action_space", "=", "self", ".", "remotes", "[", "0", "]", ".", "recv", "(", ")", "\n", "\n", "self", ".", "goal_env", "=", "False", "\n", "self", ".", "goal_keys", "=", "None", "\n", "if", "isinstance", "(", "observation_space", ",", "spaces", ".", "Dict", ")", ":", "\n", "      ", "dummy_env", "=", "env_fns", "[", "0", "]", "(", ")", "\n", "self", ".", "dummy_env", "=", "dummy_env", "\n", "if", "dummy_env", ".", "compute_reward", "is", "not", "None", ":", "\n", "        ", "self", ".", "compute_reward", "=", "dummy_env", ".", "compute_reward", "\n", "\n", "", "if", "hasattr", "(", "dummy_env", ",", "'goal_extraction_function'", ")", "and", "dummy_env", ".", "goal_extraction_function", "is", "not", "None", ":", "\n", "        ", "self", ".", "goal_extraction_function", "=", "dummy_env", ".", "goal_extraction_function", "\n", "", "self", ".", "goal_env", "=", "True", "\n", "self", ".", "goal_keys", "=", "tuple", "(", "observation_space", ".", "spaces", ".", "keys", "(", ")", ")", "\n", "", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "observation_space", ",", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.step_async": [[85, 89], ["zip", "remote.send"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "    ", "for", "remote", ",", "action", "in", "zip", "(", "self", ".", "remotes", ",", "actions", ")", ":", "\n", "      ", "remote", ".", "send", "(", "(", "'step'", ",", "action", ")", ")", "\n", "", "self", ".", "waiting", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.step_wait": [[90, 99], ["zip", "remote.recv", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack"], "methods", ["None"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "    ", "results", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "self", ".", "waiting", "=", "False", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "zip", "(", "*", "results", ")", "\n", "if", "self", ".", "goal_env", ":", "\n", "      ", "obs", "=", "{", "k", ":", "np", ".", "stack", "(", "[", "o", "[", "k", "]", "for", "o", "in", "obs", "]", ")", "for", "k", "in", "self", ".", "goal_keys", "}", "\n", "", "else", ":", "\n", "      ", "obs", "=", "np", ".", "stack", "(", "obs", ")", "\n", "", "return", "obs", ",", "np", ".", "stack", "(", "rews", ")", ",", "np", ".", "stack", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.reset": [[100, 109], ["remote.send", "remote.recv", "numpy.stack", "numpy.stack"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "      ", "remote", ".", "send", "(", "(", "'reset'", ",", "None", ")", ")", "\n", "", "obs", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "if", "self", ".", "goal_env", ":", "\n", "      ", "obs", "=", "{", "k", ":", "np", ".", "stack", "(", "[", "o", "[", "k", "]", "for", "o", "in", "obs", "]", ")", "for", "k", "in", "self", ".", "goal_keys", "}", "\n", "", "else", ":", "\n", "      ", "obs", "=", "np", ".", "stack", "(", "obs", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.close": [[110, 121], ["remote.send", "process.join", "remote.recv"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "closed", ":", "\n", "      ", "return", "\n", "", "if", "self", ".", "waiting", ":", "\n", "      ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "        ", "remote", ".", "recv", "(", ")", "\n", "", "", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "      ", "remote", ".", "send", "(", "(", "'close'", ",", "None", ")", ")", "\n", "", "for", "process", "in", "self", ".", "processes", ":", "\n", "      ", "process", ".", "join", "(", ")", "\n", "", "self", ".", "closed", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.render": [[122, 138], ["subproc_vec_env.tile_images", "pipe.send", "pipe.recv", "cv2.imshow", "cv2.waitKey"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.tile_images"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "for", "pipe", "in", "self", ".", "remotes", ":", "\n", "# gather images from subprocesses", "\n", "# `mode` will be taken into account later", "\n", "      ", "pipe", ".", "send", "(", "(", "'render'", ",", "(", "args", ",", "{", "'mode'", ":", "'rgb_array'", ",", "**", "kwargs", "}", ")", ")", ")", "\n", "", "imgs", "=", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "remotes", "]", "\n", "# Create a big image by tiling images from subprocesses", "\n", "bigimg", "=", "tile_images", "(", "imgs", ")", "\n", "if", "mode", "==", "'human'", ":", "\n", "      ", "import", "cv2", "\n", "cv2", ".", "imshow", "(", "'vecenv'", ",", "bigimg", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "cv2", ".", "waitKey", "(", "1", ")", "\n", "", "elif", "mode", "==", "'rgb_array'", ":", "\n", "      ", "return", "bigimg", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.get_images": [[139, 144], ["pipe.send", "pipe.recv"], "methods", ["None"], ["", "", "def", "get_images", "(", "self", ")", ":", "\n", "    ", "for", "pipe", "in", "self", ".", "remotes", ":", "\n", "      ", "pipe", ".", "send", "(", "(", "'render'", ",", "{", "\"mode\"", ":", "'rgb_array'", "}", ")", ")", "\n", "", "imgs", "=", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "remotes", "]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.get_attr": [[145, 151], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "      ", "\"\"\"Return attribute from vectorized environment (see base class).\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "          ", "remote", ".", "send", "(", "(", "'get_attr'", ",", "attr_name", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "target_remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.set_attr": [[152, 159], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "      ", "\"\"\"Set attribute inside vectorized environments (see base class).\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "          ", "remote", ".", "send", "(", "(", "'set_attr'", ",", "(", "attr_name", ",", "value", ")", ")", ")", "\n", "", "for", "remote", "in", "target_remotes", ":", "\n", "          ", "remote", ".", "recv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv.env_method": [[160, 166], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "      ", "\"\"\"Call instance methods of vectorized environments.\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "          ", "remote", ".", "send", "(", "(", "'env_method'", ",", "(", "method_name", ",", "method_args", ",", "method_kwargs", ")", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "target_remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes": [[167, 176], ["subproc_vec_env.SubprocVecEnv._get_indices"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv._get_indices"], ["", "def", "_get_target_remotes", "(", "self", ",", "indices", ")", ":", "\n", "      ", "\"\"\"\n      Get the connection object needed to communicate with the wanted\n      envs that are in subprocesses.\n      :param indices: (None,int,Iterable) refers to indices of envs.\n      :return: ([multiprocessing.Connection]) Connection object to communicate between processes.\n      \"\"\"", "\n", "indices", "=", "self", ".", "_get_indices", "(", "indices", ")", "\n", "return", "[", "self", ".", "remotes", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env._worker": [[9, 43], ["parent_remote.close", "env_fn_wrapper.var", "remote.recv", "env_fn_wrapper.var.step", "remote.send", "env_fn_wrapper.var.reset", "env_fn_wrapper.var.reset", "remote.send", "remote.send", "env_fn_wrapper.var.render", "remote.close", "remote.send", "getattr", "remote.send", "getattr.", "remote.send", "getattr", "remote.send", "setattr", "remote.send", "env_fn_wrapper.var._sample_goals"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close"], ["def", "_worker", "(", "remote", ",", "parent_remote", ",", "env_fn_wrapper", ")", ":", "\n", "  ", "parent_remote", ".", "close", "(", ")", "\n", "env", "=", "env_fn_wrapper", ".", "var", "(", ")", "\n", "while", "True", ":", "\n", "    ", "try", ":", "\n", "      ", "cmd", ",", "data", "=", "remote", ".", "recv", "(", ")", "\n", "if", "cmd", "==", "'step'", ":", "\n", "        ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "data", ")", "\n", "if", "done", ":", "\n", "          ", "observation", "=", "env", ".", "reset", "(", ")", "\n", "", "remote", ".", "send", "(", "(", "observation", ",", "reward", ",", "done", ",", "info", ")", ")", "\n", "", "elif", "cmd", "==", "'reset'", ":", "\n", "        ", "observation", "=", "env", ".", "reset", "(", ")", "\n", "remote", ".", "send", "(", "observation", ")", "\n", "", "elif", "cmd", "==", "'render'", ":", "\n", "        ", "remote", ".", "send", "(", "env", ".", "render", "(", "*", "data", "[", "0", "]", ",", "**", "data", "[", "1", "]", ")", ")", "\n", "", "elif", "cmd", "==", "'close'", ":", "\n", "        ", "remote", ".", "close", "(", ")", "\n", "break", "\n", "", "elif", "cmd", "==", "'get_spaces'", ":", "\n", "        ", "remote", ".", "send", "(", "(", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", ")", "\n", "", "elif", "cmd", "==", "'env_method'", ":", "\n", "        ", "method", "=", "getattr", "(", "env", ",", "data", "[", "0", "]", ")", "\n", "remote", ".", "send", "(", "method", "(", "*", "data", "[", "1", "]", ",", "**", "data", "[", "2", "]", ")", ")", "\n", "", "elif", "cmd", "==", "'get_attr'", ":", "\n", "        ", "remote", ".", "send", "(", "getattr", "(", "env", ",", "data", ")", ")", "\n", "", "elif", "cmd", "==", "'set_attr'", ":", "\n", "        ", "remote", ".", "send", "(", "setattr", "(", "env", ",", "data", "[", "0", "]", ",", "data", "[", "1", "]", ")", ")", "\n", "", "elif", "cmd", "==", "'_sample_goal'", ":", "\n", "        ", "remote", ".", "send", "(", "env", ".", "_sample_goals", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", "except", "EOFError", ":", "\n", "      ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.subproc_vec_env.tile_images": [[179, 203], ["numpy.asarray", "int", "int", "numpy.array", "np.array.reshape", "out_image.reshape.transpose", "out_image.reshape.reshape", "numpy.ceil", "numpy.ceil", "numpy.sqrt", "list", "float", "range"], "function", ["None"], ["", "", "def", "tile_images", "(", "img_nhwc", ")", ":", "\n", "  ", "\"\"\"\n    Tile N images into one big PxQ image\n    (P,Q) are chosen to be as close as possible, and if N\n    is square, then P=Q.\n\n    :param img_nhwc: (list) list or array of images, ndim=4 once turned into array. img nhwc\n        n = batch index, h = height, w = width, c = channel\n    :return: (numpy float) img_HWc, ndim=3\n    \"\"\"", "\n", "img_nhwc", "=", "np", ".", "asarray", "(", "img_nhwc", ")", "\n", "n_images", ",", "height", ",", "width", ",", "n_channels", "=", "img_nhwc", ".", "shape", "\n", "# new_height was named H before", "\n", "new_height", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "n_images", ")", ")", ")", "\n", "# new_width was named W before", "\n", "new_width", "=", "int", "(", "np", ".", "ceil", "(", "float", "(", "n_images", ")", "/", "new_height", ")", ")", "\n", "img_nhwc", "=", "np", ".", "array", "(", "list", "(", "img_nhwc", ")", "+", "[", "img_nhwc", "[", "0", "]", "*", "0", "for", "_", "in", "range", "(", "n_images", ",", "new_height", "*", "new_width", ")", "]", ")", "\n", "# img_HWhwc", "\n", "out_image", "=", "img_nhwc", ".", "reshape", "(", "new_height", ",", "new_width", ",", "height", ",", "width", ",", "n_channels", ")", "\n", "# img_HhWwc", "\n", "out_image", "=", "out_image", ".", "transpose", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "# img_Hh_Ww_c", "\n", "out_image", "=", "out_image", ".", "reshape", "(", "new_height", "*", "height", ",", "new_width", "*", "width", ",", "n_channels", ")", "\n", "return", "out_image", "\n", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.__init__": [[16, 45], ["VecEnv.__init__", "isinstance", "subspaces.items", "numpy.zeros", "numpy.zeros", "fn", "len", "isinstance", "dummy_vec_env.DummyVecEnv.keys.append", "numpy.zeros", "hasattr", "range", "tuple"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["def", "__init__", "(", "self", ",", "env_fns", ")", ":", "\n", "    ", "self", ".", "envs", "=", "[", "fn", "(", ")", "for", "fn", "in", "env_fns", "]", "\n", "env", "=", "self", ".", "envs", "[", "0", "]", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", "\n", "shapes", ",", "dtypes", "=", "{", "}", ",", "{", "}", "\n", "self", ".", "keys", "=", "[", "]", "\n", "obs_space", "=", "env", ".", "observation_space", "\n", "\n", "self", ".", "dummy_env", "=", "env", "\n", "if", "isinstance", "(", "obs_space", ",", "spaces", ".", "Dict", ")", ":", "\n", "      ", "assert", "isinstance", "(", "obs_space", ".", "spaces", ",", "OrderedDict", ")", "\n", "subspaces", "=", "obs_space", ".", "spaces", "\n", "if", "env", ".", "compute_reward", "is", "not", "None", ":", "\n", "        ", "self", ".", "compute_reward", "=", "env", ".", "compute_reward", "\n", "", "if", "hasattr", "(", "env", ",", "'goal_extraction_function'", ")", "and", "env", ".", "goal_extraction_function", "is", "not", "None", ":", "\n", "        ", "self", ".", "goal_extraction_function", "=", "env", ".", "goal_extraction_function", "\n", "", "", "else", ":", "\n", "      ", "subspaces", "=", "{", "None", ":", "obs_space", "}", "\n", "\n", "", "for", "key", ",", "box", "in", "subspaces", ".", "items", "(", ")", ":", "\n", "      ", "shapes", "[", "key", "]", "=", "box", ".", "shape", "\n", "dtypes", "[", "key", "]", "=", "box", ".", "dtype", "\n", "self", ".", "keys", ".", "append", "(", "key", ")", "\n", "\n", "", "self", ".", "buf_obs", "=", "{", "k", ":", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", "+", "tuple", "(", "shapes", "[", "k", "]", ")", ",", "dtype", "=", "dtypes", "[", "k", "]", ")", "for", "k", "in", "self", ".", "keys", "}", "\n", "self", ".", "buf_dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "self", ".", "buf_rews", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "buf_infos", "=", "[", "{", "}", "for", "_", "in", "range", "(", "self", ".", "num_envs", ")", "]", "\n", "self", ".", "actions", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.step_async": [[46, 48], ["None"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "    ", "self", ".", "actions", "=", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.step_wait": [[49, 62], ["range", "dummy_vec_env.DummyVecEnv.envs[].step", "dummy_vec_env.DummyVecEnv._save_obs", "dummy_vec_env.DummyVecEnv.envs[].reset", "numpy.copy", "numpy.copy", "numpy.copy", "dummy_vec_env.DummyVecEnv.buf_infos.copy", "numpy.copy", "numpy.copy", "dummy_vec_env.DummyVecEnv.buf_infos.copy", "dummy_vec_env.DummyVecEnv._obs_from_buf", "numpy.copy", "dummy_vec_env.DummyVecEnv._obs_from_buf().items", "dummy_vec_env.DummyVecEnv._obs_from_buf"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._save_obs", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "    ", "for", "env_idx", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "      ", "obs", ",", "self", ".", "buf_rews", "[", "env_idx", "]", ",", "self", ".", "buf_dones", "[", "env_idx", "]", ",", "self", ".", "buf_infos", "[", "env_idx", "]", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "step", "(", "self", ".", "actions", "[", "env_idx", "]", ")", "\n", "if", "self", ".", "buf_dones", "[", "env_idx", "]", ":", "\n", "        ", "obs", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "reset", "(", ")", "\n", "", "self", ".", "_save_obs", "(", "env_idx", ",", "obs", ")", "\n", "", "if", "self", ".", "keys", "==", "[", "None", "]", ":", "\n", "      ", "return", "(", "np", ".", "copy", "(", "self", ".", "_obs_from_buf", "(", ")", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_rews", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_dones", ")", ",", "self", ".", "buf_infos", ".", "copy", "(", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "{", "k", ":", "np", ".", "copy", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "_obs_from_buf", "(", ")", ".", "items", "(", ")", "}", ",", "np", ".", "copy", "(", "self", ".", "buf_rews", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_dones", ")", ",", "\n", "self", ".", "buf_infos", ".", "copy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.reset": [[63, 71], ["range", "dummy_vec_env.DummyVecEnv.envs[].reset", "dummy_vec_env.DummyVecEnv._save_obs", "numpy.copy", "dummy_vec_env.DummyVecEnv._obs_from_buf", "numpy.copy", "dummy_vec_env.DummyVecEnv._obs_from_buf().items", "dummy_vec_env.DummyVecEnv._obs_from_buf"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._save_obs", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "    ", "for", "env_idx", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "      ", "obs", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "reset", "(", ")", "\n", "self", ".", "_save_obs", "(", "env_idx", ",", "obs", ")", "\n", "", "if", "self", ".", "keys", "==", "[", "None", "]", ":", "\n", "      ", "return", "np", ".", "copy", "(", "self", ".", "_obs_from_buf", "(", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "{", "k", ":", "np", ".", "copy", "(", "v", ")", "for", "k", ",", "v", "in", "self", ".", "_obs_from_buf", "(", ")", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.close": [[72, 74], ["None"], "methods", ["None"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.get_images": [[75, 77], ["env.render"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "get_images", "(", "self", ")", ":", "\n", "    ", "return", "[", "env", ".", "render", "(", "mode", "=", "'rgb_array'", ")", "for", "env", "in", "self", ".", "envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.render": [[78, 83], ["dummy_vec_env.DummyVecEnv.envs[].render", "super().render"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "self", ".", "num_envs", "==", "1", ":", "\n", "      ", "return", "self", ".", "envs", "[", "0", "]", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "      ", "return", "super", "(", ")", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._save_obs": [[84, 90], ["None"], "methods", ["None"], ["", "", "def", "_save_obs", "(", "self", ",", "env_idx", ",", "obs", ")", ":", "\n", "    ", "for", "key", "in", "self", ".", "keys", ":", "\n", "      ", "if", "key", "is", "None", ":", "\n", "        ", "self", ".", "buf_obs", "[", "key", "]", "[", "env_idx", "]", "=", "obs", "\n", "", "else", ":", "\n", "        ", "self", ".", "buf_obs", "[", "key", "]", "[", "env_idx", "]", "=", "obs", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf": [[91, 96], ["None"], "methods", ["None"], ["", "", "", "def", "_obs_from_buf", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "keys", "==", "[", "None", "]", ":", "\n", "      ", "return", "self", ".", "buf_obs", "[", "None", "]", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "buf_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.get_attr": [[97, 101], ["dummy_vec_env.DummyVecEnv._get_target_envs", "getattr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "      ", "\"\"\"Return attribute from vectorized environment (see base class).\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "return", "[", "getattr", "(", "env_i", ",", "attr_name", ")", "for", "env_i", "in", "target_envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.set_attr": [[102, 107], ["dummy_vec_env.DummyVecEnv._get_target_envs", "setattr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "      ", "\"\"\"Set attribute inside vectorized environments (see base class).\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "for", "env_i", "in", "target_envs", ":", "\n", "          ", "setattr", "(", "env_i", ",", "attr_name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.env_method": [[108, 112], ["dummy_vec_env.DummyVecEnv._get_target_envs", "getattr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "      ", "\"\"\"Call instance methods of vectorized environments.\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "return", "[", "getattr", "(", "env_i", ",", "method_name", ")", "(", "*", "method_args", ",", "**", "method_kwargs", ")", "for", "env_i", "in", "target_envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs": [[113, 116], ["dummy_vec_env.DummyVecEnv._get_indices"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv._get_indices"], ["", "def", "_get_target_envs", "(", "self", ",", "indices", ")", ":", "\n", "      ", "indices", "=", "self", ".", "_get_indices", "(", "indices", ")", "\n", "return", "[", "self", ".", "envs", "[", "i", "]", "for", "i", "in", "indices", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.AlreadySteppingError.__init__": [[12, 15], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "'already running an async step'", "\n", "Exception", ".", "__init__", "(", "self", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.NotSteppingError.__init__": [[23, 26], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "'not running an async step'", "\n", "Exception", ".", "__init__", "(", "self", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.__init__": [[37, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_envs", ",", "observation_space", ",", "action_space", ")", ":", "\n", "        ", "self", ".", "num_envs", "=", "num_envs", "\n", "self", ".", "observation_space", "=", "observation_space", "\n", "self", ".", "action_space", "=", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.reset": [[42, 55], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all the environments and return an array of\n        observations, or a dict of observation arrays (for goal envs).\n\n        If step_async is still doing work, that work will\n        be cancelled and step_wait() should not be called\n        until step_async() is invoked again.\n\n        :return: ([int] or [float] or dict) observation\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.step_async": [[56, 67], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "\"\"\"\n        Tell all the environments to start taking a step\n        with the given actions.\n        Call step_wait() to get the results of the step.\n\n        You should not call this if a step_async run is\n        already pending.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.step_wait": [[68, 76], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Wait for the step taken with step_async().\n\n        :return: ([int] or [float] or dict, [float], [bool], dict) observation, reward, done, information\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.close": [[77, 83], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Clean up the environment's resources.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.step": [[84, 93], ["base_vec_env.VecEnv.step_async", "base_vec_env.VecEnv.step_wait"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.step_async", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.step_wait"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "\"\"\"\n        Step the environments with the given action\n\n        :param actions: ([int] or [float]) the action\n        :return: ([int] or [float] or dict, [float], [bool], dict) observation, reward, done, information\n        \"\"\"", "\n", "self", ".", "step_async", "(", "actions", ")", "\n", "return", "self", ".", "step_wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.get_images": [[94, 99], ["None"], "methods", ["None"], ["", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return RGB images from each environment\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.render": [[100, 107], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Gym environment rendering\n\n        :param mode: (str) the rendering type\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv.unwrapped": [[108, 114], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "unwrapped", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "VecEnvWrapper", ")", ":", "\n", "            ", "return", "self", ".", "venv", ".", "unwrapped", "\n", "", "else", ":", "\n", "            ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnv._get_indices": [[115, 126], ["range", "isinstance"], "methods", ["None"], ["", "", "def", "_get_indices", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"\n        Convert a flexibly-typed reference to environment indices to an implied list of indices.\n        :param indices: (None,int,Iterable) refers to indices of envs.\n        :return: (list) the implied list of indices.\n        \"\"\"", "\n", "if", "indices", "is", "None", ":", "\n", "            ", "indices", "=", "range", "(", "self", ".", "num_envs", ")", "\n", "", "elif", "isinstance", "(", "indices", ",", "int", ")", ":", "\n", "            ", "indices", "=", "[", "indices", "]", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.__init__": [[137, 141], ["base_vec_env.VecEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "observation_space", "=", "None", ",", "action_space", "=", "None", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "num_envs", "=", "venv", ".", "num_envs", ",", "observation_space", "=", "observation_space", "or", "venv", ".", "observation_space", ",", "\n", "action_space", "=", "action_space", "or", "venv", ".", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.step_async": [[142, 144], ["base_vec_env.VecEnvWrapper.venv.step_async"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.step_async"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "venv", ".", "step_async", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.reset": [[145, 148], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.step_wait": [[149, 152], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.close": [[153, 155], ["base_vec_env.VecEnvWrapper.venv.close"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.render": [[156, 158], ["base_vec_env.VecEnvWrapper.venv.render"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.get_images": [[159, 161], ["base_vec_env.VecEnvWrapper.venv.get_images"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.VecEnvWrapper.get_images"], ["", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "get_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.CloudpickleWrapper.__init__": [[163, 170], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "var", ")", ":", "\n", "        ", "\"\"\"\n        Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n\n        :param var: (Any) the variable you wish to wrap for pickling with cloudpickle\n        \"\"\"", "\n", "self", ".", "var", "=", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.CloudpickleWrapper.__getstate__": [[171, 173], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "cloudpickle", ".", "dumps", "(", "self", ".", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.base_vec_env.CloudpickleWrapper.__setstate__": [[174, 176], ["pickle.loads"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "obs", ")", ":", "\n", "        ", "self", ".", "var", "=", "pickle", ".", "loads", "(", "obs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.RunningMeanStd.__init__": [[8, 19], ["numpy.zeros", "numpy.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "epsilon", "=", "1e-4", ",", "shape", "=", "(", ")", ")", ":", "\n", "        ", "\"\"\"\n        calulates the running mean and std of a data stream\n        https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n\n        :param epsilon: (float) helps with arithmetic issues\n        :param shape: (tuple) the shape of the data stream's output\n        \"\"\"", "\n", "self", ".", "mean", "=", "np", ".", "zeros", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "var", "=", "np", ".", "ones", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "count", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.RunningMeanStd.update": [[20, 25], ["numpy.mean", "numpy.var", "vec_normalize.RunningMeanStd.update_from_moments"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update_from_moments"], ["", "def", "update", "(", "self", ",", "arr", ")", ":", "\n", "        ", "batch_mean", "=", "np", ".", "mean", "(", "arr", ",", "axis", "=", "0", ")", "\n", "batch_var", "=", "np", ".", "var", "(", "arr", ",", "axis", "=", "0", ")", "\n", "batch_count", "=", "arr", ".", "shape", "[", "0", "]", "\n", "self", ".", "update_from_moments", "(", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.RunningMeanStd.update_from_moments": [[26, 41], ["numpy.square"], "methods", ["None"], ["", "def", "update_from_moments", "(", "self", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", ":", "\n", "        ", "delta", "=", "batch_mean", "-", "self", ".", "mean", "\n", "tot_count", "=", "self", ".", "count", "+", "batch_count", "\n", "\n", "new_mean", "=", "self", ".", "mean", "+", "delta", "*", "batch_count", "/", "tot_count", "\n", "m_a", "=", "self", ".", "var", "*", "self", ".", "count", "\n", "m_b", "=", "batch_var", "*", "batch_count", "\n", "m_2", "=", "m_a", "+", "m_b", "+", "np", ".", "square", "(", "delta", ")", "*", "self", ".", "count", "*", "batch_count", "/", "(", "self", ".", "count", "+", "batch_count", ")", "\n", "new_var", "=", "m_2", "/", "(", "self", ".", "count", "+", "batch_count", ")", "\n", "\n", "new_count", "=", "batch_count", "+", "self", ".", "count", "\n", "\n", "self", ".", "mean", "=", "new_mean", "\n", "self", ".", "var", "=", "new_var", "\n", "self", ".", "count", "=", "new_count", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.__init__": [[59, 74], ["mrl.utils.vec_env.VecEnvWrapper.__init__", "vec_normalize.RunningMeanStd", "vec_normalize.RunningMeanStd", "numpy.zeros", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "training", "=", "True", ",", "norm_obs", "=", "True", ",", "norm_reward", "=", "True", ",", "\n", "clip_obs", "=", "10.", ",", "clip_reward", "=", "10.", ",", "gamma", "=", "0.99", ",", "epsilon", "=", "1e-8", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "obs_rms", "=", "RunningMeanStd", "(", "shape", "=", "self", ".", "observation_space", ".", "shape", ")", "\n", "self", ".", "ret_rms", "=", "RunningMeanStd", "(", "shape", "=", "(", ")", ")", "\n", "self", ".", "clip_obs", "=", "clip_obs", "\n", "self", ".", "clip_reward", "=", "clip_reward", "\n", "# Returns: discounted rewards", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "norm_obs", "=", "norm_obs", "\n", "self", ".", "norm_reward", "=", "norm_reward", "\n", "self", ".", "old_obs", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.step_wait": [[75, 92], ["vec_normalize.VecNormalize.venv.step_wait", "vec_normalize.VecNormalize._normalize_observation", "numpy.clip", "vec_normalize.VecNormalize.ret_rms.update", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.step_wait", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize._normalize_observation", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Apply sequence of actions to sequence of environments\n        actions -> (observations, rewards, news)\n\n        where 'news' is a boolean vector indicating whether each element is new.\n        \"\"\"", "\n", "obs", ",", "rews", ",", "news", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "ret", "=", "self", ".", "ret", "*", "self", ".", "gamma", "+", "rews", "\n", "self", ".", "old_obs", "=", "obs", "\n", "obs", "=", "self", ".", "_normalize_observation", "(", "obs", ")", "\n", "if", "self", ".", "norm_reward", ":", "\n", "            ", "if", "self", ".", "training", ":", "\n", "                ", "self", ".", "ret_rms", ".", "update", "(", "self", ".", "ret", ")", "\n", "", "rews", "=", "np", ".", "clip", "(", "rews", "/", "np", ".", "sqrt", "(", "self", ".", "ret_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "clip_reward", ",", "self", ".", "clip_reward", ")", "\n", "", "self", ".", "ret", "[", "news", "]", "=", "0", "\n", "return", "obs", ",", "rews", ",", "news", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize._normalize_observation": [[93, 105], ["numpy.clip", "vec_normalize.VecNormalize.obs_rms.update", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update"], ["", "def", "_normalize_observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "\"\"\"\n        :param obs: (numpy tensor)\n        \"\"\"", "\n", "if", "self", ".", "norm_obs", ":", "\n", "            ", "if", "self", ".", "training", ":", "\n", "                ", "self", ".", "obs_rms", ".", "update", "(", "obs", ")", "\n", "", "obs", "=", "np", ".", "clip", "(", "(", "obs", "-", "self", ".", "obs_rms", ".", "mean", ")", "/", "np", ".", "sqrt", "(", "self", ".", "obs_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "clip_obs", ",", "\n", "self", ".", "clip_obs", ")", "\n", "return", "obs", "\n", "", "else", ":", "\n", "            ", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.get_original_obs": [[106, 113], ["None"], "methods", ["None"], ["", "", "def", "get_original_obs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        returns the unnormalized observation\n\n        :return: (numpy float)\n        \"\"\"", "\n", "return", "self", ".", "old_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.reset": [[114, 125], ["vec_normalize.VecNormalize.venv.reset", "numpy.zeros", "vec_normalize.VecNormalize._normalize_observation", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize._normalize_observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        \"\"\"", "\n", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "if", "len", "(", "np", ".", "array", "(", "obs", ")", ".", "shape", ")", "==", "1", ":", "# for when num_cpu is 1", "\n", "            ", "self", ".", "old_obs", "=", "[", "obs", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "old_obs", "=", "obs", "\n", "", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "return", "self", ".", "_normalize_observation", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.save_running_average": [[126, 133], ["zip", "open", "pickle.dump"], "methods", ["None"], ["", "def", "save_running_average", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        :param path: (str) path to log dir\n        \"\"\"", "\n", "for", "rms", ",", "name", "in", "zip", "(", "[", "self", ".", "obs_rms", ",", "self", ".", "ret_rms", "]", ",", "[", "'obs_rms'", ",", "'ret_rms'", "]", ")", ":", "\n", "            ", "with", "open", "(", "\"{}/{}.pkl\"", ".", "format", "(", "path", ",", "name", ")", ",", "'wb'", ")", "as", "file_handler", ":", "\n", "                ", "pickle", ".", "dump", "(", "rms", ",", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.vec_env.vec_normalize.VecNormalize.load_running_average": [[134, 141], ["open", "setattr", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "", "def", "load_running_average", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        :param path: (str) path to log dir\n        \"\"\"", "\n", "for", "name", "in", "[", "'obs_rms'", ",", "'ret_rms'", "]", ":", "\n", "            ", "with", "open", "(", "\"{}/{}.pkl\"", ".", "format", "(", "path", ",", "name", ")", ",", "'rb'", ")", "as", "file_handler", ":", "\n", "                ", "setattr", "(", "self", ",", "name", ",", "pickle", ".", "load", "(", "file_handler", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.random_ensemble_DPG.RandomEnsembleDPG.optimize_from_batch": [[8, 57], ["random_ensemble_DPG.RandomEnsembleDPG.actor_target", "noise.clamp.clamp.clamp", "torch.cat", "torch.distributions.dirichlet.Dirichlet().sample().to", "torch.clamp().detach", "F.mse_loss", "random_ensemble_DPG.RandomEnsembleDPG.critic_opt.zero_grad", "F.mse_loss.backward", "random_ensemble_DPG.RandomEnsembleDPG.critic_opt.step", "actor_loss.backward", "random_ensemble_DPG.RandomEnsembleDPG.actor_opt.step", "torch.randn_like", "torch.cat.append", "hasattr", "random_ensemble_DPG.RandomEnsembleDPG.logger.add_histogram", "torch.cat.append", "random_ensemble_DPG.RandomEnsembleDPG.actor", "torch.cat", "random_ensemble_DPG.RandomEnsembleDPG.actor_opt.zero_grad", "critic", "torch.distributions.dirichlet.Dirichlet().sample", "torch.clamp", "critic", "torch.cat.append", "torch.cat.mean", "torch.cat", "critic", "torch.distributions.dirichlet.Dirichlet", "torch.ones", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.size"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "\n", "gammas", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "\n", "a_next_max", "=", "self", ".", "actor_target", "(", "next_states", ")", "\n", "noise", "=", "torch", ".", "randn_like", "(", "a_next_max", ")", "*", "(", "\n", "config", ".", "td3_noise", "*", "self", ".", "action_scale", ")", "\n", "noise", "=", "noise", ".", "clamp", "(", "-", "config", ".", "td3_noise_clip", "*", "self", ".", "action_scale", ",", "\n", "config", ".", "td3_noise_clip", "*", "self", ".", "action_scale", ")", "\n", "a_next_max", "=", "(", "a_next_max", "+", "noise", ")", ".", "clamp", "(", "-", "self", ".", "action_scale", ",", "\n", "self", ".", "action_scale", ")", "\n", "\n", "qs", "=", "[", "]", "\n", "for", "critic", "in", "self", ".", "critics", ":", "\n", "      ", "qs", ".", "append", "(", "critic", "(", "next_states", ",", "a_next_max", ")", ")", "\n", "\n", "", "qs", "=", "torch", ".", "cat", "(", "qs", ",", "dim", "=", "-", "1", ")", "# batch x num_qs", "\n", "\n", "sample", "=", "torch", ".", "distributions", ".", "dirichlet", ".", "Dirichlet", "(", "torch", ".", "ones", "(", "1", ",", "qs", ".", "size", "(", "-", "1", ")", ")", ")", ".", "sample", "(", ")", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "\n", "target", "=", "(", "rewards", "+", "gammas", "*", "(", "qs", "*", "sample", ")", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", ".", "detach", "(", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "100", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Target_q'", ",", "target", ")", "\n", "\n", "", "qs", "=", "[", "]", "\n", "for", "critic", "in", "self", ".", "critics", ":", "\n", "      ", "qs", ".", "append", "(", "critic", "(", "states", ",", "actions", ")", ")", "\n", "", "qs", "=", "(", "torch", ".", "cat", "(", "qs", ",", "dim", "=", "-", "1", ")", "*", "sample", ")", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "qs", ",", "target", ")", "\n", "\n", "self", ".", "critic_opt", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_opt", ".", "step", "(", ")", "\n", "\n", "if", "config", ".", "opt_steps", "%", "config", ".", "td3_delay", "==", "0", ":", "\n", "      ", "a", "=", "self", ".", "actor", "(", "states", ")", "\n", "qs", "=", "[", "]", "\n", "for", "critic", "in", "self", ".", "critics", ":", "\n", "        ", "qs", ".", "append", "(", "critic", "(", "states", ",", "a", ")", ")", "\n", "", "qs", "=", "torch", ".", "cat", "(", "qs", ",", "dim", "=", "-", "1", ")", "\n", "\n", "actor_loss", "=", "-", "qs", ".", "mean", "(", ")", "\n", "\n", "self", ".", "actor_opt", ".", "zero_grad", "(", ")", "\n", "", "actor_loss", ".", "backward", "(", ")", "\n", "self", ".", "actor_opt", ".", "step", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.fixed_horizon_DDPG.FHDDPG.optimize_from_batch": [[8, 43], ["fixed_horizon_DDPG.FHDDPG.actor_target", "noise.clamp.clamp.clamp", "fixed_horizon_DDPG.FHDDPG.critic_target", "torch.clamp().detach", "fixed_horizon_DDPG.FHDDPG.critic", "F.mse_loss", "fixed_horizon_DDPG.FHDDPG.critic_opt.zero_grad", "F.mse_loss.backward", "fixed_horizon_DDPG.FHDDPG.critic_opt.step", "fixed_horizon_DDPG.FHDDPG.actor_opt.zero_grad", "actor_loss.backward", "fixed_horizon_DDPG.FHDDPG.actor_opt.step", "torch.randn_like", "F.pad", "hasattr", "fixed_horizon_DDPG.FHDDPG.logger.add_histogram", "fixed_horizon_DDPG.FHDDPG.logger.add_histogram", "fixed_horizon_DDPG.FHDDPG.actor", "[].mean", "torch.clamp", "F.mse_loss", "torch.zeros_like", "fixed_horizon_DDPG.FHDDPG.critic"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "\n", "a_next_max", "=", "self", ".", "actor_target", "(", "next_states", ")", "\n", "noise", "=", "torch", ".", "randn_like", "(", "a_next_max", ")", "*", "(", "config", ".", "td3_noise", "*", "self", ".", "action_scale", ")", "\n", "noise", "=", "noise", ".", "clamp", "(", "-", "config", ".", "td3_noise_clip", "*", "self", ".", "action_scale", ",", "\n", "config", ".", "td3_noise_clip", "*", "self", ".", "action_scale", ")", "\n", "a_next_max", "=", "(", "a_next_max", "+", "noise", ")", ".", "clamp", "(", "-", "self", ".", "action_scale", ",", "\n", "self", ".", "action_scale", ")", "\n", "\n", "q_next", "=", "self", ".", "critic_target", "(", "next_states", ",", "a_next_max", ")", "# batch x n_horizons", "\n", "q_next", "=", "F", ".", "pad", "(", "q_next", ",", "(", "1", ",", "0", ")", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "target", "=", "(", "rewards", "+", "gammas", "*", "q_next", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", ".", "detach", "(", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "100", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/First_horizon_target'", ",", "target", "[", ":", ",", "0", "]", ")", "\n", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Last_horizon_target'", ",", "target", "[", ":", ",", "-", "1", "]", ")", "\n", "\n", "", "q", "=", "self", ".", "critic", "(", "states", ",", "actions", ")", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "q", ",", "target", ")", "\n", "\n", "self", ".", "critic_opt", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_opt", ".", "step", "(", ")", "\n", "\n", "a", "=", "self", ".", "actor", "(", "states", ")", "+", "noise", "\n", "actor_loss", "=", "-", "self", ".", "critic", "(", "states", ",", "a", ")", "[", ":", ",", "-", "5", ":", "]", ".", "mean", "(", ")", "# update actor using ensemble of last 5 horizons", "\n", "if", "self", ".", "config", ".", "action_l2_regularization", ":", "\n", "      ", "actor_loss", "+=", "self", ".", "config", ".", "action_l2_regularization", "*", "F", ".", "mse_loss", "(", "a", ",", "torch", ".", "zeros_like", "(", "a", ")", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "self", ".", "actor_opt", ".", "step", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.QValuePolicy.__init__": [[12, 19], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'policy'", ",", "\n", "required_agent_modules", "=", "[", "\n", "'qvalue'", ",", "'env'", ",", "'replay_buffer'", "\n", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.QValuePolicy._setup": [[20, 22], ["discrete_off_policy.QValuePolicy.config.get"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "use_qvalue_target", "=", "self", ".", "config", ".", "get", "(", "'use_qvalue_target'", ")", "or", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.QValuePolicy.__call__": [[23, 53], ["mrl.utils.misc.flatten_state", "hasattr", "discrete_off_policy.QValuePolicy.torch", "discrete_off_policy.QValuePolicy.state_normalizer", "discrete_off_policy.QValuePolicy.numpy", "discrete_off_policy.QValuePolicy.numpy", "numpy.random.randint", "numpy.argmax", "discrete_off_policy.QValuePolicy.config.get", "numpy.array", "hasattr", "discrete_off_policy.QValuePolicy.qvalue_target", "discrete_off_policy.QValuePolicy.qvalue", "numpy.random.random", "discrete_off_policy.QValuePolicy.config.random_action_prob", "len", "discrete_off_policy.QValuePolicy.ag_curiosity.relabel_state", "discrete_off_policy.QValuePolicy.env.action_space.sample", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.relabel_state", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "__call__", "(", "self", ",", "state", ",", "greedy", "=", "False", ")", ":", "\n", "    ", "res", "=", "None", "\n", "# Initial Exploration ", "\n", "if", "self", ".", "training", ":", "\n", "      ", "if", "self", ".", "config", ".", "get", "(", "'initial_explore'", ")", "and", "len", "(", "\n", "self", ".", "replay_buffer", ")", "<", "self", ".", "config", ".", "initial_explore", ":", "\n", "        ", "res", "=", "np", ".", "array", "(", "[", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", ")", "\n", "", "elif", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "state", "=", "self", ".", "ag_curiosity", ".", "relabel_state", "(", "state", ")", "\n", "\n", "", "", "state", "=", "flatten_state", "(", "state", ",", "self", ".", "config", ".", "modalities", "+", "self", ".", "config", ".", "goal_modalities", ")", "# flatten goal environments", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "state", "=", "self", ".", "state_normalizer", "(", "state", ",", "update", "=", "self", ".", "training", ")", "\n", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "      ", "return", "res", "\n", "\n", "", "state", "=", "self", ".", "torch", "(", "state", ")", "\n", "\n", "if", "self", ".", "use_qvalue_target", ":", "\n", "      ", "q_values", "=", "self", ".", "numpy", "(", "self", ".", "qvalue_target", "(", "state", ")", ")", "\n", "", "else", ":", "\n", "      ", "q_values", "=", "self", ".", "numpy", "(", "self", ".", "qvalue", "(", "state", ")", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "not", "greedy", "and", "np", ".", "random", ".", "random", "(", ")", "<", "self", ".", "config", ".", "random_action_prob", "(", "steps", "=", "self", ".", "config", ".", "env_steps", ")", ":", "\n", "        ", "action", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "env", ".", "action_space", ".", "n", ",", "size", "=", "[", "self", ".", "env", ".", "num_envs", "]", ")", "\n", "", "else", ":", "\n", "      ", "action", "=", "np", ".", "argmax", "(", "q_values", ",", "-", "1", ")", "# Convert to int", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.BaseQLearning.__init__": [[58, 63], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'algorithm'", ",", "\n", "required_agent_modules", "=", "[", "'qvalue'", ",", "'replay_buffer'", ",", "'env'", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.BaseQLearning._setup": [[64, 88], ["list", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "discrete_off_policy.BaseQLearning.module_dict.values", "name.startswith", "isinstance", "discrete_off_policy.BaseQLearning.qvalues.append", "list", "module.copy", "module.copy.model.load_state_dict", "discrete_off_policy.BaseQLearning.agent.set_module", "discrete_off_policy.BaseQLearning.targets_and_models.append", "module.model.parameters", "module.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.set_module", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "\"\"\" Set up Q-value optimizers and create target network modules.\"\"\"", "\n", "\n", "self", ".", "targets_and_models", "=", "[", "]", "\n", "\n", "# Q-Value setup", "\n", "qvalue_params", "=", "[", "]", "\n", "self", ".", "qvalues", "=", "[", "]", "\n", "for", "module", "in", "list", "(", "self", ".", "module_dict", ".", "values", "(", ")", ")", ":", "\n", "      ", "name", "=", "module", ".", "module_name", "\n", "if", "name", ".", "startswith", "(", "'qvalue'", ")", "and", "isinstance", "(", "module", ",", "PytorchModel", ")", ":", "\n", "        ", "self", ".", "qvalues", ".", "append", "(", "module", ")", "\n", "qvalue_params", "+=", "list", "(", "module", ".", "model", ".", "parameters", "(", ")", ")", "\n", "target", "=", "module", ".", "copy", "(", "name", "+", "'_target'", ")", "\n", "target", ".", "model", ".", "load_state_dict", "(", "module", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "agent", ".", "set_module", "(", "name", "+", "'_target'", ",", "target", ")", "\n", "self", ".", "targets_and_models", ".", "append", "(", "(", "target", ".", "model", ",", "module", ".", "model", ")", ")", "\n", "\n", "", "", "self", ".", "qvalue_opt", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "qvalue_params", ",", "\n", "lr", "=", "self", ".", "config", ".", "qvalue_lr", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "qvalue_weight_decay", ")", "\n", "\n", "self", ".", "qvalue_params", "=", "qvalue_params", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.BaseQLearning.save": [[89, 94], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "discrete_off_policy.BaseQLearning.qvalue_opt.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'qvalue_opt_state_dict'", ":", "self", ".", "qvalue_opt", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.BaseQLearning.load": [[95, 99], ["os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "discrete_off_policy.BaseQLearning.qvalue_opt.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "self", ".", "qvalue_opt", ".", "load_state_dict", "(", "checkpoint", "[", "'qvalue_opt_state_dict'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.BaseQLearning._optimize": [[100, 110], ["len", "discrete_off_policy.BaseQLearning.replay_buffer.sample", "discrete_off_policy.BaseQLearning.optimize_from_batch", "mrl.utils.misc.soft_update"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.SimpleConservativeSAC.optimize_from_batch", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.soft_update"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "if", "len", "(", "self", ".", "replay_buffer", ")", ">", "self", ".", "config", ".", "warm_up", ":", "\n", "      ", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", "=", "self", ".", "replay_buffer", ".", "sample", "(", "\n", "self", ".", "config", ".", "batch_size", ")", "\n", "\n", "self", ".", "optimize_from_batch", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", "\n", "\n", "if", "self", ".", "config", ".", "opt_steps", "%", "self", ".", "config", ".", "target_network_update_freq", "==", "0", ":", "\n", "        ", "for", "target_model", ",", "model", "in", "self", ".", "targets_and_models", ":", "\n", "          ", "soft_update", "(", "target_model", ",", "model", ",", "self", ".", "config", ".", "target_network_update_frac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.BaseQLearning.optimize_from_batch": [[111, 113], ["NotImplementedError"], "methods", ["None"], ["", "", "", "", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "'Subclass this!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.discrete_off_policy.DQN.optimize_from_batch": [[116, 147], ["discrete_off_policy.DQN.qvalue_target().detach", "torch.clamp().detach", "torch.clamp().detach", "torch.clamp().detach", "torch.clamp().detach", "discrete_off_policy.DQN.qvalue", "q.gather.gather.gather", "torch.mse_loss", "torch.mse_loss", "discrete_off_policy.DQN.qvalue_opt.zero_grad", "torch.mse_loss.backward", "discrete_off_policy.DQN.qvalue_opt.step", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "q_next.gather.gather.gather", "hasattr", "discrete_off_policy.DQN.logger.add_histogram", "actions.unsqueeze().to", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "discrete_off_policy.DQN.qvalue_target", "discrete_off_policy.DQN.qvalue", "q_next.gather.gather.max", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "actions.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "    ", "q_next", "=", "self", ".", "qvalue_target", "(", "next_states", ")", ".", "detach", "(", ")", "\n", "\n", "if", "self", ".", "config", ".", "double_q", ":", "\n", "      ", "best_actions", "=", "torch", ".", "argmax", "(", "self", ".", "qvalue", "(", "next_states", ")", ",", "dim", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "q_next", "=", "q_next", ".", "gather", "(", "-", "1", ",", "best_actions", ")", "\n", "", "else", ":", "\n", "      ", "q_next", "=", "q_next", ".", "max", "(", "-", "1", ",", "keepdims", "=", "True", ")", "[", "0", "]", "# Assuming action dim is the last dimension", "\n", "\n", "", "target", "=", "(", "rewards", "+", "gammas", "*", "q_next", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", ".", "detach", "(", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "1000", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Target_q'", ",", "target", ")", "\n", "\n", "", "q", "=", "self", ".", "qvalue", "(", "states", ")", "\n", "q", "=", "q", ".", "gather", "(", "-", "1", ",", "actions", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "torch", ".", "int64", ")", ")", "\n", "td_loss", "=", "F", ".", "mse_loss", "(", "q", ",", "target", ")", "\n", "\n", "self", ".", "qvalue_opt", ".", "zero_grad", "(", ")", "\n", "td_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "qvalue_params", ",", "self", ".", "config", ".", "grad_norm_clipping", ")", "\n", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "qvalue_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "qvalue_opt", ".", "step", "(", ")", "\n", "\n", "return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.ActorPolicy.__init__": [[12, 19], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'policy'", ",", "\n", "required_agent_modules", "=", "[", "\n", "'actor'", ",", "'action_noise'", ",", "'env'", ",", "'replay_buffer'", "\n", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.ActorPolicy._setup": [[20, 22], ["continuous_off_policy.ActorPolicy.config.get"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "use_actor_target", "=", "self", ".", "config", ".", "get", "(", "'use_actor_target'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.ActorPolicy.__call__": [[23, 59], ["mrl.utils.misc.flatten_state", "hasattr", "continuous_off_policy.ActorPolicy.torch", "numpy.clip", "continuous_off_policy.ActorPolicy.state_normalizer", "continuous_off_policy.ActorPolicy.numpy", "continuous_off_policy.ActorPolicy.numpy", "continuous_off_policy.ActorPolicy.action_noise", "continuous_off_policy.ActorPolicy.config.get", "continuous_off_policy.ActorPolicy.config.get", "numpy.array", "hasattr", "continuous_off_policy.ActorPolicy.actor_target", "continuous_off_policy.ActorPolicy.actor", "hasattr", "len", "continuous_off_policy.ActorPolicy.ag_curiosity.relabel_state", "continuous_off_policy.ActorPolicy.env.action_space.sample", "numpy.random.random", "range", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.relabel_state", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "__call__", "(", "self", ",", "state", ",", "greedy", "=", "False", ")", ":", "\n", "    ", "action_scale", "=", "self", ".", "env", ".", "max_action", "\n", "\n", "# initial exploration and intrinsic curiosity", "\n", "res", "=", "None", "\n", "if", "self", ".", "training", ":", "\n", "      ", "if", "self", ".", "config", ".", "get", "(", "'initial_explore'", ")", "and", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "config", ".", "initial_explore", ":", "\n", "        ", "res", "=", "np", ".", "array", "(", "[", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", ")", "\n", "", "elif", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "state", "=", "self", ".", "ag_curiosity", ".", "relabel_state", "(", "state", ")", "\n", "\n", "", "", "state", "=", "flatten_state", "(", "state", ",", "self", ".", "config", ".", "modalities", "+", "self", ".", "config", ".", "goal_modalities", ")", "# flatten goal environments", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "state", "=", "self", ".", "state_normalizer", "(", "state", ",", "update", "=", "self", ".", "training", ")", "\n", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "      ", "return", "res", "\n", "\n", "", "state", "=", "self", ".", "torch", "(", "state", ")", "\n", "\n", "if", "self", ".", "use_actor_target", ":", "\n", "      ", "action", "=", "self", ".", "numpy", "(", "self", ".", "actor_target", "(", "state", ")", ")", "\n", "", "else", ":", "\n", "      ", "action", "=", "self", ".", "numpy", "(", "self", ".", "actor", "(", "state", ")", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "not", "greedy", ":", "\n", "      ", "action", "=", "self", ".", "action_noise", "(", "action", ")", "\n", "if", "self", ".", "config", ".", "get", "(", "'eexplore'", ")", ":", "\n", "        ", "eexplore", "=", "self", ".", "config", ".", "eexplore", "\n", "if", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "          ", "eexplore", "=", "self", ".", "ag_curiosity", ".", "go_explore", "*", "self", ".", "config", ".", "go_eexplore", "+", "eexplore", "\n", "", "mask", "=", "(", "np", ".", "random", ".", "random", "(", "(", "action", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "<", "eexplore", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "randoms", "=", "np", ".", "random", ".", "random", "(", "action", ".", "shape", ")", "*", "(", "2", "*", "action_scale", ")", "-", "action_scale", "\n", "action", "=", "mask", "*", "randoms", "+", "(", "1", "-", "mask", ")", "*", "action", "\n", "\n", "", "", "return", "np", ".", "clip", "(", "action", ",", "-", "action_scale", ",", "action_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.StochasticActorPolicy.__init__": [[63, 70], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'policy'", ",", "\n", "required_agent_modules", "=", "[", "\n", "'actor'", ",", "'env'", ",", "'replay_buffer'", "\n", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.StochasticActorPolicy._setup": [[71, 73], ["continuous_off_policy.StochasticActorPolicy.config.get"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "use_actor_target", "=", "self", ".", "config", ".", "get", "(", "'use_actor_target'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.StochasticActorPolicy.__call__": [[74, 109], ["mrl.utils.misc.flatten_state", "hasattr", "continuous_off_policy.StochasticActorPolicy.torch", "continuous_off_policy.StochasticActorPolicy.numpy", "numpy.clip", "continuous_off_policy.StochasticActorPolicy.state_normalizer", "continuous_off_policy.StochasticActorPolicy.actor_target", "continuous_off_policy.StochasticActorPolicy.actor", "continuous_off_policy.StochasticActorPolicy.config.get", "hasattr", "continuous_off_policy.StochasticActorPolicy.config.get", "numpy.array", "hasattr", "len", "continuous_off_policy.StochasticActorPolicy.ag_curiosity.relabel_state", "numpy.random.random", "continuous_off_policy.StochasticActorPolicy.env.action_space.sample", "numpy.random.random", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.relabel_state", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "__call__", "(", "self", ",", "state", ",", "greedy", "=", "False", ")", ":", "\n", "    ", "action_scale", "=", "self", ".", "env", ".", "max_action", "\n", "\n", "# initial exploration and intrinsic curiosity", "\n", "res", "=", "None", "\n", "if", "self", ".", "training", ":", "\n", "      ", "if", "self", ".", "config", ".", "get", "(", "'initial_explore'", ")", "and", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "config", ".", "initial_explore", ":", "\n", "          ", "res", "=", "np", ".", "array", "(", "[", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", ")", "\n", "", "elif", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "state", "=", "self", ".", "ag_curiosity", ".", "relabel_state", "(", "state", ")", "\n", "\n", "", "", "state", "=", "flatten_state", "(", "state", ",", "self", ".", "config", ".", "modalities", "+", "self", ".", "config", ".", "goal_modalities", ")", "# flatten goal environments", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "state", "=", "self", ".", "state_normalizer", "(", "state", ",", "update", "=", "self", ".", "training", ")", "\n", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "      ", "return", "res", "\n", "\n", "", "state", "=", "self", ".", "torch", "(", "state", ")", "\n", "\n", "if", "self", ".", "use_actor_target", ":", "\n", "      ", "action", ",", "_", "=", "self", ".", "actor_target", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "action", ",", "_", "=", "self", ".", "actor", "(", "state", ")", "\n", "", "action", "=", "self", ".", "numpy", "(", "action", ")", "\n", "\n", "if", "self", ".", "training", "and", "not", "greedy", "and", "self", ".", "config", ".", "get", "(", "'eexplore'", ")", ":", "\n", "      ", "eexplore", "=", "self", ".", "config", ".", "eexplore", "\n", "if", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "eexplore", "=", "self", ".", "ag_curiosity", ".", "go_explore", "*", "self", ".", "config", ".", "go_eexplore", "+", "eexplore", "\n", "", "mask", "=", "(", "np", ".", "random", ".", "random", "(", "(", "action", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "<", "eexplore", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "randoms", "=", "np", ".", "random", ".", "random", "(", "action", ".", "shape", ")", "*", "(", "2", "*", "action_scale", ")", "-", "action_scale", "\n", "action", "=", "mask", "*", "randoms", "+", "(", "1", "-", "mask", ")", "*", "action", "\n", "\n", "", "return", "np", ".", "clip", "(", "action", ",", "-", "action_scale", ",", "action_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.BatchConstrainedPolicy.__init__": [[117, 124], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'policy'", ",", "\n", "required_agent_modules", "=", "[", "\n", "'critic'", ",", "'actor'", ",", "'env'", ",", "'replay_buffer'", "\n", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.BatchConstrainedPolicy.__call__": [[125, 164], ["mrl.utils.misc.flatten_state", "hasattr", "continuous_off_policy.BatchConstrainedPolicy.torch", "continuous_off_policy.BatchConstrainedPolicy.actor", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "continuous_off_policy.BatchConstrainedPolicy.critic", "q_values.reshape.reshape.reshape", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "continuous_off_policy.BatchConstrainedPolicy.gather().squeeze", "continuous_off_policy.BatchConstrainedPolicy.numpy", "numpy.clip", "continuous_off_policy.BatchConstrainedPolicy.state_normalizer", "continuous_off_policy.BatchConstrainedPolicy.reshape", "continuous_off_policy.BatchConstrainedPolicy.action_noise", "continuous_off_policy.BatchConstrainedPolicy.config.get", "continuous_off_policy.BatchConstrainedPolicy.config.get", "numpy.array", "hasattr", "continuous_off_policy.BatchConstrainedPolicy.gather", "hasattr", "len", "continuous_off_policy.BatchConstrainedPolicy.ag_curiosity.relabel_state", "torch.tile", "torch.tile", "torch.tile", "torch.tile", "continuous_off_policy.BatchConstrainedPolicy.env.action_space.sample", "numpy.random.random", "range", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.relabel_state", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "__call__", "(", "self", ",", "state", ",", "greedy", "=", "False", ")", ":", "\n", "    ", "action_scale", "=", "self", ".", "env", ".", "max_action", "\n", "\n", "# initial exploration and intrinsic curiosity", "\n", "res", "=", "None", "\n", "if", "self", ".", "training", ":", "\n", "      ", "if", "self", ".", "config", ".", "get", "(", "'initial_explore'", ")", "and", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "config", ".", "initial_explore", ":", "\n", "        ", "res", "=", "np", ".", "array", "(", "[", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", ")", "\n", "", "elif", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "state", "=", "self", ".", "ag_curiosity", ".", "relabel_state", "(", "state", ")", "\n", "\n", "", "", "state", "=", "flatten_state", "(", "state", ",", "self", ".", "config", ".", "modalities", "+", "self", ".", "config", ".", "goal_modalities", ")", "# flatten goal environments, # batch x state_dim", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "state", "=", "self", ".", "state_normalizer", "(", "state", ",", "update", "=", "self", ".", "training", ")", "\n", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "      ", "return", "res", "\n", "\n", "", "state", "=", "self", ".", "torch", "(", "state", ")", "\n", "\n", "action_proposals", "=", "self", ".", "actor", "(", "state", ")", "# batch x num_proposals x action_dim", "\n", "states", "=", "torch", ".", "repeat_interleave", "(", "state", ",", "action_proposals", ".", "shape", "[", "1", "]", ",", "0", ")", "\n", "q_values", "=", "self", ".", "critic", "(", "states", ",", "action_proposals", ".", "reshape", "(", "-", "1", ",", "action_proposals", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "q_values", "=", "q_values", ".", "reshape", "(", "state", ".", "shape", "[", "0", "]", ",", "action_proposals", ".", "shape", "[", "1", "]", ")", "# batch x num_proposals", "\n", "best_actions", "=", "torch", ".", "argmax", "(", "q_values", ",", "dim", "=", "-", "1", ",", "keepdims", "=", "True", ")", "# batch x 1", "\n", "action", "=", "action_proposals", ".", "gather", "(", "1", ",", "torch", ".", "tile", "(", "best_actions", "[", ":", ",", ":", ",", "None", "]", ",", "(", "1", ",", "1", ",", "action_proposals", ".", "shape", "[", "2", "]", ")", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "action", "=", "self", ".", "numpy", "(", "action", ")", "\n", "\n", "if", "self", ".", "training", "and", "not", "greedy", ":", "\n", "      ", "action", "=", "self", ".", "action_noise", "(", "action", ")", "\n", "if", "self", ".", "config", ".", "get", "(", "'eexplore'", ")", ":", "\n", "        ", "eexplore", "=", "self", ".", "config", ".", "eexplore", "\n", "if", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "          ", "eexplore", "=", "self", ".", "ag_curiosity", ".", "go_explore", "*", "self", ".", "config", ".", "go_eexplore", "+", "eexplore", "\n", "", "mask", "=", "(", "np", ".", "random", ".", "random", "(", "(", "action", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "<", "eexplore", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "randoms", "=", "np", ".", "random", ".", "random", "(", "action", ".", "shape", ")", "*", "(", "2", "*", "action_scale", ")", "-", "action_scale", "\n", "action", "=", "mask", "*", "randoms", "+", "(", "1", "-", "mask", ")", "*", "action", "\n", "\n", "", "", "return", "np", ".", "clip", "(", "action", ",", "-", "action_scale", ",", "action_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.OffPolicyActorCritic.__init__": [[169, 174], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'algorithm'", ",", "\n", "required_agent_modules", "=", "[", "'actor'", ",", "'critic'", ",", "'replay_buffer'", ",", "'env'", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.OffPolicyActorCritic._setup": [[175, 230], ["list", "list", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "continuous_off_policy.OffPolicyActorCritic.module_dict.values", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "mrl.utils.misc.AttrDict", "continuous_off_policy.OffPolicyActorCritic.module_dict.values", "name.startswith", "isinstance", "continuous_off_policy.OffPolicyActorCritic.actors.append", "list", "module.copy", "module.copy.model.load_state_dict", "module.copy.model.parameters", "continuous_off_policy.OffPolicyActorCritic.agent.set_module", "continuous_off_policy.OffPolicyActorCritic.targets_and_models.append", "name.startswith", "isinstance", "continuous_off_policy.OffPolicyActorCritic.critics.append", "list", "module.copy", "module.copy.model.load_state_dict", "module.copy.model.parameters", "continuous_off_policy.OffPolicyActorCritic.agent.set_module", "continuous_off_policy.OffPolicyActorCritic.targets_and_models.append", "module.model.parameters", "module.model.state_dict", "module.model.parameters", "module.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.set_module", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.set_module", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "\"\"\"Sets up actor/critic optimizers and creates target network modules\"\"\"", "\n", "\n", "self", ".", "targets_and_models", "=", "[", "]", "\n", "\n", "# Actor setup", "\n", "actor_params", "=", "[", "]", "\n", "self", ".", "actors", "=", "[", "]", "\n", "for", "module", "in", "list", "(", "self", ".", "module_dict", ".", "values", "(", ")", ")", ":", "\n", "      ", "name", "=", "module", ".", "module_name", "\n", "if", "name", ".", "startswith", "(", "'actor'", ")", "and", "isinstance", "(", "module", ",", "PytorchModel", ")", ":", "\n", "        ", "self", ".", "actors", ".", "append", "(", "module", ")", "\n", "actor_params", "+=", "list", "(", "module", ".", "model", ".", "parameters", "(", ")", ")", "\n", "target", "=", "module", ".", "copy", "(", "name", "+", "'_target'", ")", "\n", "target", ".", "model", ".", "load_state_dict", "(", "module", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "# Freeze target networks with respect to optimizers (only update via polyak averaging)", "\n", "for", "p", "in", "target", ".", "model", ".", "parameters", "(", ")", ":", "\n", "          ", "p", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "agent", ".", "set_module", "(", "name", "+", "'_target'", ",", "target", ")", "\n", "self", ".", "targets_and_models", ".", "append", "(", "(", "target", ".", "model", ",", "module", ".", "model", ")", ")", "\n", "\n", "", "", "if", "actor_params", ":", "\n", "      ", "self", ".", "actor_opt", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "actor_params", ",", "\n", "lr", "=", "self", ".", "config", ".", "actor_lr", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "actor_weight_decay", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "actor_opt", "=", "AttrDict", "(", "{", "'state_dict'", ":", "lambda", ":", "[", "]", "}", ")", "\n", "\n", "", "self", ".", "actor_params", "=", "actor_params", "\n", "\n", "# Critic setup", "\n", "critic_params", "=", "[", "]", "\n", "self", ".", "critics", "=", "[", "]", "\n", "for", "module", "in", "list", "(", "self", ".", "module_dict", ".", "values", "(", ")", ")", ":", "\n", "      ", "name", "=", "module", ".", "module_name", "\n", "if", "name", ".", "startswith", "(", "'critic'", ")", "and", "isinstance", "(", "module", ",", "PytorchModel", ")", ":", "\n", "        ", "self", ".", "critics", ".", "append", "(", "module", ")", "\n", "critic_params", "+=", "list", "(", "module", ".", "model", ".", "parameters", "(", ")", ")", "\n", "target", "=", "module", ".", "copy", "(", "name", "+", "'_target'", ")", "\n", "target", ".", "model", ".", "load_state_dict", "(", "module", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "# Freeze target networks with respect to optimizers (only update via polyak averaging)", "\n", "for", "p", "in", "target", ".", "model", ".", "parameters", "(", ")", ":", "\n", "          ", "p", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "agent", ".", "set_module", "(", "name", "+", "'_target'", ",", "target", ")", "\n", "self", ".", "targets_and_models", ".", "append", "(", "(", "target", ".", "model", ",", "module", ".", "model", ")", ")", "\n", "\n", "", "", "self", ".", "critic_opt", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "critic_params", ",", "\n", "lr", "=", "self", ".", "config", ".", "critic_lr", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "critic_weight_decay", ")", "\n", "\n", "self", ".", "critic_params", "=", "critic_params", "\n", "\n", "self", ".", "action_scale", "=", "self", ".", "env", ".", "max_action", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.OffPolicyActorCritic.save": [[231, 237], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "continuous_off_policy.OffPolicyActorCritic.actor_opt.state_dict", "continuous_off_policy.OffPolicyActorCritic.critic_opt.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'actor_opt_state_dict'", ":", "self", ".", "actor_opt", ".", "state_dict", "(", ")", ",", "\n", "'critic_opt_state_dict'", ":", "self", ".", "critic_opt", ".", "state_dict", "(", ")", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.OffPolicyActorCritic.load": [[238, 243], ["os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "continuous_off_policy.OffPolicyActorCritic.critic_opt.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "#self.actor_opt.load_state_dict(checkpoint['actor_opt_state_dict'])", "\n", "self", ".", "critic_opt", ".", "load_state_dict", "(", "checkpoint", "[", "'critic_opt_state_dict'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.OffPolicyActorCritic._optimize": [[244, 254], ["len", "continuous_off_policy.OffPolicyActorCritic.replay_buffer.sample", "continuous_off_policy.OffPolicyActorCritic.optimize_from_batch", "mrl.utils.misc.soft_update"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.SimpleConservativeSAC.optimize_from_batch", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.soft_update"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "if", "len", "(", "self", ".", "replay_buffer", ")", ">", "self", ".", "config", ".", "warm_up", ":", "\n", "      ", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", "=", "self", ".", "replay_buffer", ".", "sample", "(", "\n", "self", ".", "config", ".", "batch_size", ")", "\n", "\n", "self", ".", "optimize_from_batch", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", "\n", "\n", "if", "self", ".", "config", ".", "opt_steps", "%", "self", ".", "config", ".", "target_network_update_freq", "==", "0", ":", "\n", "        ", "for", "target_model", ",", "model", "in", "self", ".", "targets_and_models", ":", "\n", "          ", "soft_update", "(", "target_model", ",", "model", ",", "self", ".", "config", ".", "target_network_update_frac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.OffPolicyActorCritic.optimize_from_batch": [[255, 257], ["NotImplementedError"], "methods", ["None"], ["", "", "", "", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "'Subclass this!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.DDPG.optimize_from_batch": [[261, 316], ["continuous_off_policy.DDPG.critic", "torch.mse_loss", "torch.mse_loss", "continuous_off_policy.DDPG.critic_opt.zero_grad", "torch.mse_loss.backward", "continuous_off_policy.DDPG.critic_opt.step", "continuous_off_policy.DDPG.actor", "continuous_off_policy.DDPG.config.get", "continuous_off_policy.DDPG.actor_opt.zero_grad", "actor_loss.backward", "continuous_off_policy.DDPG.actor_opt.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "continuous_off_policy.DDPG.critic_target", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "hasattr", "continuous_off_policy.DDPG.logger.add_histogram", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "[].mean", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "continuous_off_policy.DDPG.actor_target", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.mse_loss", "torch.mse_loss", "p.grad.detach().mul_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "p.grad.detach().mul_", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "continuous_off_policy.DDPG.critic", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "p.grad.detach", "p.grad.detach", "p.grad.detach", "p.grad.detach"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "q_next", "=", "self", ".", "critic_target", "(", "next_states", ",", "self", ".", "actor_target", "(", "next_states", ")", ")", "\n", "target", "=", "(", "rewards", "+", "gammas", "*", "q_next", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "1000", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Target_q'", ",", "target", ")", "\n", "\n", "", "q", "=", "self", ".", "critic", "(", "states", ",", "actions", ")", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "q", ",", "target", ")", "\n", "\n", "self", ".", "critic_opt", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "        ", "clip_coef", "=", "self", ".", "config", ".", "grad_norm_clipping", "/", "(", "1e-6", "+", "torch", ".", "norm", "(", "p", ".", "grad", ".", "detach", "(", ")", ")", ")", "\n", "if", "clip_coef", "<", "1", ":", "\n", "          ", "p", ".", "grad", ".", "detach", "(", ")", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "critic_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "      ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "a", "=", "self", ".", "actor", "(", "states", ")", "\n", "if", "self", ".", "config", ".", "get", "(", "'policy_opt_noise'", ")", ":", "\n", "      ", "noise", "=", "torch", ".", "randn_like", "(", "a", ")", "*", "(", "self", ".", "config", ".", "policy_opt_noise", "*", "self", ".", "action_scale", ")", "\n", "a", "=", "(", "a", "+", "noise", ")", ".", "clamp", "(", "-", "self", ".", "action_scale", ",", "self", ".", "action_scale", ")", "\n", "\n", "", "actor_loss", "=", "-", "self", ".", "critic", "(", "states", ",", "a", ")", "[", ":", ",", "-", "1", "]", ".", "mean", "(", ")", "\n", "if", "self", ".", "config", ".", "action_l2_regularization", ":", "\n", "      ", "actor_loss", "+=", "self", ".", "config", ".", "action_l2_regularization", "*", "F", ".", "mse_loss", "(", "a", "/", "self", ".", "action_scale", ",", "torch", ".", "zeros_like", "(", "a", ")", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "for", "p", "in", "self", ".", "actor_params", ":", "\n", "        ", "clip_coef", "=", "self", ".", "config", ".", "grad_norm_clipping", "/", "(", "1e-6", "+", "torch", ".", "norm", "(", "p", ".", "grad", ".", "detach", "(", ")", ")", ")", "\n", "if", "clip_coef", "<", "1", ":", "\n", "          ", "p", ".", "grad", ".", "detach", "(", ")", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "actor_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "      ", "p", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.TD3.optimize_from_batch": [[320, 382], ["continuous_off_policy.TD3.critic_opt.zero_grad", "critic_loss.backward", "continuous_off_policy.TD3.critic_opt.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "continuous_off_policy.TD3.actor", "noise.clamp.clamp.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "hasattr", "continuous_off_policy.TD3.logger.add_histogram", "continuous_off_policy.TD3.critic", "continuous_off_policy.TD3.critic2", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "continuous_off_policy.TD3.actor", "continuous_off_policy.TD3.config.get", "continuous_off_policy.TD3.config.get", "continuous_off_policy.TD3.actor_opt.zero_grad", "actor_loss.backward", "continuous_off_policy.TD3.actor_opt.step", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "continuous_off_policy.TD3.critic_target", "continuous_off_policy.TD3.critic2_target", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "continuous_off_policy.TD3.logger.add_scalar", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.min", "torch.min", "torch.min", "torch.min", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.min", "torch.min", "torch.min", "torch.min", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "continuous_off_policy.TD3.critic", "continuous_off_policy.TD3.critic2"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "a_next_max", "=", "self", ".", "actor", "(", "next_states", ")", "\n", "noise", "=", "torch", ".", "randn_like", "(", "a_next_max", ")", "*", "(", "config", ".", "td3_noise", "*", "self", ".", "action_scale", ")", "\n", "noise", "=", "noise", ".", "clamp", "(", "-", "config", ".", "td3_noise_clip", "*", "self", ".", "action_scale", ",", "\n", "config", ".", "td3_noise_clip", "*", "self", ".", "action_scale", ")", "\n", "a_next_max", "=", "(", "a_next_max", "+", "noise", ")", ".", "clamp", "(", "-", "self", ".", "action_scale", ",", "self", ".", "action_scale", ")", "\n", "\n", "q1", ",", "q2", "=", "self", ".", "critic_target", "(", "next_states", ",", "a_next_max", ")", ",", "self", ".", "critic2_target", "(", "\n", "next_states", ",", "a_next_max", ")", "\n", "\n", "target", "=", "(", "rewards", "+", "gammas", "*", "torch", ".", "min", "(", "q1", ",", "q2", ")", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "1000", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Target_q'", ",", "target", ")", "\n", "\n", "", "q1", ",", "q2", "=", "self", ".", "critic", "(", "states", ",", "actions", ")", ",", "self", ".", "critic2", "(", "states", ",", "actions", ")", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "q1", ",", "target", ")", "+", "F", ".", "mse_loss", "(", "q2", ",", "target", ")", "\n", "\n", "self", ".", "critic_opt", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_norm_clipping", ")", "\n", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "critic_opt", ".", "step", "(", ")", "\n", "\n", "if", "config", ".", "opt_steps", "%", "config", ".", "td3_delay", "==", "0", ":", "\n", "      ", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "        ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "a", "=", "self", ".", "actor", "(", "states", ")", "\n", "if", "self", ".", "config", ".", "get", "(", "'policy_opt_noise'", ")", ":", "\n", "        ", "noise", "=", "torch", ".", "randn_like", "(", "a", ")", "*", "(", "config", ".", "policy_opt_noise", "*", "self", ".", "action_scale", ")", "\n", "a", "=", "(", "a", "+", "noise", ")", ".", "clamp", "(", "-", "self", ".", "action_scale", ",", "self", ".", "action_scale", ")", "\n", "", "actor_loss", "=", "-", "torch", ".", "min", "(", "self", ".", "critic", "(", "states", ",", "a", ")", "[", ":", ",", "-", "1", "]", ",", "self", ".", "critic2", "(", "states", ",", "a", ")", "[", ":", ",", "-", "1", "]", ")", ".", "mean", "(", ")", "\n", "if", "self", ".", "config", ".", "action_l2_regularization", ":", "\n", "        ", "actor_loss", "+=", "self", ".", "config", ".", "action_l2_regularization", "*", "F", ".", "mse_loss", "(", "a", "/", "self", ".", "action_scale", ",", "torch", ".", "zeros_like", "(", "a", ")", ")", "\n", "", "if", "self", ".", "config", ".", "get", "(", "'bc_loss'", ")", ":", "\n", "        ", "bc_loss", "=", "self", ".", "config", ".", "bc_loss", "*", "F", ".", "mse_loss", "(", "a", ",", "actions", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Optimize/bc_loss'", ",", "bc_loss", ")", "\n", "actor_loss", "+=", "bc_loss", "\n", "\n", "", "self", ".", "actor_opt", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "actor_params", ",", "self", ".", "config", ".", "grad_norm_clipping", ")", "\n", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "actor_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "        ", "p", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.SAC.optimize_from_batch": [[386, 438], ["continuous_off_policy.SAC.critic_opt.zero_grad", "critic_loss.backward", "continuous_off_policy.SAC.critic_opt.step", "continuous_off_policy.SAC.actor", "torch.min", "torch.min", "torch.min", "torch.min", "continuous_off_policy.SAC.actor_opt.zero_grad", "actor_loss.backward", "continuous_off_policy.SAC.actor_opt.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "continuous_off_policy.SAC.actor", "continuous_off_policy.SAC.critic_target", "continuous_off_policy.SAC.critic2_target", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "hasattr", "continuous_off_policy.SAC.logger.add_histogram", "continuous_off_policy.SAC.critic", "continuous_off_policy.SAC.critic2", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "continuous_off_policy.SAC.critic", "continuous_off_policy.SAC.critic2", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.mse_loss", "torch.mse_loss", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Target actions come from *current* policy", "\n", "      ", "a_next", ",", "logp_next", "=", "self", ".", "actor", "(", "next_states", ")", "\n", "q1", "=", "self", ".", "critic_target", "(", "next_states", ",", "a_next", ")", "\n", "q2", "=", "self", ".", "critic2_target", "(", "next_states", ",", "a_next", ")", "\n", "target", "=", "rewards", "+", "gammas", "*", "(", "torch", ".", "min", "(", "q1", ",", "q2", ")", "-", "config", ".", "entropy_coef", "*", "logp_next", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "1000", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Target_q'", ",", "target", ")", "\n", "\n", "", "q1", ",", "q2", "=", "self", ".", "critic", "(", "states", ",", "actions", ")", ",", "self", ".", "critic2", "(", "states", ",", "actions", ")", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "q1", ",", "target", ")", "+", "F", ".", "mse_loss", "(", "q2", ",", "target", ")", "\n", "\n", "self", ".", "critic_opt", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_norm_clipping", ")", "\n", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "critic_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "      ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "a", ",", "logp", "=", "self", ".", "actor", "(", "states", ")", "\n", "q", "=", "torch", ".", "min", "(", "self", ".", "critic", "(", "states", ",", "a", ")", ",", "self", ".", "critic2", "(", "states", ",", "a", ")", ")", "\n", "\n", "actor_loss", "=", "(", "config", ".", "entropy_coef", "*", "logp", "-", "q", ")", ".", "mean", "(", ")", "\n", "\n", "if", "self", ".", "config", ".", "action_l2_regularization", ":", "\n", "      ", "actor_loss", "+=", "self", ".", "config", ".", "action_l2_regularization", "*", "F", ".", "mse_loss", "(", "a", "/", "self", ".", "action_scale", ",", "torch", ".", "zeros_like", "(", "a", ")", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "actor_params", ",", "self", ".", "config", ".", "grad_norm_clipping", ")", "\n", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "actor_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "      ", "p", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.BCDDPG.optimize_from_batch": [[443, 473], ["continuous_off_policy.BCDDPG.critic", "torch.mse_loss", "torch.mse_loss", "continuous_off_policy.BCDDPG.critic_opt.zero_grad", "torch.mse_loss.backward", "continuous_off_policy.BCDDPG.critic_opt.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "continuous_off_policy.BCDDPG.actor", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "continuous_off_policy.BCDDPG.critic_target", "q_values.reshape.reshape.reshape", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "hasattr", "continuous_off_policy.BCDDPG.logger.add_histogram", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "continuous_off_policy.BCDDPG.reshape", "q_values.reshape.reshape.max", "p.grad.detach().mul_", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "p.grad.detach", "p.grad.detach"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "action_proposals", "=", "self", ".", "actor", "(", "next_states", ")", "# batch x num_proposals x action_dim", "\n", "_next_states", "=", "torch", ".", "repeat_interleave", "(", "next_states", ",", "action_proposals", ".", "shape", "[", "1", "]", ",", "0", ")", "\n", "q_values", "=", "self", ".", "critic_target", "(", "_next_states", ",", "action_proposals", ".", "reshape", "(", "-", "1", ",", "action_proposals", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "q_values", "=", "q_values", ".", "reshape", "(", "next_states", ".", "shape", "[", "0", "]", ",", "action_proposals", ".", "shape", "[", "1", "]", ")", "# batch x num_proposals", "\n", "q_next", "=", "q_values", ".", "max", "(", "-", "1", ",", "keepdims", "=", "True", ")", "[", "0", "]", "\n", "target", "=", "(", "rewards", "+", "gammas", "*", "q_next", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "1000", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Target_q'", ",", "target", ")", "\n", "\n", "", "q", "=", "self", ".", "critic", "(", "states", ",", "actions", ")", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "q", ",", "target", ")", "\n", "\n", "self", ".", "critic_opt", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "        ", "clip_coef", "=", "self", ".", "config", ".", "grad_norm_clipping", "/", "(", "1e-6", "+", "torch", ".", "norm", "(", "p", ".", "grad", ".", "detach", "(", ")", ")", ")", "\n", "if", "clip_coef", "<", "1", ":", "\n", "          ", "p", ".", "grad", ".", "detach", "(", ")", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "critic_opt", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.algorithms.continuous_off_policy.SimpleConservativeSAC.optimize_from_batch": [[476, 549], ["continuous_off_policy.SimpleConservativeSAC.critic", "continuous_off_policy.SimpleConservativeSAC.critic2", "continuous_off_policy.SimpleConservativeSAC.critic_opt.zero_grad", "critic_loss.backward", "continuous_off_policy.SimpleConservativeSAC.critic_opt.step", "continuous_off_policy.SimpleConservativeSAC.actor", "torch.min", "torch.min", "torch.min", "torch.min", "continuous_off_policy.SimpleConservativeSAC.actor_opt.zero_grad", "actor_loss.backward", "continuous_off_policy.SimpleConservativeSAC.actor_opt.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "continuous_off_policy.SimpleConservativeSAC.actor", "continuous_off_policy.SimpleConservativeSAC.critic_target", "continuous_off_policy.SimpleConservativeSAC.critic2_target", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "hasattr", "continuous_off_policy.SimpleConservativeSAC.logger.add_histogram", "continuous_off_policy.SimpleConservativeSAC.critic", "continuous_off_policy.SimpleConservativeSAC.critic2", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "hasattr", "continuous_off_policy.SimpleConservativeSAC.logger.add_scalar", "continuous_off_policy.SimpleConservativeSAC.logger.add_scalar", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "continuous_off_policy.SimpleConservativeSAC.critic", "continuous_off_policy.SimpleConservativeSAC.critic2", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "torch.l1_loss", "torch.l1_loss", "torch.l1_loss", "torch.l1_loss", "torch.mse_loss", "torch.mse_loss", "continuous_off_policy.SimpleConservativeSAC.mean", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.min", "torch.min", "torch.min", "torch.min", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar"], ["  ", "def", "optimize_from_batch", "(", "self", ",", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", ":", "\n", "    ", "config", "=", "self", ".", "config", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Target actions come from *current* policy", "\n", "      ", "a_next", ",", "logp_next", "=", "self", ".", "actor", "(", "next_states", ")", "\n", "q1", "=", "self", ".", "critic_target", "(", "next_states", ",", "a_next", ")", "\n", "q2", "=", "self", ".", "critic2_target", "(", "next_states", ",", "a_next", ")", "\n", "target", "=", "rewards", "+", "gammas", "*", "(", "torch", ".", "min", "(", "q1", ",", "q2", ")", "-", "config", ".", "entropy_coef", "*", "logp_next", ")", "\n", "target", "=", "torch", ".", "clamp", "(", "target", ",", "*", "self", ".", "config", ".", "clip_target_range", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "1000", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_histogram", "(", "'Optimize/Target_q'", ",", "target", ")", "\n", "\n", "", "q1", ",", "q2", "=", "self", ".", "critic", "(", "states", ",", "actions", ")", ",", "self", ".", "critic2", "(", "states", ",", "actions", ")", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "q1", ",", "target", ")", "+", "F", ".", "mse_loss", "(", "q2", ",", "target", ")", "\n", "\n", "# CQL Bit", "\n", "random_actions", "=", "(", "torch", ".", "rand", "(", "(", "len", "(", "states", ")", ",", "self", ".", "env", ".", "action_dim", ")", ")", "*", "2", "*", "self", ".", "env", ".", "max_action", "-", "self", ".", "env", ".", "max_action", ")", ".", "to", "(", "states", ".", "device", ")", "\n", "random_q", "=", "self", ".", "critic", "(", "states", ",", "random_actions", ")", "\n", "random_actions", "=", "(", "torch", ".", "rand", "(", "(", "len", "(", "states", ")", ",", "self", ".", "env", ".", "action_dim", ")", ")", "*", "2", "*", "self", ".", "env", ".", "max_action", "-", "self", ".", "env", ".", "max_action", ")", ".", "to", "(", "states", ".", "device", ")", "\n", "random_q", "+=", "self", ".", "critic2", "(", "states", ",", "random_actions", ")", "\n", "random_q", "/=", "2.", "\n", "\n", "#with torch.no_grad():", "\n", "#  a, logp = self.actor(states)", "\n", "#random_q = (self.critic(states, a) +  self.critic2(states, a)) / 2.", "\n", "\n", "min_q_loss", "=", "(", "F", ".", "l1_loss", "(", "random_q", ".", "mean", "(", ")", ",", "torch", ".", "tensor", "(", "self", ".", "config", ".", "clip_target_range", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "cuda", "(", ")", ")", "+", "F", ".", "l1_loss", "(", "(", "q1", "+", "q2", ")", ".", "mean", "(", ")", "/", "2.", ",", "torch", ".", "tensor", "(", "self", ".", "config", ".", "clip_target_range", "[", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "cuda", "(", ")", ")", ")", "*", "self", ".", "config", ".", "min_q_weight", "\n", "\n", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "config", ".", "opt_steps", "%", "100", "==", "0", ":", "\n", "      ", "self", ".", "logger", ".", "add_scalar", "(", "'Optimize/min_q_loss'", ",", "min_q_loss", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Optimize/basic_critic_loss'", ",", "critic_loss", ")", "\n", "\n", "", "critic_loss", "+=", "min_q_loss", "\n", "\n", "self", ".", "critic_opt", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_norm_clipping", ")", "\n", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "critic_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "critic_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "      ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "a", ",", "logp", "=", "self", ".", "actor", "(", "states", ")", "\n", "q", "=", "torch", ".", "min", "(", "self", ".", "critic", "(", "states", ",", "a", ")", ",", "self", ".", "critic2", "(", "states", ",", "a", ")", ")", "\n", "\n", "actor_loss", "=", "(", "config", ".", "entropy_coef", "*", "logp", "-", "q", ")", ".", "mean", "(", ")", "\n", "\n", "if", "self", ".", "config", ".", "action_l2_regularization", ":", "\n", "      ", "actor_loss", "+=", "self", ".", "config", ".", "action_l2_regularization", "*", "F", ".", "mse_loss", "(", "a", "/", "self", ".", "action_scale", ",", "torch", ".", "zeros_like", "(", "a", ")", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "\n", "# Grad clipping", "\n", "if", "self", ".", "config", ".", "grad_norm_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "actor_params", ",", "self", ".", "config", ".", "grad_norm_clipping", ")", "\n", "", "if", "self", ".", "config", ".", "grad_value_clipping", ">", "0.", ":", "\n", "      ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_value_", "(", "self", ".", "actor_params", ",", "self", ".", "config", ".", "grad_value_clipping", ")", "\n", "\n", "", "self", ".", "actor_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "critic_params", ":", "\n", "      ", "p", ".", "requires_grad", "=", "True", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.__init__": [[13, 31], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "\n", "self", ",", "\n", "module_name", "=", "'prioritized_replay'", ",", "\n", "rank_method", "=", "'dense'", ",", "\n", "temperature", "=", "1.0", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Buffer that stores entropy of trajectories for prioritized replay\n    \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "module_name", ",", "required_agent_modules", "=", "[", "'env'", ",", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "goal_space", "=", "None", "\n", "self", ".", "buffer", "=", "None", "\n", "self", ".", "rank_method", "=", "rank_method", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "traj_len", "=", "None", "\n", "self", ".", "has_fit_density", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer._setup": [[32, 51], ["mrl.utils.misc.AttrDict", "type", "mrl.replays.core.replay_buffer.RingBuffer", "range"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "ag_buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "\n", "env", "=", "self", ".", "env", "\n", "assert", "type", "(", "env", ".", "observation_space", ")", "==", "gym", ".", "spaces", ".", "Dict", "\n", "self", ".", "goal_space", "=", "env", ".", "observation_space", ".", "spaces", "[", "\"desired_goal\"", "]", "\n", "\n", "# Note: for now we apply entropy estimation on the achieved goal (ag) space", "\n", "# Define the buffers to store for prioritization", "\n", "items", "=", "[", "(", "\"entropy\"", ",", "(", "1", ",", ")", ")", ",", "(", "\"priority\"", ",", "(", "1", ",", ")", ")", "]", "\n", "self", ".", "buffer", "=", "AttrDict", "(", ")", "\n", "for", "name", ",", "shape", "in", "items", ":", "\n", "      ", "self", ".", "buffer", "[", "'buffer_'", "+", "name", "]", "=", "RingBuffer", "(", "self", ".", "ag_buffer", ".", "maxlen", ",", "shape", "=", "shape", ")", "\n", "\n", "", "self", ".", "_subbuffers", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", "\n", "self", ".", "n_envs", "=", "self", ".", "env", ".", "num_envs", "\n", "\n", "# Define the placeholder for mixture model to estimate trajectory", "\n", "self", ".", "clf", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.fit_density_model": [[52, 71], ["prioritized_replay.EntropyPrioritizedOnlineHERBuffer.ag_buffer.data[].copy", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.reshape", "sklearn.mixture.BayesianGaussianMixture", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.clf.fit", "numpy.repeat.min", "numpy.clip", "numpy.repeat.sum", "numpy.repeat", "numpy.repeat.reshape().copy", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.clf.score_samples", "numpy.repeat.reshape"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.fit", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples"], ["", "def", "fit_density_model", "(", "self", ")", ":", "\n", "    ", "if", "not", "self", ".", "has_fit_density", ":", "\n", "      ", "self", ".", "has_fit_density", "=", "True", "\n", "", "ag", "=", "self", ".", "ag_buffer", ".", "data", "[", "0", ":", "self", ".", "size", "]", ".", "copy", "(", ")", "\n", "X_train", "=", "ag", ".", "reshape", "(", "-", "1", ",", "self", ".", "traj_len", "*", "ag", ".", "shape", "[", "-", "1", "]", ")", "# [num_episodes, episode_len * goal_dim]", "\n", "\n", "self", ".", "clf", "=", "mixture", ".", "BayesianGaussianMixture", "(", "weight_concentration_prior_type", "=", "\"dirichlet_distribution\"", ",", "n_components", "=", "3", ")", "\n", "self", ".", "clf", ".", "fit", "(", "X_train", ")", "\n", "pred", "=", "-", "self", ".", "clf", ".", "score_samples", "(", "X_train", ")", "\n", "\n", "self", ".", "pred_min", "=", "pred", ".", "min", "(", ")", "\n", "pred", "=", "pred", "-", "self", ".", "pred_min", "\n", "pred", "=", "np", ".", "clip", "(", "pred", ",", "0", ",", "None", ")", "\n", "self", ".", "pred_sum", "=", "pred", ".", "sum", "(", ")", "\n", "pred", "=", "pred", "/", "self", ".", "pred_sum", "\n", "self", ".", "pred_avg", "=", "(", "1", "/", "pred", ".", "shape", "[", "0", "]", ")", "\n", "pred", "=", "np", ".", "repeat", "(", "pred", ",", "self", ".", "traj_len", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "buffer", ".", "buffer_entropy", ".", "data", "[", ":", "self", ".", "size", "]", "=", "pred", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer._process_experience": [[72, 113], ["range", "range", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer._subbuffers[].append", "len", "numpy.zeros", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.add_trajectory", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.update_priority", "isinstance", "ag.reshape", "numpy.clip", "numpy.zeros", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.clf.score_samples", "numpy.ones", "numpy.stack", "zip"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.add_trajectory", "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.update_priority", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples"], ["", "def", "_process_experience", "(", "self", ",", "exp", ")", ":", "\n", "# Compute the entropy ", "\n", "# TODO: Include previous achieved goal too? or use that instead of ag?", "\n", "    ", "achieved", "=", "exp", ".", "next_state", "[", "'achieved_goal'", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_envs", ")", ":", "\n", "      ", "self", ".", "_subbuffers", "[", "i", "]", ".", "append", "(", "[", "achieved", "[", "i", "]", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "n_envs", ")", ":", "\n", "      ", "if", "exp", ".", "trajectory_over", "[", "i", "]", ":", "\n", "# TODO: Compute the entropy of the trajectory", "\n", "        ", "traj_len", "=", "len", "(", "self", ".", "_subbuffers", "[", "i", "]", ")", "\n", "if", "self", ".", "traj_len", "is", "None", ":", "\n", "          ", "self", ".", "traj_len", "=", "traj_len", "\n", "", "else", ":", "\n", "# Current implementation assumes the same length for all trajectories", "\n", "          ", "assert", "(", "traj_len", "==", "self", ".", "traj_len", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "clf", ",", "int", ")", ":", "\n", "          ", "ag", "=", "[", "np", ".", "stack", "(", "a", ")", "for", "a", "in", "zip", "(", "*", "self", ".", "_subbuffers", "[", "i", "]", ")", "]", "[", "0", "]", "# [episode_len, goal_dim]", "\n", "X", "=", "ag", ".", "reshape", "(", "-", "1", ",", "ag", ".", "shape", "[", "0", "]", "*", "ag", ".", "shape", "[", "1", "]", ")", "\n", "pred", "=", "-", "self", ".", "clf", ".", "score_samples", "(", "X", ")", "\n", "\n", "pred", "=", "pred", "-", "self", ".", "pred_min", "\n", "pred", "=", "np", ".", "clip", "(", "pred", ",", "0", ",", "None", ")", "\n", "pred", "=", "pred", "/", "self", ".", "pred_sum", "# Shape (1,)", "\n", "\n", "entropy", "=", "np", ".", "ones", "(", "(", "traj_len", ",", "1", ")", ")", "*", "pred", "\n", "", "else", ":", "\n", "# Not enough data to train mixture density yet, set entropy to be zero", "\n", "          ", "entropy", "=", "np", ".", "zeros", "(", "(", "traj_len", ",", "1", ")", ")", "\n", "\n", "", "priority", "=", "np", ".", "zeros", "(", "(", "traj_len", ",", "1", ")", ")", "\n", "trajectory", "=", "[", "entropy", ",", "priority", "]", "\n", "\n", "# TODO: Update the trajectory with entropy", "\n", "self", ".", "add_trajectory", "(", "*", "trajectory", ")", "\n", "\n", "self", ".", "_subbuffers", "[", "i", "]", "=", "[", "]", "\n", "\n", "# TODO: Update the rank here before adding it to the trajectory?", "\n", "self", ".", "update_priority", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.add_trajectory": [[114, 123], ["zip", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.buffer.values", "buffer.append_batch"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch"], ["", "", "", "def", "add_trajectory", "(", "self", ",", "*", "items", ")", ":", "\n", "    ", "\"\"\"\n    Append a trajectory of transitions to the buffer.\n\n    :param items: a list of batched transition values to append to the replay buffer,\n        in the item order that we initialized the ReplayBuffer with.\n    \"\"\"", "\n", "for", "buffer", ",", "batched_values", "in", "zip", "(", "self", ".", "buffer", ".", "values", "(", ")", ",", "items", ")", ":", "\n", "      ", "buffer", ".", "append_batch", "(", "batched_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.update_priority": [[124, 134], ["scipy.stats.rankdata"], "methods", ["None"], ["", "", "def", "update_priority", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    After adding a trajectory to the replay buffer, update the ranking of transitions\n    \"\"\"", "\n", "# Note: 'dense' assigns the next highest element with the rank immediately ", "\n", "# after those assigned to the tied elements.", "\n", "entropy_transition_total", "=", "self", ".", "buffer", ".", "buffer_entropy", ".", "data", "[", ":", "self", ".", "size", "]", "\n", "entropy_rank", "=", "rankdata", "(", "entropy_transition_total", ",", "method", "=", "self", ".", "rank_method", ")", "\n", "entropy_rank", "=", "(", "entropy_rank", "-", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "self", ".", "buffer", ".", "buffer_priority", ".", "data", "[", ":", "self", ".", "size", "]", "=", "entropy_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.__call__": [[135, 169], ["numpy.power", "numpy.random.choice", "entropy_trajectory.reshape", "numpy.random.choice", "numpy.ones", "len", "numpy.power.sum", "numpy.power.sum"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"\n    Samples batch_size number of indices from main replay_buffer.\n\n    Args:\n      batch_size (int): size of the batch to sample\n    \n    Returns:\n      batch_idxs: a 1-D numpy array of length batch_size containing indices\n                  sampled in prioritized manner\n    \"\"\"", "\n", "if", "self", ".", "rank_method", "==", "'none'", ":", "\n", "      ", "entropy_trajectory", "=", "self", ".", "buffer", ".", "buffer_entropy", ".", "data", "[", ":", "self", ".", "size", "]", "\n", "", "else", ":", "\n", "      ", "entropy_trajectory", "=", "self", ".", "buffer", ".", "buffer_priority", ".", "data", "[", ":", "self", ".", "size", "]", "\n", "\n", "# Factorize out sampling into sampling trajectory according to priority/entropy", "\n", "# then sample time uniformly independently", "\n", "", "entropy_trajectory", "=", "entropy_trajectory", ".", "reshape", "(", "-", "1", ",", "self", ".", "traj_len", ")", "[", ":", ",", "0", "]", "\n", "p_trajectory", "=", "np", ".", "power", "(", "entropy_trajectory", ",", "1", "/", "(", "self", ".", "temperature", "+", "1e-2", ")", ")", "\n", "\n", "# If the density model hasn't been fitted yet, we have p_trajectory all 0's", "\n", "# And hence treat them as uniform:", "\n", "if", "not", "self", ".", "has_fit_density", ":", "\n", "      ", "p_trajectory", "=", "np", ".", "ones", "(", "p_trajectory", ".", "shape", ")", "/", "len", "(", "p_trajectory", ")", "\n", "", "else", ":", "\n", "      ", "assert", "(", "p_trajectory", ".", "sum", "(", ")", "!=", "0.0", ")", "\n", "p_trajectory", "=", "p_trajectory", "/", "p_trajectory", ".", "sum", "(", ")", "\n", "\n", "", "num_trajectories", "=", "p_trajectory", ".", "shape", "[", "0", "]", "\n", "batch_tidx", "=", "np", ".", "random", ".", "choice", "(", "num_trajectories", ",", "size", "=", "batch_size", ",", "p", "=", "p_trajectory", ")", "\n", "batch_idxs", "=", "self", ".", "traj_len", "*", "batch_tidx", "+", "np", ".", "random", ".", "choice", "(", "self", ".", "traj_len", ",", "size", "=", "batch_size", ")", "\n", "\n", "return", "batch_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.size": [[170, 173], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "ag_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.save": [[174, 179], ["prioritized_replay.EntropyPrioritizedOnlineHERBuffer.buffer._get_state", "open", "pickle.dump", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "if", "self", ".", "config", ".", "save_replay_buf", ":", "\n", "      ", "state", "=", "self", ".", "buffer", ".", "_get_state", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "state", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.load": [[180, 192], ["os.path.join", "os.path.exists", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.buffer._set_state", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.logger.log_color", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.logger.log_color", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.logger.log_color", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.logger.log_color", "prioritized_replay.EntropyPrioritizedOnlineHERBuffer.logger.log_color", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "load_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "      ", "with", "open", "(", "load_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "buffer", ".", "_set_state", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'cyan'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'yellow'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.OnlineHERBuffer.__init__": [[11, 27], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "\n", "self", ",", "\n", "module_name", "=", "'replay_buffer'", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Buffer that does online hindsight relabeling.\n    \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "module_name", ",", "required_agent_modules", "=", "[", "'env'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "size", "=", "None", "\n", "self", ".", "goal_shape", "=", "None", "\n", "self", ".", "buffer", "=", "None", "\n", "self", ".", "save_buffer", "=", "None", "# can be manually set to save this replay buffer irrespective of config", "\n", "self", ".", "modalities", "=", "[", "'observation'", "]", "\n", "self", ".", "goal_modalities", "=", "[", "'desired_goal'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.OnlineHERBuffer._setup": [[28, 61], ["mrl.replays.core.shared_buffer.SharedMemoryTrajectoryBuffer", "type", "online_her_buffer.parse_hindsight_mode", "online_her_buffer.parse_hindsight_mode", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.parse_hindsight_mode", "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.parse_hindsight_mode"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "size", "=", "self", ".", "config", ".", "replay_size", "\n", "\n", "env", "=", "self", ".", "env", "\n", "\n", "if", "type", "(", "env", ".", "observation_space", ")", "==", "gym", ".", "spaces", ".", "Dict", ":", "\n", "      ", "if", "env", ".", "goal_env", ":", "\n", "        ", "self", ".", "goal_modalities", "=", "[", "m", "for", "m", "in", "self", ".", "config", ".", "goal_modalities", "]", "\n", "self", ".", "goal_shape", "=", "(", "env", ".", "goal_dim", ",", ")", "\n", "", "state_shape", "=", "(", "env", ".", "state_dim", ",", ")", "\n", "self", ".", "modalities", "=", "[", "m", "for", "m", "in", "self", ".", "config", ".", "modalities", "]", "\n", "", "else", ":", "\n", "      ", "state_shape", "=", "env", ".", "observation_space", ".", "shape", "\n", "\n", "", "items", "=", "[", "(", "\"state\"", ",", "state_shape", ")", ",", "\n", "(", "\"action\"", ",", "env", ".", "action_space", ".", "shape", ")", ",", "(", "\"reward\"", ",", "(", "1", ",", ")", ")", ",", "\n", "(", "\"next_state\"", ",", "state_shape", ")", ",", "(", "\"done\"", ",", "(", "1", ",", ")", ")", "]", "\n", "\n", "if", "self", ".", "goal_shape", "is", "not", "None", ":", "\n", "      ", "items", "+=", "[", "(", "\"previous_ag\"", ",", "self", ".", "goal_shape", ")", ",", "# for reward shaping", "\n", "(", "\"ag\"", ",", "self", ".", "goal_shape", ")", ",", "# achieved goal", "\n", "(", "\"bg\"", ",", "self", ".", "goal_shape", ")", ",", "# behavioral goal (i.e., intrinsic if curious agent)", "\n", "(", "\"dg\"", ",", "self", ".", "goal_shape", ")", "]", "# desired goal (even if ignored behaviorally)", "\n", "\n", "", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "size", ",", "items", ")", "\n", "self", ".", "_subbuffers", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", "\n", "self", ".", "n_envs", "=", "self", ".", "env", ".", "num_envs", "\n", "\n", "# HER mode can differ if demo or normal replay buffer", "\n", "if", "'demo'", "in", "self", ".", "module_name", ":", "\n", "      ", "self", ".", "fut", ",", "self", ".", "act", ",", "self", ".", "ach", ",", "self", ".", "beh", "=", "parse_hindsight_mode", "(", "self", ".", "config", ".", "demo_her", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "fut", ",", "self", ".", "act", ",", "self", ".", "ach", ",", "self", ".", "beh", "=", "parse_hindsight_mode", "(", "self", ".", "config", ".", "her", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.OnlineHERBuffer._process_experience": [[62, 103], ["getattr", "numpy.expand_dims", "numpy.expand_dims", "range", "online_her_buffer.OnlineHERBuffer.logger.add_tabular", "mrl.utils.misc.flatten_state", "mrl.utils.misc.flatten_state", "hasattr", "mrl.utils.misc.flatten_state", "range", "range", "len", "online_her_buffer.OnlineHERBuffer.achieved_goal", "online_her_buffer.OnlineHERBuffer.achieved_goal", "hasattr", "online_her_buffer.OnlineHERBuffer.env.compute_reward().reshape", "online_her_buffer.OnlineHERBuffer._subbuffers[].append", "online_her_buffer.OnlineHERBuffer._subbuffers[].append", "online_her_buffer.OnlineHERBuffer.buffer.add_trajectory", "numpy.stack", "online_her_buffer.OnlineHERBuffer.env.compute_reward", "zip"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_tabular", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.flatten_state", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPushAndReach.achieved_goal", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPushAndReach.achieved_goal", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.add_trajectory", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "", "def", "_process_experience", "(", "self", ",", "exp", ")", ":", "\n", "    ", "if", "getattr", "(", "self", ",", "'logger'", ")", ":", "\n", "      ", "self", ".", "logger", ".", "add_tabular", "(", "'Replay buffer size'", ",", "len", "(", "self", ".", "buffer", ")", ")", "\n", "", "done", "=", "np", ".", "expand_dims", "(", "exp", ".", "done", ",", "1", ")", "# format for replay buffer", "\n", "reward", "=", "np", ".", "expand_dims", "(", "exp", ".", "reward", ",", "1", ")", "# format for replay buffer", "\n", "\n", "action", "=", "exp", ".", "action", "\n", "\n", "if", "self", ".", "goal_shape", ":", "\n", "      ", "state", "=", "flatten_state", "(", "exp", ".", "state", ",", "self", ".", "modalities", ")", "\n", "next_state", "=", "flatten_state", "(", "exp", ".", "next_state", ",", "self", ".", "modalities", ")", "\n", "if", "hasattr", "(", "self", ",", "'achieved_goal'", ")", ":", "\n", "        ", "previous_achieved", "=", "self", ".", "achieved_goal", "(", "exp", ".", "state", ")", "\n", "achieved", "=", "self", ".", "achieved_goal", "(", "exp", ".", "next_state", ")", "\n", "", "else", ":", "\n", "        ", "previous_achieved", "=", "exp", ".", "state", "[", "'achieved_goal'", "]", "\n", "achieved", "=", "exp", ".", "next_state", "[", "'achieved_goal'", "]", "\n", "", "desired", "=", "flatten_state", "(", "exp", ".", "state", ",", "self", ".", "goal_modalities", ")", "\n", "if", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", "and", "self", ".", "ag_curiosity", ".", "current_goals", "is", "not", "None", ":", "\n", "        ", "behavioral", "=", "self", ".", "ag_curiosity", ".", "current_goals", "\n", "# recompute online reward", "\n", "reward", "=", "self", ".", "env", ".", "compute_reward", "(", "achieved", ",", "behavioral", ",", "{", "'s'", ":", "state", ",", "'a'", ":", "action", ",", "'ns'", ":", "next_state", "}", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "behavioral", "=", "desired", "\n", "", "for", "i", "in", "range", "(", "self", ".", "n_envs", ")", ":", "\n", "        ", "self", ".", "_subbuffers", "[", "i", "]", ".", "append", "(", "[", "\n", "state", "[", "i", "]", ",", "action", "[", "i", "]", ",", "reward", "[", "i", "]", ",", "next_state", "[", "i", "]", ",", "done", "[", "i", "]", ",", "previous_achieved", "[", "i", "]", ",", "achieved", "[", "i", "]", ",", "\n", "behavioral", "[", "i", "]", ",", "desired", "[", "i", "]", "\n", "]", ")", "\n", "", "", "else", ":", "\n", "      ", "state", "=", "exp", ".", "state", "\n", "next_state", "=", "exp", ".", "next_state", "\n", "for", "i", "in", "range", "(", "self", ".", "n_envs", ")", ":", "\n", "        ", "self", ".", "_subbuffers", "[", "i", "]", ".", "append", "(", "\n", "[", "state", "[", "i", "]", ",", "action", "[", "i", "]", ",", "reward", "[", "i", "]", ",", "next_state", "[", "i", "]", ",", "done", "[", "i", "]", "]", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "self", ".", "n_envs", ")", ":", "\n", "      ", "if", "exp", ".", "trajectory_over", "[", "i", "]", ":", "\n", "        ", "trajectory", "=", "[", "np", ".", "stack", "(", "a", ")", "for", "a", "in", "zip", "(", "*", "self", ".", "_subbuffers", "[", "i", "]", ")", "]", "\n", "self", ".", "buffer", ".", "add_trajectory", "(", "*", "trajectory", ")", "\n", "self", ".", "_subbuffers", "[", "i", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.OnlineHERBuffer.sample": [[104, 212], ["hasattr", "hasattr", "online_her_buffer.OnlineHERBuffer.prioritized_replay", "numpy.random.randint", "online_her_buffer.OnlineHERBuffer.state_normalizer().astype", "online_her_buffer.OnlineHERBuffer.state_normalizer().astype", "online_her_buffer.OnlineHERBuffer.config.get", "online_her_buffer.OnlineHERBuffer.config.get", "numpy.array_split", "online_her_buffer.OnlineHERBuffer.buffer.sample", "online_her_buffer.OnlineHERBuffer.buffer.sample_future", "online_her_buffer.OnlineHERBuffer.buffer.sample_from_goal_buffer", "online_her_buffer.OnlineHERBuffer.buffer.sample_from_goal_buffer", "online_her_buffer.OnlineHERBuffer.buffer.sample_from_goal_buffer", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "hasattr", "online_her_buffer.OnlineHERBuffer.config.get", "online_her_buffer.OnlineHERBuffer.buffer.sample", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "online_her_buffer.OnlineHERBuffer.config.get", "online_her_buffer.OnlineHERBuffer.buffer.sample_n_step_transitions", "online_her_buffer.OnlineHERBuffer.buffer.sample", "online_her_buffer.OnlineHERBuffer.torch", "online_her_buffer.OnlineHERBuffer.torch", "online_her_buffer.OnlineHERBuffer.torch", "online_her_buffer.OnlineHERBuffer.torch", "online_her_buffer.OnlineHERBuffer.torch", "numpy.random.multinomial", "numpy.cumsum", "online_her_buffer.OnlineHERBuffer.goal_reward().reshape().astype", "online_her_buffer.OnlineHERBuffer.env.compute_reward().reshape().astype", "numpy.zeros_like", "online_her_buffer.OnlineHERBuffer.config.get", "numpy.concatenate", "online_her_buffer.OnlineHERBuffer.state_normalizer", "online_her_buffer.OnlineHERBuffer.state_normalizer", "numpy.round", "ValueError", "numpy.concatenate", "numpy.linalg.norm", "numpy.linalg.norm", "online_her_buffer.OnlineHERBuffer.goal_reward().reshape", "online_her_buffer.OnlineHERBuffer.env.compute_reward().reshape", "online_her_buffer.OnlineHERBuffer.goal_reward", "online_her_buffer.OnlineHERBuffer.env.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_future", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_from_goal_buffer", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_from_goal_buffer", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_from_goal_buffer", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_n_step_transitions", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "", "", "def", "sample", "(", "self", ",", "batch_size", ",", "to_torch", "=", "True", ")", ":", "\n", "    ", "if", "hasattr", "(", "self", ",", "'prioritized_replay'", ")", ":", "\n", "      ", "batch_idxs", "=", "self", ".", "prioritized_replay", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "      ", "batch_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "buffer", ".", "size", ",", "size", "=", "batch_size", ")", "\n", "\n", "", "if", "self", ".", "goal_shape", ":", "\n", "      ", "if", "\"demo\"", "in", "self", ".", "module_name", ":", "\n", "        ", "has_config_her", "=", "self", ".", "config", ".", "get", "(", "'demo_her'", ")", "\n", "", "else", ":", "\n", "        ", "has_config_her", "=", "self", ".", "config", ".", "get", "(", "'her'", ")", "\n", "\n", "", "if", "has_config_her", ":", "\n", "\n", "        ", "if", "self", ".", "config", ".", "env_steps", ">", "self", ".", "config", ".", "future_warm_up", ":", "\n", "          ", "fut_batch_size", ",", "act_batch_size", ",", "ach_batch_size", ",", "beh_batch_size", ",", "real_batch_size", "=", "np", ".", "random", ".", "multinomial", "(", "\n", "batch_size", ",", "[", "self", ".", "fut", ",", "self", ".", "act", ",", "self", ".", "ach", ",", "self", ".", "beh", ",", "1.", "]", ")", "\n", "", "else", ":", "\n", "          ", "fut_batch_size", ",", "act_batch_size", ",", "ach_batch_size", ",", "beh_batch_size", ",", "real_batch_size", "=", "batch_size", ",", "0", ",", "0", ",", "0", ",", "0", "\n", "\n", "", "fut_idxs", ",", "act_idxs", ",", "ach_idxs", ",", "beh_idxs", ",", "real_idxs", "=", "np", ".", "array_split", "(", "batch_idxs", ",", "\n", "np", ".", "cumsum", "(", "[", "fut_batch_size", ",", "act_batch_size", ",", "ach_batch_size", ",", "beh_batch_size", "]", ")", ")", "\n", "\n", "# Sample the real batch (i.e., goals = behavioral goals)", "\n", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", ",", "previous_ags", ",", "ags", ",", "goals", ",", "_", "=", "self", ".", "buffer", ".", "sample", "(", "real_batch_size", ",", "batch_idxs", "=", "real_idxs", ")", "\n", "\n", "# Sample the future batch", "\n", "states_fut", ",", "actions_fut", ",", "_", ",", "next_states_fut", ",", "dones_fut", ",", "previous_ags_fut", ",", "ags_fut", ",", "_", ",", "_", ",", "goals_fut", "=", "self", ".", "buffer", ".", "sample_future", "(", "fut_batch_size", ",", "batch_idxs", "=", "fut_idxs", ")", "\n", "\n", "# Sample the actual batch", "\n", "states_act", ",", "actions_act", ",", "_", ",", "next_states_act", ",", "dones_act", ",", "previous_ags_act", ",", "ags_act", ",", "_", ",", "_", ",", "goals_act", "=", "self", ".", "buffer", ".", "sample_from_goal_buffer", "(", "'dg'", ",", "act_batch_size", ",", "batch_idxs", "=", "act_idxs", ")", "\n", "\n", "# Sample the achieved batch", "\n", "states_ach", ",", "actions_ach", ",", "_", ",", "next_states_ach", ",", "dones_ach", ",", "previous_ags_ach", ",", "ags_ach", ",", "_", ",", "_", ",", "goals_ach", "=", "self", ".", "buffer", ".", "sample_from_goal_buffer", "(", "'ag'", ",", "ach_batch_size", ",", "batch_idxs", "=", "ach_idxs", ")", "\n", "\n", "# Sample the behavioral batch", "\n", "states_beh", ",", "actions_beh", ",", "_", ",", "next_states_beh", ",", "dones_beh", ",", "previous_ags_beh", ",", "ags_beh", ",", "_", ",", "_", ",", "goals_beh", "=", "self", ".", "buffer", ".", "sample_from_goal_buffer", "(", "'bg'", ",", "beh_batch_size", ",", "batch_idxs", "=", "beh_idxs", ")", "\n", "\n", "# Concatenate the five", "\n", "states", "=", "np", ".", "concatenate", "(", "[", "states", ",", "states_fut", ",", "states_act", ",", "states_ach", ",", "states_beh", "]", ",", "0", ")", "\n", "actions", "=", "np", ".", "concatenate", "(", "[", "actions", ",", "actions_fut", ",", "actions_act", ",", "actions_ach", ",", "actions_beh", "]", ",", "0", ")", "\n", "ags", "=", "np", ".", "concatenate", "(", "[", "ags", ",", "ags_fut", ",", "ags_act", ",", "ags_ach", ",", "ags_beh", "]", ",", "0", ")", "\n", "goals", "=", "np", ".", "concatenate", "(", "[", "goals", ",", "goals_fut", ",", "goals_act", ",", "goals_ach", ",", "goals_beh", "]", ",", "0", ")", "\n", "next_states", "=", "np", ".", "concatenate", "(", "[", "next_states", ",", "next_states_fut", ",", "next_states_act", ",", "next_states_ach", ",", "next_states_beh", "]", ",", "0", ")", "\n", "\n", "# Recompute reward online", "\n", "if", "hasattr", "(", "self", ",", "'goal_reward'", ")", ":", "\n", "          ", "rewards", "=", "self", ".", "goal_reward", "(", "ags", ",", "goals", ",", "{", "'s'", ":", "states", ",", "'a'", ":", "actions", ",", "'ns'", ":", "next_states", "}", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "          ", "rewards", "=", "self", ".", "env", ".", "compute_reward", "(", "ags", ",", "goals", ",", "{", "'s'", ":", "states", ",", "'a'", ":", "actions", ",", "'ns'", ":", "next_states", "}", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "get", "(", "'never_done'", ")", ":", "\n", "          ", "dones", "=", "np", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "elif", "self", ".", "config", ".", "get", "(", "'first_visit_succ'", ")", ":", "\n", "          ", "dones", "=", "np", ".", "round", "(", "rewards", "+", "1.", ")", "\n", "", "else", ":", "\n", "          ", "raise", "ValueError", "(", "\"Never done or first visit succ must be set in goal environments to use HER.\"", ")", "\n", "dones", "=", "np", ".", "concatenate", "(", "[", "dones", ",", "dones_fut", ",", "dones_act", ",", "dones_ach", ",", "dones_beh", "]", ",", "0", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "sparse_reward_shaping", ":", "\n", "          ", "previous_ags", "=", "np", ".", "concatenate", "(", "[", "previous_ags", ",", "previous_ags_fut", ",", "previous_ags_act", ",", "previous_ags_ach", ",", "previous_ags_beh", "]", ",", "0", ")", "\n", "previous_phi", "=", "-", "np", ".", "linalg", ".", "norm", "(", "previous_ags", "-", "goals", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "current_phi", "=", "-", "np", ".", "linalg", ".", "norm", "(", "ags", "-", "goals", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "rewards_F", "=", "self", ".", "config", ".", "gamma", "*", "current_phi", "-", "previous_phi", "\n", "rewards", "+=", "self", ".", "config", ".", "sparse_reward_shaping", "*", "rewards_F", "\n", "\n", "", "", "else", ":", "\n", "# Uses the original desired goals", "\n", "        ", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", ",", "_", ",", "_", ",", "_", ",", "goals", "=", "self", ".", "buffer", ".", "sample", "(", "batch_size", ",", "batch_idxs", "=", "batch_idxs", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "slot_based_state", ":", "\n", "# TODO: For now, we flatten according to config.slot_state_dims", "\n", "        ", "I", ",", "J", "=", "self", ".", "config", ".", "slot_state_dims", "\n", "states", "=", "np", ".", "concatenate", "(", "(", "states", "[", ":", ",", "I", ",", "J", "]", ",", "goals", ")", ",", "-", "1", ")", "\n", "next_states", "=", "np", ".", "concatenate", "(", "(", "next_states", "[", ":", ",", "I", ",", "J", "]", ",", "goals", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "states", "=", "np", ".", "concatenate", "(", "(", "states", ",", "goals", ")", ",", "-", "1", ")", "\n", "next_states", "=", "np", ".", "concatenate", "(", "(", "next_states", ",", "goals", ")", ",", "-", "1", ")", "\n", "", "gammas", "=", "self", ".", "config", ".", "gamma", "*", "(", "1.", "-", "dones", ")", "\n", "\n", "", "elif", "self", ".", "config", ".", "get", "(", "'n_step_returns'", ")", "and", "self", ".", "config", ".", "n_step_returns", ">", "1", ":", "\n", "      ", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", "=", "self", ".", "buffer", ".", "sample_n_step_transitions", "(", "\n", "batch_size", ",", "self", ".", "config", ".", "n_step_returns", ",", "self", ".", "config", ".", "gamma", ",", "batch_idxs", "=", "batch_idxs", "\n", ")", "\n", "gammas", "=", "self", ".", "config", ".", "gamma", "**", "self", ".", "config", ".", "n_step_returns", "*", "(", "1.", "-", "dones", ")", "\n", "\n", "", "else", ":", "\n", "      ", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", "=", "self", ".", "buffer", ".", "sample", "(", "\n", "batch_size", ",", "batch_idxs", "=", "batch_idxs", ")", "\n", "gammas", "=", "self", ".", "config", ".", "gamma", "*", "(", "1.", "-", "dones", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "states", "=", "self", ".", "state_normalizer", "(", "states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "next_states", "=", "self", ".", "state_normalizer", "(", "\n", "next_states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "to_torch", ":", "\n", "      ", "return", "(", "self", ".", "torch", "(", "states", ")", ",", "self", ".", "torch", "(", "actions", ")", ",", "\n", "self", ".", "torch", "(", "rewards", ")", ",", "self", ".", "torch", "(", "next_states", ")", ",", "\n", "self", ".", "torch", "(", "gammas", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.OnlineHERBuffer.__len__": [[213, 215], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.OnlineHERBuffer.save": [[216, 221], ["online_her_buffer.OnlineHERBuffer.buffer._get_state", "open", "pickle.dump", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "if", "self", ".", "config", ".", "save_replay_buf", "or", "self", ".", "save_buffer", ":", "\n", "      ", "state", "=", "self", ".", "buffer", ".", "_get_state", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "state", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.OnlineHERBuffer.load": [[222, 232], ["os.path.join", "os.path.exists", "online_her_buffer.OnlineHERBuffer.buffer._set_state", "online_her_buffer.OnlineHERBuffer.logger.log_color", "online_her_buffer.OnlineHERBuffer.logger.log_color", "online_her_buffer.OnlineHERBuffer.logger.log_color", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "load_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "      ", "with", "open", "(", "load_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "buffer", ".", "_set_state", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'cyan'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'yellow'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.online_her_buffer.parse_hindsight_mode": [[233, 275], ["hindsight_mode.split", "float", "hindsight_mode.split", "float", "float", "float", "hindsight_mode.split", "float", "float", "float", "hindsight_mode.split", "float", "float", "float", "float", "float", "float", "hindsight_mode.split", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float"], "function", ["None"], ["", "", "", "def", "parse_hindsight_mode", "(", "hindsight_mode", ":", "str", ")", ":", "\n", "  ", "if", "'future_'", "in", "hindsight_mode", ":", "\n", "    ", "_", ",", "fut", "=", "hindsight_mode", ".", "split", "(", "'_'", ")", "\n", "fut", "=", "float", "(", "fut", ")", "/", "(", "1.", "+", "float", "(", "fut", ")", ")", "\n", "act", "=", "0.", "\n", "ach", "=", "0.", "\n", "beh", "=", "0.", "\n", "", "elif", "'futureactual_'", "in", "hindsight_mode", ":", "\n", "    ", "_", ",", "fut", ",", "act", "=", "hindsight_mode", ".", "split", "(", "'_'", ")", "\n", "non_hindsight_frac", "=", "1.", "/", "(", "1.", "+", "float", "(", "fut", ")", "+", "float", "(", "act", ")", ")", "\n", "fut", "=", "float", "(", "fut", ")", "*", "non_hindsight_frac", "\n", "act", "=", "float", "(", "act", ")", "*", "non_hindsight_frac", "\n", "ach", "=", "0.", "\n", "beh", "=", "0.", "\n", "", "elif", "'futureachieved_'", "in", "hindsight_mode", ":", "\n", "    ", "_", ",", "fut", ",", "ach", "=", "hindsight_mode", ".", "split", "(", "'_'", ")", "\n", "non_hindsight_frac", "=", "1.", "/", "(", "1.", "+", "float", "(", "fut", ")", "+", "float", "(", "ach", ")", ")", "\n", "fut", "=", "float", "(", "fut", ")", "*", "non_hindsight_frac", "\n", "act", "=", "0.", "\n", "ach", "=", "float", "(", "ach", ")", "*", "non_hindsight_frac", "\n", "beh", "=", "0.", "\n", "", "elif", "'rfaa_'", "in", "hindsight_mode", ":", "\n", "    ", "_", ",", "real", ",", "fut", ",", "act", ",", "ach", "=", "hindsight_mode", ".", "split", "(", "'_'", ")", "\n", "denom", "=", "(", "float", "(", "real", ")", "+", "float", "(", "fut", ")", "+", "float", "(", "act", ")", "+", "float", "(", "ach", ")", ")", "\n", "fut", "=", "float", "(", "fut", ")", "/", "denom", "\n", "act", "=", "float", "(", "act", ")", "/", "denom", "\n", "ach", "=", "float", "(", "ach", ")", "/", "denom", "\n", "beh", "=", "0.", "\n", "", "elif", "'rfaab_'", "in", "hindsight_mode", ":", "\n", "    ", "_", ",", "real", ",", "fut", ",", "act", ",", "ach", ",", "beh", "=", "hindsight_mode", ".", "split", "(", "'_'", ")", "\n", "denom", "=", "(", "float", "(", "real", ")", "+", "float", "(", "fut", ")", "+", "float", "(", "act", ")", "+", "float", "(", "ach", ")", "+", "float", "(", "beh", ")", ")", "\n", "fut", "=", "float", "(", "fut", ")", "/", "denom", "\n", "act", "=", "float", "(", "act", ")", "/", "denom", "\n", "ach", "=", "float", "(", "ach", ")", "/", "denom", "\n", "beh", "=", "float", "(", "beh", ")", "/", "denom", "\n", "", "else", ":", "\n", "    ", "fut", "=", "0.", "\n", "act", "=", "0.", "\n", "ach", "=", "0.", "\n", "beh", "=", "0.", "\n", "\n", "", "return", "fut", ",", "act", ",", "ach", ",", "beh", "\n", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.replays.old_replay_buffer.OldReplayBuffer.__init__": [[18, 30], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    A standard replay buffer (no prioritization / fancy stuff). \n    \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "'replay_buffer'", ",", "required_agent_modules", "=", "[", "'env'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "size", "=", "None", "\n", "self", ".", "goal_space", "=", "None", "\n", "self", ".", "hindsight_buffer", "=", "None", "\n", "self", ".", "buffer", "=", "None", "\n", "self", ".", "save_buffer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.old_replay_buffer.OldReplayBuffer._setup": [[31, 47], ["mrl.replays.core.replay_buffer.ReplayBuffer", "type", "NotImplementedError"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "size", "=", "self", ".", "config", ".", "replay_size", "\n", "\n", "env", "=", "self", ".", "env", "\n", "if", "type", "(", "env", ".", "observation_space", ")", "==", "gym", ".", "spaces", ".", "Dict", ":", "\n", "      ", "observation_space", "=", "env", ".", "observation_space", ".", "spaces", "[", "\"observation\"", "]", "\n", "self", ".", "goal_space", "=", "env", ".", "observation_space", ".", "spaces", "[", "\"desired_goal\"", "]", "\n", "raise", "NotImplementedError", "(", "\"This buffer no longer supports goal spaces; use OnlineHERBuffer\"", ")", "\n", "", "else", ":", "\n", "      ", "observation_space", "=", "env", ".", "observation_space", "\n", "\n", "", "items", "=", "[", "(", "\"state\"", ",", "observation_space", ".", "shape", ")", ",", "\n", "(", "\"action\"", ",", "env", ".", "action_space", ".", "shape", ")", ",", "(", "\"reward\"", ",", "(", "1", ",", ")", ")", ",", "\n", "(", "\"next_state\"", ",", "observation_space", ".", "shape", ")", ",", "(", "\"done\"", ",", "(", "1", ",", ")", ")", "]", "\n", "\n", "self", ".", "buffer", "=", "Buffer", "(", "self", ".", "size", ",", "items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.old_replay_buffer.OldReplayBuffer._process_experience": [[48, 58], ["getattr", "numpy.expand_dims", "numpy.expand_dims", "old_replay_buffer.OldReplayBuffer.buffer.add_batch", "old_replay_buffer.OldReplayBuffer.logger.add_tabular", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_tabular"], ["", "def", "_process_experience", "(", "self", ",", "experience", ")", ":", "\n", "    ", "if", "getattr", "(", "self", ",", "'logger'", ")", ":", "\n", "      ", "self", ".", "logger", ".", "add_tabular", "(", "'Replay buffer size'", ",", "len", "(", "self", ".", "buffer", ")", ")", "\n", "", "done", "=", "np", ".", "expand_dims", "(", "experience", ".", "done", ",", "1", ")", "# format for replay buffer", "\n", "reward", "=", "np", ".", "expand_dims", "(", "experience", ".", "reward", ",", "1", ")", "# format for replay buffer", "\n", "action", "=", "experience", ".", "action", "\n", "\n", "state", "=", "experience", ".", "state", "\n", "next_state", "=", "experience", ".", "next_state", "\n", "self", ".", "buffer", ".", "add_batch", "(", "state", ",", "action", ",", "reward", ",", "next_state", ",", "done", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.old_replay_buffer.OldReplayBuffer.sample": [[59, 73], ["old_replay_buffer.OldReplayBuffer.buffer.sample", "hasattr", "old_replay_buffer.OldReplayBuffer.state_normalizer().astype", "old_replay_buffer.OldReplayBuffer.state_normalizer().astype", "old_replay_buffer.OldReplayBuffer.torch", "old_replay_buffer.OldReplayBuffer.torch", "old_replay_buffer.OldReplayBuffer.torch", "old_replay_buffer.OldReplayBuffer.torch", "old_replay_buffer.OldReplayBuffer.torch", "old_replay_buffer.OldReplayBuffer.state_normalizer", "old_replay_buffer.OldReplayBuffer.state_normalizer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch"], ["", "def", "sample", "(", "self", ",", "batch_size", ",", "to_torch", "=", "True", ")", ":", "\n", "    ", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "dones", "=", "self", ".", "buffer", ".", "sample", "(", "batch_size", ")", "\n", "gammas", "=", "self", ".", "config", ".", "gamma", "*", "(", "1", "-", "dones", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "states", "=", "self", ".", "state_normalizer", "(", "states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "next_states", "=", "self", ".", "state_normalizer", "(", "next_states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "to_torch", ":", "\n", "      ", "return", "(", "self", ".", "torch", "(", "states", ")", ",", "self", ".", "torch", "(", "actions", ")", ",", "\n", "self", ".", "torch", "(", "rewards", ")", ",", "self", ".", "torch", "(", "next_states", ")", ",", "\n", "self", ".", "torch", "(", "gammas", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "states", ",", "actions", ",", "rewards", ",", "next_states", ",", "gammas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.old_replay_buffer.OldReplayBuffer.__len__": [[74, 76], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.old_replay_buffer.OldReplayBuffer.save": [[77, 82], ["old_replay_buffer.OldReplayBuffer.buffer._get_state", "open", "pickle.dump", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "if", "self", ".", "config", ".", "save_replay_buf", "or", "self", ".", "save_buffer", ":", "\n", "      ", "state", "=", "self", ".", "buffer", ".", "_get_state", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "state", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.replays.old_replay_buffer.OldReplayBuffer.load": [[83, 95], ["os.path.join", "os.path.exists", "old_replay_buffer.OldReplayBuffer.buffer._set_state", "old_replay_buffer.OldReplayBuffer.logger.log_color", "old_replay_buffer.OldReplayBuffer.logger.log_color", "old_replay_buffer.OldReplayBuffer.logger.log_color", "old_replay_buffer.OldReplayBuffer.logger.log_color", "old_replay_buffer.OldReplayBuffer.logger.log_color", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "load_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "\"{}.pickle\"", ".", "format", "(", "self", ".", "module_name", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "      ", "with", "open", "(", "load_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "state", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "buffer", ".", "_set_state", "(", "state", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'cyan'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'red'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'WARNING'", ",", "'Replay buffer is not being loaded / was not saved.'", ",", "color", "=", "'yellow'", ")", "\n", "self", ".", "logger", ".", "log_color", "(", "'###############################################################'", ",", "''", ",", "color", "=", "'red'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.__init__": [[9, 27], ["multiprocessing.RawValue", "multiprocessing.RawValue", "numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "maxlen", ",", "shape", ",", "dtype", "=", "np", ".", "float32", ",", "data", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    A buffer object, when full restarts at the initial position\n\n    :param maxlen: (int) the max number of numpy objects to store\n    :param shape: (tuple) the shape of the numpy objects you want to store\n    :param dtype: (str) the name of the type of the numpy object you want to store\n    \"\"\"", "\n", "self", ".", "maxlen", "=", "maxlen", "\n", "self", ".", "start", "=", "RawValue", "(", "'L'", ")", "\n", "self", ".", "length", "=", "RawValue", "(", "'L'", ")", "\n", "self", ".", "shape", "=", "shape", "\n", "if", "data", "is", "None", ":", "\n", "      ", "self", ".", "data", "=", "np", ".", "zeros", "(", "(", "maxlen", ",", ")", "+", "shape", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "      ", "assert", "data", ".", "shape", "==", "(", "maxlen", ",", ")", "+", "shape", "\n", "assert", "data", ".", "dtype", "==", "dtype", "\n", "self", ".", "data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer._get_state": [[28, 33], ["range", "replay_buffer.RingBuffer.data.take"], "methods", ["None"], ["", "", "def", "_get_state", "(", "self", ")", ":", "\n", "# Only restore the values in the data", "\n", "    ", "end_idx", "=", "self", ".", "start", ".", "value", "+", "self", ".", "length", ".", "value", "\n", "indices", "=", "range", "(", "self", ".", "start", ".", "value", ",", "end_idx", ")", "\n", "return", "self", ".", "start", ".", "value", ",", "self", ".", "length", ".", "value", ",", "self", ".", "data", ".", "take", "(", "indices", ",", "axis", "=", "0", ",", "mode", "=", "'wrap'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer._set_state": [[34, 39], ["numpy.roll"], "methods", ["None"], ["", "def", "_set_state", "(", "self", ",", "start", ",", "length", ",", "data", ")", ":", "\n", "    ", "self", ".", "start", ".", "value", "=", "start", "\n", "self", ".", "length", ".", "value", "=", "length", "\n", "self", ".", "data", "[", ":", "length", "]", "=", "data", "\n", "self", ".", "data", "=", "np", ".", "roll", "(", "self", ".", "data", ",", "start", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.__len__": [[40, 42], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "length", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.__getitem__": [[43, 47], ["KeyError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "    ", "if", "idx", "<", "0", "or", "idx", ">=", "self", ".", "length", ".", "value", ":", "\n", "      ", "raise", "KeyError", "(", ")", "\n", "", "return", "self", ".", "data", "[", "(", "self", ".", "start", ".", "value", "+", "idx", ")", "%", "self", ".", "maxlen", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch": [[48, 56], ["None"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "idxs", ")", ":", "\n", "    ", "\"\"\"\n    get the value at the indexes\n\n    :param idxs: (int or numpy int) the indexes\n    :return: (np.ndarray) the stored information in the buffer at the asked positions\n    \"\"\"", "\n", "return", "self", ".", "data", "[", "(", "self", ".", "start", ".", "value", "+", "idxs", ")", "%", "self", ".", "length", ".", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append": [[57, 74], ["RuntimeError"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "var", ")", ":", "\n", "    ", "\"\"\"\n    Append an object to the buffer\n\n    :param var: (np.ndarray) the object you wish to add\n    \"\"\"", "\n", "if", "self", ".", "length", ".", "value", "<", "self", ".", "maxlen", ":", "\n", "# We have space, simply increase the length.", "\n", "      ", "self", ".", "length", ".", "value", "+=", "1", "\n", "", "elif", "self", ".", "length", ".", "value", "==", "self", ".", "maxlen", ":", "\n", "# No space, \"remove\" the first item.", "\n", "      ", "self", ".", "start", ".", "value", "=", "(", "self", ".", "start", ".", "value", "+", "1", ")", "%", "self", ".", "maxlen", "\n", "", "else", ":", "\n", "# This should never happen.", "\n", "      ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "self", ".", "data", "[", "(", "self", ".", "start", ".", "value", "+", "self", ".", "length", ".", "value", "-", "1", ")", "%", "self", ".", "maxlen", "]", "=", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer._append_batch_with_space": [[75, 93], ["len", "numpy.arange"], "methods", ["None"], ["", "def", "_append_batch_with_space", "(", "self", ",", "var", ")", ":", "\n", "    ", "\"\"\"\n    Append a batch of objects to the buffer, *assuming* there is space.\n\n    :param var: (np.ndarray) the batched objects you wish to add\n    \"\"\"", "\n", "len_batch", "=", "len", "(", "var", ")", "\n", "start_pos", "=", "(", "self", ".", "start", ".", "value", "+", "self", ".", "length", ".", "value", ")", "%", "self", ".", "maxlen", "\n", "\n", "self", ".", "data", "[", "start_pos", ":", "start_pos", "+", "len_batch", "]", "=", "var", "\n", "\n", "if", "self", ".", "length", ".", "value", "<", "self", ".", "maxlen", ":", "\n", "      ", "self", ".", "length", ".", "value", "+=", "len_batch", "\n", "assert", "self", ".", "length", ".", "value", "<=", "self", ".", "maxlen", ",", "\"this should never happen!\"", "\n", "", "else", ":", "\n", "      ", "self", ".", "start", ".", "value", "=", "(", "self", ".", "start", ".", "value", "+", "len_batch", ")", "%", "self", ".", "maxlen", "\n", "\n", "", "return", "np", ".", "arange", "(", "start_pos", ",", "start_pos", "+", "len_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch": [[94, 115], ["len", "replay_buffer.RingBuffer._append_batch_with_space", "numpy.split", "replay_buffer.RingBuffer._append_batch_with_space", "replay_buffer.RingBuffer._append_batch_with_space", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer._append_batch_with_space", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer._append_batch_with_space", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer._append_batch_with_space"], ["", "def", "append_batch", "(", "self", ",", "var", ")", ":", "\n", "    ", "\"\"\"\n    Append a batch of objects to the buffer.\n\n    :param var: (np.ndarray) the batched objects you wish to add\n    \"\"\"", "\n", "len_batch", "=", "len", "(", "var", ")", "\n", "assert", "len_batch", "<", "self", ".", "maxlen", ",", "'trying to add a batch that is too big!'", "\n", "start_pos", "=", "(", "self", ".", "start", ".", "value", "+", "self", ".", "length", ".", "value", ")", "%", "self", ".", "maxlen", "\n", "\n", "if", "start_pos", "+", "len_batch", "<=", "self", ".", "maxlen", ":", "\n", "# If there is space, add it", "\n", "      ", "idxs", "=", "self", ".", "_append_batch_with_space", "(", "var", ")", "\n", "", "else", ":", "\n", "# No space, so break it into two batches for which there is space", "\n", "      ", "first_batch", ",", "second_batch", "=", "np", ".", "split", "(", "var", ",", "[", "self", ".", "maxlen", "-", "start_pos", "]", ")", "\n", "idxs1", "=", "self", ".", "_append_batch_with_space", "(", "first_batch", ")", "\n", "# use append on second call in case len_batch > self.maxlen", "\n", "idxs2", "=", "self", ".", "_append_batch_with_space", "(", "second_batch", ")", "\n", "idxs", "=", "np", ".", "concatenate", "(", "(", "idxs1", ",", "idxs2", ")", ")", "\n", "", "return", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.__init__": [[117, 140], ["collections.OrderedDict", "zip", "zip", "replay_buffer.RingBuffer", "len"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "limit", ",", "item_shape", ",", "dtypes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    The replay buffer object\n\n    :param limit: (int) the max number of transitions to store\n    :param item_shape: a list of tuples of (str) item name and (tuple) the shape for item\n      Ex: [(\"observations0\", env.observation_space.shape),\\\n          (\"actions\",env.action_space.shape),\\\n          (\"rewards\", (1,)),\\\n          (\"observations1\",env.observation_space.shape ),\\\n          (\"terminals1\", (1,))]\n    :param dtypes: list of dtype tuples; useful for storing things as float16.\n    \"\"\"", "\n", "self", ".", "limit", "=", "limit", "\n", "\n", "self", ".", "items", "=", "OrderedDict", "(", ")", "\n", "if", "dtypes", "is", "None", ":", "\n", "      ", "dtypes", "=", "[", "(", "np", ".", "float32", ",", "np", ".", "float32", ")", "]", "*", "len", "(", "item_shape", ")", "\n", "\n", "", "self", ".", "in_types", ",", "self", ".", "out_types", "=", "zip", "(", "*", "dtypes", ")", "\n", "\n", "for", "(", "name", ",", "shape", ")", ",", "dtype", "in", "zip", "(", "item_shape", ",", "self", ".", "in_types", ")", ":", "\n", "      ", "self", ".", "items", "[", "name", "]", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "shape", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.sample": [[141, 159], ["numpy.random.randint", "zip", "replay_buffer.ReplayBuffer.items.values", "buf.get_batch().astype", "transition.append", "buf.get_batch"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch"], ["", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"\n    sample a random batch from the buffer\n\n    :param batch_size: (int) the number of element to sample for the batch\n    :return: (list) the sampled batch\n    \"\"\"", "\n", "if", "self", ".", "size", "==", "0", ":", "\n", "      ", "return", "[", "]", "\n", "\n", "", "batch_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "size", ",", "size", "=", "batch_size", ")", "\n", "\n", "transition", "=", "[", "]", "\n", "for", "buf", ",", "dtype", "in", "zip", "(", "self", ".", "items", ".", "values", "(", ")", ",", "self", ".", "out_types", ")", ":", "\n", "      ", "item", "=", "buf", ".", "get_batch", "(", "batch_idxs", ")", ".", "astype", "(", "dtype", ")", "\n", "transition", ".", "append", "(", "item", ")", "\n", "\n", "", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add": [[160, 169], ["zip", "replay_buffer.ReplayBuffer.items.values", "buf.append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "add", "(", "self", ",", "*", "items", ")", ":", "\n", "    ", "\"\"\"\n    Appends a single transition to the buffer\n\n    :param items: a list of values for the transition to append to the replay buffer,\n        in the item order that we initialized the ReplayBuffer with.\n    \"\"\"", "\n", "for", "buf", ",", "value", "in", "zip", "(", "self", ".", "items", ".", "values", "(", ")", ",", "items", ")", ":", "\n", "      ", "buf", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add_batch": [[170, 185], ["zip", "replay_buffer.ReplayBuffer.add", "replay_buffer.ReplayBuffer.items.values", "buf.append_batch", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch"], ["", "", "def", "add_batch", "(", "self", ",", "*", "items", ")", ":", "\n", "    ", "\"\"\"\n    Append a batch of transitions to the buffer.\n\n    :param items: a list of batched transition values to append to the replay buffer,\n        in the item order that we initialized the ReplayBuffer with.\n    \"\"\"", "\n", "if", "(", "items", "[", "0", "]", ".", "shape", ")", "==", "1", "or", "len", "(", "items", "[", "0", "]", ")", "==", "1", ":", "\n", "      ", "self", ".", "add", "(", "*", "items", ")", "\n", "return", "\n", "\n", "", "for", "buf", ",", "batched_values", "in", "zip", "(", "self", ".", "items", ".", "values", "(", ")", ",", "items", ")", ":", "\n", "      ", "idxs", "=", "buf", ".", "append_batch", "(", "batched_values", ")", "\n", "\n", "", "return", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.__len__": [[186, 188], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer._get_state": [[189, 194], ["dict", "replay_buffer.ReplayBuffer.items.items", "buf._get_state"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "def", "_get_state", "(", "self", ")", ":", "\n", "    ", "d", "=", "dict", "(", ")", "\n", "for", "item", ",", "buf", "in", "self", ".", "items", ".", "items", "(", ")", ":", "\n", "      ", "d", "[", "item", "]", "=", "buf", ".", "_get_state", "(", ")", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer._set_state": [[195, 198], ["replay_buffer.ReplayBuffer.items.items", "buf._set_state"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state"], ["", "def", "_set_state", "(", "self", ",", "d", ")", ":", "\n", "    ", "for", "item", ",", "buf", "in", "self", ".", "items", ".", "items", "(", ")", ":", "\n", "      ", "buf", ".", "_set_state", "(", "*", "d", "[", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.size": [[199, 203], ["len", "next", "iter", "replay_buffer.ReplayBuffer.items.values"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "# Get the size of the RingBuffer on the first item type", "\n", "    ", "return", "len", "(", "next", "(", "iter", "(", "self", ".", "items", ".", "values", "(", ")", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.__init__": [[169, 218], ["mrl.utils.misc.AttrDict", "multiprocessing.RawArray", "numpy.frombuffer", "mrl.replays.core.replay_buffer.RingBuffer", "multiprocessing.RawArray", "numpy.frombuffer", "mrl.replays.core.replay_buffer.RingBuffer", "collections.OrderedDict", "mrl.utils.misc.AttrDict.items.append", "multiprocessing.RawArray", "numpy.frombuffer().reshape", "mrl.replays.core.replay_buffer.RingBuffer", "multiprocessing.RawArray", "numpy.frombuffer", "mrl.replays.core.replay_buffer.RingBuffer", "multiprocessing.Pool", "int", "numpy.prod", "numpy.frombuffer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["def", "__init__", "(", "self", ",", "limit", ",", "item_shape", ",", "n_cpu", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    The replay buffer object. Stores everything in float32.\n\n    :param limit: (int) the max number of transitions to store\n    :param item_shape: a list of tuples of (str) item name and (tuple) the shape for item\n      Ex: [(\"observations\", env.observation_space.shape),\\\n          (\"actions\",env.action_space.shape),\\\n          (\"rewards\", (1,)),\\\n          (\"dones\", (1,))]\n    \"\"\"", "\n", "self", ".", "limit", "=", "limit", "\n", "\n", "global", "BUFF", "\n", "BUFF", "=", "AttrDict", "(", ")", "\n", "self", ".", "BUFF", "=", "BUFF", "# a global object that has shared RawArray-based RingBuffers.", "\n", "\n", "BUFF", ".", "items", "=", "[", "]", "\n", "\n", "# item buffers", "\n", "for", "name", ",", "shape", "in", "item_shape", ":", "\n", "      ", "BUFF", ".", "items", ".", "append", "(", "'buffer_'", "+", "name", ")", "\n", "BUFF", "[", "'raw_'", "+", "name", "]", "=", "RawArray", "(", "'f'", ",", "int", "(", "np", ".", "prod", "(", "(", "limit", ",", ")", "+", "shape", ")", ")", ")", "\n", "BUFF", "[", "'np_'", "+", "name", "]", "=", "np", ".", "frombuffer", "(", "BUFF", "[", "'raw_'", "+", "name", "]", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "limit", ",", ")", "+", "shape", ")", "\n", "BUFF", "[", "'buffer_'", "+", "name", "]", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "shape", ",", "data", "=", "BUFF", "[", "'np_'", "+", "name", "]", ")", "\n", "\n", "# special buffers", "\n", "", "BUFF", ".", "raw_tidx", "=", "RawArray", "(", "'d'", ",", "limit", ")", "\n", "BUFF", ".", "np_tidx", "=", "np", ".", "frombuffer", "(", "BUFF", ".", "raw_tidx", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "BUFF", ".", "buffer_tidx", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "(", ")", ",", "dtype", "=", "np", ".", "int64", ",", "data", "=", "BUFF", ".", "np_tidx", ")", "\n", "\n", "BUFF", ".", "raw_tleft", "=", "RawArray", "(", "'d'", ",", "limit", ")", "\n", "BUFF", ".", "np_tleft", "=", "np", ".", "frombuffer", "(", "BUFF", ".", "raw_tleft", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "BUFF", ".", "buffer_tleft", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "(", ")", ",", "dtype", "=", "np", ".", "int64", ",", "data", "=", "BUFF", ".", "np_tleft", ")", "\n", "\n", "if", "'buffer_bg'", "in", "BUFF", ":", "# is this a successful trajectory?", "\n", "      ", "BUFF", ".", "raw_success", "=", "RawArray", "(", "'f'", ",", "limit", ")", "\n", "BUFF", ".", "np_success", "=", "np", ".", "frombuffer", "(", "BUFF", ".", "raw_success", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "BUFF", ".", "buffer_success", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "(", ")", ",", "dtype", "=", "np", ".", "float32", ",", "data", "=", "BUFF", ".", "np_success", ")", "\n", "\n", "", "self", ".", "trajectories", "=", "OrderedDict", "(", ")", "# a centralized dict of trajectory_id --> trajectory_idxs", "\n", "self", ".", "total_trajectory_len", "=", "0", "\n", "self", ".", "current_trajectory", "=", "0", "\n", "\n", "self", ".", "pool", "=", "None", "\n", "self", ".", "n_cpu", "=", "n_cpu", "\n", "if", "n_cpu", ">", "1", ":", "\n", "      ", "self", ".", "pool", "=", "mp", ".", "Pool", "(", "n_cpu", ",", "initializer", "=", "worker_init", ",", "initargs", "=", "(", "BUFF", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.add_trajectory": [[219, 253], ["len", "zip", "shared_buffer.SharedMemoryTrajectoryBuffer.BUFF.buffer_tleft.append_batch", "shared_buffer.SharedMemoryTrajectoryBuffer.BUFF.buffer_tidx.append_batch", "shared_buffer.SharedMemoryTrajectoryBuffer.BUFF[].append_batch", "zip", "shared_buffer.SharedMemoryTrajectoryBuffer.trajectories.popitem", "len", "numpy.arange", "numpy.ones", "numpy.any", "numpy.isclose", "shared_buffer.SharedMemoryTrajectoryBuffer.BUFF.buffer_success.append_batch", "shared_buffer.SharedMemoryTrajectoryBuffer.BUFF.buffer_success.append_batch", "numpy.ones", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append_batch"], ["", "", "def", "add_trajectory", "(", "self", ",", "*", "items", ")", ":", "\n", "    ", "\"\"\"\n    Append a trajectory of transitions to the buffer.\n\n    :param items: a list of batched transition values to append to the replay buffer,\n        in the item order that we initialized the ReplayBuffer with.\n    \"\"\"", "\n", "trajectory_len", "=", "len", "(", "items", "[", "0", "]", ")", "\n", "\n", "for", "buffer_name", ",", "batched_values", "in", "zip", "(", "self", ".", "BUFF", ".", "items", ",", "items", ")", ":", "\n", "      ", "self", ".", "BUFF", "[", "buffer_name", "]", ".", "append_batch", "(", "batched_values", ")", "\n", "\n", "# add to special buffers", "\n", "", "self", ".", "BUFF", ".", "buffer_tleft", ".", "append_batch", "(", "np", ".", "arange", "(", "trajectory_len", ",", "dtype", "=", "np", ".", "int64", ")", "[", ":", ":", "-", "1", "]", ")", "\n", "idxs", "=", "self", ".", "BUFF", ".", "buffer_tidx", ".", "append_batch", "(", "np", ".", "ones", "(", "(", "trajectory_len", ",", ")", ",", "dtype", "=", "np", ".", "int64", ")", "*", "self", ".", "current_trajectory", ")", "\n", "\n", "# Keep track of successes, if has behavioral goals.", "\n", "if", "'buffer_bg'", "in", "BUFF", ":", "\n", "      ", "for", "buffer_name", ",", "batched_values", "in", "zip", "(", "self", ".", "BUFF", ".", "items", ",", "items", ")", ":", "\n", "        ", "if", "buffer_name", "==", "'buffer_reward'", ":", "\n", "          ", "success", "=", "np", ".", "any", "(", "np", ".", "isclose", "(", "batched_values", ",", "0.", ")", ")", "\n", "if", "success", ":", "\n", "            ", "self", ".", "BUFF", ".", "buffer_success", ".", "append_batch", "(", "np", ".", "ones", "(", "(", "trajectory_len", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "BUFF", ".", "buffer_success", ".", "append_batch", "(", "np", ".", "zeros", "(", "(", "trajectory_len", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "", "", "", "", "self", ".", "trajectories", "[", "self", ".", "current_trajectory", "]", "=", "idxs", "\n", "self", ".", "total_trajectory_len", "+=", "trajectory_len", "\n", "\n", "# remove trajectories until all remaining trajectories fit in the buffer.", "\n", "while", "self", ".", "total_trajectory_len", ">", "self", ".", "limit", ":", "\n", "      ", "_", ",", "idxs", "=", "self", ".", "trajectories", ".", "popitem", "(", "last", "=", "False", ")", "\n", "self", ".", "total_trajectory_len", "-=", "len", "(", "idxs", ")", "\n", "", "self", ".", "current_trajectory", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_trajectories": [[254, 275], ["numpy.cumsum", "numpy.concatenate", "list", "max", "numpy.random.randint", "numpy.random.randint", "transition.append", "zip", "len", "numpy.split", "len", "len", "len", "BUFF[].get_batch"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch"], ["", "def", "sample_trajectories", "(", "self", ",", "n", ",", "group_by_buffer", "=", "False", ",", "from_m_most_recent", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Samples n full trajectories (optionally from 'from_m_most_recent' trajectories)\n    \"\"\"", "\n", "\n", "if", "from_m_most_recent", "is", "not", "None", "and", "(", "len", "(", "self", ".", "trajectories", ")", "-", "n", ">=", "0", ")", ":", "\n", "      ", "min_idx", "=", "max", "(", "self", ".", "current_trajectory", "-", "len", "(", "self", ".", "trajectories", ")", ",", "self", ".", "current_trajectory", "-", "from_m_most_recent", ")", "\n", "idxs", "=", "np", ".", "random", ".", "randint", "(", "min_idx", ",", "self", ".", "current_trajectory", ",", "n", ")", "\n", "", "else", ":", "\n", "      ", "idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "current_trajectory", "-", "len", "(", "self", ".", "trajectories", ")", ",", "self", ".", "current_trajectory", ",", "n", ")", "\n", "", "queries", "=", "[", "self", ".", "trajectories", "[", "i", "]", "for", "i", "in", "idxs", "]", "\n", "splits", "=", "np", ".", "cumsum", "(", "[", "len", "(", "q", ")", "for", "q", "in", "queries", "[", ":", "-", "1", "]", "]", ")", "\n", "query", "=", "np", ".", "concatenate", "(", "queries", ")", "\n", "transition", "=", "[", "]", "\n", "for", "buf", "in", "BUFF", ".", "items", ":", "\n", "      ", "transition", ".", "append", "(", "np", ".", "split", "(", "BUFF", "[", "buf", "]", ".", "get_batch", "(", "query", ")", ",", "splits", ")", ")", "\n", "\n", "", "if", "group_by_buffer", ":", "\n", "      ", "return", "transition", "\n", "\n", "", "return", "list", "(", "zip", "(", "*", "transition", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample": [[276, 295], ["numpy.random.randint", "BUFF[].get_batch", "transition.append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "sample", "(", "self", ",", "batch_size", ",", "batch_idxs", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    sample a random batch from the buffer\n\n    :param batch_size: (int) the number of element to sample for the batch\n    :return: (list) the sampled batch\n    \"\"\"", "\n", "if", "self", ".", "size", "==", "0", ":", "\n", "      ", "return", "[", "]", "\n", "\n", "", "if", "batch_idxs", "is", "None", ":", "\n", "      ", "batch_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "size", ",", "size", "=", "batch_size", ")", "\n", "\n", "", "transition", "=", "[", "]", "\n", "for", "buf", "in", "BUFF", ".", "items", ":", "\n", "      ", "item", "=", "BUFF", "[", "buf", "]", ".", "get_batch", "(", "batch_idxs", ")", "\n", "transition", ".", "append", "(", "item", ")", "\n", "\n", "", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_slices": [[296, 318], ["numpy.random.randint", "BUFF.buffer_tidx.get_batch", "BUFF.buffer_tidx.get_batch", "range", "transitions.append", "int", "BUFF[].get_batch", "transitions[].append", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "sample_slices", "(", "self", ",", "batch_size", ",", "slice_size", ")", ":", "\n", "    ", "\"\"\"Tries to sample slices of length slice_size randomly. Slices must be\n    from same trajectory, which may not happen even when oversampled, so it's possible\n    (but unlikely, at least for small slice_size) to get a small batch size than requested.\n    \"\"\"", "\n", "if", "self", ".", "size", "==", "0", ":", "\n", "      ", "return", "[", "[", "]", "for", "_", "in", "range", "(", "slice_size", ")", "]", "\n", "\n", "", "b_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "size", ",", "size", "=", "int", "(", "batch_size", "*", "1.5", ")", ")", "\n", "first_t", "=", "BUFF", ".", "buffer_tidx", ".", "get_batch", "(", "b_idxs", "-", "slice_size", "+", "1", ")", "\n", "last_t", "=", "BUFF", ".", "buffer_tidx", ".", "get_batch", "(", "b_idxs", ")", "\n", "\n", "batch_idxs", "=", "b_idxs", "[", "first_t", "==", "last_t", "]", "[", ":", "batch_size", "]", "\n", "\n", "transitions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "-", "slice_size", "+", "1", ",", "1", ")", ":", "\n", "      ", "transitions", ".", "append", "(", "[", "]", ")", "\n", "for", "buf", "in", "BUFF", ".", "items", ":", "\n", "        ", "item", "=", "BUFF", "[", "buf", "]", ".", "get_batch", "(", "batch_idxs", "+", "i", ")", "\n", "transitions", "[", "-", "1", "]", ".", "append", "(", "item", ")", "\n", "\n", "", "", "return", "transitions", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_n_step_transitions": [[319, 329], ["shared_buffer.n_step_samples", "numpy.random.randint", "shared_buffer.SharedMemoryTrajectoryBuffer.pool.map", "zip", "numpy.concatenate", "numpy.array_split", "zip"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.n_step_samples"], ["", "def", "sample_n_step_transitions", "(", "self", ",", "batch_size", ",", "n_steps", ",", "gamma", ",", "batch_idxs", "=", "None", ")", ":", "\n", "    ", "if", "batch_idxs", "is", "None", ":", "\n", "      ", "batch_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "size", ",", "size", "=", "batch_size", ")", "\n", "\n", "", "if", "self", ".", "pool", "is", "not", "None", ":", "\n", "      ", "res", "=", "self", ".", "pool", ".", "map", "(", "n_step_samples", ",", "zip", "(", "np", ".", "array_split", "(", "batch_idxs", ",", "self", ".", "n_cpu", ")", ",", "[", "n_steps", "]", "*", "self", ".", "n_cpu", ",", "[", "gamma", "]", "*", "self", ".", "n_cpu", ")", ")", "\n", "res", "=", "[", "np", ".", "concatenate", "(", "x", ",", "0", ")", "for", "x", "in", "zip", "(", "*", "res", ")", "]", "\n", "return", "res", "\n", "\n", "", "return", "n_step_samples", "(", "(", "batch_idxs", ",", "n_steps", ",", "gamma", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_future": [[330, 340], ["shared_buffer.future_samples", "numpy.random.randint", "shared_buffer.SharedMemoryTrajectoryBuffer.pool.map", "numpy.array_split", "numpy.concatenate", "zip"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.future_samples"], ["", "def", "sample_future", "(", "self", ",", "batch_size", ",", "batch_idxs", "=", "None", ")", ":", "\n", "    ", "if", "batch_idxs", "is", "None", ":", "\n", "      ", "batch_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "size", ",", "size", "=", "batch_size", ")", "\n", "\n", "", "if", "self", ".", "pool", "is", "not", "None", ":", "\n", "      ", "res", "=", "self", ".", "pool", ".", "map", "(", "future_samples", ",", "np", ".", "array_split", "(", "batch_idxs", ",", "self", ".", "n_cpu", ")", ")", "\n", "res", "=", "[", "np", ".", "concatenate", "(", "x", ",", "0", ")", "for", "x", "in", "zip", "(", "*", "res", ")", "]", "\n", "return", "res", "\n", "\n", "", "return", "future_samples", "(", "batch_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_from_goal_buffer": [[341, 361], ["sample_fn", "numpy.random.randint", "shared_buffer.SharedMemoryTrajectoryBuffer.pool.map", "numpy.array_split", "numpy.concatenate", "zip"], "methods", ["None"], ["", "def", "sample_from_goal_buffer", "(", "self", ",", "buffer", ",", "batch_size", ",", "batch_idxs", "=", "None", ")", ":", "\n", "    ", "\"\"\"buffer is one of 'ag', 'dg', 'bg'\"\"\"", "\n", "if", "buffer", "==", "'ag'", ":", "\n", "      ", "sample_fn", "=", "achieved_samples", "\n", "", "elif", "buffer", "==", "'dg'", ":", "\n", "      ", "sample_fn", "=", "actual_samples", "\n", "", "elif", "buffer", "==", "'bg'", ":", "\n", "      ", "sample_fn", "=", "behavioral_samples", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "\n", "\n", "", "if", "batch_idxs", "is", "None", ":", "\n", "      ", "batch_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "size", ",", "size", "=", "batch_size", ")", "\n", "\n", "", "if", "self", ".", "pool", "is", "not", "None", ":", "\n", "      ", "res", "=", "self", ".", "pool", ".", "map", "(", "sample_fn", ",", "np", ".", "array_split", "(", "batch_idxs", ",", "self", ".", "n_cpu", ")", ")", "\n", "res", "=", "[", "np", ".", "concatenate", "(", "x", ",", "0", ")", "for", "x", "in", "zip", "(", "*", "res", ")", "]", "\n", "return", "res", "\n", "\n", "", "return", "sample_fn", "(", "batch_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.__len__": [[362, 363], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._get_state": [[364, 374], ["dict", "shared_buffer.SharedMemoryTrajectoryBuffer.BUFF[]._get_state"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["def", "_get_state", "(", "self", ")", ":", "\n", "    ", "d", "=", "dict", "(", "\n", "trajectories", "=", "self", ".", "trajectories", ",", "\n", "total_trajectory_len", "=", "self", ".", "total_trajectory_len", ",", "\n", "current_trajectory", "=", "self", ".", "current_trajectory", "\n", ")", "\n", "for", "bufname", "in", "self", ".", "BUFF", ".", "items", "+", "[", "'buffer_tleft'", ",", "'buffer_tidx'", ",", "'buffer_success'", "]", ":", "\n", "      ", "if", "bufname", "in", "self", ".", "BUFF", ":", "\n", "        ", "d", "[", "bufname", "]", "=", "self", ".", "BUFF", "[", "bufname", "]", ".", "_get_state", "(", ")", "\n", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state": [[375, 381], ["shared_buffer.SharedMemoryTrajectoryBuffer.BUFF[]._set_state"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer._set_state"], ["", "def", "_set_state", "(", "self", ",", "d", ")", ":", "\n", "    ", "for", "k", "in", "[", "'trajectories'", ",", "'total_trajectory_len'", ",", "'current_trajectory'", "]", ":", "\n", "      ", "self", ".", "__dict__", "[", "k", "]", "=", "d", "[", "k", "]", "\n", "", "for", "bufname", "in", "self", ".", "BUFF", ".", "items", "+", "[", "'buffer_tleft'", ",", "'buffer_tidx'", ",", "'buffer_success'", "]", ":", "\n", "      ", "if", "bufname", "in", "self", ".", "BUFF", ":", "\n", "        ", "self", ".", "BUFF", "[", "bufname", "]", ".", "_set_state", "(", "*", "d", "[", "bufname", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close": [[382, 385], ["shared_buffer.SharedMemoryTrajectoryBuffer.pool.close"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.close"], ["", "", "", "def", "close", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "pool", "is", "not", "None", ":", "\n", "      ", "self", ".", "pool", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.size": [[386, 389], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "BUFF", ".", "buffer_tidx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.num_trajectories": [[390, 393], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_trajectories", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "trajectories", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.worker_init": [[11, 14], ["None"], "function", ["None"], ["def", "worker_init", "(", "buffer", ":", "AttrDict", ")", ":", "\n", "  ", "global", "BUFF", "\n", "BUFF", "=", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.future_samples": [[15, 33], ["numpy.random.default_rng", "BUFF.buffer_tleft.get_batch", "BUFF.buffer_ag.get_batch", "transition.append", "BUFF[].get_batch", "transition.append", "numpy.random.default_rng.uniform", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "future_samples", "(", "idxs", ")", ":", "\n", "  ", "\"\"\"Assumes there is an 'ag' field, and samples n transitions, pairing each with a future ag\n  from its trajectory.\"\"\"", "\n", "global", "BUFF", "\n", "rng", "=", "default_rng", "(", ")", "\n", "\n", "# get original transitions", "\n", "transition", "=", "[", "]", "\n", "for", "buf", "in", "BUFF", ".", "items", ":", "\n", "    ", "item", "=", "BUFF", "[", "buf", "]", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "item", ")", "\n", "\n", "# add random future goals", "\n", "", "tlefts", "=", "BUFF", ".", "buffer_tleft", ".", "get_batch", "(", "idxs", ")", "\n", "idxs", "=", "idxs", "+", "(", "rng", ".", "uniform", "(", "size", "=", "len", "(", "idxs", ")", ")", "*", "tlefts", ")", ".", "round", "(", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "ags", "=", "BUFF", ".", "buffer_ag", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "ags", ")", "\n", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.actual_samples": [[35, 51], ["numpy.random.choice", "BUFF.buffer_dg.get_batch", "transition.append", "BUFF[].get_batch", "transition.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "actual_samples", "(", "idxs", ")", ":", "\n", "  ", "\"\"\"Assumes there is an 'dg' field, and samples n transitions, pairing each with a random dg\"\"\"", "\n", "global", "BUFF", "\n", "\n", "# get original transitions", "\n", "transition", "=", "[", "]", "\n", "for", "buf", "in", "BUFF", ".", "items", ":", "\n", "    ", "item", "=", "BUFF", "[", "buf", "]", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "item", ")", "\n", "\n", "# add random actual goals", "\n", "", "idxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "BUFF", ".", "buffer_tidx", ")", ",", "len", "(", "idxs", ")", ")", "\n", "dgs", "=", "BUFF", ".", "buffer_dg", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "dgs", ")", "\n", "\n", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.achieved_samples": [[53, 69], ["numpy.random.choice", "BUFF.buffer_ag.get_batch", "transition.append", "BUFF[].get_batch", "transition.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "achieved_samples", "(", "idxs", ")", ":", "\n", "  ", "\"\"\"Assumes there is an 'ag' field, and samples n transitions, pairing each with a random ag\"\"\"", "\n", "global", "BUFF", "\n", "\n", "# get original transitions", "\n", "transition", "=", "[", "]", "\n", "for", "buf", "in", "BUFF", ".", "items", ":", "\n", "    ", "item", "=", "BUFF", "[", "buf", "]", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "item", ")", "\n", "\n", "# add random achieved goals", "\n", "", "idxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "BUFF", ".", "buffer_tidx", ")", ",", "len", "(", "idxs", ")", ")", "\n", "ags", "=", "BUFF", ".", "buffer_ag", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "ags", ")", "\n", "\n", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.behavioral_samples": [[71, 87], ["numpy.random.choice", "BUFF.buffer_bg.get_batch", "transition.append", "BUFF[].get_batch", "transition.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "behavioral_samples", "(", "idxs", ")", ":", "\n", "  ", "\"\"\"Assumes there is an 'bg' field, and samples n transitions, pairing each with a random bg\"\"\"", "\n", "global", "BUFF", "\n", "\n", "# get original transitions", "\n", "transition", "=", "[", "]", "\n", "for", "buf", "in", "BUFF", ".", "items", ":", "\n", "    ", "item", "=", "BUFF", "[", "buf", "]", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "item", ")", "\n", "\n", "# add random achieved goals", "\n", "", "idxs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "BUFF", ".", "buffer_tidx", ")", ",", "len", "(", "idxs", ")", ")", "\n", "bgs", "=", "BUFF", ".", "buffer_bg", ".", "get_batch", "(", "idxs", ")", "\n", "transition", ".", "append", "(", "bgs", ")", "\n", "\n", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.n_step_samples": [[89, 129], ["BUFF.buffer_tleft.get_batch", "numpy.concatenate", "BUFF.buffer_tidx.get_batch", "numpy.zeros_like().reshape", "range", "transition.append", "transition.append", "BUFF.buffer_done.get_batch", "diff_traj.astype().reshape", "transition.append", "BUFF.buffer_state.get_batch", "BUFF.buffer_action.get_batch", "BUFF.buffer_next_state.get_batch", "numpy.isclose().reshape", "numpy.zeros_like", "BUFF.buffer_reward.get_batch", "BUFF.buffer_tidx.get_batch", "diff_traj.astype", "numpy.isclose", "BUFF.buffer_done.get_batch"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch"], ["", "def", "n_step_samples", "(", "args", ")", ":", "\n", "  ", "\"\"\"Samples s_t and s_{t+n}, along with the discounted reward in between.\n  Assumes buffers include: state, action, reward, next_state, done\n  Because some sampled states will not have enough future states, this will\n  sometimes return less than num_samples samples.\n  \"\"\"", "\n", "state_idxs", ",", "n_steps", ",", "gamma", "=", "args", "\n", "\n", "global", "BUFF", "\n", "\n", "tlefts", "=", "BUFF", ".", "buffer_tleft", ".", "get_batch", "(", "state_idxs", ")", "\n", "\n", "# prune idxs for which there are not enough future transitions", "\n", "good_state_idxs", "=", "state_idxs", "[", "tlefts", ">=", "n_steps", "-", "1", "]", "\n", "potentially_bad_idxs", "=", "state_idxs", "[", "tlefts", "<", "n_steps", "-", "1", "]", "# 0 tleft corresp to 1 step", "\n", "potentially_bad_delt", "=", "tlefts", "[", "tlefts", "<", "n_steps", "-", "1", "]", "\n", "also_good_state_idxs", "=", "potentially_bad_idxs", "[", "np", ".", "isclose", "(", "BUFF", ".", "buffer_done", ".", "get_batch", "(", "potentially_bad_idxs", "+", "potentially_bad_delt", ")", ",", "1", ")", ".", "reshape", "(", "-", "1", ")", "]", "\n", "\n", "state_idxs", "=", "np", ".", "concatenate", "(", "(", "good_state_idxs", ",", "also_good_state_idxs", ")", ",", "axis", "=", "0", ")", "\n", "t_idxs", "=", "BUFF", ".", "buffer_tidx", ".", "get_batch", "(", "state_idxs", ")", "\n", "\n", "# start building the transition, of state, action, n_step reward, n_step next_state, done", "\n", "transition", "=", "[", "BUFF", ".", "buffer_state", ".", "get_batch", "(", "state_idxs", ")", ",", "BUFF", ".", "buffer_action", ".", "get_batch", "(", "state_idxs", ")", "]", "\n", "rewards", "=", "np", ".", "zeros_like", "(", "state_idxs", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_steps", ")", ":", "\n", "    ", "query", "=", "state_idxs", "+", "i", "\n", "r_delta", "=", "(", "gamma", "**", "i", ")", "*", "BUFF", ".", "buffer_reward", ".", "get_batch", "(", "query", ")", "\n", "diff_traj", "=", "t_idxs", "!=", "BUFF", ".", "buffer_tidx", ".", "get_batch", "(", "query", ")", "\n", "r_delta", "[", "diff_traj", "]", "*=", "0.", "\n", "rewards", "+=", "r_delta", "\n", "\n", "", "transition", ".", "append", "(", "rewards", ")", "\n", "transition", ".", "append", "(", "BUFF", ".", "buffer_next_state", ".", "get_batch", "(", "query", ")", ")", "# n_step state", "\n", "\n", "dones", "=", "BUFF", ".", "buffer_done", ".", "get_batch", "(", "query", ")", "\n", "dones", "+=", "diff_traj", ".", "astype", "(", "np", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "transition", ".", "append", "(", "dones", ")", "\n", "\n", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawKernelDensity.__init__": [[21, 40], ["mrl.Module.__init__", "sklearn.neighbors.KernelDensity", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "item", ",", "optimize_every", "=", "10", ",", "samples", "=", "10000", ",", "kernel", "=", "'gaussian'", ",", "bandwidth", "=", "0.1", ",", "normalize", "=", "True", ",", "\n", "log_entropy", "=", "False", ",", "tag", "=", "''", ",", "buffer_name", "=", "'replay_buffer'", ")", ":", "\n", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'{}_kde{}'", ".", "format", "(", "item", ",", "tag", ")", ",", "required_agent_modules", "=", "[", "buffer_name", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "item", "=", "item", "\n", "self", ".", "kde", "=", "KernelDensity", "(", "kernel", "=", "kernel", ",", "bandwidth", "=", "bandwidth", ")", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "samples", "=", "samples", "\n", "self", ".", "kernel", "=", "kernel", "\n", "self", ".", "bandwidth", "=", "bandwidth", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "kde_sample_mean", "=", "0.", "\n", "self", ".", "kde_sample_std", "=", "1.", "\n", "self", ".", "fitted_kde", "=", "None", "\n", "self", ".", "ready", "=", "False", "\n", "self", ".", "log_entropy", "=", "log_entropy", "\n", "self", ".", "buffer_name", "=", "buffer_name", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawKernelDensity._setup": [[41, 43], ["isinstance", "getattr"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "isinstance", "(", "getattr", "(", "self", ",", "self", ".", "buffer_name", ")", ",", "OnlineHERBuffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawKernelDensity._optimize": [[44, 67], ["numpy.random.randint", "buffer.get_batch", "density.RawKernelDensity.kde.fit", "len", "len", "numpy.mean", "hasattr", "density.RawKernelDensity.fitted_kde.sample", "density.RawKernelDensity.logger.add_scalar", "getattr", "numpy.std", "numpy.log().sum", "density.RawKernelDensity.fitted_kde.score", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.fit", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar"], ["", "def", "_optimize", "(", "self", ",", "force", "=", "False", ")", ":", "\n", "    ", "buffer", "=", "getattr", "(", "self", ",", "self", ".", "buffer_name", ")", ".", "buffer", ".", "BUFF", "[", "'buffer_'", "+", "self", ".", "item", "]", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "force", "or", "(", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "buffer", ")", ")", ":", "\n", "      ", "self", ".", "ready", "=", "True", "\n", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "buffer", ")", ",", "size", "=", "self", ".", "samples", ")", "\n", "kde_samples", "=", "buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "        ", "self", ".", "kde_sample_mean", "=", "np", ".", "mean", "(", "kde_samples", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "self", ".", "kde_sample_std", "=", "np", ".", "std", "(", "kde_samples", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "+", "1e-4", "\n", "kde_samples", "=", "(", "kde_samples", "-", "self", ".", "kde_sample_mean", ")", "/", "self", ".", "kde_sample_std", "\n", "\n", "", "self", ".", "fitted_kde", "=", "self", ".", "kde", ".", "fit", "(", "kde_samples", ")", "\n", "\n", "# Now also log the entropy", "\n", "if", "self", ".", "log_entropy", "and", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "step", "%", "250", "==", "0", ":", "\n", "# Scoring samples is a bit expensive, so just use 500 points", "\n", "        ", "num_samples", "=", "500", "\n", "s", "=", "self", ".", "fitted_kde", ".", "sample", "(", "num_samples", ")", "\n", "entropy", "=", "-", "self", ".", "fitted_kde", ".", "score", "(", "s", ")", "/", "num_samples", "+", "np", ".", "log", "(", "self", ".", "kde_sample_std", ")", ".", "sum", "(", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Explore/{}_entropy'", ".", "format", "(", "self", ".", "module_name", ")", ",", "entropy", ",", "log_every", "=", "500", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawKernelDensity.evaluate_log_density": [[68, 71], ["density.RawKernelDensity.fitted_kde.score_samples"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples"], ["", "", "", "def", "evaluate_log_density", "(", "self", ",", "samples", ")", ":", "\n", "    ", "assert", "self", ".", "ready", ",", "\"ENSURE READY BEFORE EVALUATING LOG DENSITY\"", "\n", "return", "self", ".", "fitted_kde", ".", "score_samples", "(", "(", "samples", "-", "self", ".", "kde_sample_mean", ")", "/", "self", ".", "kde_sample_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawKernelDensity.evaluate_elementwise_entropy": [[72, 89], ["density.RawKernelDensity.fitted_kde.score_samples", "numpy.exp", "scipy.special.entr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples"], ["", "def", "evaluate_elementwise_entropy", "(", "self", ",", "samples", ",", "beta", "=", "0.", ")", ":", "\n", "    ", "\"\"\" Given an array of samples, compute elementwise function of entropy of the form:\n\n        elem_entropy = - (p(samples) + beta)*log(p(samples) + beta)\n\n    Args:\n      samples: 1-D array of size N\n      beta: float, offset entropy calculation\n\n    Returns:\n      elem_entropy: 1-D array of size N, elementwise entropy with beta offset\n    \"\"\"", "\n", "assert", "self", ".", "ready", ",", "\"ENSURE READY BEFORE EVALUATING ELEMENT-WISE ENTROPY\"", "\n", "log_px", "=", "self", ".", "fitted_kde", ".", "score_samples", "(", "(", "samples", "-", "self", ".", "kde_sample_mean", ")", "/", "self", ".", "kde_sample_std", ")", "\n", "px", "=", "np", ".", "exp", "(", "log_px", ")", "\n", "elem_entropy", "=", "entr", "(", "px", "+", "beta", ")", "\n", "return", "elem_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawKernelDensity.save": [[90, 92], ["density.RawKernelDensity._save_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_save_props", "(", "[", "'kde'", ",", "'kde_sample_mean'", ",", "'kde_sample_std'", ",", "'fitted_kde'", ",", "'ready'", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawKernelDensity.load": [[93, 95], ["density.RawKernelDensity._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "'kde'", ",", "'kde_sample_mean'", ",", "'kde_sample_std'", ",", "'fitted_kde'", ",", "'ready'", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity.__init__": [[104, 120], ["mrl.Module.__init__", "sklearn.neighbors.KernelDensity", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "items", ",", "optimize_every", "=", "10", ",", "samples", "=", "10000", ",", "kernel", "=", "'gaussian'", ",", "bandwidth", "=", "0.1", ",", "normalize", "=", "True", ",", "log_entropy", "=", "False", ",", "tag", "=", "''", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'{}_kde{}'", ".", "format", "(", "\"\"", ".", "join", "(", "items", ")", ",", "tag", ")", ",", "required_agent_modules", "=", "[", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "items", "=", "items", "\n", "self", ".", "kde", "=", "KernelDensity", "(", "kernel", "=", "kernel", ",", "bandwidth", "=", "bandwidth", ")", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "samples", "=", "samples", "\n", "self", ".", "kernel", "=", "kernel", "\n", "self", ".", "bandwidth", "=", "bandwidth", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "kde_sample_mean", "=", "0.", "\n", "self", ".", "kde_sample_std", "=", "1.", "\n", "self", ".", "fitted_kde", "=", "None", "\n", "self", ".", "ready", "=", "False", "\n", "self", ".", "log_entropy", "=", "log_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity._setup": [[121, 123], ["isinstance"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "OnlineHERBuffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity._optimize": [[124, 155], ["buffers.append", "numpy.random.randint", "numpy.concatenate", "density.RawJointKernelDensity.kde.fit", "len", "len", "numpy.concatenate.append", "numpy.mean", "hasattr", "density.RawJointKernelDensity.fitted_kde.sample", "density.RawJointKernelDensity.logger.add_scalar", "buffer.get_batch", "numpy.std", "numpy.log().prod", "density.RawJointKernelDensity.fitted_kde.score", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.fit", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch"], ["", "def", "_optimize", "(", "self", ",", "force", "=", "False", ")", ":", "\n", "    ", "buffers", "=", "[", "]", "\n", "for", "item", "in", "self", ".", "items", ":", "\n", "      ", "buffers", ".", "append", "(", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", "[", "'buffer_'", "+", "item", "]", ")", "\n", "\n", "", "self", ".", "step", "+=", "1", "\n", "\n", "if", "force", "or", "(", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "buffers", "[", "0", "]", ")", ")", ":", "\n", "      ", "self", ".", "ready", "=", "True", "\n", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "buffers", "[", "0", "]", ")", ",", "size", "=", "self", ".", "samples", ")", "\n", "kde_samples", "=", "[", "]", "\n", "for", "buffer", "in", "buffers", ":", "\n", "        ", "kde_samples", ".", "append", "(", "buffer", ".", "get_batch", "(", "sample_idxs", ")", ")", "\n", "\n", "# Concatenate the items", "\n", "", "kde_samples", "=", "np", ".", "concatenate", "(", "kde_samples", ",", "axis", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "        ", "self", ".", "kde_sample_mean", "=", "np", ".", "mean", "(", "kde_samples", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "self", ".", "kde_sample_std", "=", "np", ".", "std", "(", "kde_samples", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "+", "1e-4", "\n", "kde_samples", "=", "(", "kde_samples", "-", "self", ".", "kde_sample_mean", ")", "/", "self", ".", "kde_sample_std", "\n", "\n", "", "self", ".", "fitted_kde", "=", "self", ".", "kde", ".", "fit", "(", "kde_samples", ")", "\n", "\n", "# Now also log the entropy", "\n", "if", "self", ".", "log_entropy", "and", "hasattr", "(", "self", ",", "'logger'", ")", "and", "self", ".", "step", "%", "250", "==", "0", ":", "\n", "# Scoring samples is a bit expensive, so just use 1000 points", "\n", "        ", "num_samples", "=", "1000", "\n", "s", "=", "self", ".", "fitted_kde", ".", "sample", "(", "num_samples", ")", "\n", "entropy", "=", "-", "self", ".", "fitted_kde", ".", "score", "(", "s", ")", "/", "num_samples", "+", "np", ".", "log", "(", "self", ".", "kde_sample_std", ")", ".", "prod", "(", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Explore/{}_entropy'", ".", "format", "(", "self", ".", "module_name", ")", ",", "entropy", ",", "log_every", "=", "500", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity.evaluate_log_density": [[156, 159], ["density.RawJointKernelDensity.fitted_kde.score_samples"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples"], ["", "", "", "def", "evaluate_log_density", "(", "self", ",", "samples", ")", ":", "\n", "    ", "assert", "self", ".", "ready", ",", "\"ENSURE READY BEFORE EVALUATING LOG DENSITY\"", "\n", "return", "self", ".", "fitted_kde", ".", "score_samples", "(", "(", "samples", "-", "self", ".", "kde_sample_mean", ")", "/", "self", ".", "kde_sample_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity.evaluate_elementwise_entropy": [[160, 177], ["density.RawJointKernelDensity.fitted_kde.score_samples", "numpy.exp", "scipy.special.entr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples"], ["", "def", "evaluate_elementwise_entropy", "(", "self", ",", "samples", ",", "beta", "=", "0.", ")", ":", "\n", "    ", "\"\"\" Given an array of samples, compute elementwise function of entropy of the form:\n\n        elem_entropy = - (p(samples) + beta)*log(p(samples) + beta)\n\n    Args:\n      samples: 1-D array of size N\n      beta: float, offset entropy calculation\n\n    Returns:\n      elem_entropy: 1-D array of size N, elementwise entropy with beta offset\n    \"\"\"", "\n", "assert", "self", ".", "ready", ",", "\"ENSURE READY BEFORE EVALUATING ELEMENT-WISE ENTROPY\"", "\n", "log_px", "=", "self", ".", "fitted_kde", ".", "score_samples", "(", "(", "samples", "-", "self", ".", "kde_sample_mean", ")", "/", "self", ".", "kde_sample_std", ")", "\n", "px", "=", "np", ".", "exp", "(", "log_px", ")", "\n", "elem_entropy", "=", "entr", "(", "px", "+", "beta", ")", "\n", "return", "elem_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity.save": [[178, 180], ["density.RawJointKernelDensity._save_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_save_props", "(", "[", "'kde'", ",", "'kde_sample_mean'", ",", "'kde_sample_std'", ",", "'fitted_kde'", ",", "'ready'", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity.load": [[181, 183], ["density.RawJointKernelDensity._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "'kde'", ",", "'kde_sample_mean'", ",", "'kde_sample_std'", ",", "'fitted_kde'", ",", "'ready'", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity.__init__": [[191, 202], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "item", ",", "optimize_every", "=", "1", ",", "batch_size", "=", "256", ",", "layers", "=", "(", "256", ",", "256", ")", ")", ":", "\n", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'{}_rnd'", ".", "format", "(", "item", ")", ",", "required_agent_modules", "=", "[", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "item", "=", "item", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "tgt_net", ",", "self", ".", "prd_net", ",", "self", ".", "optimizer", "=", "None", ",", "None", ",", "None", "\n", "self", ".", "lazy_load", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity._setup": [[203, 205], ["isinstance"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "OnlineHERBuffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity._init_from_sample": [[206, 214], ["mrl.utils.networks.MLP", "mrl.utils.networks.MLP", "density.RandomNetworkDensity.config.get", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "density.RandomNetworkDensity.tgt_net.to", "density.RandomNetworkDensity.prd_net.to", "density.RandomNetworkDensity.prd_net.parameters"], "methods", ["None"], ["", "def", "_init_from_sample", "(", "self", ",", "x", ")", ":", "\n", "    ", "input_size", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "tgt_net", "=", "MLP", "(", "input_size", ",", "output_size", "=", "self", ".", "layers", "[", "-", "1", "]", ",", "hidden_sizes", "=", "self", ".", "layers", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "prd_net", "=", "MLP", "(", "input_size", ",", "output_size", "=", "self", ".", "layers", "[", "-", "1", "]", ",", "hidden_sizes", "=", "self", ".", "layers", "[", ":", "-", "1", "]", ")", "\n", "if", "self", ".", "config", ".", "get", "(", "'device'", ")", ":", "\n", "      ", "self", ".", "tgt_net", "=", "self", ".", "tgt_net", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "self", ".", "prd_net", "=", "self", ".", "prd_net", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "prd_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.1", ",", "weight_decay", "=", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity.evaluate_log_density": [[215, 223], ["density.RandomNetworkDensity.torch", "density.RandomNetworkDensity.tgt_net", "density.RandomNetworkDensity.prd_net", "density.RandomNetworkDensity.numpy", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "evaluate_log_density", "(", "self", ",", "samples", ")", ":", "\n", "    ", "\"\"\"Not actually log density, just prediction error\"\"\"", "\n", "assert", "self", ".", "tgt_net", "is", "not", "None", ",", "\"ENSURE READY BEFORE EVALUATING LOG DENSITY\"", "\n", "\n", "samples", "=", "self", ".", "torch", "(", "samples", ")", "\n", "tgt", "=", "self", ".", "tgt_net", "(", "samples", ")", "\n", "prd", "=", "self", ".", "prd_net", "(", "samples", ")", "\n", "return", "self", ".", "numpy", "(", "-", "torch", ".", "mean", "(", "(", "prd", "-", "tgt", ")", "**", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity.ready": [[224, 227], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "ready", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "tgt_net", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity._optimize": [[228, 251], ["numpy.random.randint", "buffer.get_batch", "density.RandomNetworkDensity.torch", "density.RandomNetworkDensity.tgt_net", "density.RandomNetworkDensity.prd_net", "torch.mse_loss", "torch.mse_loss", "density.RandomNetworkDensity.optimizer.zero_grad", "torch.mse_loss.backward", "density.RandomNetworkDensity.optimizer.step", "len", "len", "density.RandomNetworkDensity._init_from_sample", "density.RandomNetworkDensity.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity._init_from_sample", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "def", "_optimize", "(", "self", ",", "force", "=", "False", ")", ":", "\n", "    ", "buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", "[", "'buffer_'", "+", "self", ".", "item", "]", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "force", "or", "(", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "buffer", ")", ")", ":", "\n", "      ", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "buffer", ")", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "samples", "=", "buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "\n", "# lazy load the networks if not yet loaded", "\n", "if", "self", ".", "tgt_net", "is", "None", ":", "\n", "        ", "self", ".", "_init_from_sample", "(", "samples", ")", "\n", "if", "self", ".", "lazy_load", "is", "not", "None", ":", "\n", "          ", "self", ".", "load", "(", "self", ".", "lazy_load", ")", "\n", "self", ".", "lazy_load", "=", "None", "\n", "\n", "", "", "samples", "=", "self", ".", "torch", "(", "samples", ")", "\n", "tgt", "=", "self", ".", "tgt_net", "(", "samples", ")", "\n", "prd", "=", "self", ".", "prd_net", "(", "samples", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "tgt", ",", "prd", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity.save": [[252, 260], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "density.RandomNetworkDensity.tgt_net.state_dict", "density.RandomNetworkDensity.prd_net.state_dict", "density.RandomNetworkDensity.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "if", "self", ".", "tgt_net", "is", "not", "None", ":", "\n", "      ", "torch", ".", "save", "(", "{", "\n", "'tgt_state_dict'", ":", "self", ".", "tgt_net", ".", "state_dict", "(", ")", ",", "\n", "'prd_state_dict'", ":", "self", ".", "prd_net", ".", "state_dict", "(", ")", ",", "\n", "'opt_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RandomNetworkDensity.load": [[261, 270], ["os.path.join", "os.path.exists", "torch.load", "torch.load", "torch.load", "torch.load", "density.RandomNetworkDensity.tgt_net.load_state_dict", "density.RandomNetworkDensity.prd_net.load_state_dict", "density.RandomNetworkDensity.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "if", "self", ".", "tgt_net", "is", "None", "and", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "      ", "self", ".", "lazy_load", "=", "save_folder", "\n", "", "else", ":", "\n", "      ", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "self", ".", "tgt_net", ".", "load_state_dict", "(", "checkpoint", "[", "'tgt_state_dict'", "]", ")", "\n", "self", ".", "prd_net", ".", "load_state_dict", "(", "checkpoint", "[", "'prd_state_dict'", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'opt_state_dict'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.__init__": [[276, 292], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "item", ",", "optimize_every", "=", "2", ",", "batch_size", "=", "1000", ",", "lr", "=", "1e-3", ",", "num_layer_pairs", "=", "3", ",", "normalize", "=", "True", ")", ":", "\n", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'{}_flow'", ".", "format", "(", "item", ")", ",", "required_agent_modules", "=", "[", "'replay_buffer'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "item", "=", "item", "\n", "self", ".", "num_layer_pairs", "=", "num_layer_pairs", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "lazy_load", "=", "None", "\n", "self", ".", "flow_model", "=", "None", "\n", "self", ".", "dev", "=", "None", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "sample_mean", "=", "0.", "\n", "self", ".", "sample_std", "=", "1.", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity._setup": [[293, 295], ["isinstance"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "OnlineHERBuffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity._init_from_sample": [[296, 305], ["density.FlowDensity.config.get", "mrl.utils.realnvp.RealNVP", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["None"], ["", "def", "_init_from_sample", "(", "self", ",", "x", ")", ":", "\n", "    ", "input_size", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "input_channel", "=", "input_size", "\n", "if", "self", ".", "config", ".", "get", "(", "'device'", ")", ":", "\n", "      ", "self", ".", "dev", "=", "self", ".", "config", ".", "device", "\n", "", "elif", "self", ".", "dev", "is", "None", ":", "\n", "      ", "self", ".", "dev", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "# Device=None is fine for default too based on network.py in realNVP", "\n", "", "self", ".", "flow_model", "=", "RealNVP", "(", "input_channel", "=", "self", ".", "input_channel", ",", "lr", "=", "self", ".", "lr", ",", "num_layer_pairs", "=", "self", ".", "num_layer_pairs", ",", "dev", "=", "self", ".", "dev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.evaluate_log_density": [[306, 309], ["density.FlowDensity.flow_model.score_samples"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples"], ["", "def", "evaluate_log_density", "(", "self", ",", "samples", ")", ":", "\n", "    ", "assert", "self", ".", "ready", ",", "\"ENSURE READY BEFORE EVALUATING LOG DENSITY\"", "\n", "return", "self", ".", "flow_model", ".", "score_samples", "(", "(", "samples", "-", "self", ".", "sample_mean", ")", "/", "self", ".", "sample_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.ready": [[310, 313], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "ready", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "flow_model", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity._optimize": [[314, 337], ["numpy.random.randint", "buffer.get_batch", "density.FlowDensity.torch", "density.FlowDensity.flow_model.fit", "len", "len", "numpy.mean", "density.FlowDensity._init_from_sample", "numpy.std", "density.FlowDensity.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.fit", "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity._init_from_sample", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "def", "_optimize", "(", "self", ",", "force", "=", "False", ")", ":", "\n", "    ", "buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", "[", "'buffer_'", "+", "self", ".", "item", "]", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "force", "or", "(", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "buffer", ")", ")", ":", "\n", "      ", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "buffer", ")", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "samples", "=", "buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "if", "self", ".", "normalize", ":", "\n", "        ", "self", ".", "sample_mean", "=", "np", ".", "mean", "(", "samples", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "self", ".", "sample_std", "=", "np", ".", "std", "(", "samples", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "+", "1e-4", "\n", "samples", "=", "(", "samples", "-", "self", ".", "sample_mean", ")", "/", "self", ".", "sample_std", "\n", "\n", "# lazy load the model if not yet loaded", "\n", "", "if", "self", ".", "flow_model", "is", "None", ":", "\n", "        ", "self", ".", "_init_from_sample", "(", "samples", ")", "\n", "if", "self", ".", "lazy_load", "is", "not", "None", ":", "\n", "          ", "self", ".", "load", "(", "self", ".", "lazy_load", ")", "\n", "self", ".", "lazy_load", "=", "None", "\n", "\n", "", "", "samples", "=", "self", ".", "torch", "(", "samples", ")", "\n", "#del self.flow_model", "\n", "#self.flow_model = RealNVP(input_channel=self.input_channel, lr=self.lr, num_layer_pairs=self.num_layer_pairs, dev=self.dev)", "\n", "self", ".", "flow_model", ".", "fit", "(", "samples", ",", "epochs", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.save": [[338, 344], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save"], ["", "", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "if", "self", ".", "flow_model", "is", "not", "None", ":", "\n", "      ", "torch", ".", "save", "(", "{", "\n", "'flow_model'", ":", "self", ".", "flow_model", ",", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.load": [[345, 351], ["os.path.join", "os.path.exists", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "if", "self", ".", "flow_model", "is", "None", "and", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "      ", "self", ".", "lazy_load", "=", "save_folder", "\n", "", "else", ":", "\n", "      ", "self", ".", "flow_model", "=", "torch", ".", "load", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.__init__": [[25, 29], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "average_every", "=", "100", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'logger'", ",", "required_agent_modules", "=", "[", "'env'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "average_every", "=", "average_every", "\n", "self", ".", "writer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger._setup": [[30, 42], ["numpy.zeros", "numpy.zeros", "collections.defaultdict", "collections.defaultdict", "logging.Logger.save_config"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.save_config"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "# rewards and steps are always tracked", "\n", "    ", "self", ".", "rewards_per_env", "=", "np", ".", "zeros", "(", "(", "self", ".", "env", ".", "num_envs", ",", ")", ")", "\n", "self", ".", "steps_per_env", "=", "np", ".", "zeros", "(", "(", "self", ".", "env", ".", "num_envs", ",", ")", ")", "\n", "self", ".", "episode_rewards", "=", "[", "]", "\n", "self", ".", "episode_steps", "=", "[", "]", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "episodes", "=", "0", "\n", "self", ".", "tabular", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "last_log_step", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "log_every_n_steps", "=", "self", ".", "config", ".", "log_every", "\n", "self", ".", "save_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.lazy_init_writer": [[43, 46], ["torch.utils.tensorboard.SummaryWriter"], "methods", ["None"], ["", "def", "lazy_init_writer", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "writer", "is", "None", ":", "\n", "      ", "self", ".", "writer", "=", "SummaryWriter", "(", "self", ".", "agent_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.update_csv": [[47, 57], ["os.path.join", "os.path.exists", "open", "csv.writer", "csv.writer.writerow", "open", "csv.writer", "csv.writer.writerow", "tag.replace", "time.time"], "methods", ["None"], ["", "", "def", "update_csv", "(", "self", ",", "tag", ",", "value", ",", "step", ")", ":", "\n", "    ", "fields", "=", "[", "'wall_time'", ",", "'step'", ",", "tag", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "agent_folder", ",", "self", ".", "agent_name", "+", "'__'", "+", "tag", ".", "replace", "(", "'/'", ",", "'__'", ")", "+", "'.csv'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "      ", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "writer", ".", "writerow", "(", "fields", ")", "\n", "", "", "with", "open", "(", "path", ",", "'a'", ")", "as", "f", ":", "\n", "      ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "time", ".", "time", "(", ")", ",", "step", ",", "value", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar": [[58, 67], ["logging.Logger.lazy_init_writer", "logging.Logger.writer.add_scalar", "logging.Logger.update_csv"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.lazy_init_writer", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.update_csv"], ["", "", "def", "add_scalar", "(", "self", ",", "tag", ",", "value", ",", "log_every", "=", "1000", ",", "step", "=", "None", ")", ":", "\n", "    ", "\"\"\"Adds scalar to tensorboard\"\"\"", "\n", "self", ".", "lazy_init_writer", "(", ")", "\n", "if", "step", "is", "None", ":", "\n", "      ", "step", "=", "self", ".", "config", ".", "env_steps", "\n", "", "if", "step", "-", "self", ".", "last_log_step", "[", "tag", "]", ">=", "log_every", ":", "\n", "      ", "self", ".", "last_log_step", "[", "tag", "]", "=", "step", "\n", "self", ".", "writer", ".", "add_scalar", "(", "tag", ",", "value", ",", "step", ")", "\n", "self", ".", "update_csv", "(", "tag", ",", "value", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram": [[68, 80], ["logging.Logger.lazy_init_writer", "isinstance", "numpy.array", "isinstance", "logging.Logger.writer.add_histogram", "values.astype.astype.astype"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.lazy_init_writer", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram"], ["", "", "def", "add_histogram", "(", "self", ",", "tag", ",", "values", ",", "log_every", "=", "1000", ",", "step", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Adds histogram to tensorboard\"\"\"", "\n", "self", ".", "lazy_init_writer", "(", ")", "\n", "if", "isinstance", "(", "values", ",", "list", ")", ":", "\n", "      ", "values", "=", "np", ".", "array", "(", "values", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "elif", "isinstance", "(", "values", ",", "np", ".", "ndarray", ")", ":", "\n", "      ", "values", "=", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "if", "step", "is", "None", ":", "\n", "      ", "step", "=", "self", ".", "config", ".", "env_steps", "\n", "", "if", "step", "-", "self", ".", "last_log_step", "[", "tag", "]", ">=", "log_every", ":", "\n", "      ", "self", ".", "last_log_step", "[", "tag", "]", "=", "step", "\n", "self", ".", "writer", ".", "add_histogram", "(", "tag", ",", "values", ",", "step", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding": [[81, 94], ["logging.Logger.lazy_init_writer", "isinstance", "numpy.array", "isinstance", "len", "logging.Logger.writer.add_embedding", "values.astype.astype.astype"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.lazy_init_writer", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_embedding"], ["", "", "def", "add_embedding", "(", "self", ",", "tag", ",", "values", ",", "log_every", "=", "1000", ",", "step", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Adds embedding data to tensorboard\"\"\"", "\n", "self", ".", "lazy_init_writer", "(", ")", "\n", "if", "isinstance", "(", "values", ",", "list", ")", ":", "\n", "      ", "values", "=", "np", ".", "array", "(", "values", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "elif", "isinstance", "(", "values", ",", "np", ".", "ndarray", ")", ":", "\n", "      ", "values", "=", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "assert", "len", "(", "values", ".", "shape", ")", "==", "2", "\n", "if", "step", "is", "None", ":", "\n", "      ", "step", "=", "self", ".", "config", ".", "env_steps", "\n", "", "if", "step", "-", "self", ".", "last_log_step", "[", "tag", "]", ">=", "log_every", ":", "\n", "      ", "self", ".", "last_log_step", "[", "tag", "]", "=", "step", "\n", "self", ".", "writer", ".", "add_embedding", "(", "mat", "=", "values", ",", "tag", "=", "tag", ",", "global_step", "=", "step", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_tabular": [[95, 98], ["logging.Logger.tabular[].append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "def", "add_tabular", "(", "self", ",", "tag", ",", "value", ")", ":", "\n", "    ", "\"\"\"Adds scalar to console logger\"\"\"", "\n", "self", ".", "tabular", "[", "tag", "]", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.log_color": [[99, 101], ["print", "logging.colorize"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.colorize"], ["", "def", "log_color", "(", "self", ",", "tag", ",", "value", "=", "''", ",", "color", "=", "'cyan'", ")", ":", "\n", "    ", "print", "(", "colorize", "(", "tag", ",", "color", "=", "color", ",", "bold", "=", "True", ")", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.save_config": [[102, 112], ["logging.convert_json", "json.dumps", "print", "print", "print", "print", "logging.colorize", "logging.colorize", "open", "out.write", "logging.record_attrs", "os.path.join", "logging.Logger.module_dict.values"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.colorize", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.colorize", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.record_attrs"], ["", "def", "save_config", "(", "self", ")", ":", "\n", "    ", "config_json", "=", "convert_json", "(", "{", "**", "self", ".", "config", ",", "**", "record_attrs", "(", "self", ".", "module_dict", ".", "values", "(", ")", ")", "}", ")", "\n", "config_json", "[", "'agent_name'", "]", "=", "self", ".", "agent_name", "\n", "output", "=", "json", ".", "dumps", "(", "config_json", ",", "separators", "=", "(", "','", ",", "':\\t'", ")", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "print", "(", "colorize", "(", "'\\nAgent folder:'", ",", "color", "=", "'magenta'", ",", "bold", "=", "True", ")", ")", "\n", "print", "(", "self", ".", "agent_folder", ")", "\n", "print", "(", "colorize", "(", "'\\nSaving config:'", ",", "color", "=", "'cyan'", ",", "bold", "=", "True", ")", ")", "\n", "print", "(", "output", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "agent_folder", ",", "\"config.json\"", ")", ",", "'w'", ")", "as", "out", ":", "\n", "      ", "out", ".", "write", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.flush_console": [[113, 123], ["logging.Logger.tabular.items", "tabulate.tabulate.tabulate", "print", "tabulate.tabulate.tabulate.append", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "def", "flush_console", "(", "self", ")", ":", "\n", "    ", "table", "=", "[", "(", "'Environment steps'", ",", "self", ".", "steps", ")", ",", "(", "'Total episodes'", ",", "self", ".", "episodes", ")", ",", "\n", "(", "'Avg rewards (last {})'", ".", "format", "(", "self", ".", "average_every", ")", ",", "np", ".", "mean", "(", "self", ".", "episode_rewards", "[", "-", "self", ".", "average_every", ":", "]", ")", ")", ",", "\n", "(", "'Avg episode len (last {})'", ".", "format", "(", "self", ".", "average_every", ")", ",", "np", ".", "mean", "(", "self", ".", "episode_steps", "[", "-", "self", ".", "average_every", ":", "]", ")", ")", "\n", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "tabular", ".", "items", "(", ")", ":", "\n", "      ", "table", ".", "append", "(", "(", "'Avg '", "+", "k", "+", "' (last {})'", ".", "format", "(", "self", ".", "average_every", ")", ",", "np", ".", "mean", "(", "v", "[", "-", "self", ".", "average_every", ":", "]", ")", ")", ")", "\n", "", "table", "=", "tabulate", "(", "table", ",", "headers", "=", "[", "'Tag'", ",", "'Value'", "]", ",", "tablefmt", "=", "\"psql\"", ",", "floatfmt", "=", "\"8.1f\"", ")", "\n", "\n", "print", "(", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger._process_experience": [[124, 142], ["numpy.any", "list", "list", "numpy.sum", "logging.Logger.flush_console", "logging.Logger.add_scalar", "logging.Logger.add_scalar", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.flush_console", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar"], ["", "def", "_process_experience", "(", "self", ",", "experience", ")", ":", "\n", "    ", "rewards", ",", "dones", "=", "experience", ".", "reward", ",", "experience", ".", "trajectory_over", "\n", "\n", "self", ".", "rewards_per_env", "+=", "rewards", "\n", "self", ".", "steps_per_env", "+=", "1", "\n", "\n", "if", "np", ".", "any", "(", "dones", ")", ":", "\n", "      ", "self", ".", "episode_rewards", "+=", "list", "(", "self", ".", "rewards_per_env", "[", "dones", "]", ")", "\n", "self", ".", "episode_steps", "+=", "list", "(", "self", ".", "steps_per_env", "[", "dones", "]", ")", "\n", "self", ".", "rewards_per_env", "[", "dones", "]", "=", "0", "\n", "self", ".", "steps_per_env", "[", "dones", "]", "=", "0", "\n", "self", ".", "episodes", "+=", "np", ".", "sum", "(", "dones", ")", "\n", "\n", "", "self", ".", "steps", "+=", "self", ".", "env", ".", "num_envs", "\n", "if", "self", ".", "steps", "%", "self", ".", "log_every_n_steps", "<", "self", ".", "env", ".", "num_envs", ":", "\n", "      ", "self", ".", "flush_console", "(", ")", "\n", "self", ".", "add_scalar", "(", "'Train/Episode_rewards'", ",", "np", ".", "mean", "(", "self", ".", "episode_rewards", "[", "-", "30", ":", "]", ")", ")", "\n", "self", ".", "add_scalar", "(", "'Train/Episode_steps'", ",", "np", ".", "mean", "(", "self", ".", "episode_steps", "[", "-", "30", ":", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.save": [[143, 148], ["logging.Logger._save_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props"], ["", "", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_save_props", "(", "[", "\n", "'episode_rewards'", ",", "'episode_steps'", ",", "\n", "'steps'", ",", "'episodes'", ",", "'tabular'", ",", "'last_log_step'", "\n", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.load": [[149, 154], ["logging.Logger._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "\n", "'episode_rewards'", ",", "'episode_steps'", ",", "\n", "'steps'", ",", "'episodes'", ",", "'tabular'", ",", "'last_log_step'", "\n", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.colorize": [[159, 170], ["attr.append", "str", "attr.append"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["def", "colorize", "(", "string", ",", "color", ",", "bold", "=", "False", ",", "highlight", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n    Colorize a string.\n    This function was originally written by John Schulman.\n    \"\"\"", "\n", "attr", "=", "[", "]", "\n", "num", "=", "color2num", "[", "color", "]", "\n", "if", "highlight", ":", "num", "+=", "10", "\n", "attr", ".", "append", "(", "str", "(", "num", ")", ")", "\n", "if", "bold", ":", "attr", ".", "append", "(", "'1'", ")", "\n", "return", "'\\x1b[%sm%s\\x1b[0m'", "%", "(", "';'", ".", "join", "(", "attr", ")", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json": [[172, 194], ["logging.is_json_serializable", "str", "isinstance", "isinstance", "logging.convert_json", "logging.convert_json", "tuple", "isinstance", "obj.items", "logging.convert_json", "logging.convert_json", "hasattr", "logging.convert_json", "hasattr", "logging.convert_json", "logging.convert_json", "str", "obj.__dict__.items"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.is_json_serializable", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json"], ["", "def", "convert_json", "(", "obj", ",", "dict_to_str", "=", "False", ")", ":", "\n", "  ", "\"\"\" Convert obj to a version which can be serialized with JSON. \"\"\"", "\n", "if", "is_json_serializable", "(", "obj", ")", ":", "\n", "    ", "return", "obj", "\n", "", "else", ":", "\n", "    ", "if", "isinstance", "(", "obj", ",", "dict", ")", "and", "not", "dict_to_str", ":", "\n", "      ", "return", "{", "convert_json", "(", "k", ")", ":", "convert_json", "(", "v", ")", "for", "k", ",", "v", "in", "obj", ".", "items", "(", ")", "}", "\n", "\n", "", "elif", "isinstance", "(", "obj", ",", "tuple", ")", ":", "\n", "      ", "return", "tuple", "(", "[", "convert_json", "(", "x", ")", "for", "x", "in", "obj", "]", ")", "\n", "\n", "", "elif", "isinstance", "(", "obj", ",", "list", ")", ":", "\n", "      ", "return", "[", "convert_json", "(", "x", ")", "for", "x", "in", "obj", "]", "\n", "\n", "", "elif", "hasattr", "(", "obj", ",", "'__name__'", ")", "and", "not", "(", "'lambda'", "in", "obj", ".", "__name__", ")", ":", "\n", "      ", "return", "convert_json", "(", "obj", ".", "__name__", ")", "\n", "\n", "", "elif", "hasattr", "(", "obj", ",", "'__dict__'", ")", "and", "obj", ".", "__dict__", ":", "\n", "      ", "obj_dict", "=", "{", "convert_json", "(", "k", ")", ":", "convert_json", "(", "v", ")", "for", "k", ",", "v", "in", "obj", ".", "__dict__", ".", "items", "(", ")", "}", "\n", "return", "{", "str", "(", "obj", ")", ":", "obj_dict", "}", "\n", "\n", "", "return", "str", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.is_json_serializable": [[196, 202], ["json.dumps"], "function", ["None"], ["", "", "def", "is_json_serializable", "(", "v", ")", ":", "\n", "  ", "try", ":", "\n", "    ", "json", ".", "dumps", "(", "v", ")", "\n", "return", "True", "\n", "", "except", ":", "\n", "    ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.record_attrs": [[204, 209], ["logging.convert_json", "logging.strip_config_spec"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.modules.logging.convert_json", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.strip_config_spec"], ["", "", "def", "record_attrs", "(", "module_list", ")", ":", "\n", "  ", "res", "=", "{", "}", "\n", "for", "module", "in", "module_list", ":", "\n", "    ", "res", "[", "'module_'", "+", "module", ".", "module_name", "]", "=", "convert_json", "(", "strip_config_spec", "(", "module", ".", "config_spec", ")", ",", "dict_to_str", "=", "True", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.strip_config_spec": [[211, 215], ["None"], "function", ["None"], ["", "def", "strip_config_spec", "(", "config_spec", ")", ":", "\n", "  ", "if", "'__class__'", "in", "config_spec", ":", "\n", "    ", "del", "config_spec", "[", "'__class__'", "]", "\n", "", "return", "config_spec", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.action_noise.ContinuousActionNoise.__init__": [[5, 10], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "random_process_cls", "=", "GaussianProcess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'action_noise'", ",", "required_agent_modules", "=", "[", "'env'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "_random_process_cls", "=", "random_process_cls", "\n", "self", ".", "_args", "=", "args", "\n", "self", ".", "_kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.action_noise.ContinuousActionNoise._setup": [[11, 14], ["action_noise.ContinuousActionNoise._random_process_cls", "action_noise.ContinuousActionNoise.config.get"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "random_process", "=", "self", ".", "_random_process_cls", "(", "(", "self", ".", "env", ".", "num_envs", ",", "self", ".", "env", ".", "action_dim", ",", ")", ",", "*", "self", ".", "_args", ",", "**", "self", ".", "_kwargs", ")", "\n", "self", ".", "varied_action_noise", "=", "self", ".", "config", ".", "get", "(", "'varied_action_noise'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.action_noise.ContinuousActionNoise.__call__": [[15, 22], ["np.arange().reshape", "np.arange", "len", "action_noise.ContinuousActionNoise.random_process.sample"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "__call__", "(", "self", ",", "action", ")", ":", "\n", "    ", "factor", "=", "1", "\n", "if", "self", ".", "varied_action_noise", ":", "\n", "      ", "n_envs", "=", "self", ".", "env", ".", "num_envs", "\n", "factor", "=", "np", ".", "arange", "(", "0.", ",", "1.", "+", "(", "1.", "/", "n_envs", ")", ",", "1.", "/", "(", "n_envs", "-", "1", ")", ")", ".", "reshape", "(", "n_envs", ",", "1", ")", "\n", "\n", "", "return", "action", "+", "(", "self", ".", "random_process", ".", "sample", "(", ")", "*", "self", ".", "env", ".", "max_action", "*", "factor", ")", "[", ":", "len", "(", "action", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.action_noise.ContinuousActionNoise.save": [[23, 25], ["action_noise.ContinuousActionNoise._save_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_save_props", "(", "[", "'random_process'", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.action_noise.ContinuousActionNoise.load": [[26, 28], ["action_noise.ContinuousActionNoise._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "'random_process'", "]", ",", "save_folder", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.eval.EpisodicEval.__init__": [[6, 8], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'eval'", ",", "required_agent_modules", "=", "[", "'eval_env'", ",", "'policy'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.eval.EpisodicEval.__call__": [[9, 64], ["eval.EpisodicEval.eval_mode", "hasattr", "mrl.utils.misc.AttrDict", "len", "env.reset", "numpy.zeros", "numpy.zeros", "numpy.zeros", "zip", "len", "eval.EpisodicEval.logger.add_scalar", "eval.EpisodicEval.logger.add_scalar", "eval.EpisodicEval.logger.add_scalar", "numpy.all", "eval.EpisodicEval.policy", "env.step", "enumerate", "episode_rewards.append", "discounted_episode_rewards.append", "episode_steps.append", "eval.EpisodicEval.logger.add_scalar", "numpy.mean", "numpy.mean", "numpy.mean", "range", "zip", "ep_rewards[].append", "is_successes.append", "sum", "eval.discounted_sum", "numpy.mean", "max"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.eval_mode", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.eval.discounted_sum"], ["", "def", "__call__", "(", "self", ",", "num_episodes", ":", "int", ",", "*", "unused_args", ",", "any_success", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Runs num_steps steps in the environment and returns results.\n    Results tracking is done here instead of in process_experience, since \n    experiences aren't \"real\" experiences; e.g. agent cannot learn from them.  \n    \"\"\"", "\n", "self", ".", "eval_mode", "(", ")", "\n", "env", "=", "self", ".", "eval_env", "\n", "num_envs", "=", "env", ".", "num_envs", "\n", "\n", "episode_rewards", ",", "episode_steps", "=", "[", "]", ",", "[", "]", "\n", "discounted_episode_rewards", "=", "[", "]", "\n", "is_successes", "=", "[", "]", "\n", "record_success", "=", "False", "\n", "\n", "while", "len", "(", "episode_rewards", ")", "<", "num_episodes", ":", "\n", "      ", "state", "=", "env", ".", "reset", "(", ")", "\n", "\n", "dones", "=", "np", ".", "zeros", "(", "(", "num_envs", ",", ")", ")", "\n", "steps", "=", "np", ".", "zeros", "(", "(", "num_envs", ",", ")", ")", "\n", "is_success", "=", "np", ".", "zeros", "(", "(", "num_envs", ",", ")", ")", "\n", "ep_rewards", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_envs", ")", "]", "\n", "\n", "while", "not", "np", ".", "all", "(", "dones", ")", ":", "\n", "        ", "action", "=", "self", ".", "policy", "(", "state", ")", "\n", "state", ",", "reward", ",", "dones_", ",", "infos", "=", "env", ".", "step", "(", "action", ")", "\n", "\n", "for", "i", ",", "(", "rew", ",", "done", ",", "info", ")", "in", "enumerate", "(", "zip", "(", "reward", ",", "dones_", ",", "infos", ")", ")", ":", "\n", "          ", "if", "dones", "[", "i", "]", ":", "\n", "            ", "continue", "\n", "", "ep_rewards", "[", "i", "]", ".", "append", "(", "rew", ")", "\n", "steps", "[", "i", "]", "+=", "1", "\n", "if", "done", ":", "\n", "            ", "dones", "[", "i", "]", "=", "1.", "\n", "", "if", "'is_success'", "in", "info", ":", "\n", "            ", "record_success", "=", "True", "\n", "is_success", "[", "i", "]", "=", "max", "(", "info", "[", "'is_success'", "]", ",", "is_success", "[", "i", "]", ")", "if", "any_success", "else", "info", "[", "'is_success'", "]", "\n", "\n", "", "", "", "for", "ep_reward", ",", "step", ",", "is_succ", "in", "zip", "(", "ep_rewards", ",", "steps", ",", "is_success", ")", ":", "\n", "        ", "if", "record_success", ":", "\n", "          ", "is_successes", ".", "append", "(", "is_succ", ")", "\n", "", "episode_rewards", ".", "append", "(", "sum", "(", "ep_reward", ")", ")", "\n", "discounted_episode_rewards", ".", "append", "(", "discounted_sum", "(", "ep_reward", ",", "self", ".", "config", ".", "gamma", ")", ")", "\n", "episode_steps", ".", "append", "(", "step", ")", "\n", "\n", "", "", "if", "hasattr", "(", "self", ",", "'logger'", ")", ":", "\n", "      ", "if", "len", "(", "is_successes", ")", ":", "\n", "        ", "self", ".", "logger", ".", "add_scalar", "(", "'Test/Success'", ",", "np", ".", "mean", "(", "is_successes", ")", ")", "\n", "", "self", ".", "logger", ".", "add_scalar", "(", "'Test/Episode_rewards'", ",", "np", ".", "mean", "(", "episode_rewards", ")", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Test/Discounted_episode_rewards'", ",", "np", ".", "mean", "(", "discounted_episode_rewards", ")", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Test/Episode_steps'", ",", "np", ".", "mean", "(", "episode_steps", ")", ")", "\n", "\n", "", "return", "AttrDict", "(", "{", "\n", "'rewards'", ":", "episode_rewards", ",", "\n", "'steps'", ":", "episode_steps", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.eval.discounted_sum": [[66, 73], ["None"], "function", ["None"], ["", "", "def", "discounted_sum", "(", "lst", ",", "discount", ")", ":", "\n", "  ", "sum", "=", "0", "\n", "gamma", "=", "1", "\n", "for", "i", "in", "lst", ":", "\n", "    ", "sum", "+=", "gamma", "*", "i", "\n", "gamma", "*=", "discount", "\n", "", "return", "sum", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.GoalEnvReward.__init__": [[7, 11], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Wraps environment's compute reward function\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "'goal_reward'", ",", "required_agent_modules", "=", "[", "'env'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.GoalEnvReward._setup": [[12, 15], ["hasattr"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "env", ".", "goal_env", ",", "\"Environment must be a goal environment!\"", "\n", "assert", "hasattr", "(", "self", ".", "env", ",", "'compute_reward'", ")", ",", "\"Environment must have compute reward defined!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.GoalEnvReward.__call__": [[16, 18], ["goal_reward.GoalEnvReward.env.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "__call__", "(", "self", ",", "achieved_goals", ",", "goals", ",", "info", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "compute_reward", "(", "achieved_goals", ",", "goals", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.NeighborReward.__init__": [[21, 33], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "max_neighbor_distance", "=", "1", ",", "optimize_every", "=", "5", ",", "batch_size", "=", "1000", ",", "temperature", "=", "1.", ")", ":", "\n", "    ", "\"\"\"Wraps environment's compute reward function. Should probably only be used for first-visit achievment.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "'goal_reward'", ",", "required_agent_modules", "=", "[", "'replay_buffer'", ",", "'neighbor_embedding_network'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n", "if", "max_neighbor_distance", "!=", "1", ":", "# this is the number of steps from which to count two goals as neighbors.", "\n", "      ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.NeighborReward._setup": [[34, 42], ["hasattr", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "goal_reward.NeighborReward.neighbor_embedding_network.model.parameters"], "methods", ["None"], ["", "", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "env", ".", "goal_env", ",", "\"Environment must be a goal environment!\"", "\n", "assert", "hasattr", "(", "self", ".", "env", ",", "'compute_reward'", ")", ",", "\"Environment must have compute reward defined!\"", "\n", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "neighbor_embedding_network", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", ".", "critic_lr", ",", "# just using critic hparams for now", "\n", "weight_decay", "=", "self", ".", "config", ".", "critic_weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.NeighborReward._optimize": [[43, 85], ["len", "numpy.random.randint", "ag_buffer.get_batch", "pag_buffer.get_batch", "ags[].copy", "numpy.roll", "goal_reward.NeighborReward.torch", "goal_reward.NeighborReward.torch", "goal_reward.NeighborReward.torch", "goal_reward.NeighborReward.neighbor_embedding_network", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "goal_reward.NeighborReward.logger.add_tabular", "goal_reward.NeighborReward.optimizer.zero_grad", "loss.backward", "goal_reward.NeighborReward.optimizer.step", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "goal_reward.NeighborReward.numpy", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "len", "len", "len", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_tabular", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "pag_buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_previous_ag", "\n", "ag_buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "ag_buffer", ")", ":", "\n", "      ", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "ag_buffer", ")", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "\n", "ags", "=", "ag_buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "pos", "=", "pag_buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "\n", "# mix it up to keep it symmetric for now...", "\n", "temp", "=", "ags", "[", ":", "len", "(", "ags", ")", "//", "2", "]", ".", "copy", "(", ")", "\n", "ags", "[", ":", "len", "(", "ags", ")", "//", "2", "]", "=", "pos", "[", ":", "len", "(", "ags", ")", "//", "2", "]", "\n", "pos", "[", ":", "len", "(", "ags", ")", "//", "2", "]", "=", "temp", "\n", "\n", "# get random negative samples by a 1 index roll", "\n", "neg", "=", "np", ".", "roll", "(", "pos", ",", "1", ",", "axis", "=", "0", ")", "\n", "\n", "# move to torch", "\n", "ags", "=", "self", ".", "torch", "(", "ags", ")", "\n", "pos", "=", "self", ".", "torch", "(", "pos", ")", "\n", "neg", "=", "self", ".", "torch", "(", "neg", ")", "\n", "\n", "# get embeddings", "\n", "embs", "=", "self", ".", "neighbor_embedding_network", "(", "torch", ".", "cat", "(", "(", "ags", ",", "pos", ",", "neg", ")", ",", "dim", "=", "0", ")", ")", "\n", "ags", ",", "pos", ",", "neg", "=", "torch", ".", "chunk", "(", "embs", ",", "3", ")", "\n", "\n", "pos_logits", "=", "-", "self", ".", "temperature", "*", "torch", ".", "norm", "(", "ags", "-", "pos", ",", "dim", "=", "1", ")", "\n", "neg_logits", "=", "-", "self", ".", "temperature", "*", "torch", ".", "norm", "(", "ags", "-", "neg", ",", "dim", "=", "1", ")", "\n", "\n", "# use soft targets", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "torch", ".", "exp", "(", "pos_logits", ")", ",", "torch", ".", "ones_like", "(", "pos_logits", ")", "*", "0.99", ")", "+", "F", ".", "binary_cross_entropy_with_logits", "(", "torch", ".", "exp", "(", "neg_logits", ")", ",", "torch", ".", "ones_like", "(", "pos_logits", ")", "*", "0.01", ")", "\n", "\n", "\n", "self", ".", "logger", ".", "add_tabular", "(", "'intrinsic_reward_loss'", ",", "self", ".", "numpy", "(", "loss", ")", ")", "\n", "\n", "# optimize", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.NeighborReward.__call__": [[86, 102], ["achieved_goals.reshape", "goals.reshape", "goal_reward.NeighborReward.torch", "goal_reward.NeighborReward.torch", "goal_reward.NeighborReward.neighbor_embedding_network", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "goal_reward.NeighborReward.numpy().astype", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "goal_reward.NeighborReward.numpy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "def", "__call__", "(", "self", ",", "achieved_goals", ",", "goals", ",", "info", ")", ":", "\n", "    ", "\"\"\"Should return 0 for ags, gs that are predicted to be neighbors, -1 otherwise, as a numpy array\"\"\"", "\n", "ags", "=", "achieved_goals", ".", "reshape", "(", "-", "1", ",", "achieved_goals", ".", "shape", "[", "-", "1", "]", ")", "\n", "dgs", "=", "goals", ".", "reshape", "(", "-", "1", ",", "achieved_goals", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "ags", "=", "self", ".", "torch", "(", "ags", ")", "\n", "dgs", "=", "self", ".", "torch", "(", "dgs", ")", "\n", "\n", "# get embeddings", "\n", "embs", "=", "self", ".", "neighbor_embedding_network", "(", "torch", ".", "cat", "(", "(", "ags", ",", "dgs", ")", ",", "dim", "=", "0", ")", ")", "\n", "ags", ",", "dgs", "=", "torch", ".", "chunk", "(", "embs", ",", "2", ")", "\n", "\n", "# predict whether ags and dgs are transition neighbors", "\n", "preds", "=", "torch", ".", "exp", "(", "-", "self", ".", "temperature", "*", "torch", ".", "norm", "(", "ags", "-", "dgs", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "-", "self", ".", "numpy", "(", "preds", "<", "0.5", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.NeighborReward.save": [[103, 108], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "goal_reward.NeighborReward.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'opt_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_reward.NeighborReward.load": [[115, 117], ["goal_reward.NeighborReward._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "'random_process'", "]", ",", "save_folder", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.train.StandardTrain.__init__": [[8, 10], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["# 2. Get default config and update any defaults (this automatically updates the argparse defaults)", "\n", "config", "=", "best_slide_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.train.StandardTrain._setup": [[11, 16], ["hasattr"], "methods", ["None"], ["# 3. Make changes to the argparse below", "\n", "def", "main", "(", "args", ")", ":", "\n", "\n", "# 4. Update the config with args, and make the agent name. ", "\n", "  ", "if", "args", ".", "num_envs", "is", "None", ":", "\n", "    ", "import", "multiprocessing", "as", "mp", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.train.StandardTrain.__call__": [[17, 60], ["range", "train.StandardTrain.agent.train_mode", "train.StandardTrain.policy", "env.step", "train.debug_vectorized_experience", "train.StandardTrain.process_experience", "range", "train.StandardTrain.prioritized_replay.fit_density_model", "train.StandardTrain.prioritized_replay.update_priority", "env.reset", "time.sleep", "env.render", "train.StandardTrain.optimize", "isinstance"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.train_mode", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.train.debug_vectorized_experience", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.process_experience", "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.fit_density_model", "home.repos.pwc.inspect_result.spitis_mrl.replays.prioritized_replay.EntropyPrioritizedOnlineHERBuffer.update_priority", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.optimize"], ["args", ".", "num_envs", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "1", ")", "\n", "", "merge_args_into_config", "(", "args", ",", "config", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "min", "(", "8", ",", "args", ".", "num_envs", ")", ")", "\n", "torch", ".", "set_num_interop_threads", "(", "min", "(", "8", ",", "args", ".", "num_envs", ")", ")", "\n", "\n", "if", "config", ".", "gamma", "<", "1.", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "(", "1", "/", "(", "1", "-", "config", ".", "gamma", ")", ")", ",", "2", ")", ",", "0.", ")", "\n", "if", "config", ".", "gamma", "==", "1", ":", "config", ".", "clip_target_range", "=", "(", "np", ".", "round", "(", "-", "args", ".", "env_max_step", "-", "5", ",", "2", ")", ",", "0.", ")", "\n", "if", "args", ".", "sparse_reward_shaping", "or", "'sac'", "in", "args", ".", "alg", ".", "lower", "(", ")", ":", "\n", "    ", "config", ".", "clip_target_range", "=", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ")", "\n", "\n", "", "config", ".", "agent_name", "=", "make_agent_name", "(", "config", ",", "[", "'env'", ",", "'alg'", ",", "'tb'", ",", "'seed'", "]", ",", "prefix", "=", "args", ".", "prefix", ")", "\n", "\n", "# 6. Setup environments & add them to config, so modules can refer to them if need be", "\n", "env", ",", "eval_env", "=", "make_env", "(", "args", ")", "\n", "if", "args", ".", "first_visit_done", ":", "\n", "    ", "env1", ",", "eval_env1", "=", "env", ",", "eval_env", "\n", "env", "=", "lambda", ":", "FirstVisitDoneWrapper", "(", "env1", "(", ")", ")", "# Terminates the training episode on \"done\"", "\n", "eval_env", "=", "lambda", ":", "FirstVisitDoneWrapper", "(", "eval_env1", "(", ")", ")", "\n", "", "if", "args", ".", "first_visit_succ", ":", "\n", "    ", "config", ".", "first_visit_succ", "=", "True", "# Continues the training episode on \"done\", but counts it as if \"done\" (gamma = 0)", "\n", "", "if", "'dictpush'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "    ", "config", ".", "modalities", "=", "[", "'gripper'", ",", "'object'", ",", "'relative'", "]", "\n", "if", "'reach'", "in", "args", ".", "env", ".", "lower", "(", ")", ":", "\n", "      ", "config", ".", "goal_modalities", "=", "[", "'gripper_goal'", ",", "'object_goal'", "]", "\n", "", "else", ":", "\n", "      ", "config", ".", "goal_modalities", "=", "[", "'desired_goal'", "]", "\n", "", "config", ".", "achieved_goal", "=", "GoalEnvAchieved", "(", ")", "\n", "", "config", ".", "train_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "args", ".", "num_envs", ",", "seed", "=", "args", ".", "seed", ",", "modalities", "=", "config", ".", "modalities", ",", "goal_modalities", "=", "config", ".", "goal_modalities", ")", "\n", "config", ".", "eval_env", "=", "EnvModule", "(", "eval_env", ",", "num_envs", "=", "args", ".", "num_eval_envs", ",", "name", "=", "'eval_env'", ",", "seed", "=", "args", ".", "seed", "+", "1138", ",", "modalities", "=", "config", ".", "modalities", ",", "goal_modalities", "=", "config", ".", "goal_modalities", ")", "\n", "\n", "# 7. Setup / add modules to the config", "\n", "\n", "# Base Modules", "\n", "config", ".", "update", "(", "\n", "dict", "(", "\n", "trainer", "=", "StandardTrain", "(", ")", ",", "\n", "evaluation", "=", "EpisodicEval", "(", ")", ",", "\n", "policy", "=", "ActorPolicy", "(", ")", ",", "\n", "logger", "=", "Logger", "(", ")", ",", "\n", "state_normalizer", "=", "Normalizer", "(", "MeanStdNormalizer", "(", ")", ")", ",", "\n", "replay", "=", "OnlineHERBuffer", "(", ")", ",", "\n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.train.StandardTrain.reset_next": [[61, 64], ["None"], "methods", ["None"], ["# Goal Selection Modules", "\n", "if", "args", ".", "ag_curiosity", "is", "not", "None", ":", "\n", "    ", "config", ".", "ag_kde", "=", "RawKernelDensity", "(", "'ag'", ",", "optimize_every", "=", "4", ",", "samples", "=", "2000", ",", "kernel", "=", "args", ".", "kde_kernel", ",", "bandwidth", "=", "args", ".", "bandwidth", ",", "log_entropy", "=", "True", ")", "\n", "config", ".", "dg_kde", "=", "RawKernelDensity", "(", "'dg'", ",", "optimize_every", "=", "500", ",", "samples", "=", "5000", ",", "kernel", "=", "'tophat'", ",", "bandwidth", "=", "0.2", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.train.StandardTrain.save": [[65, 67], ["train.StandardTrain._save_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props"], ["config", ".", "ag_kde_tophat", "=", "RawKernelDensity", "(", "'ag'", ",", "optimize_every", "=", "100", ",", "samples", "=", "5000", ",", "kernel", "=", "'tophat'", ",", "bandwidth", "=", "0.2", ",", "tag", "=", "'_tophat'", ")", "\n", "if", "args", ".", "transition_to_dg", ":", "\n", "      ", "config", ".", "alpha_curiosity", "=", "CuriosityAlphaMixtureModule", "(", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.train.StandardTrain.load": [[68, 70], ["train.StandardTrain._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["\n", "", "use_qcutoff", "=", "not", "args", ".", "no_cutoff", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.train.debug_vectorized_experience": [[71, 98], ["mrl.utils.misc.AttrDict", "copy.deepcopy", "numpy.argwhere", "numpy.array", "isinstance", "isinstance", "range", "len"], "function", ["None"], ["if", "args", ".", "ag_curiosity", "==", "'minkde'", ":", "\n", "      ", "config", ".", "ag_curiosity", "=", "DensityAchievedGoalCuriosity", "(", "max_steps", "=", "args", ".", "env_max_step", ",", "num_sampled_ags", "=", "args", ".", "num_sampled_ags", ",", "use_qcutoff", "=", "use_qcutoff", ",", "keep_dg_percent", "=", "args", ".", "keep_dg_percent", ")", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "\n", "\n", "# Action Noise Modules", "\n", "", "", "if", "args", ".", "noise_type", ".", "lower", "(", ")", "==", "'gaussian'", ":", "noise_type", "=", "GaussianProcess", "\n", "if", "args", ".", "noise_type", ".", "lower", "(", ")", "==", "'ou'", ":", "noise_type", "=", "OrnsteinUhlenbeckProcess", "\n", "config", ".", "action_noise", "=", "ContinuousActionNoise", "(", "noise_type", ",", "std", "=", "ConstantSchedule", "(", "args", ".", "action_noise", ")", ")", "\n", "\n", "# Algorithm Modules", "\n", "if", "args", ".", "alg", ".", "lower", "(", ")", "==", "'ddpg'", ":", "\n", "    ", "config", ".", "algorithm", "=", "DDPG", "(", ")", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'td3'", ":", "\n", "    ", "config", ".", "algorithm", "=", "TD3", "(", ")", "\n", "config", ".", "target_network_update_freq", "*=", "2", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'sac'", ":", "\n", "    ", "config", ".", "algorithm", "=", "SAC", "(", ")", "\n", "", "elif", "args", ".", "alg", ".", "lower", "(", ")", "==", "'dqn'", ":", "\n", "    ", "config", ".", "algorithm", "=", "DQN", "(", ")", "\n", "config", ".", "policy", "=", "QValuePolicy", "(", ")", "\n", "config", ".", "qvalue_lr", "=", "config", ".", "critic_lr", "\n", "config", ".", "qvalue_weight_decay", "=", "config", ".", "actor_weight_decay", "\n", "config", ".", "double_q", "=", "True", "\n", "config", ".", "random_action_prob", "=", "LinearSchedule", "(", "1.0", ",", "config", ".", "eexplore", ",", "1e5", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.GoalEnvReward.__init__": [[7, 11], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Wraps environment's compute reward function\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "'goal_reward'", ",", "required_agent_modules", "=", "[", "'env'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.GoalEnvReward._setup": [[12, 15], ["hasattr"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "env", ".", "goal_env", ",", "\"Environment must be a goal environment!\"", "\n", "assert", "hasattr", "(", "self", ".", "env", ",", "'compute_reward'", ")", ",", "\"Environment must have compute reward defined!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.GoalEnvReward.__call__": [[16, 18], ["goal_modules.GoalEnvReward.env.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "__call__", "(", "self", ",", "achieved_goals", ",", "goals", ",", "info", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "compute_reward", "(", "achieved_goals", ",", "goals", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.GoalEnvAchieved.__init__": [[20, 24], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Wraps environment's achieved goal function\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "'achieved_goal'", ",", "required_agent_modules", "=", "[", "'env'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.GoalEnvAchieved._setup": [[25, 28], ["hasattr"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "env", ".", "goal_env", ",", "\"Environment must be a goal environment!\"", "\n", "assert", "hasattr", "(", "self", ".", "env", ",", "'achieved_goal'", ")", ",", "\"Environment must have achieved_goal defined!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.GoalEnvAchieved.__call__": [[29, 31], ["goal_modules.GoalEnvAchieved.env.achieved_goal"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPushAndReach.achieved_goal"], ["", "def", "__call__", "(", "self", ",", "observation", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "achieved_goal", "(", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.NeighborReward.__init__": [[34, 46], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "max_neighbor_distance", "=", "1", ",", "optimize_every", "=", "5", ",", "batch_size", "=", "1000", ",", "temperature", "=", "1.", ")", ":", "\n", "    ", "\"\"\"Wraps environment's compute reward function. Should probably only be used for first-visit achievment.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "'goal_reward'", ",", "required_agent_modules", "=", "[", "'replay_buffer'", ",", "'neighbor_embedding_network'", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n", "if", "max_neighbor_distance", "!=", "1", ":", "# this is the number of steps from which to count two goals as neighbors.", "\n", "      ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.NeighborReward._setup": [[47, 55], ["hasattr", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "goal_modules.NeighborReward.neighbor_embedding_network.model.parameters"], "methods", ["None"], ["", "", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "env", ".", "goal_env", ",", "\"Environment must be a goal environment!\"", "\n", "assert", "hasattr", "(", "self", ".", "env", ",", "'compute_reward'", ")", ",", "\"Environment must have compute reward defined!\"", "\n", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "neighbor_embedding_network", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", ".", "critic_lr", ",", "# just using critic hparams for now", "\n", "weight_decay", "=", "self", ".", "config", ".", "critic_weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.NeighborReward._optimize": [[56, 98], ["len", "numpy.random.randint", "ag_buffer.get_batch", "pag_buffer.get_batch", "ags[].copy", "numpy.roll", "goal_modules.NeighborReward.torch", "goal_modules.NeighborReward.torch", "goal_modules.NeighborReward.torch", "goal_modules.NeighborReward.neighbor_embedding_network", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "goal_modules.NeighborReward.logger.add_tabular", "goal_modules.NeighborReward.optimizer.zero_grad", "loss.backward", "goal_modules.NeighborReward.optimizer.step", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "goal_modules.NeighborReward.numpy", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "len", "len", "len", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_tabular", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "pag_buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_previous_ag", "\n", "ag_buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "ag_buffer", ")", ":", "\n", "      ", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "ag_buffer", ")", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "\n", "ags", "=", "ag_buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "pos", "=", "pag_buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "\n", "# mix it up to keep it symmetric for now...", "\n", "temp", "=", "ags", "[", ":", "len", "(", "ags", ")", "//", "2", "]", ".", "copy", "(", ")", "\n", "ags", "[", ":", "len", "(", "ags", ")", "//", "2", "]", "=", "pos", "[", ":", "len", "(", "ags", ")", "//", "2", "]", "\n", "pos", "[", ":", "len", "(", "ags", ")", "//", "2", "]", "=", "temp", "\n", "\n", "# get random negative samples by a 1 index roll", "\n", "neg", "=", "np", ".", "roll", "(", "pos", ",", "1", ",", "axis", "=", "0", ")", "\n", "\n", "# move to torch", "\n", "ags", "=", "self", ".", "torch", "(", "ags", ")", "\n", "pos", "=", "self", ".", "torch", "(", "pos", ")", "\n", "neg", "=", "self", ".", "torch", "(", "neg", ")", "\n", "\n", "# get embeddings", "\n", "embs", "=", "self", ".", "neighbor_embedding_network", "(", "torch", ".", "cat", "(", "(", "ags", ",", "pos", ",", "neg", ")", ",", "dim", "=", "0", ")", ")", "\n", "ags", ",", "pos", ",", "neg", "=", "torch", ".", "chunk", "(", "embs", ",", "3", ")", "\n", "\n", "pos_logits", "=", "-", "self", ".", "temperature", "*", "torch", ".", "norm", "(", "ags", "-", "pos", ",", "dim", "=", "1", ")", "\n", "neg_logits", "=", "-", "self", ".", "temperature", "*", "torch", ".", "norm", "(", "ags", "-", "neg", ",", "dim", "=", "1", ")", "\n", "\n", "# use soft targets", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "torch", ".", "exp", "(", "pos_logits", ")", ",", "torch", ".", "ones_like", "(", "pos_logits", ")", "*", "0.99", ")", "+", "F", ".", "binary_cross_entropy_with_logits", "(", "torch", ".", "exp", "(", "neg_logits", ")", ",", "torch", ".", "ones_like", "(", "pos_logits", ")", "*", "0.01", ")", "\n", "\n", "\n", "self", ".", "logger", ".", "add_tabular", "(", "'intrinsic_reward_loss'", ",", "self", ".", "numpy", "(", "loss", ")", ")", "\n", "\n", "# optimize", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.NeighborReward.__call__": [[99, 115], ["achieved_goals.reshape", "goals.reshape", "goal_modules.NeighborReward.torch", "goal_modules.NeighborReward.torch", "goal_modules.NeighborReward.neighbor_embedding_network", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "goal_modules.NeighborReward.numpy().astype", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "goal_modules.NeighborReward.numpy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "def", "__call__", "(", "self", ",", "achieved_goals", ",", "goals", ",", "info", ")", ":", "\n", "    ", "\"\"\"Should return 0 for ags, gs that are predicted to be neighbors, -1 otherwise, as a numpy array\"\"\"", "\n", "ags", "=", "achieved_goals", ".", "reshape", "(", "-", "1", ",", "achieved_goals", ".", "shape", "[", "-", "1", "]", ")", "\n", "dgs", "=", "goals", ".", "reshape", "(", "-", "1", ",", "achieved_goals", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "ags", "=", "self", ".", "torch", "(", "ags", ")", "\n", "dgs", "=", "self", ".", "torch", "(", "dgs", ")", "\n", "\n", "# get embeddings", "\n", "embs", "=", "self", ".", "neighbor_embedding_network", "(", "torch", ".", "cat", "(", "(", "ags", ",", "dgs", ")", ",", "dim", "=", "0", ")", ")", "\n", "ags", ",", "dgs", "=", "torch", ".", "chunk", "(", "embs", ",", "2", ")", "\n", "\n", "# predict whether ags and dgs are transition neighbors", "\n", "preds", "=", "torch", ".", "exp", "(", "-", "self", ".", "temperature", "*", "torch", ".", "norm", "(", "ags", "-", "dgs", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "-", "self", ".", "numpy", "(", "preds", "<", "0.5", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.NeighborReward.save": [[116, 121], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "goal_modules.NeighborReward.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'opt_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.goal_modules.NeighborReward.load": [[128, 130], ["goal_modules.NeighborReward._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "'random_process'", "]", ",", "save_folder", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.__init__": [[28, 37], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "num_sampled_ags", "=", "500", ",", "max_steps", "=", "50", ",", "keep_dg_percent", "=", "-", "1e-1", ",", "randomize", "=", "False", ",", "use_qcutoff", "=", "True", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'ag_curiosity'", ",", "\n", "required_agent_modules", "=", "[", "'env'", ",", "'replay_buffer'", ",", "'actor'", ",", "'critic'", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "num_sampled_ags", "=", "num_sampled_ags", "\n", "self", ".", "max_steps", "=", "max_steps", "#TODO: have this be learned from past trajectories?", "\n", "self", ".", "keep_dg_percent", "=", "keep_dg_percent", "\n", "self", ".", "randomize", "=", "randomize", "\n", "self", ".", "use_qcutoff", "=", "use_qcutoff", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity._setup": [[38, 60], ["isinstance", "numpy.zeros", "max", "numpy.zeros", "numpy.zeros", "collections.deque", "min"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "OnlineHERBuffer", ")", "\n", "assert", "self", ".", "env", ".", "goal_env", "\n", "\n", "self", ".", "n_envs", "=", "self", ".", "env", ".", "num_envs", "\n", "self", ".", "current_goals", "=", "None", "\n", "self", ".", "replaced_goal", "=", "np", ".", "zeros", "(", "(", "self", ".", "env", ".", "num_envs", ",", ")", ")", "\n", "\n", "# setup cutoff", "\n", "if", "self", ".", "config", ".", "gamma", "<", "1.", ":", "\n", "      ", "r", "=", "min", "(", "self", ".", "config", ".", "gamma", ",", "0.99", ")", "\n", "self", ".", "min_min_cutoff", "=", "-", "(", "1", "-", "r", "**", "(", "self", ".", "max_steps", "*", "0.8", ")", ")", "/", "(", "1", "-", "r", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "min_min_cutoff", "=", "-", "self", ".", "max_steps", "*", "0.8", "\n", "", "self", ".", "min_cutoff", "=", "max", "(", "self", ".", "config", ".", "initial_cutoff", ",", "self", ".", "min_min_cutoff", ")", "\n", "self", ".", "cutoff", "=", "self", ".", "min_cutoff", "\n", "\n", "# go explore + success accounting", "\n", "self", ".", "go_explore", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_envs", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "is_success", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_envs", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "successes_deque", "=", "deque", "(", "maxlen", "=", "10", ")", "# for dynamic cutoff", "\n", "self", ".", "successes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity._manage_resets_and_success_behaviors": [[61, 84], ["enumerate", "numpy.array", "numpy.random.random", "reset_idxs.append", "overshooting_idxs.append", "overshooting_proposals.append", "curiosity.AchievedGoalCuriosity.config.get", "numpy.random.random", "curiosity.generate_overshooting_goals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.generate_overshooting_goals"], ["", "def", "_manage_resets_and_success_behaviors", "(", "self", ",", "experience", ",", "close", ")", ":", "\n", "    ", "\"\"\" Manage (1) end of trajectory, (2) early resets, (3) go explore and overshot goals \"\"\"", "\n", "reset_idxs", ",", "overshooting_idxs", ",", "overshooting_proposals", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", ",", "over", "in", "enumerate", "(", "experience", ".", "trajectory_over", ")", ":", "\n", "      ", "if", "over", ":", "# if over update it", "\n", "        ", "self", ".", "current_goals", "[", "i", "]", "=", "experience", ".", "reset_state", "[", "'desired_goal'", "]", "[", "i", "]", "\n", "self", ".", "replaced_goal", "[", "i", "]", "=", "0.", "\n", "if", "np", ".", "random", ".", "random", "(", ")", "<", "(", "self", ".", "go_explore", "[", "i", "]", "*", "self", ".", "config", ".", "go_reset_percent", ")", ":", "\n", "          ", "reset_idxs", ".", "append", "(", "i", ")", "\n", "\n", "", "", "if", "not", "over", "and", "close", "[", "i", "]", ":", "# if not over and success, modify go_explore; maybe overshoot goal?", "\n", "        ", "self", ".", "is_success", "[", "i", "]", "+=", "1.", "\n", "self", ".", "go_explore", "[", "i", "]", "+=", "1.", "\n", "\n", "if", "not", "self", ".", "config", ".", "get", "(", "'never_done'", ")", "and", "np", ".", "random", ".", "random", "(", ")", "<", "self", ".", "config", ".", "overshoot_goal_percent", ":", "\n", "          ", "step_amount", "=", "experience", ".", "next_state", "[", "'achieved_goal'", "]", "[", "i", "]", "-", "experience", ".", "state", "[", "'achieved_goal'", "]", "[", "i", "]", "\n", "overshooting_idxs", ".", "append", "(", "i", ")", "\n", "overshooting_proposals", ".", "append", "(", "\n", "generate_overshooting_goals", "(", "self", ".", "num_sampled_ags", ",", "step_amount", ",", "self", ".", "config", ".", "direct_overshoots", ",", "\n", "self", ".", "current_goals", "[", "i", "]", ")", ")", "\n", "\n", "", "", "", "return", "reset_idxs", ",", "overshooting_idxs", ",", "np", ".", "array", "(", "overshooting_proposals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity._overshoot_goals": [[85, 113], ["len", "numpy.tile", "numpy.concatenate().reshape", "curiosity.AchievedGoalCuriosity.score_goals", "numpy.argmin", "numpy.sum", "zip", "curiosity.AchievedGoalCuriosity.compute_q", "q_values.reshape.reshape.reshape", "mrl.utils.misc.AttrDict", "curiosity.AchievedGoalCuriosity.dg_kde.evaluate_log_density", "dg_scores.reshape.reshape.reshape", "numpy.eye", "numpy.concatenate", "overshooting_proposals.reshape"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.EntropyGainScoringGoalCuriosity.score_goals", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.compute_q", "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.evaluate_log_density"], ["", "def", "_overshoot_goals", "(", "self", ",", "experience", ",", "overshooting_idxs", ",", "overshooting_proposals", ")", ":", "\n", "#score the proposals", "\n", "    ", "num_proposals", "=", "overshooting_proposals", ".", "shape", "[", "1", "]", "\n", "num_idxs", "=", "len", "(", "overshooting_idxs", ")", "\n", "states", "=", "np", ".", "tile", "(", "experience", ".", "reset_state", "[", "'observation'", "]", "[", "overshooting_idxs", ",", "None", ",", ":", "]", ",", "(", "1", ",", "num_proposals", ",", "1", ")", ")", "\n", "states", "=", "np", ".", "concatenate", "(", "(", "states", ",", "overshooting_proposals", ")", ",", "-", "1", ")", ".", "reshape", "(", "num_proposals", "*", "num_idxs", ",", "-", "1", ")", "\n", "\n", "bad_q_idxs", ",", "q_values", "=", "[", "]", ",", "None", "\n", "if", "self", ".", "use_qcutoff", ":", "\n", "      ", "q_values", "=", "self", ".", "compute_q", "(", "states", ")", "\n", "q_values", "=", "q_values", ".", "reshape", "(", "num_idxs", ",", "num_proposals", ")", "\n", "bad_q_idxs", "=", "q_values", "<", "self", ".", "cutoff", "\n", "", "goal_values", "=", "self", ".", "score_goals", "(", "overshooting_proposals", ",", "AttrDict", "(", "q_values", "=", "q_values", ",", "states", "=", "states", ")", ")", "\n", "\n", "if", "self", ".", "config", ".", "dg_score_multiplier", ">", "1.", "and", "self", ".", "dg_kde", ".", "ready", ":", "\n", "      ", "dg_scores", "=", "self", ".", "dg_kde", ".", "evaluate_log_density", "(", "overshooting_proposals", ".", "reshape", "(", "num_proposals", "*", "num_idxs", ",", "-", "1", ")", ")", "\n", "dg_scores", "=", "dg_scores", ".", "reshape", "(", "num_idxs", ",", "num_proposals", ")", "\n", "goal_values", "[", "dg_scores", ">", "-", "np", ".", "inf", "]", "*=", "self", ".", "config", ".", "dg_score_multiplier", "\n", "\n", "", "goal_values", "[", "bad_q_idxs", "]", "=", "q_values", "[", "bad_q_idxs", "]", "*", "-", "1e-8", "\n", "\n", "chosen_idx", "=", "np", ".", "argmin", "(", "goal_values", ",", "axis", "=", "1", ")", "\n", "chosen_idx", "=", "np", ".", "eye", "(", "num_proposals", ")", "[", "chosen_idx", "]", "# shape(sampled_ags) = n_envs x num_proposals", "\n", "chosen_ags", "=", "np", ".", "sum", "(", "overshooting_proposals", "*", "chosen_idx", "[", ":", ",", ":", ",", "None", "]", ",", "axis", "=", "1", ")", "# n_envs x goal_feats", "\n", "\n", "for", "idx", ",", "goal", "in", "zip", "(", "overshooting_idxs", ",", "chosen_ags", ")", ":", "\n", "      ", "self", ".", "current_goals", "[", "idx", "]", "=", "goal", "\n", "self", ".", "replaced_goal", "[", "idx", "]", "=", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity._process_experience": [[114, 228], ["curiosity.AchievedGoalCuriosity.env.compute_reward", "curiosity.AchievedGoalCuriosity._manage_resets_and_success_behaviors", "curiosity.AchievedGoalCuriosity.train.reset_next", "len", "curiosity.AchievedGoalCuriosity._overshoot_goals", "numpy.any", "len", "numpy.random.randint", "ag_buffer.get_batch", "sampled_ags.reshape.reshape.reshape", "numpy.tile", "numpy.concatenate().reshape", "numpy.concatenate", "numpy.concatenate", "curiosity.AchievedGoalCuriosity.score_goals", "numpy.sum", "hasattr", "numpy.logical_or().astype.reshape", "range", "len", "curiosity.AchievedGoalCuriosity.compute_q", "numpy.split", "q_values.reshape.reshape.reshape", "numpy.min", "mrl.utils.misc.AttrDict", "curiosity.AchievedGoalCuriosity.dg_kde.evaluate_log_density", "dg_scores.reshape.reshape.reshape", "numpy.abs", "numpy.argmin", "numpy.eye", "numpy.ones", "hasattr", "curiosity.AchievedGoalCuriosity.logger.add_scalar", "curiosity.AchievedGoalCuriosity.logger.add_scalar", "numpy.concatenate", "len", "max", "numpy.mean", "sampled_ags.reshape.reshape.reshape", "numpy.sum", "numpy.logical_or().astype", "len", "curiosity.AchievedGoalCuriosity.logger.add_histogram", "numpy.mean", "curiosity.AchievedGoalCuriosity.successes.append", "curiosity.AchievedGoalCuriosity.successes_deque.append", "min", "max", "curiosity.AchievedGoalCuriosity.successes_deque.clear", "numpy.random.uniform", "float", "float", "numpy.min", "max", "curiosity.AchievedGoalCuriosity.successes_deque.clear", "normalized_values.cumsum", "numpy.logical_or", "min", "numpy.random.rand", "numpy.random.random", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity._manage_resets_and_success_behaviors", "home.repos.pwc.inspect_result.spitis_mrl.modules.train.StandardTrain.reset_next", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity._overshoot_goals", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.EntropyGainScoringGoalCuriosity.score_goals", "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.compute_q", "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.evaluate_log_density", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "def", "_process_experience", "(", "self", ",", "experience", ")", ":", "\n", "    ", "\"\"\"Curiosity module updates the desired goal depending on experience.trajectory_over\"\"\"", "\n", "ag_buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", ".", "buffer_ag", "\n", "\n", "if", "self", ".", "current_goals", "is", "None", ":", "\n", "      ", "self", ".", "current_goals", "=", "experience", ".", "reset_state", "[", "'desired_goal'", "]", "\n", "\n", "", "computed_reward", "=", "self", ".", "env", ".", "compute_reward", "(", "experience", ".", "next_state", "[", "'achieved_goal'", "]", ",", "self", ".", "current_goals", ",", "\n", "{", "'s'", ":", "experience", ".", "state", "[", "'observation'", "]", ",", "'a'", ":", "experience", ".", "action", ",", "'ns'", ":", "experience", ".", "next_state", "[", "'observation'", "]", "}", ")", "\n", "close", "=", "computed_reward", ">", "-", "0.15", "\n", "\n", "# First, manage the episode resets & any special behavior that occurs on goal achievement, like go explore / resets / overshooting", "\n", "reset_idxs", ",", "overshooting_idxs", ",", "overshooting_proposals", "=", "self", ".", "_manage_resets_and_success_behaviors", "(", "experience", ",", "close", ")", "\n", "\n", "if", "reset_idxs", ":", "\n", "      ", "self", ".", "train", ".", "reset_next", "(", "reset_idxs", ")", "\n", "\n", "", "if", "overshooting_idxs", "and", "len", "(", "ag_buffer", ")", ":", "\n", "      ", "self", ".", "_overshoot_goals", "(", "experience", ",", "overshooting_idxs", ",", "overshooting_proposals", ")", "\n", "\n", "# Now consider replacing the current goals with something else:", "\n", "", "if", "np", ".", "any", "(", "experience", ".", "trajectory_over", ")", "and", "len", "(", "ag_buffer", ")", ":", "\n", "# sample some achieved goals", "\n", "      ", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "ag_buffer", ")", ",", "size", "=", "self", ".", "num_sampled_ags", "*", "self", ".", "n_envs", ")", "\n", "sampled_ags", "=", "ag_buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "sampled_ags", "=", "sampled_ags", ".", "reshape", "(", "self", ".", "n_envs", ",", "self", ".", "num_sampled_ags", ",", "-", "1", ")", "\n", "\n", "# compute the q-values of both the sampled achieved goals and the current goals", "\n", "states", "=", "np", ".", "tile", "(", "experience", ".", "reset_state", "[", "'observation'", "]", "[", ":", ",", "None", ",", ":", "]", ",", "(", "1", ",", "self", ".", "num_sampled_ags", ",", "1", ")", ")", "\n", "states", "=", "np", ".", "concatenate", "(", "(", "states", ",", "sampled_ags", ")", ",", "-", "1", ")", ".", "reshape", "(", "self", ".", "num_sampled_ags", "*", "self", ".", "n_envs", ",", "-", "1", ")", "\n", "states_curr", "=", "np", ".", "concatenate", "(", "(", "experience", ".", "reset_state", "[", "'observation'", "]", ",", "self", ".", "current_goals", ")", ",", "-", "1", ")", "\n", "states_cat", "=", "np", ".", "concatenate", "(", "(", "states", ",", "states_curr", ")", ",", "0", ")", "\n", "\n", "bad_q_idxs", ",", "q_values", "=", "[", "]", ",", "None", "\n", "if", "self", ".", "use_qcutoff", ":", "\n", "        ", "q_values", "=", "self", ".", "compute_q", "(", "states_cat", ")", "\n", "q_values", ",", "curr_q", "=", "np", ".", "split", "(", "q_values", ",", "[", "self", ".", "num_sampled_ags", "*", "self", ".", "n_envs", "]", ")", "\n", "q_values", "=", "q_values", ".", "reshape", "(", "self", ".", "n_envs", ",", "self", ".", "num_sampled_ags", ")", "\n", "\n", "# Set cutoff dynamically by using intrinsic_success_percent", "\n", "if", "len", "(", "self", ".", "successes_deque", ")", "==", "10", ":", "\n", "          ", "self", ".", "min_cutoff", "=", "max", "(", "self", ".", "min_min_cutoff", ",", "min", "(", "np", ".", "min", "(", "q_values", ")", ",", "self", ".", "min_cutoff", ")", ")", "\n", "intrinsic_success_percent", "=", "np", ".", "mean", "(", "self", ".", "successes_deque", ")", "\n", "if", "intrinsic_success_percent", ">=", "self", ".", "config", ".", "cutoff_success_threshold", "[", "1", "]", ":", "\n", "            ", "self", ".", "cutoff", "=", "max", "(", "self", ".", "min_cutoff", ",", "self", ".", "cutoff", "-", "1.", ")", "\n", "self", ".", "successes_deque", ".", "clear", "(", ")", "\n", "", "elif", "intrinsic_success_percent", "<=", "self", ".", "config", ".", "cutoff_success_threshold", "[", "0", "]", ":", "\n", "            ", "self", ".", "cutoff", "=", "max", "(", "min", "(", "self", ".", "config", ".", "initial_cutoff", ",", "self", ".", "cutoff", "+", "1.", ")", ",", "self", ".", "min_min_cutoff", ")", "\n", "self", ".", "successes_deque", ".", "clear", "(", ")", "\n", "\n", "# zero out the \"bad\" values. This practically eliminates them as candidates if any goals are viable.", "\n", "", "", "bad_q_idxs", "=", "q_values", "<", "self", ".", "cutoff", "\n", "q_values", "[", "bad_q_idxs", "]", "*=", "-", "1", "\n", "min_q_values", "=", "np", ".", "min", "(", "q_values", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "# num_envs x1", "\n", "q_values", "[", "bad_q_idxs", "]", "*=", "-", "1", "\n", "\n", "# score the goals -- lower is better", "\n", "", "goal_values", "=", "self", ".", "score_goals", "(", "sampled_ags", ",", "AttrDict", "(", "q_values", "=", "q_values", ",", "states", "=", "states", ")", ")", "\n", "\n", "if", "self", ".", "config", ".", "dg_score_multiplier", ">", "1.", "and", "self", ".", "dg_kde", ".", "ready", ":", "\n", "        ", "dg_scores", "=", "self", ".", "dg_kde", ".", "evaluate_log_density", "(", "sampled_ags", ".", "reshape", "(", "self", ".", "n_envs", "*", "self", ".", "num_sampled_ags", ",", "-", "1", ")", ")", "\n", "dg_scores", "=", "dg_scores", ".", "reshape", "(", "self", ".", "n_envs", ",", "self", ".", "num_sampled_ags", ")", "\n", "goal_values", "[", "dg_scores", ">", "-", "np", ".", "inf", "]", "*=", "self", ".", "config", ".", "dg_score_multiplier", "\n", "\n", "", "if", "q_values", "is", "not", "None", ":", "\n", "        ", "goal_values", "[", "bad_q_idxs", "]", "=", "q_values", "[", "bad_q_idxs", "]", "*", "-", "1e-8", "\n", "\n", "", "if", "self", ".", "randomize", ":", "# sample proportional to the absolute score", "\n", "        ", "abs_goal_values", "=", "np", ".", "abs", "(", "goal_values", ")", "\n", "normalized_values", "=", "abs_goal_values", "/", "np", ".", "sum", "(", "abs_goal_values", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "chosen_idx", "=", "(", "normalized_values", ".", "cumsum", "(", "1", ")", ">", "np", ".", "random", ".", "rand", "(", "normalized_values", ".", "shape", "[", "0", "]", ")", "[", ":", ",", "None", "]", ")", ".", "argmax", "(", "1", ")", "\n", "", "else", ":", "# take minimum", "\n", "        ", "chosen_idx", "=", "np", ".", "argmin", "(", "goal_values", ",", "axis", "=", "1", ")", "\n", "\n", "", "chosen_idx", "=", "np", ".", "eye", "(", "self", ".", "num_sampled_ags", ")", "[", "chosen_idx", "]", "# shape(sampled_ags) = n_envs x num_sampled_ags", "\n", "if", "q_values", "is", "not", "None", ":", "\n", "        ", "chosen_q_val", "=", "(", "chosen_idx", "*", "q_values", ")", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "", "chosen_ags", "=", "np", ".", "sum", "(", "sampled_ags", "*", "chosen_idx", "[", ":", ",", ":", ",", "None", "]", ",", "axis", "=", "1", ")", "# n_envs x goal_feats", "\n", "\n", "# replace goal always when first_visit_succ (relying on the dg_score_multiplier to dg focus), otherwise", "\n", "# we are going to transition into the dgs using the ag_kde_tophat", "\n", "if", "hasattr", "(", "self", ",", "'curiosity_alpha'", ")", ":", "\n", "        ", "if", "self", ".", "use_qcutoff", ":", "\n", "          ", "replace_goal", "=", "np", ".", "logical_or", "(", "(", "np", ".", "random", ".", "random", "(", "(", "self", ".", "n_envs", ",", "1", ")", ")", ">", "self", ".", "curiosity_alpha", ".", "alpha", ")", ",", "\n", "curr_q", "<", "self", ".", "cutoff", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "          ", "replace_goal", "=", "(", "np", ".", "random", ".", "random", "(", "(", "self", ".", "n_envs", ",", "1", ")", ")", ">", "self", ".", "curiosity_alpha", ".", "alpha", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "replace_goal", "=", "np", ".", "ones", "(", "(", "self", ".", "n_envs", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# sometimes keep the desired goal anyways", "\n", "", "replace_goal", "*=", "(", "np", ".", "random", ".", "uniform", "(", "size", "=", "[", "self", ".", "n_envs", ",", "1", "]", ")", ">", "self", ".", "keep_dg_percent", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "new_goals", "=", "replace_goal", "*", "chosen_ags", "+", "(", "1", "-", "replace_goal", ")", "*", "self", ".", "current_goals", "\n", "\n", "if", "hasattr", "(", "self", ",", "'logger'", ")", "and", "len", "(", "self", ".", "successes", ")", ">", "50", ":", "\n", "        ", "if", "q_values", "is", "not", "None", ":", "\n", "          ", "self", ".", "logger", ".", "add_histogram", "(", "'Explore/Goal_q'", ",", "replace_goal", "*", "chosen_q_val", "+", "(", "1", "-", "replace_goal", ")", "*", "curr_q", ")", "\n", "", "self", ".", "logger", ".", "add_scalar", "(", "'Explore/Intrinsic_success_percent'", ",", "np", ".", "mean", "(", "self", ".", "successes", ")", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Explore/Cutoff'", ",", "self", ".", "cutoff", ")", "\n", "self", ".", "successes", "=", "[", "]", "\n", "\n", "", "replace_goal", "=", "replace_goal", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_envs", ")", ":", "\n", "        ", "if", "experience", ".", "trajectory_over", "[", "i", "]", ":", "\n", "          ", "self", ".", "successes", ".", "append", "(", "float", "(", "self", ".", "is_success", "[", "i", ",", "0", "]", ">=", "1.", ")", ")", "# compromise due to exploration", "\n", "self", ".", "successes_deque", ".", "append", "(", "float", "(", "self", ".", "is_success", "[", "i", ",", "0", "]", ">=", "1.", ")", ")", "# compromise due to exploration", "\n", "self", ".", "current_goals", "[", "i", "]", "=", "new_goals", "[", "i", "]", "\n", "if", "replace_goal", "[", "i", "]", ":", "\n", "            ", "self", ".", "replaced_goal", "[", "i", "]", "=", "1.", "\n", "", "self", ".", "go_explore", "[", "i", "]", "=", "0.", "\n", "self", ".", "is_success", "[", "i", "]", "=", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.compute_q": [[229, 236], ["curiosity.AchievedGoalCuriosity.state_normalizer().astype", "curiosity.AchievedGoalCuriosity.torch", "curiosity.AchievedGoalCuriosity.actor", "isinstance", "curiosity.AchievedGoalCuriosity.numpy", "curiosity.AchievedGoalCuriosity.critic", "curiosity.AchievedGoalCuriosity.state_normalizer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "", "", "def", "compute_q", "(", "self", ",", "numpy_states", ")", ":", "\n", "    ", "numpy_states", "=", "self", ".", "state_normalizer", "(", "numpy_states", ",", "update", "=", "False", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "states", "=", "self", ".", "torch", "(", "numpy_states", ")", "\n", "max_actions", "=", "self", ".", "actor", "(", "states", ")", "\n", "if", "isinstance", "(", "max_actions", ",", "tuple", ")", ":", "\n", "      ", "max_actions", "=", "max_actions", "[", "0", "]", "\n", "", "return", "self", ".", "numpy", "(", "self", ".", "critic", "(", "states", ",", "max_actions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.relabel_state": [[237, 246], ["None"], "methods", ["None"], ["", "def", "relabel_state", "(", "self", ",", "state", ")", ":", "\n", "    ", "\"\"\"Should be called by the policy module to relabel states with intrinsic goals\"\"\"", "\n", "if", "self", ".", "current_goals", "is", "None", ":", "\n", "      ", "return", "state", "\n", "\n", "", "return", "{", "\n", "'observation'", ":", "state", "[", "'observation'", "]", ",", "\n", "'achieved_goal'", ":", "state", "[", "'achieved_goal'", "]", ",", "\n", "'desired_goal'", ":", "self", ".", "current_goals", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.score_goals": [[248, 251], ["None"], "methods", ["None"], ["", "def", "score_goals", "(", "self", ",", "sampled_ags", ",", "info", ")", ":", "\n", "    ", "\"\"\" Lower is better \"\"\"", "\n", "raise", "NotImplementedError", "# SUBCLASS THIS!", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.save": [[252, 254], ["curiosity.AchievedGoalCuriosity._save_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_save_props", "(", "[", "'cutoff'", ",", "'min_cutoff'", "]", ",", "save_folder", ")", "#can restart keeping track of successes / go explore", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.AchievedGoalCuriosity.load": [[255, 257], ["curiosity.AchievedGoalCuriosity._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "'cutoff'", ",", "'min_cutoff'", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.QAchievedGoalCuriosity.score_goals": [[263, 270], ["numpy.copy", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["def", "score_goals", "(", "self", ",", "sampled_ags", ",", "info", ")", ":", "\n", "    ", "scores", "=", "np", ".", "copy", "(", "info", ".", "q_values", ")", "\n", "max_score", "=", "np", ".", "max", "(", "scores", ")", "\n", "if", "max_score", ">", "0", ":", "\n", "      ", "scores", "-=", "max_score", "# so all scores negative", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.SuccessAchievedGoalCuriosity._setup": [[276, 279], ["curiosity.AchievedGoalCuriosity._setup"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup"], ["def", "_setup", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "_setup", "(", ")", "\n", "self", ".", "use_qcutoff", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.SuccessAchievedGoalCuriosity.score_goals": [[280, 289], ["curiosity.SuccessAchievedGoalCuriosity.success_predictor().reshape", "numpy.abs", "curiosity.SuccessAchievedGoalCuriosity.success_predictor"], "methods", ["None"], ["", "def", "score_goals", "(", "self", ",", "sampled_ags", ",", "info", ")", ":", "\n", "\n", "# sampled_ags is np.array of shape NUM_ENVS x NUM_SAMPLED_GOALS (both arbitrary)", "\n", "    ", "num_envs", ",", "num_sampled_ags", "=", "sampled_ags", ".", "shape", "[", ":", "2", "]", "\n", "\n", "scores", "=", "self", ".", "success_predictor", "(", "info", ".", "states", ")", ".", "reshape", "(", "num_envs", ",", "num_sampled_ags", ")", "# these are predicted success %", "\n", "scores", "=", "-", "0.5", "+", "np", ".", "abs", "(", "scores", "-", "0.5", ")", "# rank by distance to 0.5, lower is closer to 0.5", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.DensityAchievedGoalCuriosity.__init__": [[298, 303], ["curiosity.AchievedGoalCuriosity.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "density_module", "=", "'ag_kde'", ",", "interest_module", "=", "'ag_interest'", ",", "alpha", "=", "-", "1.0", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "density_module", "=", "density_module", "\n", "self", ".", "interest_module", "=", "interest_module", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.DensityAchievedGoalCuriosity._setup": [[304, 307], ["hasattr", "curiosity.AchievedGoalCuriosity._setup"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "hasattr", "(", "self", ",", "self", ".", "density_module", ")", "\n", "super", "(", ")", ".", "_setup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.DensityAchievedGoalCuriosity.score_goals": [[308, 337], ["getattr", "hasattr", "sampled_ags.reshape", "getattr.evaluate_log_density", "sampled_ag_scores.reshape.reshape.reshape", "mrl.utils.misc.softmax", "getattr._optimize", "getattr", "getattr.evaluate_log_interest"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.evaluate_log_density", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.mega.train_mega.SweepSafetyInterest.evaluate_log_interest"], ["", "def", "score_goals", "(", "self", ",", "sampled_ags", ",", "info", ")", ":", "\n", "    ", "\"\"\" Lower is better \"\"\"", "\n", "density_module", "=", "getattr", "(", "self", ",", "self", ".", "density_module", ")", "\n", "if", "not", "density_module", ".", "ready", ":", "\n", "      ", "density_module", ".", "_optimize", "(", "force", "=", "True", ")", "\n", "", "interest_module", "=", "None", "\n", "if", "hasattr", "(", "self", ",", "self", ".", "interest_module", ")", ":", "\n", "      ", "interest_module", "=", "getattr", "(", "self", ",", "self", ".", "interest_module", ")", "\n", "if", "not", "interest_module", ".", "ready", ":", "\n", "        ", "interest_module", "=", "None", "\n", "\n", "# sampled_ags is np.array of shape NUM_ENVS x NUM_SAMPLED_GOALS (both arbitrary)", "\n", "", "", "num_envs", ",", "num_sampled_ags", "=", "sampled_ags", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# score the sampled_ags to get log densities, and exponentiate to get densities", "\n", "flattened_sampled_ags", "=", "sampled_ags", ".", "reshape", "(", "num_envs", "*", "num_sampled_ags", ",", "-", "1", ")", "\n", "sampled_ag_scores", "=", "density_module", ".", "evaluate_log_density", "(", "flattened_sampled_ags", ")", "\n", "if", "interest_module", ":", "\n", "# Interest is ~(det(feature_transform)), so we subtract it  in order to add ~(det(inverse feature_transform)) for COV.", "\n", "      ", "sampled_ag_scores", "-=", "interest_module", ".", "evaluate_log_interest", "(", "flattened_sampled_ags", ")", "# add in log interest", "\n", "", "sampled_ag_scores", "=", "sampled_ag_scores", ".", "reshape", "(", "num_envs", ",", "num_sampled_ags", ")", "# these are log densities", "\n", "\n", "# Take softmax of the alpha * log density.", "\n", "# If alpha = -1, this gives us normalized inverse densities (higher is rarer)", "\n", "# If alpha < -1, this skews the density to give us low density samples", "\n", "normalized_inverse_densities", "=", "softmax", "(", "sampled_ag_scores", "*", "self", ".", "alpha", ")", "\n", "normalized_inverse_densities", "*=", "-", "1.", "# make negative / reverse order so that lower is better.", "\n", "\n", "return", "normalized_inverse_densities", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.EntropyGainScoringGoalCuriosity.__init__": [[345, 347], ["curiosity.AchievedGoalCuriosity.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.EntropyGainScoringGoalCuriosity._setup": [[348, 354], ["hasattr", "hasattr", "hasattr", "hasattr", "curiosity.AchievedGoalCuriosity._setup"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "assert", "hasattr", "(", "self", ",", "'bg_kde'", ")", "\n", "assert", "hasattr", "(", "self", ",", "'ag_kde'", ")", "\n", "assert", "hasattr", "(", "self", ",", "'bgag_kde'", ")", "\n", "assert", "hasattr", "(", "self", ",", "'replay_buffer'", ")", "\n", "super", "(", ")", ".", "_setup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.EntropyGainScoringGoalCuriosity.score_goals": [[355, 412], ["sampled_ags.reshape", "numpy.concatenate", "numpy.repeat", "numpy.concatenate", "joint_candidate_bgags.reshape.reshape.reshape", "curiosity.EntropyGainScoringGoalCuriosity.bgag_kde.evaluate_log_density", "joint_candidate_score.reshape.reshape.reshape", "curiosity.EntropyGainScoringGoalCuriosity.bg_kde.evaluate_log_density", "candidate_bgs_score.reshape.reshape.reshape", "mrl.utils.misc.softmax", "curiosity.EntropyGainScoringGoalCuriosity.ag_kde.evaluate_elementwise_entropy", "curiosity.EntropyGainScoringGoalCuriosity.ag_kde.evaluate_elementwise_entropy", "numpy.concatenate", "sampled_ag_entr_gain.mean.mean.mean", "sampled_ag_entr_gain.mean.mean.reshape", "curiosity.EntropyGainScoringGoalCuriosity.ag_kde._optimize", "curiosity.EntropyGainScoringGoalCuriosity.bg_kde._optimize", "curiosity.EntropyGainScoringGoalCuriosity.bgag_kde._optimize", "numpy.arange().reshape", "numpy.arange().reshape", "numpy.repeat.reshape", "len", "numpy.arange", "numpy.arange", "range", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.evaluate_log_density", "home.repos.pwc.inspect_result.spitis_mrl.modules.density.FlowDensity.evaluate_log_density", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax", "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity.evaluate_elementwise_entropy", "home.repos.pwc.inspect_result.spitis_mrl.modules.density.RawJointKernelDensity.evaluate_elementwise_entropy", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize"], ["", "def", "score_goals", "(", "self", ",", "sampled_ags", ",", "info", ")", ":", "\n", "    ", "\"\"\" Higher entropy gain is better \"\"\"", "\n", "if", "not", "self", ".", "ag_kde", ".", "ready", ":", "\n", "      ", "self", ".", "ag_kde", ".", "_optimize", "(", "force", "=", "True", ")", "\n", "\n", "", "if", "not", "self", ".", "bg_kde", ".", "ready", ":", "\n", "      ", "self", ".", "bg_kde", ".", "_optimize", "(", "force", "=", "True", ")", "\n", "\n", "", "if", "not", "self", ".", "bgag_kde", ".", "ready", ":", "\n", "      ", "self", ".", "bgag_kde", ".", "_optimize", "(", "force", "=", "True", ")", "\n", "\n", "# sampled_ags is np.array of shape NUM_ENVS x NUM_SAMPLED_GOALS (both arbitrary)", "\n", "", "num_envs", ",", "num_sampled_ags", "=", "sampled_ags", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# Get sample of predicted achieved goal from mixture density network", "\n", "candidate_bgs", "=", "sampled_ags", ".", "reshape", "(", "num_envs", "*", "num_sampled_ags", ",", "-", "1", ")", "\n", "\n", "# Reuse the candidate bgs as potential ags", "\n", "# Note: We are using a sliding window to reuse sampled_ags as the potential ag for each bg", "\n", "# Prior that each bgs has one ag that is identical to bg, i.e. that it reaches the bg.", "\n", "num_ags", "=", "10", "# TODO: Not make it hard coded", "\n", "indexer", "=", "np", ".", "arange", "(", "num_envs", "*", "num_sampled_ags", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "+", "np", ".", "arange", "(", "num_ags", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "indexer", "%=", "num_envs", "*", "num_sampled_ags", "# To wrap around to the beginning", "\n", "ags_samples", "=", "np", ".", "concatenate", "(", "\n", "[", "candidate_bgs", "[", "indexer", "[", "i", "]", "]", "[", "np", ".", "newaxis", ",", ":", ",", ":", "]", "for", "i", "in", "range", "(", "num_envs", "*", "num_sampled_ags", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "candidate_bgs_repeat", "=", "np", ".", "repeat", "(", "candidate_bgs", "[", ":", ",", "np", ".", "newaxis", ",", ":", "]", ",", "num_ags", ",", "\n", "axis", "=", "1", ")", "# Shape num_envs*num_sampled_ags, num_ags, dim", "\n", "joint_candidate_bgags", "=", "np", ".", "concatenate", "(", "[", "candidate_bgs_repeat", ",", "ags_samples", "]", ",", "axis", "=", "-", "1", ")", "\n", "joint_candidate_bgags", "=", "joint_candidate_bgags", ".", "reshape", "(", "num_envs", "*", "num_sampled_ags", "*", "num_ags", ",", "-", "1", ")", "\n", "\n", "# score the sampled_ags to get log densities, and exponentiate to get densities", "\n", "joint_candidate_score", "=", "self", ".", "bgag_kde", ".", "evaluate_log_density", "(", "joint_candidate_bgags", ")", "\n", "joint_candidate_score", "=", "joint_candidate_score", ".", "reshape", "(", "num_envs", "*", "num_sampled_ags", ",", "\n", "num_ags", ")", "# these are log densities", "\n", "\n", "candidate_bgs_score", "=", "self", ".", "bg_kde", ".", "evaluate_log_density", "(", "\n", "candidate_bgs_repeat", ".", "reshape", "(", "num_envs", "*", "num_sampled_ags", "*", "num_ags", ",", "-", "1", ")", ")", "\n", "candidate_bgs_score", "=", "candidate_bgs_score", ".", "reshape", "(", "num_envs", "*", "num_sampled_ags", ",", "num_ags", ")", "# these are log densities", "\n", "cond_candidate_score", "=", "joint_candidate_score", "-", "candidate_bgs_score", "\n", "cond_candidate_score", "=", "softmax", "(", "cond_candidate_score", ",", "axis", "=", "1", ")", "\n", "\n", "# Compute entropy gain for the predicted achieved goal", "\n", "beta", "=", "1", "/", "len", "(", "self", ".", "replay_buffer", ".", "buffer", ")", "\n", "sampled_ag_entr_new", "=", "self", ".", "ag_kde", ".", "evaluate_elementwise_entropy", "(", "candidate_bgs", ",", "beta", "=", "beta", ")", "\n", "sampled_ag_entr_old", "=", "self", ".", "ag_kde", ".", "evaluate_elementwise_entropy", "(", "candidate_bgs", ",", "beta", "=", "0.", ")", "\n", "sampled_ag_entr_gain", "=", "sampled_ag_entr_new", "-", "sampled_ag_entr_old", "\n", "sampled_ag_entr_gain", "/=", "beta", "# Normalize by beta # TODO: Get rid of this part if not necessary", "\n", "sampled_ag_entr_gain", "=", "np", ".", "concatenate", "(", "\n", "[", "sampled_ag_entr_gain", "[", "indexer", "[", "i", "]", "]", "[", "np", ".", "newaxis", ",", ":", "]", "for", "i", "in", "range", "(", "num_envs", "*", "num_sampled_ags", ")", "]", ",", "axis", "=", "0", ")", "\n", "sampled_ag_entr_gain", "*=", "cond_candidate_score", "\n", "sampled_ag_entr_gain", "=", "sampled_ag_entr_gain", ".", "mean", "(", "axis", "=", "1", ")", "\n", "\n", "scores", "=", "sampled_ag_entr_gain", ".", "reshape", "(", "num_envs", ",", "num_sampled_ags", ")", "\n", "scores", "*=", "-", "1.", "# make negative / reverse order so that lower is better.", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.CuriosityAlphaMixtureModule.__init__": [[418, 431], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "optimize_every", "=", "100", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'curiosity_alpha'", ",", "\n", "required_agent_modules", "=", "[", "'ag_curiosity'", ",", "'ag_kde'", ",", "'replay_buffer'", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "samples", "=", "None", "\n", "self", ".", "bandwidth", "=", "None", "\n", "self", ".", "kernel", "=", "None", "\n", "self", ".", "kde", "=", "None", "\n", "self", ".", "fitted_kde", "=", "None", "\n", "self", ".", "_alpha", "=", "0.", "\n", "self", ".", "_beta", "=", "-", "3.", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.CuriosityAlphaMixtureModule._setup": [[432, 439], ["sklearn.neighbors.KernelDensity"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "samples", "=", "self", ".", "ag_kde", ".", "samples", "\n", "self", ".", "bandwidth", "=", "self", ".", "ag_kde", ".", "bandwidth", "\n", "self", ".", "kernel", "=", "self", ".", "ag_kde", ".", "kernel", "\n", "self", ".", "kde", "=", "KernelDensity", "(", "kernel", "=", "self", ".", "kernel", ",", "bandwidth", "=", "self", ".", "bandwidth", ")", "\n", "if", "'curiosity_beta'", "in", "self", ".", "config", ":", "\n", "      ", "self", ".", "_beta", "=", "self", ".", "config", ".", "curiosity_beta", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.CuriosityAlphaMixtureModule.alpha": [[440, 443], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "alpha", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.CuriosityAlphaMixtureModule._optimize": [[444, 466], ["len", "numpy.random.randint", "buffer.get_batch", "curiosity.CuriosityAlphaMixtureModule.kde.fit", "curiosity.CuriosityAlphaMixtureModule.fitted_kde.score_samples", "curiosity.CuriosityAlphaMixtureModule.ag_kde.fitted_kde.score_samples", "curiosity.CuriosityAlphaMixtureModule.logger.add_scalar", "curiosity.CuriosityAlphaMixtureModule.logger.add_tabular", "len", "max", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.get_batch", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.fit", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples", "home.repos.pwc.inspect_result.spitis_mrl.utils.realnvp.RealNVP.score_samples", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_scalar", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_tabular"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "buffer", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "BUFF", "[", "'buffer_dg'", "]", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "self", ".", "step", "%", "self", ".", "optimize_every", "==", "0", "and", "len", "(", "buffer", ")", ":", "\n", "\n", "# Fit the DG KDE", "\n", "      ", "num_samples", "=", "1000", "\n", "sample_idxs", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "buffer", ")", ",", "size", "=", "num_samples", ")", "\n", "kde_samples", "=", "buffer", ".", "get_batch", "(", "sample_idxs", ")", "\n", "kde_samples", "=", "(", "kde_samples", "-", "self", ".", "ag_kde", ".", "kde_sample_mean", ")", "/", "self", ".", "ag_kde", ".", "kde_sample_std", "\n", "self", ".", "fitted_kde", "=", "self", ".", "kde", ".", "fit", "(", "kde_samples", ")", "\n", "\n", "# Now compute alpha", "\n", "s", "=", "kde_samples", "\n", "log_p_dg", "=", "self", ".", "fitted_kde", ".", "score_samples", "(", "s", ")", "\n", "log_p_ag", "=", "self", ".", "ag_kde", ".", "fitted_kde", ".", "score_samples", "(", "s", ")", "\n", "self", ".", "_alpha", "=", "1.", "/", "max", "(", "(", "self", ".", "_beta", "+", "np", ".", "mean", "(", "log_p_dg", ")", "-", "np", ".", "mean", "(", "log_p_ag", ")", ")", ",", "1.", ")", "\n", "\n", "# Occasionally log the alpha", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Explore/curiosity_alpha'", ",", "self", ".", "_alpha", ",", "log_every", "=", "500", ")", "\n", "self", ".", "logger", ".", "add_tabular", "(", "'Curiosity_alpha'", ",", "self", ".", "_alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.CuriosityAlphaMixtureModule.save": [[467, 469], ["curiosity.CuriosityAlphaMixtureModule._save_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._save_props"], ["", "", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_save_props", "(", "[", "'kde'", ",", "'samples'", ",", "'bandwidth'", ",", "'kernel'", "]", ",", "save_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.CuriosityAlphaMixtureModule.load": [[470, 472], ["curiosity.CuriosityAlphaMixtureModule._load_props"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Module._load_props"], ["", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "self", ".", "_load_props", "(", "[", "'kde'", ",", "'samples'", ",", "'bandwidth'", ",", "'kernel'", "]", ",", "save_folder", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.curiosity.generate_overshooting_goals": [[13, 20], ["numpy.array", "numpy.concatenate", "numpy.random.uniform"], "function", ["None"], ["def", "generate_overshooting_goals", "(", "num_proposals", ",", "step_amount", ",", "direct_overshoots", ",", "base_goal", ")", ":", "\n", "  ", "base_proposals", "=", "np", ".", "array", "(", "[", "base_goal", ",", "base_goal", "+", "step_amount", "]", ")", "\n", "if", "direct_overshoots", ":", "\n", "    ", "return", "base_proposals", "\n", "", "additional_proposals", "=", "base_goal", "[", "None", "]", "+", "np", ".", "random", ".", "uniform", "(", "\n", "-", "1.5", ",", "1.5", ",", "(", "num_proposals", "-", "2", ",", "step_amount", ".", "shape", "[", "0", "]", ")", ")", "*", "step_amount", "[", "None", "]", "\n", "return", "np", ".", "concatenate", "(", "(", "base_proposals", ",", "additional_proposals", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.__init__": [[16, 20], ["mrl.Module.__init__", "model.PytorchModel.model_fn", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "name", ":", "str", ",", "model_fn", ":", "Callable", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "name", ",", "required_agent_modules", "=", "[", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "model_fn", "=", "model_fn", "\n", "self", ".", "model", "=", "self", ".", "model_fn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel._setup": [[21, 24], ["model.PytorchModel.config.get", "model.PytorchModel.model.to"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "config", ".", "get", "(", "'device'", ")", ":", "\n", "      ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "config", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.save": [[25, 28], ["os.path.join", "torch.save", "model.PytorchModel.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.load": [[29, 32], ["os.path.join", "model.PytorchModel.model.load_state_dict", "torch.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ",", "strict", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy": [[33, 38], ["dill.loads", "model.PytorchModel.__class__", "dill.dumps"], "methods", ["None"], ["", "def", "copy", "(", "self", ",", "new_name", ")", ":", "\n", "    ", "\"\"\"Makes a copy of the Model; e.g., for target networks\"\"\"", "\n", "new_model", "=", "dill", ".", "loads", "(", "dill", ".", "dumps", "(", "self", ".", "model", ")", ")", "\n", "model_fn", "=", "lambda", ":", "new_model", "\n", "return", "self", ".", "__class__", "(", "new_name", ",", "model_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.__call__": [[39, 45], ["model.PytorchModel.model", "model.PytorchModel.model.train", "model.PytorchModel.model.eval"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "self", ".", "training", ":", "\n", "      ", "self", ".", "model", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "model", ".", "eval", "(", ")", "\n", "", "return", "self", ".", "model", "(", "*", "args", ",", "**", "kwargs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.__init__": [[9, 13], ["numpy.zeros", "numpy.ones"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "epsilon", "=", "1e-4", ",", "shape", "=", "(", ")", ")", ":", "\n", "    ", "self", ".", "mean", "=", "np", ".", "zeros", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "var", "=", "np", ".", "ones", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "count", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update": [[14, 19], ["numpy.mean", "numpy.var", "normalizer.RunningMeanStd.update_from_moments"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update_from_moments"], ["", "def", "update", "(", "self", ",", "x", ")", ":", "\n", "    ", "batch_mean", "=", "np", ".", "mean", "(", "x", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "batch_var", "=", "np", ".", "var", "(", "x", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "batch_count", "=", "x", ".", "shape", "[", "0", "]", "\n", "self", ".", "update_from_moments", "(", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update_from_moments": [[20, 33], ["numpy.square"], "methods", ["None"], ["", "def", "update_from_moments", "(", "self", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", ":", "\n", "    ", "delta", "=", "batch_mean", "-", "self", ".", "mean", "\n", "tot_count", "=", "self", ".", "count", "+", "batch_count", "\n", "\n", "new_mean", "=", "self", ".", "mean", "+", "delta", "*", "batch_count", "/", "tot_count", "\n", "m_a", "=", "self", ".", "var", "*", "(", "self", ".", "count", ")", "\n", "m_b", "=", "batch_var", "*", "(", "batch_count", ")", "\n", "M2", "=", "m_a", "+", "m_b", "+", "np", ".", "square", "(", "delta", ")", "*", "self", ".", "count", "*", "batch_count", "/", "(", "tot_count", ")", "\n", "new_var", "=", "M2", "/", "(", "tot_count", ")", "\n", "\n", "self", ".", "mean", "=", "new_mean", "\n", "self", ".", "var", "=", "new_var", "\n", "self", ".", "count", "=", "tot_count", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.Normalizer.__init__": [[36, 40], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "normalizer", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "'state_normalizer'", ",", "required_agent_modules", "=", "[", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "normalizer", "=", "normalizer", "\n", "self", ".", "lazy_load", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.Normalizer.__call__": [[41, 54], ["normalizer.Normalizer.normalizer", "normalizer.Normalizer.normalizer", "normalizer.Normalizer.load", "print"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "self", ".", "training", ":", "\n", "      ", "self", ".", "normalizer", ".", "read_only", "=", "False", "\n", "", "else", ":", "\n", "      ", "self", ".", "normalizer", ".", "read_only", "=", "True", "\n", "\n", "", "if", "self", ".", "lazy_load", "is", "not", "None", ":", "\n", "      ", "self", ".", "normalizer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "load", "(", "self", ".", "lazy_load", ")", "\n", "print", "(", "\"LOADED NORMALIZER\"", ")", "\n", "self", ".", "lazy_load", "=", "None", "\n", "\n", "", "return", "self", ".", "normalizer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.Normalizer.save": [[55, 59], ["normalizer.Normalizer.normalizer.state_dict", "open", "pickle.dump", "os.path.join", "normalizer.Normalizer.normalizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "if", "self", ".", "normalizer", ".", "state_dict", "(", ")", "is", "not", "None", ":", "\n", "      ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "'normalizer.pickle'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "self", ".", "normalizer", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.Normalizer.load": [[60, 70], ["normalizer.Normalizer.normalizer.state_dict", "os.path.join", "os.path.exists", "print", "open", "normalizer.Normalizer.normalizer.load_state_dict", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load"], ["", "", "", "def", "load", "(", "self", ",", "save_folder", ")", ":", "\n", "    ", "if", "self", ".", "normalizer", ".", "state_dict", "(", ")", "is", "not", "None", ":", "\n", "      ", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "'normalizer.pickle'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "        ", "with", "open", "(", "save_path", ",", "'rb'", ")", "as", "f", ":", "\n", "          ", "self", ".", "normalizer", ".", "load_state_dict", "(", "pickle", ".", "load", "(", "f", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'WARNING: No saved normalizer state to load.'", ")", "\n", "", "", "else", ":", "\n", "      ", "self", ".", "lazy_load", "=", "save_folder", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.BaseNormalizer.__init__": [[76, 78], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "read_only", "=", "False", ")", ":", "\n", "    ", "self", ".", "read_only", "=", "read_only", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.BaseNormalizer.set_read_only": [[79, 81], ["None"], "methods", ["None"], ["", "def", "set_read_only", "(", "self", ")", ":", "\n", "    ", "self", ".", "read_only", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.BaseNormalizer.unset_read_only": [[82, 84], ["None"], "methods", ["None"], ["", "def", "unset_read_only", "(", "self", ")", ":", "\n", "    ", "self", ".", "read_only", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.BaseNormalizer.state_dict": [[85, 87], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "    ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.BaseNormalizer.load_state_dict": [[88, 90], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "_", ")", ":", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.__init__": [[93, 100], ["normalizer.BaseNormalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "read_only", "=", "False", ",", "clip_before", "=", "200.0", ",", "clip_after", "=", "5.0", ",", "epsilon", "=", "1e-8", ")", ":", "\n", "    ", "BaseNormalizer", ".", "__init__", "(", "self", ",", "read_only", ")", "\n", "self", ".", "read_only", "=", "read_only", "\n", "self", ".", "rms", "=", "None", "\n", "self", ".", "clip_before", "=", "clip_before", "\n", "self", ".", "clip_after", "=", "clip_after", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.__call__": [[101, 108], ["numpy.clip", "numpy.clip", "numpy.asarray", "normalizer.RunningMeanStd", "normalizer.MeanStdNormalizer.rms.update", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update"], ["", "def", "__call__", "(", "self", ",", "x", ",", "update", "=", "True", ")", ":", "\n", "    ", "x", "=", "np", ".", "clip", "(", "np", ".", "asarray", "(", "x", ")", ",", "-", "self", ".", "clip_before", ",", "self", ".", "clip_before", ")", "\n", "if", "self", ".", "rms", "is", "None", ":", "\n", "      ", "self", ".", "rms", "=", "RunningMeanStd", "(", "shape", "=", "(", "1", ",", ")", "+", "x", ".", "shape", "[", "1", ":", "]", ")", "\n", "", "if", "not", "self", ".", "read_only", "and", "update", ":", "\n", "      ", "self", ".", "rms", ".", "update", "(", "x", ")", "\n", "", "return", "np", ".", "clip", "(", "(", "x", "-", "self", ".", "rms", ".", "mean", ")", "/", "np", ".", "sqrt", "(", "self", ".", "rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "clip_after", ",", "self", ".", "clip_after", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict": [[109, 112], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "rms", "is", "not", "None", ":", "\n", "      ", "return", "{", "'mean'", ":", "self", ".", "rms", ".", "mean", ",", "'var'", ":", "self", ".", "rms", ".", "var", ",", "'count'", ":", "self", ".", "rms", ".", "count", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict": [[113, 117], ["None"], "methods", ["None"], ["", "", "def", "load_state_dict", "(", "self", ",", "saved", ")", ":", "\n", "    ", "self", ".", "rms", ".", "mean", "=", "saved", "[", "'mean'", "]", "\n", "self", ".", "rms", ".", "var", "=", "saved", "[", "'var'", "]", "\n", "self", ".", "rms", ".", "count", "=", "saved", "[", "'count'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RescaleNormalizer.__init__": [[120, 123], ["normalizer.BaseNormalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "coef", "=", "1.0", ")", ":", "\n", "    ", "BaseNormalizer", ".", "__init__", "(", "self", ")", "\n", "self", ".", "coef", "=", "coef", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RescaleNormalizer.__call__": [[124, 128], ["isinstance", "numpy.asarray"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ",", "*", "unused_args", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "      ", "x", "=", "np", ".", "asarray", "(", "x", ")", "\n", "", "return", "self", ".", "coef", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.ImageNormalizer.__init__": [[131, 133], ["normalizer.RescaleNormalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "RescaleNormalizer", ".", "__init__", "(", "self", ",", "1.0", "/", "255", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.SignNormalizer.__call__": [[136, 138], ["numpy.sign"], "methods", ["None"], ["  ", "def", "__call__", "(", "self", ",", "x", ",", "*", "unused_args", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.__init__": [[14, 26], ["mrl.Module.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", "=", "50", ",", "history_length", "=", "200", ",", "optimize_every", "=", "250", ",", "log_every", "=", "5000", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'success_predictor'", ",", "\n", "required_agent_modules", "=", "[", "\n", "'env'", ",", "'replay_buffer'", ",", "'goal_discriminator'", "\n", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "self", ".", "log_every", "=", "log_every", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "history_length", "=", "history_length", "\n", "self", ".", "optimize_every", "=", "optimize_every", "\n", "self", ".", "opt_steps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup": [[27, 33], ["super()._setup", "isinstance", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "success_prediction.GoalSuccessPredictor.goal_discriminator.model.parameters"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._setup"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "_setup", "(", ")", "\n", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "OnlineHERBuffer", ")", "\n", "assert", "self", ".", "env", ".", "goal_env", "\n", "self", ".", "n_envs", "=", "self", ".", "env", ".", "num_envs", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "goal_discriminator", ".", "model", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor._optimize": [[34, 60], ["success_prediction.GoalSuccessPredictor.replay_buffer.buffer.sample_trajectories", "numpy.array", "numpy.array", "numpy.array", "numpy.concatenate", "success_prediction.GoalSuccessPredictor.torch", "success_prediction.GoalSuccessPredictor.torch", "success_prediction.GoalSuccessPredictor.goal_discriminator", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "hasattr", "success_prediction.GoalSuccessPredictor.optimizer.zero_grad", "torch.binary_cross_entropy_with_logits.backward", "success_prediction.GoalSuccessPredictor.optimizer.step", "len", "success_prediction.GoalSuccessPredictor.logger.add_histogram", "success_prediction.GoalSuccessPredictor.logger.add_histogram", "numpy.any", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample_trajectories", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram", "home.repos.pwc.inspect_result.spitis_mrl.modules.logging.Logger.add_histogram"], ["", "def", "_optimize", "(", "self", ")", ":", "\n", "    ", "self", ".", "opt_steps", "+=", "1", "\n", "\n", "if", "len", "(", "self", ".", "replay_buffer", ".", "buffer", ".", "trajectories", ")", ">", "self", ".", "batch_size", "and", "self", ".", "opt_steps", "%", "self", ".", "optimize_every", "==", "0", ":", "\n", "      ", "trajs", "=", "self", ".", "replay_buffer", ".", "buffer", ".", "sample_trajectories", "(", "self", ".", "batch_size", ",", "group_by_buffer", "=", "True", ",", "from_m_most_recent", "=", "self", ".", "history_length", ")", "\n", "successes", "=", "np", ".", "array", "(", "[", "np", ".", "any", "(", "np", ".", "isclose", "(", "traj", ",", "0.", ")", ",", "axis", "=", "0", ")", "for", "traj", "in", "trajs", "[", "2", "]", "]", ")", "\n", "\n", "start_states", "=", "np", ".", "array", "(", "[", "t", "[", "0", "]", "for", "t", "in", "trajs", "[", "0", "]", "]", ")", "\n", "behav_goals", "=", "np", ".", "array", "(", "[", "t", "[", "0", "]", "for", "t", "in", "trajs", "[", "7", "]", "]", ")", "\n", "states", "=", "np", ".", "concatenate", "(", "(", "start_states", ",", "behav_goals", ")", ",", "-", "1", ")", "\n", "\n", "targets", "=", "self", ".", "torch", "(", "successes", ")", "\n", "inputs", "=", "self", ".", "torch", "(", "states", ")", "\n", "\n", "# outputs here have not been passed through sigmoid", "\n", "outputs", "=", "self", ".", "goal_discriminator", "(", "inputs", ")", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "outputs", ",", "targets", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "'logger'", ")", ":", "\n", "        ", "self", ".", "logger", ".", "add_histogram", "(", "'predictions'", ",", "torch", ".", "sigmoid", "(", "outputs", ")", ",", "self", ".", "log_every", ")", "\n", "self", ".", "logger", ".", "add_histogram", "(", "'targets'", ",", "targets", ",", "self", ".", "log_every", ")", "\n", "\n", "# optimize", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.__call__": [[61, 65], ["numpy.concatenate", "success_prediction.GoalSuccessPredictor.numpy", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "success_prediction.GoalSuccessPredictor.goal_discriminator", "success_prediction.GoalSuccessPredictor.torch"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.torch"], ["", "", "def", "__call__", "(", "self", ",", "*", "states_and_maybe_goals", ")", ":", "\n", "    ", "\"\"\"Input / output are numpy arrays\"\"\"", "\n", "states", "=", "np", ".", "concatenate", "(", "states_and_maybe_goals", ",", "-", "1", ")", "\n", "return", "self", ".", "numpy", "(", "torch", ".", "sigmoid", "(", "self", ".", "goal_discriminator", "(", "self", ".", "torch", "(", "states", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save": [[66, 71], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "success_prediction.GoalSuccessPredictor.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'opt_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load": [[72, 76], ["os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "success_prediction.GoalSuccessPredictor.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load", "(", "self", ",", "save_folder", ":", "str", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "self", ".", "module_name", "+", "'.pt'", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'opt_state_dict'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.EnvModule.__init__": [[23, 91], ["mrl.Module.__init__", "isinstance", "print", "isinstance", "isinstance", "env.EnvModule.env.reset", "int", "isinstance", "mrl.utils.vec_env.dummy_vec_env.DummyVecEnv", "mrl.utils.vec_env.subproc_vec_env.SubprocVecEnv", "isinstance", "numpy.allclose", "int", "locals", "time.time", "env.make_env_by_id", "env.make_env_by_id", "env.make_env", "env.make_env", "hasattr", "int", "numpy.prod", "range", "range", "int", "numpy.prod", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env_by_id", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env_by_id", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env"], ["def", "__init__", "(", "\n", "self", ",", "\n", "env", ":", "Union", "[", "str", ",", "Callable", "]", ",", "\n", "num_envs", ":", "int", "=", "1", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "modalities", "=", "[", "'observation'", "]", ",", "\n", "goal_modalities", "=", "[", "'desired_goal'", "]", ",", "\n", "episode_life", "=", "True", "# for Atari", "\n", ")", ":", "\n", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "name", "or", "'env'", ",", "required_agent_modules", "=", "[", "]", ",", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "self", ".", "num_envs", "=", "num_envs", "\n", "\n", "if", "seed", "is", "None", ":", "\n", "      ", "seed", "=", "int", "(", "time", ".", "time", "(", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "env", ",", "str", ")", ":", "\n", "      ", "sample_env", "=", "make_env_by_id", "(", "env", ",", "seed", ",", "0", ",", "episode_life", ")", "(", ")", "\n", "env_list", "=", "[", "make_env_by_id", "(", "env", ",", "seed", ",", "i", ",", "episode_life", ")", "for", "i", "in", "range", "(", "num_envs", ")", "]", "\n", "", "else", ":", "\n", "      ", "sample_env", "=", "make_env", "(", "env", ",", "seed", ",", "0", ")", "(", ")", "\n", "assert", "isinstance", "(", "sample_env", ",", "gym", ".", "core", ".", "Env", ")", ",", "\"Only gym environments supported for now!\"", "\n", "env_list", "=", "[", "make_env", "(", "env", ",", "seed", ",", "i", ")", "for", "i", "in", "range", "(", "num_envs", ")", "]", "\n", "\n", "", "if", "num_envs", "==", "1", ":", "\n", "      ", "self", ".", "env", "=", "DummyVecEnv", "(", "env_list", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "env", "=", "SubprocVecEnv", "(", "env_list", ")", "\n", "", "print", "(", "'Initializing env!'", ")", "\n", "\n", "self", ".", "render", "=", "self", ".", "env", ".", "render", "\n", "self", ".", "observation_space", "=", "sample_env", ".", "observation_space", "\n", "self", ".", "action_space", "=", "sample_env", ".", "action_space", "\n", "\n", "if", "isinstance", "(", "self", ".", "action_space", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "      ", "self", ".", "action_dim", "=", "self", ".", "action_space", ".", "n", "\n", "self", ".", "max_action", "=", "None", "\n", "", "else", ":", "\n", "      ", "assert", "isinstance", "(", "self", ".", "action_space", ",", "gym", ".", "spaces", ".", "Box", ")", ",", "\"Only Box/Discrete actions supported for now!\"", "\n", "self", ".", "action_dim", "=", "self", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "self", ".", "max_action", "=", "self", ".", "action_space", ".", "high", "[", "0", "]", "\n", "assert", "np", ".", "allclose", "(", "self", ".", "action_space", ".", "high", ",", "\n", "-", "self", ".", "action_space", ".", "low", ")", ",", "\"Action high/lows must equal! Several modules rely on this\"", "\n", "\n", "", "self", ".", "goal_env", "=", "False", "\n", "self", ".", "goal_dim", "=", "0", "\n", "\n", "if", "isinstance", "(", "self", ".", "observation_space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "      ", "if", "goal_modalities", "[", "0", "]", "in", "self", ".", "observation_space", ".", "spaces", ":", "\n", "        ", "self", ".", "goal_env", "=", "True", "\n", "self", ".", "compute_reward", "=", "sample_env", ".", "compute_reward", "\n", "if", "hasattr", "(", "sample_env", ",", "'achieved_goal'", ")", ":", "\n", "          ", "self", ".", "achieved_goal", "=", "sample_env", ".", "achieved_goal", "\n", "", "for", "key", "in", "goal_modalities", ":", "\n", "          ", "assert", "key", "in", "self", ".", "env", ".", "observation_space", ".", "spaces", "\n", "self", ".", "goal_dim", "+=", "int", "(", "np", ".", "prod", "(", "self", ".", "env", ".", "observation_space", "[", "key", "]", ".", "shape", ")", ")", "\n", "", "", "state_dim", "=", "0", "\n", "for", "key", "in", "modalities", ":", "\n", "        ", "if", "key", "==", "'desired_goal'", ":", "continue", "\n", "assert", "key", "in", "self", ".", "env", ".", "observation_space", ".", "spaces", "\n", "state_dim", "+=", "int", "(", "np", ".", "prod", "(", "self", ".", "env", ".", "observation_space", "[", "key", "]", ".", "shape", ")", ")", "\n", "", "self", ".", "state_dim", "=", "state_dim", "\n", "", "else", ":", "\n", "      ", "self", ".", "state_dim", "=", "int", "(", "np", ".", "prod", "(", "self", ".", "env", ".", "observation_space", ".", "shape", ")", ")", "\n", "\n", "", "self", ".", "state", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.EnvModule.step": [[92, 96], ["env.EnvModule.env.step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "res", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "state", "=", "res", "[", "0", "]", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.EnvModule.reset": [[97, 111], ["env.EnvModule.env.reset", "env.EnvModule.env.env_method", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.vec_env.dummy_vec_env.DummyVecEnv.env_method"], ["", "def", "reset", "(", "self", ",", "indices", "=", "None", ")", ":", "\n", "    ", "if", "not", "indices", ":", "\n", "      ", "self", ".", "state", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "return", "self", ".", "state", "\n", "", "else", ":", "\n", "      ", "reset_states", "=", "self", ".", "env", ".", "env_method", "(", "'reset'", ",", "indices", "=", "indices", ")", "\n", "if", "self", ".", "goal_env", ":", "\n", "        ", "for", "i", ",", "reset_state", "in", "zip", "(", "indices", ",", "reset_states", ")", ":", "\n", "          ", "for", "key", "in", "reset_state", ":", "\n", "            ", "self", ".", "state", "[", "key", "]", "[", "i", "]", "=", "reset_state", "[", "key", "]", "\n", "", "", "", "else", ":", "\n", "        ", "for", "i", ",", "reset_state", "in", "zip", "(", "indices", ",", "reset_states", ")", ":", "\n", "          ", "self", ".", "state", "[", "i", "]", "=", "reset_state", "\n", "", "", "return", "self", ".", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.ReturnAndObsWrapper.__init__": [[163, 166], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "    ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "total_rewards", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.ReturnAndObsWrapper.step": [[167, 182], ["env.ReturnAndObsWrapper.env.step", "mrl.utils.misc.AttrDict", "mrl.utils.misc.AttrDict.get"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "info", "=", "AttrDict", "(", "info", ")", "\n", "self", ".", "total_rewards", "+=", "reward", "\n", "if", "done", ":", "\n", "      ", "info", ".", "done_observation", "=", "obs", "\n", "info", ".", "terminal_state", "=", "True", "\n", "if", "info", ".", "get", "(", "'TimeLimit.truncated'", ")", ":", "\n", "        ", "info", ".", "terminal_state", "=", "False", "\n", "", "info", ".", "episodic_return", "=", "self", ".", "total_rewards", "\n", "self", ".", "total_rewards", "=", "0", "\n", "", "else", ":", "\n", "      ", "info", ".", "terminal_state", "=", "False", "\n", "info", ".", "episodic_return", "=", "None", "\n", "", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.ReturnAndObsWrapper.render": [[183, 185], ["env.ReturnAndObsWrapper.env.render"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.ReturnAndObsWrapper.reset": [[186, 188], ["env.ReturnAndObsWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.ReturnAndObsWrapper.__getattr__": [[189, 191], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "    ", "return", "getattr", "(", "self", ".", "env", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FirstVisitDoneWrapper.step": [[196, 204], ["env.FirstVisitDoneWrapper.env.step", "numpy.allclose", "info.get"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "np", ".", "allclose", "(", "reward", ",", "0.", ")", ":", "\n", "      ", "done", "=", "True", "\n", "info", "[", "'is_success'", "]", "=", "True", "\n", "if", "info", ".", "get", "(", "'TimeLimit.truncated'", ")", ":", "\n", "        ", "del", "info", "[", "'TimeLimit.truncated'", "]", "\n", "", "", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FirstVisitDoneWrapper.reset": [[205, 207], ["env.FirstVisitDoneWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FirstVisitDoneWrapper.__getattr__": [[208, 210], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "    ", "return", "getattr", "(", "self", ".", "env", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.TransposeImage.__init__": [[213, 220], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "env", "=", "None", ")", ":", "\n", "    ", "super", "(", "TransposeImage", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "obs_shape", "=", "self", ".", "observation_space", ".", "shape", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "self", ".", "observation_space", ".", "low", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "self", ".", "observation_space", ".", "high", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "obs_shape", "[", "2", "]", ",", "obs_shape", "[", "1", "]", ",", "obs_shape", "[", "0", "]", "]", ",", "\n", "dtype", "=", "self", ".", "observation_space", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.TransposeImage.observation": [[221, 223], ["observation.transpose"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "    ", "return", "observation", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__init__": [[227, 234], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "frames", ")", ":", "\n", "    ", "\"\"\"This object ensures that common frames between the observations are only stored once.\n      It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n      buffers.\n      This object should only be converted to numpy array before being passed to the model.\n      You'd not believe how complex the previous solution was.\"\"\"", "\n", "self", ".", "_frames", "=", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__array__": [[235, 240], ["numpy.concatenate", "out.astype.astype.astype"], "methods", ["None"], ["", "def", "__array__", "(", "self", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "out", "=", "np", ".", "concatenate", "(", "self", ".", "_frames", ",", "axis", "=", "0", ")", "\n", "if", "dtype", "is", "not", "None", ":", "\n", "      ", "out", "=", "out", ".", "astype", "(", "dtype", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__len__": [[241, 243], ["len", "env.LazyFrames.__array__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__array__"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "__array__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__getitem__": [[244, 246], ["env.LazyFrames.__array__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.env.LazyFrames.__array__"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "    ", "return", "self", ".", "__array__", "(", ")", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FrameStack.__init__": [[249, 263], ["gym.Wrapper.__init__", "deque", "spaces.Box"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "env", ",", "k", ")", ":", "\n", "    ", "\"\"\"Stack k last frames.\n\n    Returns lazy array, which is much more memory efficient.\n\n    See Also\n    --------\n    baselines.common.atari_wrappers.LazyFrames\n    \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "frames", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "k", ")", "\n", "shp", "=", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "(", "shp", "[", "0", "]", ",", "shp", "[", "1", "]", ",", "shp", "[", "2", "]", "*", "k", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FrameStack.reset": [[264, 269], ["env.FrameStack.env.reset", "range", "env.FrameStack._get_ob", "env.FrameStack.frames.append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FrameStack._get_ob", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "ob", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "      ", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "", "return", "self", ".", "_get_ob", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FrameStack.step": [[270, 274], ["env.FrameStack.env.step", "env.FrameStack.frames.append", "env.FrameStack._get_ob"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FrameStack._get_ob"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "ob", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "return", "self", ".", "_get_ob", "(", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.FrameStack._get_ob": [[275, 278], ["env.LazyFrames", "len", "list"], "methods", ["None"], ["", "def", "_get_ob", "(", "self", ")", ":", "\n", "    ", "assert", "len", "(", "self", ".", "frames", ")", "==", "self", ".", "k", "\n", "return", "LazyFrames", "(", "list", "(", "self", ".", "frames", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env": [[113, 129], ["mrl.utils.misc.set_global_seeds", "env_fn", "ReturnAndObsWrapper.seed", "env.ReturnAndObsWrapper"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.set_global_seeds", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["", "", "", "def", "make_env", "(", "env_fn", ",", "seed", ",", "rank", ")", ":", "\n", "  ", "\"\"\"\n  Utility function for multiprocessed env.\n  \n  :param env_id: (str) the environment ID\n  :param num_env: (int) the number of environment you wish to have in subprocesses\n  :param seed: (int) the inital seed for RNG\n  \"\"\"", "\n", "def", "_init", "(", ")", ":", "\n", "    ", "env", "=", "env_fn", "(", ")", "\n", "env", ".", "seed", "(", "seed", "+", "rank", ")", "\n", "env", "=", "ReturnAndObsWrapper", "(", "env", ")", "\n", "return", "env", "\n", "\n", "", "set_global_seeds", "(", "seed", ")", "\n", "return", "_init", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.modules.env.make_env_by_id": [[136, 160], ["mrl.utils.misc.set_global_seeds", "env_id.startswith", "TransposeImage.seed", "env.ReturnAndObsWrapper", "env_id.split", "dm_control2gym.make", "gym.make", "hasattr", "isinstance", "make_atari", "wrap_deepmind", "env.FrameStack", "len", "env.TransposeImage"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.set_global_seeds", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["", "def", "make_env_by_id", "(", "env_id", ",", "seed", ",", "rank", ",", "episode_life", "=", "True", ")", ":", "\n", "  ", "\"\"\"Used for regular gym environments and Atari Envs\"\"\"", "\n", "def", "_init", "(", ")", ":", "\n", "    ", "if", "env_id", ".", "startswith", "(", "\"dm\"", ")", ":", "\n", "      ", "import", "dm_control2gym", "\n", "_", ",", "domain", ",", "task", "=", "env_id", ".", "split", "(", "'-'", ")", "\n", "env", "=", "dm_control2gym", ".", "make", "(", "domain_name", "=", "domain", ",", "task_name", "=", "task", ")", "\n", "", "else", ":", "\n", "      ", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "", "is_atari", "=", "hasattr", "(", "gym", ".", "envs", ",", "'atari'", ")", "and", "isinstance", "(", "env", ".", "unwrapped", ",", "gym", ".", "envs", ".", "atari", ".", "atari_env", ".", "AtariEnv", ")", "\n", "if", "is_atari", ":", "\n", "      ", "env", "=", "make_atari", "(", "env_id", ")", "\n", "", "env", ".", "seed", "(", "seed", "+", "rank", ")", "\n", "if", "is_atari", ":", "\n", "      ", "env", "=", "wrap_deepmind", "(", "env", ",", "episode_life", "=", "episode_life", ",", "clip_rewards", "=", "False", ",", "frame_stack", "=", "False", ",", "scale", "=", "False", ")", "\n", "obs_shape", "=", "env", ".", "observation_space", ".", "shape", "\n", "if", "len", "(", "obs_shape", ")", "==", "3", ":", "\n", "        ", "env", "=", "TransposeImage", "(", "env", ")", "\n", "", "env", "=", "FrameStack", "(", "env", ",", "4", ")", "\n", "", "env", "=", "ReturnAndObsWrapper", "(", "env", ")", "\n", "return", "env", "\n", "\n", "", "set_global_seeds", "(", "seed", ")", "\n", "return", "_init", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.discrete_off_policy.dqn_config": [[48, 61], ["default_dqn_config", "mrl.utils.schedule.LinearSchedule", "int"], "function", ["None"], ["        ", "action", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "env", ".", "action_space", ".", "n", ",", "size", "=", "[", "self", ".", "env", ".", "num_envs", "]", ")", "\n", "", "else", ":", "\n", "      ", "action", "=", "np", ".", "argmax", "(", "q_values", ",", "-", "1", ")", "# Convert to int", "\n", "\n", "", "return", "action", "\n", "\n", "\n", "", "", "class", "BaseQLearning", "(", "mrl", ".", "Module", ")", ":", "\n", "  ", "\"\"\" Generic Discrete Action Q-Learning Algorithm\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'algorithm'", ",", "\n", "required_agent_modules", "=", "[", "'qvalue'", ",", "'replay_buffer'", ",", "'env'", "]", ",", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_ddpg_agent": [[7, 79], ["argparse.Namespace", "callable", "merge_args_into_config", "make_agent_name", "config.update", "EnvModule", "EnvModule", "PytorchModel", "PytorchModel", "base_config.", "hasattr", "max", "hasattr", "str", "type", "hasattr", "time.time", "dict().items", "gym.make", "type", "hasattr", "Actor", "Critic", "mp.cpu_count", "gym.make", "FCBody", "FCBody", "dict", "make_activ", "make_activ", "StandardTrain", "EpisodicEval", "ActorPolicy", "Logger", "Normalizer", "OnlineHERBuffer", "ContinuousActionNoise", "DDPG", "MeanStdNormalizer", "ConstantSchedule"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.utils.misc.merge_args_into_config", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_agent_name", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.RunningMeanStd.update", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ"], ["def", "make_ddpg_agent", "(", "base_config", "=", "default_ddpg_config", ",", "\n", "args", "=", "Namespace", "(", "env", "=", "'InvertedPendulum-v2'", ",", "\n", "tb", "=", "''", ",", "\n", "parent_folder", "=", "'/tmp/mrl'", ",", "\n", "layers", "=", "(", "256", ",", "256", ")", ",", "\n", "num_envs", "=", "None", ")", ",", "\n", "agent_name_attrs", "=", "[", "'env'", ",", "'seed'", ",", "'tb'", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "  ", "if", "callable", "(", "base_config", ")", ":", "\n", "    ", "base_config", "=", "base_config", "(", ")", "\n", "", "config", "=", "base_config", "\n", "\n", "if", "hasattr", "(", "args", ",", "'num_envs'", ")", "and", "args", ".", "num_envs", "is", "None", ":", "\n", "    ", "import", "multiprocessing", "as", "mp", "\n", "args", ".", "num_envs", "=", "max", "(", "mp", ".", "cpu_count", "(", ")", "-", "1", ",", "1", ")", "\n", "\n", "", "if", "not", "hasattr", "(", "args", ",", "'prefix'", ")", ":", "\n", "    ", "args", ".", "prefix", "=", "'ddpg'", "\n", "", "if", "not", "args", ".", "tb", ":", "\n", "    ", "args", ".", "tb", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "\n", "", "merge_args_into_config", "(", "args", ",", "config", ")", "\n", "\n", "config", ".", "agent_name", "=", "make_agent_name", "(", "config", ",", "agent_name_attrs", ",", "prefix", "=", "args", ".", "prefix", ")", "\n", "\n", "\n", "base_modules", "=", "{", "\n", "k", ":", "v", "\n", "for", "k", ",", "v", "in", "dict", "(", "module_train", "=", "StandardTrain", "(", ")", ",", "\n", "module_eval", "=", "EpisodicEval", "(", ")", ",", "\n", "module_policy", "=", "ActorPolicy", "(", ")", ",", "\n", "module_logger", "=", "Logger", "(", ")", ",", "\n", "module_state_normalizer", "=", "Normalizer", "(", "MeanStdNormalizer", "(", ")", ")", ",", "\n", "module_replay", "=", "OnlineHERBuffer", "(", ")", ",", "\n", "module_action_noise", "=", "ContinuousActionNoise", "(", "GaussianProcess", ",", "\n", "std", "=", "ConstantSchedule", "(", "config", ".", "action_noise", ")", ")", ",", "\n", "module_algorithm", "=", "DDPG", "(", ")", ")", ".", "items", "(", ")", "if", "not", "k", "in", "config", "\n", "}", "\n", "\n", "config", ".", "update", "(", "base_modules", ")", "\n", "\n", "if", "type", "(", "args", ".", "env", ")", "is", "str", ":", "\n", "    ", "env", "=", "lambda", ":", "gym", ".", "make", "(", "args", ".", "env", ")", "\n", "eval_env", "=", "env", "\n", "", "else", ":", "\n", "    ", "env", "=", "args", ".", "env", "\n", "eval_env", "=", "env", "\n", "\n", "", "if", "hasattr", "(", "args", ",", "'eval_env'", ")", "and", "args", ".", "eval_env", "is", "not", "None", ":", "\n", "    ", "if", "type", "(", "args", ".", "eval_env", ")", "is", "str", ":", "\n", "      ", "eval_env", "=", "lambda", ":", "gym", ".", "make", "(", "args", ".", "eval_env", ")", "\n", "", "else", ":", "\n", "      ", "eval_env", "=", "args", ".", "eval_env", "\n", "\n", "\n", "\n", "", "", "config", ".", "module_train_env", "=", "EnvModule", "(", "env", ",", "num_envs", "=", "config", ".", "num_envs", ",", "seed", "=", "config", ".", "seed", ")", "\n", "config", ".", "module_eval_env", "=", "EnvModule", "(", "eval_env", ",", "num_envs", "=", "config", ".", "num_eval_envs", ",", "name", "=", "'eval_env'", ",", "seed", "=", "config", ".", "seed", "+", "1138", ")", "\n", "\n", "layer_norm", "=", "nn", ".", "LayerNorm", "if", "(", "hasattr", "(", "args", ",", "'layer_norm'", ")", "and", "args", ".", "layer_norm", ")", "else", "nn", ".", "Identity", "\n", "\n", "e", "=", "config", ".", "module_eval_env", "\n", "config", ".", "module_actor", "=", "PytorchModel", "(", "\n", "'actor'", ",", "lambda", ":", "Actor", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "layer_norm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "e", ".", "action_dim", ",", "e", ".", "max_action", ")", ")", "\n", "config", ".", "module_critic", "=", "PytorchModel", "(", "\n", "'critic'", ",", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "layer_norm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "1", ")", ")", "\n", "\n", "if", "e", ".", "goal_env", ":", "\n", "    ", "config", ".", "never_done", "=", "True", "# important for standard Gym goal environments, which are never done", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_td3_agent": [[81, 102], ["argparse.Namespace", "make_continuous_agents.make_ddpg_agent", "TD3", "PytorchModel", "hasattr", "Critic", "FCBody", "make_activ"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_ddpg_agent", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ"], ["", "def", "make_td3_agent", "(", "base_config", "=", "spinning_up_td3_config", ",", "\n", "args", "=", "Namespace", "(", "env", "=", "'InvertedPendulum-v2'", ",", "\n", "tb", "=", "''", ",", "\n", "prefix", "=", "'td3'", ",", "\n", "parent_folder", "=", "'/tmp/mrl'", ",", "\n", "layers", "=", "(", "256", ",", "256", ")", ",", "\n", "num_envs", "=", "None", ")", ",", "\n", "agent_name_attrs", "=", "[", "'env'", ",", "'seed'", ",", "'tb'", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "  ", "config", "=", "make_ddpg_agent", "(", "base_config", ",", "args", ",", "agent_name_attrs", ",", "**", "kwargs", ")", "\n", "del", "config", ".", "module_algorithm", "\n", "config", ".", "module_algorithm", "=", "TD3", "(", ")", "\n", "\n", "layer_norm", "=", "nn", ".", "LayerNorm", "if", "(", "hasattr", "(", "args", ",", "'layer_norm'", ")", "and", "args", ".", "layer_norm", ")", "else", "nn", ".", "Identity", "\n", "\n", "e", "=", "config", ".", "module_eval_env", "\n", "config", ".", "module_critic2", "=", "PytorchModel", "(", "'critic2'", ",", "\n", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "layer_norm", ",", "make_activ", "(", "config", ".", "activ", ")", ",", "False", ")", ",", "1", ",", "False", ")", ")", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_sac_agent": [[104, 133], ["argparse.Namespace", "make_continuous_agents.make_ddpg_agent", "StochasticActorPolicy", "SAC", "PytorchModel", "PytorchModel", "hasattr", "StochasticActor", "Critic", "FCBody", "FCBody", "make_activ", "make_activ"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_ddpg_agent", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ", "home.repos.pwc.inspect_result.spitis_mrl.utils.misc.make_activ"], ["", "def", "make_sac_agent", "(", "base_config", "=", "spinning_up_sac_config", ",", "\n", "args", "=", "Namespace", "(", "env", "=", "'InvertedPendulum-v2'", ",", "\n", "tb", "=", "''", ",", "\n", "prefix", "=", "'sac'", ",", "\n", "parent_folder", "=", "'/tmp/mrl'", ",", "\n", "layers", "=", "(", "256", ",", "256", ")", ",", "\n", "num_envs", "=", "None", ")", ",", "\n", "agent_name_attrs", "=", "[", "'env'", ",", "'seed'", ",", "'tb'", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "  ", "config", "=", "make_ddpg_agent", "(", "base_config", ",", "args", ",", "agent_name_attrs", ",", "**", "kwargs", ")", "\n", "e", "=", "config", ".", "module_eval_env", "\n", "layer_norm", "=", "nn", ".", "LayerNorm", "if", "(", "hasattr", "(", "args", ",", "'layer_norm'", ")", "and", "args", ".", "layer_norm", ")", "else", "nn", ".", "Identity", "\n", "\n", "del", "config", ".", "module_actor", "\n", "del", "config", ".", "module_action_noise", "\n", "del", "config", ".", "module_policy", "\n", "config", ".", "module_policy", "=", "StochasticActorPolicy", "(", ")", "\n", "del", "config", ".", "module_algorithm", "\n", "config", ".", "module_algorithm", "=", "SAC", "(", ")", "\n", "\n", "config", ".", "module_actor", "=", "PytorchModel", "(", "\n", "'actor'", ",", "lambda", ":", "StochasticActor", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", ",", "args", ".", "layers", ",", "layer_norm", ",", "make_activ", "(", "config", ".", "activ", ")", ")", ",", "\n", "e", ".", "action_dim", ",", "e", ".", "max_action", ",", "log_std_bounds", "=", "(", "-", "20", ",", "2", ")", ")", ")", "\n", "\n", "config", ".", "module_critic2", "=", "PytorchModel", "(", "'critic2'", ",", "\n", "lambda", ":", "Critic", "(", "FCBody", "(", "e", ".", "state_dim", "+", "e", ".", "goal_dim", "+", "e", ".", "action_dim", ",", "args", ".", "layers", ",", "layer_norm", ",", "make_activ", "(", "config", ".", "activ", ")", ",", "False", ")", ",", "1", ",", "False", ")", ")", "\n", "\n", "return", "config", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.protoge_config": [[59, 81], ["default_ddpg_config", "int"], "function", ["None"], ["\n", "\n", "", "", "class", "StochasticActorPolicy", "(", "mrl", ".", "Module", ")", ":", "\n", "  ", "\"\"\"Used for SAC / learned action noise\"\"\"", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'policy'", ",", "\n", "required_agent_modules", "=", "[", "\n", "'actor'", ",", "'env'", ",", "'replay_buffer'", "\n", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "", "def", "_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "use_actor_target", "=", "self", ".", "config", ".", "get", "(", "'use_actor_target'", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "state", ",", "greedy", "=", "False", ")", ":", "\n", "    ", "action_scale", "=", "self", ".", "env", ".", "max_action", "\n", "\n", "# initial exploration and intrinsic curiosity", "\n", "res", "=", "None", "\n", "if", "self", ".", "training", ":", "\n", "      ", "if", "self", ".", "config", ".", "get", "(", "'initial_explore'", ")", "and", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "config", ".", "initial_explore", ":", "\n", "          ", "res", "=", "np", ".", "array", "(", "[", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.best_slide_config": [[82, 95], ["continuous_off_policy.protoge_config", "int"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.protoge_config"], ["", "elif", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "state", "=", "self", ".", "ag_curiosity", ".", "relabel_state", "(", "state", ")", "\n", "\n", "", "", "state", "=", "flatten_state", "(", "state", ",", "self", ".", "config", ".", "modalities", "+", "self", ".", "config", ".", "goal_modalities", ")", "# flatten goal environments", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "state", "=", "self", ".", "state_normalizer", "(", "state", ",", "update", "=", "self", ".", "training", ")", "\n", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "      ", "return", "res", "\n", "\n", "", "state", "=", "self", ".", "torch", "(", "state", ")", "\n", "\n", "if", "self", ".", "use_actor_target", ":", "\n", "      ", "action", ",", "_", "=", "self", ".", "actor_target", "(", "state", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.protoge_td3_config": [[96, 112], ["default_ddpg_config", "int"], "function", ["None"], ["", "else", ":", "\n", "      ", "action", ",", "_", "=", "self", ".", "actor", "(", "state", ")", "\n", "", "action", "=", "self", ".", "numpy", "(", "action", ")", "\n", "\n", "if", "self", ".", "training", "and", "not", "greedy", "and", "self", ".", "config", ".", "get", "(", "'eexplore'", ")", ":", "\n", "      ", "eexplore", "=", "self", ".", "config", ".", "eexplore", "\n", "if", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "eexplore", "=", "self", ".", "ag_curiosity", ".", "go_explore", "*", "self", ".", "config", ".", "go_eexplore", "+", "eexplore", "\n", "", "mask", "=", "(", "np", ".", "random", ".", "random", "(", "(", "action", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "<", "eexplore", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "randoms", "=", "np", ".", "random", ".", "random", "(", "action", ".", "shape", ")", "*", "(", "2", "*", "action_scale", ")", "-", "action_scale", "\n", "action", "=", "mask", "*", "randoms", "+", "(", "1", "-", "mask", ")", "*", "action", "\n", "\n", "", "return", "np", ".", "clip", "(", "action", ",", "-", "action_scale", ",", "action_scale", ")", "\n", "\n", "\n", "", "", "class", "BatchConstrainedPolicy", "(", "mrl", ".", "Module", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_td3_config": [[113, 135], ["default_ddpg_config", "int"], "function", ["None"], ["\n", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'policy'", ",", "\n", "required_agent_modules", "=", "[", "\n", "'critic'", ",", "'actor'", ",", "'env'", ",", "'replay_buffer'", "\n", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "state", ",", "greedy", "=", "False", ")", ":", "\n", "    ", "action_scale", "=", "self", ".", "env", ".", "max_action", "\n", "\n", "# initial exploration and intrinsic curiosity", "\n", "res", "=", "None", "\n", "if", "self", ".", "training", ":", "\n", "      ", "if", "self", ".", "config", ".", "get", "(", "'initial_explore'", ")", "and", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "config", ".", "initial_explore", ":", "\n", "        ", "res", "=", "np", ".", "array", "(", "[", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", "for", "_", "in", "range", "(", "self", ".", "env", ".", "num_envs", ")", "]", ")", "\n", "", "elif", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "        ", "state", "=", "self", ".", "ag_curiosity", ".", "relabel_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_sac_config": [[136, 158], ["default_ddpg_config", "int"], "function", ["None"], ["", "", "state", "=", "flatten_state", "(", "state", ",", "self", ".", "config", ".", "modalities", "+", "self", ".", "config", ".", "goal_modalities", ")", "# flatten goal environments, # batch x state_dim", "\n", "if", "hasattr", "(", "self", ",", "'state_normalizer'", ")", ":", "\n", "      ", "state", "=", "self", ".", "state_normalizer", "(", "state", ",", "update", "=", "self", ".", "training", ")", "\n", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "      ", "return", "res", "\n", "\n", "", "state", "=", "self", ".", "torch", "(", "state", ")", "\n", "\n", "action_proposals", "=", "self", ".", "actor", "(", "state", ")", "# batch x num_proposals x action_dim", "\n", "states", "=", "torch", ".", "repeat_interleave", "(", "state", ",", "action_proposals", ".", "shape", "[", "1", "]", ",", "0", ")", "\n", "q_values", "=", "self", ".", "critic", "(", "states", ",", "action_proposals", ".", "reshape", "(", "-", "1", ",", "action_proposals", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "q_values", "=", "q_values", ".", "reshape", "(", "state", ".", "shape", "[", "0", "]", ",", "action_proposals", ".", "shape", "[", "1", "]", ")", "# batch x num_proposals", "\n", "best_actions", "=", "torch", ".", "argmax", "(", "q_values", ",", "dim", "=", "-", "1", ",", "keepdims", "=", "True", ")", "# batch x 1", "\n", "action", "=", "action_proposals", ".", "gather", "(", "1", ",", "torch", ".", "tile", "(", "best_actions", "[", ":", ",", ":", ",", "None", "]", ",", "(", "1", ",", "1", ",", "action_proposals", ".", "shape", "[", "2", "]", ")", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "action", "=", "self", ".", "numpy", "(", "action", ")", "\n", "\n", "if", "self", ".", "training", "and", "not", "greedy", ":", "\n", "      ", "action", "=", "self", ".", "action_noise", "(", "action", ")", "\n", "if", "self", ".", "config", ".", "get", "(", "'eexplore'", ")", ":", "\n", "        ", "eexplore", "=", "self", ".", "config", ".", "eexplore", "\n", "if", "hasattr", "(", "self", ",", "'ag_curiosity'", ")", ":", "\n", "          ", "eexplore", "=", "self", ".", "ag_curiosity", ".", "go_explore", "*", "self", ".", "config", ".", "go_eexplore", "+", "eexplore", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_ddpg_config": [[159, 164], ["continuous_off_policy.spinning_up_td3_config"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_td3_config"], ["", "mask", "=", "(", "np", ".", "random", ".", "random", "(", "(", "action", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "<", "eexplore", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "randoms", "=", "np", ".", "random", ".", "random", "(", "action", ".", "shape", ")", "*", "(", "2", "*", "action_scale", ")", "-", "action_scale", "\n", "action", "=", "mask", "*", "randoms", "+", "(", "1", "-", "mask", ")", "*", "action", "\n", "\n", "", "", "return", "np", ".", "clip", "(", "action", ",", "-", "action_scale", ",", "action_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.td3_config": [[165, 175], ["continuous_off_policy.spinning_up_td3_config"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.continuous_off_policy.spinning_up_td3_config"], ["\n", "", "", "class", "OffPolicyActorCritic", "(", "mrl", ".", "Module", ")", ":", "\n", "  ", "\"\"\"This is the standard DDPG\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "'algorithm'", ",", "\n", "required_agent_modules", "=", "[", "'actor'", ",", "'critic'", ",", "'replay_buffer'", ",", "'env'", "]", ",", "\n", "locals", "=", "locals", "(", ")", ")", "\n", "\n", "", "def", "_setup", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.__init__": [[34, 125], ["gym.spaces.Discrete", "gym.spaces.Box", "gym.spaces.Dict", "len", "os.path.dirname", "os.path.join", "os.path.exists", "numpy.zeros", "goal_grid.GoalGridWorldEnv._sample_goal_loc", "numpy.copy", "os.path.dirname", "os.path.join", "os.path.exists", "os.path.dirname", "os.path.join", "os.path.exists", "goal_grid.GoalGridWorldEnv._sample_agent_loc", "os.path.abspath", "numpy.loadtxt", "print", "os.path.abspath", "numpy.loadtxt", "print", "os.path.abspath", "numpy.loadtxt", "print", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._sample_goal_loc", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._sample_agent_loc"], ["def", "__init__", "(", "self", ",", "grid_size", "=", "16", ",", "max_step", "=", "100", ",", "grid_file", "=", "None", ",", "random_init_loc", "=", "True", ",", "agent_loc_file", "=", "None", ",", "goal_file", "=", "None", ",", "seed", "=", "1337", ")", ":", "\n", "# Action enumeration", "\n", "        ", "self", ".", "actions", "=", "GoalGridWorldEnv", ".", "Actions", "\n", "\n", "# Actions are discrete integer values", "\n", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "len", "(", "self", ".", "actions", ")", ")", "\n", "\n", "# Object types", "\n", "self", ".", "objects", "=", "GoalGridWorldEnv", ".", "ObjectTypes", "\n", "\n", "# Whether to change initialization of the agent", "\n", "self", ".", "random_init_loc", "=", "random_init_loc", "\n", "\n", "# Environment configuration", "\n", "self", ".", "grid_size", "=", "grid_size", "\n", "self", ".", "max_step", "=", "max_step", "\n", "\n", "self", ".", "end_of_game", "=", "False", "\n", "\n", "if", "grid_file", ":", "\n", "            ", "curr_abs_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "rel_path", "=", "os", ".", "path", ".", "join", "(", "curr_abs_path", ",", "\"grid_samples\"", ",", "grid_file", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "rel_path", ")", ":", "\n", "                ", "grid_file", "=", "rel_path", "\n", "self", ".", "grid", "=", "np", ".", "loadtxt", "(", "grid_file", ",", "delimiter", "=", "','", ")", "\n", "# Overwrite grid size if necessary", "\n", "self", ".", "grid_size_0", "=", "self", ".", "grid", ".", "shape", "[", "0", "]", "\n", "self", ".", "grid_size_1", "=", "self", ".", "grid", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Cannot find path: {}\"", ".", "format", "(", "rel_path", ")", ")", "\n", "", "", "else", ":", "\n", "# Generate an empty grid", "\n", "            ", "self", ".", "grid", "=", "np", ".", "zeros", "(", "(", "self", ".", "grid_size_0", ",", "self", ".", "grid_size_1", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "# Sample the agent", "\n", "self", ".", "goal_loc", "=", "self", ".", "_sample_goal_loc", "(", ")", "\n", "self", ".", "goal", "=", "np", ".", "copy", "(", "self", ".", "grid", ")", "\n", "self", ".", "goal", "[", "self", ".", "goal_loc", "[", "0", "]", ",", "self", ".", "goal_loc", "[", "1", "]", "]", "=", "self", ".", "objects", ".", "agent", "\n", "\n", "", "if", "goal_file", ":", "\n", "# Load the goal_file, which is a 0/1 mask for where we can sample goals from", "\n", "            ", "curr_abs_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "rel_path", "=", "os", ".", "path", ".", "join", "(", "curr_abs_path", ",", "\"grid_samples\"", ",", "goal_file", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "rel_path", ")", ":", "\n", "                ", "goal_file", "=", "rel_path", "\n", "self", ".", "goal_mask", "=", "np", ".", "loadtxt", "(", "goal_file", ",", "delimiter", "=", "','", ")", "\n", "# Check that the size of the goal mask is the same as grid size", "\n", "assert", "(", "self", ".", "goal_mask", ".", "shape", "[", "0", "]", "==", "self", ".", "grid", ".", "shape", "[", "0", "]", ")", "\n", "assert", "(", "self", ".", "goal_mask", ".", "shape", "[", "1", "]", "==", "self", ".", "grid", ".", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Cannot find path: {}\"", ".", "format", "(", "rel_path", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "goal_mask", "=", "None", "\n", "\n", "", "if", "agent_loc_file", ":", "\n", "# Load the goal_file, which is a 0/1 mask for where we can sample goals from", "\n", "            ", "curr_abs_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "rel_path", "=", "os", ".", "path", ".", "join", "(", "curr_abs_path", ",", "\"grid_samples\"", ",", "agent_loc_file", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "rel_path", ")", ":", "\n", "                ", "agent_loc_file", "=", "rel_path", "\n", "self", ".", "agent_mask", "=", "np", ".", "loadtxt", "(", "goal_file", ",", "delimiter", "=", "','", ")", "\n", "# Check that the size of the goal mask is the same as grid size", "\n", "assert", "(", "self", ".", "agent_mask", ".", "shape", "[", "0", "]", "==", "self", ".", "grid", ".", "shape", "[", "0", "]", ")", "\n", "assert", "(", "self", ".", "agent_mask", ".", "shape", "[", "1", "]", "==", "self", ".", "grid", ".", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Cannot find path: {}\"", ".", "format", "(", "rel_path", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "agent_mask", "=", "None", "\n", "\n", "# Set agent initial location", "\n", "", "if", "self", ".", "random_init_loc", ":", "\n", "            ", "self", ".", "agent_pos", "=", "self", ".", "_sample_agent_loc", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "agent_pos", "=", "[", "0", ",", "0", "]", "\n", "\n", "# Observations are dictionaries containing an", "\n", "# grid observation, achieved and desired goals", "\n", "", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "1", ",", "\n", "shape", "=", "(", "self", ".", "grid_size_0", ",", "self", ".", "grid_size_1", ",", "len", "(", "self", ".", "objects", ")", ")", ",", "\n", "dtype", "=", "'uint8'", "\n", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "{", "\n", "'observation'", ":", "observation_space", ",", "\n", "'desired_goal'", ":", "observation_space", ",", "\n", "'achieved_goal'", ":", "observation_space", "\n", "}", ")", "\n", "\n", "self", ".", "num_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.seed": [[129, 132], ["gym.utils.seeding.np_random"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "np_random", ",", "seed", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "return", "[", "seed", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.reset": [[133, 145], ["goal_grid.GoalGridWorldEnv._sample_goal_loc", "numpy.copy", "goal_grid.GoalGridWorldEnv._get_obs", "goal_grid.GoalGridWorldEnv._sample_goal_loc"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._sample_goal_loc", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._sample_goal_loc"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "end_of_game", "=", "False", "\n", "self", ".", "num_step", "=", "0", "\n", "if", "self", ".", "random_init_loc", ":", "\n", "            ", "self", ".", "agent_pos", "=", "self", ".", "_sample_goal_loc", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "agent_pos", "=", "[", "0", ",", "0", "]", "\n", "", "self", ".", "goal_loc", "=", "self", ".", "_sample_goal_loc", "(", ")", "\n", "self", ".", "goal", "=", "np", ".", "copy", "(", "self", ".", "grid", ")", "\n", "self", ".", "goal", "[", "self", ".", "goal_loc", "[", "0", "]", ",", "self", ".", "goal_loc", "[", "1", "]", "]", "=", "self", ".", "objects", ".", "agent", "\n", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.step": [[146, 168], ["goal_grid.GoalGridWorldEnv._take_action", "goal_grid.GoalGridWorldEnv._get_obs", "goal_grid.GoalGridWorldEnv.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._take_action", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"\n        Taking a step in the environment.\n\n        :param action:\n        :return:\n        \"\"\"", "\n", "# assert self.action_space.contains(action)", "\n", "# Take action, get reward, get observation", "\n", "self", ".", "_take_action", "(", "action", ")", "\n", "obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "info", "=", "{", "}", "\n", "reward", "=", "self", ".", "compute_reward", "(", "obs", "[", "'achieved_goal'", "]", ",", "obs", "[", "'desired_goal'", "]", ",", "info", ")", "\n", "\n", "self", ".", "num_step", "+=", "1", "\n", "\n", "if", "reward", "==", "1.0", "or", "self", ".", "num_step", "==", "self", ".", "max_step", "or", "self", ".", "end_of_game", ":", "\n", "            ", "done", "=", "1", "\n", "", "else", ":", "\n", "            ", "done", "=", "0", "\n", "\n", "", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._take_action": [[169, 188], ["goal_grid.GoalGridWorldEnv._get_new_position"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_new_position"], ["", "def", "_take_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"\n        Performs the action on the grid. Updates the grid information.\n\n        :param action:\n        :return:\n        \"\"\"", "\n", "# Move the agent in that direction", "\n", "new_agent_pos", "=", "self", ".", "_get_new_position", "(", "action", ")", "\n", "\n", "# Check if this position is a wall", "\n", "if", "self", ".", "grid", "[", "new_agent_pos", "[", "0", "]", ",", "new_agent_pos", "[", "1", "]", "]", "!=", "self", ".", "objects", ".", "wall", ":", "\n", "            ", "self", ".", "agent_pos", "=", "new_agent_pos", "\n", "\n", "# Set end of game if agent goes into lava", "\n", "", "if", "self", ".", "grid", "[", "self", ".", "agent_pos", "[", "0", "]", ",", "self", ".", "agent_pos", "[", "1", "]", "]", "==", "self", ".", "objects", ".", "lava", ":", "\n", "            ", "self", ".", "end_of_game", "=", "True", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_new_position": [[189, 205], ["None"], "methods", ["None"], ["", "def", "_get_new_position", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"\n        Apply the action to change the agent's position\n\n        :param action:\n        :return:\n        \"\"\"", "\n", "new_agent_pos", "=", "[", "self", ".", "agent_pos", "[", "0", "]", "+", "self", ".", "MOVE_DIRECTION", "[", "action", "]", "[", "0", "]", ",", "\n", "self", ".", "agent_pos", "[", "1", "]", "+", "self", ".", "MOVE_DIRECTION", "[", "action", "]", "[", "1", "]", "]", "\n", "\n", "# Check if the new location is out of boundary", "\n", "if", "new_agent_pos", "[", "0", "]", "<", "0", "or", "new_agent_pos", "[", "1", "]", "<", "0", "or", "new_agent_pos", "[", "0", "]", ">", "(", "self", ".", "grid_size_0", "-", "1", ")", "or", "new_agent_pos", "[", "1", "]", ">", "(", "self", ".", "grid_size_1", "-", "1", ")", ":", "\n", "            ", "return", "self", ".", "agent_pos", "\n", "", "else", ":", "\n", "            ", "return", "new_agent_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_reward": [[206, 211], ["None"], "methods", ["None"], ["", "", "def", "_get_reward", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "agent_pos", "[", "0", "]", "==", "self", ".", "goal_loc", "[", "0", "]", "and", "self", ".", "agent_pos", "[", "1", "]", "==", "self", ".", "goal_loc", "[", "1", "]", ":", "\n", "            ", "return", "1.0", "\n", "", "else", ":", "\n", "            ", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_obs": [[212, 224], ["goal_grid.GoalGridWorldEnv._get_state", "goal_grid.GoalGridWorldEnv.one_hot", "goal_grid.GoalGridWorldEnv._get_state", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state", "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.one_hot", "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "", "def", "_get_obs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the observation as a dictionary of observation and goals\n\n        :return:\n        \"\"\"", "\n", "obs", "=", "{", "\n", "'observation'", ":", "self", ".", "_get_state", "(", "self", ".", "grid", ")", ",", "\n", "'desired_goal'", ":", "self", ".", "one_hot", "(", "self", ".", "goal", ",", "len", "(", "self", ".", "objects", ")", ")", ",", "\n", "'achieved_goal'", ":", "self", ".", "_get_state", "(", "self", ".", "grid", ")", "\n", "}", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state": [[225, 241], ["numpy.copy", "goal_grid.GoalGridWorldEnv.one_hot", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.one_hot"], ["", "def", "_get_state", "(", "self", ",", "grid", ",", "use_one_hot", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Get the grid information.\n\n        :return:\n        \"\"\"", "\n", "# Convert to one-hot representation: [NxNxK] where N is the size of grid and K is number of object types", "\n", "state", "=", "np", ".", "copy", "(", "grid", ")", "\n", "\n", "# Set the agent's position on the grid", "\n", "state", "[", "self", ".", "agent_pos", "[", "0", "]", ",", "self", ".", "agent_pos", "[", "1", "]", "]", "=", "self", ".", "objects", ".", "agent", "\n", "\n", "if", "use_one_hot", ":", "\n", "            ", "state", "=", "self", ".", "one_hot", "(", "state", ",", "len", "(", "self", ".", "objects", ")", ")", "\n", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._sample_goal": [[242, 249], ["None"], "methods", ["None"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Sample an achievable state for the agent's goal\n\n        :return:\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._sample_goal_loc": [[250, 271], ["random.randint", "random.randint", "random.randint", "random.randint", "random.randint", "random.randint"], "methods", ["None"], ["", "def", "_sample_goal_loc", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate a goal location. Make sure that it is not a wall location,\n        or is valid according to the goal_file\n        :return:\n        \"\"\"", "\n", "coord_1", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_0", "-", "1", ")", "# TODO: Make it dependent on the seed", "\n", "coord_2", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_1", "-", "1", ")", "\n", "\n", "if", "self", ".", "goal_mask", "is", "not", "None", ":", "\n", "# Make sure that the sampled goal is a valid goal according to the mask", "\n", "            ", "while", "self", ".", "goal_mask", "[", "coord_1", ",", "coord_2", "]", "!=", "1", ":", "\n", "                ", "coord_1", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_0", "-", "1", ")", "# TODO: Make it dependent on the seed", "\n", "coord_2", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_1", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# Make sure that the sampled goal position is empty", "\n", "            ", "while", "self", ".", "grid", "[", "coord_1", ",", "coord_2", "]", "!=", "self", ".", "objects", ".", "empty", ":", "\n", "                ", "coord_1", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_0", "-", "1", ")", "# TODO: Make it dependent on the seed", "\n", "coord_2", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_1", "-", "1", ")", "\n", "\n", "", "", "return", "coord_1", ",", "coord_2", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._sample_agent_loc": [[272, 293], ["random.randint", "random.randint", "random.randint", "random.randint", "random.randint", "random.randint"], "methods", ["None"], ["", "def", "_sample_agent_loc", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate a agent location. Make sure that it is not a wall location,\n        or is valid according to the agent_loc_file\n        :return:\n        \"\"\"", "\n", "coord_1", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_0", "-", "1", ")", "# TODO: Make it dependent on the seed", "\n", "coord_2", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_1", "-", "1", ")", "\n", "\n", "if", "self", ".", "agent_mask", "is", "not", "None", ":", "\n", "# Make sure that the sampled goal is a valid goal according to the mask", "\n", "            ", "while", "self", ".", "agent_mask", "[", "coord_1", ",", "coord_2", "]", "!=", "1", ":", "\n", "                ", "coord_1", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_0", "-", "1", ")", "# TODO: Make it dependent on the seed", "\n", "coord_2", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_1", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# Make sure that the sampled goal position is empty", "\n", "            ", "while", "self", ".", "grid", "[", "coord_1", ",", "coord_2", "]", "!=", "self", ".", "objects", ".", "empty", ":", "\n", "                ", "coord_1", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_0", "-", "1", ")", "# TODO: Make it dependent on the seed", "\n", "coord_2", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "grid_size_1", "-", "1", ")", "\n", "\n", "", "", "return", "coord_1", ",", "coord_2", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.render": [[294, 313], ["matplotlib.clf", "range", "matplotlib.figtext", "matplotlib.pause", "matplotlib.clim", "matplotlib.show", "goal_grid.GoalGridWorldEnv._get_state", "matplotlib.subplot", "matplotlib.subplot.set_title", "matplotlib.imshow"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv._get_state"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "columns", "=", "2", "\n", "rows", "=", "1", "\n", "plt", ".", "clf", "(", ")", "\n", "\n", "imgs", "=", "[", "self", ".", "_get_state", "(", "self", ".", "grid", ",", "use_one_hot", "=", "False", ")", ",", "self", ".", "goal", "]", "\n", "titles", "=", "[", "\"Observation\"", ",", "\"Goal\"", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "columns", "*", "rows", "+", "1", ")", ":", "\n", "            ", "ax", "=", "plt", ".", "subplot", "(", "rows", ",", "columns", ",", "i", ")", "\n", "ax", ".", "set_title", "(", "titles", "[", "i", "-", "1", "]", ")", "\n", "plt", ".", "imshow", "(", "imgs", "[", "i", "-", "1", "]", ")", "\n", "\n", "", "plt", ".", "figtext", "(", "0.5", ",", "0.1", ",", "'Time step: {}'", ".", "format", "(", "self", ".", "num_step", ")", ",", "horizontalalignment", "=", "'center'", ")", "\n", "\n", "plt", ".", "pause", "(", "0.01", ")", "\n", "plt", ".", "clim", "(", "0", ",", "10", ")", "\n", "plt", ".", "show", "(", "block", "=", "False", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.compute_reward": [[314, 333], ["numpy.sum"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "desired_goal", ",", "info", ")", ":", "\n", "        ", "\"\"\"Compute the step reward. This externalizes the reward function and makes\n        it dependent on an a desired goal and the one that was achieved. If you wish to include\n        additional rewards that are independent of the goal, you can include the necessary values\n        to derive it in info and compute it accordingly.\n        Args:\n            achieved_goal (object): the goal that was achieved during execution\n            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n            info (dict): an info dictionary with additional information\n        Returns:\n            float: The reward that corresponds to the provided achieved goal w.r.t. to the desired\n            goal. Note that the following should always hold true:\n                ob, reward, done, info = env.step()\n                assert reward == env.compute_reward(ob['achieved_goal'], ob['goal'], info)\n        \"\"\"", "\n", "if", "np", ".", "sum", "(", "(", "achieved_goal", "-", "desired_goal", ")", "**", "2", ")", ">", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.goal_grid.GoalGridWorldEnv.one_hot": [[334, 339], ["vec.flatten", "oh.reshape.reshape.reshape", "numpy.eye", "vec.flatten.astype"], "methods", ["None"], ["", "", "def", "one_hot", "(", "self", ",", "vec", ",", "size", ")", ":", "\n", "        ", "flattened", "=", "vec", ".", "flatten", "(", ")", "\n", "oh", "=", "np", ".", "eye", "(", "size", ")", "[", "flattened", ".", "astype", "(", "int", ")", "]", "\n", "oh", "=", "oh", ".", "reshape", "(", "self", ".", "grid_size_0", ",", "self", ".", "grid_size_1", ",", "size", ")", "\n", "return", "oh", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.__init__.softmax": [[4, 8], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.goalgridworld.__init__.discrete_to_box_wrapper": [[10, 27], ["isinstance", "gym.spaces.Box", "numpy.clip", "__init__.softmax", "numpy.random.choice", "old_step", "range"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax"], []], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv.__init__": [[181, 238], ["range", "gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__", "max", "numpy.sqrt", "STACKXML.replace"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "max_step", "=", "50", ",", "\n", "n", "=", "1", ",", "\n", "internal_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "external_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "mode", "=", "\"-1/0\"", ",", "\n", "compute_reward_with_internal", "=", "False", ",", "\n", "per_dim_threshold", "=", "None", ",", "\n", "hard", "=", "False", ",", "\n", "distance_threshold", "=", "0.", ",", "\n", "range_min", "=", "None", ",", "\n", "range_max", "=", "None", ")", ":", "\n", "    ", "self", ".", "internal_goal", "=", "internal_goal", "\n", "self", ".", "external_goal", "=", "external_goal", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "hard", "=", "hard", "\n", "\n", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.405", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "k", "=", "'object{}:joint'", ".", "format", "(", "i", ")", "\n", "initial_qpos", "[", "k", "]", "=", "INIT_Q_POSES", "[", "i", "]", "\n", "\n", "", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "STACKXML", ".", "replace", "(", "'#'", ",", "'{}'", ".", "format", "(", "n", ")", ")", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "False", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.2", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "0.0", ",", "\n", "obj_range", "=", "0.15", ",", "\n", "target_range", "=", "0.1", ",", "\n", "distance_threshold", "=", "0.05", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "'sparse'", ")", "\n", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n", "self", ".", "max_step", "=", "max", "(", "50", "*", "(", "n", "-", "1", ")", ",", "50", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "\n", "self", ".", "mode", "=", "0", "\n", "if", "mode", "==", "\"0/1\"", "or", "mode", "==", "1", ":", "\n", "      ", "self", ".", "mode", "=", "1", "\n", "\n", "", "if", "self", ".", "external_goal", "==", "internal_goal", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "True", "\n", "", "else", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "compute_reward_with_internal", "\n", "\n", "", "self", ".", "per_dim_threshold", "=", "np", ".", "sqrt", "(", "self", ".", "distance_threshold", "**", "2", "/", "3", ")", "\n", "if", "per_dim_threshold", ":", "\n", "      ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv.compute_reward": [[239, 279], ["zip", "len", "numpy.ones", "gym.envs.robotics.fetch_env.goal_distance", "len", "gym.envs.robotics.fetch_env.goal_distance", "gym.envs.robotics.fetch_env.goal_distance", "len", "numpy.split", "numpy.split", "numpy.split", "numpy.split", "len", "numpy.split", "numpy.split", "numpy.split", "numpy.split"], "methods", ["None"], ["", "", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "# Compute distance between goal and the achieved goal.", "\n", "\n", "    ", "if", "self", ".", "external_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "      ", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "        ", "actual_internal_goals", "=", "np", ".", "split", "(", "goal", "[", ":", "-", "3", "]", ",", "self", ".", "n", ")", "\n", "achieved_internal_goals", "=", "np", ".", "split", "(", "achieved_goal", "[", ":", "-", "3", "]", ",", "self", ".", "n", ")", "\n", "", "else", ":", "\n", "        ", "actual_internal_goals", "=", "np", ".", "split", "(", "goal", "[", ":", ",", ":", "-", "3", "]", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "achieved_internal_goals", "=", "np", ".", "split", "(", "achieved_goal", "[", ":", ",", ":", "-", "3", "]", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "", "", "elif", "self", ".", "external_goal", "==", "GoalType", ".", "OBJ", ":", "\n", "      ", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "        ", "actual_internal_goals", "=", "np", ".", "split", "(", "goal", ",", "self", ".", "n", ")", "\n", "achieved_internal_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "self", ".", "n", ")", "\n", "", "else", ":", "\n", "        ", "actual_internal_goals", "=", "np", ".", "split", "(", "goal", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "achieved_internal_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "", "", "else", ":", "\n", "      ", "raise", "\n", "\n", "", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "success", "=", "1.", "\n", "", "else", ":", "\n", "      ", "success", "=", "np", ".", "ones", "(", "achieved_goal", ".", "shape", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "for", "b", ",", "g", "in", "zip", "(", "achieved_internal_goals", ",", "actual_internal_goals", ")", ":", "\n", "      ", "d", "=", "goal_distance", "(", "b", ",", "g", ")", "\n", "success", "*=", "(", "d", "<=", "self", ".", "distance_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "self", ".", "compute_reward_with_internal", ":", "\n", "      ", "return", "success", "-", "(", "1.", "-", "self", ".", "mode", ")", "\n", "\n", "# use per_dim_thresholds for other dimensions", "\n", "", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "d", "=", "goal_distance", "(", "achieved_goal", "[", "-", "3", ":", "]", ",", "goal", "[", "-", "3", ":", "]", ")", "\n", "", "else", ":", "\n", "      ", "d", "=", "goal_distance", "(", "achieved_goal", "[", ":", ",", "-", "3", ":", "]", ",", "goal", "[", ":", ",", "-", "3", ":", "]", ")", "\n", "", "success", "*=", "(", "d", "<=", "self", ".", "distance_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "return", "success", "-", "(", "1.", "-", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv._get_obs": [[280, 319], ["custom_fetch.StackEnv.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "range", "numpy.concatenate", "custom_fetch.StackEnv.sim.data.get_site_xvelp", "custom_fetch.StackEnv.sim.data.get_site_xpos().ravel", "max", "gym.envs.robotics.rotations.mat2euler().ravel", "obj_feats.append", "obj_poses.append", "numpy.concatenate", "numpy.concatenate", "custom_fetch.StackEnv.goal.copy", "sum", "custom_fetch.StackEnv.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "custom_fetch.StackEnv.sim.data.get_site_xmat", "custom_fetch.StackEnv.sim.data.get_site_xvelp", "custom_fetch.StackEnv.sim.data.get_site_xvelr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "# positions", "\n", "    ", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "\n", "obj_feats", "=", "[", "]", "\n", "obj_poses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "obj_labl", "=", "'object{}'", ".", "format", "(", "i", ")", "\n", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "obj_labl", ")", ".", "ravel", "(", ")", "\n", "object_pos", "[", "2", "]", "=", "max", "(", "object_pos", "[", "2", "]", ",", "self", ".", "height_offset", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "obj_labl", ")", ")", ".", "ravel", "(", ")", "\n", "# velocities", "\n", "object_velp", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "obj_labl", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "object_velr", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "obj_labl", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "# gripper state", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "#object_velp -= grip_velp", "\n", "\n", "obj_feats", ".", "append", "(", "[", "object_pos", ",", "object_rel_pos", ",", "object_rot", ",", "object_velp", ",", "object_velr", "]", ")", "\n", "obj_poses", ".", "append", "(", "object_pos", ")", "\n", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "if", "self", ".", "external_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "      ", "achieved_goal", "=", "np", ".", "concatenate", "(", "obj_poses", "+", "[", "grip_pos", "]", ")", "\n", "", "else", ":", "\n", "      ", "achieved_goal", "=", "np", ".", "concatenate", "(", "obj_poses", ")", "\n", "", "obs", "=", "np", ".", "concatenate", "(", "[", "grip_pos", ",", "gripper_state", ",", "grip_velp", ",", "gripper_vel", "]", "+", "sum", "(", "obj_feats", ",", "[", "]", ")", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv._render_callback": [[321, 333], ["range", "custom_fetch.StackEnv.sim.forward", "numpy.split", "numpy.split", "custom_fetch.StackEnv.sim.model.site_name2id"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", "\n", "if", "self", ".", "external_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "      ", "goals", "=", "np", ".", "split", "(", "self", ".", "goal", "[", ":", "-", "3", "]", ",", "self", ".", "n", ")", "\n", "", "else", ":", "\n", "      ", "goals", "=", "np", ".", "split", "(", "self", ".", "goal", ",", "self", ".", "n", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target{}'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goals", "[", "i", "]", "-", "sites_offset", "[", "i", "]", "\n", "", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv._reset_sim": [[334, 358], ["custom_fetch.StackEnv.sim.set_state", "range", "custom_fetch.StackEnv.sim.forward", "custom_fetch.StackEnv.sim.data.get_joint_qpos", "custom_fetch.StackEnv.np_random.uniform", "custom_fetch.StackEnv.sim.data.set_joint_qpos"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_reset_sim", "(", "self", ")", ":", "\n", "    ", "self", ".", "sim", ".", "set_state", "(", "self", ".", "initial_state", ")", "\n", "\n", "# Only a little randomize about the start state", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "object_qpos", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qpos", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ")", "\n", "object_qpos", "[", ":", "2", "]", "+=", "self", ".", "np_random", ".", "uniform", "(", "-", "0.03", ",", "0.03", ",", "size", "=", "2", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ",", "object_qpos", ")", "\n", "\n", "", "bad_poses", "=", "[", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "]", "\n", "# Randomize start positions of boxes.", "\n", "# for i in range(self.n):", "\n", "#   object_xpos = self.initial_gripper_xpos[:2]", "\n", "#   while min([np.linalg.norm(object_xpos - p) for p in bad_poses]) < 0.1:", "\n", "#       object_xpos = self.initial_gripper_xpos[:2] + self.np_random.uniform(-self.obj_range, self.obj_range, size=2)", "\n", "#   bad_poses.append(object_xpos)", "\n", "\n", "#   object_qpos = self.sim.data.get_joint_qpos('object{}:joint'.format(i))", "\n", "#   assert object_qpos.shape == (7,)", "\n", "#   object_qpos[:2] = object_xpos", "\n", "#   self.sim.data.set_joint_qpos('object{}:joint'.format(i), object_qpos)", "\n", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv._sample_goal": [[359, 371], ["range", "numpy.concatenate", "custom_fetch.StackEnv.np_random.uniform", "goal.append", "goal.append", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "bottom_box", "=", "self", ".", "initial_gripper_xpos", "[", ":", "3", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "3", ")", "\n", "bottom_box", "[", "2", "]", "=", "self", ".", "height_offset", "#self.sim.data.get_joint_qpos('object0:joint')[:3]", "\n", "\n", "goal", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "goal", ".", "append", "(", "bottom_box", "+", "(", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.05", "]", ")", "*", "i", ")", ")", "\n", "\n", "", "if", "self", ".", "external_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "      ", "goal", ".", "append", "(", "goal", "[", "-", "1", "]", "+", "np", ".", "array", "(", "[", "-", "0.01", ",", "0.", ",", "0.008", "]", ")", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "goal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv.step": [[372, 383], ["super().step", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "if", "self", ".", "mode", "==", "1", "and", "reward", ":", "\n", "      ", "done", "=", "True", "\n", "\n", "", "info", "[", "'is_success'", "]", "=", "np", ".", "allclose", "(", "reward", ",", "self", ".", "mode", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.StackEnv.reset": [[384, 388], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushEnv.__init__": [[391, 430], ["gym.envs.robotics.fetch.push.FetchPushEnv.__init__", "numpy.sqrt", "print", "ValueError", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "max_step", "=", "51", ",", "\n", "internal_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "external_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "mode", "=", "\"-1/0\"", ",", "\n", "compute_reward_with_internal", "=", "False", ",", "\n", "per_dim_threshold", "=", "None", ",", "\n", "hard", "=", "False", ",", "\n", "distance_threshold", "=", "0.", ",", "\n", "n", "=", "0", ",", "\n", "range_min", "=", "None", ",", "\n", "range_max", "=", "None", ")", ":", "\n", "    ", "self", ".", "internal_goal", "=", "internal_goal", "\n", "self", ".", "external_goal", "=", "external_goal", "\n", "if", "hard", "or", "n", ">", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"Hard not supported\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "reward_type", "=", "'sparse'", ")", "\n", "\n", "if", "distance_threshold", ">", "1e-5", ":", "\n", "      ", "self", ".", "distance_threshold", "=", "distance_threshold", "\n", "\n", "", "if", "self", ".", "internal_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "      ", "self", ".", "distance_threshold", "*=", "np", ".", "sqrt", "(", "2", ")", "\n", "\n", "", "self", ".", "max_step", "=", "max_step", "\n", "self", ".", "num_step", "=", "0", "\n", "self", ".", "mode", "=", "0", "\n", "if", "mode", "==", "\"0/1\"", "or", "mode", "==", "1", ":", "\n", "      ", "self", ".", "mode", "=", "1", "\n", "\n", "", "if", "self", ".", "external_goal", "==", "internal_goal", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "True", "\n", "", "else", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "compute_reward_with_internal", "\n", "\n", "", "self", ".", "per_dim_threshold", "=", "np", ".", "sqrt", "(", "self", ".", "distance_threshold", "**", "2", "/", "3", ")", "\n", "if", "per_dim_threshold", ":", "\n", "      ", "self", ".", "per_dim_threshold", "=", "per_dim_threshold", "\n", "", "print", "(", "'PER DIM THRESHOLD:'", ",", "self", ".", "per_dim_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushEnv.compute_reward": [[431, 434], ["custom_fetch.PushEnv.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "    ", "return", "compute_reward", "(", "achieved_goal", ",", "goal", ",", "self", ".", "internal_goal", ",", "self", ".", "distance_threshold", ",", "self", ".", "per_dim_threshold", ",", "\n", "self", ".", "compute_reward_with_internal", ",", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushEnv._render_callback": [[435, 444], ["custom_fetch.PushEnv.sim.model.site_name2id", "custom_fetch.PushEnv.sim.forward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", ".", "copy", "(", ")", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target0'", ")", "\n", "\n", "goal", "=", "self", ".", "goal", "[", ":", "3", "]", "\n", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goal", "-", "sites_offset", "[", "0", "]", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushEnv._get_obs": [[445, 447], ["custom_fetch.get_obs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.get_obs"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "return", "get_obs", "(", "self", ".", "sim", ",", "self", ".", "external_goal", ",", "self", ".", "goal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushEnv._sample_goal": [[448, 451], ["custom_fetch.sample_goal", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "return", "sample_goal", "(", "self", ".", "initial_gripper_xpos", ",", "self", ".", "np_random", ",", "self", ".", "target_range", ",", "self", ".", "target_offset", ",", "\n", "self", ".", "height_offset", ",", "self", ".", "internal_goal", ",", "self", ".", "external_goal", ",", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.05", "]", ")", ",", "[", "0.", ",", "0.", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushEnv.step": [[452, 463], ["super().step", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "if", "self", ".", "mode", "==", "1", "and", "reward", ":", "\n", "      ", "done", "=", "True", "\n", "\n", "", "info", "[", "'is_success'", "]", "=", "np", ".", "allclose", "(", "reward", ",", "self", ".", "mode", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushEnv.reset": [[464, 468], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideEnv.__init__": [[471, 512], ["gym.envs.robotics.fetch.slide.FetchSlideEnv.__init__", "numpy.sqrt", "print", "ValueError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "max_step", "=", "51", ",", "\n", "internal_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "external_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "mode", "=", "\"-1/0\"", ",", "\n", "compute_reward_with_internal", "=", "False", ",", "\n", "per_dim_threshold", "=", "None", ",", "\n", "hard", "=", "False", ",", "\n", "distance_threshold", "=", "0.", ",", "\n", "n", "=", "0", ",", "\n", "range_min", "=", "None", ",", "\n", "range_max", "=", "None", ")", ":", "\n", "    ", "self", ".", "internal_goal", "=", "internal_goal", "\n", "self", ".", "external_goal", "=", "external_goal", "\n", "\n", "self", ".", "subtract_obj_velp", "=", "True", "\n", "if", "self", ".", "external_goal", "in", "[", "GoalType", ".", "OBJSPEED", ",", "GoalType", ".", "OBJSPEED2", "]", ":", "\n", "      ", "self", ".", "subtract_obj_velp", "=", "False", "\n", "\n", "", "if", "hard", "or", "n", ">", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"Hard not supported\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "reward_type", "=", "'sparse'", ")", "\n", "\n", "if", "distance_threshold", ">", "1e-5", ":", "\n", "      ", "self", ".", "distance_threshold", "=", "distance_threshold", "\n", "\n", "", "self", ".", "max_step", "=", "max_step", "\n", "self", ".", "num_step", "=", "0", "\n", "self", ".", "mode", "=", "0", "\n", "if", "mode", "==", "\"0/1\"", "or", "mode", "==", "1", ":", "\n", "      ", "self", ".", "mode", "=", "1", "\n", "\n", "", "if", "self", ".", "external_goal", "==", "internal_goal", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "True", "\n", "", "else", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "compute_reward_with_internal", "\n", "\n", "", "self", ".", "per_dim_threshold", "=", "np", ".", "sqrt", "(", "self", ".", "distance_threshold", "**", "2", "/", "3", ")", "\n", "if", "isinstance", "(", "per_dim_threshold", ",", "float", ")", "and", "per_dim_threshold", ">", "1e-3", ":", "\n", "      ", "self", ".", "per_dim_threshold", "=", "per_dim_threshold", "\n", "", "print", "(", "'PER DIM THRESHOLD:'", ",", "self", ".", "per_dim_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideEnv.compute_reward": [[513, 516], ["custom_fetch.SlideEnv.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "    ", "return", "compute_reward", "(", "achieved_goal", ",", "goal", ",", "self", ".", "internal_goal", ",", "self", ".", "distance_threshold", ",", "self", ".", "per_dim_threshold", ",", "\n", "self", ".", "compute_reward_with_internal", ",", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideEnv._render_callback": [[517, 526], ["custom_fetch.SlideEnv.sim.model.site_name2id", "custom_fetch.SlideEnv.sim.forward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", ".", "copy", "(", ")", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target0'", ")", "\n", "\n", "goal", "=", "self", ".", "goal", "[", ":", "3", "]", "\n", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goal", "-", "sites_offset", "[", "0", "]", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideEnv._get_obs": [[527, 529], ["custom_fetch.get_obs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.get_obs"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "return", "get_obs", "(", "self", ".", "sim", ",", "self", ".", "external_goal", ",", "self", ".", "goal", ",", "self", ".", "subtract_obj_velp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideEnv._sample_goal": [[530, 533], ["custom_fetch.sample_goal", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "return", "sample_goal", "(", "self", ".", "initial_gripper_xpos", ",", "self", ".", "np_random", ",", "self", ".", "target_range", ",", "self", ".", "target_offset", ",", "\n", "self", ".", "height_offset", ",", "self", ".", "internal_goal", ",", "self", ".", "external_goal", ",", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.05", "]", ")", ",", "[", "0.", ",", "0.", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideEnv.step": [[534, 545], ["super().step", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "if", "self", ".", "mode", "==", "1", "and", "reward", ":", "\n", "      ", "done", "=", "True", "\n", "\n", "", "info", "[", "'is_success'", "]", "=", "np", ".", "allclose", "(", "reward", ",", "self", ".", "mode", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideEnv.reset": [[546, 550], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PickPlaceEnv.__init__": [[553, 594], ["gym.envs.robotics.fetch.pick_and_place.FetchPickAndPlaceEnv.__init__", "numpy.sqrt", "print"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "max_step", "=", "51", ",", "\n", "internal_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "external_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "mode", "=", "\"-1/0\"", ",", "\n", "compute_reward_with_internal", "=", "False", ",", "\n", "per_dim_threshold", "=", "None", ",", "\n", "hard", "=", "False", ",", "\n", "distance_threshold", "=", "0.", ",", "\n", "n", "=", "0.5", ",", "\n", "range_min", "=", "0.2", ",", "\n", "range_max", "=", "0.45", ")", ":", "\n", "    ", "self", ".", "internal_goal", "=", "internal_goal", "\n", "self", ".", "external_goal", "=", "external_goal", "\n", "if", "hard", ":", "\n", "      ", "self", ".", "minimum_air", "=", "range_min", "\n", "self", ".", "maximum_air", "=", "range_max", "\n", "", "else", ":", "\n", "      ", "self", ".", "minimum_air", "=", "0.", "\n", "self", ".", "maximum_air", "=", "range_max", "\n", "", "self", ".", "in_air_percentage", "=", "n", "\n", "super", "(", ")", ".", "__init__", "(", "reward_type", "=", "'sparse'", ")", "\n", "\n", "if", "distance_threshold", ">", "1e-5", ":", "\n", "      ", "self", ".", "distance_threshold", "=", "distance_threshold", "\n", "\n", "", "self", ".", "max_step", "=", "max_step", "\n", "self", ".", "num_step", "=", "0", "\n", "self", ".", "mode", "=", "0", "\n", "if", "mode", "==", "\"0/1\"", "or", "mode", "==", "1", ":", "\n", "      ", "self", ".", "mode", "=", "1", "\n", "\n", "", "if", "self", ".", "external_goal", "==", "internal_goal", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "True", "\n", "", "else", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "compute_reward_with_internal", "\n", "\n", "", "self", ".", "per_dim_threshold", "=", "np", ".", "sqrt", "(", "self", ".", "distance_threshold", "**", "2", "/", "3", ")", "\n", "if", "per_dim_threshold", ":", "\n", "      ", "self", ".", "per_dim_threshold", "=", "per_dim_threshold", "\n", "", "print", "(", "'PER DIM THRESHOLD:'", ",", "self", ".", "per_dim_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PickPlaceEnv.compute_reward": [[595, 598], ["custom_fetch.PickPlaceEnv.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "    ", "return", "compute_reward", "(", "achieved_goal", ",", "goal", ",", "self", ".", "internal_goal", ",", "self", ".", "distance_threshold", ",", "self", ".", "per_dim_threshold", ",", "\n", "self", ".", "compute_reward_with_internal", ",", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PickPlaceEnv._render_callback": [[599, 608], ["custom_fetch.PickPlaceEnv.sim.model.site_name2id", "custom_fetch.PickPlaceEnv.sim.forward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", ".", "copy", "(", ")", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target0'", ")", "\n", "\n", "goal", "=", "self", ".", "goal", "[", ":", "3", "]", "\n", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goal", "-", "sites_offset", "[", "0", "]", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PickPlaceEnv._get_obs": [[609, 611], ["custom_fetch.get_obs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.get_obs"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "return", "get_obs", "(", "self", ".", "sim", ",", "self", ".", "external_goal", ",", "self", ".", "goal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PickPlaceEnv._sample_goal": [[612, 618], ["custom_fetch.sample_goal", "custom_fetch.PickPlaceEnv.np_random.uniform", "custom_fetch.PickPlaceEnv.np_random.uniform", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "height_offset", "=", "self", ".", "height_offset", "\n", "if", "self", ".", "np_random", ".", "uniform", "(", ")", "<", "self", ".", "in_air_percentage", ":", "\n", "      ", "height_offset", "+=", "self", ".", "np_random", ".", "uniform", "(", "self", ".", "minimum_air", ",", "self", ".", "maximum_air", ")", "\n", "", "return", "sample_goal", "(", "self", ".", "initial_gripper_xpos", ",", "self", ".", "np_random", ",", "self", ".", "target_range", ",", "self", ".", "target_offset", ",", "height_offset", ",", "\n", "self", ".", "internal_goal", ",", "self", ".", "external_goal", ",", "np", ".", "array", "(", "[", "-", "0.01", ",", "0.", ",", "0.008", "]", ")", ",", "[", "0.024273", ",", "0.024273", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PickPlaceEnv.step": [[619, 630], ["super().step", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "if", "self", ".", "mode", "==", "1", "and", "reward", ":", "\n", "      ", "done", "=", "True", "\n", "\n", "", "info", "[", "'is_success'", "]", "=", "np", ".", "allclose", "(", "reward", ",", "self", ".", "mode", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PickPlaceEnv.reset": [[631, 635], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRandGoalDistEnv.__init__": [[645, 677], ["custom_fetch.PushEnv.__init__", "custom_fetch.PushRandGoalDistEnv.seed", "custom_fetch.PushRandGoalDistEnv.np_random.randn", "numpy.linalg.inv", "custom_fetch.PushEnv._sample_goal", "numpy.isfinite", "custom_fetch.PushRandGoalDistEnv.np_random.randn", "numpy.linalg.cond"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal"], ["  ", "def", "__init__", "(", "self", ",", "\n", "max_step", "=", "51", ",", "\n", "internal_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "external_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "mode", "=", "\"-1/0\"", ",", "\n", "compute_reward_with_internal", "=", "False", ",", "\n", "per_dim_threshold", "=", "None", ",", "\n", "compute_external_reward_with_soft_threshold", "=", "0", ",", "\n", "seed", "=", "123", ")", ":", "\n", "    ", "self", ".", "done_init", "=", "False", "\n", "# May be there's a nicer way to pass down the init to parent", "\n", "super", "(", ")", ".", "__init__", "(", "max_step", "=", "max_step", ",", "\n", "internal_goal", "=", "internal_goal", ",", "\n", "external_goal", "=", "external_goal", ",", "\n", "mode", "=", "mode", ",", "\n", "compute_reward_with_internal", "=", "compute_reward_with_internal", ",", "\n", "per_dim_threshold", "=", "per_dim_threshold", ",", "\n", "compute_external_reward_with_soft_threshold", "=", "compute_external_reward_with_soft_threshold", ")", "\n", "self", ".", "done_init", "=", "True", "\n", "# Additionally sample a random invertible matrix", "\n", "self", ".", "seed", "(", "seed", ")", "\n", "\n", "# Get the size of the goal for this configuration from parent class", "\n", "goal_shape", "=", "super", "(", ")", ".", "_sample_goal", "(", ")", ".", "shape", "\n", "\n", "W", "=", "self", ".", "np_random", ".", "randn", "(", "goal_shape", "[", "0", "]", ",", "goal_shape", "[", "0", "]", ")", "\n", "# Check if W is invertible, sample new ones if not", "\n", "while", "not", "np", ".", "isfinite", "(", "np", ".", "linalg", ".", "cond", "(", "W", ")", ")", ":", "\n", "      ", "W", "=", "self", ".", "np_random", ".", "randn", "(", "goal_shape", "[", "0", "]", ",", "goal_shape", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "rand_goal_W", "=", "W", "\n", "self", ".", "rand_goal_W_inv", "=", "np", ".", "linalg", ".", "inv", "(", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRandGoalDistEnv._sample_goal": [[678, 687], ["custom_fetch.PushEnv._sample_goal", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "goal", "=", "super", "(", ")", ".", "_sample_goal", "(", ")", "\n", "\n", "# Check if has done init yet. If not then just use the original goal space", "\n", "if", "self", ".", "done_init", ":", "\n", "# Apply random distillation", "\n", "      ", "return", "np", ".", "dot", "(", "self", ".", "rand_goal_W", ",", "goal", ")", "\n", "", "else", ":", "\n", "      ", "return", "goal", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRandGoalDistEnv._render_callback": [[688, 702], ["custom_fetch.PushRandGoalDistEnv.sim.model.site_name2id", "custom_fetch.PushRandGoalDistEnv.sim.forward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", ".", "copy", "(", ")", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target0'", ")", "\n", "\n", "if", "self", ".", "external_goal", "==", "GoalType", ".", "OBJ", ":", "\n", "      ", "goal", "=", "self", ".", "goal", "\n", "", "elif", "self", ".", "external_goal", "==", "GoalType", ".", "OBJSPEED", ":", "\n", "      ", "goal", "=", "self", ".", "goal", "[", ":", "3", "]", "\n", "", "else", ":", "\n", "      ", "goal", "=", "self", ".", "goal", "[", "3", ":", "6", "]", "\n", "\n", "", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goal", "-", "sites_offset", "[", "0", "]", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRandGoalDistEnv._get_obs": [[703, 712], ["custom_fetch.PushEnv._get_obs", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "observation", "=", "super", "(", ")", ".", "_get_obs", "(", ")", "\n", "\n", "if", "self", ".", "done_init", ":", "\n", "# Apply random distillation for the achieved goal.", "\n", "# desired_goal is already in the distillation form", "\n", "      ", "observation", "[", "'achieved_goal'", "]", "=", "np", ".", "dot", "(", "self", ".", "rand_goal_W", ",", "observation", "[", "'achieved_goal'", "]", ")", "\n", "\n", "", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRandGoalDistEnv.compute_reward": [[713, 722], ["numpy.dot", "numpy.dot", "custom_fetch.PushEnv.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "# Invert the goals back to original goal space, then use compute reward func from parent", "\n", "\n", "    ", "og_achieved_goal", "=", "np", ".", "dot", "(", "self", ".", "rand_goal_W_inv", ",", "achieved_goal", ")", "\n", "og_desired_goal", "=", "np", ".", "dot", "(", "self", ".", "rand_goal_W_inv", ",", "goal", ")", "\n", "\n", "reward", "=", "super", "(", ")", ".", "compute_reward", "(", "og_achieved_goal", ",", "og_desired_goal", ",", "info", ")", "\n", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideRandGoalDistEnv.__init__": [[725, 754], ["custom_fetch.SlideEnv.__init__", "custom_fetch.SlideRandGoalDistEnv.seed", "custom_fetch.SlideRandGoalDistEnv.np_random.randn", "numpy.linalg.inv", "custom_fetch.SlideEnv._sample_goal", "numpy.isfinite", "custom_fetch.SlideRandGoalDistEnv.np_random.randn", "numpy.linalg.cond"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal"], ["  ", "def", "__init__", "(", "self", ",", "\n", "max_step", "=", "51", ",", "\n", "internal_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "external_goal", "=", "GoalType", ".", "OBJ", ",", "\n", "mode", "=", "\"-1/0\"", ",", "\n", "compute_reward_with_internal", "=", "False", ",", "\n", "per_dim_threshold", "=", "None", ",", "\n", "seed", "=", "123", ")", ":", "\n", "    ", "self", ".", "done_init", "=", "False", "\n", "super", "(", ")", ".", "__init__", "(", "max_step", "=", "max_step", ",", "\n", "internal_goal", "=", "internal_goal", ",", "\n", "external_goal", "=", "external_goal", ",", "\n", "mode", "=", "mode", ",", "\n", "compute_reward_with_internal", "=", "compute_reward_with_internal", ",", "\n", "per_dim_threshold", "=", "per_dim_threshold", ")", "\n", "self", ".", "done_init", "=", "True", "\n", "# Additionally sample a random invertible matrix", "\n", "self", ".", "seed", "(", "seed", ")", "\n", "\n", "# Get the size of the goal for this configuration from parent class", "\n", "goal_shape", "=", "super", "(", ")", ".", "_sample_goal", "(", ")", ".", "shape", "\n", "\n", "W", "=", "self", ".", "np_random", ".", "randn", "(", "goal_shape", "[", "0", "]", ",", "goal_shape", "[", "0", "]", ")", "\n", "# Check if W is invertible, sample new ones if not", "\n", "while", "not", "np", ".", "isfinite", "(", "np", ".", "linalg", ".", "cond", "(", "W", ")", ")", ":", "\n", "      ", "W", "=", "self", ".", "np_random", ".", "randn", "(", "goal_shape", "[", "0", "]", ",", "goal_shape", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "rand_goal_W", "=", "W", "\n", "self", ".", "rand_goal_W_inv", "=", "np", ".", "linalg", ".", "inv", "(", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideRandGoalDistEnv._sample_goal": [[755, 764], ["custom_fetch.SlideEnv._sample_goal", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "goal", "=", "super", "(", ")", ".", "_sample_goal", "(", ")", "\n", "\n", "# Check if has done init yet. If not then just use the original goal space", "\n", "if", "self", ".", "done_init", ":", "\n", "# Apply random distillation", "\n", "      ", "return", "np", ".", "dot", "(", "self", ".", "rand_goal_W", ",", "goal", ")", "\n", "", "else", ":", "\n", "      ", "return", "goal", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideRandGoalDistEnv._get_obs": [[765, 774], ["custom_fetch.SlideEnv._get_obs", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["", "", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "observation", "=", "super", "(", ")", ".", "_get_obs", "(", ")", "\n", "\n", "if", "self", ".", "done_init", ":", "\n", "# Apply random distillation for the achieved goal.", "\n", "# desired_goal is already in the distillation form", "\n", "      ", "observation", "[", "'achieved_goal'", "]", "=", "np", ".", "dot", "(", "self", ".", "rand_goal_W", ",", "observation", "[", "'achieved_goal'", "]", ")", "\n", "\n", "", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideRandGoalDistEnv.compute_reward": [[775, 784], ["numpy.dot", "numpy.dot", "custom_fetch.SlideEnv.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "# Invert the goals back to original goal space, then use compute reward func from parent", "\n", "\n", "    ", "og_achieved_goal", "=", "np", ".", "dot", "(", "self", ".", "rand_goal_W_inv", ",", "achieved_goal", ")", "\n", "og_desired_goal", "=", "np", ".", "dot", "(", "self", ".", "rand_goal_W_inv", ",", "goal", ")", "\n", "\n", "reward", "=", "super", "(", ")", ".", "compute_reward", "(", "og_achieved_goal", ",", "og_desired_goal", ",", "info", ")", "\n", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushGoalVisualizer.__init__": [[787, 809], ["gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.405", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "'object0:joint'", ":", "[", "1.25", ",", "0.53", ",", "0.4", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "}", "\n", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "PUSHXML", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "True", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.0", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "0.0", ",", "\n", "obj_range", "=", "0.15", ",", "\n", "target_range", "=", "0.15", ",", "\n", "distance_threshold", "=", "0.05", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "'sparse'", ")", "\n", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushGoalVisualizer._render_callback": [[810, 820], ["custom_fetch.PushGoalVisualizer.sim.model.site_name2id", "custom_fetch.PushGoalVisualizer.sim.model.site_name2id", "custom_fetch.PushGoalVisualizer.sim.forward", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", ".", "copy", "(", ")", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target0'", ")", "\n", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "self", ".", "goal", "-", "sites_offset", "[", "0", "]", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target1'", ")", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "self", ".", "goal", "-", "sites_offset", "[", "0", "]", "+", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.05", "]", ")", "\n", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PPGoalVisualizer.__init__": [[823, 845], ["gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.405", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "'object0:joint'", ":", "[", "1.25", ",", "0.53", ",", "0.4", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "}", "\n", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "PPXML", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "False", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.2", ",", "\n", "target_in_the_air", "=", "True", ",", "\n", "target_offset", "=", "0.0", ",", "\n", "obj_range", "=", "0.15", ",", "\n", "target_range", "=", "0.15", ",", "\n", "distance_threshold", "=", "0.05", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "'sparse'", ")", "\n", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PPGoalVisualizer._render_callback": [[846, 856], ["custom_fetch.PPGoalVisualizer.sim.model.site_name2id", "custom_fetch.PPGoalVisualizer.sim.model.site_name2id", "custom_fetch.PPGoalVisualizer.sim.forward", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", ".", "copy", "(", ")", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target0'", ")", "\n", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "self", ".", "goal", "-", "sites_offset", "[", "0", "]", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target1'", ")", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "self", ".", "goal", "-", "sites_offset", "[", "0", "]", "+", "np", ".", "array", "(", "[", "-", "0.01", ",", "0.", ",", "0.008", "]", ")", "\n", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideGoalVisualizer.__init__": [[859, 884], ["gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.05", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "'table0:slide0'", ":", "0.7", ",", "\n", "'table0:slide1'", ":", "0.3", ",", "\n", "'table0:slide2'", ":", "0.0", ",", "\n", "'object0:joint'", ":", "[", "1.7", ",", "1.1", ",", "0.4", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "}", "\n", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "SLIDEXML", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "True", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "-", "0.02", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "np", ".", "array", "(", "[", "0.4", ",", "0.0", ",", "0.0", "]", ")", ",", "\n", "obj_range", "=", "0.1", ",", "\n", "target_range", "=", "0.3", ",", "\n", "distance_threshold", "=", "0.05", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "'sparse'", ")", "\n", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideGoalVisualizer._render_callback": [[885, 895], ["custom_fetch.SlideGoalVisualizer.sim.model.site_name2id", "custom_fetch.SlideGoalVisualizer.sim.model.site_name2id", "custom_fetch.SlideGoalVisualizer.sim.forward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", ".", "copy", "(", ")", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target0'", ")", "\n", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "self", ".", "goal", "-", "sites_offset", "[", "0", "]", "\n", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target1'", ")", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "self", ".", "goal", "-", "sites_offset", "[", "0", "]", "\n", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushLeft.__init__": [[898, 921], ["gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "reward_type", "=", "'sparse'", ")", ":", "\n", "    ", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.405", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "'object0:joint'", ":", "[", "1.25", ",", "0.53", ",", "0.4", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "}", "\n", "self", ".", "max_step", "=", "50", "\n", "self", ".", "num_step", "=", "0", "\n", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "ORIGPUSHXML", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "True", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.0", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "0.0", ",", "\n", "obj_range", "=", "0.15", ",", "\n", "target_range", "=", "0.15", ",", "\n", "distance_threshold", "=", "0.05", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "reward_type", ")", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushLeft._env_setup": [[922, 942], ["initial_qpos.items", "gym.envs.robotics.utils.reset_mocap_welds", "custom_fetch.PushLeft.sim.forward", "numpy.array", "numpy.array", "custom_fetch.PushLeft.sim.data.set_mocap_pos", "custom_fetch.PushLeft.sim.data.set_mocap_quat", "range", "numpy.array", "custom_fetch.PushLeft.sim.data.set_joint_qpos", "custom_fetch.PushLeft.sim.data.get_site_xpos", "custom_fetch.PushLeft.sim.step", "numpy.array", "custom_fetch.PushLeft.sim.data.get_site_xpos"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "_env_setup", "(", "self", ",", "initial_qpos", ")", ":", "\n", "    ", "for", "name", ",", "value", "in", "initial_qpos", ".", "items", "(", ")", ":", "\n", "      ", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "name", ",", "value", ")", "\n", "", "utils", ".", "reset_mocap_welds", "(", "self", ".", "sim", ")", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n", "delta", "=", "np", ".", "array", "(", "[", "-", "0.2", ",", "0.", ",", "0.", "]", ")", "\n", "# Move end effector into position.", "\n", "gripper_target", "=", "np", ".", "array", "(", "[", "-", "0.498", ",", "0.005", ",", "-", "0.431", "+", "self", ".", "gripper_extra_height", "\n", "]", ")", "+", "delta", "+", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "gripper_rotation", "=", "np", ".", "array", "(", "[", "1.", ",", "0.", ",", "1.", ",", "0.", "]", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_pos", "(", "'robot0:mocap'", ",", "gripper_target", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_quat", "(", "'robot0:mocap'", ",", "gripper_rotation", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "      ", "self", ".", "sim", ".", "step", "(", ")", "\n", "\n", "# Extract information for sampling goals.", "\n", "", "self", ".", "initial_gripper_xpos", "=", "np", ".", "array", "(", "[", "1.34182673", ",", "0.74891285", ",", "0.41317183", "]", ")", "\n", "if", "self", ".", "has_object", ":", "\n", "      ", "self", ".", "height_offset", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushLeft.step": [[943, 948], ["super().step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushLeft.reset": [[949, 953], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushLeft._sample_goal": [[954, 967], ["goal.copy", "custom_fetch.PushLeft.np_random.random", "custom_fetch.PushLeft.np_random.uniform", "custom_fetch.PushLeft.np_random.uniform", "custom_fetch.PushLeft.np_random.uniform", "custom_fetch.PushLeft.np_random.uniform", "custom_fetch.PushLeft.np_random.uniform"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "has_object", ":", "\n", "      ", "if", "self", ".", "np_random", ".", "random", "(", ")", "<", "0.15", ":", "\n", "        ", "goal", "=", "self", ".", "initial_gripper_xpos", "[", ":", "3", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "3", ")", "\n", "", "else", ":", "\n", "        ", "goal", "=", "self", ".", "initial_gripper_xpos", "[", ":", "3", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "0.", ",", "size", "=", "3", ")", "\n", "", "goal", "+=", "self", ".", "target_offset", "\n", "goal", "[", "2", "]", "=", "self", ".", "height_offset", "\n", "if", "self", ".", "target_in_the_air", "and", "self", ".", "np_random", ".", "uniform", "(", ")", "<", "0.5", ":", "\n", "        ", "goal", "[", "2", "]", "+=", "self", ".", "np_random", ".", "uniform", "(", "0", ",", "0.45", ")", "\n", "", "", "else", ":", "\n", "      ", "goal", "=", "self", ".", "initial_gripper_xpos", "[", ":", "3", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "0.15", ",", "0.15", ",", "size", "=", "3", ")", "\n", "", "return", "goal", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRight.__init__": [[970, 993], ["gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "reward_type", "=", "'sparse'", ")", ":", "\n", "    ", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.405", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "'object0:joint'", ":", "[", "1.25", ",", "0.53", ",", "0.4", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "}", "\n", "self", ".", "max_step", "=", "50", "\n", "self", ".", "num_step", "=", "0", "\n", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "ORIGPUSHXML", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "True", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.0", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "0.0", ",", "\n", "obj_range", "=", "0.15", ",", "\n", "target_range", "=", "0.15", ",", "\n", "distance_threshold", "=", "0.05", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "reward_type", ")", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRight._env_setup": [[994, 1014], ["initial_qpos.items", "gym.envs.robotics.utils.reset_mocap_welds", "custom_fetch.PushRight.sim.forward", "numpy.array", "numpy.array", "custom_fetch.PushRight.sim.data.set_mocap_pos", "custom_fetch.PushRight.sim.data.set_mocap_quat", "range", "numpy.array", "custom_fetch.PushRight.sim.data.set_joint_qpos", "custom_fetch.PushRight.sim.data.get_site_xpos", "custom_fetch.PushRight.sim.step", "numpy.array", "custom_fetch.PushRight.sim.data.get_site_xpos"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "_env_setup", "(", "self", ",", "initial_qpos", ")", ":", "\n", "    ", "for", "name", ",", "value", "in", "initial_qpos", ".", "items", "(", ")", ":", "\n", "      ", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "name", ",", "value", ")", "\n", "", "utils", ".", "reset_mocap_welds", "(", "self", ".", "sim", ")", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n", "delta", "=", "np", ".", "array", "(", "[", "0.2", ",", "0.", ",", "0.", "]", ")", "\n", "# Move end effector into position.", "\n", "gripper_target", "=", "np", ".", "array", "(", "[", "-", "0.498", ",", "0.005", ",", "-", "0.431", "+", "self", ".", "gripper_extra_height", "\n", "]", ")", "+", "delta", "+", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "gripper_rotation", "=", "np", ".", "array", "(", "[", "1.", ",", "0.", ",", "1.", ",", "0.", "]", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_pos", "(", "'robot0:mocap'", ",", "gripper_target", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_quat", "(", "'robot0:mocap'", ",", "gripper_rotation", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "      ", "self", ".", "sim", ".", "step", "(", ")", "\n", "\n", "# Extract information for sampling goals.", "\n", "", "self", ".", "initial_gripper_xpos", "=", "np", ".", "array", "(", "[", "1.34182673", ",", "0.74891285", ",", "0.41317183", "]", ")", "\n", "if", "self", ".", "has_object", ":", "\n", "      ", "self", ".", "height_offset", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRight.step": [[1015, 1021], ["super().step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRight.reset": [[1022, 1026], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushRight._sample_goal": [[1027, 1040], ["goal.copy", "custom_fetch.PushRight.np_random.random", "custom_fetch.PushRight.np_random.uniform", "custom_fetch.PushRight.np_random.uniform", "custom_fetch.PushRight.np_random.uniform", "custom_fetch.PushRight.np_random.uniform", "custom_fetch.PushRight.np_random.uniform"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "has_object", ":", "\n", "      ", "if", "self", ".", "np_random", ".", "random", "(", ")", "<", "0.15", ":", "\n", "        ", "goal", "=", "self", ".", "initial_gripper_xpos", "[", ":", "3", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "3", ")", "\n", "", "else", ":", "\n", "        ", "goal", "=", "self", ".", "initial_gripper_xpos", "[", ":", "3", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "0.", ",", "self", ".", "target_range", ",", "size", "=", "3", ")", "\n", "", "goal", "+=", "self", ".", "target_offset", "\n", "goal", "[", "2", "]", "=", "self", ".", "height_offset", "\n", "if", "self", ".", "target_in_the_air", "and", "self", ".", "np_random", ".", "uniform", "(", ")", "<", "0.5", ":", "\n", "        ", "goal", "[", "2", "]", "+=", "self", ".", "np_random", ".", "uniform", "(", "0", ",", "0.45", ")", "\n", "", "", "else", ":", "\n", "      ", "goal", "=", "self", ".", "initial_gripper_xpos", "[", ":", "3", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "0.15", ",", "0.15", ",", "size", "=", "3", ")", "\n", "", "return", "goal", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DisentangledFetchPushEnv._get_obs": [[1043, 1074], ["custom_fetch.DisentangledFetchPushEnv.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "numpy.squeeze", "numpy.concatenate", "custom_fetch.DisentangledFetchPushEnv.sim.data.get_site_xvelp", "custom_fetch.DisentangledFetchPushEnv.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "numpy.zeros", "numpy.zeros.copy", "numpy.concatenate.copy", "numpy.squeeze.copy", "custom_fetch.DisentangledFetchPushEnv.goal.copy", "custom_fetch.DisentangledFetchPushEnv.sim.data.get_site_xmat", "custom_fetch.DisentangledFetchPushEnv.sim.data.get_site_xvelp", "custom_fetch.DisentangledFetchPushEnv.sim.data.get_site_xvelr", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros.ravel"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["  ", "def", "_get_obs", "(", "self", ")", ":", "\n", "# positions", "\n", "    ", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "if", "self", ".", "has_object", ":", "\n", "        ", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "'object0'", ")", ")", "\n", "# velocities", "\n", "object_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'object0'", ")", "*", "dt", "\n", "object_velr", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "'object0'", ")", "*", "dt", "\n", "# gripper state", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "object_velp", "-=", "grip_velp", "\n", "", "else", ":", "\n", "        ", "object_pos", "=", "object_rot", "=", "object_velp", "=", "object_velr", "=", "object_rel_pos", "=", "np", ".", "zeros", "(", "0", ")", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "achieved_goal", "=", "np", ".", "squeeze", "(", "object_pos", ".", "copy", "(", ")", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "\n", "grip_pos", ",", "gripper_state", ",", "grip_velp", ",", "gripper_vel", ",", "\n", "object_pos", ".", "ravel", "(", ")", ",", "object_rot", ".", "ravel", "(", ")", ",", "object_velp", ".", "ravel", "(", ")", ",", "object_velr", ".", "ravel", "(", ")", ",", "\n", "]", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "obs", ".", "copy", "(", ")", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ".", "copy", "(", ")", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPush.__init__": [[1078, 1088], ["gym.envs.robotics.fetch.push.FetchPushEnv.__init__", "custom_fetch.DictPush._get_obs", "gym.spaces.Dict", "dict", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "dict", "(", "\n", "observation", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", "desired_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'achieved_goal'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "achieved_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'achieved_goal'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "gripper", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'gripper'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "object", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'object'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "relative", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'relative'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPush._get_obs": [[1090, 1120], ["custom_fetch.DictPush.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "custom_fetch.DictPush.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "numpy.squeeze", "custom_fetch.DictPush.sim.data.get_site_xvelp", "custom_fetch.DictPush.sim.data.get_site_xmat", "custom_fetch.DictPush.sim.data.get_site_xvelp", "custom_fetch.DictPush.sim.data.get_site_xvelr", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "custom_fetch.DictPush.goal.copy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "\n", "# gripper state", "\n", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "# object state", "\n", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "'object0'", ")", ")", "\n", "# velocities", "\n", "object_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'object0'", ")", "*", "dt", "\n", "object_velr", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "'object0'", ")", "*", "dt", "\n", "# relative states", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "object_rel_vel", "=", "object_velp", "-", "grip_velp", "\n", "\n", "achieved_goal", "=", "np", ".", "squeeze", "(", "object_pos", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "np", ".", "zeros", "(", "0", ")", ",", "# hack to get around gym's GoalEnv checks", "\n", "'gripper'", ":", "np", ".", "concatenate", "(", "[", "grip_pos", ",", "gripper_state", ",", "grip_velp", ",", "gripper_vel", "]", ")", ",", "\n", "'object'", ":", "np", ".", "concatenate", "(", "[", "object_pos", ",", "object_rot", ",", "object_velp", ",", "object_velr", "]", ")", ",", "\n", "'relative'", ":", "np", ".", "concatenate", "(", "[", "object_rel_pos", ",", "object_rel_vel", "]", ")", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPush.achieved_goal": [[1122, 1127], ["len"], "methods", ["None"], ["", "def", "achieved_goal", "(", "self", ",", "observation", ")", ":", "\n", "    ", "obj", "=", "observation", "[", "'object'", "]", "\n", "if", "len", "(", "obj", ".", "shape", ")", "==", "1", ":", "\n", "      ", "return", "obj", "[", ":", "3", "]", "\n", "", "return", "obj", "[", ":", ",", ":", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPushAndReach.__init__": [[1129, 1141], ["gym.envs.robotics.fetch.push.FetchPushEnv.__init__", "custom_fetch.DictPushAndReach._get_obs", "gym.spaces.Dict", "dict", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "dict", "(", "\n", "observation", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", "desired_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'achieved_goal'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "achieved_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'achieved_goal'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "gripper", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'gripper'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "object", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'object'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "relative", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'relative'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "gripper_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "3", ",", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", "object_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "3", ",", ")", ",", "dtype", "=", "'float32'", ")", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPushAndReach._get_obs": [[1143, 1173], ["custom_fetch.DictPushAndReach.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "custom_fetch.DictPushAndReach.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "numpy.squeeze", "custom_fetch.DictPushAndReach.sim.data.get_site_xvelp", "custom_fetch.DictPushAndReach.sim.data.get_site_xmat", "custom_fetch.DictPushAndReach.sim.data.get_site_xvelp", "custom_fetch.DictPushAndReach.sim.data.get_site_xvelr", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "custom_fetch.DictPushAndReach.goal.copy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "\n", "# gripper state", "\n", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "# object state", "\n", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "'object0'", ")", ")", "\n", "# velocities", "\n", "object_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'object0'", ")", "*", "dt", "\n", "object_velr", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "'object0'", ")", "*", "dt", "\n", "# relative states", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "object_rel_vel", "=", "object_velp", "-", "grip_velp", "\n", "\n", "achieved_goal", "=", "np", ".", "squeeze", "(", "object_pos", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "np", ".", "zeros", "(", "0", ")", ",", "# hack to get around gym's GoalEnv checks", "\n", "'gripper'", ":", "np", ".", "concatenate", "(", "[", "grip_pos", ",", "gripper_state", ",", "grip_velp", ",", "gripper_vel", "]", ")", ",", "\n", "'object'", ":", "np", ".", "concatenate", "(", "[", "object_pos", ",", "object_rot", ",", "object_velp", ",", "object_velr", "]", ")", ",", "\n", "'relative'", ":", "np", ".", "concatenate", "(", "[", "object_rel_pos", ",", "object_rel_vel", "]", ")", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DictPushAndReach.achieved_goal": [[1175, 1180], ["len"], "methods", ["None"], ["", "def", "achieved_goal", "(", "self", ",", "observation", ")", ":", "\n", "    ", "obj", "=", "observation", "[", "'object'", "]", "\n", "if", "len", "(", "obj", ".", "shape", ")", "==", "1", ":", "\n", "      ", "return", "obj", "[", ":", "3", "]", "\n", "", "return", "obj", "[", ":", ",", ":", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DisentangledFetchSlideEnv.__init__": [[1183, 1205], ["gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "distance_threshold", "=", "0.05", ",", "reward_type", "=", "'sparse'", ")", ":", "\n", "    ", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.05", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "'object0:joint'", ":", "[", "1.7", ",", "1.1", ",", "0.41", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "}", "\n", "assert", "False", ",", "\"NEEEDS TO BE REVISED\"", "\n", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "ORIGSLIDEXML", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "True", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "-", "0.02", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "np", ".", "array", "(", "[", "0.4", ",", "0.0", ",", "0.0", "]", ")", ",", "\n", "obj_range", "=", "0.1", ",", "\n", "target_range", "=", "0.3", ",", "\n", "distance_threshold", "=", "distance_threshold", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "reward_type", ")", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DisentangledFetchSlideEnv._get_obs": [[1206, 1253], ["custom_fetch.DisentangledFetchSlideEnv.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "custom_fetch.DisentangledFetchSlideEnv.sim.data.get_site_xvelp", "custom_fetch.DisentangledFetchSlideEnv.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "numpy.zeros", "custom_fetch.DisentangledFetchSlideEnv.copy", "numpy.squeeze", "numpy.stack", "numpy.squeeze.copy", "custom_fetch.DisentangledFetchSlideEnv.goal.copy", "custom_fetch.DisentangledFetchSlideEnv.sim.data.get_site_xmat", "custom_fetch.DisentangledFetchSlideEnv.sim.data.get_site_xvelp", "custom_fetch.DisentangledFetchSlideEnv.sim.data.get_site_xvelr", "numpy.zeros.copy", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros_like", "numpy.zeros_like"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "# positions", "\n", "    ", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "if", "self", ".", "has_object", ":", "\n", "      ", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "'object0'", ")", ")", "\n", "# velocities", "\n", "object_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'object0'", ")", "*", "dt", "\n", "object_velr", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "'object0'", ")", "*", "dt", "\n", "# gripper state", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "object_velp", "-=", "grip_velp", "\n", "", "else", ":", "\n", "      ", "object_pos", "=", "object_rot", "=", "object_velp", "=", "object_velr", "=", "object_rel_pos", "=", "np", ".", "zeros", "(", "0", ")", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "if", "not", "self", ".", "has_object", ":", "\n", "      ", "achieved_goal", "=", "grip_pos", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "      ", "achieved_goal", "=", "np", ".", "squeeze", "(", "object_pos", ".", "copy", "(", ")", ")", "\n", "\n", "", "grip_obs", "=", "np", ".", "concatenate", "(", "[", "\n", "grip_pos", ",", "\n", "gripper_state", ",", "\n", "grip_velp", ",", "\n", "gripper_vel", ",", "\n", "]", ")", "\n", "\n", "obj_obs", "=", "np", ".", "concatenate", "(", "[", "\n", "object_pos", ".", "ravel", "(", ")", ",", "\n", "object_rot", ".", "ravel", "(", ")", ",", "\n", "object_velp", ".", "ravel", "(", ")", ",", "\n", "object_velr", ".", "ravel", "(", ")", ",", "\n", "]", ")", "\n", "\n", "grip_obs_padded", "=", "np", ".", "concatenate", "(", "(", "grip_obs", ",", "np", ".", "zeros_like", "(", "obj_obs", ")", ")", ",", "0", ")", "\n", "obj_obs_padded", "=", "np", ".", "concatenate", "(", "(", "np", ".", "zeros_like", "(", "grip_obs", ")", ",", "obj_obs", ")", ",", "0", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "np", ".", "stack", "(", "(", "grip_obs_padded", ",", "obj_obs_padded", ")", ",", "0", ")", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ".", "copy", "(", ")", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.DisentangledFetchPickAndPlaceEnv._get_obs": [[1257, 1305], ["custom_fetch.DisentangledFetchPickAndPlaceEnv.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "custom_fetch.DisentangledFetchPickAndPlaceEnv.sim.data.get_site_xvelp", "custom_fetch.DisentangledFetchPickAndPlaceEnv.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "numpy.zeros", "custom_fetch.DisentangledFetchPickAndPlaceEnv.copy", "numpy.squeeze", "numpy.stack", "numpy.squeeze.copy", "custom_fetch.DisentangledFetchPickAndPlaceEnv.goal.copy", "custom_fetch.DisentangledFetchPickAndPlaceEnv.sim.data.get_site_xmat", "custom_fetch.DisentangledFetchPickAndPlaceEnv.sim.data.get_site_xvelp", "custom_fetch.DisentangledFetchPickAndPlaceEnv.sim.data.get_site_xvelr", "numpy.zeros.copy", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros.ravel", "numpy.zeros_like", "numpy.zeros_like"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["  ", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "assert", "False", ",", "\"NEEEDS TO BE REVISED\"", "\n", "# positions", "\n", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "if", "self", ".", "has_object", ":", "\n", "      ", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "'object0'", ")", ")", "\n", "# velocities", "\n", "object_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'object0'", ")", "*", "dt", "\n", "object_velr", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "'object0'", ")", "*", "dt", "\n", "# gripper state", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "object_velp", "-=", "grip_velp", "\n", "", "else", ":", "\n", "      ", "object_pos", "=", "object_rot", "=", "object_velp", "=", "object_velr", "=", "object_rel_pos", "=", "np", ".", "zeros", "(", "0", ")", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "if", "not", "self", ".", "has_object", ":", "\n", "      ", "achieved_goal", "=", "grip_pos", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "      ", "achieved_goal", "=", "np", ".", "squeeze", "(", "object_pos", ".", "copy", "(", ")", ")", "\n", "\n", "", "grip_obs", "=", "np", ".", "concatenate", "(", "[", "\n", "grip_pos", ",", "\n", "gripper_state", ",", "\n", "grip_velp", ",", "\n", "gripper_vel", ",", "\n", "]", ")", "\n", "\n", "obj_obs", "=", "np", ".", "concatenate", "(", "[", "\n", "object_pos", ".", "ravel", "(", ")", ",", "\n", "object_rot", ".", "ravel", "(", ")", ",", "\n", "object_velp", ".", "ravel", "(", ")", ",", "\n", "object_velr", ".", "ravel", "(", ")", ",", "\n", "]", ")", "\n", "\n", "grip_obs_padded", "=", "np", ".", "concatenate", "(", "(", "grip_obs", ",", "np", ".", "zeros_like", "(", "obj_obs", ")", ")", ",", "0", ")", "\n", "obj_obs_padded", "=", "np", ".", "concatenate", "(", "(", "np", ".", "zeros_like", "(", "grip_obs", ")", ",", "obj_obs", ")", ",", "0", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "np", ".", "stack", "(", "(", "grip_obs_padded", ",", "obj_obs_padded", ")", ",", "0", ")", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ".", "copy", "(", ")", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv.__init__": [[1309, 1347], ["numpy.concatenate", "range", "gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__", "SLIDE_N_XML.replace", "numpy.arange", "numpy.arange", "range", "numpy.array", "numpy.arange", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "n", "=", "1", ",", "\n", "distance_threshold", "=", "0.075", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "n", "=", "n", "\n", "self", ".", "disentangled_idxs", "=", "[", "np", ".", "arange", "(", "10", ")", "]", "+", "[", "10", "+", "12", "*", "i", "+", "np", ".", "arange", "(", "12", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "self", ".", "disentangled_goal_idxs", "=", "[", "3", "*", "i", "+", "np", ".", "arange", "(", "3", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "self", ".", "ag_dims", "=", "np", ".", "concatenate", "(", "[", "a", "[", ":", "3", "]", "for", "a", "in", "self", ".", "disentangled_idxs", "[", "1", ":", "]", "]", ")", "\n", "if", "not", "distance_threshold", ">", "1e-5", ":", "\n", "      ", "distance_threshold", "=", "0.075", "# default", "\n", "\n", "", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.05", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "k", "=", "'object{}:joint'", ".", "format", "(", "i", ")", "\n", "initial_qpos", "[", "k", "]", "=", "INIT_Q_POSES_SLIDE", "[", "i", "]", "\n", "\n", "\n", "", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "SLIDE_N_XML", ".", "replace", "(", "'#'", ",", "'{}'", ".", "format", "(", "n", ")", ")", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "True", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "np", ".", "array", "(", "[", "-", "0.075", ",", "0.0", ",", "0.0", "]", ")", ",", "\n", "obj_range", "=", "0.15", ",", "\n", "target_range", "=", "0.30", ",", "\n", "distance_threshold", "=", "distance_threshold", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "'sparse'", ")", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n", "self", ".", "max_step", "=", "50", "+", "25", "*", "(", "n", "-", "1", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv.reset": [[1349, 1353], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv._reset_sim": [[1354, 1380], ["custom_fetch.SlideNEnv.sim.set_state", "range", "custom_fetch.SlideNEnv.sim.forward", "bad_poses.append", "custom_fetch.SlideNEnv.sim.data.get_joint_qpos", "custom_fetch.SlideNEnv.sim.data.get_joint_qvel", "numpy.array", "custom_fetch.SlideNEnv.sim.data.set_joint_qpos", "custom_fetch.SlideNEnv.sim.data.set_joint_qvel", "min", "numpy.zeros_like", "custom_fetch.SlideNEnv.np_random.uniform", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_reset_sim", "(", "self", ")", ":", "\n", "    ", "self", ".", "sim", ".", "set_state", "(", "self", ".", "initial_state", ")", "\n", "\n", "# Only a little randomize about the start state", "\n", "# for i in range(self.n):", "\n", "#   object_qpos = self.sim.data.get_joint_qpos('object{}:joint'.format(i))", "\n", "#   object_qpos[:2] += self.np_random.uniform(-0.03, 0.03, size=2)", "\n", "#   self.sim.data.set_joint_qpos('object{}:joint'.format(i), object_qpos)", "\n", "\n", "bad_poses", "=", "[", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "]", "\n", "# Randomize start positions of pucks.", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "\n", "while", "min", "(", "[", "np", ".", "linalg", ".", "norm", "(", "object_xpos", "-", "p", ")", "for", "p", "in", "bad_poses", "]", ")", "<", "0.08", ":", "\n", "          ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "obj_range", ",", "self", ".", "obj_range", ",", "size", "=", "2", ")", "\n", "", "bad_poses", ".", "append", "(", "object_xpos", ")", "\n", "\n", "object_qpos", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qpos", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ")", "\n", "object_qvel", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qvel", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ")", "\n", "object_qpos", "[", ":", "2", "]", "=", "object_xpos", "\n", "object_qpos", "[", "2", ":", "]", "=", "np", ".", "array", "(", "[", "0.42", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ",", "object_qpos", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qvel", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ",", "np", ".", "zeros_like", "(", "object_qvel", ")", ")", "\n", "\n", "", "self", ".", "sim", ".", "forward", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv._sample_goal": [[1381, 1394], ["range", "numpy.concatenate", "custom_fetch.SlideNEnv.np_random.uniform", "goal_xys.append", "numpy.concatenate", "custom_fetch.SlideNEnv.np_random.uniform", "min", "custom_fetch.SlideNEnv.np_random.uniform", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "first_puck", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "2", ")", "\n", "\n", "goal_xys", "=", "[", "first_puck", "[", ":", "2", "]", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", "-", "1", ")", ":", "\n", "      ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "2", ")", "\n", "while", "min", "(", "[", "np", ".", "linalg", ".", "norm", "(", "object_xpos", "-", "p", ")", "for", "p", "in", "goal_xys", "]", ")", "<", "0.08", ":", "\n", "        ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "2", ")", "\n", "", "goal_xys", ".", "append", "(", "object_xpos", ")", "\n", "\n", "", "goals", "=", "[", "np", ".", "concatenate", "(", "(", "goal", ",", "[", "self", ".", "height_offset", "]", ")", ")", "for", "goal", "in", "goal_xys", "]", "\n", "\n", "return", "np", ".", "concatenate", "(", "goals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv._env_setup": [[1395, 1413], ["initial_qpos.items", "gym.envs.robotics.utils.reset_mocap_welds", "custom_fetch.SlideNEnv.sim.forward", "numpy.array", "custom_fetch.SlideNEnv.sim.data.set_mocap_pos", "custom_fetch.SlideNEnv.sim.data.set_mocap_quat", "range", "custom_fetch.SlideNEnv.sim.data.get_site_xpos().copy", "custom_fetch.SlideNEnv.sim.data.set_joint_qpos", "numpy.array", "custom_fetch.SlideNEnv.sim.data.get_site_xpos", "custom_fetch.SlideNEnv.sim.step", "custom_fetch.SlideNEnv.sim.data.get_site_xpos", "custom_fetch.SlideNEnv.sim.data.get_site_xpos"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "_env_setup", "(", "self", ",", "initial_qpos", ")", ":", "\n", "      ", "for", "name", ",", "value", "in", "initial_qpos", ".", "items", "(", ")", ":", "\n", "          ", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "name", ",", "value", ")", "\n", "", "utils", ".", "reset_mocap_welds", "(", "self", ".", "sim", ")", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n", "# Move end effector into position.", "\n", "gripper_target", "=", "np", ".", "array", "(", "[", "-", "0.548", ",", "0.005", ",", "-", "0.431", "+", "self", ".", "gripper_extra_height", "]", ")", "+", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "gripper_rotation", "=", "np", ".", "array", "(", "[", "1.", ",", "0.", ",", "1.", ",", "0.", "]", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_pos", "(", "'robot0:mocap'", ",", "gripper_target", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_quat", "(", "'robot0:mocap'", ",", "gripper_rotation", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "          ", "self", ".", "sim", ".", "step", "(", ")", "\n", "\n", "# Extract information for sampling goals.", "\n", "", "self", ".", "initial_gripper_xpos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", ".", "copy", "(", ")", "\n", "if", "self", ".", "has_object", ":", "\n", "          ", "self", ".", "height_offset", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv.step": [[1414, 1422], ["super().step", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "info", "[", "'is_success'", "]", "=", "np", ".", "allclose", "(", "reward", ",", "0.", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv._render_callback": [[1423, 1432], ["numpy.split", "range", "custom_fetch.SlideNEnv.sim.forward", "custom_fetch.SlideNEnv.sim.model.site_name2id"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", "\n", "goals", "=", "np", ".", "split", "(", "self", ".", "goal", ",", "self", ".", "n", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target{}'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goals", "[", "i", "]", "-", "sites_offset", "[", "i", "]", "\n", "", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv.compute_reward": [[1433, 1450], ["zip", "len", "numpy.split", "numpy.split", "numpy.split", "numpy.split", "numpy.ones", "gym.envs.robotics.fetch_env.goal_distance"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "# Compute distance between goal and the achieved goal.", "\n", "\n", "    ", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "actual_goals", "=", "np", ".", "split", "(", "goal", ",", "self", ".", "n", ")", "\n", "achieved_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "self", ".", "n", ")", "\n", "success", "=", "1.", "\n", "", "else", ":", "\n", "      ", "actual_goals", "=", "np", ".", "split", "(", "goal", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "achieved_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "success", "=", "np", ".", "ones", "(", "achieved_goal", ".", "shape", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "for", "b", ",", "g", "in", "zip", "(", "achieved_goals", ",", "actual_goals", ")", ":", "\n", "      ", "d", "=", "goal_distance", "(", "b", ",", "g", ")", "\n", "success", "*=", "(", "d", "<=", "self", ".", "distance_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "return", "success", "-", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.SlideNEnv._get_obs": [[1451, 1500], ["custom_fetch.SlideNEnv.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "range", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "custom_fetch.SlideNEnv.sim.data.get_site_xvelp", "custom_fetch.SlideNEnv.sim.data.get_site_xpos().ravel", "max", "gym.envs.robotics.rotations.mat2euler().ravel", "obj_feats.append", "obj_poses.append", "custom_fetch.SlideNEnv.goal.copy", "sum", "custom_fetch.SlideNEnv.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "custom_fetch.SlideNEnv.ravel", "gym.envs.robotics.rotations.mat2euler().ravel.ravel", "object_velp.ravel", "object_velr.ravel", "custom_fetch.SlideNEnv.sim.data.get_site_xmat", "custom_fetch.SlideNEnv.sim.data.get_site_xvelp", "custom_fetch.SlideNEnv.sim.data.get_site_xvelr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "# positions", "\n", "    ", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "\n", "obj_feats", "=", "[", "]", "\n", "obj_poses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "obj_labl", "=", "'object{}'", ".", "format", "(", "i", ")", "\n", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "obj_labl", ")", ".", "ravel", "(", ")", "\n", "object_pos", "[", "2", "]", "=", "max", "(", "object_pos", "[", "2", "]", ",", "self", ".", "height_offset", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "obj_labl", ")", ")", ".", "ravel", "(", ")", "\n", "# velocities", "\n", "object_velp", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "obj_labl", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "object_velr", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "obj_labl", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "# gripper state", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "#object_velp -= grip_velp", "\n", "\n", "obj_feats", ".", "append", "(", "[", "\n", "object_pos", ".", "ravel", "(", ")", ",", "\n", "object_rot", ".", "ravel", "(", ")", ",", "\n", "object_velp", ".", "ravel", "(", ")", ",", "\n", "object_velr", ".", "ravel", "(", ")", ",", "\n", "]", ")", "\n", "obj_poses", ".", "append", "(", "object_pos", ")", "\n", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "achieved_goal", "=", "np", ".", "concatenate", "(", "obj_poses", ")", "\n", "\n", "grip_obs", "=", "np", ".", "concatenate", "(", "[", "\n", "grip_pos", ",", "\n", "gripper_state", ",", "\n", "grip_velp", ",", "\n", "gripper_vel", ",", "\n", "]", ")", "\n", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "grip_pos", ",", "gripper_state", ",", "grip_velp", ",", "gripper_vel", "]", "+", "sum", "(", "obj_feats", ",", "[", "]", ")", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv.__init__": [[1504, 1541], ["numpy.concatenate", "range", "gym.envs.robotics.fetch_env.FetchEnv.__init__", "gym.utils.EzPickle.__init__", "PUSH_N_XML.replace", "numpy.arange", "numpy.array", "numpy.arange", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "n", "=", "1", ",", "\n", "distance_threshold", "=", "0.05", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "n", "=", "n", "\n", "self", ".", "disentangled_idxs", "=", "[", "np", ".", "arange", "(", "10", ")", "]", "+", "[", "10", "+", "12", "*", "i", "+", "np", ".", "arange", "(", "12", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "self", ".", "ag_dims", "=", "np", ".", "concatenate", "(", "[", "a", "[", ":", "3", "]", "for", "a", "in", "self", ".", "disentangled_idxs", "[", "1", ":", "]", "]", ")", "\n", "if", "not", "distance_threshold", ">", "1e-5", ":", "\n", "      ", "distance_threshold", "=", "0.05", "# default", "\n", "\n", "", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.05", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "k", "=", "'object{}:joint'", ".", "format", "(", "i", ")", "\n", "initial_qpos", "[", "k", "]", "=", "INIT_Q_POSES_SLIDE", "[", "i", "]", "\n", "\n", "\n", "", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "PUSH_N_XML", ".", "replace", "(", "'#'", ",", "'{}'", ".", "format", "(", "n", ")", ")", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "True", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.", ",", "\n", "target_in_the_air", "=", "False", ",", "\n", "target_offset", "=", "np", ".", "array", "(", "[", "-", "0.075", ",", "0.0", ",", "0.0", "]", ")", ",", "\n", "obj_range", "=", "0.15", ",", "\n", "target_range", "=", "0.25", ",", "\n", "distance_threshold", "=", "distance_threshold", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "'sparse'", ")", "\n", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n", "self", ".", "max_step", "=", "50", "+", "25", "*", "(", "n", "-", "1", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv.reset": [[1543, 1547], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv._reset_sim": [[1548, 1574], ["custom_fetch.PushNEnv.sim.set_state", "range", "custom_fetch.PushNEnv.sim.forward", "bad_poses.append", "custom_fetch.PushNEnv.sim.data.get_joint_qpos", "custom_fetch.PushNEnv.sim.data.get_joint_qvel", "numpy.array", "custom_fetch.PushNEnv.sim.data.set_joint_qpos", "custom_fetch.PushNEnv.sim.data.set_joint_qvel", "min", "numpy.zeros_like", "custom_fetch.PushNEnv.np_random.uniform", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_reset_sim", "(", "self", ")", ":", "\n", "    ", "self", ".", "sim", ".", "set_state", "(", "self", ".", "initial_state", ")", "\n", "\n", "# Only a little randomize about the start state", "\n", "# for i in range(self.n):", "\n", "#   object_qpos = self.sim.data.get_joint_qpos('object{}:joint'.format(i))", "\n", "#   object_qpos[:2] += self.np_random.uniform(-0.03, 0.03, size=2)", "\n", "#   self.sim.data.set_joint_qpos('object{}:joint'.format(i), object_qpos)", "\n", "\n", "bad_poses", "=", "[", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "]", "\n", "# Randomize start positions of pucks.", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "\n", "while", "min", "(", "[", "np", ".", "linalg", ".", "norm", "(", "object_xpos", "-", "p", ")", "for", "p", "in", "bad_poses", "]", ")", "<", "0.08", ":", "\n", "          ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "obj_range", ",", "self", ".", "obj_range", ",", "size", "=", "2", ")", "\n", "", "bad_poses", ".", "append", "(", "object_xpos", ")", "\n", "\n", "object_qpos", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qpos", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ")", "\n", "object_qvel", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qvel", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ")", "\n", "object_qpos", "[", ":", "2", "]", "=", "object_xpos", "\n", "object_qpos", "[", "2", ":", "]", "=", "np", ".", "array", "(", "[", "0.42", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ",", "object_qpos", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qvel", "(", "'object{}:joint'", ".", "format", "(", "i", ")", ",", "np", ".", "zeros_like", "(", "object_qvel", ")", ")", "\n", "\n", "", "self", ".", "sim", ".", "forward", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv._sample_goal": [[1575, 1588], ["range", "numpy.concatenate", "custom_fetch.PushNEnv.np_random.uniform", "goal_xys.append", "numpy.concatenate", "custom_fetch.PushNEnv.np_random.uniform", "min", "custom_fetch.PushNEnv.np_random.uniform", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "first_puck", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "2", ")", "\n", "\n", "goal_xys", "=", "[", "first_puck", "[", ":", "2", "]", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", "-", "1", ")", ":", "\n", "      ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "2", ")", "\n", "while", "min", "(", "[", "np", ".", "linalg", ".", "norm", "(", "object_xpos", "-", "p", ")", "for", "p", "in", "goal_xys", "]", ")", "<", "0.08", ":", "\n", "        ", "object_xpos", "=", "self", ".", "initial_gripper_xpos", "[", ":", "2", "]", "+", "self", ".", "np_random", ".", "uniform", "(", "-", "self", ".", "target_range", ",", "self", ".", "target_range", ",", "size", "=", "2", ")", "\n", "", "goal_xys", ".", "append", "(", "object_xpos", ")", "\n", "\n", "", "goals", "=", "[", "np", ".", "concatenate", "(", "(", "goal", ",", "[", "self", ".", "height_offset", "]", ")", ")", "for", "goal", "in", "goal_xys", "]", "\n", "\n", "return", "np", ".", "concatenate", "(", "goals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv._env_setup": [[1589, 1607], ["initial_qpos.items", "gym.envs.robotics.utils.reset_mocap_welds", "custom_fetch.PushNEnv.sim.forward", "numpy.array", "custom_fetch.PushNEnv.sim.data.set_mocap_pos", "custom_fetch.PushNEnv.sim.data.set_mocap_quat", "range", "custom_fetch.PushNEnv.sim.data.get_site_xpos().copy", "custom_fetch.PushNEnv.sim.data.set_joint_qpos", "numpy.array", "custom_fetch.PushNEnv.sim.data.get_site_xpos", "custom_fetch.PushNEnv.sim.step", "custom_fetch.PushNEnv.sim.data.get_site_xpos", "custom_fetch.PushNEnv.sim.data.get_site_xpos"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "_env_setup", "(", "self", ",", "initial_qpos", ")", ":", "\n", "      ", "for", "name", ",", "value", "in", "initial_qpos", ".", "items", "(", ")", ":", "\n", "          ", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "name", ",", "value", ")", "\n", "", "utils", ".", "reset_mocap_welds", "(", "self", ".", "sim", ")", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n", "# Move end effector into position.", "\n", "gripper_target", "=", "np", ".", "array", "(", "[", "-", "0.548", ",", "0.005", ",", "-", "0.431", "+", "self", ".", "gripper_extra_height", "]", ")", "+", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "gripper_rotation", "=", "np", ".", "array", "(", "[", "1.", ",", "0.", ",", "1.", ",", "0.", "]", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_pos", "(", "'robot0:mocap'", ",", "gripper_target", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_quat", "(", "'robot0:mocap'", ",", "gripper_rotation", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "          ", "self", ".", "sim", ".", "step", "(", ")", "\n", "\n", "# Extract information for sampling goals.", "\n", "", "self", ".", "initial_gripper_xpos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", ".", "copy", "(", ")", "\n", "if", "self", ".", "has_object", ":", "\n", "          ", "self", ".", "height_offset", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv.step": [[1608, 1616], ["super().step", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "info", "[", "'is_success'", "]", "=", "np", ".", "allclose", "(", "reward", ",", "0.", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv._render_callback": [[1617, 1626], ["numpy.split", "range", "custom_fetch.PushNEnv.sim.forward", "custom_fetch.PushNEnv.sim.model.site_name2id"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", "\n", "goals", "=", "np", ".", "split", "(", "self", ".", "goal", ",", "self", ".", "n", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target{}'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goals", "[", "i", "]", "-", "sites_offset", "[", "i", "]", "\n", "", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv.compute_reward": [[1627, 1644], ["zip", "len", "numpy.split", "numpy.split", "numpy.split", "numpy.split", "numpy.ones", "gym.envs.robotics.fetch_env.goal_distance"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "# Compute distance between goal and the achieved goal.", "\n", "\n", "    ", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "actual_goals", "=", "np", ".", "split", "(", "goal", ",", "self", ".", "n", ")", "\n", "achieved_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "self", ".", "n", ")", "\n", "success", "=", "1.", "\n", "", "else", ":", "\n", "      ", "actual_goals", "=", "np", ".", "split", "(", "goal", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "achieved_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "self", ".", "n", ",", "axis", "=", "1", ")", "\n", "success", "=", "np", ".", "ones", "(", "achieved_goal", ".", "shape", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "for", "b", ",", "g", "in", "zip", "(", "achieved_goals", ",", "actual_goals", ")", ":", "\n", "      ", "d", "=", "goal_distance", "(", "b", ",", "g", ")", "\n", "success", "*=", "(", "d", "<=", "self", ".", "distance_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "return", "success", "-", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.PushNEnv._get_obs": [[1645, 1694], ["custom_fetch.PushNEnv.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "range", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "custom_fetch.PushNEnv.sim.data.get_site_xvelp", "custom_fetch.PushNEnv.sim.data.get_site_xpos().ravel", "max", "gym.envs.robotics.rotations.mat2euler().ravel", "obj_feats.append", "obj_poses.append", "custom_fetch.PushNEnv.goal.copy", "sum", "custom_fetch.PushNEnv.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "custom_fetch.PushNEnv.ravel", "gym.envs.robotics.rotations.mat2euler().ravel.ravel", "object_velp.ravel", "object_velr.ravel", "custom_fetch.PushNEnv.sim.data.get_site_xmat", "custom_fetch.PushNEnv.sim.data.get_site_xvelp", "custom_fetch.PushNEnv.sim.data.get_site_xvelr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "# positions", "\n", "    ", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "\n", "obj_feats", "=", "[", "]", "\n", "obj_poses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "      ", "obj_labl", "=", "'object{}'", ".", "format", "(", "i", ")", "\n", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "obj_labl", ")", ".", "ravel", "(", ")", "\n", "object_pos", "[", "2", "]", "=", "max", "(", "object_pos", "[", "2", "]", ",", "self", ".", "height_offset", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "obj_labl", ")", ")", ".", "ravel", "(", ")", "\n", "# velocities", "\n", "object_velp", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "obj_labl", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "object_velr", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "obj_labl", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "# gripper state", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "#object_velp -= grip_velp", "\n", "\n", "obj_feats", ".", "append", "(", "[", "\n", "object_pos", ".", "ravel", "(", ")", ",", "\n", "object_rot", ".", "ravel", "(", ")", ",", "\n", "object_velp", ".", "ravel", "(", ")", ",", "\n", "object_velr", ".", "ravel", "(", ")", ",", "\n", "]", ")", "\n", "obj_poses", ".", "append", "(", "object_pos", ")", "\n", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "achieved_goal", "=", "np", ".", "concatenate", "(", "obj_poses", ")", "\n", "\n", "grip_obs", "=", "np", ".", "concatenate", "(", "[", "\n", "grip_pos", ",", "\n", "gripper_state", ",", "\n", "grip_velp", ",", "\n", "gripper_vel", ",", "\n", "]", ")", "\n", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "grip_pos", ",", "gripper_state", ",", "grip_velp", ",", "gripper_vel", "]", "+", "sum", "(", "obj_feats", ",", "[", "]", ")", ")", "\n", "\n", "return", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv.__init__": [[1706, 1761], ["numpy.array", "gym.envs.robotics.fetch_env.FetchEnv.__init__", "custom_fetch.FetchHookSweepAllEnv._sample_goal", "custom_fetch.FetchHookSweepAllEnv._get_obs", "gym.spaces.Dict", "os.path.dirname", "os.path.join", "numpy.array", "dict", "os.path.dirname", "os.path.abspath", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["def", "__init__", "(", "self", ",", "xml_file", "=", "None", ",", "place_two", "=", "False", ",", "place_random", "=", "False", ",", "goal_in_air", "=", "False", ",", "smaller_state", "=", "False", ",", "raw_state", "=", "False", ")", ":", "\n", "    ", "initial_qpos", "=", "{", "\n", "'robot0:slide0'", ":", "0.405", ",", "\n", "'robot0:slide1'", ":", "0.48", ",", "\n", "'robot0:slide2'", ":", "0.0", ",", "\n", "'object0:joint'", ":", "[", "1.85", ",", "0.75", ",", "0.4", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "'object1:joint'", ":", "[", "1.85", ",", "0.75", ",", "0.4", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "}", "\n", "\n", "self", ".", "max_step", "=", "75", "\n", "self", ".", "num_step", "=", "0", "\n", "\n", "if", "xml_file", "is", "None", ":", "\n", "#Go 3 folders up to base of rl_with_teachers dir", "\n", "      ", "package_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ")", "\n", "xml_file", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "'xmls'", ",", "'sweep_all.xml'", ")", "\n", "\n", "", "self", ".", "JOINTS", "=", "(", "'robot0:slide0'", ",", "'robot0:slide1'", ",", "'robot0:slide2'", ",", "'robot0:torso_lift_joint'", ",", "\n", "'robot0:head_pan_joint'", ",", "'robot0:head_tilt_joint'", ",", "'robot0:shoulder_pan_joint'", ",", "\n", "'robot0:shoulder_lift_joint'", ",", "'robot0:upperarm_roll_joint'", ",", "'robot0:elbow_flex_joint'", ",", "\n", "'robot0:forearm_roll_joint'", ",", "'robot0:wrist_flex_joint'", ",", "'robot0:wrist_roll_joint'", ",", "\n", "'object0:joint'", ",", "'object1:joint'", ")", "\n", "\n", "self", ".", "place_two", "=", "place_two", "\n", "self", ".", "place_random", "=", "place_random", "\n", "self", ".", "goal_in_air", "=", "goal_in_air", "\n", "self", ".", "smaller_state", "=", "smaller_state", "\n", "self", ".", "raw_state", "=", "raw_state", "\n", "\n", "# base goal position, from which all other are derived", "\n", "self", ".", "_base_goal_pos", "=", "np", ".", "array", "(", "[", "1.85", ",", "0.7", ",", "0.42", ",", "1.85", ",", "0.8", ",", "0.42", "]", ")", "\n", "if", "self", ".", "goal_in_air", ":", "\n", "      ", "self", ".", "_base_goal_pos", "=", "np", ".", "array", "(", "[", "1.85", ",", "0.7", ",", "0.6", ",", "1.85", ",", "0.8", ",", "0.42", "]", ")", "\n", "", "self", ".", "_goal_pos", "=", "self", ".", "_base_goal_pos", "\n", "\n", "fetch_env", ".", "FetchEnv", ".", "__init__", "(", "self", ",", "\n", "xml_file", ",", "\n", "has_object", "=", "True", ",", "\n", "block_gripper", "=", "False", ",", "\n", "n_substeps", "=", "20", ",", "\n", "gripper_extra_height", "=", "0.2", ",", "\n", "target_in_the_air", "=", "True", ",", "\n", "target_offset", "=", "0.0", ",", "\n", "obj_range", "=", "None", ",", "\n", "target_range", "=", "None", ",", "\n", "distance_threshold", "=", "0.14", ",", "\n", "initial_qpos", "=", "initial_qpos", ",", "\n", "reward_type", "=", "'sparse'", ")", "\n", "\n", "self", ".", "_goal_pos", "=", "self", ".", "_sample_goal", "(", ")", "\n", "obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "\n", "dict", "(", "observation", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'observation'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "achieved_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'desired_goal'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ",", "\n", "desired_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "obs", "[", "'desired_goal'", "]", ".", "shape", ",", "dtype", "=", "'float32'", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv._viewer_setup": [[1762, 1770], ["custom_fetch.FetchHookSweepAllEnv.sim.model.body_name2id", "enumerate"], "methods", ["None"], ["", "def", "_viewer_setup", "(", "self", ")", ":", "\n", "    ", "body_id", "=", "self", ".", "sim", ".", "model", ".", "body_name2id", "(", "'robot0:gripper_link'", ")", "\n", "lookat", "=", "self", ".", "sim", ".", "data", ".", "body_xpos", "[", "body_id", "]", "\n", "for", "idx", ",", "value", "in", "enumerate", "(", "lookat", ")", ":", "\n", "      ", "self", ".", "viewer", ".", "cam", ".", "lookat", "[", "idx", "]", "=", "value", "\n", "", "self", ".", "viewer", ".", "cam", ".", "distance", "=", "2.5", "\n", "self", ".", "viewer", ".", "cam", ".", "azimuth", "=", "180.", "\n", "self", ".", "viewer", ".", "cam", ".", "elevation", "=", "-", "24.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv.render": [[1771, 1784], ["custom_fetch.FetchHookSweepAllEnv._render_callback", "super().render", "custom_fetch.FetchHookSweepAllEnv._get_viewer().render", "custom_fetch.FetchHookSweepAllEnv._get_viewer().read_pixels", "custom_fetch.FetchHookSweepAllEnv._get_viewer().render", "custom_fetch.FetchHookSweepAllEnv._get_viewer", "custom_fetch.FetchHookSweepAllEnv._get_viewer", "custom_fetch.FetchHookSweepAllEnv._get_viewer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv._render_callback", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "\"human\"", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# See https://github.com/openai/gym/issues/1081", "\n", "    ", "self", ".", "_render_callback", "(", ")", "\n", "if", "mode", "==", "'rgb_array'", ":", "\n", "      ", "self", ".", "_get_viewer", "(", "mode", "=", "'human'", ")", ".", "render", "(", ")", "\n", "width", ",", "height", "=", "3350", ",", "1800", "\n", "data", "=", "self", ".", "_get_viewer", "(", "mode", "=", "'human'", ")", ".", "read_pixels", "(", "width", ",", "height", ",", "depth", "=", "False", ")", "\n", "# original image is upside-down, so flip it", "\n", "return", "data", "[", ":", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "", "elif", "mode", "==", "'human'", ":", "\n", "      ", "self", ".", "_get_viewer", "(", "mode", "=", "'human'", ")", ".", "render", "(", ")", "\n", "\n", "", "return", "super", "(", ")", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv._render_callback": [[1786, 1795], ["numpy.split", "range", "custom_fetch.FetchHookSweepAllEnv.sim.forward", "custom_fetch.FetchHookSweepAllEnv.sim.model.site_name2id"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "_render_callback", "(", "self", ")", ":", "\n", "# Visualize target.", "\n", "    ", "sites_offset", "=", "(", "self", ".", "sim", ".", "data", ".", "site_xpos", "-", "self", ".", "sim", ".", "model", ".", "site_pos", ")", "\n", "goals", "=", "np", ".", "split", "(", "self", ".", "goal", ",", "2", ")", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "      ", "site_id", "=", "self", ".", "sim", ".", "model", ".", "site_name2id", "(", "'target{}'", ".", "format", "(", "i", ")", ")", "\n", "self", ".", "sim", ".", "model", ".", "site_pos", "[", "site_id", "]", "=", "goals", "[", "i", "]", "-", "sites_offset", "[", "i", "]", "\n", "", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv._sample_goal": [[1796, 1818], ["custom_fetch.FetchHookSweepAllEnv._base_goal_pos.copy", "numpy.array", "custom_fetch.FetchHookSweepAllEnv.np_random.random", "custom_fetch.FetchHookSweepAllEnv.np_random.random", "numpy.array", "numpy.array", "numpy.array", "custom_fetch.FetchHookSweepAllEnv.np_random.random", "custom_fetch.FetchHookSweepAllEnv.np_random.random", "numpy.array", "custom_fetch.FetchHookSweepAllEnv.np_random.random", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "goal_pos", "=", "self", ".", "_base_goal_pos", ".", "copy", "(", ")", "\n", "\n", "adj", "=", "self", ".", "np_random", ".", "random", "(", "size", "=", "(", "3", ",", ")", ")", "*", "np", ".", "array", "(", "[", "0.2", ",", "0.2", ",", "0.", "]", ")", "-", "np", ".", "array", "(", "[", "0.1", ",", "0.1", ",", "0", "]", ")", "\n", "if", "self", ".", "np_random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "      ", "adj", "[", "0", "]", "+=", "0.31", "\n", "", "else", ":", "\n", "      ", "adj", "[", "0", "]", "-=", "0.31", "\n", "\n", "", "if", "self", ".", "place_two", ":", "\n", "      ", "goal_pos", "[", ":", "3", "]", "+=", "adj", "\n", "goal_pos", "[", "3", ":", "]", "+=", "adj", "\n", "", "elif", "self", ".", "place_random", ":", "\n", "      ", "goal_pos", "[", ":", "3", "]", "+=", "self", ".", "np_random", ".", "random", "(", "size", "=", "(", "3", ",", ")", ")", "*", "np", ".", "array", "(", "[", "0.8", ",", "0.8", ",", "0.", "]", ")", "-", "np", ".", "array", "(", "[", "0.4", ",", "0.4", ",", "0", "]", ")", "\n", "goal_pos", "[", "3", ":", "]", "+=", "self", ".", "np_random", ".", "random", "(", "size", "=", "(", "3", ",", ")", ")", "*", "np", ".", "array", "(", "[", "0.8", ",", "0.8", ",", "0.", "]", ")", "-", "np", ".", "array", "(", "[", "0.4", ",", "0.4", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "      ", "if", "self", ".", "np_random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "        ", "goal_pos", "[", ":", "3", "]", "+=", "adj", "\n", "", "else", ":", "\n", "        ", "goal_pos", "[", "3", ":", "]", "+=", "adj", "\n", "\n", "", "", "return", "goal_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv._reset_sim": [[1819, 1842], ["custom_fetch.FetchHookSweepAllEnv.sim.set_state", "range", "custom_fetch.FetchHookSweepAllEnv.sim.forward", "range", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_joint_qpos", "custom_fetch.FetchHookSweepAllEnv.sim.data.set_joint_qpos", "custom_fetch.FetchHookSweepAllEnv.np_random.uniform", "deltas.append", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_reset_sim", "(", "self", ")", ":", "\n", "    ", "self", ".", "sim", ".", "set_state", "(", "self", ".", "initial_state", ")", "\n", "\n", "while", "True", ":", "\n", "      ", "deltas", "=", "[", "]", "\n", "for", "o", "in", "range", "(", "2", ")", ":", "\n", "        ", "delta", "=", "self", ".", "np_random", ".", "uniform", "(", "-", "0.08", ",", "0.08", ",", "(", "2", ",", ")", ")", "\n", "deltas", ".", "append", "(", "delta", ")", "\n", "", "if", "np", ".", "linalg", ".", "norm", "(", "deltas", "[", "0", "]", "-", "deltas", "[", "1", "]", ")", ">", "0.1", ":", "\n", "        ", "break", "\n", "\n", "", "", "if", "deltas", "[", "0", "]", "[", "1", "]", ">", "deltas", "[", "1", "]", "[", "1", "]", ":", "\n", "      ", "t", "=", "deltas", "[", "0", "]", "[", "1", "]", "\n", "deltas", "[", "0", "]", "[", "1", "]", "=", "deltas", "[", "1", "]", "[", "1", "]", "\n", "deltas", "[", "1", "]", "[", "1", "]", "=", "t", "\n", "", "for", "o", "in", "range", "(", "2", ")", ":", "\n", "      ", "object_qpos", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qpos", "(", "f'object{o}:joint'", ")", "\n", "assert", "object_qpos", ".", "shape", "==", "(", "7", ",", ")", "\n", "object_qpos", "[", ":", "2", "]", "+=", "deltas", "[", "o", "]", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "f'object{o}:joint'", ",", "object_qpos", ")", "\n", "\n", "", "self", ".", "sim", ".", "forward", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv._get_obs": [[1843, 1905], ["custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "range", "numpy.concatenate", "range", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xvelp", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "obj_poses.append", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate.copy", "numpy.concatenate.copy", "custom_fetch.FetchHookSweepAllEnv.goal.copy", "obj_poses.append", "custom_fetch.FetchHookSweepAllEnv.sim.get_state().flatten", "numpy.concatenate", "custom_fetch.FetchHookSweepAllEnv.goal.copy", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xmat", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xvelp", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xvelr", "obj_feats.append", "obj_feats.append", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xpos", "sum", "sum", "custom_fetch.FetchHookSweepAllEnv.sim.get_state"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_get_obs", "(", "self", ",", "force_original", "=", "False", ")", ":", "\n", "\n", "    ", "if", "self", ".", "raw_state", "and", "not", "force_original", ":", "\n", "\n", "      ", "obj_poses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "        ", "obj_labl", "=", "'object{}'", ".", "format", "(", "i", ")", "\n", "obj_poses", ".", "append", "(", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "obj_labl", ")", ")", "\n", "\n", "", "return", "{", "\n", "'observation'", ":", "self", ".", "sim", ".", "get_state", "(", ")", ".", "flatten", "(", ")", ",", "\n", "'achieved_goal'", ":", "np", ".", "concatenate", "(", "obj_poses", ")", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n", "\n", "# positions", "\n", "", "grip_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "self", ".", "sim", ".", "nsubsteps", "*", "self", ".", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "self", ".", "sim", ")", "\n", "\n", "obj_feats", "=", "[", "]", "\n", "obj_poses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "      ", "obj_labl", "=", "'object{}'", ".", "format", "(", "i", ")", "\n", "object_pos", "=", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "obj_labl", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "self", ".", "sim", ".", "data", ".", "get_site_xmat", "(", "obj_labl", ")", ")", "\n", "# velocities", "\n", "object_velp", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelp", "(", "obj_labl", ")", "*", "dt", ")", "\n", "object_velr", "=", "(", "self", ".", "sim", ".", "data", ".", "get_site_xvelr", "(", "obj_labl", ")", "*", "dt", ")", "\n", "# gripper state", "\n", "\n", "if", "self", ".", "smaller_state", ":", "\n", "        ", "obj_feats", ".", "append", "(", "[", "\n", "object_pos", ",", "\n", "object_velp", "[", ":", "2", "]", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "obj_feats", ".", "append", "(", "[", "\n", "object_pos", ",", "\n", "object_rot", ",", "\n", "object_velp", ",", "\n", "object_velr", ",", "\n", "]", ")", "\n", "", "obj_poses", ".", "append", "(", "object_pos", ")", "\n", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "achieved_goal", "=", "np", ".", "concatenate", "(", "obj_poses", ")", "\n", "\n", "if", "self", ".", "smaller_state", ":", "\n", "      ", "obs", "=", "np", ".", "concatenate", "(", "[", "grip_pos", ",", "grip_velp", "]", "+", "sum", "(", "obj_feats", ",", "[", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "obs", "=", "np", ".", "concatenate", "(", "[", "grip_pos", ",", "gripper_state", ",", "grip_velp", ",", "gripper_vel", "]", "+", "sum", "(", "obj_feats", ",", "[", "]", ")", ")", "\n", "\n", "", "return", "{", "\n", "'observation'", ":", "obs", ".", "copy", "(", ")", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ".", "copy", "(", ")", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv.compute_reward": [[1908, 1931], ["zip", "numpy.clip", "len", "numpy.split", "numpy.split", "numpy.clip", "numpy.split", "numpy.split", "numpy.ones", "numpy.clip", "gym.envs.robotics.fetch_env.goal_distance", "numpy.clip", "numpy.abs", "numpy.abs"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "# Compute distance between goal and the achieved goal.", "\n", "\n", "    ", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "actual_goals", "=", "np", ".", "split", "(", "goal", ",", "2", ")", "\n", "achieved_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "2", ")", "\n", "success", "=", "1.", "\n", "on_table_bonus", "=", "np", ".", "clip", "(", "0.5", "-", "np", ".", "abs", "(", "info", "[", "'s'", "]", "[", "2", "]", "-", "0.42", ")", "*", "5.", ",", "0.", ",", "0.5", ")", "\n", "", "else", ":", "\n", "      ", "actual_goals", "=", "np", ".", "split", "(", "goal", ",", "2", ",", "axis", "=", "1", ")", "\n", "achieved_goals", "=", "np", ".", "split", "(", "achieved_goal", ",", "2", ",", "axis", "=", "1", ")", "\n", "success", "=", "np", ".", "ones", "(", "achieved_goal", ".", "shape", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "on_table_bonus", "=", "np", ".", "clip", "(", "0.5", "-", "np", ".", "abs", "(", "info", "[", "'s'", "]", "[", ":", ",", "2", "]", "-", "0.42", ")", "*", "5.", ",", "0.", ",", "0.5", ")", "\n", "\n", "", "farness_penalty", "=", "0", "\n", "for", "b", ",", "g", "in", "zip", "(", "achieved_goals", ",", "actual_goals", ")", ":", "\n", "      ", "d", "=", "goal_distance", "(", "b", ",", "g", ")", "\n", "success", "*=", "(", "d", "<=", "self", ".", "distance_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "farness_penalty", "+=", "np", ".", "clip", "(", "d", "/", "self", ".", "distance_threshold", ",", "0.", ",", "1.", ")", "*", "0.1", "\n", "\n", "", "on_table_bonus", "*=", "(", "1.", "-", "success", ")", "\n", "\n", "return", "np", ".", "clip", "(", "success", "-", "1.", "-", "farness_penalty", "+", "on_table_bonus", ",", "-", "1.", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv.step": [[1932, 1954], ["numpy.clip", "custom_fetch.FetchHookSweepAllEnv._set_action", "custom_fetch.FetchHookSweepAllEnv.sim.step", "custom_fetch.FetchHookSweepAllEnv._step_callback", "custom_fetch.FetchHookSweepAllEnv._get_obs", "custom_fetch.FetchHookSweepAllEnv.compute_reward", "custom_fetch.FetchHookSweepAllEnv._is_success", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "action", "=", "np", ".", "clip", "(", "action", ",", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", ")", "\n", "self", ".", "_set_action", "(", "action", ")", "\n", "self", ".", "sim", ".", "step", "(", ")", "\n", "self", ".", "_step_callback", "(", ")", "\n", "obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "\n", "done", "=", "False", "\n", "info", "=", "{", "\n", "'s'", ":", "obs", "[", "'observation'", "]", ",", "\n", "'a'", ":", "action", ",", "\n", "'is_success'", ":", "self", ".", "_is_success", "(", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "goal", ")", ",", "\n", "}", "\n", "reward", "=", "self", ".", "compute_reward", "(", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "goal", ",", "info", ")", "\n", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "info", "[", "'is_success'", "]", "=", "np", ".", "abs", "(", "reward", ")", "<", "0.3", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv.reset": [[1955, 1960], ["custom_fetch.FetchHookSweepAllEnv._sample_goal", "super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "_goal_pos", "=", "self", ".", "_sample_goal", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.FetchHookSweepAllEnv._env_setup": [[1961, 1974], ["initial_qpos.items", "gym.envs.robotics.utils.reset_mocap_welds", "custom_fetch.FetchHookSweepAllEnv.sim.forward", "numpy.array", "custom_fetch.FetchHookSweepAllEnv.sim.data.set_mocap_pos", "custom_fetch.FetchHookSweepAllEnv.sim.data.set_mocap_quat", "range", "custom_fetch.FetchHookSweepAllEnv.sim.data.set_joint_qpos", "numpy.array", "custom_fetch.FetchHookSweepAllEnv.sim.data.get_site_xpos", "custom_fetch.FetchHookSweepAllEnv.sim.step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "_env_setup", "(", "self", ",", "initial_qpos", ")", ":", "\n", "    ", "for", "name", ",", "value", "in", "initial_qpos", ".", "items", "(", ")", ":", "\n", "      ", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "name", ",", "value", ")", "\n", "", "utils", ".", "reset_mocap_welds", "(", "self", ".", "sim", ")", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "\n", "gripper_target", "=", "np", ".", "array", "(", "[", "-", "0.498", ",", "0.005", ",", "-", "0.431", "+", "self", ".", "gripper_extra_height", "\n", "]", ")", "+", "self", ".", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "gripper_rotation", "=", "np", ".", "array", "(", "[", "1.", ",", "0.", ",", "1.", ",", "0.", "]", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_pos", "(", "'robot0:mocap'", ",", "gripper_target", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_mocap_quat", "(", "'robot0:mocap'", ",", "gripper_rotation", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "      ", "self", ".", "sim", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.compute_reward": [[54, 80], ["numpy.all", "numpy.logical_and().astype", "len", "gym.envs.robotics.fetch_env.goal_distance", "gym.envs.robotics.fetch_env.goal_distance", "numpy.abs", "numpy.logical_and", "len", "gym.envs.robotics.fetch_env.goal_distance", "gym.envs.robotics.fetch_env.goal_distance"], "function", ["None"], ["", "def", "compute_reward", "(", "achieved_goal", ",", "goal", ",", "internal_goal", ",", "distance_threshold", ",", "per_dim_threshold", ",", "\n", "compute_reward_with_internal", ",", "mode", ")", ":", "\n", "# Always require internal success.", "\n", "  ", "internal_success", "=", "0.", "\n", "if", "internal_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "    ", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "d", "=", "goal_distance", "(", "achieved_goal", "[", ":", "6", "]", ",", "goal", "[", ":", "6", "]", ")", "\n", "", "else", ":", "\n", "      ", "d", "=", "goal_distance", "(", "achieved_goal", "[", ":", ",", ":", "6", "]", ",", "goal", "[", ":", ",", ":", "6", "]", ")", "\n", "", "", "elif", "internal_goal", "in", "[", "GoalType", ".", "GRIP", ",", "GoalType", ".", "OBJ", "]", ":", "\n", "    ", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "d", "=", "goal_distance", "(", "achieved_goal", "[", ":", "3", "]", ",", "goal", "[", ":", "3", "]", ")", "\n", "", "else", ":", "\n", "      ", "d", "=", "goal_distance", "(", "achieved_goal", "[", ":", ",", ":", "3", "]", ",", "goal", "[", ":", ",", ":", "3", "]", ")", "\n", "", "", "else", ":", "\n", "    ", "raise", "\n", "\n", "", "internal_success", "=", "(", "d", "<=", "distance_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "if", "compute_reward_with_internal", ":", "\n", "    ", "return", "internal_success", "-", "(", "1.", "-", "mode", ")", "\n", "\n", "# use per_dim_thresholds for other dimensions", "\n", "", "success", "=", "np", ".", "all", "(", "np", ".", "abs", "(", "achieved_goal", "-", "goal", ")", "<", "per_dim_threshold", ",", "axis", "=", "-", "1", ")", "\n", "success", "=", "np", ".", "logical_and", "(", "internal_success", ",", "success", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "success", "-", "(", "1.", "-", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.get_obs": [[82, 146], ["sim.data.get_site_xpos", "gym.envs.robotics.utils.robot_get_obs", "sim.data.get_site_xpos().ravel", "gym.envs.robotics.rotations.mat2euler().ravel", "numpy.concatenate", "sim.data.get_site_xvelp", "numpy.concatenate", "goal.copy", "sim.data.get_site_xpos", "gym.envs.robotics.rotations.mat2euler", "sim.data.get_site_xmat", "sim.data.get_site_xvelp", "sim.data.get_site_xvelr", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "ValueError"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "get_obs", "(", "sim", ",", "external_goal", ",", "goal", ",", "subtract_obj_velp", "=", "True", ")", ":", "\n", "# positions", "\n", "  ", "grip_pos", "=", "sim", ".", "data", ".", "get_site_xpos", "(", "'robot0:grip'", ")", "\n", "dt", "=", "sim", ".", "nsubsteps", "*", "sim", ".", "model", ".", "opt", ".", "timestep", "\n", "grip_velp", "=", "sim", ".", "data", ".", "get_site_xvelp", "(", "'robot0:grip'", ")", "*", "dt", "\n", "robot_qpos", ",", "robot_qvel", "=", "utils", ".", "robot_get_obs", "(", "sim", ")", "\n", "\n", "object_pos", "=", "sim", ".", "data", ".", "get_site_xpos", "(", "'object0'", ")", ".", "ravel", "(", ")", "\n", "# rotations", "\n", "object_rot", "=", "rotations", ".", "mat2euler", "(", "sim", ".", "data", ".", "get_site_xmat", "(", "'object0'", ")", ")", ".", "ravel", "(", ")", "\n", "# velocities", "\n", "object_velp", "=", "(", "sim", ".", "data", ".", "get_site_xvelp", "(", "'object0'", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "object_velr", "=", "(", "sim", ".", "data", ".", "get_site_xvelr", "(", "'object0'", ")", "*", "dt", ")", ".", "ravel", "(", ")", "\n", "# gripper state", "\n", "object_rel_pos", "=", "object_pos", "-", "grip_pos", "\n", "if", "subtract_obj_velp", ":", "\n", "    ", "object_velp", "-=", "grip_velp", "\n", "\n", "", "gripper_state", "=", "robot_qpos", "[", "-", "2", ":", "]", "\n", "gripper_vel", "=", "robot_qvel", "[", "-", "2", ":", "]", "*", "dt", "# change to a scalar if the gripper is made symmetric", "\n", "\n", "items", "=", "[", "\n", "grip_pos", ",", "\n", "object_pos", ",", "\n", "object_rel_pos", ",", "\n", "gripper_state", ",", "\n", "object_rot", ",", "\n", "object_velp", ",", "\n", "object_velr", ",", "\n", "grip_velp", ",", "\n", "gripper_vel", ",", "\n", "]", "\n", "\n", "obs", "=", "np", ".", "concatenate", "(", "items", ")", "\n", "\n", "if", "external_goal", "==", "GoalType", ".", "ALL", ":", "\n", "    ", "achieved_goal", "=", "np", ".", "concatenate", "(", "[", "\n", "object_pos", ",", "\n", "grip_pos", ",", "\n", "object_rel_pos", ",", "\n", "gripper_state", ",", "\n", "object_rot", ",", "\n", "object_velp", ",", "\n", "object_velr", ",", "\n", "grip_velp", ",", "\n", "gripper_vel", ",", "\n", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJ", ":", "\n", "    ", "achieved_goal", "=", "object_pos", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "    ", "achieved_goal", "=", "np", ".", "concatenate", "(", "[", "object_pos", ",", "grip_pos", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJ_GRIP_GRIPPER", ":", "\n", "    ", "achieved_goal", "=", "np", ".", "concatenate", "(", "[", "object_pos", ",", "grip_pos", ",", "gripper_state", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJSPEED", ":", "\n", "    ", "achieved_goal", "=", "np", ".", "concatenate", "(", "[", "object_pos", ",", "object_velp", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJSPEED2", ":", "\n", "    ", "achieved_goal", "=", "np", ".", "concatenate", "(", "[", "object_pos", ",", "object_velp", ",", "object_velr", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'unsupported goal type!'", ")", "\n", "\n", "", "return", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "achieved_goal", ",", "\n", "'desired_goal'", ":", "goal", ".", "copy", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_fetch.sample_goal": [[149, 178], ["ValueError", "np_random.uniform", "numpy.concatenate", "numpy.array", "np_random.uniform", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "function", ["None"], ["", "def", "sample_goal", "(", "initial_gripper_xpos", ",", "np_random", ",", "target_range", ",", "target_offset", ",", "height_offset", ",", "internal_goal", ",", "\n", "external_goal", ",", "grip_offset", ",", "gripper_goal", ")", ":", "\n", "  ", "obj_goal", "=", "initial_gripper_xpos", "[", ":", "3", "]", "+", "np_random", ".", "uniform", "(", "-", "target_range", ",", "target_range", ",", "size", "=", "3", ")", "\n", "obj_goal", "+=", "target_offset", "\n", "obj_goal", "[", "2", "]", "=", "height_offset", "\n", "\n", "if", "internal_goal", "in", "[", "GoalType", ".", "GRIP", ",", "GoalType", ".", "OBJ_GRIP", "]", ":", "\n", "    ", "grip_goal", "=", "initial_gripper_xpos", "[", ":", "3", "]", "+", "np_random", ".", "uniform", "(", "-", "0.15", ",", "0.15", ",", "size", "=", "3", ")", "+", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.15", "]", ")", "\n", "obj_rel_goal", "=", "obj_goal", "-", "grip_goal", "\n", "", "else", ":", "\n", "    ", "grip_goal", "=", "obj_goal", "+", "grip_offset", "\n", "obj_rel_goal", "=", "-", "grip_offset", "\n", "\n", "", "if", "external_goal", "==", "GoalType", ".", "ALL", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "obj_goal", ",", "grip_goal", ",", "obj_rel_goal", ",", "gripper_goal", ",", "[", "0.", "]", "*", "14", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJ", ":", "\n", "    ", "return", "obj_goal", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJ_GRIP_GRIPPER", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "obj_goal", ",", "grip_goal", ",", "gripper_goal", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJ_GRIP", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "obj_goal", ",", "grip_goal", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJSPEED", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "obj_goal", ",", "[", "0.", "]", "*", "3", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "OBJSPEED2", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "obj_goal", ",", "[", "0.", "]", "*", "6", "]", ")", "\n", "", "elif", "external_goal", "==", "GoalType", ".", "GRIP", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n", "", "raise", "ValueError", "(", "\"BAD external goal value\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandBlockEnv.__init__": [[12, 20], ["gym.envs.robotics.hand.manipulate.ManipulateEnv.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "max_step", "=", "100", ",", "target_position", "=", "'random'", ",", "target_rotation", "=", "'xyz'", ",", "reward_type", "=", "'sparse'", ",", "distance_threshold", "=", "0.01", ",", "rotation_threshold", "=", "0.1", ")", ":", "\n", "    ", "self", ".", "num_step", "=", "0", "\n", "self", ".", "max_step", "=", "max_step", "\n", "super", "(", "HandBlockEnv", ",", "self", ")", ".", "__init__", "(", "\n", "model_path", "=", "MANIPULATE_BLOCK_XML", ",", "target_position", "=", "target_position", ",", "\n", "target_rotation", "=", "target_rotation", ",", "\n", "target_position_range", "=", "np", ".", "array", "(", "[", "(", "-", "0.04", ",", "0.04", ")", ",", "(", "-", "0.06", ",", "0.02", ")", ",", "(", "0.0", ",", "0.06", ")", "]", ")", ",", "\n", "reward_type", "=", "'sparse'", ",", "distance_threshold", "=", "distance_threshold", ",", "rotation_threshold", "=", "rotation_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandBlockEnv.step": [[21, 27], ["super().step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandBlockEnv.reset": [[28, 32], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandPenEnv.__init__": [[35, 44], ["gym.envs.robotics.hand.manipulate.ManipulateEnv.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "max_step", "=", "100", ",", "target_position", "=", "'random'", ",", "target_rotation", "=", "'xyz'", ",", "reward_type", "=", "'sparse'", ",", "distance_threshold", "=", "0.05", ",", "rotation_threshold", "=", "0.1", ")", ":", "\n", "    ", "self", ".", "num_step", "=", "0", "\n", "self", ".", "max_step", "=", "max_step", "\n", "super", "(", "HandPenEnv", ",", "self", ")", ".", "__init__", "(", "\n", "model_path", "=", "MANIPULATE_PEN_XML", ",", "target_position", "=", "target_position", ",", "\n", "target_rotation", "=", "target_rotation", ",", "\n", "target_position_range", "=", "np", ".", "array", "(", "[", "(", "-", "0.04", ",", "0.04", ")", ",", "(", "-", "0.06", ",", "0.02", ")", ",", "(", "0.0", ",", "0.06", ")", "]", ")", ",", "\n", "randomize_initial_rotation", "=", "False", ",", "reward_type", "=", "reward_type", ",", "\n", "ignore_z_target_rotation", "=", "True", ",", "distance_threshold", "=", "distance_threshold", ",", "rotation_threshold", "=", "rotation_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandPenEnv.step": [[45, 51], ["super().step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandPenEnv.reset": [[52, 56], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandEggEnv.__init__": [[59, 67], ["gym.envs.robotics.hand.manipulate.ManipulateEnv.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "max_step", "=", "100", ",", "target_position", "=", "'random'", ",", "target_rotation", "=", "'xyz'", ",", "reward_type", "=", "'sparse'", ",", "distance_threshold", "=", "0.01", ",", "rotation_threshold", "=", "0.1", ")", ":", "\n", "    ", "self", ".", "num_step", "=", "0", "\n", "self", ".", "max_step", "=", "max_step", "\n", "super", "(", "HandEggEnv", ",", "self", ")", ".", "__init__", "(", "\n", "model_path", "=", "MANIPULATE_EGG_XML", ",", "target_position", "=", "target_position", ",", "\n", "target_rotation", "=", "target_rotation", ",", "\n", "target_position_range", "=", "np", ".", "array", "(", "[", "(", "-", "0.04", ",", "0.04", ")", ",", "(", "-", "0.06", ",", "0.02", ")", ",", "(", "0.0", ",", "0.06", ")", "]", ")", ",", "\n", "reward_type", "=", "reward_type", ",", "distance_threshold", "=", "distance_threshold", ",", "rotation_threshold", "=", "rotation_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandEggEnv.step": [[68, 74], ["super().step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandEggEnv.reset": [[75, 79], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandReachFullEnv.__init__": [[82, 87], ["gym.envs.robotics.hand.reach.HandReachEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["  ", "def", "__init__", "(", "self", ",", "max_step", "=", "50", ",", "distance_threshold", "=", "0.01", ",", "n_substeps", "=", "20", ",", "reward_type", "=", "'sparse'", ",", ")", ":", "\n", "    ", "self", ".", "num_step", "=", "0", "\n", "self", ".", "max_step", "=", "max_step", "\n", "super", "(", "HandReachFullEnv", ",", "self", ")", ".", "__init__", "(", "\n", "distance_threshold", "=", "distance_threshold", ",", "n_substeps", "=", "n_substeps", ",", "reward_type", "=", "reward_type", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandReachFullEnv.step": [[89, 95], ["super().step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "_", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "self", ".", "num_step", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_step", ">=", "self", ".", "max_step", "else", "False", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.custom_hand.HandReachFullEnv.reset": [[96, 100], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "num_step", "=", "0", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax": [[4, 8], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.discrete_to_box_wrapper": [[10, 27], ["isinstance", "gym.spaces.Box", "numpy.clip", "__init__.softmax", "numpy.random.choice", "old_step", "range"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.__init__.softmax"], []], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.EpsilonWrapper.__init__": [[6, 33], ["hasattr", "epsilon_wrapper.EpsilonWrapper.env.reset", "numpy.array", "gym.spaces.Dict", "hasattr", "dict", "epsilon_wrapper.EpsilonWrapper.attrs.append", "epsilon_wrapper.EpsilonWrapper.defaults.append", "getattr", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "len", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["  ", "def", "__init__", "(", "self", ",", "env", ",", "attrs", "=", "(", "'distance_threshold'", ",", "'rotation_threshold'", ")", ",", "compute_reward_with_internal", "=", "None", ")", ":", "\n", "    ", "\"\"\"Attrs is list of attributes (strings like \"distance_threshold\"). Only valid ones are used. \"\"\"", "\n", "\n", "self", ".", "env", "=", "env", "\n", "if", "hasattr", "(", "self", ".", "env", ",", "'mode'", ")", ":", "\n", "      ", "assert", "self", ".", "env", ".", "mode", "==", "0", "\n", "\n", "", "if", "compute_reward_with_internal", "is", "not", "None", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "compute_reward_with_internal", "\n", "\n", "", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "internal_len", "=", "obs", "[", "'achieved_goal'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "self", ".", "attrs", "=", "[", "]", "\n", "self", ".", "defaults", "=", "[", "]", "\n", "\n", "for", "attr", "in", "attrs", ":", "\n", "      ", "if", "hasattr", "(", "self", ".", "env", ",", "attr", ")", ":", "\n", "        ", "self", ".", "attrs", ".", "append", "(", "attr", ")", "\n", "self", ".", "defaults", ".", "append", "(", "getattr", "(", "self", ".", "env", ",", "attr", ")", ")", "\n", "\n", "", "", "self", ".", "defaults", "=", "np", ".", "array", "(", "self", ".", "defaults", ")", "\n", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "dict", "(", "\n", "desired_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "self", ".", "internal_len", "+", "len", "(", "self", ".", "attrs", ")", ",", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", "achieved_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "self", ".", "internal_len", "+", "len", "(", "self", ".", "attrs", ")", ",", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", "observation", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "obs", "[", "'observation'", "]", ".", "shape", "[", "0", "]", ",", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.EpsilonWrapper.__getattr__": [[36, 40], ["getattr", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "    ", "if", "attr", "in", "self", ".", "__dict__", ":", "\n", "      ", "return", "getattr", "(", "self", ",", "attr", ")", "\n", "", "return", "getattr", "(", "self", ".", "env", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.EpsilonWrapper.compute_reward": [[41, 56], ["zip", "epsilon_wrapper.EpsilonWrapper.env.compute_reward", "zip", "epsilon_wrapper.EpsilonWrapper.env.compute_reward", "setattr", "setattr"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "    ", "internal_achieved", "=", "achieved_goal", "[", ":", "self", ".", "internal_len", "]", "\n", "internal_goal", "=", "goal", "[", ":", "self", ".", "internal_len", "]", "\n", "\n", "if", "self", ".", "compute_reward_with_internal", ":", "\n", "      ", "for", "attr", ",", "eps", "in", "zip", "(", "self", ".", "attrs", ",", "self", ".", "defaults", ")", ":", "\n", "        ", "setattr", "(", "self", ".", "env", ",", "attr", ",", "eps", ")", "\n", "", "internal_reward", "=", "self", ".", "env", ".", "compute_reward", "(", "internal_achieved", ",", "internal_goal", ",", "info", ")", "\n", "return", "internal_reward", "\n", "\n", "# Otherwise, use epsilon in the goal to determine external reward", "\n", "", "for", "attr", ",", "eps", "in", "zip", "(", "self", ".", "attrs", ",", "goal", "[", "self", ".", "internal_len", ":", "]", ")", ":", "\n", "      ", "setattr", "(", "self", ".", "env", ",", "attr", ",", "eps", ")", "\n", "", "reward", "=", "self", ".", "env", ".", "compute_reward", "(", "internal_achieved", ",", "internal_goal", ",", "info", ")", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.EpsilonWrapper.step": [[58, 64], ["epsilon_wrapper.EpsilonWrapper.env.step", "numpy.concatenate", "numpy.concatenate", "epsilon_wrapper.EpsilonWrapper.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "obs", "[", "'achieved_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "defaults", "]", ")", "\n", "obs", "[", "'desired_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'desired_goal'", "]", ",", "self", ".", "defaults", "]", ")", "\n", "reward", "=", "self", ".", "compute_reward", "(", "obs", "[", "'achieved_goal'", "]", ",", "obs", "[", "'desired_goal'", "]", ",", "info", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.EpsilonWrapper._get_obs": [[66, 72], ["epsilon_wrapper.EpsilonWrapper.env._get_obs", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "\"\"\"just adds a large epsilon (content doesn't super matter)\"\"\"", "\n", "obs", "=", "self", ".", "env", ".", "_get_obs", "(", ")", "\n", "obs", "[", "'achieved_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "defaults", "]", ")", "\n", "obs", "[", "'desired_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'desired_goal'", "]", ",", "self", ".", "defaults", "]", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.EpsilonWrapper._sample_goal": [[73, 78], ["epsilon_wrapper.EpsilonWrapper.env._sample_goal", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "\"\"\"just adds a large epsilon (content doesn't super matter)\"\"\"", "\n", "goal", "=", "self", ".", "env", ".", "_sample_goal", "(", ")", "\n", "goal", "=", "np", ".", "concatenate", "(", "[", "goal", ",", "self", ".", "defaults", "]", ")", "\n", "return", "goal", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.EpsilonWrapper.reset": [[79, 84], ["epsilon_wrapper.EpsilonWrapper.env.reset", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "obs", "[", "'achieved_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "defaults", "]", ")", "\n", "obs", "[", "'desired_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'desired_goal'", "]", ",", "self", ".", "defaults", "]", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper.__init__": [[87, 104], ["hasattr", "epsilon_wrapper.OldEpsilonWrapper.env.reset", "gym.spaces.Dict", "numpy.ones_like", "dict", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["  ", "def", "__init__", "(", "self", ",", "env", ",", "epsilon", ",", "compute_reward_with_internal", "=", "None", ")", ":", "\n", "    ", "\"\"\"Epsilon is float or np.array, specifying default epsilon\"\"\"", "\n", "\n", "self", ".", "env", "=", "env", "\n", "if", "hasattr", "(", "self", ".", "env", ",", "'mode'", ")", ":", "\n", "      ", "assert", "self", ".", "env", ".", "mode", "==", "0", "\n", "\n", "", "if", "compute_reward_with_internal", "is", "not", "None", ":", "\n", "      ", "self", ".", "compute_reward_with_internal", "=", "compute_reward_with_internal", "\n", "\n", "", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "default_epsilon", "=", "np", ".", "ones_like", "(", "obs", "[", "'desired_goal'", "]", ")", "*", "epsilon", "\n", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Dict", "(", "dict", "(", "\n", "desired_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "obs", "[", "'achieved_goal'", "]", ".", "shape", "[", "0", "]", "*", "2", ",", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", "achieved_goal", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "obs", "[", "'achieved_goal'", "]", ".", "shape", "[", "0", "]", "*", "2", ",", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", "observation", "=", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "(", "obs", "[", "'observation'", "]", ".", "shape", "[", "0", "]", ",", ")", ",", "dtype", "=", "'float32'", ")", ",", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper.__getattr__": [[107, 111], ["getattr", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "    ", "if", "attr", "in", "self", ".", "__dict__", ":", "\n", "      ", "return", "getattr", "(", "self", ",", "attr", ")", "\n", "", "return", "getattr", "(", "self", ".", "env", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper.compute_reward": [[112, 126], ["numpy.all", "len", "epsilon_wrapper.OldEpsilonWrapper.env.compute_reward", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "goal", ",", "info", ")", ":", "\n", "    ", "internal_len", "=", "len", "(", "achieved_goal", ")", "//", "2", "\n", "internal_achieved", "=", "achieved_goal", "[", ":", "internal_len", "]", "\n", "internal_goal", "=", "goal", "[", ":", "internal_len", "]", "\n", "\n", "if", "self", ".", "compute_reward_with_internal", ":", "\n", "      ", "internal_reward", "=", "self", ".", "env", ".", "compute_reward", "(", "internal_achieved", ",", "internal_goal", ",", "info", ")", "\n", "return", "internal_reward", "\n", "\n", "# Otherwise, use epsilon to determine external reward", "\n", "", "epsilon", "=", "goal", "[", "internal_len", ":", "]", "\n", "\n", "success", "=", "np", ".", "all", "(", "np", ".", "abs", "(", "internal_achieved", "-", "internal_goal", ")", "<", "epsilon", ")", "\n", "return", "success", "-", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper.step": [[128, 134], ["epsilon_wrapper.OldEpsilonWrapper.env.step", "numpy.concatenate", "numpy.concatenate", "epsilon_wrapper.OldEpsilonWrapper.compute_reward"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "obs", "[", "'achieved_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "default_epsilon", "]", ")", "\n", "obs", "[", "'desired_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'desired_goal'", "]", ",", "self", ".", "default_epsilon", "]", ")", "\n", "reward", "=", "self", ".", "compute_reward", "(", "obs", "[", "'achieved_goal'", "]", ",", "obs", "[", "'desired_goal'", "]", ",", "info", ")", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._get_obs": [[136, 142], ["epsilon_wrapper.OldEpsilonWrapper.env._get_obs", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "\"\"\"just adds a large epsilon (content doesn't super matter)\"\"\"", "\n", "obs", "=", "self", ".", "env", ".", "_get_obs", "(", ")", "\n", "obs", "[", "'achieved_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "default_epsilon", "]", ")", "\n", "obs", "[", "'desired_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'desired_goal'", "]", ",", "self", ".", "default_epsilon", "]", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal": [[143, 148], ["epsilon_wrapper.OldEpsilonWrapper.env._sample_goal", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper._sample_goal"], ["", "def", "_sample_goal", "(", "self", ")", ":", "\n", "    ", "\"\"\"just adds a large epsilon (content doesn't super matter)\"\"\"", "\n", "goal", "=", "self", ".", "env", ".", "_sample_goal", "(", ")", "\n", "goal", "=", "np", ".", "concatenate", "(", "[", "goal", ",", "self", ".", "default_epsilon", "]", ")", "\n", "return", "goal", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.customfetch.epsilon_wrapper.OldEpsilonWrapper.reset": [[149, 154], ["epsilon_wrapper.OldEpsilonWrapper.env.reset", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "obs", "[", "'achieved_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'achieved_goal'", "]", ",", "self", ".", "default_epsilon", "]", ")", "\n", "obs", "[", "'desired_goal'", "]", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "'desired_goal'", "]", ",", "self", ".", "default_epsilon", "]", ")", "\n", "return", "obs", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.GoalBasedSawyerLift.__init__": [[13, 57], ["super().__init__", "gym.spaces.Box", "numpy.array", "sawyer.GoalBasedSawyerLift._get_observation", "gym.spaces.Box", "gym.spaces.Dict", "gym.spaces.Box", "gym.spaces.Box", "sum", "numpy.concatenate", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "test", "=", "False", ",", "use_dense", "=", "True", ",", "objgrip", "=", "False", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "use_camera_obs", "=", "False", ",", "\n", "has_renderer", "=", "False", ",", "\n", "use_indicator_object", "=", "True", ",", "\n", "has_offscreen_renderer", "=", "False", ",", "\n", "horizon", "=", "50", ",", "\n", "ignore_done", "=", "True", "\n", ")", "\n", "self", ".", "_viewer", "=", "None", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "*", "self", ".", "action_spec", ")", "\n", "\n", "self", ".", "_init_eef", "=", "np", ".", "array", "(", "[", "0.58218024", ",", "-", "0.01407946", ",", "0.90169981", "]", ")", "\n", "\n", "o", "=", "self", ".", "_get_observation", "(", ")", "\n", "self", ".", "_obs_keys", "=", "[", "'cube_pos'", ",", "'cube_quat'", ",", "'eef_pos'", ",", "'joint_pos'", ",", "'joint_vel'", ",", "'gripper_qpos'", ",", "'gripper_qvel'", "]", "\n", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "sum", "(", "[", "len", "(", "o", "[", "k", "]", ")", "for", "k", "in", "self", ".", "_obs_keys", "]", ")", ",", ")", ")", "\n", "if", "objgrip", ":", "\n", "      ", "self", ".", "ag", "=", "lambda", "obs", ":", "np", ".", "concatenate", "(", "(", "obs", "[", ":", "3", "]", ",", "obs", "[", "7", ":", "10", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "ag", "=", "lambda", "obs", ":", "obs", "[", ":", "3", "]", "\n", "\n", "", "if", "objgrip", ":", "\n", "      ", "goal_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "6", ",", ")", ")", "\n", "", "else", ":", "\n", "      ", "goal_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "3", ",", ")", ")", "\n", "\n", "", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Dict", "(", "{", "\n", "'observation'", ":", "observation_space", ",", "\n", "'desired_goal'", ":", "goal_space", ",", "\n", "'achieved_goal'", ":", "goal_space", "\n", "}", ")", "\n", "\n", "self", ".", "max_steps", "=", "50", "\n", "self", ".", "num_steps", "=", "0", "\n", "self", ".", "dist_threshold", "=", "0.05", "\n", "if", "objgrip", ":", "\n", "      ", "self", ".", "dist_threshold", "=", "0.07", "\n", "", "self", ".", "test", "=", "test", "\n", "self", ".", "use_dense", "=", "use_dense", "\n", "self", ".", "objgrip", "=", "objgrip", "\n", "\n", "self", ".", "goal", "=", "None", "\n", "self", ".", "_prev_state", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.GoalBasedSawyerLift.reset": [[58, 113], ["sawyer.GoalBasedSawyerLift.sim.set_state", "sawyer.GoalBasedSawyerLift.initialize_time", "sawyer.GoalBasedSawyerLift._get_reference", "sawyer.GoalBasedSawyerLift.sim.data.get_joint_qpos", "numpy.random.uniform", "sawyer.GoalBasedSawyerLift.sim.data.set_joint_qpos", "sawyer.GoalBasedSawyerLift.move_indicator", "numpy.array", "numpy.array", "sawyer.GoalBasedSawyerLift.sim.forward", "sawyer.GoalBasedSawyerLift._get_observation", "numpy.concatenate", "sawyer.GoalBasedSawyerLift.ag", "numpy.array", "numpy.concatenate", "numpy.random.randn"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Need to override reset because the original is awfully inefficient (it reloads Mujoco Sim entirely)\n    \"\"\"", "\n", "self", ".", "num_steps", "=", "0", "\n", "\n", "# From base.py", "\n", "self", ".", "sim", ".", "set_state", "(", "self", ".", "sim_state_initial", ")", "\n", "self", ".", "initialize_time", "(", "self", ".", "control_freq", ")", "\n", "self", ".", "_get_reference", "(", ")", "\n", "self", ".", "cur_time", "=", "0", "\n", "self", ".", "timestep", "=", "0", "\n", "self", ".", "done", "=", "False", "\n", "\n", "# From sawyer.py", "\n", "self", ".", "sim", ".", "data", ".", "qpos", "[", "self", ".", "_ref_joint_pos_indexes", "]", "=", "self", ".", "mujoco_robot", ".", "init_qpos", "\n", "\n", "if", "self", ".", "has_gripper", ":", "\n", "        ", "self", ".", "sim", ".", "data", ".", "qpos", "[", "\n", "self", ".", "_ref_gripper_joint_pos_indexes", "\n", "]", "=", "self", ".", "gripper", ".", "init_qpos", "\n", "\n", "# From sawyer_lift.py", "\n", "\n", "# reset positions of objects", "\n", "# self.model.place_objects() <- doesn't actually work, because this operates on the model and not the sim...", "\n", "", "init_pos", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qpos", "(", "'cube'", ")", "\n", "init_pos", "[", ":", "2", "]", "+=", "np", ".", "random", ".", "uniform", "(", "-", "0.1", ",", "0.1", ",", "2", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "'cube'", ",", "init_pos", ")", "\n", "\n", "# reset goal position", "\n", "self", ".", "goal", "=", "init_pos", "[", ":", "3", "]", "+", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.12", "]", ")", "\n", "self", ".", "move_indicator", "(", "self", ".", "goal", ")", "\n", "if", "self", ".", "objgrip", ":", "\n", "      ", "self", ".", "goal", "=", "np", ".", "concatenate", "(", "(", "self", ".", "goal", ",", "self", ".", "goal", ")", ")", "\n", "\n", "\n", "# reset joint positions", "\n", "", "init_pos", "=", "np", ".", "array", "(", "[", "-", "0.5538", ",", "-", "0.8208", ",", "0.4155", ",", "1.8409", ",", "-", "0.4955", ",", "0.6482", ",", "1.9628", "]", ")", "\n", "init_pos", "+=", "np", ".", "random", ".", "randn", "(", "init_pos", ".", "shape", "[", "0", "]", ")", "*", "0.02", "\n", "self", ".", "sim", ".", "data", ".", "qpos", "[", "self", ".", "_ref_joint_pos_indexes", "]", "=", "np", ".", "array", "(", "init_pos", ")", "\n", "\n", "# And again from base.py", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "obs", "=", "self", ".", "_get_observation", "(", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "k", "]", "for", "k", "in", "self", ".", "_obs_keys", "]", ")", "\n", "ag", "=", "self", ".", "ag", "(", "obs", ")", "\n", "\n", "self", ".", "_prev_state", "=", "obs", "\n", "obs", "=", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "ag", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ",", "\n", "}", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.GoalBasedSawyerLift.seed": [[114, 116], ["numpy.random.seed"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.GoalBasedSawyerLift.compute_reward": [[117, 140], ["numpy.linalg.norm", "len", "len", "numpy.tanh", "numpy.tanh", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.mean", "numpy.mean", "numpy.abs", "numpy.abs"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "ag", ",", "dg", ",", "info", ")", ":", "\n", "    ", "d", "=", "np", ".", "linalg", ".", "norm", "(", "ag", "-", "dg", ",", "axis", "=", "-", "1", ")", "\n", "reward", "=", "-", "(", "d", ">=", "self", ".", "dist_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "success", "=", "1.", "+", "reward", "\n", "failure", "=", "-", "1", "*", "reward", "\n", "\n", "reward", "-=", "d", "*", "success", "\n", "\n", "ns", "=", "info", "[", "'ns'", "]", "\n", "if", "len", "(", "ns", ".", "shape", ")", "==", "1", ":", "\n", "      ", "reward", "-=", "(", "0.2", "*", "np", ".", "tanh", "(", "np", ".", "mean", "(", "np", ".", "abs", "(", "info", "[", "'s'", "]", "[", "7", ":", "17", "]", "-", "ns", "[", "7", ":", "17", "]", ")", ",", "axis", "=", "-", "1", ")", ")", "*", "success", ")", "# Penalize successes that move", "\n", "", "else", ":", "\n", "      ", "reward", "-=", "(", "0.2", "*", "np", ".", "tanh", "(", "np", ".", "mean", "(", "np", ".", "abs", "(", "info", "[", "'s'", "]", "[", ":", ",", "7", ":", "17", "]", "-", "ns", "[", ":", ",", "7", ":", "17", "]", ")", ",", "axis", "=", "-", "1", ")", ")", "*", "success", ")", "# Penalize successes that move", "\n", "\n", "# add dense reward discourages agent from being far away from the cube", "\n", "", "if", "self", ".", "use_dense", ":", "\n", "      ", "if", "len", "(", "ns", ".", "shape", ")", "==", "1", ":", "\n", "        ", "reward", "-=", "np", ".", "linalg", ".", "norm", "(", "ns", "[", ":", "3", "]", "-", "ns", "[", "7", ":", "10", "]", ")", "*", "failure", "\n", "", "else", ":", "\n", "        ", "reward", "-=", "np", ".", "linalg", ".", "norm", "(", "ns", "[", ":", ",", ":", "3", "]", "-", "ns", "[", ":", ",", "7", ":", "10", "]", ",", "axis", "=", "-", "1", ")", "*", "failure", "\n", "\n", "", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.GoalBasedSawyerLift.is_success": [[141, 144], ["numpy.linalg.norm"], "methods", ["None"], ["", "def", "is_success", "(", "self", ",", "ag", ",", "dg", ")", ":", "\n", "    ", "d", "=", "np", ".", "linalg", ".", "norm", "(", "ag", "[", ":", "3", "]", "-", "dg", "[", ":", "3", "]", ",", "axis", "=", "-", "1", ")", "\n", "return", "d", "<=", "self", ".", "dist_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.GoalBasedSawyerLift.step": [[145, 170], ["super().step", "numpy.concatenate", "sawyer.GoalBasedSawyerLift.ag", "sawyer.GoalBasedSawyerLift.compute_reward", "sawyer.GoalBasedSawyerLift.is_success", "sawyer.GoalBasedSawyerLift._check_success"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.is_success"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "_", ",", "_", ",", "_", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "k", "]", "for", "k", "in", "self", ".", "_obs_keys", "]", ")", "\n", "ag", "=", "self", ".", "ag", "(", "obs", ")", "\n", "eef", "=", "obs", "[", "7", ":", "10", "]", "\n", "\n", "reward", "=", "self", ".", "compute_reward", "(", "ag", ",", "self", ".", "goal", ",", "{", "'s'", ":", "obs", ",", "'ns'", ":", "self", ".", "_prev_state", "}", ")", "\n", "self", ".", "_prev_state", "=", "obs", "\n", "obs", "=", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "ag", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ",", "\n", "}", "\n", "\n", "\n", "if", "not", "self", ".", "test", ":", "\n", "      ", "info", "=", "{", "'is_success'", ":", "self", ".", "is_success", "(", "ag", ",", "self", ".", "goal", ")", "}", "\n", "", "elif", "self", ".", "test", ":", "\n", "      ", "info", "=", "{", "'is_success'", ":", "self", ".", "_check_success", "(", ")", "}", "\n", "\n", "", "self", ".", "num_steps", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_steps", ">=", "self", ".", "max_steps", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.GoalBasedSawyerLift.render": [[173, 191], ["time.sleep", "sawyer.GoalBasedSawyerLift._viewer.render", "robosuite.utils.MujocoPyRenderer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Fix Robosuite render method, so that Viewer is only spawned on render\n    \"\"\"", "\n", "if", "self", ".", "_viewer", "is", "None", ":", "\n", "      ", "self", ".", "_viewer", "=", "MujocoPyRenderer", "(", "self", ".", "sim", ")", "\n", "self", ".", "_viewer", ".", "viewer", ".", "vopt", ".", "geomgroup", "[", "0", "]", "=", "(", "\n", "1", "if", "self", ".", "render_collision_mesh", "else", "0", "\n", ")", "\n", "self", ".", "_viewer", ".", "viewer", ".", "vopt", ".", "geomgroup", "[", "1", "]", "=", "1", "if", "self", ".", "render_visual_mesh", "else", "0", "\n", "\n", "# hiding the overlay speeds up rendering significantly", "\n", "self", ".", "_viewer", ".", "viewer", ".", "_hide_overlay", "=", "True", "\n", "\n", "self", ".", "_viewer", ".", "viewer", ".", "_render_every_frame", "=", "True", "\n", "\n", "", "time", ".", "sleep", "(", "1", "/", "self", ".", "control_freq", ")", "\n", "self", ".", "_viewer", ".", "render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.SawyerReach.__init__": [[196, 226], ["super().__init__", "gym.spaces.Box", "numpy.array", "sawyer.SawyerReach._get_observation", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Dict", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "\n", "use_camera_obs", "=", "False", ",", "\n", "has_renderer", "=", "False", ",", "\n", "use_indicator_object", "=", "True", ",", "\n", "has_offscreen_renderer", "=", "False", ",", "\n", "horizon", "=", "50", ",", "\n", "ignore_done", "=", "True", "\n", ")", "\n", "self", ".", "_viewer", "=", "None", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "*", "self", ".", "action_spec", ")", "\n", "\n", "self", ".", "_init_eef", "=", "np", ".", "array", "(", "[", "0.58218024", ",", "-", "0.01407946", ",", "0.90169981", "]", ")", "\n", "\n", "o", "=", "self", ".", "_get_observation", "(", ")", "\n", "self", ".", "_obs_keys", "=", "[", "'eef_pos'", ",", "'joint_pos'", ",", "'joint_vel'", ",", "'gripper_qpos'", ",", "'gripper_qvel'", "]", "#, 'cube_pos', 'cube_quat']", "\n", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "(", "sum", "(", "[", "len", "(", "o", "[", "k", "]", ")", "for", "k", "in", "self", ".", "_obs_keys", "]", ")", ",", ")", ")", "\n", "self", ".", "ag", "=", "lambda", "obs", ":", "obs", "[", ":", "3", "]", "\n", "goal_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "o", "[", "'eef_pos'", "]", ".", "shape", ")", "\n", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Dict", "(", "{", "\n", "'observation'", ":", "observation_space", ",", "\n", "'desired_goal'", ":", "goal_space", ",", "\n", "'achieved_goal'", ":", "goal_space", "\n", "}", ")", "\n", "\n", "self", ".", "max_steps", "=", "50", "\n", "self", ".", "num_steps", "=", "0", "\n", "self", ".", "dist_threshold", "=", "0.05", "\n", "self", ".", "_prev_state", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.SawyerReach.reset": [[227, 285], ["sawyer.SawyerReach.sim.set_state", "sawyer.SawyerReach.initialize_time", "sawyer.SawyerReach._get_reference", "sawyer.SawyerReach.sim.data.get_joint_qpos", "numpy.random.uniform", "sawyer.SawyerReach.sim.data.set_joint_qpos", "numpy.array", "numpy.array", "sawyer.SawyerReach.move_indicator", "sawyer.SawyerReach.sim.forward", "sawyer.SawyerReach._get_observation", "numpy.concatenate", "sawyer.SawyerReach.ag", "numpy.random.randn", "numpy.array", "numpy.linalg.norm", "numpy.random.uniform", "numpy.array", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Need to override reset because the original is awfully inefficient (it reloads Mujoco Sim entirely)\n    \"\"\"", "\n", "self", ".", "num_steps", "=", "0", "\n", "\n", "# From base.py", "\n", "self", ".", "sim", ".", "set_state", "(", "self", ".", "sim_state_initial", ")", "\n", "self", ".", "initialize_time", "(", "self", ".", "control_freq", ")", "\n", "self", ".", "_get_reference", "(", ")", "\n", "self", ".", "cur_time", "=", "0", "\n", "self", ".", "timestep", "=", "0", "\n", "self", ".", "done", "=", "False", "\n", "\n", "# From sawyer.py", "\n", "self", ".", "sim", ".", "data", ".", "qpos", "[", "self", ".", "_ref_joint_pos_indexes", "]", "=", "self", ".", "mujoco_robot", ".", "init_qpos", "\n", "\n", "if", "self", ".", "has_gripper", ":", "\n", "        ", "self", ".", "sim", ".", "data", ".", "qpos", "[", "\n", "self", ".", "_ref_gripper_joint_pos_indexes", "\n", "]", "=", "self", ".", "gripper", ".", "init_qpos", "\n", "\n", "# From sawyer_lift.py", "\n", "\n", "# reset positions of objects", "\n", "# self.model.place_objects() <- doesn't actually work, because this operates on the model and not the sim...", "\n", "", "init_pos", "=", "self", ".", "sim", ".", "data", ".", "get_joint_qpos", "(", "'cube'", ")", "\n", "init_pos", "[", ":", "2", "]", "+=", "np", ".", "random", ".", "uniform", "(", "-", "0.05", ",", "0.05", ",", "2", ")", "\n", "self", ".", "sim", ".", "data", ".", "set_joint_qpos", "(", "'cube'", ",", "init_pos", ")", "\n", "\n", "# reset joint positions", "\n", "init_pos", "=", "np", ".", "array", "(", "[", "-", "0.5538", ",", "-", "0.8208", ",", "0.4155", ",", "1.8409", ",", "-", "0.4955", ",", "0.6482", ",", "1.9628", "]", ")", "\n", "init_pos", "+=", "np", ".", "random", ".", "randn", "(", "init_pos", ".", "shape", "[", "0", "]", ")", "*", "0.02", "\n", "self", ".", "sim", ".", "data", ".", "qpos", "[", "self", ".", "_ref_joint_pos_indexes", "]", "=", "np", ".", "array", "(", "init_pos", ")", "\n", "\n", "# reset goal position", "\n", "init_pos", "=", "self", ".", "_init_eef", "\n", "proposal", "=", "init_pos", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.2", ",", "0.2", ",", "3", ")", "+", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.15", "]", ")", "\n", "while", "np", ".", "linalg", ".", "norm", "(", "init_pos", "-", "proposal", ")", "<", "0.05", ":", "\n", "      ", "proposal", "=", "init_pos", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.2", ",", "0.2", ",", "3", ")", "+", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.15", "]", ")", "\n", "\n", "", "self", ".", "goal", "=", "proposal", "\n", "self", ".", "move_indicator", "(", "self", ".", "goal", ")", "\n", "\n", "# And again from base.py", "\n", "self", ".", "sim", ".", "forward", "(", ")", "\n", "obs", "=", "self", ".", "_get_observation", "(", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "k", "]", "for", "k", "in", "self", ".", "_obs_keys", "]", ")", "\n", "ag", "=", "self", ".", "ag", "(", "obs", ")", "\n", "\n", "\n", "self", ".", "_prev_state", "=", "obs", "\n", "obs", "=", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "ag", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ",", "\n", "}", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.SawyerReach.seed": [[286, 288], ["numpy.random.seed"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.SawyerReach.compute_reward": [[289, 302], ["numpy.linalg.norm", "len", "numpy.tanh", "numpy.tanh", "numpy.mean", "numpy.mean", "numpy.abs", "numpy.abs"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "desired_goal", ",", "info", ")", ":", "\n", "    ", "d", "=", "np", ".", "linalg", ".", "norm", "(", "achieved_goal", "-", "desired_goal", ",", "axis", "=", "-", "1", ")", "\n", "reward", "=", "-", "(", "d", ">=", "self", ".", "dist_threshold", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "success", "=", "1.", "+", "reward", "\n", "\n", "reward", "-=", "d", "*", "success", "# penalize distance when successful", "\n", "\n", "if", "len", "(", "achieved_goal", ".", "shape", ")", "==", "1", ":", "\n", "      ", "reward", "-=", "(", "0.2", "*", "np", ".", "tanh", "(", "np", ".", "mean", "(", "np", ".", "abs", "(", "info", "[", "'s'", "]", "[", "0", ":", "10", "]", "-", "info", "[", "'ns'", "]", "[", "0", ":", "10", "]", ")", ",", "axis", "=", "-", "1", ")", ")", "*", "success", ")", "# Penalize successes that move", "\n", "", "else", ":", "\n", "      ", "reward", "-=", "(", "0.2", "*", "np", ".", "tanh", "(", "np", ".", "mean", "(", "np", ".", "abs", "(", "info", "[", "'s'", "]", "[", ":", ",", "0", ":", "10", "]", "-", "info", "[", "'ns'", "]", "[", ":", ",", "0", ":", "10", "]", ")", ",", "axis", "=", "-", "1", ")", ")", "*", "success", ")", "# Penalize successes that move", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.SawyerReach.is_success": [[303, 306], ["numpy.linalg.norm"], "methods", ["None"], ["", "def", "is_success", "(", "self", ",", "ag", ",", "dg", ")", ":", "\n", "    ", "d", "=", "np", ".", "linalg", ".", "norm", "(", "ag", "[", ":", "3", "]", "-", "dg", "[", ":", "3", "]", ",", "axis", "=", "-", "1", ")", "\n", "return", "d", "<=", "self", ".", "dist_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.SawyerReach.step": [[307, 326], ["super().step", "numpy.concatenate", "sawyer.SawyerReach.ag", "sawyer.SawyerReach.compute_reward", "sawyer.SawyerReach.is_success"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.is_success"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "obs", ",", "_", ",", "_", ",", "_", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", "[", "k", "]", "for", "k", "in", "self", ".", "_obs_keys", "]", ")", "\n", "ag", "=", "self", ".", "ag", "(", "obs", ")", "\n", "\n", "reward", "=", "self", ".", "compute_reward", "(", "ag", ",", "self", ".", "goal", ",", "{", "'s'", ":", "self", ".", "_prev_state", ",", "'ns'", ":", "obs", "}", ")", "\n", "self", ".", "_prev_state", "=", "obs", "\n", "obs", "=", "{", "\n", "'observation'", ":", "obs", ",", "\n", "'achieved_goal'", ":", "ag", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ",", "\n", "}", "\n", "\n", "info", "=", "{", "'is_success'", ":", "self", ".", "is_success", "(", "ag", ",", "self", ".", "goal", ")", "}", "\n", "self", ".", "num_steps", "+=", "1", "\n", "done", "=", "True", "if", "self", ".", "num_steps", ">=", "self", ".", "max_steps", "else", "False", "\n", "if", "done", ":", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.robosuite.sawyer.SawyerReach.render": [[327, 344], ["time.sleep", "sawyer.SawyerReach._viewer.render", "robosuite.utils.MujocoPyRenderer"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    Fix Robosuite render method, so that Viewer is only spawned on render\n    \"\"\"", "\n", "if", "self", ".", "_viewer", "is", "None", ":", "\n", "      ", "self", ".", "_viewer", "=", "MujocoPyRenderer", "(", "self", ".", "sim", ")", "\n", "self", ".", "_viewer", ".", "viewer", ".", "vopt", ".", "geomgroup", "[", "0", "]", "=", "(", "\n", "1", "if", "self", ".", "render_collision_mesh", "else", "0", "\n", ")", "\n", "self", ".", "_viewer", ".", "viewer", ".", "vopt", ".", "geomgroup", "[", "1", "]", "=", "1", "if", "self", ".", "render_visual_mesh", "else", "0", "\n", "\n", "# hiding the overlay speeds up rendering significantly", "\n", "self", ".", "_viewer", ".", "viewer", ".", "_hide_overlay", "=", "True", "\n", "self", ".", "_viewer", ".", "_render_every_frame", "=", "True", "\n", "\n", "", "time", ".", "sleep", "(", "1", "/", "self", ".", "control_freq", ")", "\n", "self", ".", "_viewer", ".", "render", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.create_maze_env.create_maze_env": [[9, 55], ["env_name.startswith", "env_name.startswith", "cls", "cls.reset", "ValueError"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["def", "create_maze_env", "(", "env_name", "=", "None", ",", "top_down_view", "=", "False", ")", ":", "\n", "  ", "n_bins", "=", "0", "\n", "manual_collision", "=", "False", "\n", "if", "env_name", ".", "startswith", "(", "'Ego'", ")", ":", "\n", "    ", "n_bins", "=", "8", "\n", "env_name", "=", "env_name", "[", "3", ":", "]", "\n", "", "if", "env_name", ".", "startswith", "(", "'Ant'", ")", ":", "\n", "    ", "cls", "=", "AntMazeEnv", "\n", "env_name", "=", "env_name", "[", "3", ":", "]", "\n", "maze_size_scaling", "=", "2", "\n", "", "else", ":", "\n", "    ", "assert", "False", ",", "'unknown env %s'", "%", "env_name", "\n", "\n", "", "observe_blocks", "=", "False", "\n", "put_spin_near_agent", "=", "False", "\n", "if", "env_name", "==", "'Maze'", ":", "\n", "    ", "maze_id", "=", "'Maze'", "\n", "", "elif", "env_name", "==", "'Push'", ":", "\n", "    ", "maze_id", "=", "'Push'", "\n", "observe_blocks", "=", "True", "\n", "", "elif", "env_name", "==", "'Fall'", ":", "\n", "    ", "maze_id", "=", "'Fall'", "\n", "observe_blocks", "=", "True", "\n", "", "elif", "env_name", "==", "'Block'", ":", "\n", "    ", "maze_id", "=", "'Block'", "\n", "put_spin_near_agent", "=", "True", "\n", "observe_blocks", "=", "True", "\n", "", "elif", "env_name", "==", "'BlockMaze'", ":", "\n", "    ", "maze_id", "=", "'BlockMaze'", "\n", "put_spin_near_agent", "=", "True", "\n", "observe_blocks", "=", "True", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unknown maze environment %s'", "%", "env_name", ")", "\n", "\n", "", "gym_mujoco_kwargs", "=", "{", "\n", "'maze_id'", ":", "maze_id", ",", "\n", "'n_bins'", ":", "n_bins", ",", "\n", "'observe_blocks'", ":", "observe_blocks", ",", "\n", "'put_spin_near_agent'", ":", "put_spin_near_agent", ",", "\n", "'top_down_view'", ":", "top_down_view", ",", "\n", "'manual_collision'", ":", "manual_collision", ",", "\n", "'maze_size_scaling'", ":", "maze_size_scaling", "\n", "}", "\n", "gym_env", "=", "cls", "(", "**", "gym_mujoco_kwargs", ")", "\n", "gym_env", ".", "reset", "(", ")", "\n", "return", "gym_env", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.__init__": [[40, 50], ["gym.envs.mujoco.mujoco_env.MujocoEnv.__init__", "gym.utils.EzPickle.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["def", "__init__", "(", "self", ",", "file_path", "=", "None", ",", "expose_all_qpos", "=", "True", ",", "\n", "expose_body_coms", "=", "None", ",", "expose_body_comvels", "=", "None", ")", ":", "\n", "    ", "self", ".", "_expose_all_qpos", "=", "expose_all_qpos", "\n", "self", ".", "_expose_body_coms", "=", "expose_body_coms", "\n", "self", ".", "_expose_body_comvels", "=", "expose_body_comvels", "\n", "self", ".", "_body_com_indices", "=", "{", "}", "\n", "self", ".", "_body_comvel_indices", "=", "{", "}", "\n", "\n", "mujoco_env", ".", "MujocoEnv", ".", "__init__", "(", "self", ",", "file_path", ",", "5", ")", "\n", "utils", ".", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.physics": [[51, 54], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "physics", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "sim", "#self.model", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv._step": [[55, 57], ["ant.AntEnv.step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "_step", "(", "self", ",", "a", ")", ":", "\n", "    ", "return", "self", ".", "step", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.step": [[58, 73], ["ant.AntEnv.do_simulation", "ant.AntEnv.state_vector", "ant.AntEnv._get_obs", "ant.AntEnv.get_body_com", "ant.AntEnv.get_body_com", "numpy.square().sum", "dict", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["", "def", "step", "(", "self", ",", "a", ")", ":", "\n", "    ", "xposbefore", "=", "self", ".", "get_body_com", "(", "\"torso\"", ")", "[", "0", "]", "\n", "self", ".", "do_simulation", "(", "a", ",", "self", ".", "frame_skip", ")", "\n", "xposafter", "=", "self", ".", "get_body_com", "(", "\"torso\"", ")", "[", "0", "]", "\n", "forward_reward", "=", "(", "xposafter", "-", "xposbefore", ")", "/", "self", ".", "dt", "\n", "ctrl_cost", "=", ".5", "*", "np", ".", "square", "(", "a", ")", ".", "sum", "(", ")", "\n", "survive_reward", "=", "1.0", "\n", "reward", "=", "forward_reward", "-", "ctrl_cost", "+", "survive_reward", "\n", "state", "=", "self", ".", "state_vector", "(", ")", "\n", "done", "=", "False", "\n", "ob", "=", "self", ".", "_get_obs", "(", ")", "\n", "return", "ob", ",", "reward", ",", "done", ",", "dict", "(", "\n", "reward_forward", "=", "forward_reward", ",", "\n", "reward_ctrl", "=", "-", "ctrl_cost", ",", "\n", "reward_survive", "=", "survive_reward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv._get_obs": [[74, 103], ["numpy.concatenate", "numpy.concatenate", "ant.AntEnv.get_body_com", "numpy.concatenate", "ant.AntEnv.get_body_comvel", "numpy.concatenate", "range", "range", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "# No cfrc observation", "\n", "    ", "if", "self", ".", "_expose_all_qpos", ":", "\n", "      ", "obs", "=", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "physics", ".", "data", ".", "qpos", ".", "flat", "[", ":", "15", "]", ",", "# Ensures only ant obs.", "\n", "self", ".", "physics", ".", "data", ".", "qvel", ".", "flat", "[", ":", "14", "]", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "      ", "obs", "=", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "physics", ".", "data", ".", "qpos", ".", "flat", "[", "2", ":", "15", "]", ",", "\n", "self", ".", "physics", ".", "data", ".", "qvel", ".", "flat", "[", ":", "14", "]", ",", "\n", "]", ")", "\n", "\n", "", "if", "self", ".", "_expose_body_coms", "is", "not", "None", ":", "\n", "      ", "for", "name", "in", "self", ".", "_expose_body_coms", ":", "\n", "        ", "com", "=", "self", ".", "get_body_com", "(", "name", ")", "\n", "if", "name", "not", "in", "self", ".", "_body_com_indices", ":", "\n", "          ", "indices", "=", "range", "(", "len", "(", "obs", ")", ",", "len", "(", "obs", ")", "+", "len", "(", "com", ")", ")", "\n", "self", ".", "_body_com_indices", "[", "name", "]", "=", "indices", "\n", "", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", ",", "com", "]", ")", "\n", "\n", "", "", "if", "self", ".", "_expose_body_comvels", "is", "not", "None", ":", "\n", "      ", "for", "name", "in", "self", ".", "_expose_body_comvels", ":", "\n", "        ", "comvel", "=", "self", ".", "get_body_comvel", "(", "name", ")", "\n", "if", "name", "not", "in", "self", ".", "_body_comvel_indices", ":", "\n", "          ", "indices", "=", "range", "(", "len", "(", "obs", ")", ",", "len", "(", "obs", ")", "+", "len", "(", "comvel", ")", ")", "\n", "self", ".", "_body_comvel_indices", "[", "name", "]", "=", "indices", "\n", "", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", ",", "comvel", "]", ")", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.reset_model": [[104, 114], ["ant.AntEnv.set_state", "ant.AntEnv._get_obs", "ant.AntEnv.np_random.uniform", "ant.AntEnv.np_random.randn"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["", "def", "reset_model", "(", "self", ")", ":", "\n", "    ", "qpos", "=", "self", ".", "init_qpos", "+", "self", ".", "np_random", ".", "uniform", "(", "\n", "size", "=", "self", ".", "model", ".", "nq", ",", "low", "=", "-", ".1", ",", "high", "=", ".1", ")", "\n", "qvel", "=", "self", ".", "init_qvel", "+", "self", ".", "np_random", ".", "randn", "(", "self", ".", "model", ".", "nv", ")", "*", ".1", "\n", "\n", "# Set everything other than ant to original position and 0 velocity.", "\n", "qpos", "[", "15", ":", "]", "=", "self", ".", "init_qpos", "[", "15", ":", "]", "\n", "qvel", "[", "14", ":", "]", "=", "0.", "\n", "self", ".", "set_state", "(", "qpos", ",", "qvel", ")", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.viewer_setup": [[115, 117], ["None"], "methods", ["None"], ["", "def", "viewer_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "viewer", ".", "cam", ".", "distance", "=", "self", ".", "model", ".", "stat", ".", "extent", "*", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.get_ori": [[118, 124], ["math.atan2", "ant.q_mult", "ant.q_mult", "ant.q_inv"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.q_mult", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.q_mult", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.q_inv"], ["", "def", "get_ori", "(", "self", ")", ":", "\n", "    ", "ori", "=", "[", "0", ",", "1", ",", "0", ",", "0", "]", "\n", "rot", "=", "self", ".", "physics", ".", "data", ".", "qpos", "[", "self", ".", "__class__", ".", "ORI_IND", ":", "self", ".", "__class__", ".", "ORI_IND", "+", "4", "]", "# take the quaternion", "\n", "ori", "=", "q_mult", "(", "q_mult", "(", "rot", ",", "ori", ")", ",", "q_inv", "(", "rot", ")", ")", "[", "1", ":", "3", "]", "# project onto x-y plane", "\n", "ori", "=", "math", ".", "atan2", "(", "ori", "[", "1", "]", ",", "ori", "[", "0", "]", ")", "\n", "return", "ori", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.set_xy": [[125, 132], ["numpy.copy", "ant.AntEnv.set_state"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.model.PytorchModel.copy"], ["", "def", "set_xy", "(", "self", ",", "xy", ")", ":", "\n", "    ", "qpos", "=", "np", ".", "copy", "(", "self", ".", "physics", ".", "data", ".", "qpos", ")", "\n", "qpos", "[", "0", "]", "=", "xy", "[", "0", "]", "\n", "qpos", "[", "1", "]", "=", "xy", "[", "1", "]", "\n", "\n", "qvel", "=", "self", ".", "physics", ".", "data", ".", "qvel", "\n", "self", ".", "set_state", "(", "qpos", ",", "qvel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.get_xy": [[133, 135], ["None"], "methods", ["None"], ["", "def", "get_xy", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "physics", ".", "data", ".", "qpos", "[", ":", "2", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.q_inv": [[24, 26], ["None"], "function", ["None"], ["def", "q_inv", "(", "a", ")", ":", "\n", "  ", "return", "[", "a", "[", "0", "]", ",", "-", "a", "[", "1", "]", ",", "-", "a", "[", "2", "]", ",", "-", "a", "[", "3", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.q_mult": [[28, 34], ["None"], "function", ["None"], ["", "def", "q_mult", "(", "a", ",", "b", ")", ":", "# multiply two quaternion", "\n", "  ", "w", "=", "a", "[", "0", "]", "*", "b", "[", "0", "]", "-", "a", "[", "1", "]", "*", "b", "[", "1", "]", "-", "a", "[", "2", "]", "*", "b", "[", "2", "]", "-", "a", "[", "3", "]", "*", "b", "[", "3", "]", "\n", "i", "=", "a", "[", "0", "]", "*", "b", "[", "1", "]", "+", "a", "[", "1", "]", "*", "b", "[", "0", "]", "+", "a", "[", "2", "]", "*", "b", "[", "3", "]", "-", "a", "[", "3", "]", "*", "b", "[", "2", "]", "\n", "j", "=", "a", "[", "0", "]", "*", "b", "[", "2", "]", "-", "a", "[", "1", "]", "*", "b", "[", "3", "]", "+", "a", "[", "2", "]", "*", "b", "[", "0", "]", "+", "a", "[", "3", "]", "*", "b", "[", "1", "]", "\n", "k", "=", "a", "[", "0", "]", "*", "b", "[", "3", "]", "+", "a", "[", "1", "]", "*", "b", "[", "2", "]", "-", "a", "[", "2", "]", "*", "b", "[", "1", "]", "+", "a", "[", "3", "]", "*", "b", "[", "0", "]", "\n", "return", "[", "w", ",", "i", ",", "j", ",", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.__init__": [[38, 237], ["os.path.join", "xml.parse", "xml.parse.find", "envs.sibrivalry.ant_maze.maze_env_utils.construct_maze", "any", "any", "maze_env.MazeEnv._find_robot", "numpy.zeros", "range", "xml.parse.find", "ET.parse.find.findall", "tempfile.mkstemp", "xml.parse.write", "model_cls", "xml.parse.find", "ET.parse.find.set", "xml.parse.find", "ET.parse.find.find().set", "len", "range", "any", "maze_env.MazeEnv._find_all_robots", "len", "Exception", "ET.parse.find.find", "xml.SubElement", "xml.SubElement", "envs.sibrivalry.ant_maze.maze_env_utils.can_move", "envs.sibrivalry.ant_maze.maze_env_utils.can_move", "maze_env.MazeEnv.movable_blocks.append", "envs.sibrivalry.ant_maze.maze_env_utils.can_move_z", "envs.sibrivalry.ant_maze.maze_env_utils.can_spin", "xml.SubElement", "xml.SubElement", "envs.sibrivalry.ant_maze.maze_env_utils.can_move_x", "envs.sibrivalry.ant_maze.maze_env_utils.can_move_y", "envs.sibrivalry.ant_maze.maze_env_utils.can_move_z", "envs.sibrivalry.ant_maze.maze_env_utils.can_spin", "xml.SubElement", "xml.SubElement", "xml.SubElement", "xml.SubElement"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.construct_maze", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._find_robot", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._find_all_robots", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_z", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_spin", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_x", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_y", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_z", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_spin"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model_dir", "=", "None", ",", "\n", "maze_id", "=", "None", ",", "\n", "maze_height", "=", "0.5", ",", "\n", "maze_size_scaling", "=", "8", ",", "\n", "n_bins", "=", "0", ",", "\n", "sensor_range", "=", "3.", ",", "\n", "sensor_span", "=", "2", "*", "math", ".", "pi", ",", "\n", "observe_blocks", "=", "False", ",", "\n", "put_spin_near_agent", "=", "False", ",", "\n", "top_down_view", "=", "False", ",", "\n", "manual_collision", "=", "False", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "_maze_id", "=", "maze_id", "\n", "\n", "model_cls", "=", "self", ".", "__class__", ".", "MODEL_CLASS", "\n", "if", "model_cls", "is", "None", ":", "\n", "      ", "raise", "\"MODEL_CLASS unspecified!\"", "\n", "", "xml_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DIR", "if", "model_dir", "is", "None", "else", "model_dir", ",", "model_cls", ".", "FILE", ")", "\n", "tree", "=", "ET", ".", "parse", "(", "xml_path", ")", "\n", "worldbody", "=", "tree", ".", "find", "(", "\".//worldbody\"", ")", "\n", "\n", "self", ".", "MAZE_HEIGHT", "=", "height", "=", "maze_height", "\n", "self", ".", "MAZE_SIZE_SCALING", "=", "size_scaling", "=", "maze_size_scaling", "\n", "self", ".", "_n_bins", "=", "n_bins", "\n", "self", ".", "_sensor_range", "=", "sensor_range", "*", "size_scaling", "\n", "self", ".", "_sensor_span", "=", "sensor_span", "\n", "self", ".", "_observe_blocks", "=", "observe_blocks", "\n", "self", ".", "_put_spin_near_agent", "=", "put_spin_near_agent", "\n", "self", ".", "_top_down_view", "=", "top_down_view", "\n", "self", ".", "_manual_collision", "=", "manual_collision", "\n", "\n", "self", ".", "MAZE_STRUCTURE", "=", "structure", "=", "maze_env_utils", ".", "construct_maze", "(", "maze_id", "=", "self", ".", "_maze_id", ")", "\n", "self", ".", "elevated", "=", "any", "(", "-", "1", "in", "row", "for", "row", "in", "structure", ")", "# Elevate the maze to allow for falling.", "\n", "self", ".", "blocks", "=", "any", "(", "\n", "any", "(", "maze_env_utils", ".", "can_move", "(", "r", ")", "for", "r", "in", "row", ")", "\n", "for", "row", "in", "structure", ")", "# Are there any movable blocks?", "\n", "\n", "torso_x", ",", "torso_y", "=", "self", ".", "_find_robot", "(", ")", "\n", "self", ".", "_init_torso_x", "=", "torso_x", "\n", "self", ".", "_init_torso_y", "=", "torso_y", "\n", "self", ".", "_init_positions", "=", "[", "\n", "(", "x", "-", "torso_x", ",", "y", "-", "torso_y", ")", "\n", "for", "x", ",", "y", "in", "self", ".", "_find_all_robots", "(", ")", "]", "\n", "\n", "self", ".", "_xy_to_rowcol", "=", "lambda", "x", ",", "y", ":", "(", "2", "+", "(", "y", "+", "size_scaling", "/", "2", ")", "/", "size_scaling", ",", "\n", "2", "+", "(", "x", "+", "size_scaling", "/", "2", ")", "/", "size_scaling", ")", "\n", "self", ".", "_view", "=", "np", ".", "zeros", "(", "[", "5", ",", "5", ",", "3", "]", ")", "# walls (immovable), chasms (fall), movable blocks", "\n", "\n", "height_offset", "=", "0.", "\n", "if", "self", ".", "elevated", ":", "\n", "# Increase initial z-pos of ant.", "\n", "      ", "height_offset", "=", "height", "*", "size_scaling", "\n", "torso", "=", "tree", ".", "find", "(", "\".//body[@name='torso']\"", ")", "\n", "torso", ".", "set", "(", "'pos'", ",", "'0 0 %.2f'", "%", "(", "0.75", "+", "height_offset", ")", ")", "\n", "", "if", "self", ".", "blocks", ":", "\n", "# If there are movable blocks, change simulation settings to perform", "\n", "# better contact detection.", "\n", "      ", "default", "=", "tree", ".", "find", "(", "\".//default\"", ")", "\n", "default", ".", "find", "(", "'.//geom'", ")", ".", "set", "(", "'solimp'", ",", "'.995 .995 .01'", ")", "\n", "\n", "", "self", ".", "movable_blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "struct", "=", "structure", "[", "i", "]", "[", "j", "]", "\n", "if", "struct", "==", "'r'", "and", "self", ".", "_put_spin_near_agent", ":", "\n", "          ", "struct", "=", "maze_env_utils", ".", "Move", ".", "SpinXY", "\n", "", "if", "self", ".", "elevated", "and", "struct", "not", "in", "[", "-", "1", "]", ":", "\n", "# Create elevated platform.", "\n", "          ", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "\n", "name", "=", "\"elevated_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", ",", "\n", "0.5", "*", "size_scaling", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.9 0.9 0.9 1\"", ",", "\n", ")", "\n", "", "if", "struct", "==", "1", ":", "# Unmovable block.", "\n", "# Offset all coordinates so that robot starts at the origin.", "\n", "          ", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "\n", "name", "=", "\"block_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", ",", "\n", "height_offset", "+", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", ",", "\n", "0.5", "*", "size_scaling", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.4 0.4 0.4 1\"", ",", "\n", ")", "\n", "", "elif", "maze_env_utils", ".", "can_move", "(", "struct", ")", ":", "# Movable block.", "\n", "# The \"falling\" blocks are shrunk slightly and increased in mass to", "\n", "# ensure that it can fall easily through a gap in the platform blocks.", "\n", "          ", "name", "=", "\"movable_%d_%d\"", "%", "(", "i", ",", "j", ")", "\n", "self", ".", "movable_blocks", ".", "append", "(", "(", "name", ",", "struct", ")", ")", "\n", "falling", "=", "maze_env_utils", ".", "can_move_z", "(", "struct", ")", "\n", "spinning", "=", "maze_env_utils", ".", "can_spin", "(", "struct", ")", "\n", "x_offset", "=", "0.25", "*", "size_scaling", "if", "spinning", "else", "0.0", "\n", "y_offset", "=", "0.0", "\n", "shrink", "=", "0.1", "if", "spinning", "else", "0.99", "if", "falling", "else", "1.0", "\n", "height_shrink", "=", "0.1", "if", "spinning", "else", "1.0", "\n", "movable_body", "=", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"body\"", ",", "\n", "name", "=", "name", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", "+", "x_offset", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", "+", "y_offset", ",", "\n", "height_offset", "+", "\n", "height", "/", "2", "*", "size_scaling", "*", "height_shrink", ")", ",", "\n", ")", "\n", "ET", ".", "SubElement", "(", "\n", "movable_body", ",", "\"geom\"", ",", "\n", "name", "=", "\"block_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", "*", "shrink", ",", "\n", "0.5", "*", "size_scaling", "*", "shrink", ",", "\n", "height", "/", "2", "*", "size_scaling", "*", "height_shrink", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "mass", "=", "\"0.001\"", "if", "falling", "else", "\"0.0002\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.9 0.1 0.1 1\"", "\n", ")", "\n", "if", "maze_env_utils", ".", "can_move_x", "(", "struct", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "movable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"1 0 0\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"true\"", "if", "falling", "else", "\"false\"", ",", "\n", "range", "=", "\"%f %f\"", "%", "(", "-", "size_scaling", ",", "size_scaling", ")", ",", "\n", "margin", "=", "\"0.01\"", ",", "\n", "name", "=", "\"movable_x_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"slide\"", "\n", ")", "\n", "", "if", "maze_env_utils", ".", "can_move_y", "(", "struct", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "movable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"0 1 0\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"true\"", "if", "falling", "else", "\"false\"", ",", "\n", "range", "=", "\"%f %f\"", "%", "(", "-", "size_scaling", ",", "size_scaling", ")", ",", "\n", "margin", "=", "\"0.01\"", ",", "\n", "name", "=", "\"movable_y_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"slide\"", "\n", ")", "\n", "", "if", "maze_env_utils", ".", "can_move_z", "(", "struct", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "movable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"0 0 1\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"true\"", ",", "\n", "range", "=", "\"%f 0\"", "%", "(", "-", "height_offset", ")", ",", "\n", "margin", "=", "\"0.01\"", ",", "\n", "name", "=", "\"movable_z_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"slide\"", "\n", ")", "\n", "", "if", "maze_env_utils", ".", "can_spin", "(", "struct", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "movable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"0 0 1\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"false\"", ",", "\n", "name", "=", "\"spinable_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"ball\"", "\n", ")", "\n", "\n", "", "", "", "", "torso", "=", "tree", ".", "find", "(", "\".//body[@name='torso']\"", ")", "\n", "geoms", "=", "torso", ".", "findall", "(", "\".//geom\"", ")", "\n", "for", "geom", "in", "geoms", ":", "\n", "      ", "if", "'name'", "not", "in", "geom", ".", "attrib", ":", "\n", "        ", "raise", "Exception", "(", "\"Every geom of the torso must have a name \"", "\n", "\"defined\"", ")", "\n", "\n", "", "", "_", ",", "file_path", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.xml'", ",", "text", "=", "True", ")", "\n", "tree", ".", "write", "(", "file_path", ")", "\n", "\n", "self", ".", "wrapped_env", "=", "model_cls", "(", "*", "args", ",", "file_path", "=", "file_path", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_ori": [[238, 240], ["maze_env.MazeEnv.wrapped_env.get_ori"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_ori"], ["", "def", "get_ori", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_env", ".", "get_ori", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_top_down_view": [[241, 324], ["numpy.zeros_like", "maze_env.MazeEnv.get_ori", "range", "maze_env.MazeEnv.get_top_down_view.valid"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_ori"], ["", "def", "get_top_down_view", "(", "self", ")", ":", "\n", "    ", "self", ".", "_view", "=", "np", ".", "zeros_like", "(", "self", ".", "_view", ")", "\n", "\n", "def", "valid", "(", "row", ",", "col", ")", ":", "\n", "      ", "return", "self", ".", "_view", ".", "shape", "[", "0", "]", ">", "row", ">=", "0", "and", "self", ".", "_view", ".", "shape", "[", "1", "]", ">", "col", ">=", "0", "\n", "\n", "", "def", "update_view", "(", "x", ",", "y", ",", "d", ",", "row", "=", "None", ",", "col", "=", "None", ")", ":", "\n", "      ", "if", "row", "is", "None", "or", "col", "is", "None", ":", "\n", "        ", "x", "=", "x", "-", "self", ".", "_robot_x", "\n", "y", "=", "y", "-", "self", ".", "_robot_y", "\n", "th", "=", "self", ".", "_robot_ori", "\n", "\n", "row", ",", "col", "=", "self", ".", "_xy_to_rowcol", "(", "x", ",", "y", ")", "\n", "update_view", "(", "x", ",", "y", ",", "d", ",", "row", "=", "row", ",", "col", "=", "col", ")", "\n", "return", "\n", "\n", "", "row", ",", "row_frac", ",", "col", ",", "col_frac", "=", "int", "(", "row", ")", ",", "row", "%", "1", ",", "int", "(", "col", ")", ",", "col", "%", "1", "\n", "if", "row_frac", "<", "0", ":", "\n", "        ", "row_frac", "+=", "1", "\n", "", "if", "col_frac", "<", "0", ":", "\n", "        ", "col_frac", "+=", "1", "\n", "\n", "", "if", "valid", "(", "row", ",", "col", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", ",", "col", ",", "d", "]", "+=", "(", "\n", "(", "min", "(", "1.", ",", "row_frac", "+", "0.5", ")", "-", "max", "(", "0.", ",", "row_frac", "-", "0.5", ")", ")", "*", "\n", "(", "min", "(", "1.", ",", "col_frac", "+", "0.5", ")", "-", "max", "(", "0.", ",", "col_frac", "-", "0.5", ")", ")", ")", "\n", "", "if", "valid", "(", "row", "-", "1", ",", "col", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", "-", "1", ",", "col", ",", "d", "]", "+=", "(", "\n", "(", "max", "(", "0.", ",", "0.5", "-", "row_frac", ")", ")", "*", "\n", "(", "min", "(", "1.", ",", "col_frac", "+", "0.5", ")", "-", "max", "(", "0.", ",", "col_frac", "-", "0.5", ")", ")", ")", "\n", "", "if", "valid", "(", "row", "+", "1", ",", "col", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", "+", "1", ",", "col", ",", "d", "]", "+=", "(", "\n", "(", "max", "(", "0.", ",", "row_frac", "-", "0.5", ")", ")", "*", "\n", "(", "min", "(", "1.", ",", "col_frac", "+", "0.5", ")", "-", "max", "(", "0.", ",", "col_frac", "-", "0.5", ")", ")", ")", "\n", "", "if", "valid", "(", "row", ",", "col", "-", "1", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", ",", "col", "-", "1", ",", "d", "]", "+=", "(", "\n", "(", "min", "(", "1.", ",", "row_frac", "+", "0.5", ")", "-", "max", "(", "0.", ",", "row_frac", "-", "0.5", ")", ")", "*", "\n", "(", "max", "(", "0.", ",", "0.5", "-", "col_frac", ")", ")", ")", "\n", "", "if", "valid", "(", "row", ",", "col", "+", "1", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", ",", "col", "+", "1", ",", "d", "]", "+=", "(", "\n", "(", "min", "(", "1.", ",", "row_frac", "+", "0.5", ")", "-", "max", "(", "0.", ",", "row_frac", "-", "0.5", ")", ")", "*", "\n", "(", "max", "(", "0.", ",", "col_frac", "-", "0.5", ")", ")", ")", "\n", "", "if", "valid", "(", "row", "-", "1", ",", "col", "-", "1", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", "-", "1", ",", "col", "-", "1", ",", "d", "]", "+=", "(", "\n", "(", "max", "(", "0.", ",", "0.5", "-", "row_frac", ")", ")", "*", "max", "(", "0.", ",", "0.5", "-", "col_frac", ")", ")", "\n", "", "if", "valid", "(", "row", "-", "1", ",", "col", "+", "1", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", "-", "1", ",", "col", "+", "1", ",", "d", "]", "+=", "(", "\n", "(", "max", "(", "0.", ",", "0.5", "-", "row_frac", ")", ")", "*", "max", "(", "0.", ",", "col_frac", "-", "0.5", ")", ")", "\n", "", "if", "valid", "(", "row", "+", "1", ",", "col", "+", "1", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", "+", "1", ",", "col", "+", "1", ",", "d", "]", "+=", "(", "\n", "(", "max", "(", "0.", ",", "row_frac", "-", "0.5", ")", ")", "*", "max", "(", "0.", ",", "col_frac", "-", "0.5", ")", ")", "\n", "", "if", "valid", "(", "row", "+", "1", ",", "col", "-", "1", ")", ":", "\n", "        ", "self", ".", "_view", "[", "row", "+", "1", ",", "col", "-", "1", ",", "d", "]", "+=", "(", "\n", "(", "max", "(", "0.", ",", "row_frac", "-", "0.5", ")", ")", "*", "max", "(", "0.", ",", "0.5", "-", "col_frac", ")", ")", "\n", "\n", "# Draw ant.", "\n", "", "", "robot_x", ",", "robot_y", "=", "self", ".", "wrapped_env", ".", "get_body_com", "(", "\"torso\"", ")", "[", ":", "2", "]", "\n", "self", ".", "_robot_x", "=", "robot_x", "\n", "self", ".", "_robot_y", "=", "robot_y", "\n", "self", ".", "_robot_ori", "=", "self", ".", "get_ori", "(", ")", "\n", "\n", "structure", "=", "self", ".", "MAZE_STRUCTURE", "\n", "size_scaling", "=", "self", ".", "MAZE_SIZE_SCALING", "\n", "height", "=", "self", ".", "MAZE_HEIGHT", "\n", "\n", "# Draw immovable blocks and chasms.", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "1", ":", "# Wall.", "\n", "          ", "update_view", "(", "j", "*", "size_scaling", "-", "self", ".", "_init_torso_x", ",", "\n", "i", "*", "size_scaling", "-", "self", ".", "_init_torso_y", ",", "\n", "0", ")", "\n", "", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "-", "1", ":", "# Chasm.", "\n", "          ", "update_view", "(", "j", "*", "size_scaling", "-", "self", ".", "_init_torso_x", ",", "\n", "i", "*", "size_scaling", "-", "self", ".", "_init_torso_y", ",", "\n", "1", ")", "\n", "\n", "# Draw movable blocks.", "\n", "", "", "", "for", "block_name", ",", "block_type", "in", "self", ".", "movable_blocks", ":", "\n", "      ", "block_x", ",", "block_y", "=", "self", ".", "wrapped_env", ".", "get_body_com", "(", "block_name", ")", "[", ":", "2", "]", "\n", "update_view", "(", "block_x", ",", "block_y", ",", "2", ")", "\n", "\n", "", "return", "self", ".", "_view", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_range_sensor_obs": [[325, 408], ["maze_env.MazeEnv.get_ori", "range", "numpy.zeros", "range", "maze_env.MazeEnv.wrapped_env.get_body_com", "len", "range", "len", "maze_env.MazeEnv.wrapped_env.get_body_com", "envs.sibrivalry.ant_maze.maze_env_utils.ray_segment_intersect", "len", "segments.append", "ray_segments.append", "sorted", "segments.append", "dict", "dict", "dict", "envs.sibrivalry.ant_maze.maze_env_utils.can_move", "envs.sibrivalry.ant_maze.maze_env_utils.point_distance"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_ori", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.ray_segment_intersect", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.point_distance"], ["", "def", "get_range_sensor_obs", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns egocentric range sensor observations of maze.\"\"\"", "\n", "robot_x", ",", "robot_y", ",", "robot_z", "=", "self", ".", "wrapped_env", ".", "get_body_com", "(", "\"torso\"", ")", "[", ":", "3", "]", "\n", "ori", "=", "self", ".", "get_ori", "(", ")", "\n", "\n", "structure", "=", "self", ".", "MAZE_STRUCTURE", "\n", "size_scaling", "=", "self", ".", "MAZE_SIZE_SCALING", "\n", "height", "=", "self", ".", "MAZE_HEIGHT", "\n", "\n", "segments", "=", "[", "]", "\n", "# Get line segments (corresponding to outer boundary) of each immovable", "\n", "# block or drop-off.", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "structure", "[", "i", "]", "[", "j", "]", "in", "[", "1", ",", "-", "1", "]", ":", "# There's a wall or drop-off.", "\n", "          ", "cx", "=", "j", "*", "size_scaling", "-", "self", ".", "_init_torso_x", "\n", "cy", "=", "i", "*", "size_scaling", "-", "self", ".", "_init_torso_y", "\n", "x1", "=", "cx", "-", "0.5", "*", "size_scaling", "\n", "x2", "=", "cx", "+", "0.5", "*", "size_scaling", "\n", "y1", "=", "cy", "-", "0.5", "*", "size_scaling", "\n", "y2", "=", "cy", "+", "0.5", "*", "size_scaling", "\n", "struct_segments", "=", "[", "\n", "(", "(", "x1", ",", "y1", ")", ",", "(", "x2", ",", "y1", ")", ")", ",", "\n", "(", "(", "x2", ",", "y1", ")", ",", "(", "x2", ",", "y2", ")", ")", ",", "\n", "(", "(", "x2", ",", "y2", ")", ",", "(", "x1", ",", "y2", ")", ")", ",", "\n", "(", "(", "x1", ",", "y2", ")", ",", "(", "x1", ",", "y1", ")", ")", ",", "\n", "]", "\n", "for", "seg", "in", "struct_segments", ":", "\n", "            ", "segments", ".", "append", "(", "dict", "(", "\n", "segment", "=", "seg", ",", "\n", "type", "=", "structure", "[", "i", "]", "[", "j", "]", ",", "\n", ")", ")", "\n", "# Get line segments (corresponding to outer boundary) of each movable", "\n", "# block within the agent's z-view.", "\n", "", "", "", "", "for", "block_name", ",", "block_type", "in", "self", ".", "movable_blocks", ":", "\n", "      ", "block_x", ",", "block_y", ",", "block_z", "=", "self", ".", "wrapped_env", ".", "get_body_com", "(", "block_name", ")", "[", ":", "3", "]", "\n", "if", "(", "block_z", "+", "height", "*", "size_scaling", "/", "2", ">=", "robot_z", "and", "\n", "robot_z", ">=", "block_z", "-", "height", "*", "size_scaling", "/", "2", ")", ":", "# Block in view.", "\n", "        ", "x1", "=", "block_x", "-", "0.5", "*", "size_scaling", "\n", "x2", "=", "block_x", "+", "0.5", "*", "size_scaling", "\n", "y1", "=", "block_y", "-", "0.5", "*", "size_scaling", "\n", "y2", "=", "block_y", "+", "0.5", "*", "size_scaling", "\n", "struct_segments", "=", "[", "\n", "(", "(", "x1", ",", "y1", ")", ",", "(", "x2", ",", "y1", ")", ")", ",", "\n", "(", "(", "x2", ",", "y1", ")", ",", "(", "x2", ",", "y2", ")", ")", ",", "\n", "(", "(", "x2", ",", "y2", ")", ",", "(", "x1", ",", "y2", ")", ")", ",", "\n", "(", "(", "x1", ",", "y2", ")", ",", "(", "x1", ",", "y1", ")", ")", ",", "\n", "]", "\n", "for", "seg", "in", "struct_segments", ":", "\n", "          ", "segments", ".", "append", "(", "dict", "(", "\n", "segment", "=", "seg", ",", "\n", "type", "=", "block_type", ",", "\n", ")", ")", "\n", "\n", "", "", "", "sensor_readings", "=", "np", ".", "zeros", "(", "(", "self", ".", "_n_bins", ",", "3", ")", ")", "# 3 for wall, drop-off, block", "\n", "for", "ray_idx", "in", "range", "(", "self", ".", "_n_bins", ")", ":", "\n", "      ", "ray_ori", "=", "(", "ori", "-", "self", ".", "_sensor_span", "*", "0.5", "+", "\n", "(", "2", "*", "ray_idx", "+", "1.0", ")", "/", "(", "2", "*", "self", ".", "_n_bins", ")", "*", "self", ".", "_sensor_span", ")", "\n", "ray_segments", "=", "[", "]", "\n", "# Get all segments that intersect with ray.", "\n", "for", "seg", "in", "segments", ":", "\n", "        ", "p", "=", "maze_env_utils", ".", "ray_segment_intersect", "(", "\n", "ray", "=", "(", "(", "robot_x", ",", "robot_y", ")", ",", "ray_ori", ")", ",", "\n", "segment", "=", "seg", "[", "\"segment\"", "]", ")", "\n", "if", "p", "is", "not", "None", ":", "\n", "          ", "ray_segments", ".", "append", "(", "dict", "(", "\n", "segment", "=", "seg", "[", "\"segment\"", "]", ",", "\n", "type", "=", "seg", "[", "\"type\"", "]", ",", "\n", "ray_ori", "=", "ray_ori", ",", "\n", "distance", "=", "maze_env_utils", ".", "point_distance", "(", "p", ",", "(", "robot_x", ",", "robot_y", ")", ")", ",", "\n", ")", ")", "\n", "", "", "if", "len", "(", "ray_segments", ")", ">", "0", ":", "\n", "# Find out which segment is intersected first.", "\n", "        ", "first_seg", "=", "sorted", "(", "ray_segments", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"distance\"", "]", ")", "[", "0", "]", "\n", "seg_type", "=", "first_seg", "[", "\"type\"", "]", "\n", "idx", "=", "(", "0", "if", "seg_type", "==", "1", "else", "# Wall.", "\n", "1", "if", "seg_type", "==", "-", "1", "else", "# Drop-off.", "\n", "2", "if", "maze_env_utils", ".", "can_move", "(", "seg_type", ")", "else", "# Block.", "\n", "None", ")", "\n", "if", "first_seg", "[", "\"distance\"", "]", "<=", "self", ".", "_sensor_range", ":", "\n", "          ", "sensor_readings", "[", "ray_idx", "]", "[", "idx", "]", "=", "(", "self", ".", "_sensor_range", "-", "first_seg", "[", "\"distance\"", "]", ")", "/", "self", ".", "_sensor_range", "\n", "\n", "", "", "", "return", "sensor_readings", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs": [[409, 428], ["maze_env.MazeEnv.wrapped_env._get_obs", "maze_env.MazeEnv.get_range_sensor_obs", "numpy.concatenate", "numpy.concatenate", "additional_obs.append", "maze_env.MazeEnv.get_top_down_view", "maze_env.MazeEnv.wrapped_env.get_body_com"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_range_sensor_obs", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.get_top_down_view"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "wrapped_obs", "=", "self", ".", "wrapped_env", ".", "_get_obs", "(", ")", "\n", "if", "self", ".", "_top_down_view", ":", "\n", "      ", "view", "=", "[", "self", ".", "get_top_down_view", "(", ")", ".", "flat", "]", "\n", "", "else", ":", "\n", "      ", "view", "=", "[", "]", "\n", "\n", "", "if", "self", ".", "_observe_blocks", ":", "\n", "      ", "additional_obs", "=", "[", "]", "\n", "for", "block_name", ",", "block_type", "in", "self", ".", "movable_blocks", ":", "\n", "        ", "additional_obs", ".", "append", "(", "self", ".", "wrapped_env", ".", "get_body_com", "(", "block_name", ")", ")", "\n", "", "wrapped_obs", "=", "np", ".", "concatenate", "(", "[", "wrapped_obs", "[", ":", "3", "]", "]", "+", "additional_obs", "+", "\n", "[", "wrapped_obs", "[", "3", ":", "]", "]", ")", "\n", "\n", "", "range_sensor_obs", "=", "self", ".", "get_range_sensor_obs", "(", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "[", "wrapped_obs", ",", "\n", "range_sensor_obs", ".", "flat", "]", "+", "\n", "view", "+", "[", "[", "self", ".", "t", "*", "0.001", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.reset": [[429, 437], ["maze_env.MazeEnv.wrapped_env.reset", "maze_env.MazeEnv._get_obs", "len", "random.choice", "maze_env.MazeEnv.wrapped_env.set_xy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.set_xy"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "t", "=", "0", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "self", ".", "wrapped_env", ".", "reset", "(", ")", "\n", "if", "len", "(", "self", ".", "_init_positions", ")", ">", "1", ":", "\n", "      ", "xy", "=", "random", ".", "choice", "(", "self", ".", "_init_positions", ")", "\n", "self", ".", "wrapped_env", ".", "set_xy", "(", "xy", ")", "\n", "", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.viewer": [[438, 441], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "viewer", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_env", ".", "viewer", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.render": [[442, 444], ["maze_env.MazeEnv.wrapped_env.render"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_env", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.observation_space": [[445, 451], ["gym.spaces.Box", "maze_env.MazeEnv._get_obs", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "    ", "shape", "=", "self", ".", "_get_obs", "(", ")", ".", "shape", "\n", "high", "=", "np", ".", "inf", "*", "np", ".", "ones", "(", "shape", ")", "\n", "low", "=", "-", "high", "\n", "return", "gym", ".", "spaces", ".", "Box", "(", "low", ",", "high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.action_space": [[452, 455], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_env", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._find_robot": [[456, 464], ["range", "len", "range", "len"], "methods", ["None"], ["", "def", "_find_robot", "(", "self", ")", ":", "\n", "    ", "structure", "=", "self", ".", "MAZE_STRUCTURE", "\n", "size_scaling", "=", "self", ".", "MAZE_SIZE_SCALING", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "'r'", ":", "\n", "          ", "return", "j", "*", "size_scaling", ",", "i", "*", "size_scaling", "\n", "", "", "", "assert", "False", ",", "'No robot in maze specification.'", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._find_all_robots": [[465, 474], ["range", "len", "range", "len", "coords.append"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_find_all_robots", "(", "self", ")", ":", "\n", "    ", "structure", "=", "self", ".", "MAZE_STRUCTURE", "\n", "size_scaling", "=", "self", ".", "MAZE_SIZE_SCALING", "\n", "coords", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "'r'", ":", "\n", "          ", "coords", ".", "append", "(", "(", "j", "*", "size_scaling", ",", "i", "*", "size_scaling", ")", ")", "\n", "", "", "", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._is_in_collision": [[475, 489], ["range", "len", "range", "len"], "methods", ["None"], ["", "def", "_is_in_collision", "(", "self", ",", "pos", ")", ":", "\n", "    ", "x", ",", "y", "=", "pos", "\n", "structure", "=", "self", ".", "MAZE_STRUCTURE", "\n", "size_scaling", "=", "self", ".", "MAZE_SIZE_SCALING", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "1", ":", "\n", "          ", "minx", "=", "j", "*", "size_scaling", "-", "size_scaling", "*", "0.5", "-", "self", ".", "_init_torso_x", "\n", "maxx", "=", "j", "*", "size_scaling", "+", "size_scaling", "*", "0.5", "-", "self", ".", "_init_torso_x", "\n", "miny", "=", "i", "*", "size_scaling", "-", "size_scaling", "*", "0.5", "-", "self", ".", "_init_torso_y", "\n", "maxy", "=", "i", "*", "size_scaling", "+", "size_scaling", "*", "0.5", "-", "self", ".", "_init_torso_y", "\n", "if", "minx", "<=", "x", "<=", "maxx", "and", "miny", "<=", "y", "<=", "maxy", ":", "\n", "            ", "return", "True", "\n", "", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv.step": [[490, 503], ["maze_env.MazeEnv._get_obs", "maze_env.MazeEnv.wrapped_env.get_xy", "maze_env.MazeEnv.wrapped_env.step", "maze_env.MazeEnv.wrapped_env.get_xy", "maze_env.MazeEnv._is_in_collision", "maze_env.MazeEnv.wrapped_env.step", "maze_env.MazeEnv.wrapped_env.set_xy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.get_xy", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.get_xy", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env.MazeEnv._is_in_collision", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant.AntEnv.set_xy"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "self", ".", "t", "+=", "1", "\n", "if", "self", ".", "_manual_collision", ":", "\n", "      ", "old_pos", "=", "self", ".", "wrapped_env", ".", "get_xy", "(", ")", "\n", "inner_next_obs", ",", "inner_reward", ",", "done", ",", "info", "=", "self", ".", "wrapped_env", ".", "step", "(", "action", ")", "\n", "new_pos", "=", "self", ".", "wrapped_env", ".", "get_xy", "(", ")", "\n", "if", "self", ".", "_is_in_collision", "(", "new_pos", ")", ":", "\n", "        ", "self", ".", "wrapped_env", ".", "set_xy", "(", "old_pos", ")", "\n", "", "", "else", ":", "\n", "      ", "inner_next_obs", ",", "inner_reward", ",", "done", ",", "info", "=", "self", ".", "wrapped_env", ".", "step", "(", "action", ")", "\n", "", "next_obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "done", "=", "False", "\n", "return", "next_obs", ",", "inner_reward", ",", "done", ",", "info", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.__init__.AntMazeEnv.__init__": [[15, 70], ["variant.split", "envs.sibrivalry.ant_maze.create_maze_env.create_maze_env", "__init__.AntMazeEnv.seed", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Dict", "numpy.sqrt", "len", "len", "__init__.AntMazeEnv.np_random.uniform().astype", "numpy.array", "numpy.array", "ValueError", "numpy.array", "__init__.AntMazeEnv.np_random.uniform"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.create_maze_env.create_maze_env", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], []], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.__init__.AntMazeEnv.seed": [[71, 75], ["gym.utils.seeding.np_random", "__init__.AntMazeEnv.maze.wrapped_env.seed"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], []], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.__init__.AntMazeEnv.sample_goal": [[66, 69], ["__init__.AntMazeEnv.np_random.choice", "GOAL_GRID[].astype", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.__init__.AntMazeEnv.step": [[78, 101], ["__init__.AntMazeEnv.maze.step", "next_state.astype.astype.astype", "__init__.AntMazeEnv.compute_reward", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], []], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.__init__.AntMazeEnv.reset": [[102, 115], ["__init__.AntMazeEnv.maze.wrapped_env.seed", "__init__.AntMazeEnv.maze.reset().astype", "__init__.AntMazeEnv.maze.wrapped_env.seed", "__init__.AntMazeEnv.sample_goal", "__init__.AntMazeEnv.np_random.randint", "__init__.AntMazeEnv.np_random.randint", "__init__.AntMazeEnv.maze.reset", "numpy.iinfo", "numpy.iinfo"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], []], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.__init__.AntMazeEnv.render": [[117, 119], ["__init__.AntMazeEnv.maze.render"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render"], []], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.__init__.AntMazeEnv.compute_reward": [[120, 129], ["numpy.linalg.norm", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_x": [[32, 35], ["None"], "function", ["None"], ["", "def", "can_move_x", "(", "movable", ")", ":", "\n", "  ", "return", "movable", "in", "[", "Move", ".", "X", ",", "Move", ".", "XY", ",", "Move", ".", "XZ", ",", "Move", ".", "XYZ", ",", "\n", "Move", ".", "SpinXY", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_y": [[37, 40], ["None"], "function", ["None"], ["", "def", "can_move_y", "(", "movable", ")", ":", "\n", "  ", "return", "movable", "in", "[", "Move", ".", "Y", ",", "Move", ".", "XY", ",", "Move", ".", "YZ", ",", "Move", ".", "XYZ", ",", "\n", "Move", ".", "SpinXY", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_z": [[42, 44], ["None"], "function", ["None"], ["", "def", "can_move_z", "(", "movable", ")", ":", "\n", "  ", "return", "movable", "in", "[", "Move", ".", "Z", ",", "Move", ".", "XZ", ",", "Move", ".", "YZ", ",", "Move", ".", "XYZ", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_spin": [[46, 48], ["None"], "function", ["None"], ["", "def", "can_spin", "(", "movable", ")", ":", "\n", "  ", "return", "movable", "in", "[", "Move", ".", "SpinXY", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move": [[50, 52], ["maze_env_utils.can_move_x", "maze_env_utils.can_move_y", "maze_env_utils.can_move_z"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_x", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_y", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.can_move_z"], ["", "def", "can_move", "(", "movable", ")", ":", "\n", "  ", "return", "can_move_x", "(", "movable", ")", "or", "can_move_y", "(", "movable", ")", "or", "can_move_z", "(", "movable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.construct_maze": [[54, 102], ["NotImplementedError"], "function", ["None"], ["", "def", "construct_maze", "(", "maze_id", "=", "'Maze'", ")", ":", "\n", "  ", "if", "maze_id", "==", "'Maze'", ":", "\n", "    ", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "'r'", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "elif", "maze_id", "==", "'Push'", ":", "\n", "    ", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "'r'", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "Move", ".", "XY", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "0", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "elif", "maze_id", "==", "'Fall'", ":", "\n", "    ", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "'r'", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "Move", ".", "YZ", ",", "1", "]", ",", "\n", "[", "1", ",", "-", "1", ",", "-", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "elif", "maze_id", "==", "'Block'", ":", "\n", "    ", "O", "=", "'r'", "\n", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "O", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "elif", "maze_id", "==", "'BlockMaze'", ":", "\n", "    ", "O", "=", "'r'", "\n", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "O", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "'The provided MazeId %s is not recognized'", "%", "maze_id", ")", "\n", "\n", "", "return", "structure", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.line_intersect": [[104, 142], ["math.fabs"], "function", ["None"], ["", "def", "line_intersect", "(", "pt1", ",", "pt2", ",", "ptA", ",", "ptB", ")", ":", "\n", "  ", "\"\"\"\n  Taken from https://www.cs.hmc.edu/ACM/lectures/intersections.html\n  this returns the intersection of Line(pt1,pt2) and Line(ptA,ptB)\n  \"\"\"", "\n", "\n", "DET_TOLERANCE", "=", "0.00000001", "\n", "\n", "# the first line is pt1 + r*(pt2-pt1)", "\n", "# in component form:", "\n", "x1", ",", "y1", "=", "pt1", "\n", "x2", ",", "y2", "=", "pt2", "\n", "dx1", "=", "x2", "-", "x1", "\n", "dy1", "=", "y2", "-", "y1", "\n", "\n", "# the second line is ptA + s*(ptB-ptA)", "\n", "x", ",", "y", "=", "ptA", "\n", "xB", ",", "yB", "=", "ptB", "\n", "dx", "=", "xB", "-", "x", "\n", "dy", "=", "yB", "-", "y", "\n", "\n", "DET", "=", "(", "-", "dx1", "*", "dy", "+", "dy1", "*", "dx", ")", "\n", "\n", "if", "math", ".", "fabs", "(", "DET", ")", "<", "DET_TOLERANCE", ":", "return", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ")", "\n", "\n", "# now, the determinant should be OK", "\n", "DETinv", "=", "1.0", "/", "DET", "\n", "\n", "# find the scalar amount along the \"self\" segment", "\n", "r", "=", "DETinv", "*", "(", "-", "dy", "*", "(", "x", "-", "x1", ")", "+", "dx", "*", "(", "y", "-", "y1", ")", ")", "\n", "\n", "# find the scalar amount along the input line", "\n", "s", "=", "DETinv", "*", "(", "-", "dy1", "*", "(", "x", "-", "x1", ")", "+", "dx1", "*", "(", "y", "-", "y1", ")", ")", "\n", "\n", "# return the average of the two descriptions", "\n", "xi", "=", "(", "x1", "+", "r", "*", "dx1", "+", "x", "+", "s", "*", "dx", ")", "/", "2.0", "\n", "yi", "=", "(", "y1", "+", "r", "*", "dy1", "+", "y", "+", "s", "*", "dy", ")", "/", "2.0", "\n", "return", "(", "xi", ",", "yi", ",", "1", ",", "r", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.ray_segment_intersect": [[144, 158], ["maze_env_utils.line_intersect", "math.cos", "math.sin"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.line_intersect"], ["", "def", "ray_segment_intersect", "(", "ray", ",", "segment", ")", ":", "\n", "  ", "\"\"\"\n  Check if the ray originated from (x, y) with direction theta intersects the line segment (x1, y1) -- (x2, y2),\n  and return the intersection point if there is one\n  \"\"\"", "\n", "(", "x", ",", "y", ")", ",", "theta", "=", "ray", "\n", "# (x1, y1), (x2, y2) = segment", "\n", "pt1", "=", "(", "x", ",", "y", ")", "\n", "len", "=", "1", "\n", "pt2", "=", "(", "x", "+", "len", "*", "math", ".", "cos", "(", "theta", ")", ",", "y", "+", "len", "*", "math", ".", "sin", "(", "theta", ")", ")", "\n", "xo", ",", "yo", ",", "valid", ",", "r", ",", "s", "=", "line_intersect", "(", "pt1", ",", "pt2", ",", "*", "segment", ")", "\n", "if", "valid", "and", "r", ">=", "0", "and", "0", "<=", "s", "<=", "1", ":", "\n", "    ", "return", "(", "xo", ",", "yo", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.maze_env_utils.point_distance": [[160, 164], ["None"], "function", ["None"], ["", "def", "point_distance", "(", "p1", ",", "p2", ")", ":", "\n", "  ", "x1", ",", "y1", "=", "p1", "\n", "x2", ",", "y2", "=", "p2", "\n", "return", "(", "(", "x1", "-", "x2", ")", "**", "2", "+", "(", "y1", "-", "y2", ")", "**", "2", ")", "**", "0.5", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.__init__": [[13, 31], ["bool", "envs.sibrivalry.ant_maze.create_maze_env.create_maze_env", "dict", "my_maze.Env.reset", "my_maze.Env.maze.wrapped_env.seed"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.create_maze_env.create_maze_env", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["    ", "def", "__init__", "(", "self", ",", "n", "=", "None", ",", "maze_type", "=", "None", ",", "hardmode", "=", "False", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "maze_type", "=", "maze_type", "\n", "self", ".", "hardmode", "=", "bool", "(", "hardmode", ")", "\n", "\n", "self", ".", "maze", "=", "create_maze_env", "(", "maze_type", ")", "\n", "\n", "self", ".", "dist_threshold", "=", "1.0", "\n", "\n", "if", "self", ".", "maze_type", "==", "'AntMaze'", ":", "\n", "            ", "self", ".", "_dscale", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "_state", "=", "dict", "(", "state", "=", "None", ",", "goal", "=", "None", ",", "n", "=", "None", ",", "done", "=", "None", ")", "\n", "self", ".", "_seed", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "[", "0", "]", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.state_size": [[32, 35], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "30", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.goal_size": [[36, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "goal_size", "(", "self", ")", ":", "\n", "        ", "return", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.action_size": [[40, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_size", "(", "self", ")", ":", "\n", "        ", "return", "8", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.to_tensor": [[44, 50], ["isinstance", "torch.from_numpy", "torch.FloatTensor", "x.astype"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "to_tensor", "(", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "torch", ".", "from_numpy", "(", "x", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "FloatTensor", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.to_coords": [[51, 58], ["isinstance", "isinstance", "x.data.numpy.data.numpy.data.numpy", "float", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "@", "staticmethod", "\n", "def", "to_coords", "(", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "return", "x", "[", "0", "]", ",", "x", "[", "1", "]", "\n", "", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "x", "=", "x", ".", "data", ".", "numpy", "(", ")", "\n", "", "return", "float", "(", "x", "[", "0", "]", ")", ",", "float", "(", "x", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.action_range": [[59, 62], ["my_maze.Env.to_tensor"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor"], ["", "@", "property", "\n", "def", "action_range", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "to_tensor", "(", "self", ".", "maze", ".", "action_space", ".", "high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.state": [[63, 66], ["my_maze.Env._state[].view().detach", "my_maze.Env._state[].view"], "methods", ["None"], ["", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_state", "[", "'state'", "]", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.goal": [[67, 70], ["my_maze.Env._state[].view().detach", "my_maze.Env._state[].view"], "methods", ["None"], ["", "@", "property", "\n", "def", "goal", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_state", "[", "'goal'", "]", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.achieved": [[71, 74], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "achieved", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "goal", "if", "self", ".", "is_success", "else", "self", ".", "state", "[", ":", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.is_done": [[75, 78], ["bool"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_done", "(", "self", ")", ":", "\n", "        ", "return", "bool", "(", "self", ".", "_state", "[", "'done'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.is_success": [[79, 83], ["my_maze.Env.dist"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["", "@", "property", "\n", "def", "is_success", "(", "self", ")", ":", "\n", "        ", "d", "=", "self", ".", "dist", "(", "self", ".", "goal", ",", "self", ".", "state", ")", "\n", "return", "d", "<=", "self", ".", "dist_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.next_phase_reset": [[84, 87], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "next_phase_reset", "(", "self", ")", ":", "\n", "        ", "return", "{", "'state'", ":", "self", ".", "_seed", ",", "'goal'", ":", "self", ".", "achieved", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.sibling_reset": [[88, 91], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sibling_reset", "(", "self", ")", ":", "\n", "        ", "return", "{", "'state'", ":", "self", ".", "_seed", ",", "'goal'", ":", "self", ".", "goal", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.dist": [[92, 95], ["torch.sqrt", "torch.sum", "torch.pow"], "methods", ["None"], ["", "def", "dist", "(", "self", ",", "goal", ",", "outcome", ")", ":", "\n", "# return torch.sum(torch.abs(goal - outcome))", "\n", "        ", "return", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "torch", ".", "pow", "(", "goal", "[", ":", "2", "]", "-", "outcome", "[", ":", "2", "]", ",", "2", ")", ")", ")", "/", "self", ".", "_dscale", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.sample_goal": [[96, 123], ["numpy.random.uniform", "numpy.random.uniform", "my_maze.Env.to_tensor", "numpy.array().astype", "my_maze.Env.to_tensor", "numpy.random.uniform", "numpy.random.uniform", "numpy.array().astype", "my_maze.Env.dist", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["", "def", "sample_goal", "(", "self", ",", "s_xy", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "maze_type", "==", "'AntMaze'", ":", "\n", "            ", "if", "self", ".", "hardmode", ":", "\n", "                ", "g_x", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "3.5", ",", "high", "=", "3.5", ")", "\n", "g_y", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "12.5", ",", "high", "=", "19.5", ")", "\n", "g", "=", "self", ".", "to_tensor", "(", "np", ".", "array", "(", "[", "g_x", ",", "g_y", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "                ", "g_x", ",", "g_y", "=", "0.0", ",", "0.0", "\n", "outer_valid", "=", "False", "\n", "while", "not", "outer_valid", ":", "\n", "                    ", "valid", "=", "False", "\n", "while", "not", "valid", ":", "\n", "                        ", "g_x", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "3.5", ",", "high", "=", "19.5", ")", "\n", "g_y", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "3.5", ",", "high", "=", "19.5", ")", "\n", "if", "g_x", ">", "13", ":", "\n", "                            ", "valid", "=", "True", "\n", "", "elif", "g_y", "<", "3.5", "or", "g_y", ">", "12.5", ":", "\n", "                            ", "valid", "=", "True", "\n", "", "", "g", "=", "self", ".", "to_tensor", "(", "np", ".", "array", "(", "[", "g_x", ",", "g_y", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "if", "s_xy", "is", "None", ":", "\n", "                        ", "outer_valid", "=", "True", "\n", "", "else", ":", "\n", "                        ", "d", "=", "self", ".", "dist", "(", "g", ",", "s_xy", ")", "\n", "outer_valid", "=", "d", ">", "self", ".", "dist_threshold", "\n", "", "", "", "return", "g", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.reset": [[124, 142], ["my_maze.Env.to_tensor", "my_maze.Env.maze.wrapped_env.seed", "my_maze.Env.to_tensor", "my_maze.Env.maze.wrapped_env.seed", "my_maze.Env.sample_goal", "my_maze.Env.maze.wrapped_env.seed", "my_maze.Env.maze.reset", "my_maze.Env.maze.wrapped_env.seed", "my_maze.Env.maze.reset", "int"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "", "def", "reset", "(", "self", ",", "state", "=", "None", ",", "goal", "=", "None", ")", ":", "\n", "        ", "if", "state", "is", "None", ":", "\n", "            ", "self", ".", "_seed", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "[", "0", "]", "\n", "s", "=", "self", ".", "to_tensor", "(", "self", ".", "maze", ".", "reset", "(", ")", ")", "\n", "_", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_seed", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", "int", "(", "state", ")", ")", "[", "0", "]", "\n", "s", "=", "self", ".", "to_tensor", "(", "self", ".", "maze", ".", "reset", "(", ")", ")", "\n", "_", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "\n", "\n", "", "if", "goal", "is", "None", ":", "\n", "            ", "goal", "=", "self", ".", "sample_goal", "(", "s_xy", "=", "s", "[", ":", "2", "]", ")", "\n", "\n", "", "self", ".", "_state", "=", "{", "\n", "'state'", ":", "s", ",", "\n", "'goal'", ":", "goal", ",", "\n", "'n'", ":", "0", ",", "\n", "'done'", ":", "False", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.my_maze.Env.step": [[144, 149], ["my_maze.Env.maze.step", "my_maze.Env.to_tensor"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "next_state", ",", "_", ",", "_", ",", "_", "=", "self", ".", "maze", ".", "step", "(", "action", ")", "\n", "self", ".", "_state", "[", "'state'", "]", "=", "self", ".", "to_tensor", "(", "next_state", ")", "\n", "self", ".", "_state", "[", "'n'", "]", "+=", "1", "\n", "self", ".", "_state", "[", "'done'", "]", "=", "(", "self", ".", "_state", "[", "'n'", "]", ">=", "self", ".", "n", ")", "or", "self", ".", "is_success", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.__init__": [[16, 34], ["bool", "envs.sibrivalry.ant_maze.create_maze_env.create_maze_env", "dict", "ant_agents.Env.reset", "ant_agents.Env.maze.wrapped_env.seed"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.create_maze_env.create_maze_env", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "maze_type", ",", "hardmode", "=", "False", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "maze_type", "=", "maze_type", "\n", "self", ".", "hardmode", "=", "bool", "(", "hardmode", ")", "\n", "\n", "self", ".", "maze", "=", "create_maze_env", "(", "maze_type", ")", "\n", "\n", "self", ".", "dist_threshold", "=", "1.0", "\n", "\n", "if", "self", ".", "maze_type", "==", "'AntMaze'", ":", "\n", "            ", "self", ".", "_dscale", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "_state", "=", "dict", "(", "state", "=", "None", ",", "goal", "=", "None", ",", "n", "=", "None", ",", "done", "=", "None", ")", "\n", "self", ".", "_seed", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "[", "0", "]", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.to_tensor": [[35, 41], ["isinstance", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "x.astype"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "to_tensor", "(", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "torch", ".", "from_numpy", "(", "x", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "FloatTensor", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.to_coords": [[42, 49], ["isinstance", "isinstance", "x.data.numpy.data.numpy.data.numpy", "float", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "", "@", "staticmethod", "\n", "def", "to_coords", "(", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "return", "x", "[", "0", "]", ",", "x", "[", "1", "]", "\n", "", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "x", "=", "x", ".", "data", ".", "numpy", "(", ")", "\n", "", "return", "float", "(", "x", "[", "0", "]", ")", ",", "float", "(", "x", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.action_range": [[50, 53], ["ant_agents.Env.to_tensor"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor"], ["", "@", "property", "\n", "def", "action_range", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "to_tensor", "(", "self", ".", "maze", ".", "action_space", ".", "high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.state": [[54, 57], ["ant_agents.Env._state[].view().detach", "ant_agents.Env._state[].view"], "methods", ["None"], ["", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_state", "[", "'state'", "]", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.goal": [[58, 61], ["ant_agents.Env._state[].view().detach", "ant_agents.Env._state[].view"], "methods", ["None"], ["", "@", "property", "\n", "def", "goal", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_state", "[", "'goal'", "]", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.achieved": [[62, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "achieved", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "goal", "if", "self", ".", "is_success", "else", "self", ".", "state", "[", ":", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.is_done": [[66, 69], ["bool"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_done", "(", "self", ")", ":", "\n", "        ", "return", "bool", "(", "self", ".", "_state", "[", "'done'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.is_success": [[70, 74], ["ant_agents.Env.dist"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["", "@", "property", "\n", "def", "is_success", "(", "self", ")", ":", "\n", "        ", "d", "=", "self", ".", "dist", "(", "self", ".", "goal", ",", "self", ".", "state", ")", "\n", "return", "d", "<=", "self", ".", "dist_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.next_phase_reset": [[75, 78], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "next_phase_reset", "(", "self", ")", ":", "\n", "        ", "return", "{", "'state'", ":", "self", ".", "_seed", ",", "'goal'", ":", "self", ".", "achieved", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.dist": [[79, 82], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "dist", "(", "self", ",", "goal", ",", "outcome", ")", ":", "\n", "# return torch.sum(torch.abs(goal - outcome))", "\n", "        ", "return", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "torch", ".", "pow", "(", "goal", "[", ":", "2", "]", "-", "outcome", "[", ":", "2", "]", ",", "2", ")", ")", ")", "/", "self", ".", "_dscale", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.sample_goal": [[83, 102], ["numpy.array().astype", "ant_agents.Env.to_tensor", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor"], ["", "def", "sample_goal", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "maze_type", "==", "'AntMaze'", ":", "\n", "            ", "if", "self", ".", "hardmode", ":", "\n", "                ", "g_x", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "3.5", ",", "high", "=", "11.5", ")", "\n", "g_y", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "12.5", ",", "high", "=", "19.5", ")", "\n", "", "else", ":", "\n", "                ", "g_x", ",", "g_y", "=", "0.0", ",", "0.0", "\n", "valid", "=", "False", "\n", "while", "not", "valid", ":", "\n", "                    ", "g_x", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "3.5", ",", "high", "=", "19.5", ")", "\n", "g_y", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "3.5", ",", "high", "=", "19.5", ")", "\n", "if", "g_x", ">", "13", ":", "\n", "                        ", "valid", "=", "True", "\n", "", "elif", "g_y", "<", "3.5", "or", "g_y", ">", "12.5", ":", "\n", "                        ", "valid", "=", "True", "\n", "", "", "", "g", "=", "np", ".", "array", "(", "[", "g_x", ",", "g_y", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "self", ".", "to_tensor", "(", "g", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.reset": [[103, 121], ["ant_agents.Env.to_tensor", "ant_agents.Env.maze.wrapped_env.seed", "ant_agents.Env.to_tensor", "ant_agents.Env.maze.wrapped_env.seed", "ant_agents.Env.sample_goal", "ant_agents.Env.maze.wrapped_env.seed", "ant_agents.Env.maze.reset", "ant_agents.Env.maze.wrapped_env.seed", "ant_agents.Env.maze.reset", "int"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "", "def", "reset", "(", "self", ",", "state", "=", "None", ",", "goal", "=", "None", ")", ":", "\n", "        ", "if", "state", "is", "None", ":", "\n", "            ", "self", ".", "_seed", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "[", "0", "]", "\n", "s", "=", "self", ".", "to_tensor", "(", "self", ".", "maze", ".", "reset", "(", ")", ")", "\n", "_", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_seed", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", "int", "(", "state", ")", ")", "[", "0", "]", "\n", "s", "=", "self", ".", "to_tensor", "(", "self", ".", "maze", ".", "reset", "(", ")", ")", "\n", "_", "=", "self", ".", "maze", ".", "wrapped_env", ".", "seed", "(", ")", "\n", "\n", "", "if", "goal", "is", "None", ":", "\n", "            ", "goal", "=", "self", ".", "sample_goal", "(", ")", "\n", "\n", "", "self", ".", "_state", "=", "{", "\n", "'state'", ":", "s", ",", "\n", "'goal'", ":", "goal", ",", "\n", "'n'", ":", "0", ",", "\n", "'done'", ":", "False", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Env.step": [[123, 128], ["ant_agents.Env.maze.step", "ant_agents.Env.to_tensor"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "next_state", ",", "_", ",", "_", ",", "_", "=", "self", ".", "maze", ".", "step", "(", "action", ")", "\n", "self", ".", "_state", "[", "'state'", "]", "=", "self", ".", "to_tensor", "(", "next_state", ")", "\n", "self", ".", "_state", "[", "'n'", "]", "+=", "1", "\n", "self", ".", "_state", "[", "'done'", "]", "=", "(", "self", ".", "_state", "[", "'n'", "]", ">=", "self", ".", "n", ")", "or", "self", ".", "is_success", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Policy.__init__": [[131, 142], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "a_range", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_range", "=", "a_range", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "32", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "8", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Policy.forward": [[144, 147], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "ant_agents.Policy.layers", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "s", ",", "g", ")", ":", "\n", "        ", "\"\"\"Produce an action\"\"\"", "\n", "return", "torch", ".", "tanh", "(", "self", ".", "layers", "(", "torch", ".", "cat", "(", "[", "s", ",", "g", "]", ",", "dim", "=", "1", ")", ")", "*", "0.005", ")", "*", "self", ".", "a_range", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticPolicy.__init__": [[150, 162], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softplus", "torch.Softplus", "torch.Softplus"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "a_range", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_range", "=", "a_range", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "32", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "16", ")", ",", "\n", "nn", ".", "Softplus", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticPolicy.action_stats": [[164, 168], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ant_agents.StochasticPolicy.layers"], "methods", ["None"], ["", "def", "action_stats", "(", "self", ",", "s", ",", "g", ")", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "[", "s", ",", "g", "]", ",", "dim", "=", "1", ")", "\n", "action_stats", "=", "self", ".", "layers", "(", "x", ")", "+", "1", "+", "1e-6", "\n", "return", "action_stats", "[", ":", ",", ":", "8", "]", ",", "action_stats", "[", ":", ",", "8", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticPolicy.scale_action": [[169, 175], ["None"], "methods", ["None"], ["", "def", "scale_action", "(", "self", ",", "logit", ")", ":", "\n", "# Scale to [-1, 1]", "\n", "        ", "logit", "=", "2", "*", "(", "logit", "-", "0.5", ")", "\n", "# Scale to the action range", "\n", "action", "=", "logit", "*", "self", ".", "a_range", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticPolicy.forward": [[176, 200], ["ant_agents.StochasticPolicy.action_stats", "torch.distributions.Beta", "torch.distributions.Beta", "torch.distributions.Beta", "torch.distributions.Beta.log_prob", "torch.distributions.Beta.log_prob", "torch.distributions.Beta.log_prob", "ant_agents.StochasticPolicy.scale_action", "torch.distributions.Beta.log_prob", "torch.distributions.Beta.log_prob", "torch.distributions.Beta.log_prob", "ant_agents.StochasticPolicy.scale_action", "torch.distributions.Beta.sample", "torch.distributions.Beta.sample", "torch.distributions.Beta.sample", "torch.distributions.Beta.entropy().mean", "torch.distributions.Beta.entropy().mean", "torch.distributions.Beta.entropy().mean", "torch.distributions.Beta.entropy().mean", "torch.distributions.Beta.entropy().mean", "torch.distributions.Beta.entropy().mean", "torch.distributions.Beta.entropy", "torch.distributions.Beta.entropy", "torch.distributions.Beta.entropy", "torch.distributions.Beta.entropy", "torch.distributions.Beta.entropy", "torch.distributions.Beta.entropy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticPolicy.action_stats", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticPolicy.scale_action", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticPolicy.scale_action", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample"], ["", "def", "forward", "(", "self", ",", "s", ",", "g", ",", "greedy", "=", "False", ",", "action_logit", "=", "None", ")", ":", "\n", "        ", "\"\"\"Produce an action\"\"\"", "\n", "c0", ",", "c1", "=", "self", ".", "action_stats", "(", "s", ",", "g", ")", "\n", "action_mode", "=", "(", "c0", "-", "1", ")", "/", "(", "c0", "+", "c1", "-", "2", ")", "\n", "m", "=", "Beta", "(", "c0", ",", "c1", ")", "\n", "\n", "# Sample.", "\n", "if", "action_logit", "is", "None", ":", "\n", "            ", "if", "greedy", ":", "\n", "                ", "action_logit", "=", "action_mode", "\n", "", "else", ":", "\n", "                ", "action_logit", "=", "m", ".", "sample", "(", ")", "\n", "\n", "", "n_ent", "=", "-", "m", ".", "entropy", "(", ")", ".", "mean", "(", ")", "\n", "lprobs", "=", "m", ".", "log_prob", "(", "action_logit", ")", "\n", "action", "=", "self", ".", "scale_action", "(", "action_logit", ")", "\n", "return", "action", ",", "action_logit", ",", "lprobs", ",", "n_ent", "\n", "\n", "# Evaluate the action previously taken", "\n", "", "else", ":", "\n", "            ", "n_ent", "=", "-", "m", ".", "entropy", "(", ")", ".", "mean", "(", "dim", "=", "1", ")", "\n", "lprobs", "=", "m", ".", "log_prob", "(", "action_logit", ")", "\n", "action", "=", "self", ".", "scale_action", "(", "action_logit", ")", "\n", "return", "lprobs", ",", "n_ent", ",", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Critic.__init__": [[203, 214], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "use_antigoal", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_antigoal", "=", "use_antigoal", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "42", "if", "self", ".", "use_antigoal", "else", "40", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Critic.q_no_grad": [[216, 226], ["ant_agents.Critic.parameters", "ant_agents.Critic.", "ant_agents.Critic.parameters"], "methods", ["None"], ["", "def", "q_no_grad", "(", "self", ",", "s", ",", "a", ",", "g", ",", "ag", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "q", "=", "self", "(", "s", ",", "a", ",", "g", ",", "ag", ")", "\n", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "True", "\n", "\n", "", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Critic.forward": [[227, 233], ["ant_agents.Critic.layers().view", "ant_agents.Critic.layers().view", "ant_agents.Critic.layers", "ant_agents.Critic.layers", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "s", ",", "a", ",", "g", ",", "ag", ")", ":", "\n", "        ", "\"\"\"Produce an action\"\"\"", "\n", "if", "self", ".", "use_antigoal", ":", "\n", "            ", "return", "self", ".", "layers", "(", "torch", ".", "cat", "(", "[", "s", ",", "a", ",", "g", ",", "ag", "]", ",", "dim", "=", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "layers", "(", "torch", ".", "cat", "(", "[", "s", ",", "a", ",", "g", "]", ",", "dim", "=", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Value.__init__": [[236, 247], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "use_antigoal", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_antigoal", "=", "use_antigoal", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "34", "if", "self", ".", "use_antigoal", "else", "32", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Value.q_no_grad": [[249, 259], ["ant_agents.Value.parameters", "ant_agents.Value.", "ant_agents.Value.parameters"], "methods", ["None"], ["", "def", "q_no_grad", "(", "self", ",", "s", ",", "g", ",", "ag", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "v", "=", "self", "(", "s", ",", "g", ",", "ag", ")", "\n", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "True", "\n", "\n", "", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Value.forward": [[260, 265], ["ant_agents.Value.layers().view", "ant_agents.Value.layers().view", "ant_agents.Value.layers", "ant_agents.Value.layers", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "s", ",", "g", ",", "ag", ")", ":", "\n", "        ", "if", "self", ".", "use_antigoal", ":", "\n", "            ", "return", "self", ".", "layers", "(", "torch", ".", "cat", "(", "[", "s", ",", "g", ",", "ag", "]", ",", "dim", "=", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "layers", "(", "torch", ".", "cat", "(", "[", "s", ",", "g", "]", ",", "dim", "=", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Agent.__init__": [[268, 277], ["torch.Module.__init__", "max", "max", "ant_agents.Env", "ant_agents.Policy", "float", "min", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "maze_type", ",", "noise", "=", "0.1", ",", "epsilon", "=", "0.2", ",", "hardmode", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "noise", "=", "max", "(", "0.0", ",", "float", "(", "noise", ")", ")", "\n", "self", ".", "epsilon", "=", "max", "(", "0.0", ",", "min", "(", "1.0", ",", "float", "(", "epsilon", ")", ")", ")", "\n", "\n", "self", ".", "env", "=", "Env", "(", "n", "=", "n", ",", "maze_type", "=", "maze_type", ",", "hardmode", "=", "hardmode", ")", "\n", "self", ".", "policy", "=", "Policy", "(", "a_range", "=", "self", ".", "env", ".", "action_range", ")", "\n", "self", ".", "episode", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Agent.rollout": [[278, 284], ["torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "@", "property", "\n", "def", "rollout", "(", "self", ")", ":", "\n", "        ", "states", "=", "torch", ".", "stack", "(", "[", "e", "[", "'pre_achieved'", "]", "for", "e", "in", "self", ".", "episode", "]", "+", "[", "self", ".", "episode", "[", "-", "1", "]", "[", "'achieved'", "]", "]", ")", ".", "data", ".", "numpy", "(", ")", "\n", "xs", "=", "states", "[", ":", ",", "0", "]", "\n", "ys", "=", "states", "[", ":", ",", "1", "]", "\n", "return", "[", "xs", ",", "ys", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Agent.reset": [[285, 288], ["ant_agents.Agent.env.reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ",", "state", "=", "None", ",", "goal", "=", "None", ")", ":", "\n", "        ", "self", ".", "env", ".", "reset", "(", "state", ",", "goal", ")", "\n", "self", ".", "episode", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Agent.step": [[289, 326], ["ant_agents.Agent.policy().view", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "ant_agents.Agent.env.step", "ant_agents.Agent.episode.append", "torch.from_numpy.data.numpy", "torch.from_numpy.data.numpy", "torch.from_numpy.data.numpy", "float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ant_agents.Agent.policy", "numpy.random.rand", "numpy.random.uniform", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "terminal.view", "complete.view", "r.view", "s.view", "g.view", "torch.from_numpy.astype", "torch.from_numpy.astype", "torch.from_numpy.astype", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "ant_agents.Agent.env.action_range.data.numpy", "ant_agents.Agent.env.action_range.data.numpy", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.core.shared_buffer.SharedMemoryTrajectoryBuffer.sample", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "step", "(", "self", ",", "do_eval", "=", "False", ")", ":", "\n", "        ", "s", "=", "self", ".", "env", ".", "state", "\n", "g", "=", "self", ".", "env", ".", "goal", "\n", "pre_achieved", "=", "self", ".", "env", ".", "achieved", "\n", "a", "=", "self", ".", "policy", "(", "s", ".", "view", "(", "1", ",", "-", "1", ")", ",", "g", ".", "view", "(", "1", ",", "-", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "if", "not", "do_eval", ":", "\n", "            ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "                ", "a", "=", "np", ".", "random", ".", "uniform", "(", "\n", "low", "=", "-", "self", ".", "env", ".", "action_range", ".", "data", ".", "numpy", "(", ")", ",", "\n", "high", "=", "self", ".", "env", ".", "action_range", ".", "data", ".", "numpy", "(", ")", ",", "\n", "size", "=", "(", "8", ",", ")", "\n", ")", "\n", "a", "=", "torch", ".", "from_numpy", "(", "a", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "                ", "z", "=", "Normal", "(", "torch", ".", "zeros_like", "(", "a", ")", ",", "torch", ".", "ones_like", "(", "a", ")", "*", "self", ".", "noise", "*", "self", ".", "env", ".", "action_range", ")", "\n", "a", "=", "a", "+", "z", ".", "sample", "(", ")", "\n", "", "", "ar", "=", "self", ".", "env", ".", "action_range", "[", "0", "]", "\n", "a", "=", "torch", ".", "clamp", "(", "a", ",", "-", "ar", ",", "ar", ")", "\n", "\n", "self", ".", "env", ".", "step", "(", "a", ".", "data", ".", "numpy", "(", ")", ")", "\n", "complete", "=", "float", "(", "self", ".", "env", ".", "is_success", ")", "*", "torch", ".", "ones", "(", "1", ")", "\n", "terminal", "=", "float", "(", "self", ".", "env", ".", "is_done", ")", "*", "torch", ".", "ones", "(", "1", ")", "\n", "s_next", "=", "self", ".", "env", ".", "state", "\n", "achieved", "=", "self", ".", "env", ".", "achieved", "\n", "r", "=", "-", "1", "*", "torch", ".", "ones", "(", "1", ")", "\n", "\n", "self", ".", "episode", ".", "append", "(", "{", "\n", "'state'", ":", "s", ",", "\n", "'goal'", ":", "g", ",", "\n", "'action'", ":", "a", ",", "\n", "'pre_achieved'", ":", "pre_achieved", ",", "\n", "'next_state'", ":", "s_next", ",", "\n", "'achieved'", ":", "achieved", ",", "\n", "'terminal'", ":", "terminal", ".", "view", "(", "[", "]", ")", ",", "\n", "'complete'", ":", "complete", ".", "view", "(", "[", "]", ")", ",", "\n", "'reward'", ":", "r", ".", "view", "(", "[", "]", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Agent.play_episode": [[328, 332], ["ant_agents.Agent.reset", "ant_agents.Agent.step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "play_episode", "(", "self", ",", "reset_dict", "=", "{", "}", ",", "do_eval", "=", "False", ")", ":", "\n", "        ", "self", ".", "reset", "(", "**", "reset_dict", ")", "\n", "while", "not", "self", ".", "env", ".", "is_done", ":", "\n", "            ", "self", ".", "step", "(", "do_eval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticAgent.__init__": [[335, 344], ["torch.Module.__init__", "ant_agents.Env", "isinstance", "ant_agents.StochasticPolicy"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "maze_type", ",", "policy", "=", "None", ",", "hardmode", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "env", "=", "Env", "(", "n", "=", "n", ",", "maze_type", "=", "maze_type", ",", "hardmode", "=", "hardmode", ")", "\n", "if", "isinstance", "(", "policy", ",", "StochasticPolicy", ")", ":", "\n", "            ", "self", ".", "policy", "=", "policy", "\n", "", "else", ":", "\n", "            ", "self", ".", "policy", "=", "StochasticPolicy", "(", "a_range", "=", "self", ".", "env", ".", "action_range", ")", "\n", "", "self", ".", "episode", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticAgent.rollout": [[345, 351], ["torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack().data.numpy", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "@", "property", "\n", "def", "rollout", "(", "self", ")", ":", "\n", "        ", "states", "=", "torch", ".", "stack", "(", "[", "e", "[", "'pre_achieved'", "]", "for", "e", "in", "self", ".", "episode", "]", "+", "[", "self", ".", "episode", "[", "-", "1", "]", "[", "'achieved'", "]", "]", ")", ".", "data", ".", "numpy", "(", ")", "\n", "xs", "=", "states", "[", ":", ",", "0", "]", "\n", "ys", "=", "states", "[", ":", ",", "1", "]", "\n", "return", "[", "xs", ",", "ys", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticAgent.reset": [[352, 355], ["ant_agents.StochasticAgent.env.reset"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset"], ["", "def", "reset", "(", "self", ",", "state", "=", "None", ",", "goal", "=", "None", ")", ":", "\n", "        ", "self", ".", "env", ".", "reset", "(", "state", ",", "goal", ")", "\n", "self", ".", "episode", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticAgent.step": [[356, 385], ["ant_agents.StochasticAgent.policy", "a.view.view.view", "logit.view.view.view", "log_prob.sum.sum.sum", "ant_agents.StochasticAgent.env.step", "ant_agents.StochasticAgent.episode.append", "s.view", "g.view", "a.view.view.data.numpy", "float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "log_prob.sum.sum.view", "n_ent.view", "terminal.view", "complete.view", "r.view"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["", "def", "step", "(", "self", ",", "do_eval", "=", "False", ")", ":", "\n", "        ", "s", "=", "self", ".", "env", ".", "state", "\n", "g", "=", "self", ".", "env", ".", "goal", "\n", "pre_achieved", "=", "self", ".", "env", ".", "achieved", "\n", "a", ",", "logit", ",", "log_prob", ",", "n_ent", "=", "self", ".", "policy", "(", "s", ".", "view", "(", "1", ",", "-", "1", ")", ",", "g", ".", "view", "(", "1", ",", "-", "1", ")", ",", "greedy", "=", "do_eval", ")", "\n", "a", "=", "a", ".", "view", "(", "-", "1", ")", "\n", "logit", "=", "logit", ".", "view", "(", "-", "1", ")", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", ")", "\n", "\n", "self", ".", "env", ".", "step", "(", "a", ".", "data", ".", "numpy", "(", ")", ")", "\n", "complete", "=", "float", "(", "self", ".", "env", ".", "is_success", ")", "*", "torch", ".", "ones", "(", "1", ")", "\n", "terminal", "=", "float", "(", "self", ".", "env", ".", "is_done", ")", "*", "torch", ".", "ones", "(", "1", ")", "\n", "s_next", "=", "self", ".", "env", ".", "state", "\n", "achieved", "=", "self", ".", "env", ".", "achieved", "\n", "r", "=", "-", "1", "*", "torch", ".", "ones", "(", "1", ")", "\n", "\n", "self", ".", "episode", ".", "append", "(", "{", "\n", "'state'", ":", "s", ",", "\n", "'goal'", ":", "g", ",", "\n", "'pre_achieved'", ":", "pre_achieved", ",", "\n", "'action'", ":", "a", ",", "\n", "'action_logit'", ":", "logit", ",", "\n", "'log_prob'", ":", "log_prob", ".", "view", "(", "[", "]", ")", ",", "\n", "'n_ent'", ":", "n_ent", ".", "view", "(", "[", "]", ")", ",", "\n", "'next_state'", ":", "s_next", ",", "\n", "'achieved'", ":", "achieved", ",", "\n", "'terminal'", ":", "terminal", ".", "view", "(", "[", "]", ")", ",", "\n", "'complete'", ":", "complete", ".", "view", "(", "[", "]", ")", ",", "\n", "'reward'", ":", "r", ".", "view", "(", "[", "]", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.StochasticAgent.play_episode": [[387, 391], ["ant_agents.StochasticAgent.reset", "ant_agents.StochasticAgent.step"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step"], ["", "def", "play_episode", "(", "self", ",", "reset_dict", "=", "{", "}", ",", "do_eval", "=", "False", ")", ":", "\n", "        ", "self", ".", "reset", "(", "**", "reset_dict", ")", "\n", "while", "not", "self", ".", "env", ".", "is_done", ":", "\n", "            ", "self", ".", "step", "(", "do_eval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.__init__": [[394, 440], ["torch.Module.__init__", "bool", "ant_agents.Agent", "ant_agents.Agent", "ant_agents.GoalChainAgentDDPG._sync_agents", "ant_agents.Critic", "ant_agents.Critic", "ant_agents.GoalChainAgentDDPG.q_target.load_state_dict", "ant_agents.Policy", "ant_agents.GoalChainAgentDDPG.p_target.load_state_dict", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ant_agents.GoalChainAgentDDPG.q_module.state_dict", "ant_agents.GoalChainAgentDDPG.p_module.state_dict", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG._sync_agents", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["    ", "def", "__init__", "(", "self", ",", "\n", "n", "=", "100", ",", "maze_type", "=", "'AntMaze'", ",", "\n", "gamma", "=", "0.98", ",", "polyak", "=", "0.95", ",", "\n", "noise", "=", "0.1", ",", "epsilon", "=", "0.2", ",", "\n", "action_l2_lambda", "=", "0.01", ",", "\n", "ddiff", "=", "False", ",", "\n", "use_dense", "=", "True", ",", "\n", "use_antigoal", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "max_goal_prop", "=", "0", "\n", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "polyak", "=", "polyak", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "action_l2_lambda", "=", "action_l2_lambda", "\n", "self", ".", "ddiff", "=", "bool", "(", "ddiff", ")", "\n", "self", ".", "use_antigoal", "=", "use_antigoal", "\n", "self", ".", "use_dense", "=", "use_dense", "\n", "\n", "self", ".", "a0", "=", "Agent", "(", "n", "=", "n", ",", "maze_type", "=", "maze_type", ",", "noise", "=", "noise", ",", "epsilon", "=", "self", ".", "epsilon", ")", "\n", "self", ".", "a1", "=", "Agent", "(", "n", "=", "n", ",", "maze_type", "=", "maze_type", ",", "noise", "=", "noise", ",", "epsilon", "=", "self", ".", "epsilon", ")", "\n", "self", ".", "_sync_agents", "(", ")", "\n", "\n", "self", ".", "q_module", "=", "Critic", "(", "self", ".", "use_antigoal", ")", "\n", "self", ".", "q_target", "=", "Critic", "(", "self", ".", "use_antigoal", ")", "\n", "self", ".", "q_target", ".", "load_state_dict", "(", "self", ".", "q_module", ".", "state_dict", "(", ")", ")", "\n", "\n", "self", ".", "p_module", "=", "self", ".", "a0", ".", "policy", "\n", "# self.p_target = StochasticPolicy(self.a0.env.action_range)", "\n", "self", ".", "p_target", "=", "Policy", "(", "self", ".", "a0", ".", "env", ".", "action_range", ")", "\n", "self", ".", "p_target", ".", "load_state_dict", "(", "self", ".", "p_module", ".", "state_dict", "(", ")", ")", "\n", "\n", "# VERY IMPORTANT that the training algorithm uses train_steps to track the number of episodes played", "\n", "self", ".", "train_steps", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "train_steps", ".", "requires_grad", "=", "False", "\n", "\n", "self", ".", "distance", "=", "[", "]", "\n", "self", ".", "distance_ag", "=", "[", "]", "\n", "self", ".", "_ep_summary", "=", "[", "]", "\n", "\n", "# For clamping the q target", "\n", "if", "self", ".", "use_dense", ":", "\n", "            ", "self", ".", "_q_clamp", "=", "[", "-", "2", "/", "(", "1", "-", "self", ".", "gamma", ")", ",", "2", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_q_clamp", "=", "[", "-", "1", "/", "(", "1", "-", "self", ".", "gamma", ")", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.reset": [[441, 443], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.was_success": [[444, 447], ["bool"], "methods", ["None"], ["", "@", "property", "\n", "def", "was_success", "(", "self", ")", ":", "\n", "        ", "return", "bool", "(", "self", ".", "a0", ".", "env", ".", "is_success", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.curr_ep": [[448, 451], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "curr_ep", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "a0", ".", "episode", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.save_checkpoint": [[452, 455], ["ant_agents.GoalChainAgentDDPG._sync_agents", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "ant_agents.GoalChainAgentDDPG.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG._sync_agents", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save_checkpoint", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "self", ".", "_sync_agents", "(", ")", "\n", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.load_checkpoint": [[456, 459], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "ant_agents.GoalChainAgentDDPG.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load_checkpoint", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "filepath", ")", "\n", "self", ".", "load_state_dict", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG._sync_agents": [[460, 462], ["ant_agents.GoalChainAgentDDPG.a1.load_state_dict", "ant_agents.GoalChainAgentDDPG.a0.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "_sync_agents", "(", "self", ")", ":", "\n", "        ", "self", ".", "a1", ".", "load_state_dict", "(", "self", ".", "a0", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.soft_update": [[463, 473], ["zip", "zip", "ant_agents.GoalChainAgentDDPG._sync_agents", "ant_agents.GoalChainAgentDDPG.q_module.parameters", "ant_agents.GoalChainAgentDDPG.q_target.parameters", "ant_agents.GoalChainAgentDDPG.p_module.parameters", "ant_agents.GoalChainAgentDDPG.p_target.parameters"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG._sync_agents"], ["", "def", "soft_update", "(", "self", ")", ":", "\n", "        ", "for", "p", ",", "p_targ", "in", "zip", "(", "self", ".", "q_module", ".", "parameters", "(", ")", ",", "self", ".", "q_target", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "p_targ", ".", "data", "*=", "self", ".", "polyak", "\n", "p_targ", ".", "data", "+=", "(", "1", "-", "self", ".", "polyak", ")", "*", "p", ".", "data", "\n", "\n", "", "for", "p", ",", "p_targ", "in", "zip", "(", "self", ".", "p_module", ".", "parameters", "(", ")", ",", "self", ".", "p_target", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "p_targ", ".", "data", "*=", "self", ".", "polyak", "\n", "p_targ", ".", "data", "+=", "(", "1", "-", "self", ".", "polyak", ")", "*", "p", ".", "data", "\n", "\n", "", "self", ".", "_sync_agents", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.play_episode": [[474, 481], ["ant_agents.GoalChainAgentDDPG.a0.play_episode", "ant_agents.GoalChainAgentDDPG.a1.play_episode"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.play_episode", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.play_episode"], ["", "def", "play_episode", "(", "self", ",", "reset_dict", "=", "{", "}", ",", "do_eval", "=", "False", ")", ":", "\n", "        ", "self", ".", "distance", "=", "[", "]", "\n", "self", ".", "distance_ag", "=", "[", "]", "\n", "self", ".", "_ep_summary", "=", "[", "]", "\n", "\n", "self", ".", "a0", ".", "play_episode", "(", "reset_dict", ",", "do_eval", "=", "do_eval", ")", "\n", "self", ".", "a1", ".", "play_episode", "(", "reset_dict", "=", "self", ".", "a0", ".", "env", ".", "next_phase_reset", ",", "do_eval", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.relabel_episode": [[482, 505], ["ant_agents.GoalChainAgentDDPG.a0.env.dist", "ant_agents.GoalChainAgentDDPG.a0.env.dist", "ant_agents.GoalChainAgentDDPG.distance.append", "ant_agents.GoalChainAgentDDPG.distance_ag.append", "ant_agents.GoalChainAgentDDPG.a0.env.dist", "ant_agents.GoalChainAgentDDPG.a0.env.dist", "ant_agents.GoalChainAgentDDPG.item", "ant_agents.GoalChainAgentDDPG.item", "float", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["", "def", "relabel_episode", "(", "self", ")", ":", "\n", "        ", "antigoal", "=", "self", ".", "a1", ".", "env", ".", "achieved", "\n", "\n", "for", "e", "in", "self", ".", "a0", ".", "episode", ":", "\n", "            ", "e", "[", "'antigoal'", "]", "=", "antigoal", "\n", "\n", "dg_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'achieved'", "]", ",", "e", "[", "'goal'", "]", ")", "\n", "da_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'achieved'", "]", ",", "e", "[", "'antigoal'", "]", ")", "\n", "\n", "ddg", "=", "-", "dg_nxt", "\n", "dda", "=", "-", "da_nxt", "\n", "\n", "if", "self", ".", "ddiff", ":", "\n", "                ", "ddg", "+=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'pre_achieved'", "]", ",", "e", "[", "'goal'", "]", ")", "\n", "dda", "+=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'pre_achieved'", "]", ",", "e", "[", "'antigoal'", "]", ")", "\n", "\n", "", "r_sparse", "=", "1", "*", "e", "[", "'complete'", "]", "\n", "r_dense", "=", "ddg", "-", "(", "float", "(", "self", ".", "use_antigoal", ")", "*", "dda", ")", "\n", "\n", "e", "[", "'reward'", "]", "+=", "r_sparse", "+", "(", "float", "(", "self", ".", "use_dense", ")", "*", "r_dense", ")", "\n", "\n", "self", ".", "distance", ".", "append", "(", "dg_nxt", ".", "item", "(", ")", ")", "\n", "self", ".", "distance_ag", ".", "append", "(", "da_nxt", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.transitions_for_buffer": [[506, 508], ["None"], "methods", ["None"], ["", "", "def", "transitions_for_buffer", "(", "self", ",", "training", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "a0", ".", "episode", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.normalize_batch": [[509, 512], ["None"], "methods", ["None"], ["", "def", "normalize_batch", "(", "self", ",", "batch_dict", ")", ":", "\n", "        ", "\"\"\"Apply batch normalization to the appropriate inputs within the batch\"\"\"", "\n", "return", "batch_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.forward": [[513, 543], ["ant_agents.GoalChainAgentDDPG.p_target", "ant_agents.GoalChainAgentDDPG.q_target", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "ant_agents.GoalChainAgentDDPG.q_module", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "ant_agents.GoalChainAgentDDPG.p_module", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "float", "float", "float", "reward.mean", "ant_agents.GoalChainAgentDDPG.mean", "ant_agents.GoalChainAgentDDPG.q_target.q_no_grad().mean", "reward.mean.item", "ant_agents.GoalChainAgentDDPG.mean.item", "torch.pow().mean.item", "torch.pow().mean.item", "torch.pow().mean.item", "p_loss.item", "torch.mean.item", "torch.mean.item", "torch.mean.item", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "ant_agents.GoalChainAgentDDPG.q_target.q_no_grad", "torch.clamp.detach", "torch.clamp.detach", "torch.clamp.detach"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.Value.q_no_grad"], ["", "def", "forward", "(", "self", ",", "state", ",", "action", ",", "goal", ",", "antigoal", ",", "reward", ",", "next_state", ",", "terminal", ",", "complete", ",", "**", "kwargs", ")", ":", "\n", "# Get the q target", "\n", "        ", "next_policy_actions", "=", "self", ".", "p_target", "(", "next_state", ",", "goal", ")", "\n", "q_next", "=", "self", ".", "q_target", "(", "next_state", ",", "next_policy_actions", ",", "goal", ",", "antigoal", ")", "\n", "q_targ", "=", "reward", "+", "(", "(", "1", "-", "complete", ")", "*", "self", ".", "gamma", "*", "q_next", ")", "\n", "q_targ", "=", "torch", ".", "clamp", "(", "q_targ", ",", "*", "self", ".", "_q_clamp", ")", "\n", "\n", "# Get the Q values associated with the observed transitions", "\n", "q", "=", "self", ".", "q_module", "(", "state", ",", "action", ",", "goal", ",", "antigoal", ")", "\n", "\n", "# Loss for the q_module", "\n", "q_loss", "=", "torch", ".", "pow", "(", "q", "-", "q_targ", ".", "detach", "(", ")", ",", "2", ")", ".", "mean", "(", ")", "\n", "\n", "# We want to optimize the actions wrt their q value (without getting q module gradients)", "\n", "policy_actions", "=", "self", ".", "p_module", "(", "state", ",", "goal", ")", "\n", "p_loss", "=", "-", "self", ".", "q_target", ".", "q_no_grad", "(", "state", ",", "policy_actions", ",", "goal", ",", "antigoal", ")", ".", "mean", "(", ")", "\n", "\n", "l2", "=", "torch", ".", "mean", "(", "policy_actions", "**", "2", ")", "\n", "l2_loss", "=", "l2", "*", "self", ".", "action_l2_lambda", "\n", "\n", "succeeded", "=", "float", "(", "self", ".", "was_success", ")", "\n", "dist_to_g", "=", "float", "(", "self", ".", "distance", "[", "-", "1", "]", ")", "\n", "dist_to_a", "=", "float", "(", "self", ".", "distance_ag", "[", "-", "1", "]", ")", "\n", "avg_r", "=", "reward", ".", "mean", "(", ")", "\n", "avg_q", "=", "q", ".", "mean", "(", ")", "\n", "self", ".", "_ep_summary", "=", "[", "\n", "succeeded", ",", "dist_to_g", ",", "dist_to_a", ",", "avg_r", ".", "item", "(", ")", ",", "avg_q", ".", "item", "(", ")", ",", "q_loss", ".", "item", "(", ")", ",", "p_loss", ".", "item", "(", ")", ",", "l2", ".", "item", "(", ")", "\n", "]", "\n", "\n", "return", "p_loss", "+", "q_loss", "+", "l2_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPG.episode_summary": [[544, 553], ["ant_agents.GoalChainAgentDDPG.", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "float", "ant_agents.GoalChainAgentDDPG.a0.episode[].keys", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "episode_summary", "(", "self", ")", ":", "\n", "        ", "keys", "=", "[", "k", "for", "k", "in", "self", ".", "a0", ".", "episode", "[", "0", "]", ".", "keys", "(", ")", "]", "\n", "batched_ep", "=", "{", "}", "\n", "for", "key", "in", "keys", ":", "\n", "            ", "batched_ep", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "e", "[", "key", "]", "for", "e", "in", "self", ".", "a0", ".", "episode", "]", ")", ".", "detach", "(", ")", "\n", "\n", "", "_", "=", "self", "(", "**", "batched_ep", ")", "\n", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "self", ".", "_ep_summary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPGHER.__init__": [[556, 562], ["ant_agents.GoalChainAgentDDPG.__init__"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "k", "=", "4", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "k", "=", "k", "\n", "# Switch the default here to NOT use dense reward (by default, this is true HER w/ sparse reward)", "\n", "if", "'use_dense'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'use_dense'", "]", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentDDPGHER.transitions_for_buffer": [[563, 606], ["range", "len", "int", "ant_agents.GoalChainAgentDDPGHER.a0.env.dist", "ant_agents.GoalChainAgentDDPGHER.a0.env.dist", "ant_agents.GoalChainAgentDDPGHER.a0.env.dist", "ant_agents.GoalChainAgentDDPGHER.a0.env.dist", "bool", "float", "her_goal.detach", "her_transitions.append", "numpy.random.permutation", "v.clone().detach", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "numpy.arange", "float", "float", "ant_agents.GoalChainAgentDDPGHER.curr_ep[].items", "len", "v.clone"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "transitions_for_buffer", "(", "self", ",", "training", "=", "None", ")", ":", "\n", "        ", "her_transitions", "=", "[", "]", "\n", "\n", "for", "t", "in", "range", "(", "len", "(", "self", ".", "curr_ep", ")", ")", ":", "\n", "            ", "perm_idx", "=", "[", "int", "(", "i", ")", "for", "i", "in", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "t", ",", "len", "(", "self", ".", "curr_ep", ")", ")", ")", "]", "\n", "her_goal_indices", "=", "perm_idx", "[", ":", "self", ".", "k", "]", "\n", "for", "idx", "in", "her_goal_indices", ":", "\n", "                ", "her_goal", "=", "self", ".", "curr_ep", "[", "idx", "]", "[", "'achieved'", "]", "\n", "\n", "dg_pre", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "her_goal", ",", "self", ".", "curr_ep", "[", "t", "]", "[", "'state'", "]", ")", "\n", "dg_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "her_goal", ",", "self", ".", "curr_ep", "[", "t", "]", "[", "'next_state'", "]", ")", "\n", "\n", "if", "dg_pre", "==", "0", ":", "# This transition makes no sense. Skip it", "\n", "                    ", "continue", "\n", "\n", "", "da_pre", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "self", ".", "curr_ep", "[", "t", "]", "[", "'antigoal'", "]", ",", "self", ".", "curr_ep", "[", "t", "]", "[", "'state'", "]", ")", "\n", "da_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "self", ".", "curr_ep", "[", "t", "]", "[", "'antigoal'", "]", ",", "self", ".", "curr_ep", "[", "t", "]", "[", "'next_state'", "]", ")", "\n", "\n", "ddg", "=", "-", "dg_nxt", "\n", "dda", "=", "-", "da_nxt", "\n", "\n", "if", "self", ".", "ddiff", ":", "\n", "                    ", "ddg", "+=", "dg_pre", "\n", "dda", "+=", "da_pre", "\n", "\n", "", "now_complete", "=", "bool", "(", "(", "dg_nxt", "<=", "self", ".", "a0", ".", "env", ".", "dist_threshold", ")", ".", "item", "(", ")", ")", "\n", "r_sparse", "=", "float", "(", "now_complete", ")", "\n", "r_dense", "=", "ddg", "-", "(", "float", "(", "self", ".", "use_antigoal", ")", "*", "dda", ")", "\n", "\n", "new_reward", "=", "-", "1", "+", "r_sparse", "+", "(", "float", "(", "self", ".", "use_dense", ")", "*", "r_dense", ")", "\n", "\n", "new_trans", "=", "{", "k", ":", "v", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "k", ",", "v", "in", "self", ".", "curr_ep", "[", "t", "]", ".", "items", "(", ")", "}", "\n", "new_trans", "[", "'goal'", "]", "=", "her_goal", ".", "detach", "(", ")", "\n", "new_trans", "[", "'reward'", "]", "=", "new_reward", "*", "torch", ".", "ones_like", "(", "new_trans", "[", "'reward'", "]", ")", "\n", "\n", "# The episode would have ended here (with the her goal)", "\n", "if", "now_complete", ":", "\n", "                    ", "new_trans", "[", "'terminal'", "]", "=", "torch", ".", "ones_like", "(", "new_trans", "[", "'terminal'", "]", ")", "\n", "new_trans", "[", "'complete'", "]", "=", "torch", ".", "ones_like", "(", "new_trans", "[", "'complete'", "]", ")", "\n", "\n", "", "her_transitions", ".", "append", "(", "new_trans", ")", "\n", "\n", "", "", "return", "her_transitions", "+", "self", ".", "a0", ".", "episode", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.__init__": [[609, 655], ["torch.Module.__init__", "float", "float", "float", "float", "bool", "ant_agents.StochasticAgent", "ant_agents.StochasticAgent", "ant_agents.Value", "torch.Parameter", "torch.Parameter", "torch.Parameter", "int", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "n", "=", "100", ",", "maze_type", "=", "'AntMaze'", ",", "hardmode", "=", "False", ",", "\n", "horizon", "=", "400", ",", "mini_batch_size", "=", "100", ",", "\n", "gamma", "=", "0.98", ",", "gae_lambda", "=", "0.95", ",", "\n", "entropy_lambda", "=", "0.05", ",", "action_l2_weight", "=", "0.0", ",", "\n", "ddiff", "=", "False", ",", "\n", "use_antigoal", "=", "True", ",", "max_goal_prop", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "use_antigoal", "=", "use_antigoal", "\n", "\n", "self", ".", "max_goal_prop", "=", "max_goal_prop", "\n", "\n", "self", ".", "gamma", "=", "float", "(", "gamma", ")", "\n", "\n", "self", ".", "gae_lambda", "=", "float", "(", "gae_lambda", ")", "\n", "self", ".", "entropy_lambda", "=", "float", "(", "entropy_lambda", ")", "\n", "self", ".", "action_l2_weight", "=", "float", "(", "action_l2_weight", ")", "\n", "self", ".", "ddiff", "=", "bool", "(", "ddiff", ")", "\n", "\n", "self", ".", "a0", "=", "StochasticAgent", "(", "n", "=", "n", ",", "maze_type", "=", "maze_type", ",", "hardmode", "=", "hardmode", ")", "\n", "self", ".", "a1", "=", "StochasticAgent", "(", "n", "=", "n", ",", "maze_type", "=", "maze_type", ",", "hardmode", "=", "hardmode", ")", "\n", "\n", "self", ".", "v_module", "=", "Value", "(", "self", ".", "use_antigoal", ")", "\n", "\n", "# VERY IMPORTANT that the training algorithm uses train_steps to track the number of episodes played", "\n", "self", ".", "train_steps", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "train_steps", ".", "requires_grad", "=", "False", "\n", "\n", "self", ".", "horizon", "=", "int", "(", "horizon", ")", "\n", "self", ".", "mini_batch_size", "=", "int", "(", "mini_batch_size", ")", "\n", "self", ".", "clip_range", "=", "0.2", "\n", "\n", "self", ".", "_mini_buffer", "=", "{", "'state'", ":", "None", "}", "\n", "self", ".", "_epoch_transitions", "=", "{", "}", "\n", "\n", "self", ".", "distance", "=", "[", "]", "\n", "self", ".", "distance_ag", "=", "[", "]", "\n", "\n", "self", ".", "losses", "=", "[", "]", "\n", "\n", "self", ".", "_ep_summary", "=", "[", "]", "\n", "self", ".", "_batched_ep", "=", "None", "\n", "self", ".", "_phase", "=", "0", "\n", "self", ".", "_next_reset", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.reset": [[656, 658], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.sync_agents": [[659, 661], ["ant_agents.GoalChainAgentPPO.a1.load_state_dict", "ant_agents.GoalChainAgentPPO.a0.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "sync_agents", "(", "self", ")", ":", "\n", "        ", "self", ".", "a1", ".", "load_state_dict", "(", "self", ".", "a0", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.current_horizon": [[662, 669], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_horizon", "(", "self", ")", ":", "\n", "        ", "mb_state", "=", "self", ".", "_mini_buffer", "[", "'state'", "]", "\n", "if", "mb_state", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "return", "mb_state", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.was_success": [[670, 673], ["bool"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "was_success", "(", "self", ")", ":", "\n", "        ", "return", "bool", "(", "self", ".", "a0", ".", "env", ".", "is_success", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.curr_ep": [[674, 677], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "curr_ep", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "a0", ".", "episode", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.save_checkpoint": [[678, 681], ["ant_agents.GoalChainAgentPPO.sync_agents", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "ant_agents.GoalChainAgentPPO.state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.sync_agents", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.save", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.state_dict"], ["", "def", "save_checkpoint", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "self", ".", "sync_agents", "(", ")", "\n", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.load_checkpoint": [[682, 685], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "ant_agents.GoalChainAgentPPO.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.success_prediction.GoalSuccessPredictor.load", "home.repos.pwc.inspect_result.spitis_mrl.modules.normalizer.MeanStdNormalizer.load_state_dict"], ["", "def", "load_checkpoint", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "filepath", ")", "\n", "self", ".", "load_state_dict", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.add_to_mini_buffer": [[686, 695], ["batched_episode.items", "int", "all", "ant_agents.GoalChainAgentPPO._mini_buffer.get", "v.detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "int", "ant_agents.GoalChainAgentPPO._mini_buffer.values"], "methods", ["None"], ["", "def", "add_to_mini_buffer", "(", "self", ",", "batched_episode", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "batched_episode", ".", "items", "(", ")", ":", "\n", "            ", "if", "self", ".", "_mini_buffer", ".", "get", "(", "k", ",", "None", ")", "is", "None", ":", "\n", "                ", "self", ".", "_mini_buffer", "[", "k", "]", "=", "v", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_mini_buffer", "[", "k", "]", "=", "torch", ".", "cat", "(", "[", "self", ".", "_mini_buffer", "[", "k", "]", ",", "v", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "curr_horizon", "=", "int", "(", "self", ".", "current_horizon", ")", "\n", "assert", "all", "(", "[", "int", "(", "v", ".", "shape", "[", "0", "]", ")", "==", "curr_horizon", "for", "v", "in", "self", ".", "_mini_buffer", ".", "values", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.fill_epoch_transitions": [[696, 706], ["int", "ant_agents.GoalChainAgentPPO._mini_buffer.items"], "methods", ["None"], ["", "def", "fill_epoch_transitions", "(", "self", ")", ":", "\n", "        ", "curr_horizon", "=", "int", "(", "self", ".", "current_horizon", ")", "\n", "assert", "curr_horizon", ">=", "self", ".", "horizon", "\n", "self", ".", "_epoch_transitions", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "_mini_buffer", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "_epoch_transitions", "[", "k", "]", "=", "v", "[", ":", "self", ".", "horizon", "]", "\n", "if", "curr_horizon", ">", "self", ".", "horizon", ":", "\n", "                ", "self", ".", "_mini_buffer", "[", "k", "]", "=", "v", "[", "self", ".", "horizon", ":", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "_mini_buffer", "[", "k", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.make_epoch_mini_batches": [[707, 719], ["numpy.split", "numpy.random.permutation", "mini_batches.append", "this_batch[].mean().view", "this_batch[].std().view", "ant_agents.GoalChainAgentPPO._epoch_transitions.items", "this_batch[].mean", "this_batch[].std"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "", "def", "make_epoch_mini_batches", "(", "self", ",", "normalize_advantage", "=", "False", ")", ":", "\n", "        ", "mb_indices", "=", "np", ".", "split", "(", "np", ".", "random", ".", "permutation", "(", "self", ".", "horizon", ")", ",", "self", ".", "horizon", "//", "self", ".", "mini_batch_size", ")", "\n", "\n", "mini_batches", "=", "[", "]", "\n", "for", "indices", "in", "mb_indices", ":", "\n", "            ", "this_batch", "=", "{", "k", ":", "v", "[", "indices", "]", "for", "k", ",", "v", "in", "self", ".", "_epoch_transitions", ".", "items", "(", ")", "}", "\n", "if", "normalize_advantage", "and", "'advantage'", "in", "this_batch", ":", "\n", "                ", "mb_mean", "=", "this_batch", "[", "'advantage'", "]", ".", "mean", "(", "dim", "=", "0", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "mb_std", "=", "this_batch", "[", "'advantage'", "]", ".", "std", "(", "dim", "=", "0", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "this_batch", "[", "'advantage'", "]", "=", "(", "this_batch", "[", "'advantage'", "]", "-", "mb_mean", ")", "/", "mb_std", "\n", "", "mini_batches", ".", "append", "(", "this_batch", ")", "\n", "", "return", "mini_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.distributed_advantage_normalization": [[720, 742], ["a.sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "len", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "a_std.view", "a_mean.view"], "methods", ["None"], ["", "def", "distributed_advantage_normalization", "(", "self", ")", ":", "\n", "        ", "if", "'advantage'", "not", "in", "self", ".", "_epoch_transitions", ":", "\n", "            ", "return", "\n", "", "a", "=", "self", ".", "_epoch_transitions", "[", "'advantage'", "]", "\n", "\n", "a_sum", "=", "a", ".", "sum", "(", "dim", "=", "0", ")", "\n", "a_sumsq", "=", "torch", ".", "pow", "(", "a", ",", "2", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "dist", ".", "all_reduce", "(", "a_sum", ")", "\n", "dist", ".", "all_reduce", "(", "a_sumsq", ")", "\n", "\n", "n", "=", "dist", ".", "get_world_size", "(", ")", "\n", "a_mean", "=", "a_sum", "/", "(", "self", ".", "horizon", "*", "n", ")", "\n", "a_var", "=", "(", "a_sumsq", "/", "(", "self", ".", "horizon", "*", "n", ")", ")", "-", "(", "a_mean", "**", "2", ")", "\n", "a_std", "=", "torch", ".", "pow", "(", "a_var", ",", "0.5", ")", "+", "1e-8", "\n", "\n", "n_dim", "=", "len", "(", "a", ".", "shape", ")", "\n", "if", "n_dim", "==", "1", ":", "\n", "            ", "self", ".", "_epoch_transitions", "[", "'advantage'", "]", "=", "(", "a", "-", "a_mean", ")", "/", "a_std", "\n", "", "elif", "n_dim", "==", "2", ":", "\n", "            ", "self", ".", "_epoch_transitions", "[", "'advantage'", "]", "=", "(", "a", "-", "a_mean", ".", "view", "(", "1", ",", "-", "1", ")", ")", "/", "a_std", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.reach_horizon": [[743, 750], ["ant_agents.GoalChainAgentPPO.sync_agents", "ant_agents.GoalChainAgentPPO.fill_epoch_transitions", "ant_agents.GoalChainAgentPPO.play_episode", "ant_agents.GoalChainAgentPPO.add_to_mini_buffer", "v.detach", "ant_agents.GoalChainAgentPPO.compress_episode().items", "ant_agents.GoalChainAgentPPO.compress_episode"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.sync_agents", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.fill_epoch_transitions", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.play_episode", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.add_to_mini_buffer", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.compress_episode"], ["", "", "def", "reach_horizon", "(", "self", ")", ":", "\n", "        ", "self", ".", "sync_agents", "(", ")", "\n", "while", "self", ".", "current_horizon", "<", "self", ".", "horizon", ":", "\n", "            ", "self", ".", "play_episode", "(", ")", "\n", "batched_episode", "=", "{", "k", ":", "v", ".", "detach", "(", ")", "for", "k", ",", "v", "in", "self", ".", "compress_episode", "(", ")", ".", "items", "(", ")", "}", "\n", "self", ".", "add_to_mini_buffer", "(", "batched_episode", ")", "\n", "", "self", ".", "fill_epoch_transitions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.play_episode": [[751, 780], ["ant_agents.GoalChainAgentPPO.a0.play_episode", "ant_agents.GoalChainAgentPPO.a1.play_episode", "ant_agents.GoalChainAgentPPO.relabel_episode"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.play_episode", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.play_episode", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.relabel_episode"], ["", "def", "play_episode", "(", "self", ",", "reset_dict", "=", "None", ",", "do_eval", "=", "False", ",", "force_reset", "=", "False", ")", ":", "\n", "        ", "self", ".", "distance", "=", "[", "]", "\n", "self", ".", "distance_ag", "=", "[", "]", "\n", "self", ".", "_ep_summary", "=", "[", "]", "\n", "self", ".", "_batched_ep", "=", "None", "\n", "\n", "if", "do_eval", "or", "force_reset", ":", "\n", "            ", "self", ".", "_phase", "=", "0", "\n", "self", ".", "_next_reset", "=", "{", "}", "\n", "\n", "", "if", "reset_dict", "is", "None", ":", "\n", "            ", "reset_dict", "=", "self", ".", "_next_reset", "\n", "\n", "", "self", ".", "a0", ".", "play_episode", "(", "reset_dict", ",", "do_eval", "=", "do_eval", ")", "\n", "self", ".", "a1", ".", "play_episode", "(", "reset_dict", "=", "self", ".", "a0", ".", "env", ".", "next_phase_reset", ",", "do_eval", "=", "True", ")", "\n", "self", ".", "relabel_episode", "(", ")", "\n", "\n", "self", ".", "_phase", "+=", "1", "\n", "\n", "if", "do_eval", "or", "self", ".", "_phase", ">", "self", ".", "max_goal_prop", ":", "\n", "            ", "self", ".", "_phase", "=", "0", "\n", "\n", "", "if", "self", ".", "a0", ".", "env", ".", "is_success", "or", "self", ".", "a1", ".", "env", ".", "is_success", ":", "\n", "            ", "self", ".", "_phase", "=", "0", "\n", "\n", "", "if", "self", ".", "_phase", "==", "0", ":", "\n", "            ", "self", ".", "_next_reset", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "_next_reset", "=", "self", ".", "a0", ".", "env", ".", "next_phase_reset", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.relabel_episode": [[781, 804], ["ant_agents.GoalChainAgentPPO.a0.env.dist", "ant_agents.GoalChainAgentPPO.a0.env.dist", "ant_agents.GoalChainAgentPPO.distance.append", "ant_agents.GoalChainAgentPPO.distance_ag.append", "ant_agents.GoalChainAgentPPO.a0.env.dist", "ant_agents.GoalChainAgentPPO.a0.env.dist", "ant_agents.GoalChainAgentPPO.item", "ant_agents.GoalChainAgentPPO.item", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["", "", "def", "relabel_episode", "(", "self", ")", ":", "\n", "        ", "antigoal", "=", "self", ".", "a1", ".", "env", ".", "achieved", "\n", "\n", "for", "e", "in", "self", ".", "a0", ".", "episode", ":", "\n", "            ", "e", "[", "'antigoal'", "]", "=", "antigoal", "\n", "\n", "dg_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'achieved'", "]", ",", "e", "[", "'goal'", "]", ")", "\n", "da_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'achieved'", "]", ",", "e", "[", "'antigoal'", "]", ")", "\n", "\n", "ddg", "=", "-", "dg_nxt", "\n", "dda", "=", "-", "da_nxt", "\n", "\n", "if", "self", ".", "ddiff", ":", "\n", "                ", "ddg", "+=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'pre_achieved'", "]", ",", "e", "[", "'goal'", "]", ")", "\n", "dda", "+=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'pre_achieved'", "]", ",", "e", "[", "'antigoal'", "]", ")", "\n", "\n", "", "r_sparse", "=", "1", "*", "e", "[", "'complete'", "]", "\n", "r_dense", "=", "ddg", "-", "(", "float", "(", "self", ".", "use_antigoal", ")", "*", "dda", ")", "\n", "\n", "e", "[", "'reward'", "]", "+=", "r_sparse", "+", "r_dense", "\n", "\n", "self", ".", "distance", ".", "append", "(", "dg_nxt", ".", "item", "(", ")", ")", "\n", "self", ".", "distance_ag", ".", "append", "(", "da_nxt", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.compress_episode": [[805, 846], ["ant_agents.GoalChainAgentPPO.v_module", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "reversed", "torch.zeros_like.detach", "torch.zeros_like.detach", "torch.zeros_like.detach", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "range", "torch.zeros_like.detach", "torch.zeros_like.detach", "torch.zeros_like.detach", "batched_episode[].detach", "ant_agents.GoalChainAgentPPO.v_module"], "methods", ["None"], ["", "", "def", "compress_episode", "(", "self", ")", ":", "\n", "        ", "keys", "=", "[", "\n", "'state'", ",", "'next_state'", ",", "'goal'", ",", "'antigoal'", ",", "\n", "'action'", ",", "'n_ent'", ",", "'log_prob'", ",", "'action_logit'", ",", "\n", "'reward'", ",", "'terminal'", ",", "'complete'", "\n", "]", "\n", "batched_episode", "=", "{", "}", "\n", "for", "key", "in", "keys", ":", "\n", "            ", "batched_episode", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "et", "[", "key", "]", "for", "et", "in", "self", ".", "a0", ".", "episode", "]", ")", "\n", "\n", "", "batched_episode", "[", "'value'", "]", "=", "self", ".", "v_module", "(", "\n", "batched_episode", "[", "'state'", "]", ",", "\n", "batched_episode", "[", "'goal'", "]", ",", "\n", "batched_episode", "[", "'antigoal'", "]", "\n", ")", "\n", "\n", "advs", "=", "torch", ".", "zeros_like", "(", "batched_episode", "[", "'reward'", "]", ")", "\n", "last_adv", "=", "0", "\n", "for", "t", "in", "reversed", "(", "range", "(", "advs", ".", "shape", "[", "0", "]", ")", ")", ":", "\n", "            ", "if", "t", "==", "advs", ".", "shape", "[", "0", "]", "-", "1", ":", "\n", "                ", "has_next", "=", "1.0", "-", "batched_episode", "[", "'complete'", "]", "[", "t", "]", "# Is this a genuine terminal action?", "\n", "# has_next = 1.0 - batched_episode['terminal'][t]  # Will there be a timestep after this one?", "\n", "next_value", "=", "self", ".", "v_module", "(", "\n", "batched_episode", "[", "'next_state'", "]", "[", "-", "1", ":", "]", ",", "\n", "batched_episode", "[", "'goal'", "]", "[", "-", "1", ":", "]", ",", "\n", "batched_episode", "[", "'antigoal'", "]", "[", "-", "1", ":", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "has_next", "=", "1.0", "# By our setup, this cannot be a terminal action", "\n", "next_value", "=", "batched_episode", "[", "'value'", "]", "[", "t", "+", "1", "]", "\n", "\n", "", "delta", "=", "batched_episode", "[", "'reward'", "]", "[", "t", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "has_next", "-", "batched_episode", "[", "'value'", "]", "[", "t", "]", "\n", "advs", "[", "t", "]", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "has_next", "*", "last_adv", "\n", "last_adv", "=", "advs", "[", "t", "]", "\n", "\n", "", "batched_episode", "[", "'advantage'", "]", "=", "advs", ".", "detach", "(", ")", "\n", "batched_episode", "[", "'cumulative_return'", "]", "=", "advs", ".", "detach", "(", ")", "+", "batched_episode", "[", "'value'", "]", ".", "detach", "(", ")", "\n", "\n", "self", ".", "_batched_ep", "=", "batched_episode", "\n", "\n", "return", "batched_episode", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.replay_loss": [[847, 890], ["ant_agents.GoalChainAgentPPO.v_module", "ant_agents.GoalChainAgentPPO.a0.policy", "n_ent.mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "log_prob.sum.sum.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max.mean", "torch.max.mean", "torch.max.mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "float", "float", "float", "mini_batch[].mean", "mini_batch[].mean", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "mini_batch[].mean.item", "mini_batch[].mean.item", "v_loss.item", "torch.max.mean.item", "n_ent.mean.item", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "replay_loss", "(", "self", ",", "mini_batch", "=", "None", ")", ":", "\n", "        ", "if", "mini_batch", "is", "None", ":", "\n", "            ", "mini_batch", "=", "self", ".", "_batched_ep", "\n", "fill_summary", "=", "True", "\n", "", "else", ":", "\n", "            ", "fill_summary", "=", "False", "\n", "\n", "", "value", "=", "self", ".", "v_module", "(", "\n", "mini_batch", "[", "'state'", "]", ",", "\n", "mini_batch", "[", "'goal'", "]", ",", "\n", "mini_batch", "[", "'antigoal'", "]", "\n", ")", "\n", "v_loss", "=", "0.5", "*", "torch", ".", "pow", "(", "mini_batch", "[", "'cumulative_return'", "]", "-", "value", ",", "2", ")", ".", "mean", "(", ")", "\n", "\n", "log_prob", ",", "n_ent", ",", "greedy_action", "=", "self", ".", "a0", ".", "policy", "(", "\n", "mini_batch", "[", "'state'", "]", ",", "mini_batch", "[", "'goal'", "]", ",", "\n", "action_logit", "=", "mini_batch", "[", "'action_logit'", "]", "\n", ")", "\n", "e_loss", "=", "n_ent", ".", "mean", "(", ")", "\n", "l2_loss", "=", "torch", ".", "pow", "(", "greedy_action", ",", "2", ")", ".", "mean", "(", ")", "\n", "\n", "# Defining Loss = - J is equivalent to max J", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", "dim", "=", "1", ")", "\n", "ratio", "=", "torch", ".", "exp", "(", "log_prob", "-", "mini_batch", "[", "'log_prob'", "]", ")", "\n", "\n", "pg_losses1", "=", "-", "mini_batch", "[", "'advantage'", "]", "*", "ratio", "\n", "pg_losses2", "=", "-", "mini_batch", "[", "'advantage'", "]", "*", "torch", ".", "clamp", "(", "ratio", ",", "1.0", "-", "self", ".", "clip_range", ",", "1.0", "+", "self", ".", "clip_range", ")", "\n", "p_losses", "=", "torch", ".", "max", "(", "pg_losses1", ",", "pg_losses2", ")", "\n", "p_loss", "=", "p_losses", ".", "mean", "(", ")", "\n", "\n", "loss", "=", "v_loss", "+", "p_loss", "+", "(", "self", ".", "entropy_lambda", "*", "e_loss", ")", "+", "(", "self", ".", "action_l2_weight", "*", "l2_loss", ")", "\n", "\n", "if", "fill_summary", ":", "\n", "            ", "succeeded", "=", "float", "(", "self", ".", "was_success", ")", "\n", "dist_to_g", "=", "float", "(", "self", ".", "distance", "[", "-", "1", "]", ")", "\n", "dist_to_a", "=", "float", "(", "self", ".", "distance_ag", "[", "-", "1", "]", ")", "\n", "avg_r", "=", "mini_batch", "[", "'reward'", "]", ".", "mean", "(", ")", "\n", "avg_v", "=", "mini_batch", "[", "'value'", "]", ".", "mean", "(", ")", "\n", "self", ".", "_ep_summary", "=", "[", "\n", "succeeded", ",", "dist_to_g", ",", "dist_to_a", ",", "avg_r", ".", "item", "(", ")", ",", "avg_v", ".", "item", "(", ")", ",", "v_loss", ".", "item", "(", ")", ",", "p_loss", ".", "item", "(", ")", ",", "e_loss", ".", "item", "(", ")", "\n", "]", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.forward": [[891, 893], ["ant_agents.GoalChainAgentPPO.replay_loss"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.replay_loss"], ["", "def", "forward", "(", "self", ",", "mini_batch", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "replay_loss", "(", "mini_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPPO.episode_summary": [[894, 900], ["ant_agents.GoalChainAgentPPO.compress_episode", "ant_agents.GoalChainAgentPPO.replay_loss", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.compress_episode", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.replay_loss"], ["", "def", "episode_summary", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "_batched_ep", ":", "\n", "            ", "_", "=", "self", ".", "compress_episode", "(", ")", "\n", "", "if", "not", "self", ".", "_ep_summary", ":", "\n", "            ", "_", "=", "self", ".", "replay_loss", "(", ")", "\n", "", "return", "[", "float", "(", "x", ")", "for", "x", "in", "self", ".", "_ep_summary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.__init__": [[903, 959], ["ant_agents.GoalChainAgentPPO.__init__", "float", "float", "float", "float", "bool", "max", "ant_agents.Env", "ant_agents.StochasticPolicy", "ant_agents.Value", "torch.Parameter", "torch.Parameter", "torch.Parameter", "int", "int", "int", "ant_agents.StochasticAgent", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "n", "=", "100", ",", "maze_type", "=", "'AntMaze'", ",", "hardmode", "=", "False", ",", "\n", "horizon", "=", "400", ",", "mini_batch_size", "=", "100", ",", "\n", "gamma", "=", "0.98", ",", "gae_lambda", "=", "0.95", ",", "\n", "entropy_lambda", "=", "0.05", ",", "action_l2_weight", "=", "0.0", ",", "\n", "ddiff", "=", "False", ",", "\n", "n_rollouts", "=", "2", ",", "\n", "use_antigoal", "=", "True", ",", "\n", "value_ignore_antigoal", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "use_antigoal", "=", "use_antigoal", "\n", "\n", "self", ".", "gamma", "=", "float", "(", "gamma", ")", "\n", "\n", "self", ".", "gae_lambda", "=", "float", "(", "gae_lambda", ")", "\n", "self", ".", "entropy_lambda", "=", "float", "(", "entropy_lambda", ")", "\n", "self", ".", "action_l2_weight", "=", "float", "(", "action_l2_weight", ")", "\n", "self", ".", "ddiff", "=", "bool", "(", "ddiff", ")", "\n", "self", ".", "value_antigoal_coeff", "=", "0.0", "if", "value_ignore_antigoal", "else", "1.0", "\n", "\n", "self", ".", "n_rollouts", "=", "max", "(", "2", ",", "int", "(", "n_rollouts", ")", ")", "\n", "\n", "_dummy_env", "=", "Env", "(", "n", "=", "n", ",", "maze_type", "=", "maze_type", ")", "\n", "self", ".", "policy", "=", "StochasticPolicy", "(", "_dummy_env", ".", "action_range", ")", "\n", "self", ".", "v_module", "=", "Value", "(", "self", ".", "use_antigoal", ")", "\n", "\n", "self", ".", "agents", "=", "[", "\n", "StochasticAgent", "(", "\n", "n", "=", "n", ",", "maze_type", "=", "maze_type", ",", "policy", "=", "self", ".", "policy", ",", "hardmode", "=", "hardmode", "\n", ")", "for", "_", "in", "range", "(", "self", ".", "n_rollouts", ")", "\n", "]", "\n", "self", ".", "a0", "=", "self", ".", "agents", "[", "0", "]", "\n", "self", ".", "a1", "=", "self", ".", "agents", "[", "1", "]", "\n", "\n", "# VERY IMPORTANT that the training algorithm uses train_steps to track the number of episodes played", "\n", "self", ".", "train_steps", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "self", ".", "train_steps", ".", "requires_grad", "=", "False", "\n", "\n", "self", ".", "horizon", "=", "int", "(", "horizon", ")", "\n", "self", ".", "mini_batch_size", "=", "int", "(", "mini_batch_size", ")", "\n", "self", ".", "clip_range", "=", "0.2", "\n", "\n", "self", ".", "_mini_buffer", "=", "{", "'state'", ":", "None", "}", "\n", "self", ".", "_epoch_transitions", "=", "{", "}", "\n", "\n", "self", ".", "distance", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "n_rollouts", ")", "]", "\n", "self", ".", "distance_ag", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "n_rollouts", ")", "]", "\n", "\n", "self", ".", "losses", "=", "[", "]", "\n", "\n", "self", ".", "_ep_summary", "=", "[", "]", "\n", "self", ".", "_compress_me", "=", "[", "]", "\n", "self", ".", "_batched_ep", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.avg_success": [[960, 963], ["float", "numpy.mean"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg_success", "(", "self", ")", ":", "\n", "        ", "return", "float", "(", "np", ".", "mean", "(", "[", "agent", ".", "env", ".", "is_success", "for", "agent", "in", "self", ".", "agents", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.avg_dist_to_goal": [[964, 967], ["float", "numpy.mean"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg_dist_to_goal", "(", "self", ")", ":", "\n", "        ", "return", "float", "(", "np", ".", "mean", "(", "[", "d", "[", "-", "1", "]", "for", "d", "in", "self", ".", "distance", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.avg_dist_to_antigoal": [[968, 971], ["float", "numpy.mean"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg_dist_to_antigoal", "(", "self", ")", ":", "\n", "        ", "return", "float", "(", "np", ".", "mean", "(", "[", "d", "[", "-", "1", "]", "for", "d", "in", "self", ".", "distance_ag", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.sync_agents": [[972, 974], ["None"], "methods", ["None"], ["", "def", "sync_agents", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.play_episode": [[975, 989], ["ant_agents.GoalChainAgentPairGo.relabel_episode", "agent.play_episode", "range", "range", "agent.env._state[].detach"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.relabel_episode", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.play_episode"], ["", "def", "play_episode", "(", "self", ",", "reset_dict", "=", "None", ",", "do_eval", "=", "False", ",", "force_reset", "=", "None", ")", ":", "\n", "        ", "self", ".", "distance", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "n_rollouts", ")", "]", "\n", "self", ".", "distance_ag", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "n_rollouts", ")", "]", "\n", "self", ".", "_ep_summary", "=", "[", "]", "\n", "self", ".", "_compress_me", "=", "[", "]", "\n", "self", ".", "_batched_ep", "=", "None", "\n", "\n", "if", "reset_dict", "is", "None", ":", "\n", "            ", "reset_dict", "=", "{", "}", "\n", "\n", "", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "agent", ".", "play_episode", "(", "reset_dict", ",", "do_eval", ")", "\n", "reset_dict", "=", "{", "'state'", ":", "agent", ".", "env", ".", "_seed", ",", "'goal'", ":", "agent", ".", "env", ".", "_state", "[", "'goal'", "]", ".", "detach", "(", ")", "}", "\n", "", "self", ".", "relabel_episode", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo._organize_episodes": [[990, 1003], ["ant_agents.GoalChainAgentPairGo.a0.env.goal.detach", "enumerate", "sorted", "range", "sorted.append", "ant_agents.GoalChainAgentPairGo.a0.env.dist().item", "ant_agents.GoalChainAgentPairGo.a0.env.dist"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["", "def", "_organize_episodes", "(", "self", ")", ":", "\n", "        ", "goal", "=", "self", ".", "a0", ".", "env", ".", "goal", ".", "detach", "(", ")", "\n", "ep_dicts", "=", "[", "]", "\n", "for", "ai", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "ep_dict", "=", "{", "'ai'", ":", "ai", ",", "'ep'", ":", "agent", ".", "episode", ",", "'achieved'", ":", "agent", ".", "env", ".", "achieved", ",", "'antigoal'", ":", "None", "}", "\n", "ep_dicts", ".", "append", "(", "ep_dict", ")", "\n", "", "ep_dicts", "=", "sorted", "(", "ep_dicts", ",", "key", "=", "lambda", "d", ":", "self", ".", "a0", ".", "env", ".", "dist", "(", "goal", ",", "d", "[", "'achieved'", "]", ")", ".", "item", "(", ")", ")", "\n", "\n", "ep_dicts", "[", "0", "]", "[", "'antigoal'", "]", "=", "ep_dicts", "[", "1", "]", "[", "'achieved'", "]", "\n", "for", "ep_rank", "in", "range", "(", "1", ",", "self", ".", "n_rollouts", ")", ":", "\n", "            ", "ep_dicts", "[", "ep_rank", "]", "[", "'antigoal'", "]", "=", "ep_dicts", "[", "ep_rank", "-", "1", "]", "[", "'achieved'", "]", "\n", "\n", "", "return", "ep_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.relabel_episode": [[1004, 1034], ["ant_agents.GoalChainAgentPairGo._organize_episodes", "enumerate", "ant_agents.GoalChainAgentPairGo.a0.env.dist", "ant_agents.GoalChainAgentPairGo.a0.env.dist", "ant_agents.GoalChainAgentPairGo.distance[].append", "ant_agents.GoalChainAgentPairGo.distance_ag[].append", "ant_agents.GoalChainAgentPairGo._compress_me.append", "ant_agents.GoalChainAgentPairGo.a0.env.dist", "ant_agents.GoalChainAgentPairGo.a0.env.dist", "ant_agents.GoalChainAgentPairGo.item", "ant_agents.GoalChainAgentPairGo.item", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo._organize_episodes", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["", "def", "relabel_episode", "(", "self", ")", ":", "\n", "        ", "self", ".", "_compress_me", "=", "[", "]", "\n", "\n", "ep_dicts", "=", "self", ".", "_organize_episodes", "(", ")", "\n", "\n", "for", "rank", ",", "ep_dict", "in", "enumerate", "(", "ep_dicts", ")", ":", "\n", "            ", "for", "e", "in", "ep_dict", "[", "'ep'", "]", ":", "\n", "                ", "e", "[", "'antigoal'", "]", "=", "ep_dict", "[", "'antigoal'", "]", "\n", "\n", "dg_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'next_state'", "]", ",", "e", "[", "'goal'", "]", ")", "\n", "da_nxt", "=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'next_state'", "]", ",", "e", "[", "'antigoal'", "]", ")", "\n", "\n", "ddg", "=", "-", "dg_nxt", "\n", "dda", "=", "-", "da_nxt", "\n", "\n", "if", "self", ".", "ddiff", ":", "\n", "                    ", "ddg", "+=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'state'", "]", ",", "e", "[", "'goal'", "]", ")", "\n", "dda", "+=", "self", ".", "a0", ".", "env", ".", "dist", "(", "e", "[", "'state'", "]", ",", "e", "[", "'antigoal'", "]", ")", "\n", "\n", "", "r_sparse", "=", "1", "*", "e", "[", "'complete'", "]", "\n", "r_dense", "=", "ddg", "-", "(", "float", "(", "self", ".", "use_antigoal", ")", "*", "dda", ")", "\n", "\n", "e", "[", "'reward'", "]", "+=", "r_sparse", "+", "r_dense", "\n", "\n", "ai", "=", "ep_dict", "[", "'ai'", "]", "\n", "self", ".", "distance", "[", "ai", "]", ".", "append", "(", "dg_nxt", ".", "item", "(", ")", ")", "\n", "self", ".", "distance_ag", "[", "ai", "]", ".", "append", "(", "da_nxt", ".", "item", "(", ")", ")", "\n", "\n", "", "if", "rank", ">", "0", "or", "da_nxt", "<", "dg_nxt", "or", "self", ".", "agents", "[", "ep_dict", "[", "'ai'", "]", "]", ".", "env", ".", "is_success", ":", "\n", "                ", "self", ".", "_compress_me", ".", "append", "(", "ep_dict", "[", "'ep'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.compress_episode": [[1035, 1086], ["ant_agents.GoalChainAgentPairGo.v_module", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "reversed", "torch.zeros_like.detach", "torch.zeros_like.detach", "torch.zeros_like.detach", "batched_episodes.append", "len", "batched_episodes[].keys", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "range", "torch.zeros_like.detach", "torch.zeros_like.detach", "torch.zeros_like.detach", "batched_episode[].detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ant_agents.GoalChainAgentPairGo.v_module"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "", "def", "compress_episode", "(", "self", ")", ":", "\n", "        ", "keys", "=", "[", "\n", "'state'", ",", "'next_state'", ",", "'goal'", ",", "'antigoal'", ",", "\n", "'action'", ",", "'n_ent'", ",", "'log_prob'", ",", "'action_logit'", ",", "\n", "'reward'", ",", "'terminal'", ",", "'complete'", ",", "\n", "]", "\n", "batched_episodes", "=", "[", "]", "\n", "for", "ep", "in", "self", ".", "_compress_me", ":", "\n", "            ", "batched_episode", "=", "{", "key", ":", "torch", ".", "stack", "(", "[", "e", "[", "key", "]", "for", "e", "in", "ep", "]", ")", "for", "key", "in", "keys", "}", "\n", "\n", "batched_episode", "[", "'value'", "]", "=", "self", ".", "v_module", "(", "\n", "batched_episode", "[", "'state'", "]", ",", "\n", "batched_episode", "[", "'goal'", "]", ",", "\n", "batched_episode", "[", "'antigoal'", "]", "*", "self", ".", "value_antigoal_coeff", "\n", ")", "\n", "\n", "advs", "=", "torch", ".", "zeros_like", "(", "batched_episode", "[", "'reward'", "]", ")", "\n", "last_adv", "=", "0", "\n", "for", "t", "in", "reversed", "(", "range", "(", "advs", ".", "shape", "[", "0", "]", ")", ")", ":", "\n", "                ", "if", "t", "==", "advs", ".", "shape", "[", "0", "]", "-", "1", ":", "\n", "                    ", "has_next", "=", "1.0", "-", "batched_episode", "[", "'complete'", "]", "[", "t", "]", "# Is this a genuine terminal action?", "\n", "next_value", "=", "self", ".", "v_module", "(", "\n", "batched_episode", "[", "'next_state'", "]", "[", "-", "1", ":", "]", ",", "\n", "batched_episode", "[", "'goal'", "]", "[", "-", "1", ":", "]", ",", "\n", "batched_episode", "[", "'antigoal'", "]", "[", "-", "1", ":", "]", "*", "self", ".", "value_antigoal_coeff", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "has_next", "=", "1.0", "# By our setup, this cannot be a terminal action", "\n", "next_value", "=", "batched_episode", "[", "'value'", "]", "[", "t", "+", "1", "]", "\n", "\n", "", "delta", "=", "batched_episode", "[", "'reward'", "]", "[", "t", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "has_next", "-", "batched_episode", "[", "'value'", "]", "[", "t", "]", "\n", "advs", "[", "t", "]", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "has_next", "*", "last_adv", "\n", "last_adv", "=", "advs", "[", "t", "]", "\n", "\n", "", "batched_episode", "[", "'advantage'", "]", "=", "advs", ".", "detach", "(", ")", "\n", "batched_episode", "[", "'cumulative_return'", "]", "=", "advs", ".", "detach", "(", ")", "+", "batched_episode", "[", "'value'", "]", ".", "detach", "(", ")", "\n", "\n", "batched_episodes", ".", "append", "(", "batched_episode", ")", "\n", "\n", "", "if", "len", "(", "batched_episodes", ")", "==", "1", ":", "\n", "            ", "batched_ep", "=", "batched_episodes", "[", "0", "]", "\n", "\n", "", "else", ":", "\n", "            ", "keys", "=", "batched_episodes", "[", "0", "]", ".", "keys", "(", ")", "\n", "batched_ep", "=", "{", "\n", "k", ":", "torch", ".", "cat", "(", "[", "b_ep", "[", "k", "]", "for", "b_ep", "in", "batched_episodes", "]", ")", "for", "k", "in", "keys", "\n", "}", "\n", "\n", "", "self", ".", "_batched_ep", "=", "batched_ep", "\n", "\n", "return", "batched_ep", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.replay_loss": [[1087, 1135], ["ant_agents.GoalChainAgentPairGo.v_module", "v_losses.mean", "ant_agents.GoalChainAgentPairGo.policy", "n_ent.mean", "log_prob.sum.sum.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max.mean", "torch.max.mean", "torch.max.mean", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "mini_batch[].mean", "mini_batch[].mean", "mini_batch[].mean.item", "mini_batch[].mean.item", "v_losses.mean.item", "torch.max.mean.item", "n_ent.mean.item"], "methods", ["None"], ["", "def", "replay_loss", "(", "self", ",", "mini_batch", "=", "None", ")", ":", "\n", "        ", "if", "mini_batch", "is", "None", ":", "\n", "            ", "mini_batch", "=", "self", ".", "_batched_ep", "\n", "fill_summary", "=", "True", "\n", "", "else", ":", "\n", "            ", "fill_summary", "=", "False", "\n", "\n", "# sum_w = torch.sum(mini_batch['weight'])", "\n", "\n", "", "value", "=", "self", ".", "v_module", "(", "\n", "mini_batch", "[", "'state'", "]", ",", "\n", "mini_batch", "[", "'goal'", "]", ",", "\n", "mini_batch", "[", "'antigoal'", "]", "*", "self", ".", "value_antigoal_coeff", "\n", ")", "\n", "v_losses", "=", "0.5", "*", "torch", ".", "pow", "(", "mini_batch", "[", "'cumulative_return'", "]", "-", "value", ",", "2", ")", "\n", "v_loss", "=", "v_losses", ".", "mean", "(", ")", "\n", "# v_loss = torch.mean(v_losses * mini_batch['weight'])", "\n", "\n", "log_prob", ",", "n_ent", ",", "greedy_action", "=", "self", ".", "policy", "(", "\n", "mini_batch", "[", "'state'", "]", ",", "mini_batch", "[", "'goal'", "]", ",", "\n", "action_logit", "=", "mini_batch", "[", "'action_logit'", "]", "\n", ")", "\n", "e_loss", "=", "n_ent", ".", "mean", "(", ")", "\n", "# e_loss = torch.mean(n_ent * mini_batch['weight'])", "\n", "\n", "# Defining Loss = - J is equivalent to max J", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", "dim", "=", "1", ")", "\n", "ratio", "=", "torch", ".", "exp", "(", "log_prob", "-", "mini_batch", "[", "'log_prob'", "]", ")", "\n", "\n", "pg_losses1", "=", "-", "mini_batch", "[", "'advantage'", "]", "*", "ratio", "\n", "pg_losses2", "=", "-", "mini_batch", "[", "'advantage'", "]", "*", "torch", ".", "clamp", "(", "ratio", ",", "1.0", "-", "self", ".", "clip_range", ",", "1.0", "+", "self", ".", "clip_range", ")", "\n", "p_losses", "=", "torch", ".", "max", "(", "pg_losses1", ",", "pg_losses2", ")", "\n", "p_loss", "=", "p_losses", ".", "mean", "(", ")", "\n", "# p_loss = torch.mean(p_losses * mini_batch['weight'])", "\n", "\n", "loss", "=", "v_loss", "+", "p_loss", "+", "(", "self", ".", "entropy_lambda", "*", "e_loss", ")", "\n", "\n", "if", "fill_summary", ":", "\n", "            ", "succeeded", "=", "self", ".", "avg_success", "\n", "dist_to_g", "=", "self", ".", "avg_dist_to_goal", "\n", "dist_to_a", "=", "self", ".", "avg_dist_to_antigoal", "\n", "avg_r", "=", "mini_batch", "[", "'reward'", "]", ".", "mean", "(", ")", "\n", "avg_v", "=", "mini_batch", "[", "'value'", "]", ".", "mean", "(", ")", "\n", "self", ".", "_ep_summary", "=", "[", "\n", "succeeded", ",", "dist_to_g", ",", "dist_to_a", ",", "avg_r", ".", "item", "(", ")", ",", "avg_v", ".", "item", "(", ")", ",", "v_loss", ".", "item", "(", ")", ",", "p_loss", ".", "item", "(", ")", ",", "e_loss", ".", "item", "(", ")", "\n", "]", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.forward": [[1136, 1138], ["ant_agents.GoalChainAgentPairGo.replay_loss"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.replay_loss"], ["", "def", "forward", "(", "self", ",", "mini_batch", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "replay_loss", "(", "mini_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.episode_summary": [[1139, 1145], ["ant_agents.GoalChainAgentPairGo.compress_episode", "ant_agents.GoalChainAgentPairGo.replay_loss", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.compress_episode", "home.repos.pwc.inspect_result.spitis_mrl.ant_maze.ant_agents.GoalChainAgentPairGo.replay_loss"], ["", "def", "episode_summary", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "_batched_ep", ":", "\n", "            ", "_", "=", "self", ".", "compress_episode", "(", ")", "\n", "", "if", "not", "self", ".", "_ep_summary", ":", "\n", "            ", "_", "=", "self", ".", "replay_loss", "(", ")", "\n", "", "return", "[", "float", "(", "x", ")", "for", "x", "in", "self", ".", "_ep_summary", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.__init__": [[12, 54], ["maze_type.lower", "bool", "maze_env.Env.maze_type.startswith", "maze_env.Env.maze_type.startswith", "maze_env.Env.maze_type.startswith", "maze_env.Env.maze_type.startswith", "bool", "bool", "dict", "maze_env.Env.reset", "maze_env.Env.maze_type.split", "int", "int", "maze_env.Env.maze_type.split", "int", "int", "int", "int", "int", "envs.sibrivalry.toy_maze.mazes.make_crazy_maze", "envs.sibrivalry.toy_maze.mazes.make_experiment_maze", "envs.sibrivalry.toy_maze.mazes.make_hallway_maze", "envs.sibrivalry.toy_maze.mazes.make_u_maze", "maze_env.Env.maze_type.split", "maze_env.Env.maze_type.split"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_crazy_maze", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_experiment_maze", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_hallway_maze", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_u_maze"], ["# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n", "# ==============================================================================", "\n", "\n", "\"\"\"Adapted from rllab maze_env.py.\"\"\"", "\n", "\n", "import", "os", "\n", "import", "tempfile", "\n", "import", "xml", ".", "etree", ".", "ElementTree", "as", "ET", "\n", "import", "math", "\n", "import", "numpy", "as", "np", "\n", "import", "gym", "\n", "import", "random", "\n", "\n", "from", "envs", ".", "goalgan", ".", "ant_maze", "import", "maze_env_utils", "\n", "\n", "# Directory that contains mujoco xml files.", "\n", "MODEL_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'assets'", ")", "\n", "\n", "\n", "class", "MazeEnv", "(", "gym", ".", "Env", ")", ":", "\n", "  ", "MODEL_CLASS", "=", "None", "\n", "\n", "MAZE_HEIGHT", "=", "None", "\n", "MAZE_SIZE_SCALING", "=", "None", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "model_dir", "=", "None", ",", "\n", "maze_id", "=", "None", ",", "\n", "maze_height", "=", "0.5", ",", "\n", "maze_size_scaling", "=", "8", ",", "\n", "n_bins", "=", "0", ",", "\n", "sensor_range", "=", "3.", ",", "\n", "sensor_span", "=", "2", "*", "math", ".", "pi", ",", "\n", "observe_blocks", "=", "False", ",", "\n", "put_spin_near_agent", "=", "False", ",", "\n", "top_down_view", "=", "False", ",", "\n", "manual_collision", "=", "False", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "_maze_id", "=", "maze_id", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.state_size": [[55, 58], ["None"], "methods", ["None"], ["model_cls", "=", "self", ".", "__class__", ".", "MODEL_CLASS", "\n", "if", "model_cls", "is", "None", ":", "\n", "      ", "raise", "\"MODEL_CLASS unspecified!\"", "\n", "", "xml_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DIR", "if", "model_dir", "is", "None", "else", "model_dir", ",", "model_cls", ".", "FILE", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.goal_size": [[59, 62], ["None"], "methods", ["None"], ["tree", "=", "ET", ".", "parse", "(", "xml_path", ")", "\n", "worldbody", "=", "tree", ".", "find", "(", "\".//worldbody\"", ")", "\n", "\n", "self", ".", "MAZE_HEIGHT", "=", "height", "=", "maze_height", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.action_size": [[63, 66], ["None"], "methods", ["None"], ["self", ".", "MAZE_SIZE_SCALING", "=", "size_scaling", "=", "maze_size_scaling", "\n", "self", ".", "_n_bins", "=", "n_bins", "\n", "self", ".", "_sensor_range", "=", "sensor_range", "*", "size_scaling", "\n", "self", ".", "_sensor_span", "=", "sensor_span", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor": [[67, 70], ["torch.FloatTensor"], "methods", ["None"], ["self", ".", "_observe_blocks", "=", "observe_blocks", "\n", "self", ".", "_put_spin_near_agent", "=", "put_spin_near_agent", "\n", "self", ".", "_top_down_view", "=", "top_down_view", "\n", "self", ".", "_manual_collision", "=", "manual_collision", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_coords": [[71, 78], ["isinstance", "isinstance", "x.data.numpy.data.numpy.data.numpy", "float", "float"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.Agent.numpy"], ["\n", "self", ".", "MAZE_STRUCTURE", "=", "structure", "=", "maze_env_utils", ".", "construct_maze", "(", "maze_id", "=", "self", ".", "_maze_id", ")", "\n", "self", ".", "elevated", "=", "any", "(", "-", "1", "in", "row", "for", "row", "in", "structure", ")", "# Elevate the maze to allow for falling.", "\n", "self", ".", "blocks", "=", "any", "(", "\n", "any", "(", "maze_env_utils", ".", "can_move", "(", "r", ")", "for", "r", "in", "row", ")", "\n", "for", "row", "in", "structure", ")", "# Are there any movable blocks?", "\n", "\n", "torso_x", ",", "torso_y", "=", "self", ".", "_find_robot", "(", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist": [[79, 83], ["torch.sqrt", "torch.sum", "torch.pow"], "methods", ["None"], ["self", ".", "_init_torso_x", "=", "torso_x", "\n", "self", ".", "_init_torso_y", "=", "torso_y", "\n", "self", ".", "_init_positions", "=", "[", "\n", "(", "x", "-", "torso_x", ",", "y", "-", "torso_y", ")", "\n", "for", "x", ",", "y", "in", "self", ".", "_find_all_robots", "(", ")", "]", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.maze": [[84, 87], ["None"], "methods", ["None"], ["\n", "self", ".", "_xy_to_rowcol", "=", "lambda", "x", ",", "y", ":", "(", "2", "+", "(", "y", "+", "size_scaling", "/", "2", ")", "/", "size_scaling", ",", "\n", "2", "+", "(", "x", "+", "size_scaling", "/", "2", ")", "/", "size_scaling", ")", "\n", "self", ".", "_view", "=", "np", ".", "zeros", "(", "[", "5", ",", "5", ",", "3", "]", ")", "# walls (immovable), chasms (fall), movable blocks", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.action_range": [[88, 91], ["None"], "methods", ["None"], ["\n", "height_offset", "=", "0.", "\n", "if", "self", ".", "elevated", ":", "\n", "# Increase initial z-pos of ant.", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.state": [[92, 95], ["maze_env.Env._state[].view().detach", "maze_env.Env._state[].view"], "methods", ["None"], ["      ", "height_offset", "=", "height", "*", "size_scaling", "\n", "torso", "=", "tree", ".", "find", "(", "\".//body[@name='torso']\"", ")", "\n", "torso", ".", "set", "(", "'pos'", ",", "'0 0 %.2f'", "%", "(", "0.75", "+", "height_offset", ")", ")", "\n", "", "if", "self", ".", "blocks", ":", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.goal": [[96, 99], ["maze_env.Env._state[].view().detach", "maze_env.Env._state[].view"], "methods", ["None"], ["# If there are movable blocks, change simulation settings to perform", "\n", "# better contact detection.", "\n", "      ", "default", "=", "tree", ".", "find", "(", "\".//default\"", ")", "\n", "default", ".", "find", "(", "'.//geom'", ")", ".", "set", "(", "'solimp'", ",", "'.995 .995 .01'", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.antigoal": [[100, 103], ["maze_env.Env._state[].view().detach", "maze_env.Env._state[].view"], "methods", ["None"], ["\n", "", "self", ".", "movable_blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.reward": [[104, 118], ["float", "maze_env.Env.dist", "maze_env.Env.dist", "torch.ones", "torch.clamp", "maze_env.Env.dist", "maze_env.Env.dist"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["        ", "struct", "=", "structure", "[", "i", "]", "[", "j", "]", "\n", "if", "struct", "==", "'r'", "and", "self", ".", "_put_spin_near_agent", ":", "\n", "          ", "struct", "=", "maze_env_utils", ".", "Move", ".", "SpinXY", "\n", "", "if", "self", ".", "elevated", "and", "struct", "not", "in", "[", "-", "1", "]", ":", "\n", "# Create elevated platform.", "\n", "          ", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "\n", "name", "=", "\"elevated_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", ",", "\n", "0.5", "*", "size_scaling", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.achieved": [[119, 122], ["None"], "methods", ["None"], ["material", "=", "\"\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.9 0.9 0.9 1\"", ",", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.is_done": [[123, 126], ["bool"], "methods", ["None"], [")", "\n", "", "if", "struct", "==", "1", ":", "# Unmovable block.", "\n", "# Offset all coordinates so that robot starts at the origin.", "\n", "          ", "ET", ".", "SubElement", "(", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.is_success": [[127, 131], ["maze_env.Env.dist"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist"], ["worldbody", ",", "\"geom\"", ",", "\n", "name", "=", "\"block_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", ",", "\n", "height_offset", "+", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.d_goal_0": [[132, 135], ["maze_env.Env._state[].item"], "methods", ["None"], ["height", "/", "2", "*", "size_scaling", ")", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", ",", "\n", "0.5", "*", "size_scaling", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.d_antigoal_0": [[136, 139], ["maze_env.Env._state[].item"], "methods", ["None"], ["type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.next_phase_reset": [[140, 143], ["maze_env.Env._state[].detach"], "methods", ["None"], ["rgba", "=", "\"0.4 0.4 0.4 1\"", ",", "\n", ")", "\n", "", "elif", "maze_env_utils", ".", "can_move", "(", "struct", ")", ":", "# Movable block.", "\n", "# The \"falling\" blocks are shrunk slightly and increased in mass to", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.sibling_reset": [[144, 147], ["maze_env.Env._state[].detach"], "methods", ["None"], ["# ensure that it can fall easily through a gap in the platform blocks.", "\n", "          ", "name", "=", "\"movable_%d_%d\"", "%", "(", "i", ",", "j", ")", "\n", "self", ".", "movable_blocks", ".", "append", "(", "(", "name", ",", "struct", ")", ")", "\n", "falling", "=", "maze_env_utils", ".", "can_move_z", "(", "struct", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.reset": [[148, 176], ["maze_env.Env.to_tensor", "maze_env.Env.to_tensor", "maze_env.Env.to_tensor", "maze_env.Env.to_tensor", "maze_env.Env.to_tensor", "maze_env.Env.dist", "maze_env.Env.dist", "maze_env.Env.maze.sample_start", "maze_env.Env.to_tensor", "maze_env.Env.to_tensor", "torch.ones_like", "torch.ones_like", "maze_env.Env.maze.sample_goal", "maze_env.Env.maze.sample_goal"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.dist", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_start", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal"], ["spinning", "=", "maze_env_utils", ".", "can_spin", "(", "struct", ")", "\n", "x_offset", "=", "0.25", "*", "size_scaling", "if", "spinning", "else", "0.0", "\n", "y_offset", "=", "0.0", "\n", "shrink", "=", "0.1", "if", "spinning", "else", "0.99", "if", "falling", "else", "1.0", "\n", "height_shrink", "=", "0.1", "if", "spinning", "else", "1.0", "\n", "movable_body", "=", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"body\"", ",", "\n", "name", "=", "name", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", "+", "x_offset", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", "+", "y_offset", ",", "\n", "height_offset", "+", "\n", "height", "/", "2", "*", "size_scaling", "*", "height_shrink", ")", ",", "\n", ")", "\n", "ET", ".", "SubElement", "(", "\n", "movable_body", ",", "\"geom\"", ",", "\n", "name", "=", "\"block_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", "*", "shrink", ",", "\n", "0.5", "*", "size_scaling", "*", "shrink", ",", "\n", "height", "/", "2", "*", "size_scaling", "*", "height_shrink", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "mass", "=", "\"0.001\"", "if", "falling", "else", "\"0.0002\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.9 0.1 0.1 1\"", "\n", ")", "\n", "if", "maze_env_utils", ".", "can_move_x", "(", "struct", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.step": [[178, 192], ["maze_env.Env.to_tensor", "maze_env.Env.to_tensor", "maze_env.Env.maze.move", "maze_env.Env.to_coords", "maze_env.Env.to_coords", "print", "print", "maze_env.Env.to_coords", "maze_env.Env.to_coords"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_tensor", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_coords", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_coords", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_coords", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.maze_env.Env.to_coords"], ["armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"1 0 0\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"true\"", "if", "falling", "else", "\"false\"", ",", "\n", "range", "=", "\"%f %f\"", "%", "(", "-", "size_scaling", ",", "size_scaling", ")", ",", "\n", "margin", "=", "\"0.01\"", ",", "\n", "name", "=", "\"movable_x_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"slide\"", "\n", ")", "\n", "", "if", "maze_env_utils", ".", "can_move_y", "(", "struct", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "movable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"0 1 0\"", ",", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.Obstacle.__init__": [[14, 17], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.Obstacle.in_collision": [[18, 27], ["len", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.Obstacle.get_patch": [[29, 39], ["matplotlib.patches.Rectangle"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.__init__": [[43, 67], ["numpy.array", "gym.spaces.Discrete", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Dict", "__init__.SimpleMazeEnv.get_free_point", "__init__.SimpleMazeEnv.get_free_point", "__init__.Obstacle", "__init__.Obstacle", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.get_free_point", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.get_free_point"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.seed": [[68, 70], ["numpy.random.seed"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.compute_reward": [[71, 76], ["numpy.linalg.norm", "__init__.SimpleMazeEnv.in_collision"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.in_collision"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.render": [[77, 79], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.step": [[80, 107], ["numpy.clip", "__init__.SimpleMazeEnv.compute_reward", "numpy.allclose", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.in_collision": [[108, 110], ["numpy.any", "x.in_collision"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.in_collision"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.get_free_point": [[111, 121], ["numpy.random.rand", "__init__.SimpleMazeEnv.in_collision", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.in_collision"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.reset": [[122, 130], ["__init__.SimpleMazeEnv.get_free_point", "__init__.SimpleMazeEnv.get_free_point"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.get_free_point", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.SimpleMazeEnv.get_free_point"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.__init__": [[137, 157], ["gym.GoalEnv.__init__", "maze_env.Env", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Dict", "numpy.array", "numpy.array", "__init__.PointMaze2D.maze.sample_start", "__init__.PointMaze2D.maze.sample_goal"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_start", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.seed": [[158, 160], ["__init__.PointMaze2D.maze.seed"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.step": [[161, 191], ["__init__.PointMaze2D.compute_reward", "numpy.array", "numpy.allclose", "numpy.allclose", "__init__.PointMaze2D.maze.move", "print", "tuple", "tuple", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.reset": [[192, 202], ["numpy.array", "numpy.array", "__init__.PointMaze2D.maze.sample_start", "__init__.PointMaze2D.maze.sample_goal"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_start", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.render": [[204, 206], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.__init__.PointMaze2D.compute_reward": [[207, 210], ["numpy.linalg.norm"], "methods", ["None"], []], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.__init__": [[11, 23], ["float", "float", "float", "float", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "ring_r", "=", "0.15", "\n", "self", ".", "stop_t", "=", "0.05", "\n", "self", ".", "s_angle", "=", "30", "\n", "\n", "self", ".", "mean_s0", "=", "(", "\n", "float", "(", "np", ".", "cos", "(", "np", ".", "pi", "*", "self", ".", "s_angle", "/", "180", ")", ")", ",", "\n", "float", "(", "np", ".", "sin", "(", "np", ".", "pi", "*", "self", ".", "s_angle", "/", "180", ")", ")", "\n", ")", "\n", "self", ".", "mean_g", "=", "(", "\n", "float", "(", "np", ".", "cos", "(", "np", ".", "pi", "*", "(", "360", "-", "self", ".", "s_angle", ")", "/", "180", ")", ")", ",", "\n", "float", "(", "np", ".", "sin", "(", "np", ".", "pi", "*", "(", "360", "-", "self", ".", "s_angle", ")", "/", "180", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.plot": [[25, 42], ["numpy.linspace", "ax.plot", "ax.plot", "ax.plot", "ax.plot", "ax.set_xlim", "ax.set_ylim", "matplotlib.subplots", "matplotlib.subplots", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot"], ["", "def", "plot", "(", "self", ",", "ax", "=", "None", ")", ":", "\n", "        ", "if", "ax", "is", "None", ":", "\n", "            ", "_", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "5", ",", "4", ")", ")", "\n", "", "if", "ax", "is", "None", ":", "\n", "            ", "_", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "5", ",", "4", ")", ")", "\n", "", "rads", "=", "np", ".", "linspace", "(", "self", ".", "stop_t", "*", "2", "*", "np", ".", "pi", ",", "(", "1", "-", "self", ".", "stop_t", ")", "*", "2", "*", "np", ".", "pi", ")", "\n", "xs_i", "=", "(", "1", "-", "self", ".", "ring_r", ")", "*", "np", ".", "cos", "(", "rads", ")", "\n", "ys_i", "=", "(", "1", "-", "self", ".", "ring_r", ")", "*", "np", ".", "sin", "(", "rads", ")", "\n", "xs_o", "=", "(", "1", "+", "self", ".", "ring_r", ")", "*", "np", ".", "cos", "(", "rads", ")", "\n", "ys_o", "=", "(", "1", "+", "self", ".", "ring_r", ")", "*", "np", ".", "sin", "(", "rads", ")", "\n", "ax", ".", "plot", "(", "xs_i", ",", "ys_i", ",", "'k'", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "plot", "(", "xs_o", ",", "ys_o", ",", "'k'", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "plot", "(", "[", "xs_i", "[", "0", "]", ",", "xs_o", "[", "0", "]", "]", ",", "[", "ys_i", "[", "0", "]", ",", "ys_o", "[", "0", "]", "]", ",", "'k'", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "plot", "(", "[", "xs_i", "[", "-", "1", "]", ",", "xs_o", "[", "-", "1", "]", "]", ",", "[", "ys_i", "[", "-", "1", "]", ",", "ys_o", "[", "-", "1", "]", "]", ",", "'k'", ",", "linewidth", "=", "3", ")", "\n", "lim", "=", "1.1", "+", "self", ".", "ring_r", "\n", "ax", ".", "set_xlim", "(", "[", "-", "lim", ",", "lim", "]", ")", "\n", "ax", ".", "set_ylim", "(", "[", "-", "lim", ",", "lim", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.sample_start": [[43, 46], ["mazes.CircleMaze.move", "numpy.random.randn", "numpy.random.randn"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move"], ["", "def", "sample_start", "(", "self", ")", ":", "\n", "        ", "STD", "=", "0.1", "\n", "return", "self", ".", "move", "(", "self", ".", "mean_s0", ",", "(", "STD", "*", "np", ".", "random", ".", "randn", "(", ")", ",", "STD", "*", "np", ".", "random", ".", "randn", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.sample_goal": [[47, 50], ["mazes.CircleMaze.move", "numpy.random.randn", "numpy.random.randn"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move"], ["", "def", "sample_goal", "(", "self", ")", ":", "\n", "        ", "STD", "=", "0.1", "\n", "return", "self", ".", "move", "(", "self", ".", "mean_g", ",", "(", "STD", "*", "np", ".", "random", ".", "randn", "(", ")", ",", "STD", "*", "np", ".", "random", ".", "randn", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.xy_to_rt": [[51, 58], ["numpy.sqrt", "numpy.arctan2"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "xy_to_rt", "(", "xy", ")", ":", "\n", "        ", "x", "=", "xy", "[", "0", "]", "\n", "y", "=", "xy", "[", "1", "]", "\n", "r", "=", "np", ".", "sqrt", "(", "x", "**", "2", "+", "y", "**", "2", ")", "\n", "t", "=", "np", ".", "arctan2", "(", "y", ",", "x", ")", "%", "(", "2", "*", "np", ".", "pi", ")", "\n", "return", "r", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.move": [[59, 105], ["mazes.CircleMaze.xy_to_rt", "mazes.CircleMaze.xy_to_rt", "numpy.clip", "numpy.array().astype", "float", "float", "numpy.clip", "numpy.clip", "numpy.cos", "numpy.sin", "mazes.CircleMaze.move.r_ok"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.xy_to_rt", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.CircleMaze.xy_to_rt"], ["", "def", "move", "(", "self", ",", "coords", ",", "action", ")", ":", "\n", "        ", "xp", ",", "yp", "=", "coords", "\n", "rp", ",", "tp", "=", "self", ".", "xy_to_rt", "(", "coords", ")", "\n", "\n", "xy", "=", "(", "coords", "[", "0", "]", "+", "action", "[", "0", "]", ",", "coords", "[", "1", "]", "+", "action", "[", "1", "]", ")", "\n", "\n", "r", ",", "t", "=", "self", ".", "xy_to_rt", "(", "xy", ")", "\n", "t", "=", "np", ".", "clip", "(", "t", "%", "(", "2", "*", "np", ".", "pi", ")", ",", "(", "0.001", "+", "self", ".", "stop_t", ")", "*", "(", "2", "*", "np", ".", "pi", ")", ",", "(", "1", "-", "(", "0.001", "+", "self", ".", "stop_t", ")", ")", "*", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "x", "=", "np", ".", "cos", "(", "t", ")", "*", "r", "\n", "y", "=", "np", ".", "sin", "(", "t", ")", "*", "r", "\n", "\n", "if", "coords", "is", "not", "None", ":", "\n", "\n", "            ", "if", "xp", ">", "0", ":", "\n", "                ", "if", "(", "y", "<", "0", ")", "and", "(", "yp", ">", "0", ")", ":", "\n", "                    ", "t", "=", "self", ".", "stop_t", "*", "2", "*", "np", ".", "pi", "\n", "", "elif", "(", "y", ">", "0", ")", "and", "(", "yp", "<", "0", ")", ":", "\n", "                    ", "t", "=", "(", "1", "-", "self", ".", "stop_t", ")", "*", "2", "*", "np", ".", "pi", "\n", "", "", "x", "=", "np", ".", "cos", "(", "t", ")", "*", "r", "\n", "y", "=", "np", ".", "sin", "(", "t", ")", "*", "r", "\n", "\n", "", "n", "=", "8", "\n", "xyi", "=", "np", ".", "array", "(", "[", "xp", ",", "yp", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dxy", "=", "(", "np", ".", "array", "(", "[", "x", ",", "y", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "-", "xyi", ")", "/", "n", "\n", "new_r", "=", "float", "(", "rp", ")", "\n", "new_t", "=", "float", "(", "tp", ")", "\n", "\n", "count", "=", "0", "\n", "\n", "def", "r_ok", "(", "r_", ")", ":", "\n", "            ", "return", "(", "1", "-", "self", ".", "ring_r", ")", "<=", "r_", "<=", "(", "1", "+", "self", ".", "ring_r", ")", "\n", "\n", "", "def", "t_ok", "(", "t_", ")", ":", "\n", "            ", "return", "(", "self", ".", "stop_t", "*", "(", "2", "*", "np", ".", "pi", ")", ")", "<=", "(", "t_", "%", "(", "2", "*", "np", ".", "pi", ")", ")", "<=", "(", "(", "1", "-", "self", ".", "stop_t", ")", "*", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "\n", "", "while", "r_ok", "(", "new_r", ")", "and", "t_ok", "(", "new_t", ")", "and", "count", "<", "n", ":", "\n", "            ", "xyi", "+=", "dxy", "\n", "new_r", ",", "new_t", "=", "self", ".", "xy_to_rt", "(", "xyi", ")", "\n", "count", "+=", "1", "\n", "\n", "", "r", "=", "np", ".", "clip", "(", "new_r", ",", "1", "-", "self", ".", "ring_r", "+", "0.01", ",", "1", "+", "self", ".", "ring_r", "-", "0.01", ")", "\n", "t", "=", "np", ".", "clip", "(", "new_t", "%", "(", "2", "*", "np", ".", "pi", ")", ",", "(", "0.001", "+", "self", ".", "stop_t", ")", "*", "(", "2", "*", "np", ".", "pi", ")", ",", "(", "1", "-", "(", "0.001", "+", "self", ".", "stop_t", ")", ")", "*", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "x", "=", "np", ".", "cos", "(", "t", ")", "*", "r", "\n", "y", "=", "np", ".", "sin", "(", "t", ")", "*", "r", "\n", "\n", "return", "float", "(", "x", ")", ",", "float", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.__init__": [[108, 140], ["set", "mazes.Maze._locs.add", "set", "mazes.Maze._finalize", "mazes.Maze.seed", "mazes.Maze._walls.add", "isinstance", "isinstance", "mazes.Maze._add_segment", "set", "mazes.Maze._wall_line", "isinstance", "isinstance", "goal_squares.lower", "start_squares.lower", "gs.lower", "ss.lower"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._finalize", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._add_segment", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._wall_line"], ["    ", "def", "__init__", "(", "self", ",", "*", "segment_dicts", ",", "goal_squares", "=", "None", ",", "start_squares", "=", "None", ")", ":", "\n", "        ", "self", ".", "_segments", "=", "{", "'origin'", ":", "{", "'loc'", ":", "(", "0.0", ",", "0.0", ")", ",", "'connect'", ":", "set", "(", ")", "}", "}", "\n", "self", ".", "_locs", "=", "set", "(", ")", "\n", "self", ".", "_locs", ".", "add", "(", "self", ".", "_segments", "[", "'origin'", "]", "[", "'loc'", "]", ")", "\n", "self", ".", "_walls", "=", "set", "(", ")", "\n", "for", "direction", "in", "[", "'up'", ",", "'down'", ",", "'left'", ",", "'right'", "]", ":", "\n", "            ", "self", ".", "_walls", ".", "add", "(", "self", ".", "_wall_line", "(", "self", ".", "_segments", "[", "'origin'", "]", "[", "'loc'", "]", ",", "direction", ")", ")", "\n", "", "self", ".", "_last_segment", "=", "'origin'", "\n", "self", ".", "goal_squares", "=", "None", "\n", "\n", "if", "goal_squares", "is", "None", ":", "\n", "            ", "self", ".", "_goal_squares", "=", "None", "\n", "", "elif", "isinstance", "(", "goal_squares", ",", "str", ")", ":", "\n", "            ", "self", ".", "_goal_squares", "=", "[", "goal_squares", ".", "lower", "(", ")", "]", "\n", "", "elif", "isinstance", "(", "goal_squares", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "self", ".", "_goal_squares", "=", "[", "gs", ".", "lower", "(", ")", "for", "gs", "in", "goal_squares", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "\n", "\n", "", "if", "start_squares", "is", "None", ":", "\n", "            ", "self", ".", "start_squares", "=", "[", "'origin'", "]", "\n", "", "elif", "isinstance", "(", "start_squares", ",", "str", ")", ":", "\n", "            ", "self", ".", "start_squares", "=", "[", "start_squares", ".", "lower", "(", ")", "]", "\n", "", "elif", "isinstance", "(", "start_squares", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "self", ".", "start_squares", "=", "[", "ss", ".", "lower", "(", ")", "for", "ss", "in", "start_squares", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "\n", "\n", "", "for", "segment_dict", "in", "segment_dicts", ":", "\n", "            ", "self", ".", "_add_segment", "(", "**", "segment_dict", ")", "\n", "", "self", ".", "_finalize", "(", ")", "\n", "self", ".", "seed", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed": [[141, 144], ["gym.utils.seeding.np_random"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "np_random", ",", "seed", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "return", "[", "seed", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._wall_line": [[145, 160], ["tuple", "tuple", "sorted"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_wall_line", "(", "coord", ",", "direction", ")", ":", "\n", "        ", "x", ",", "y", "=", "coord", "\n", "if", "direction", "==", "'up'", ":", "\n", "            ", "w", "=", "[", "(", "x", "-", "0.5", ",", "x", "+", "0.5", ")", ",", "(", "y", "+", "0.5", ",", "y", "+", "0.5", ")", "]", "\n", "", "elif", "direction", "==", "'right'", ":", "\n", "            ", "w", "=", "[", "(", "x", "+", "0.5", ",", "x", "+", "0.5", ")", ",", "(", "y", "+", "0.5", ",", "y", "-", "0.5", ")", "]", "\n", "", "elif", "direction", "==", "'down'", ":", "\n", "            ", "w", "=", "[", "(", "x", "-", "0.5", ",", "x", "+", "0.5", ")", ",", "(", "y", "-", "0.5", ",", "y", "-", "0.5", ")", "]", "\n", "", "elif", "direction", "==", "'left'", ":", "\n", "            ", "w", "=", "[", "(", "x", "-", "0.5", ",", "x", "-", "0.5", ")", ",", "(", "y", "-", "0.5", ",", "y", "+", "0.5", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "", "w", "=", "tuple", "(", "[", "tuple", "(", "sorted", "(", "line", ")", ")", "for", "line", "in", "w", "]", ")", "\n", "return", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._add_segment": [[161, 217], ["str().lower", "str().lower", "str().lower", "str().lower", "set", "mazes.Maze._locs.add", "str().lower", "range", "isinstance", "set.add", "mazes.Maze._walls.add", "str", "str", "mazes.Maze._add_segment", "str", "str", "str", "str().lower", "set.add", "isinstance", "set.add", "mazes.Maze._wall_line", "str", "str", "set.add", "this_name.lower", "str", "str().lower", "set.add", "set.add", "str"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._add_segment", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._wall_line", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.ReplayBuffer.add"], ["", "def", "_add_segment", "(", "self", ",", "name", ",", "anchor", ",", "direction", ",", "connect", "=", "None", ",", "times", "=", "1", ")", ":", "\n", "        ", "name", "=", "str", "(", "name", ")", ".", "lower", "(", ")", "\n", "original_name", "=", "str", "(", "name", ")", ".", "lower", "(", ")", "\n", "if", "times", ">", "1", ":", "\n", "            ", "assert", "connect", "is", "None", "\n", "last_name", "=", "str", "(", "anchor", ")", ".", "lower", "(", ")", "\n", "for", "time", "in", "range", "(", "times", ")", ":", "\n", "                ", "this_name", "=", "original_name", "+", "str", "(", "time", ")", "\n", "self", ".", "_add_segment", "(", "name", "=", "this_name", ".", "lower", "(", ")", ",", "anchor", "=", "last_name", ",", "direction", "=", "direction", ")", "\n", "last_name", "=", "str", "(", "this_name", ")", "\n", "", "return", "\n", "\n", "", "anchor", "=", "str", "(", "anchor", ")", ".", "lower", "(", ")", "\n", "assert", "anchor", "in", "self", ".", "_segments", "\n", "\n", "direction", "=", "str", "(", "direction", ")", ".", "lower", "(", ")", "\n", "\n", "final_connect", "=", "set", "(", ")", "\n", "\n", "if", "connect", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "connect", ",", "str", ")", ":", "\n", "                ", "connect", "=", "str", "(", "connect", ")", ".", "lower", "(", ")", "\n", "assert", "connect", "in", "[", "'up'", ",", "'down'", ",", "'left'", ",", "'right'", "]", "\n", "final_connect", ".", "add", "(", "connect", ")", "\n", "", "elif", "isinstance", "(", "connect", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "                ", "for", "connect_direction", "in", "connect", ":", "\n", "                    ", "connect_direction", "=", "str", "(", "connect_direction", ")", ".", "lower", "(", ")", "\n", "assert", "connect_direction", "in", "[", "'up'", ",", "'down'", ",", "'left'", ",", "'right'", "]", "\n", "final_connect", ".", "add", "(", "connect_direction", ")", "\n", "\n", "", "", "", "sx", ",", "sy", "=", "self", ".", "_segments", "[", "anchor", "]", "[", "'loc'", "]", "\n", "dx", ",", "dy", "=", "0.0", ",", "0.0", "\n", "if", "direction", "==", "'left'", ":", "\n", "            ", "dx", "-=", "1", "\n", "final_connect", ".", "add", "(", "'right'", ")", "\n", "", "elif", "direction", "==", "'right'", ":", "\n", "            ", "dx", "+=", "1", "\n", "final_connect", ".", "add", "(", "'left'", ")", "\n", "", "elif", "direction", "==", "'up'", ":", "\n", "            ", "dy", "+=", "1", "\n", "final_connect", ".", "add", "(", "'down'", ")", "\n", "", "elif", "direction", "==", "'down'", ":", "\n", "            ", "dy", "-=", "1", "\n", "final_connect", ".", "add", "(", "'up'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "\n", "", "new_loc", "=", "(", "sx", "+", "dx", ",", "sy", "+", "dy", ")", "\n", "assert", "new_loc", "not", "in", "self", ".", "_locs", "\n", "\n", "self", ".", "_segments", "[", "name", "]", "=", "{", "'loc'", ":", "new_loc", ",", "'connect'", ":", "final_connect", "}", "\n", "for", "direction", "in", "[", "'up'", ",", "'down'", ",", "'left'", ",", "'right'", "]", ":", "\n", "            ", "self", ".", "_walls", ".", "add", "(", "self", ".", "_wall_line", "(", "new_loc", ",", "direction", ")", ")", "\n", "", "self", ".", "_locs", ".", "add", "(", "new_loc", ")", "\n", "\n", "self", ".", "_last_segment", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._finalize": [[218, 232], ["mazes.Maze._segments.values", "list", "mazes.Maze._wall_line", "mazes.Maze.goal_squares.append", "mazes.Maze._walls.remove"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._wall_line", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "_finalize", "(", "self", ")", ":", "\n", "        ", "for", "segment", "in", "self", ".", "_segments", ".", "values", "(", ")", ":", "\n", "            ", "for", "c_dir", "in", "list", "(", "segment", "[", "'connect'", "]", ")", ":", "\n", "                ", "wall", "=", "self", ".", "_wall_line", "(", "segment", "[", "'loc'", "]", ",", "c_dir", ")", "\n", "if", "wall", "in", "self", ".", "_walls", ":", "\n", "                    ", "self", ".", "_walls", ".", "remove", "(", "wall", ")", "\n", "\n", "", "", "", "if", "self", ".", "_goal_squares", "is", "None", ":", "\n", "            ", "self", ".", "goal_squares", "=", "[", "self", ".", "_last_segment", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "goal_squares", "=", "[", "]", "\n", "for", "gs", "in", "self", ".", "_goal_squares", ":", "\n", "                ", "assert", "gs", "in", "self", ".", "_segments", "\n", "self", ".", "goal_squares", ".", "append", "(", "gs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot": [[233, 238], ["matplotlib.subplots", "ax.plot"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.plot"], ["", "", "", "def", "plot", "(", "self", ",", "ax", "=", "None", ")", ":", "\n", "        ", "if", "ax", "is", "None", ":", "\n", "            ", "_", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "5", ",", "4", ")", ")", "\n", "", "for", "x", ",", "y", "in", "self", ".", "_walls", ":", "\n", "            ", "ax", ".", "plot", "(", "x", ",", "y", ",", "'k-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_start": [[239, 253], ["mazes.Maze.np_random.uniform", "mazes.Maze.move", "mazes.Maze.np_random.randint", "numpy.array", "numpy.sign", "float", "numpy.sum", "len", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move"], ["", "", "def", "sample_start", "(", "self", ")", ":", "\n", "        ", "min_wall_dist", "=", "0.05", "\n", "\n", "s_square", "=", "self", ".", "start_squares", "[", "self", ".", "np_random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "len", "(", "self", ".", "start_squares", ")", ")", "]", "\n", "s_square_loc", "=", "self", ".", "_segments", "[", "s_square", "]", "[", "'loc'", "]", "\n", "\n", "while", "True", ":", "\n", "            ", "shift", "=", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "0.5", ",", "high", "=", "0.5", ",", "size", "=", "(", "2", ",", ")", ")", "\n", "loc", "=", "s_square_loc", "+", "shift", "\n", "dist_checker", "=", "np", ".", "array", "(", "[", "min_wall_dist", ",", "min_wall_dist", "]", ")", "*", "np", ".", "sign", "(", "shift", ")", "\n", "stopped_loc", "=", "self", ".", "move", "(", "loc", ",", "dist_checker", ")", "\n", "if", "float", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "(", "loc", "+", "dist_checker", ")", "-", "stopped_loc", ")", ")", ")", "==", "0.0", ":", "\n", "                ", "break", "\n", "", "", "return", "loc", "[", "0", "]", ",", "loc", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.sample_goal": [[254, 270], ["min", "mazes.Maze.np_random.uniform", "mazes.Maze.move", "max", "mazes.Maze.np_random.randint", "numpy.array", "numpy.sign", "float", "numpy.sum", "len", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move"], ["", "def", "sample_goal", "(", "self", ",", "min_wall_dist", "=", "None", ")", ":", "\n", "        ", "if", "min_wall_dist", "is", "None", ":", "\n", "            ", "min_wall_dist", "=", "0.1", "\n", "", "else", ":", "\n", "            ", "min_wall_dist", "=", "min", "(", "0.4", ",", "max", "(", "0.01", ",", "min_wall_dist", ")", ")", "\n", "\n", "", "g_square", "=", "self", ".", "goal_squares", "[", "self", ".", "np_random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "len", "(", "self", ".", "goal_squares", ")", ")", "]", "\n", "g_square_loc", "=", "self", ".", "_segments", "[", "g_square", "]", "[", "'loc'", "]", "\n", "while", "True", ":", "\n", "            ", "shift", "=", "self", ".", "np_random", ".", "uniform", "(", "low", "=", "-", "0.5", ",", "high", "=", "0.5", ",", "size", "=", "(", "2", ",", ")", ")", "\n", "loc", "=", "g_square_loc", "+", "shift", "\n", "dist_checker", "=", "np", ".", "array", "(", "[", "min_wall_dist", ",", "min_wall_dist", "]", ")", "*", "np", ".", "sign", "(", "shift", ")", "\n", "stopped_loc", "=", "self", ".", "move", "(", "loc", ",", "dist_checker", ")", "\n", "if", "float", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "(", "loc", "+", "dist_checker", ")", "-", "stopped_loc", ")", ")", ")", "==", "0.0", ":", "\n", "                ", "break", "\n", "", "", "return", "loc", "[", "0", "]", ",", "loc", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move": [[271, 329], ["numpy.round", "numpy.round", "numpy.round", "numpy.round", "int", "int", "numpy.abs", "numpy.abs", "numpy.round", "numpy.round", "mazes.Maze._wall_line", "numpy.round", "numpy.round", "mazes.Maze._wall_line", "sorted", "range", "range", "sorted.append", "sorted.append", "float", "mazes.Maze.move", "numpy.sign", "numpy.sign", "numpy.abs", "numpy.sign", "numpy.sign", "mazes.Maze.np_random.rand"], "methods", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._wall_line", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze._wall_line", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.move"], ["", "def", "move", "(", "self", ",", "coord_start", ",", "coord_delta", ",", "depth", "=", "None", ")", ":", "\n", "        ", "if", "depth", "is", "None", ":", "\n", "            ", "depth", "=", "0", "\n", "", "cx", ",", "cy", "=", "coord_start", "\n", "loc_x0", "=", "np", ".", "round", "(", "cx", ")", "\n", "loc_y0", "=", "np", ".", "round", "(", "cy", ")", "\n", "#assert (float(loc_x0), float(loc_y0)) in self._locs", "\n", "dx", ",", "dy", "=", "coord_delta", "\n", "loc_x1", "=", "np", ".", "round", "(", "cx", "+", "dx", ")", "\n", "loc_y1", "=", "np", ".", "round", "(", "cy", "+", "dy", ")", "\n", "d_loc_x", "=", "int", "(", "np", ".", "abs", "(", "loc_x1", "-", "loc_x0", ")", ")", "\n", "d_loc_y", "=", "int", "(", "np", ".", "abs", "(", "loc_y1", "-", "loc_y0", ")", ")", "\n", "xs_crossed", "=", "[", "loc_x0", "+", "(", "np", ".", "sign", "(", "dx", ")", "*", "(", "i", "+", "0.5", ")", ")", "for", "i", "in", "range", "(", "d_loc_x", ")", "]", "\n", "ys_crossed", "=", "[", "loc_y0", "+", "(", "np", ".", "sign", "(", "dy", ")", "*", "(", "i", "+", "0.5", ")", ")", "for", "i", "in", "range", "(", "d_loc_y", ")", "]", "\n", "\n", "rds", "=", "[", "]", "\n", "\n", "for", "x", "in", "xs_crossed", ":", "\n", "            ", "r", "=", "(", "x", "-", "cx", ")", "/", "dx", "\n", "loc_x", "=", "np", ".", "round", "(", "cx", "+", "(", "0.999", "*", "r", "*", "dx", ")", ")", "\n", "loc_y", "=", "np", ".", "round", "(", "cy", "+", "(", "0.999", "*", "r", "*", "dy", ")", ")", "\n", "direction", "=", "'right'", "if", "dx", ">", "0", "else", "'left'", "\n", "crossed_line", "=", "self", ".", "_wall_line", "(", "(", "loc_x", ",", "loc_y", ")", ",", "direction", ")", "\n", "if", "crossed_line", "in", "self", ".", "_walls", ":", "\n", "                ", "rds", ".", "append", "(", "[", "r", ",", "direction", "]", ")", "\n", "\n", "", "", "for", "y", "in", "ys_crossed", ":", "\n", "            ", "r", "=", "(", "y", "-", "cy", ")", "/", "dy", "\n", "loc_x", "=", "np", ".", "round", "(", "cx", "+", "(", "0.999", "*", "r", "*", "dx", ")", ")", "\n", "loc_y", "=", "np", ".", "round", "(", "cy", "+", "(", "0.999", "*", "r", "*", "dy", ")", ")", "\n", "direction", "=", "'up'", "if", "dy", ">", "0", "else", "'down'", "\n", "crossed_line", "=", "self", ".", "_wall_line", "(", "(", "loc_x", ",", "loc_y", ")", ",", "direction", ")", "\n", "if", "crossed_line", "in", "self", ".", "_walls", ":", "\n", "                ", "rds", ".", "append", "(", "[", "r", ",", "direction", "]", ")", "\n", "\n", "# The wall will only stop the agent in the direction perpendicular to the wall", "\n", "", "", "if", "rds", ":", "\n", "            ", "rds", "=", "sorted", "(", "rds", ")", "\n", "r", ",", "direction", "=", "rds", "[", "0", "]", "\n", "if", "depth", "<", "3", ":", "\n", "                ", "new_dx", "=", "r", "*", "dx", "\n", "new_dy", "=", "r", "*", "dy", "\n", "repulsion", "=", "float", "(", "np", ".", "abs", "(", "self", ".", "np_random", ".", "rand", "(", ")", "*", "0.01", ")", ")", "\n", "if", "direction", "in", "[", "'right'", ",", "'left'", "]", ":", "\n", "                    ", "new_dx", "-=", "np", ".", "sign", "(", "dx", ")", "*", "repulsion", "\n", "partial_coords", "=", "cx", "+", "new_dx", ",", "cy", "+", "new_dy", "\n", "remaining_delta", "=", "(", "0.0", ",", "(", "1", "-", "r", ")", "*", "dy", ")", "\n", "", "else", ":", "\n", "                    ", "new_dy", "-=", "np", ".", "sign", "(", "dy", ")", "*", "repulsion", "\n", "partial_coords", "=", "cx", "+", "new_dx", ",", "cy", "+", "new_dy", "\n", "remaining_delta", "=", "(", "(", "1", "-", "r", ")", "*", "dx", ",", "0.0", ")", "\n", "", "return", "self", ".", "move", "(", "partial_coords", ",", "remaining_delta", ",", "depth", "+", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "r", "=", "1.0", "\n", "\n", "", "dx", "*=", "r", "\n", "dy", "*=", "r", "\n", "return", "cx", "+", "dx", ",", "cy", "+", "dy", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_crazy_maze": [[331, 379], ["numpy.random.seed", "range", "zip", "numpy.random.seed", "mazes.Maze", "range", "empty_locs.pop", "len", "numpy.random.shuffle", "segments.append", "empty_locs.append", "numpy.random.shuffle", "str", "str", "dict", "still_empty.append", "str", "str", "locs.append", "dirs.append", "anchors.append"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.Maze.seed", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "", "def", "make_crazy_maze", "(", "size", ",", "seed", "=", "None", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "deltas", "=", "[", "\n", "[", "(", "-", "1", ",", "0", ")", ",", "'right'", "]", ",", "\n", "[", "(", "1", ",", "0", ")", ",", "'left'", "]", ",", "\n", "[", "(", "0", ",", "-", "1", ")", ",", "'up'", "]", ",", "\n", "[", "(", "0", ",", "1", ")", ",", "'down'", "]", ",", "\n", "]", "\n", "\n", "empty_locs", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "size", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "size", ")", ":", "\n", "            ", "empty_locs", ".", "append", "(", "(", "x", ",", "y", ")", ")", "\n", "\n", "", "", "locs", "=", "[", "empty_locs", ".", "pop", "(", "0", ")", "]", "\n", "dirs", "=", "[", "None", "]", "\n", "anchors", "=", "[", "None", "]", "\n", "\n", "while", "len", "(", "empty_locs", ")", ">", "0", ":", "\n", "        ", "still_empty", "=", "[", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "empty_locs", ")", "\n", "for", "empty_x", ",", "empty_y", "in", "empty_locs", ":", "\n", "            ", "found_anchor", "=", "False", "\n", "np", ".", "random", ".", "shuffle", "(", "deltas", ")", "\n", "for", "(", "dx", ",", "dy", ")", ",", "direction", "in", "deltas", ":", "\n", "                ", "c", "=", "(", "empty_x", "+", "dx", ",", "empty_y", "+", "dy", ")", "\n", "if", "c", "in", "locs", ":", "\n", "                    ", "found_anchor", "=", "True", "\n", "locs", ".", "append", "(", "(", "empty_x", ",", "empty_y", ")", ")", "\n", "dirs", ".", "append", "(", "direction", ")", "\n", "anchors", ".", "append", "(", "c", ")", "\n", "break", "\n", "", "", "if", "not", "found_anchor", ":", "\n", "                ", "still_empty", ".", "append", "(", "(", "empty_x", ",", "empty_y", ")", ")", "\n", "", "", "empty_locs", "=", "still_empty", "[", ":", "]", "\n", "\n", "", "locs", "=", "[", "str", "(", "x", ")", "+", "','", "+", "str", "(", "y", ")", "for", "x", ",", "y", "in", "locs", "[", "1", ":", "]", "]", "\n", "dirs", "=", "dirs", "[", "1", ":", "]", "\n", "anchors", "=", "[", "str", "(", "x", ")", "+", "','", "+", "str", "(", "y", ")", "for", "x", ",", "y", "in", "anchors", "[", "1", ":", "]", "]", "\n", "anchors", "=", "[", "'origin'", "if", "a", "==", "'0,0'", "else", "a", "for", "a", "in", "anchors", "]", "\n", "\n", "segments", "=", "[", "]", "\n", "for", "loc", ",", "d", ",", "anchor", "in", "zip", "(", "locs", ",", "dirs", ",", "anchors", ")", ":", "\n", "        ", "segments", ".", "append", "(", "dict", "(", "name", "=", "loc", ",", "anchor", "=", "anchor", ",", "direction", "=", "d", ")", ")", "\n", "\n", "", "np", ".", "random", ".", "seed", "(", ")", "\n", "return", "Maze", "(", "*", "segments", ",", "goal_squares", "=", "'{s},{s}'", ".", "format", "(", "s", "=", "size", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_experiment_maze": [[381, 403], ["range", "range", "mazes.Maze", "segments.append", "segments.append", "range", "segments.append"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "make_experiment_maze", "(", "h", ",", "half_w", ",", "sz0", ")", ":", "\n", "    ", "if", "h", "<", "2", ":", "\n", "        ", "h", "=", "2", "\n", "", "if", "half_w", "<", "3", ":", "\n", "        ", "half_w", "=", "3", "\n", "", "w", "=", "1", "+", "(", "2", "*", "half_w", ")", "\n", "# Create the starting row", "\n", "segments", "=", "[", "{", "'anchor'", ":", "'origin'", ",", "'direction'", ":", "'right'", ",", "'name'", ":", "'0,1'", "}", "]", "\n", "for", "w_", "in", "range", "(", "1", ",", "w", "-", "1", ")", ":", "\n", "        ", "segments", ".", "append", "(", "{", "'anchor'", ":", "'0,{}'", ".", "format", "(", "w_", ")", ",", "'direction'", ":", "'right'", ",", "'name'", ":", "'0,{}'", ".", "format", "(", "w_", "+", "1", ")", "}", ")", "\n", "\n", "# Add each row to create H", "\n", "", "for", "h_", "in", "range", "(", "1", ",", "h", ")", ":", "\n", "        ", "segments", ".", "append", "(", "{", "'anchor'", ":", "'{},{}'", ".", "format", "(", "h_", "-", "1", ",", "w", "-", "1", ")", ",", "'direction'", ":", "'up'", ",", "'name'", ":", "'{},{}'", ".", "format", "(", "h_", ",", "w", "-", "1", ")", "}", ")", "\n", "\n", "c", "=", "None", "if", "h_", "==", "sz0", "else", "'down'", "\n", "for", "w_", "in", "range", "(", "w", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "segments", ".", "append", "(", "\n", "{", "'anchor'", ":", "'{},{}'", ".", "format", "(", "h_", ",", "w_", "+", "1", ")", ",", "'direction'", ":", "'left'", ",", "'connect'", ":", "c", ",", "'name'", ":", "'{},{}'", ".", "format", "(", "h_", ",", "w_", ")", "}", "\n", ")", "\n", "\n", "", "", "return", "Maze", "(", "*", "segments", ",", "goal_squares", "=", "[", "'{},{}'", ".", "format", "(", "h", "-", "1", ",", "half_w", "+", "d", ")", "for", "d", "in", "[", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_hallway_maze": [[405, 417], ["int", "range", "mazes.Maze", "segments.append", "str"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "make_hallway_maze", "(", "corridor_length", ")", ":", "\n", "    ", "corridor_length", "=", "int", "(", "corridor_length", ")", "\n", "assert", "corridor_length", ">=", "1", "\n", "\n", "segments", "=", "[", "]", "\n", "last", "=", "'origin'", "\n", "for", "x", "in", "range", "(", "1", ",", "corridor_length", "+", "1", ")", ":", "\n", "        ", "next_name", "=", "'0,{}'", ".", "format", "(", "x", ")", "\n", "segments", ".", "append", "(", "{", "'anchor'", ":", "last", ",", "'direction'", ":", "'right'", ",", "'name'", ":", "next_name", "}", ")", "\n", "last", "=", "str", "(", "next_name", ")", "\n", "\n", "", "return", "Maze", "(", "*", "segments", ",", "goal_squares", "=", "last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.toy_maze.mazes.make_u_maze": [[419, 449], ["int", "range", "range", "range", "mazes.Maze", "segments.append", "str", "segments.append", "str", "segments.append", "str"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append", "home.repos.pwc.inspect_result.spitis_mrl.core.replay_buffer.RingBuffer.append"], ["", "def", "make_u_maze", "(", "corridor_length", ")", ":", "\n", "    ", "corridor_length", "=", "int", "(", "corridor_length", ")", "\n", "assert", "corridor_length", ">=", "1", "\n", "\n", "segments", "=", "[", "]", "\n", "last", "=", "'origin'", "\n", "for", "x", "in", "range", "(", "1", ",", "corridor_length", "+", "1", ")", ":", "\n", "        ", "next_name", "=", "'0,{}'", ".", "format", "(", "x", ")", "\n", "segments", ".", "append", "(", "{", "'anchor'", ":", "last", ",", "'direction'", ":", "'right'", ",", "'name'", ":", "next_name", "}", ")", "\n", "last", "=", "str", "(", "next_name", ")", "\n", "\n", "", "assert", "last", "==", "'0,{}'", ".", "format", "(", "corridor_length", ")", "\n", "\n", "up_size", "=", "2", "\n", "\n", "for", "x", "in", "range", "(", "1", ",", "up_size", "+", "1", ")", ":", "\n", "        ", "next_name", "=", "'{},{}'", ".", "format", "(", "x", ",", "corridor_length", ")", "\n", "segments", ".", "append", "(", "{", "'anchor'", ":", "last", ",", "'direction'", ":", "'up'", ",", "'name'", ":", "next_name", "}", ")", "\n", "last", "=", "str", "(", "next_name", ")", "\n", "\n", "", "assert", "last", "==", "'{},{}'", ".", "format", "(", "up_size", ",", "corridor_length", ")", "\n", "\n", "for", "x", "in", "range", "(", "1", ",", "corridor_length", "+", "1", ")", ":", "\n", "        ", "next_name", "=", "'{},{}'", ".", "format", "(", "up_size", ",", "corridor_length", "-", "x", ")", "\n", "segments", ".", "append", "(", "{", "'anchor'", ":", "last", ",", "'direction'", ":", "'left'", ",", "'name'", ":", "next_name", "}", ")", "\n", "last", "=", "str", "(", "next_name", ")", "\n", "\n", "", "assert", "last", "==", "'{},0'", ".", "format", "(", "up_size", ")", "\n", "\n", "return", "Maze", "(", "*", "segments", ",", "goal_squares", "=", "last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.spitis_mrl.tests.test_agent_td3.test_td3": [[5, 17], ["make_td3_agent", "mrl.config_to_agent", "mrl.config_to_agent.train", "len", "Namespace", "mrl.config_to_agent.eval"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_td3_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent"], ["def", "test_td3", "(", ")", ":", "\n", "  ", "config", "=", "make_td3_agent", "(", "args", "=", "Namespace", "(", "env", "=", "'InvertedPendulum-v2'", ",", "\n", "tb", "=", "''", ",", "\n", "parent_folder", "=", "'/tmp/mrl'", ",", "\n", "layers", "=", "(", "32", ",", "1", ")", ",", "\n", "num_envs", "=", "1", ",", "\n", "num_eval_envs", "=", "1", ",", "\n", "device", "=", "'cpu'", ")", ")", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "agent", ".", "train", "(", "num_steps", "=", "1", ")", "\n", "assert", "len", "(", "agent", ".", "eval", "(", "num_episodes", "=", "1", ")", ".", "rewards", ")", "==", "1", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.tests.test_agent_ddpg.test_ddpg": [[5, 17], ["make_ddpg_agent", "mrl.config_to_agent", "mrl.config_to_agent.train", "len", "Namespace", "mrl.config_to_agent.eval"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_ddpg_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent"], ["def", "test_ddpg", "(", ")", ":", "\n", "  ", "config", "=", "make_ddpg_agent", "(", "args", "=", "Namespace", "(", "env", "=", "'InvertedPendulum-v2'", ",", "\n", "tb", "=", "''", ",", "\n", "parent_folder", "=", "'/tmp/mrl'", ",", "\n", "layers", "=", "(", "32", ",", "1", ")", ",", "\n", "num_envs", "=", "1", ",", "\n", "num_eval_envs", "=", "1", ",", "\n", "device", "=", "'cpu'", ")", ")", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "agent", ".", "train", "(", "num_steps", "=", "1", ")", "\n", "assert", "len", "(", "agent", ".", "eval", "(", "num_episodes", "=", "1", ")", ".", "rewards", ")", "==", "1", "", "", ""]], "home.repos.pwc.inspect_result.spitis_mrl.tests.test_agent_sac.test_sac": [[5, 17], ["make_sac_agent", "mrl.config_to_agent", "mrl.config_to_agent.train", "len", "Namespace", "mrl.config_to_agent.eval"], "function", ["home.repos.pwc.inspect_result.spitis_mrl.configs.make_continuous_agents.make_sac_agent", "home.repos.pwc.inspect_result.spitis_mrl.mrl.agent_base.config_to_agent"], ["def", "test_sac", "(", ")", ":", "\n", "  ", "config", "=", "make_sac_agent", "(", "args", "=", "Namespace", "(", "env", "=", "'InvertedPendulum-v2'", ",", "\n", "tb", "=", "''", ",", "\n", "parent_folder", "=", "'/tmp/mrl'", ",", "\n", "layers", "=", "(", "32", ",", "1", ")", ",", "\n", "num_envs", "=", "1", ",", "\n", "num_eval_envs", "=", "1", ",", "\n", "device", "=", "'cpu'", ")", ")", "\n", "agent", "=", "mrl", ".", "config_to_agent", "(", "config", ")", "\n", "\n", "agent", ".", "train", "(", "num_steps", "=", "1", ")", "\n", "assert", "len", "(", "agent", ".", "eval", "(", "num_episodes", "=", "1", ")", ".", "rewards", ")", "==", "1", "", "", ""]]}