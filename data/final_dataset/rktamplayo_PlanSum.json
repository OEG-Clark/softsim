{"home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.train_condense.train": [[18, 193], ["print", "os.makedirs", "transformers.BertTokenizer.from_pretrained", "BertTokenizer.from_pretrained.add_special_tokens", "len", "print", "utils.condense_data", "print", "torch.Embedding", "nn.Embedding.cuda", "model.Condense", "model.Condense.cuda", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "transformers.get_constant_schedule_with_warmup", "os.path.exists", "print", "range", "utils.condense_data", "numpy.random.permutation", "model.Condense.parameters", "print", "torch.load", "torch.load", "torch.load", "nn.Embedding.load_state_dict", "model.Condense.load_state_dict", "torch.optim.Adam.load_state_dict", "numpy.random.permutation", "tqdm.tqdm", "numpy.arange", "numpy.arange", "range", "nn.Embedding.train", "model.Condense.train", "utils.pad_text", "nn.Embedding.", "model.Condense.", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "model.Condense.calculate_loss", "asp_losses.append", "asp_norm_losses.append", "sen_losses.append", "sen_norm_losses.append", "adv_losses.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum.backward", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "model.Condense.parameters", "len", "len", "len", "len", "tqdm.tqdm.close", "len", "BertTokenizer.from_pretrained.encode", "losses[].item", "losses[].item", "losses[].item", "losses[].item", "losses[].item", "torch.stack", "torch.stack", "torch.stack", "nn.Embedding.parameters", "model.Condense.parameters", "torch.optim.Adam.step", "transformers.get_constant_schedule_with_warmup.step", "torch.optim.Adam.zero_grad", "numpy.random.permutation", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "tqdm.tqdm", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.isnan", "torch.isnan", "torch.isnan", "numpy.arange", "numpy.array", "numpy.array", "range", "nn.Embedding.eval", "model.Condense.eval", "utils.pad_text", "nn.Embedding.", "model.Condense.", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "model.Condense.calculate_loss", "np.mean.append", "np.mean.append", "np.mean.append", "np.mean.append", "np.mean.append", "tqdm.tqdm.write", "torch.save", "torch.save", "torch.save", "tqdm.tqdm.write", "param.grad.sum", "len", "len", "BertTokenizer.from_pretrained.encode", "losses[].item", "losses[].item", "losses[].item", "losses[].item", "losses[].item", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "nn.Embedding.state_dict", "model.Condense.state_dict", "torch.optim.Adam.state_dict", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.condense_data", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.condense_data", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.train_abstract.train", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.train_abstract.train", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.calculate_loss", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.GradientReverse.backward", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.calculate_loss"], ["def", "train", "(", "args", ")", ":", "\n", "  ", "print", "(", "args", ")", "\n", "\n", "os", ".", "makedirs", "(", "'model/%s/'", "%", "args", ".", "data_type", ",", "exist_ok", "=", "True", ")", "\n", "model_file", "=", "'model/%s/condense.model'", "%", "args", ".", "data_type", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_config", ")", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "'additional_special_tokens'", ":", "[", "'<movie>'", "]", "}", ")", "\n", "vocab_size", "=", "len", "(", "tokenizer", ")", "\n", "\n", "print", "(", "'Loading datasets...'", ")", "\n", "x_train", ",", "y_train", "=", "utils", ".", "condense_data", "(", "args", ".", "train_file", ",", "args", ".", "adjust_sentiment", ")", "\n", "if", "args", ".", "data_type", "==", "'rotten'", ":", "\n", "    ", "x_dev", ",", "y_dev", "=", "utils", ".", "condense_data", "(", "args", ".", "dev_file", ",", "args", ".", "adjust_sentiment", ")", "\n", "", "else", ":", "\n", "    ", "shuffle_indices", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "x_train", ")", ")", ")", "\n", "x_dev", "=", "x_train", "[", ":", "2000", "]", "\n", "y_dev", "=", "y_train", "[", ":", "2000", "]", "\n", "x_train", "=", "x_train", "[", "2000", ":", "]", "\n", "y_train", "=", "y_train", "[", "2000", ":", "]", "\n", "\n", "", "print", "(", "'Initializing models...'", ")", "\n", "encoder", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "args", ".", "input_dim", ")", "\n", "encoder", ".", "cuda", "(", ")", "\n", "\n", "model", "=", "Condense", "(", "args", ".", "aspect_dim", ",", "args", ".", "sentiment_dim", ",", "args", ".", "input_dim", ",", "args", ".", "hidden_dim", ",", "vocab_size", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ",", "betas", "=", "(", "0.9", ",", "0.998", ")", ",", "eps", "=", "1e-9", ")", "\n", "scheduler", "=", "get_constant_schedule_with_warmup", "(", "optimizer", ",", "args", ".", "warmup", ")", "\n", "\n", "best_loss", "=", "10000", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_file", ")", ":", "\n", "    ", "print", "(", "'Loading model checkpoint...'", ")", "\n", "best_point", "=", "torch", ".", "load", "(", "model_file", ")", "\n", "encoder", ".", "load_state_dict", "(", "best_point", "[", "'encoder'", "]", ")", "\n", "model", ".", "load_state_dict", "(", "best_point", "[", "'model'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "best_point", "[", "'optimizer'", "]", ")", "\n", "best_loss", "=", "best_point", "[", "'dev_loss'", "]", "\n", "\n", "", "eval_at", "=", "args", ".", "evaluate_every", "\n", "stop_at", "=", "args", ".", "training_stopper", "\n", "\n", "step", "=", "0", "\n", "print", "(", "'Start training...'", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epoch", ")", ":", "\n", "    ", "if", "stop_at", "<=", "0", ":", "\n", "      ", "break", "\n", "\n", "", "shuffle_indices", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "x_train", ")", ")", ")", "\n", "\n", "asp_losses", "=", "[", "]", "\n", "asp_norm_losses", "=", "[", "]", "\n", "sen_losses", "=", "[", "]", "\n", "sen_norm_losses", "=", "[", "]", "\n", "adv_losses", "=", "[", "]", "\n", "\n", "train_iterator", "=", "tqdm", "(", "range", "(", "0", ",", "len", "(", "shuffle_indices", ")", ",", "args", ".", "batch_size", ")", ")", "\n", "for", "i", "in", "train_iterator", ":", "\n", "      ", "if", "stop_at", "<=", "0", ":", "\n", "        ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "if", "i", "+", "args", ".", "batch_size", ">=", "len", "(", "shuffle_indices", ")", ":", "\n", "        ", "continue", "\n", "\n", "", "encoder", ".", "train", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "indices", "=", "shuffle_indices", "[", "i", ":", "i", "+", "args", ".", "batch_size", "]", "\n", "x_batch", "=", "[", "x_train", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "y_batch", "=", "[", "y_train", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "\n", "x_batch", "=", "[", "tokenizer", ".", "encode", "(", "x_inst", ")", "for", "x_inst", "in", "x_batch", "]", "\n", "x_batch", ",", "mask", "=", "utils", ".", "pad_text", "(", "x_batch", ")", "\n", "\n", "tokens", "=", "encoder", "(", "x_batch", ")", "\n", "before", ",", "after", ",", "sent_pred", ",", "adv_pred", "=", "model", "(", "tokens", ",", "mask", ",", "x_batch", ")", "\n", "\n", "sent_gold", "=", "torch", ".", "Tensor", "(", "y_batch", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "losses", "=", "model", ".", "calculate_loss", "(", "before", ",", "after", ",", "sent_pred", ",", "adv_pred", ",", "sent_gold", ")", "\n", "\n", "asp_losses", ".", "append", "(", "losses", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "asp_norm_losses", ".", "append", "(", "losses", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "sen_losses", ".", "append", "(", "losses", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "sen_norm_losses", ".", "append", "(", "losses", "[", "3", "]", ".", "item", "(", ")", ")", "\n", "adv_losses", ".", "append", "(", "losses", "[", "4", "]", ".", "item", "(", ")", ")", "\n", "\n", "batch_loss", "=", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "losses", ")", ")", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "encoder", ".", "parameters", "(", ")", ",", "2", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "2", ")", "\n", "nan_check", "=", "False", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "          ", "if", "torch", ".", "isnan", "(", "param", ".", "grad", ".", "sum", "(", ")", ")", ":", "\n", "            ", "nan_check", "=", "True", "\n", "break", "\n", "", "", "", "if", "not", "nan_check", ":", "\n", "        ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "eval_at", "-=", "len", "(", "x_batch", ")", "\n", "if", "eval_at", "<=", "0", ":", "\n", "        ", "shuffle_indices", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "x_dev", ")", ")", ")", "\n", "x_dev", "=", "np", ".", "array", "(", "x_dev", ")", "[", "shuffle_indices", "]", "\n", "y_dev", "=", "np", ".", "array", "(", "y_dev", ")", "[", "shuffle_indices", "]", "\n", "\n", "train_asp_loss", "=", "np", ".", "mean", "(", "asp_losses", ")", "\n", "train_asp_norm_loss", "=", "np", ".", "mean", "(", "asp_norm_losses", ")", "\n", "train_sen_loss", "=", "np", ".", "mean", "(", "sen_losses", ")", "\n", "train_sen_norm_loss", "=", "np", ".", "mean", "(", "sen_norm_losses", ")", "\n", "train_adv_loss", "=", "np", ".", "mean", "(", "adv_losses", ")", "\n", "\n", "dev_asp_loss", "=", "[", "]", "\n", "dev_asp_norm_loss", "=", "[", "]", "\n", "dev_sen_loss", "=", "[", "]", "\n", "dev_sen_norm_loss", "=", "[", "]", "\n", "dev_adv_loss", "=", "[", "]", "\n", "\n", "for", "j", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "x_dev", ")", ",", "args", ".", "batch_size", ")", ")", ":", "\n", "          ", "encoder", ".", "eval", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "x_batch", "=", "x_dev", "[", "j", ":", "j", "+", "args", ".", "batch_size", "]", "\n", "x_batch", "=", "[", "tokenizer", ".", "encode", "(", "x_inst", ")", "for", "x_inst", "in", "x_batch", "]", "\n", "x_batch", ",", "mask", "=", "utils", ".", "pad_text", "(", "x_batch", ")", "\n", "\n", "tokens", "=", "encoder", "(", "x_batch", ")", "\n", "before", ",", "after", ",", "sent_pred", ",", "adv_pred", "=", "model", "(", "tokens", ",", "mask", ",", "x_batch", ")", "\n", "\n", "sent_gold", "=", "torch", ".", "Tensor", "(", "y_dev", "[", "j", ":", "j", "+", "args", ".", "batch_size", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "losses", "=", "model", ".", "calculate_loss", "(", "before", ",", "after", ",", "sent_pred", ",", "adv_pred", ",", "sent_gold", ")", "\n", "\n", "dev_asp_loss", ".", "append", "(", "losses", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "dev_asp_norm_loss", ".", "append", "(", "losses", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "dev_sen_loss", ".", "append", "(", "losses", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "dev_sen_norm_loss", ".", "append", "(", "losses", "[", "3", "]", ".", "item", "(", ")", ")", "\n", "dev_adv_loss", ".", "append", "(", "losses", "[", "4", "]", ".", "item", "(", ")", ")", "\n", "\n", "", "dev_asp_loss", "=", "np", ".", "mean", "(", "dev_asp_loss", ")", "\n", "dev_asp_norm_loss", "=", "np", ".", "mean", "(", "dev_asp_norm_loss", ")", "\n", "dev_sen_loss", "=", "np", ".", "mean", "(", "dev_sen_loss", ")", "\n", "dev_sen_norm_loss", "=", "np", ".", "mean", "(", "dev_sen_norm_loss", ")", "\n", "dev_adv_loss", "=", "np", ".", "mean", "(", "dev_adv_loss", ")", "\n", "dev_loss", "=", "dev_asp_loss", "+", "dev_asp_norm_loss", "+", "dev_sen_loss", "+", "dev_sen_norm_loss", "+", "dev_adv_loss", "\n", "\n", "tqdm", ".", "write", "(", "\"----------------------------------------------\"", ")", "\n", "tqdm", ".", "write", "(", "\"Epoch: %d, Batch: %d\"", "%", "(", "epoch", ",", "i", ")", ")", "\n", "tqdm", ".", "write", "(", "\"Train Losses: %.4f %.4f %.4f %.4f %.4f\"", "%", "(", "train_asp_loss", ",", "train_asp_norm_loss", ",", "train_sen_loss", ",", "train_sen_norm_loss", ",", "train_adv_loss", ")", ")", "\n", "tqdm", ".", "write", "(", "\"Dev Losses: %.4f %.4f %.4f %.4f %.4f\"", "%", "(", "dev_asp_loss", ",", "dev_asp_norm_loss", ",", "dev_sen_loss", ",", "dev_sen_norm_loss", ",", "dev_adv_loss", ")", ")", "\n", "\n", "if", "best_loss", ">=", "dev_loss", ":", "\n", "          ", "tqdm", ".", "write", "(", "\"UPDATING MODEL FILE...\"", ")", "\n", "best_loss", "=", "dev_loss", "\n", "stop_at", "=", "args", ".", "training_stopper", "\n", "torch", ".", "save", "(", "{", "\n", "'encoder'", ":", "encoder", ".", "state_dict", "(", ")", ",", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'dev_loss'", ":", "dev_loss", "\n", "}", ",", "model_file", ")", "\n", "", "else", ":", "\n", "          ", "stop_at", "-=", "1", "\n", "tqdm", ".", "write", "(", "\"STOPPING AT: %d\"", "%", "stop_at", ")", "\n", "\n", "\n", "", "tqdm", ".", "write", "(", "\"----------------------------------------------\"", ")", "\n", "\n", "asp_losses", "=", "[", "]", "\n", "asp_norm_losses", "=", "[", "]", "\n", "sen_losses", "=", "[", "]", "\n", "sen_norm_losses", "=", "[", "]", "\n", "adv_losses", "=", "[", "]", "\n", "eval_at", "=", "args", ".", "evaluate_every", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.train_condense.create_synthetic_data": [[195, 283], ["print", "transformers.BertTokenizer.from_pretrained", "BertTokenizer.from_pretrained.add_special_tokens", "len", "print", "utils.abstract_data", "print", "os.path.exists", "torch.Embedding", "nn.Embedding.requires_grad_", "nn.Embedding.cuda", "model.Condense", "model.Condense.requires_grad_", "model.Condense.cuda", "torch.load", "torch.load", "torch.load", "nn.Embedding.load_state_dict", "model.Condense.load_state_dict", "print", "tqdm.tqdm", "open", "json.dump", "open.close", "print", "range", "range", "len", "len", "utils.pad_text", "nn.Embedding.", "model.Condense.condense", "doc.cpu().detach().numpy.cpu().detach().numpy", "prob_a.cpu().detach().numpy.cpu().detach().numpy", "prob_s.cpu().detach().numpy.cpu().detach().numpy", "enumerate", "BertTokenizer.from_pretrained.encode", "len", "zip", "int", "numpy.sqrt", "numpy.sqrt", "data.append", "doc.cpu().detach().numpy.cpu().detach", "prob_a.cpu().detach().numpy.cpu().detach", "prob_s.cpu().detach().numpy.cpu().detach", "utils.check_summary_worthy", "numpy.random.normal", "numpy.random.dirichlet", "numpy.random.dirichlet", "numpy.argsort", "min", "BertTokenizer.from_pretrained.decode().split", "doc.cpu().detach().numpy.cpu", "prob_a.cpu().detach().numpy.cpu", "prob_s.cpu().detach().numpy.cpu", "len", "idx_set.append", "BertTokenizer.from_pretrained.decode().split", "BertTokenizer.from_pretrained.decode", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "BertTokenizer.from_pretrained.decode"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.abstract_data", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.condense", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.check_summary_worthy"], ["", "", "", "", "def", "create_synthetic_data", "(", "args", ")", ":", "\n", "  ", "print", "(", "args", ")", "\n", "\n", "file_name", "=", "'data/%s/train.plan.json'", "%", "args", ".", "data_type", "\n", "\n", "alpha_a", "=", "args", ".", "alpha", "\n", "alpha_s", "=", "args", ".", "alpha", "\n", "\n", "condense_file", "=", "'model/%s/condense.model'", "%", "args", ".", "data_type", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_config", ")", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "'additional_special_tokens'", ":", "[", "'<movie>'", "]", "}", ")", "\n", "vocab_size", "=", "len", "(", "tokenizer", ")", "\n", "\n", "print", "(", "'Loading corpus...'", ")", "\n", "x_train", ",", "_", "=", "utils", ".", "abstract_data", "(", "args", ".", "train_file", ",", "tokenizer", ")", "\n", "\n", "print", "(", "'Loading models...'", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "condense_file", ")", "\n", "con_encoder", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "args", ".", "input_dim", ")", "\n", "con_encoder", ".", "requires_grad_", "(", "False", ")", "\n", "con_encoder", ".", "cuda", "(", ")", "\n", "\n", "con_model", "=", "Condense", "(", "args", ".", "aspect_dim", ",", "args", ".", "sentiment_dim", ",", "args", ".", "input_dim", ",", "args", ".", "hidden_dim", ",", "vocab_size", ")", "\n", "con_model", ".", "requires_grad_", "(", "False", ")", "\n", "con_model", ".", "cuda", "(", ")", "\n", "\n", "best_point", "=", "torch", ".", "load", "(", "condense_file", ")", "\n", "con_encoder", ".", "load_state_dict", "(", "best_point", "[", "'encoder'", "]", ")", "\n", "con_model", ".", "load_state_dict", "(", "best_point", "[", "'model'", "]", ")", "\n", "\n", "data", "=", "[", "]", "\n", "vectors", "=", "[", "]", "\n", "\n", "print", "(", "'Creating synthetic dataset...'", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "x_train", ")", ")", ")", ":", "\n", "    ", "x_batches", "=", "x_train", "[", "i", "]", "\n", "\n", "for", "x_idx", "in", "range", "(", "0", ",", "len", "(", "x_batches", ")", ",", "500", ")", ":", "\n", "      ", "x_batch", "=", "x_batches", "[", "x_idx", ":", "x_idx", "+", "500", "]", "\n", "x_batch", "=", "[", "tokenizer", ".", "encode", "(", "x_inst", ")", "for", "x_inst", "in", "x_batch", "]", "\n", "if", "len", "(", "x_batch", ")", "<", "100", ":", "\n", "        ", "continue", "\n", "\n", "", "token_ids", ",", "mask", "=", "utils", ".", "pad_text", "(", "x_batch", ")", "\n", "tokens", "=", "con_encoder", "(", "token_ids", ")", "\n", "_", ",", "doc", ",", "prob_a", ",", "prob_s", "=", "con_model", ".", "condense", "(", "tokens", ",", "mask", ")", "\n", "\n", "doc", "=", "doc", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "prob_a", "=", "prob_a", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# b, a", "\n", "prob_s", "=", "prob_s", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# b, s", "\n", "\n", "for", "idx", ",", "(", "d", ",", "a", ",", "s", ")", "in", "enumerate", "(", "zip", "(", "doc", ",", "prob_a", ",", "prob_s", ")", ")", ":", "\n", "        ", "if", "not", "utils", ".", "check_summary_worthy", "(", "x_batch", "[", "idx", "]", ",", "tokenizer", ",", "\n", "args", ".", "min_length", ",", "args", ".", "max_length", ",", "args", ".", "max_symbols", ",", "args", ".", "max_tridots", ")", ":", "\n", "          ", "continue", "\n", "\n", "", "N", "=", "-", "1", "\n", "while", "N", "<", "args", ".", "min_reviews", "or", "N", ">", "min", "(", "len", "(", "x_batch", ")", ",", "args", ".", "max_reviews", ")", ":", "\n", "          ", "N", "=", "np", ".", "random", ".", "normal", "(", "args", ".", "mean_reviews", ",", "args", ".", "std_reviews", ")", "\n", "", "N", "=", "int", "(", "N", ")", "\n", "\n", "a_", "=", "np", ".", "random", ".", "dirichlet", "(", "alpha_a", "*", "a", "+", "1e-9", ",", "N", ")", "[", ":", ",", "np", ".", "newaxis", "]", "# N, a", "\n", "s_", "=", "np", ".", "random", ".", "dirichlet", "(", "alpha_s", "*", "s", "+", "1e-9", ",", "N", ")", "[", ":", ",", "np", ".", "newaxis", "]", "# N, s", "\n", "\n", "dist_a", "=", "np", ".", "sqrt", "(", "(", "(", "np", ".", "sqrt", "(", "prob_a", "[", "np", ".", "newaxis", "]", ")", "-", "np", ".", "sqrt", "(", "a_", ")", ")", "**", "2", ")", ".", "sum", "(", "-", "1", ")", ")", "\n", "dist_s", "=", "np", ".", "sqrt", "(", "(", "(", "np", ".", "sqrt", "(", "prob_s", "[", "np", ".", "newaxis", "]", ")", "-", "np", ".", "sqrt", "(", "s_", ")", ")", "**", "2", ")", ".", "sum", "(", "-", "1", ")", ")", "\n", "\n", "dist", "=", "dist_a", "+", "dist_s", "\n", "dist", "[", ":", ",", "idx", "]", "=", "1e9", "\n", "\n", "idx_set", "=", "[", "]", "\n", "for", "d", "in", "dist", ":", "\n", "          ", "d", "=", "np", ".", "argsort", "(", "d", ")", "\n", "for", "d_", "in", "d", ":", "\n", "            ", "if", "d_", "not", "in", "idx_set", ":", "\n", "              ", "idx_set", ".", "append", "(", "d_", ")", "\n", "break", "\n", "\n", "", "", "", "inst", "=", "{", "}", "\n", "inst", "[", "'summary'", "]", "=", "' '", ".", "join", "(", "tokenizer", ".", "decode", "(", "x_batch", "[", "idx", "]", ")", ".", "split", "(", ")", "[", "1", ":", "-", "1", "]", ")", "\n", "inst", "[", "'reviews'", "]", "=", "[", "' '", ".", "join", "(", "tokenizer", ".", "decode", "(", "x_batch", "[", "i", "]", ")", ".", "split", "(", ")", "[", "1", ":", "-", "1", "]", ")", "for", "i", "in", "idx_set", "if", "idx", "!=", "i", "]", "\n", "data", ".", "append", "(", "inst", ")", "\n", "\n", "", "", "", "f", "=", "open", "(", "file_name", ",", "'w'", ")", "\n", "json", ".", "dump", "(", "data", ",", "f", ",", "indent", "=", "2", ")", "\n", "f", ".", "close", "(", ")", "\n", "print", "(", "'Dataset saved.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.train_abstract.train": [[18, 208], ["print", "transformers.BertTokenizer.from_pretrained", "BertTokenizer.from_pretrained.add_special_tokens", "len", "print", "utils.abstract_data", "utils.abstract_data", "print", "transformers.BertForMaskedLM.from_pretrained", "BertForMaskedLM.from_pretrained.requires_grad_", "BertForMaskedLM.from_pretrained.cuda", "os.path.exists", "torch.Embedding", "nn.Embedding.requires_grad_", "nn.Embedding.cuda", "model.Condense", "model.Condense.requires_grad_", "model.Condense.cuda", "torch.load", "torch.load", "torch.load", "nn.Embedding.load_state_dict", "model.Condense.load_state_dict", "model.Abstract", "model.Abstract.cuda", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "os.path.exists", "print", "range", "model.Abstract.parameters", "print", "torch.load", "torch.load", "torch.load", "model.Abstract.load_state_dict", "torch.optim.Adam.load_state_dict", "numpy.random.permutation", "tqdm.tqdm", "len", "range", "model.Abstract.train", "utils.run_condense", "utils.bert_label_smoothing", "utils.pad_text", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "utils.pad_text", "model.Abstract.", "losses.append", "gate.append", "torch.utils.clip_grad_norm_", "model.Abstract.parameters", "len", "BertTokenizer.from_pretrained.encode", "utils.pad_vector", "loss.item", "gt.mean().item", "loss.backward", "model.Abstract.parameters", "torch.optim.Adam.step", "torch.optim.Adam.zero_grad", "BertTokenizer.from_pretrained.encode", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.isnan", "torch.isnan", "torch.isnan", "torch.no_grad", "torch.no_grad", "torch.no_grad", "numpy.mean", "numpy.mean", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm", "numpy.mean", "tqdm.tqdm.write", "tqdm.tqdm.write", "gt.mean", "param.grad.sum", "range", "model.Abstract.eval", "utils.run_condense", "utils.bert_label_smoothing", "utils.pad_text", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "utils.pad_text", "model.Abstract.", "np.mean.append", "output_batch[].cpu().detach().numpy", "pred_batch[].argmax().cpu().detach().numpy", "list", "list", "BertTokenizer.from_pretrained.decode", "BertTokenizer.from_pretrained.decode", "gold_sums.append", "pred_sums.append", "tqdm.tqdm.write", "torch.save", "torch.save", "torch.save", "tqdm.tqdm.write", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len", "BertTokenizer.from_pretrained.encode", "utils.pad_vector", "loss[].item", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "BertTokenizer.from_pretrained.encode", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "output_batch[].cpu().detach", "pred_batch[].argmax().cpu().detach", "tokenizer.decode.index", "model.Abstract.state_dict", "torch.optim.Adam.state_dict", "tokenizer.decode.index", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "output_batch[].cpu", "pred_batch[].argmax().cpu", "pred_batch[].argmax"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.abstract_data", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.abstract_data", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.train_abstract.train", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.run_condense", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.bert_label_smoothing", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_vector", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.GradientReverse.backward", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.run_condense", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.bert_label_smoothing", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_vector"], ["def", "train", "(", "args", ")", ":", "\n", "  ", "print", "(", "args", ")", "\n", "\n", "condense_file", "=", "'model/%s/condense.model'", "%", "args", ".", "data_type", "\n", "abstract_file", "=", "'model/%s/abstract.model'", "%", "args", ".", "data_type", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_config", ")", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "'additional_special_tokens'", ":", "[", "'<movie>'", "]", "}", ")", "\n", "vocab_size", "=", "len", "(", "tokenizer", ")", "\n", "\n", "print", "(", "'Loading datasets...'", ")", "\n", "x_train", ",", "y_train", "=", "utils", ".", "abstract_data", "(", "args", ".", "train_file", ")", "\n", "x_dev", ",", "y_dev", "=", "utils", ".", "abstract_data", "(", "args", ".", "test_file", ",", "multi_ref", "=", "args", ".", "multi_ref", ")", "\n", "\n", "print", "(", "'Initializing models...'", ")", "\n", "language_model", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "args", ".", "bert_config", ")", "\n", "language_model", ".", "requires_grad_", "(", "False", ")", "\n", "language_model", ".", "cuda", "(", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "condense_file", ")", "\n", "con_encoder", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "args", ".", "input_dim", ")", "\n", "con_encoder", ".", "requires_grad_", "(", "False", ")", "\n", "con_encoder", ".", "cuda", "(", ")", "\n", "\n", "con_model", "=", "Condense", "(", "args", ".", "aspect_dim", ",", "args", ".", "sentiment_dim", ",", "args", ".", "input_dim", ",", "args", ".", "hidden_dim", ",", "vocab_size", ")", "\n", "con_model", ".", "requires_grad_", "(", "False", ")", "\n", "con_model", ".", "cuda", "(", ")", "\n", "\n", "best_point", "=", "torch", ".", "load", "(", "condense_file", ")", "\n", "con_encoder", ".", "load_state_dict", "(", "best_point", "[", "'encoder'", "]", ")", "\n", "con_model", ".", "load_state_dict", "(", "best_point", "[", "'model'", "]", ")", "\n", "\n", "model", "=", "Abstract", "(", "vocab_size", ",", "args", ".", "hidden_dim", ",", "args", ".", "hidden_dim", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "best_acc", "=", "0", "\n", "saved_models", "=", "[", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "abstract_file", ")", ":", "\n", "    ", "print", "(", "'Loading model checkpoint...'", ")", "\n", "best_point", "=", "torch", ".", "load", "(", "abstract_file", ")", "\n", "model", ".", "load_state_dict", "(", "best_point", "[", "'model'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "best_point", "[", "'optimizer'", "]", ")", "\n", "best_acc", "=", "best_point", "[", "'dev_acc'", "]", "\n", "\n", "", "eval_at", "=", "args", ".", "evaluate_every", "\n", "stop_at", "=", "args", ".", "training_stopper", "\n", "\n", "losses", "=", "[", "]", "\n", "gate", "=", "[", "]", "\n", "\n", "print", "(", "'Start training...'", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epoch", ")", ":", "\n", "    ", "if", "stop_at", "<=", "0", ":", "\n", "      ", "break", "\n", "\n", "", "shuffle_indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "x_train", ")", ")", "\n", "\n", "for", "step", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "x_train", ")", ",", "args", ".", "batch_size", ")", ")", ":", "\n", "      ", "if", "stop_at", "<=", "0", ":", "\n", "        ", "break", "\n", "\n", "", "indices", "=", "shuffle_indices", "[", "step", ":", "step", "+", "args", ".", "batch_size", "]", "\n", "x_batch", "=", "[", "x_train", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "y_batch", "=", "[", "y_train", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "\n", "x_batch", "=", "[", "[", "tokenizer", ".", "encode", "(", "x_rev", ")", "for", "x_rev", "in", "x_inst", "]", "for", "x_inst", "in", "x_batch", "]", "\n", "y_batch", "=", "[", "tokenizer", ".", "encode", "(", "y_inst", ")", "for", "y_inst", "in", "y_batch", "]", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "tokens_batch", ",", "token_ids_batch", ",", "aspect_batch", ",", "sentiment_batch", "=", "utils", ".", "run_condense", "(", "x_batch", ",", "tokenizer", ",", "con_encoder", ",", "con_model", ")", "\n", "output_smooth_batch", ",", "output_mask_batch", "=", "utils", ".", "bert_label_smoothing", "(", "y_batch", ",", "tokenizer", ",", "language_model", ")", "\n", "\n", "tokens_batch", "=", "utils", ".", "pad_vector", "(", "tokens_batch", ",", "args", ".", "hidden_dim", ")", "[", "0", "]", "\n", "token_ids_batch", ",", "token_mask_batch", "=", "utils", ".", "pad_text", "(", "token_ids_batch", ")", "\n", "aspect_batch", "=", "torch", ".", "Tensor", "(", "aspect_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "# batch size, hidden dim", "\n", "sentiment_batch", "=", "torch", ".", "Tensor", "(", "sentiment_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "# batch size, hidden dim", "\n", "\n", "output_batch", ",", "_", "=", "utils", ".", "pad_text", "(", "y_batch", ")", "\n", "\n", "_", ",", "gt", ",", "loss", "=", "model", "(", "tokens_batch", ",", "token_ids_batch", ",", "token_mask_batch", ",", "\n", "aspect_batch", ",", "sentiment_batch", ",", "\n", "output_batch", ",", "output_smooth_batch", ",", "output_mask_batch", ")", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "gate", ".", "append", "(", "gt", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "loss", ".", "backward", "(", ")", "\n", "", "except", ":", "\n", "        ", "continue", "\n", "", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "3", ")", "\n", "nan_check", "=", "False", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "          ", "if", "torch", ".", "isnan", "(", "param", ".", "grad", ".", "sum", "(", ")", ")", ":", "\n", "            ", "nan_check", "=", "True", "\n", "break", "\n", "", "", "", "if", "not", "nan_check", ":", "\n", "        ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "eval_at", "-=", "1", "\n", "if", "eval_at", "<=", "0", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "          ", "train_loss", "=", "np", ".", "mean", "(", "losses", ")", "\n", "train_gate", "=", "np", ".", "mean", "(", "gate", ")", "\n", "\n", "eval_at", "=", "args", ".", "evaluate_every", "\n", "losses", "=", "[", "]", "\n", "gate", "=", "[", "]", "\n", "\n", "tqdm", ".", "write", "(", "\"----------------------------------------------\"", ")", "\n", "tqdm", ".", "write", "(", "\"Epoch: %d\"", "%", "(", "epoch", ")", ")", "\n", "tqdm", ".", "write", "(", "\"Step: %d\"", "%", "(", "step", ")", ")", "\n", "tqdm", ".", "write", "(", "'Train gate: %.4f'", "%", "train_gate", ")", "\n", "tqdm", ".", "write", "(", "'Train loss: %.4f'", "%", "train_loss", ")", "\n", "if", "train_loss", ">", "4", ":", "\n", "            ", "continue", "\n", "\n", "", "dev_acc", "=", "[", "]", "\n", "dev_loss", "=", "[", "]", "\n", "pred_sums", "=", "[", "]", "\n", "gold_sums", "=", "[", "]", "\n", "printing", "=", "5", "\n", "for", "j", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "x_dev", ")", ",", "1", ")", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "\n", "x_batch", "=", "x_dev", "[", "j", ":", "j", "+", "1", "]", "\n", "y_batch", "=", "y_dev", "[", "j", ":", "j", "+", "1", "]", "\n", "\n", "x_batch", "=", "[", "[", "tokenizer", ".", "encode", "(", "x_rev", ")", "for", "x_rev", "in", "x_inst", "]", "for", "x_inst", "in", "x_batch", "]", "\n", "y_batch", "=", "[", "tokenizer", ".", "encode", "(", "y_inst", ")", "for", "y_inst", "in", "y_batch", "]", "\n", "\n", "tokens_batch", ",", "token_ids_batch", ",", "aspect_batch", ",", "sentiment_batch", "=", "utils", ".", "run_condense", "(", "x_batch", ",", "tokenizer", ",", "con_encoder", ",", "con_model", ")", "\n", "output_smooth_batch", ",", "output_mask_batch", "=", "utils", ".", "bert_label_smoothing", "(", "y_batch", ",", "tokenizer", ",", "language_model", ")", "\n", "\n", "tokens_batch", "=", "utils", ".", "pad_vector", "(", "tokens_batch", ",", "args", ".", "hidden_dim", ")", "[", "0", "]", "\n", "token_ids_batch", ",", "token_mask_batch", "=", "utils", ".", "pad_text", "(", "token_ids_batch", ")", "\n", "aspect_batch", "=", "torch", ".", "Tensor", "(", "aspect_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "# batch size, hidden dim", "\n", "sentiment_batch", "=", "torch", ".", "Tensor", "(", "sentiment_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "# batch size, hidden dim", "\n", "\n", "output_batch", ",", "_", "=", "utils", ".", "pad_text", "(", "y_batch", ")", "\n", "\n", "pred_batch", ",", "_", ",", "loss", "=", "model", "(", "tokens_batch", ",", "token_ids_batch", ",", "token_mask_batch", ",", "\n", "aspect_batch", ",", "sentiment_batch", ",", "\n", "output_batch", ",", "output_smooth_batch", ",", "output_mask_batch", ",", "\n", "dev", "=", "True", ")", "\n", "\n", "dev_acc", ".", "append", "(", "loss", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "\n", "output", "=", "output_batch", "[", "0", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "pred", "=", "pred_batch", "[", "0", "]", ".", "argmax", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "output", "=", "list", "(", "output", ")", "\n", "pred", "=", "list", "(", "pred", ")", "\n", "output", "=", "output", "[", "1", ":", "output", ".", "index", "(", "102", ")", "]", "\n", "try", ":", "\n", "              ", "pred", "=", "pred", "[", ":", "pred", ".", "index", "(", "102", ")", "]", "\n", "", "except", ":", "\n", "              ", "pass", "\n", "\n", "", "output", "=", "tokenizer", ".", "decode", "(", "output", ")", "\n", "pred", "=", "tokenizer", ".", "decode", "(", "pred", ")", "\n", "\n", "gold_sums", ".", "append", "(", "output", ")", "\n", "pred_sums", ".", "append", "(", "pred", ")", "\n", "if", "printing", ":", "\n", "              ", "printing", "-=", "1", "\n", "tqdm", ".", "write", "(", "'gold: %s'", "%", "output", ")", "\n", "tqdm", ".", "write", "(", "'pred: %s'", "%", "pred", ")", "\n", "tqdm", ".", "write", "(", "\"----------------------------------------------\"", ")", "\n", "\n", "", "", "dev_acc", "=", "np", ".", "mean", "(", "dev_acc", ")", "\n", "tqdm", ".", "write", "(", "'Dev ACC: %.4f'", "%", "dev_acc", ")", "\n", "\n", "if", "dev_acc", ">=", "best_acc", ":", "\n", "            ", "tqdm", ".", "write", "(", "'UPDATING MODEL FILE...'", ")", "\n", "best_acc", "=", "dev_acc", "\n", "stop_at", "=", "args", ".", "training_stopper", "\n", "torch", ".", "save", "(", "{", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'dev_acc'", ":", "dev_acc", ",", "\n", "}", ",", "abstract_file", ")", "\n", "", "else", ":", "\n", "            ", "stop_at", "-=", "1", "\n", "tqdm", ".", "write", "(", "\"STOPPING AT: %d\"", "%", "stop_at", ")", "\n", "\n", "", "tqdm", ".", "write", "(", "\"----------------------------------------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.train_abstract.evaluate": [[210, 306], ["print", "os.makedirs", "transformers.BertTokenizer.from_pretrained", "BertTokenizer.from_pretrained.add_special_tokens", "len", "print", "utils.abstract_data", "print", "torch.Embedding", "nn.Embedding.requires_grad_", "nn.Embedding.cuda", "model.Condense", "model.Condense.requires_grad_", "model.Condense.cuda", "model.Abstract", "model.Abstract.requires_grad_", "model.Abstract.cuda", "print", "os.path.exists", "torch.load", "torch.load", "torch.load", "nn.Embedding.load_state_dict", "model.Condense.load_state_dict", "os.path.exists", "torch.load", "torch.load", "torch.load", "model.Abstract.load_state_dict", "open", "print", "tqdm.tqdm", "open.close", "print", "utils.get_movies_from_file", "range", "model.Abstract.eval", "utils.run_condense", "utils.pad_text", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "utils.pad_text", "model.Abstract.beam_search", "output_batch[].cpu().detach().numpy", "model.beam_search.cpu().detach().numpy", "list", "list", "BertTokenizer.from_pretrained.decode", "BertTokenizer.from_pretrained.decode", "open.write", "len", "BertTokenizer.from_pretrained.encode", "utils.pad_vector", "BertTokenizer.from_pretrained.encode", "output.replace.replace", "pred.replace.replace", "tqdm.tqdm.write", "tqdm.tqdm.write", "tqdm.tqdm.write", "BertTokenizer.from_pretrained.encode", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "output_batch[].cpu().detach", "model.beam_search.cpu().detach", "int", "int", "output.replace.index", "pred.replace.index", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "output_batch[].cpu", "model.beam_search.cpu", "int", "int"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.abstract_data", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.get_movies_from_file", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.run_condense", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Abstract.beam_search", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_vector"], ["", "", "", "", "", "def", "evaluate", "(", "args", ")", ":", "\n", "  ", "print", "(", "args", ")", "\n", "\n", "condense_file", "=", "'model/%s/condense.model'", "%", "args", ".", "data_type", "\n", "abstract_file", "=", "'model/%s/abstract.model'", "%", "args", ".", "data_type", "\n", "os", ".", "makedirs", "(", "'output/%s/'", "%", "args", ".", "data_type", ",", "exist_ok", "=", "True", ")", "\n", "solution_file", "=", "'output/%s/predictions.txt'", "%", "args", ".", "data_type", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_config", ")", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "'additional_special_tokens'", ":", "[", "'<movie>'", "]", "}", ")", "\n", "vocab_size", "=", "len", "(", "tokenizer", ")", "\n", "\n", "print", "(", "'Loading datasets...'", ")", "\n", "x_test", ",", "y_test", "=", "utils", ".", "abstract_data", "(", "args", ".", "test_file", ",", "multi_ref", "=", "args", ".", "multi_ref", ")", "\n", "if", "args", ".", "data_type", "==", "'rotten'", ":", "\n", "    ", "m_test", "=", "utils", ".", "get_movies_from_file", "(", "args", ".", "test_file", ")", "\n", "\n", "", "print", "(", "'Initializing models...'", ")", "\n", "con_encoder", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "args", ".", "input_dim", ")", "\n", "con_encoder", ".", "requires_grad_", "(", "False", ")", "\n", "con_encoder", ".", "cuda", "(", ")", "\n", "\n", "con_model", "=", "Condense", "(", "args", ".", "aspect_dim", ",", "args", ".", "sentiment_dim", ",", "args", ".", "input_dim", ",", "args", ".", "hidden_dim", ",", "vocab_size", ")", "\n", "con_model", ".", "requires_grad_", "(", "False", ")", "\n", "con_model", ".", "cuda", "(", ")", "\n", "\n", "model", "=", "Abstract", "(", "vocab_size", ",", "args", ".", "hidden_dim", ",", "args", ".", "hidden_dim", ")", "\n", "model", ".", "requires_grad_", "(", "False", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "print", "(", "'Loading models...'", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "condense_file", ")", "\n", "best_point", "=", "torch", ".", "load", "(", "condense_file", ")", "\n", "con_encoder", ".", "load_state_dict", "(", "best_point", "[", "'encoder'", "]", ")", "\n", "con_model", ".", "load_state_dict", "(", "best_point", "[", "'model'", "]", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "abstract_file", ")", "\n", "best_point", "=", "torch", ".", "load", "(", "abstract_file", ")", "\n", "model", ".", "load_state_dict", "(", "best_point", "[", "'model'", "]", ")", "\n", "\n", "eval_at", "=", "args", ".", "evaluate_every", "\n", "stop_at", "=", "args", ".", "training_stopper", "\n", "\n", "f_sol", "=", "open", "(", "solution_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "\n", "printing", "=", "5", "\n", "pred_sums", "=", "[", "]", "\n", "print", "(", "'Generating summaries...'", ")", "\n", "for", "j", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "x_test", ")", ",", "1", ")", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "x_batch", "=", "x_test", "[", "j", ":", "j", "+", "1", "]", "\n", "y_batch", "=", "y_test", "[", "j", ":", "j", "+", "1", "]", "\n", "if", "args", ".", "data_type", "==", "'rotten'", ":", "\n", "      ", "m_batch", "=", "m_test", "[", "j", ":", "j", "+", "1", "]", "\n", "\n", "", "x_batch", "=", "[", "[", "tokenizer", ".", "encode", "(", "x_rev", ")", "for", "x_rev", "in", "x_inst", "]", "for", "x_inst", "in", "x_batch", "]", "\n", "y_batch", "=", "[", "tokenizer", ".", "encode", "(", "y_inst", ")", "for", "y_inst", "in", "y_batch", "]", "\n", "\n", "tokens_batch", ",", "token_ids_batch", ",", "aspect_batch", ",", "sentiment_batch", "=", "utils", ".", "run_condense", "(", "x_batch", ",", "tokenizer", ",", "con_encoder", ",", "con_model", ")", "\n", "\n", "tokens_batch", "=", "utils", ".", "pad_vector", "(", "tokens_batch", ",", "args", ".", "hidden_dim", ")", "[", "0", "]", "\n", "token_ids_batch", ",", "token_mask_batch", "=", "utils", ".", "pad_text", "(", "token_ids_batch", ")", "\n", "aspect_batch", "=", "torch", ".", "Tensor", "(", "aspect_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "# batch size, hidden dim", "\n", "sentiment_batch", "=", "torch", ".", "Tensor", "(", "sentiment_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "# batch size, hidden dim", "\n", "\n", "y_batch", "=", "[", "tokenizer", ".", "encode", "(", "y", ")", "for", "y", "in", "y_batch", "]", "\n", "output_batch", ",", "output_mask_batch", "=", "utils", ".", "pad_text", "(", "y_batch", ")", "\n", "\n", "pred_batch", "=", "model", ".", "beam_search", "(", "tokens_batch", ",", "token_ids_batch", ",", "token_mask_batch", ",", "\n", "aspect_batch", ",", "sentiment_batch", ",", "beam_size", "=", "args", ".", "beam_size", ",", "max_len", "=", "args", ".", "max_len", ")", "\n", "\n", "output", "=", "output_batch", "[", "0", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "pred", "=", "pred_batch", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "output", "=", "list", "(", "[", "int", "(", "y", ")", "for", "y", "in", "output", "if", "int", "(", "y", ")", "!=", "101", "]", ")", "\n", "pred", "=", "list", "(", "[", "int", "(", "p", ")", "for", "p", "in", "pred", "if", "int", "(", "p", ")", "!=", "101", "]", ")", "\n", "output", "=", "output", "[", ":", "output", ".", "index", "(", "102", ")", "]", "\n", "try", ":", "\n", "      ", "pred", "=", "pred", "[", ":", "pred", ".", "index", "(", "102", ")", "]", "\n", "", "except", ":", "\n", "      ", "pass", "\n", "", "output", "=", "tokenizer", ".", "decode", "(", "output", ")", "\n", "pred", "=", "tokenizer", ".", "decode", "(", "pred", ")", "\n", "if", "args", ".", "data_type", "==", "'rotten'", ":", "\n", "      ", "output", "=", "output", ".", "replace", "(", "'<movie>'", ",", "m_batch", "[", "0", "]", ")", "\n", "pred", "=", "pred", ".", "replace", "(", "'<movie>'", ",", "m_batch", "[", "0", "]", ")", "\n", "\n", "", "f_sol", ".", "write", "(", "pred", "+", "'\\n'", ")", "\n", "\n", "if", "printing", ":", "\n", "      ", "printing", "-=", "1", "\n", "tqdm", ".", "write", "(", "'gold: %s'", "%", "output", ")", "\n", "tqdm", ".", "write", "(", "'pred: %s'", "%", "pred", ")", "\n", "tqdm", ".", "write", "(", "\"----------------------------------------------\"", ")", "\n", "\n", "", "", "f_sol", ".", "close", "(", ")", "\n", "print", "(", "'Summaries saved.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.GradientReverse.forward": [[16, 20], ["inp.clone"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inp", ")", ":", "\n", "    ", "out", "=", "inp", ".", "clone", "(", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.GradientReverse.backward": [[21, 24], ["grad_out.neg"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_out", ")", ":", "\n", "    ", "return", "grad_out", ".", "neg", "(", ")", "*", "GradientReverse", ".", "lambd", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.__init__": [[33, 54], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Abstract.__init__"], ["  ", "def", "__init__", "(", "self", ",", "aspect_dim", ",", "sentiment_dim", ",", "input_dim", ",", "hidden_dim", ",", "vocab_size", ")", ":", "\n", "    ", "super", "(", "Condense", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "aspect_dim", "=", "aspect_dim", "\n", "self", ".", "sentiment_dim", "=", "sentiment_dim", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "\n", "self", ".", "aspect_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "aspect_dim", ",", "hidden_dim", "//", "2", ")", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "aspect_embedding", ")", "\n", "self", ".", "sentiment_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "sentiment_dim", ",", "hidden_dim", "//", "2", ")", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "sentiment_embedding", ")", "\n", "\n", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "input_dim", ",", "hidden_dim", "//", "2", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "doc_asp_classifier", "=", "nn", ".", "Linear", "(", "hidden_dim", "//", "2", ",", "aspect_dim", ")", "\n", "self", ".", "doc_sen_classifier", "=", "nn", ".", "Linear", "(", "hidden_dim", "//", "2", ",", "sentiment_dim", ")", "\n", "\n", "self", ".", "adv_classifier", "=", "nn", ".", "Linear", "(", "hidden_dim", "//", "2", ",", "sentiment_dim", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.forward": [[56, 75], ["model.Condense.encoder", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.chunk", "torch.sum.chunk", "torch.sum.chunk", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "model.reverse_gradient", "torch.softmax", "torch.softmax", "torch.softmax", "model.Condense.doc_asp_classifier", "model.Condense.doc_sen_classifier", "model.Condense.adv_classifier", "mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.reverse_gradient"], ["", "def", "forward", "(", "self", ",", "tokens", ",", "mask", ",", "outputs", ",", "lambd", "=", "1", ")", ":", "\n", "    ", "tokens", "=", "self", ".", "encoder", "(", "tokens", ")", "\n", "tokens", "=", "tokens", "[", "0", "]", "\n", "\n", "doc", "=", "torch", ".", "sum", "(", "tokens", "*", "mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "dim", "=", "1", ")", "# before encoding", "\n", "\n", "a_doc", ",", "s_doc", "=", "doc", ".", "chunk", "(", "2", ",", "-", "1", ")", "\n", "\n", "prob_a", "=", "F", ".", "softmax", "(", "self", ".", "doc_asp_classifier", "(", "a_doc", ")", ",", "dim", "=", "1", ")", "\n", "prob_s", "=", "F", ".", "softmax", "(", "self", ".", "doc_sen_classifier", "(", "s_doc", ")", ",", "dim", "=", "1", ")", "\n", "\n", "aspect", "=", "torch", ".", "matmul", "(", "prob_a", ",", "self", ".", "aspect_embedding", ")", "\n", "sentiment", "=", "torch", ".", "matmul", "(", "prob_s", ",", "self", ".", "sentiment_embedding", ")", "\n", "\n", "# ADVERSARIAL", "\n", "adv_a_doc", "=", "reverse_gradient", "(", "a_doc", ",", "lambd", ")", "\n", "adv_prob_s", "=", "F", ".", "softmax", "(", "self", ".", "adv_classifier", "(", "adv_a_doc", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "(", "a_doc", ",", "s_doc", ")", ",", "(", "aspect", ",", "sentiment", ")", ",", "prob_s", ",", "adv_prob_s", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.condense": [[77, 88], ["model.Condense.encoder", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.chunk", "torch.sum.chunk", "torch.sum.chunk", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "model.Condense.doc_asp_classifier", "model.Condense.doc_sen_classifier", "mask.unsqueeze"], "methods", ["None"], ["", "def", "condense", "(", "self", ",", "tokens", ",", "mask", ")", ":", "\n", "    ", "tokens", "=", "self", ".", "encoder", "(", "tokens", ")", "\n", "tokens", "=", "tokens", "[", "0", "]", "\n", "\n", "doc", "=", "torch", ".", "sum", "(", "tokens", "*", "mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "dim", "=", "1", ")", "# before encoding", "\n", "a_doc", ",", "s_doc", "=", "doc", ".", "chunk", "(", "2", ",", "-", "1", ")", "\n", "\n", "prob_a", "=", "F", ".", "softmax", "(", "self", ".", "doc_asp_classifier", "(", "a_doc", ")", ",", "dim", "=", "1", ")", "\n", "prob_s", "=", "F", ".", "softmax", "(", "self", ".", "doc_sen_classifier", "(", "s_doc", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "tokens", ",", "doc", ",", "prob_a", ",", "prob_s", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.calculate_loss": [[90, 122], ["before[].view", "after[].view", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "torch.max.mean", "torch.max.mean", "torch.max.mean", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "asp_norm_loss.abs().sum.abs().sum.abs().sum", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "sen_norm_loss.abs().sum.abs().sum.abs().sum", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "numpy.random.permutation", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "sen_pred.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "adv_pred.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.arange", "torch.norm.t", "torch.norm.t", "torch.norm.t", "asp_norm_loss.abs().sum.abs().sum.abs", "torch.norm.t", "torch.norm.t", "torch.norm.t", "sen_norm_loss.abs().sum.abs().sum.abs", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "before[].view.size"], "methods", ["None"], ["", "def", "calculate_loss", "(", "self", ",", "before", ",", "after", ",", "sen_pred", ",", "adv_pred", ",", "sen_gold", ")", ":", "\n", "    ", "before", "=", "before", "[", "0", "]", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_dim", "//", "2", ")", "\n", "after", "=", "after", "[", "0", "]", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_dim", "//", "2", ")", "\n", "\n", "asp_loss", "=", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", "\n", "pos_sim", "=", "(", "before", "*", "after", ")", ".", "sum", "(", "1", ")", "\n", "for", "k", "in", "range", "(", "5", ")", ":", "\n", "      ", "shuffle_indices", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "before", ".", "size", "(", ")", "[", "0", "]", ")", ")", "\n", "negative", "=", "before", "[", "shuffle_indices", "]", "\n", "neg_sim", "=", "(", "negative", "*", "after", ")", ".", "sum", "(", "1", ")", "\n", "asp_loss", "=", "torch", ".", "max", "(", "asp_loss", ",", "1", "-", "pos_sim", "+", "neg_sim", ")", "\n", "", "asp_loss", "=", "asp_loss", ".", "mean", "(", ")", "\n", "\n", "asp_norm", "=", "torch", ".", "norm", "(", "self", ".", "aspect_embedding", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "asp_norm", "=", "self", ".", "aspect_embedding", "/", "asp_norm", "\n", "asp_norm_loss", "=", "torch", ".", "matmul", "(", "asp_norm", ",", "asp_norm", ".", "t", "(", ")", ")", "-", "torch", ".", "eye", "(", "self", ".", "aspect_dim", ")", ".", "cuda", "(", ")", "\n", "asp_norm_loss", "=", "asp_norm_loss", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "\n", "sen_pred", "=", "sen_pred", "+", "1e-9", "\n", "sen_pred", "=", "sen_pred", "/", "sen_pred", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "sen_loss", "=", "F", ".", "nll_loss", "(", "torch", ".", "log", "(", "sen_pred", ")", ",", "sen_gold", ")", "\n", "\n", "sen_norm", "=", "torch", ".", "norm", "(", "self", ".", "sentiment_embedding", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "sen_norm", "=", "self", ".", "sentiment_embedding", "/", "sen_norm", "\n", "sen_norm_loss", "=", "torch", ".", "matmul", "(", "sen_norm", ",", "sen_norm", ".", "t", "(", ")", ")", "-", "torch", ".", "eye", "(", "self", ".", "sentiment_dim", ")", ".", "cuda", "(", ")", "\n", "sen_norm_loss", "=", "sen_norm_loss", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "\n", "adv_pred", "=", "adv_pred", "+", "1e-9", "\n", "adv_pred", "=", "adv_pred", "/", "adv_pred", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "adv_loss", "=", "F", ".", "nll_loss", "(", "torch", ".", "log", "(", "adv_pred", ")", ",", "sen_gold", ")", "\n", "\n", "return", "asp_loss", ",", "asp_norm_loss", ",", "sen_loss", ",", "sen_norm_loss", ",", "adv_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.get_aspect": [[124, 126], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "get_aspect", "(", "self", ",", "prob_a", ")", ":", "\n", "    ", "return", "torch", ".", "matmul", "(", "prob_a", ",", "self", ".", "aspect_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.get_sentiment": [[128, 130], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "get_sentiment", "(", "self", ",", "prob_s", ")", ":", "\n", "    ", "return", "torch", ".", "matmul", "(", "prob_s", ",", "self", ".", "sentiment_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Abstract.__init__": [[134, 162], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Abstract.__init__"], ["  ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "input_dim", ",", "hidden_dim", ")", ":", "\n", "    ", "super", "(", "Abstract", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "input_dim", ")", "\n", "self", ".", "iso_transform", "=", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", "\n", "self", ".", "iso_mlp", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "\n", "self", ".", "ht_transform", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "2", "*", "hidden_dim", ")", "\n", "self", ".", "yt_transform", "=", "nn", ".", "Linear", "(", "input_dim", "+", "hidden_dim", ",", "hidden_dim", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "LSTM", "(", "hidden_dim", ",", "hidden_dim", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "attend_key", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "attend_query", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "attend_weight", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n", "self", ".", "pointer", "=", "nn", ".", "Linear", "(", "hidden_dim", "*", "3", ",", "1", ")", "\n", "\n", "self", ".", "att_classifier", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "vocab_size", ")", "\n", "\n", "self", ".", "dec_classifier", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "vocab_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Abstract.forward": [[164, 229], ["model.Abstract.size", "output.size", "model.Abstract.iso_transform", "model.Abstract.iso_mlp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Abstract.embedding", "model.Abstract.dropout", "zt.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "model.Abstract.yt_transform", "model.Abstract.ht_transform().chunk", "st.unsqueeze().contiguous.unsqueeze().contiguous.unsqueeze().contiguous", "ct.unsqueeze().contiguous.unsqueeze().contiguous.unsqueeze().contiguous", "model.Abstract.decoder", "model.Abstract.attend_key().unsqueeze", "model.Abstract.attend_query().unsqueeze", "model.Abstract.attend_weight().softmax", "at.squeeze.squeeze.squeeze", "model.Abstract.pointer().sigmoid", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "token_ids.unsqueeze().expand().contiguous().view", "output_mask[].contiguous", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "output_smooth[].contiguous", "loss.mean.mean.mean", "model.Abstract.embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "token_mask.mean().unsqueeze", "token_mask.unsqueeze().unsqueeze", "at.squeeze.squeeze.sum", "loss.mean.mean.sum", "loss.mean.mean.sum", "output_mask[].contiguous.sum", "loss2.mean.mean.mean", "zt.unsqueeze().expand.unsqueeze().expand.unsqueeze", "model.Abstract.ht_transform", "st.unsqueeze().contiguous.unsqueeze().contiguous.unsqueeze", "ct.unsqueeze().contiguous.unsqueeze().contiguous.unsqueeze", "model.Abstract.attend_key", "model.Abstract.attend_query", "model.Abstract.attend_weight", "model.Abstract.pointer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "token_ids.unsqueeze().expand().contiguous", "pt.argmax().eq", "loss2.mean.mean.sum", "output_mask[].contiguous.sum", "token_mask.unsqueeze", "token_mask.mean", "token_mask.unsqueeze", "model.Abstract.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Abstract.dec_classifier", "model.Abstract.att_classifier", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "token_ids.unsqueeze().expand", "pt.argmax", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "token_ids.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ",", "token_ids", ",", "token_mask", ",", "\n", "aspect", ",", "sentiment", ",", "\n", "output", ",", "output_smooth", ",", "output_mask", ",", "\n", "dev", "=", "False", ")", ":", "\n", "    ", "batch_size", ",", "token_len", ",", "hidden_dim", "=", "tokens", ".", "size", "(", ")", "\n", "_", ",", "output_len", "=", "output", ".", "size", "(", ")", "\n", "output_len", "-=", "1", "\n", "\n", "xt", "=", "self", ".", "iso_transform", "(", "self", ".", "embedding", "(", "token_ids", ")", ")", "\n", "xt", "=", "xt", "+", "tokens", "\n", "tokens", "=", "self", ".", "iso_mlp", "(", "xt", ")", "\n", "\n", "zt", "=", "torch", ".", "cat", "(", "[", "aspect", ",", "sentiment", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# embed output tokens", "\n", "yt", "=", "self", ".", "embedding", "(", "output", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "yt", "=", "self", ".", "dropout", "(", "yt", ")", "\n", "zt", "=", "zt", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "output_len", ",", "-", "1", ")", "\n", "\n", "yzt", "=", "self", ".", "yt_transform", "(", "torch", ".", "cat", "(", "[", "yt", ",", "zt", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "# decode, attend, point", "\n", "input_", "=", "(", "tokens", "*", "token_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "input_", "=", "input_", "/", "token_mask", ".", "mean", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "st", ",", "ct", "=", "self", ".", "ht_transform", "(", "input_", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "st", "=", "st", ".", "unsqueeze", "(", "0", ")", ".", "contiguous", "(", ")", "\n", "ct", "=", "ct", ".", "unsqueeze", "(", "0", ")", ".", "contiguous", "(", ")", "\n", "\n", "st", ",", "_", "=", "self", ".", "decoder", "(", "yzt", ",", "(", "st", ",", "ct", ")", ")", "\n", "\n", "kt", "=", "self", ".", "attend_key", "(", "tokens", ")", ".", "unsqueeze", "(", "1", ")", "# batch size, 1, token len, hidden dim", "\n", "qt", "=", "self", ".", "attend_query", "(", "st", ")", ".", "unsqueeze", "(", "2", ")", "# batch size, output len, 1, hidden dim", "\n", "at", "=", "self", ".", "attend_weight", "(", "(", "kt", "+", "qt", ")", ".", "tanh", "(", ")", ")", ".", "softmax", "(", "dim", "=", "2", ")", "# batch size, output len, token len, 1", "\n", "at", "=", "at", "*", "token_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "at", "=", "at", "/", "at", ".", "sum", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "vt", "=", "(", "tokens", ".", "unsqueeze", "(", "1", ")", "*", "at", ")", ".", "sum", "(", "dim", "=", "2", ")", "# batch size, output len, hidden dim", "\n", "at", "=", "at", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "gt", "=", "self", ".", "pointer", "(", "torch", ".", "cat", "(", "[", "yzt", ",", "st", ",", "vt", "]", ",", "dim", "=", "-", "1", ")", ")", ".", "sigmoid", "(", ")", "\n", "p_copy", "=", "torch", ".", "zeros", "(", "batch_size", ",", "output_len", ",", "self", ".", "vocab_size", ")", ".", "cuda", "(", ")", "\n", "bindex", "=", "torch", ".", "arange", "(", "0", ",", "batch_size", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "token_len", "*", "output_len", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "oindex", "=", "torch", ".", "arange", "(", "0", ",", "output_len", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "token_len", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "tindex", "=", "torch", ".", "arange", "(", "0", ",", "token_len", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "output_len", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "vindex", "=", "token_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "output_len", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "p_copy", "[", "bindex", ",", "oindex", ",", "vindex", "]", "+=", "at", "[", "bindex", ",", "oindex", ",", "tindex", "]", "\n", "\n", "p_generate", "=", "(", "self", ".", "dec_classifier", "(", "st", ")", "+", "self", ".", "att_classifier", "(", "vt", ")", ")", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "pt", "=", "gt", "*", "p_generate", "+", "(", "1", "-", "gt", ")", "*", "p_copy", "\n", "\n", "mask", "=", "output_mask", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "log_pt", "=", "torch", ".", "log", "(", "pt", "+", "1e-9", ")", "# b, s, v", "\n", "yt_", "=", "output_smooth", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "# b, s, v", "\n", "\n", "loss", "=", "-", "log_pt", "*", "yt_", "# b, s, v", "\n", "loss", "=", "loss", ".", "sum", "(", "-", "1", ")", "*", "mask", "# b, s", "\n", "loss", "=", "loss", ".", "sum", "(", "-", "1", ")", "/", "mask", ".", "sum", "(", "-", "1", ")", "# b", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "if", "dev", ":", "\n", "      ", "loss2", "=", "pt", ".", "argmax", "(", "-", "1", ")", ".", "eq", "(", "output", "[", ":", ",", "1", ":", "]", ")", "*", "mask", "# b, s", "\n", "loss2", "=", "loss2", ".", "sum", "(", "1", ")", "/", "mask", ".", "sum", "(", "1", ")", "# b", "\n", "loss2", "=", "loss2", ".", "mean", "(", ")", "\n", "\n", "loss", "=", "(", "loss", ",", "loss2", ")", "\n", "\n", "", "return", "pt", ",", "gt", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Abstract.beam_search": [[231, 341], ["model.Abstract.size", "model.Abstract.iso_transform", "model.Abstract.iso_mlp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Abstract.ht_transform().chunk", "zt.unsqueeze.unsqueeze.unsqueeze", "s0.view.view.view", "c0.view.view.view", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "model.Abstract.embedding", "token_mask.mean().unsqueeze", "len", "utils.pad_text", "model.Abstract.embedding", "model.Abstract.size", "model.Abstract.yt_transform", "s0.view.view.expand().contiguous", "c0.view.view.expand().contiguous", "model.Abstract.decoder", "model.Abstract.attend_key().unsqueeze", "model.Abstract.attend_query().unsqueeze", "model.Abstract.attend_weight().softmax", "at.squeeze.squeeze.squeeze", "model.Abstract.pointer().sigmoid", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "torch.arange().unsqueeze().unsqueeze().expand().contiguous().view", "token_ids.unsqueeze().expand().contiguous().view", "zip", "sorted", "model.Abstract.ht_transform", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "token_mask.unsqueeze().unsqueeze", "at.squeeze.squeeze.sum", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "zip", "sorted", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "token_mask.unsqueeze", "token_mask.mean", "s0.view.view.expand", "c0.view.view.expand", "model.Abstract.attend_key", "model.Abstract.attend_query", "model.Abstract.attend_weight", "model.Abstract.pointer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "torch.arange().unsqueeze().unsqueeze().expand().contiguous", "token_ids.unsqueeze().expand().contiguous", "len", "finished.append", "finished.append", "new_beam.append", "zt.unsqueeze.unsqueeze.expand", "token_mask.unsqueeze", "model.Abstract.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Abstract.dec_classifier", "model.Abstract.att_classifier", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "torch.arange().unsqueeze().unsqueeze().expand", "token_ids.unsqueeze().expand", "len", "len", "len", "len", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "len", "tuple", "model.Abstract.item", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "len", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "tuple", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "torch.arange().unsqueeze().unsqueeze", "token_ids.unsqueeze", "model.Abstract.item", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "model.Abstract.item", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text"], ["", "def", "beam_search", "(", "self", ",", "tokens", ",", "token_ids", ",", "token_mask", ",", "\n", "aspect", ",", "sentiment", ",", "start_idx", "=", "101", ",", "end_idx", "=", "102", ",", "\n", "beam_size", "=", "1", ",", "max_len", "=", "200", ",", "dev", "=", "False", ")", ":", "\n", "    ", "batch_size", ",", "token_len", ",", "hidden_dim", "=", "tokens", ".", "size", "(", ")", "\n", "\n", "xt", "=", "self", ".", "iso_transform", "(", "self", ".", "embedding", "(", "token_ids", ")", ")", "\n", "xt", "=", "xt", "+", "tokens", "\n", "tokens", "=", "self", ".", "iso_mlp", "(", "xt", ")", "\n", "\n", "zt", "=", "torch", ".", "cat", "(", "[", "aspect", ",", "sentiment", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "input_", "=", "(", "tokens", "*", "token_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "input_", "=", "input_", "/", "token_mask", ".", "mean", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "s0", ",", "c0", "=", "self", ".", "ht_transform", "(", "input_", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "zt", "=", "zt", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "s0", "=", "s0", ".", "view", "(", "1", ",", "1", ",", "self", ".", "hidden_dim", ")", "\n", "c0", "=", "c0", ".", "view", "(", "1", ",", "1", ",", "self", ".", "hidden_dim", ")", "\n", "\n", "beam", "=", "[", "{", "\n", "'input'", ":", "[", "start_idx", "]", ",", "#torch.tensor([start_idx]).cuda(),", "\n", "'prob'", ":", "0", ",", "\n", "'prob_norm'", ":", "0", ",", "\n", "'trigrams'", ":", "[", "]", "\n", "}", "]", "\n", "finished", "=", "[", "]", "\n", "\n", "while", "len", "(", "beam", ")", "!=", "0", ":", "\n", "      ", "new_beam", "=", "[", "]", "\n", "\n", "inp_batch", "=", "[", "instance", "[", "'input'", "]", "for", "instance", "in", "beam", "]", "\n", "inp_batch", ",", "_", "=", "utils", ".", "pad_text", "(", "inp_batch", ")", "\n", "\n", "yt", "=", "self", ".", "embedding", "(", "inp_batch", ")", "\n", "\n", "batch_size", ",", "output_len", ",", "_", "=", "yt", ".", "size", "(", ")", "\n", "yzt", "=", "self", ".", "yt_transform", "(", "torch", ".", "cat", "(", "[", "yt", ",", "zt", ".", "expand", "(", "batch_size", ",", "output_len", ",", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "s0_", "=", "s0", ".", "expand", "(", "-", "1", ",", "batch_size", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "c0_", "=", "c0", ".", "expand", "(", "-", "1", ",", "batch_size", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "st", ",", "_", "=", "self", ".", "decoder", "(", "yzt", ",", "(", "s0_", ",", "c0_", ")", ")", "\n", "\n", "kt", "=", "self", ".", "attend_key", "(", "tokens", ")", ".", "unsqueeze", "(", "1", ")", "\n", "qt", "=", "self", ".", "attend_query", "(", "st", ")", ".", "unsqueeze", "(", "2", ")", "# batch size, output len, 1, hidden dim", "\n", "at", "=", "self", ".", "attend_weight", "(", "(", "kt", "+", "qt", ")", ".", "tanh", "(", ")", ")", ".", "softmax", "(", "dim", "=", "2", ")", "# batch size, output len, token len, 1", "\n", "at", "=", "at", "*", "token_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "at", "=", "at", "/", "at", ".", "sum", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "vt", "=", "(", "tokens", ".", "unsqueeze", "(", "1", ")", "*", "at", ")", ".", "sum", "(", "dim", "=", "2", ")", "# batch size, output len, hidden dim", "\n", "at", "=", "at", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "gt", "=", "self", ".", "pointer", "(", "torch", ".", "cat", "(", "[", "yzt", ",", "st", ",", "vt", "]", ",", "dim", "=", "-", "1", ")", ")", ".", "sigmoid", "(", ")", "\n", "p_copy", "=", "torch", ".", "zeros", "(", "batch_size", ",", "output_len", ",", "self", ".", "vocab_size", ")", ".", "cuda", "(", ")", "\n", "bindex", "=", "torch", ".", "arange", "(", "0", ",", "batch_size", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "token_len", "*", "output_len", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "oindex", "=", "torch", ".", "arange", "(", "0", ",", "output_len", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "token_len", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "tindex", "=", "torch", ".", "arange", "(", "0", ",", "token_len", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "output_len", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "vindex", "=", "token_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "output_len", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "p_copy", "[", "bindex", ",", "oindex", ",", "vindex", "]", "+=", "at", "[", "bindex", ",", "oindex", ",", "tindex", "]", "\n", "\n", "p_generate", "=", "(", "self", ".", "dec_classifier", "(", "st", ")", "+", "self", ".", "att_classifier", "(", "vt", ")", ")", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "pt_batch", "=", "gt", "*", "p_generate", "+", "(", "1", "-", "gt", ")", "*", "p_copy", "\n", "\n", "for", "pt", ",", "instance", "in", "zip", "(", "pt_batch", ",", "beam", ")", ":", "\n", "        ", "inp", "=", "instance", "[", "'input'", "]", "\n", "prob", "=", "instance", "[", "'prob'", "]", "\n", "trigrams", "=", "instance", "[", "'trigrams'", "]", "\n", "\n", "if", "len", "(", "inp", ")", "==", "max_len", ":", "\n", "          ", "finished", ".", "append", "(", "instance", ")", "\n", "continue", "\n", "", "if", "inp", "[", "-", "1", "]", "==", "end_idx", ":", "\n", "          ", "finished", ".", "append", "(", "instance", ")", "\n", "continue", "\n", "\n", "", "pt", "=", "pt", "[", "len", "(", "inp", ")", "-", "1", "]", "\n", "\n", "pk", ",", "yk", "=", "torch", ".", "topk", "(", "pt", ",", "k", "=", "20", ",", "dim", "=", "-", "1", ")", "\n", "count", "=", "0", "\n", "nuclear", "=", "0", "\n", "for", "pt", ",", "yt", "in", "zip", "(", "pk", ",", "yk", ")", ":", "\n", "          ", "if", "count", "==", "beam_size", ":", "\n", "            ", "break", "\n", "\n", "", "if", "not", "dev", ":", "\n", "            ", "if", "yt", "==", "end_idx", "and", "len", "(", "inp", ")", "<", "10", ":", "\n", "              ", "continue", "\n", "", "if", "len", "(", "inp", ")", ">=", "1", ":", "\n", "              ", "if", "inp", "[", "-", "1", "]", "==", "yt", ":", "\n", "                ", "continue", "\n", "", "", "if", "len", "(", "inp", ")", ">=", "1", ":", "\n", "              ", "if", "tuple", "(", "inp", "[", "-", "1", ":", "]", "+", "[", "yt", ".", "item", "(", ")", "]", ")", "in", "trigrams", ":", "\n", "                ", "continue", "\n", "", "", "if", "len", "(", "inp", ")", ">=", "3", ":", "\n", "              ", "if", "inp", "[", "-", "3", ":", "-", "1", "]", "==", "inp", "[", "-", "1", ":", "]", "+", "[", "yt", ".", "item", "(", ")", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "", "", "count", "+=", "1", "\n", "new_instance", "=", "{", "\n", "'input'", ":", "inp", "+", "[", "yt", ".", "item", "(", ")", "]", ",", "#torch.cat([inp, yt.unsqueeze(0)], dim=-1),", "\n", "'prob'", ":", "prob", "+", "torch", ".", "log", "(", "pt", ")", ",", "\n", "'prob_norm'", ":", "(", "prob", "+", "torch", ".", "log", "(", "pt", ")", ")", "/", "(", "len", "(", "inp", ")", "+", "1", ")", ",", "\n", "'prob_ln'", ":", "(", "prob", "+", "torch", ".", "log", "(", "pt", ")", ")", "/", "(", "(", "5", "+", "len", "(", "inp", ")", ")", "**", "0.6", "/", "6", "**", "0.6", ")", ",", "\n", "'trigrams'", ":", "trigrams", "+", "[", "tuple", "(", "inp", "[", "-", "2", ":", "]", ")", "]", "\n", "}", "\n", "new_beam", ".", "append", "(", "new_instance", ")", "\n", "\n", "", "", "beam", "=", "sorted", "(", "new_beam", ",", "key", "=", "lambda", "a", ":", "-", "a", "[", "'prob_norm'", "]", ")", "[", ":", "beam_size", "]", "\n", "\n", "", "finished", "=", "sorted", "(", "finished", ",", "key", "=", "lambda", "a", ":", "-", "a", "[", "'prob_norm'", "]", ")", "[", "0", "]", "\n", "return", "torch", ".", "Tensor", "(", "finished", "[", "'input'", "]", ")", ".", "cuda", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.reverse_gradient": [[26, 29], ["GradientReverse.apply"], "function", ["None"], ["", "", "def", "reverse_gradient", "(", "x", ",", "lambd", ")", ":", "\n", "  ", "GradientReverse", ".", "lambd", "=", "lambd", "\n", "return", "GradientReverse", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.get_movie": [[11, 32], ["movie.replace().split.replace().split", "len", "int", "movie.replace().split.replace", "len", "int"], "function", ["None"], ["def", "get_movie", "(", "movie", ")", ":", "\n", "  ", "movie", "=", "movie", ".", "replace", "(", "'-'", ",", "'_'", ")", ".", "split", "(", "'_'", ")", "\n", "\n", "if", "len", "(", "movie", ")", ">", "1", ":", "\n", "    ", "if", "len", "(", "movie", "[", "-", "1", "]", ")", "==", "4", ":", "\n", "      ", "try", ":", "\n", "        ", "int", "(", "movie", "[", "-", "1", "]", ")", "\n", "movie", "=", "movie", "[", ":", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "", "", "", "try", ":", "\n", "    ", "int", "(", "movie", "[", "0", "]", ")", "\n", "movie", "=", "movie", "[", "1", ":", "]", "\n", "", "except", ":", "\n", "    ", "pass", "\n", "", "movie", "=", "' '", ".", "join", "(", "movie", ")", "\n", "if", "movie", "==", "''", ":", "\n", "    ", "movie", "=", "'<movie>'", "# for condasum", "\n", "#movie = 'MOV'", "\n", "\n", "", "return", "movie", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.get_movies_from_file": [[34, 45], ["open", "json.load", "open.close", "m_data.append", "utils.get_movie"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.get_movie"], ["", "def", "get_movies_from_file", "(", "file", ")", ":", "\n", "  ", "f", "=", "open", "(", "file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "\n", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "m_data", "=", "[", "]", "\n", "for", "inst", "in", "data", ":", "\n", "    ", "movie", "=", "inst", "[", "'movie'", "]", "\n", "m_data", ".", "append", "(", "get_movie", "(", "movie", ")", ")", "\n", "\n", "", "return", "m_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.condense_data": [[47, 71], ["open", "json.load", "open.close", "tqdm.tqdm", "review.replace().strip.replace().strip", "x_data.append", "y_data.append", "review.replace().strip.replace"], "function", ["None"], ["", "def", "condense_data", "(", "file", ",", "adjust_sentiment", "=", "0", ")", ":", "\n", "  ", "\"\"\"\n    Preprocess dataset for Condense model.\n  \"\"\"", "\n", "f", "=", "open", "(", "file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "\n", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "x_data", "=", "[", "]", "\n", "y_data", "=", "[", "]", "# sentiment labels", "\n", "\n", "for", "instance", "in", "tqdm", "(", "data", ")", ":", "\n", "    ", "for", "review", "in", "instance", "[", "'reviews'", "]", ":", "\n", "      ", "review", ",", "sentiment", "=", "review", "\n", "if", "sentiment", "==", "-", "1", ":", "\n", "        ", "continue", "\n", "", "sentiment", "-=", "adjust_sentiment", "\n", "\n", "review", "=", "review", ".", "replace", "(", "'MOV'", ",", "'<movie>'", ")", ".", "strip", "(", ")", "\n", "\n", "x_data", ".", "append", "(", "review", ")", "\n", "y_data", ".", "append", "(", "sentiment", ")", "\n", "\n", "", "", "return", "x_data", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.check_summary_worthy": [[73, 101], ["tokenizer.decode", "x.replace.replace", "x.replace.split", "re.sub", "len"], "function", ["None"], ["", "def", "check_summary_worthy", "(", "x", ",", "tokenizer", ",", "\n", "min_length", "=", "50", ",", "\n", "max_length", "=", "90", ",", "\n", "max_symbols", "=", "0", ",", "\n", "max_tridots", "=", "0", ")", ":", "\n", "  ", "\"\"\"\n    Check whether the review x is summary-worthy or not.\n  \"\"\"", "\n", "x", "=", "tokenizer", ".", "decode", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "replace", "(", "'<movie>'", ",", "'movie'", ")", "\n", "tokens", "=", "x", ".", "split", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "\n", "length", "=", "0", "\n", "num_symbols", "=", "0", "\n", "num_tridots", "=", "0", "\n", "\n", "for", "token", "in", "tokens", ":", "\n", "    ", "if", "token", "in", "[", "'[CLS]'", ",", "'[SEP]'", "]", ":", "\n", "      ", "continue", "\n", "", "length", "+=", "1", "\n", "if", "token", "==", "'...'", ":", "\n", "      ", "num_tridots", "+=", "1", "\n", "", "symbol", "=", "re", ".", "sub", "(", "\"[A-Za-z0-9]\"", ",", "''", ",", "token", ")", "\n", "if", "len", "(", "symbol", ")", ">", "0", "and", "symbol", "not", "in", "\",!.'\"", ":", "\n", "      ", "num_symbols", "+=", "1", "\n", "\n", "", "", "return", "length", ">=", "min_length", "and", "length", "<=", "max_length", "and", "num_symbols", "<=", "max_symbols", "and", "num_tridots", "<=", "max_tridots", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.abstract_data": [[103, 133], ["open", "json.load", "open.close", "tqdm.tqdm", "x_data.append", "review[].replace().strip", "reviews.append", "instance[].replace().strip", "y_data.append", "[].strip", "y_data.append", "review[].replace", "instance[].replace"], "function", ["None"], ["", "def", "abstract_data", "(", "file", ",", "multi_ref", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n    Preprocess dataset for Abstract model.\n  \"\"\"", "\n", "f", "=", "open", "(", "file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "\n", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "x_data", "=", "[", "]", "\n", "y_data", "=", "[", "]", "\n", "\n", "for", "instance", "in", "tqdm", "(", "data", ")", ":", "\n", "\n", "    ", "if", "not", "multi_ref", ":", "\n", "      ", "if", "'summary'", "in", "instance", ":", "\n", "        ", "summary", "=", "instance", "[", "'summary'", "]", ".", "replace", "(", "'MOV'", ",", "'<movie>'", ")", ".", "strip", "(", ")", "\n", "y_data", ".", "append", "(", "summary", ")", "\n", "", "", "else", ":", "\n", "      ", "if", "'summary'", "in", "instance", ":", "\n", "        ", "summary", "=", "instance", "[", "'summary'", "]", "[", "0", "]", ".", "strip", "(", ")", "\n", "y_data", ".", "append", "(", "summary", ")", "\n", "\n", "", "", "reviews", "=", "[", "]", "\n", "for", "review", "in", "instance", "[", "'reviews'", "]", ":", "\n", "      ", "review", "=", "review", "[", "0", "]", ".", "replace", "(", "'MOV'", ",", "'<movie>'", ")", ".", "strip", "(", ")", "\n", "reviews", ".", "append", "(", "review", ")", "\n", "\n", "", "x_data", ".", "append", "(", "reviews", ")", "\n", "\n", "", "return", "x_data", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text": [[135, 153], ["max", "torch.Tensor().long().cuda", "torch.Tensor().long().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "isinstance", "list", "torch.Tensor().float().cuda.append", "torch.Tensor().long().cuda.append", "len", "inst.tolist.tolist", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().float", "torch.Tensor().float", "len", "len", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["", "def", "pad_text", "(", "batch", ",", "pad_id", "=", "0", ")", ":", "\n", "  ", "max_length", "=", "max", "(", "len", "(", "inst", ")", "for", "inst", "in", "batch", ")", "\n", "\n", "inst_batch", "=", "[", "]", "\n", "mask_batch", "=", "[", "]", "\n", "for", "inst", "in", "batch", ":", "\n", "    ", "if", "isinstance", "(", "inst", ",", "torch", ".", "Tensor", ")", ":", "\n", "      ", "inst", "=", "inst", ".", "tolist", "(", ")", "\n", "", "inst", "=", "list", "(", "inst", ")", "\n", "mask", "=", "[", "1.0", "]", "*", "len", "(", "inst", ")", "+", "[", "0.0", "]", "*", "(", "max_length", "-", "len", "(", "inst", ")", ")", "\n", "inst", "=", "inst", "+", "[", "pad_id", "]", "*", "(", "max_length", "-", "len", "(", "inst", ")", ")", "\n", "mask_batch", ".", "append", "(", "mask", ")", "\n", "inst_batch", ".", "append", "(", "inst", ")", "\n", "\n", "", "inst_batch", "=", "torch", ".", "Tensor", "(", "inst_batch", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "mask_batch", "=", "torch", ".", "Tensor", "(", "mask_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "return", "inst_batch", ",", "mask_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_vector": [[155, 173], ["max", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "torch.Tensor().float().cuda", "isinstance", "list", "torch.Tensor().float().cuda.append", "torch.Tensor().float().cuda.append", "len", "inst.tolist.tolist", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "len", "len", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["", "def", "pad_vector", "(", "batch", ",", "vec_len", ")", ":", "\n", "  ", "max_length", "=", "max", "(", "len", "(", "inst", ")", "for", "inst", "in", "batch", ")", "\n", "\n", "inst_batch", "=", "[", "]", "\n", "mask_batch", "=", "[", "]", "\n", "for", "inst", "in", "batch", ":", "\n", "    ", "if", "isinstance", "(", "inst", ",", "torch", ".", "Tensor", ")", ":", "\n", "      ", "inst", "=", "inst", ".", "tolist", "(", ")", "\n", "", "inst", "=", "list", "(", "inst", ")", "\n", "mask", "=", "[", "1.0", "]", "*", "len", "(", "inst", ")", "+", "[", "0.0", "]", "*", "(", "max_length", "-", "len", "(", "inst", ")", ")", "\n", "inst", "=", "inst", "+", "[", "[", "0.0", "]", "*", "vec_len", "]", "*", "(", "max_length", "-", "len", "(", "inst", ")", ")", "\n", "mask_batch", ".", "append", "(", "mask", ")", "\n", "inst_batch", ".", "append", "(", "inst", ")", "\n", "\n", "", "inst_batch", "=", "torch", ".", "Tensor", "(", "inst_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "mask_batch", "=", "torch", ".", "Tensor", "(", "mask_batch", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "return", "inst_batch", ",", "mask_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.concat_pad": [[175, 185], ["utils.pad_text", "new_batch.append"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text"], ["", "def", "concat_pad", "(", "batch", ")", ":", "\n", "  ", "new_batch", "=", "[", "]", "\n", "\n", "for", "inst", "in", "batch", ":", "\n", "    ", "new_inst", "=", "[", "]", "\n", "for", "doc", "in", "inst", ":", "\n", "      ", "new_inst", "+=", "doc", "\n", "", "new_batch", ".", "append", "(", "new_inst", ")", "\n", "\n", "", "return", "pad_text", "(", "new_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.get_distance": [[187, 197], ["print", "print", "utils.get_distance.hellinger"], "function", ["None"], ["", "def", "get_distance", "(", "a", ",", "b", ")", ":", "\n", "  ", "def", "hellinger", "(", "p", ",", "q", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "(", "np", ".", "sqrt", "(", "p", ")", "-", "np", ".", "sqrt", "(", "q", ")", ")", "**", "2", ")", ")", "/", "np", ".", "sqrt", "(", "2", ")", "\n", "\n", "", "print", "(", "a", ")", "\n", "print", "(", "b", ")", "\n", "asp_dist", "=", "hellinger", "(", "a", "[", "0", "]", ",", "b", "[", "0", "]", ")", "\n", "sen_dist", "=", "hellinger", "(", "a", "[", "1", "]", ",", "b", "[", "1", "]", ")", "\n", "\n", "return", "asp_dist", "+", "sen_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.run_condense": [[199, 254], ["len", "utils.pad_text", "encoder", "model.condense", "tokens.contiguous().view.contiguous().view", "token_ids.view.view", "mask.view.view", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.arange", "torch.arange", "torch.zeros().cuda.nonzero().squeeze", "torch.zeros().cuda.nonzero().squeeze", "model.get_aspect().squeeze().cpu().detach().numpy", "model.get_sentiment().squeeze().cpu().detach().numpy", "tokens_data.append", "token_ids_data.append", "aspect_data.append", "sentiment_data.append", "tokens.contiguous().view.size", "token_ids.view.size", "torch.zeros().cuda.unsqueeze", "torch.zeros().cuda.cpu().detach().numpy", "cnt_tokens.nonzero().squeeze.cpu().detach().numpy", "tokens.contiguous().view.contiguous", "tokens.contiguous().view.size", "token_ids.view.size", "tokens.contiguous().view.size", "mask.view.size", "mask.view.nonzero().squeeze", "mask.view.nonzero().squeeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().cuda.nonzero", "torch.zeros().cuda.nonzero", "model.get_aspect().squeeze().cpu().detach", "model.get_sentiment().squeeze().cpu().detach", "torch.zeros().cuda.cpu().detach", "cnt_tokens.nonzero().squeeze.cpu().detach", "mask.view.nonzero", "mask.view.nonzero", "model.get_aspect().squeeze().cpu", "model.get_sentiment().squeeze().cpu", "torch.zeros().cuda.cpu", "cnt_tokens.nonzero().squeeze.cpu", "model.get_aspect().squeeze", "model.get_sentiment().squeeze", "model.get_aspect", "model.get_sentiment", "prob_a.mean", "prob_s.mean"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.condense", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.get_aspect", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.model.Condense.get_sentiment"], ["", "def", "run_condense", "(", "x_data", ",", "tokenizer", ",", "encoder", ",", "model", ")", ":", "\n", "  ", "\"\"\"\n    Runs the Condense model then aggregates outputs for each batch.\n  \"\"\"", "\n", "vocab_size", "=", "len", "(", "tokenizer", ")", "\n", "\n", "tokens_data", "=", "[", "]", "\n", "token_ids_data", "=", "[", "]", "\n", "aspect_data", "=", "[", "]", "\n", "sentiment_data", "=", "[", "]", "\n", "\n", "for", "x_batch", "in", "x_data", ":", "\n", "    ", "token_ids", ",", "mask", "=", "pad_text", "(", "x_batch", ")", "\n", "\n", "tokens", "=", "encoder", "(", "token_ids", ")", "\n", "\n", "tokens", ",", "_", ",", "prob_a", ",", "prob_s", "=", "model", ".", "condense", "(", "tokens", ",", "mask", ")", "\n", "\n", "hidden_dim", "=", "tokens", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "\n", "tokens", "=", "tokens", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "hidden_dim", ")", "\n", "token_ids", "=", "token_ids", ".", "view", "(", "-", "1", ")", "\n", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", "\n", "\n", "assert", "tokens", ".", "size", "(", ")", "[", "0", "]", "==", "token_ids", ".", "size", "(", ")", "[", "0", "]", "\n", "assert", "tokens", ".", "size", "(", ")", "[", "0", "]", "==", "mask", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "tokens", "=", "tokens", "[", "mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "]", "# token len = batch_size*length-mask, hidden_dim ", "\n", "token_ids", "=", "token_ids", "[", "mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "]", "\n", "\n", "# token mean fusion", "\n", "token_len", "=", "token_ids", ".", "size", "(", ")", "[", "0", "]", "\n", "sum_tokens", "=", "torch", ".", "zeros", "(", "vocab_size", ",", "hidden_dim", ")", ".", "cuda", "(", ")", "\n", "cnt_tokens", "=", "torch", ".", "zeros", "(", "vocab_size", ")", ".", "cuda", "(", ")", "\n", "tindex", "=", "torch", ".", "arange", "(", "0", ",", "token_len", ")", "\n", "sum_tokens", "[", "token_ids", "]", "+=", "tokens", "[", "tindex", "]", "\n", "cnt_tokens", "[", "token_ids", "]", "+=", "1", "\n", "ave_tokens", "=", "sum_tokens", "/", "cnt_tokens", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "sum_token_ids", "=", "cnt_tokens", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "sum_tokens", "=", "sum_tokens", "[", "sum_token_ids", "]", "\n", "\n", "ave_token_ids", "=", "cnt_tokens", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "ave_tokens", "=", "ave_tokens", "[", "ave_token_ids", "]", "\n", "\n", "# prob distribution injective fusion", "\n", "aspect", "=", "model", ".", "get_aspect", "(", "prob_a", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "sentiment", "=", "model", ".", "get_sentiment", "(", "prob_s", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "tokens_data", ".", "append", "(", "sum_tokens", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "token_ids_data", ".", "append", "(", "sum_token_ids", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "aspect_data", ".", "append", "(", "aspect", ")", "\n", "sentiment_data", ".", "append", "(", "sentiment", ")", "\n", "\n", "", "return", "tokens_data", ",", "token_ids_data", ",", "aspect_data", ",", "sentiment_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.bert_label_smoothing": [[256, 275], ["utils.pad_text", "y_batch_.size", "[].softmax", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "utils.pad_text", "torch.one_hot", "torch.zeros", "torch.zeros", "len", "language_model", "len"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.pad_text"], ["", "def", "bert_label_smoothing", "(", "y_batch", ",", "tokenizer", ",", "language_model", ",", "rate", "=", "0.1", ")", ":", "\n", "  ", "\"\"\"\n    Apply BERT-based label smoothing.\n  \"\"\"", "\n", "y_batch_", "=", "[", "[", "yy", "if", "yy", "!=", "len", "(", "tokenizer", ")", "-", "1", "else", "0", "for", "yy", "in", "y", "]", "for", "y", "in", "y_batch", "]", "\n", "y_batch_", ",", "mask", "=", "pad_text", "(", "y_batch_", ")", "\n", "\n", "batch_size", ",", "seq_len", "=", "y_batch_", ".", "size", "(", ")", "\n", "\n", "p_batch", "=", "language_model", "(", "y_batch_", ",", "mask", ")", "[", "0", "]", ".", "softmax", "(", "-", "1", ")", "# b, s, v", "\n", "pad", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_len", ",", "1", ")", ".", "cuda", "(", ")", "\n", "p_batch", "=", "torch", ".", "cat", "(", "[", "p_batch", ",", "pad", "]", ",", "-", "1", ")", "\n", "\n", "y_batch", ",", "mask", "=", "pad_text", "(", "y_batch", ")", "\n", "y_batch", "=", "F", ".", "one_hot", "(", "y_batch", ",", "num_classes", "=", "len", "(", "tokenizer", ")", ")", "\n", "\n", "output_batch", "=", "rate", "*", "p_batch", "+", "(", "1", "-", "rate", ")", "*", "y_batch", "\n", "\n", "return", "output_batch", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.rouge_preprocess": [[285, 291], ["rouge.Rouge.REMOVE_CHAR_PATTERN.sub().strip", "rouge.Rouge.tokenize_text", "rouge.Rouge.stem_tokens", "rouge.Rouge.KEEP_CANNOT_IN_ONE_WORD_REVERSED.sub", "rouge.Rouge.KEEP_CANNOT_IN_ONE_WORD.sub", "rouge.Rouge.REMOVE_CHAR_PATTERN.sub", "rouge.Rouge.REMOVE_CHAR_PATTERN.sub().strip.lower"], "function", ["None"], ["def", "rouge_preprocess", "(", "text", ")", ":", "\n", "  ", "text", "=", "rouge", ".", "Rouge", ".", "REMOVE_CHAR_PATTERN", ".", "sub", "(", "' '", ",", "text", ".", "lower", "(", ")", ")", ".", "strip", "(", ")", "\n", "tokens", "=", "rouge", ".", "Rouge", ".", "tokenize_text", "(", "rouge", ".", "Rouge", ".", "KEEP_CANNOT_IN_ONE_WORD", ".", "sub", "(", "'_cannot_'", ",", "text", ")", ")", "\n", "rouge", ".", "Rouge", ".", "stem_tokens", "(", "tokens", ")", "\n", "preprocessed_text", "=", "rouge", ".", "Rouge", ".", "KEEP_CANNOT_IN_ONE_WORD_REVERSED", ".", "sub", "(", "'cannot'", ",", "' '", ".", "join", "(", "tokens", ")", ")", "\n", "return", "preprocessed_text", "\n", "\n"]], "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.get_metrics": [[293, 303], ["rouge_eval.get_scores", "utils.rouge_preprocess", "utils.rouge_preprocess"], "function", ["home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.rouge_preprocess", "home.repos.pwc.inspect_result.rktamplayo_PlanSum.src.utils.rouge_preprocess"], ["", "def", "get_metrics", "(", "golds", ",", "preds", ")", ":", "\n", "  ", "gold_sums", "=", "[", "[", "rouge_preprocess", "(", "g", ")", "for", "g", "in", "gold", "]", "for", "gold", "in", "golds", "]", "\n", "pred_sums", "=", "[", "rouge_preprocess", "(", "pred", ")", "for", "pred", "in", "preds", "]", "\n", "\n", "scores", "=", "rouge_eval", ".", "get_scores", "(", "pred_sums", ",", "gold_sums", ")", "\n", "rouge_l", "=", "scores", "[", "'rouge-l'", "]", "[", "'f'", "]", "*", "100", "\n", "rouge_1", "=", "scores", "[", "'rouge-1'", "]", "[", "'f'", "]", "*", "100", "\n", "rouge_2", "=", "scores", "[", "'rouge-2'", "]", "[", "'f'", "]", "*", "100", "\n", "\n", "return", "rouge_1", ",", "rouge_2", ",", "rouge_l", "\n", "", ""]]}