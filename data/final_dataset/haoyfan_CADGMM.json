{"home.repos.pwc.inspect_result.haoyfan_CADGMM.None.main.run": [[17, 38], ["logger.info", "importlib.import_module", "importlib.import_module.run", "logger.error", "logger.exception", "logger.error"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.run"], ["def", "run", "(", "args", ")", ":", "\n", "\n", "    ", "has_effect", "=", "False", "\n", "\n", "if", "args", ".", "model", "and", "args", ".", "dataset", "and", "args", ".", "split", ":", "\n", "        ", "try", ":", "\n", "\n", "            ", "mod_name", "=", "\"{}.{}\"", ".", "format", "(", "args", ".", "model", ",", "args", ".", "split", ")", "\n", "\n", "logger", ".", "info", "(", "\"Running script at {}\"", ".", "format", "(", "mod_name", ")", ")", "\n", "\n", "mod", "=", "importlib", ".", "import_module", "(", "mod_name", ")", "\n", "\n", "mod", ".", "run", "(", "args", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "logger", ".", "exception", "(", "e", ")", "\n", "logger", ".", "error", "(", "\"Uhoh, the script halted with an error.\"", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "not", "has_effect", ":", "\n", "            ", "logger", ".", "error", "(", "\"Script halted without any effect. To run code, use command:\\npython3 main.py <example name> {train, test}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.None.main.path": [[39, 45], ["os.path.isdir", "argparse.ArgumentTypeError"], "function", ["None"], ["", "", "", "def", "path", "(", "d", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "d", ")", "\n", "return", "d", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "\"Example {} cannot be located.\"", ".", "format", "(", "d", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.Layer.__init__": [[33, 46], ["kwargs.keys", "kwargs.get", "kwargs.get", "layers.Layer.__class__.__name__.lower", "str", "layers.get_layer_uid"], "methods", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.get_layer_uid"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "allowed_kwargs", "=", "{", "'name'", ",", "'logging'", "}", "\n", "for", "kwarg", "in", "kwargs", ".", "keys", "(", ")", ":", "\n", "            ", "assert", "kwarg", "in", "allowed_kwargs", ",", "'Invalid keyword argument: '", "+", "kwarg", "\n", "", "name", "=", "kwargs", ".", "get", "(", "'name'", ")", "\n", "if", "not", "name", ":", "\n", "            ", "layer", "=", "self", ".", "__class__", ".", "__name__", ".", "lower", "(", ")", "\n", "name", "=", "layer", "+", "'_'", "+", "str", "(", "get_layer_uid", "(", "layer", ")", ")", "\n", "", "self", ".", "name", "=", "name", "\n", "self", ".", "vars", "=", "{", "}", "\n", "logging", "=", "kwargs", ".", "get", "(", "'logging'", ",", "False", ")", "\n", "self", ".", "logging", "=", "logging", "\n", "self", ".", "issparse", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.Layer._call": [[47, 49], ["None"], "methods", ["None"], ["", "def", "_call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.Layer.__call__": [[50, 54], ["tensorflow.name_scope", "layers.Layer._call"], "methods", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.NodeAttention_SP._call"], ["", "def", "__call__", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "outputs", "=", "self", ".", "_call", "(", "inputs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.NodeAttention_SP.__init__": [[59, 69], ["layers.Layer.__init__", "layers.NodeAttention_SP._log_vars"], "methods", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.NodeAttention_SP.__init__"], ["def", "__init__", "(", "self", ",", "out_sz", ",", "bias_mat", ",", "nb_nodes", ",", "dropout", "=", "0.", ",", "\n", "act", "=", "tf", ".", "nn", ".", "elu", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "NodeAttention_SP", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "act", "=", "act", "\n", "self", ".", "out_sz", "=", "out_sz", "\n", "self", ".", "bias_mat", "=", "bias_mat", "\n", "self", ".", "nb_nodes", "=", "nb_nodes", "\n", "\n", "if", "self", ".", "logging", ":", "\n", "            ", "self", ".", "_log_vars", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.NodeAttention_SP._call": [[70, 98], ["tensorflow.layers.conv1d", "tensorflow.layers.conv1d", "tensorflow.layers.conv1d", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.sparse_add", "tensorflow.SparseTensor", "tensorflow.sparse_softmax", "tensorflow.sparse_reshape", "tensorflow.squeeze", "tensorflow.sparse_tensor_dense_matmul", "tensorflow.expand_dims", "tensorflow.expand_dims.set_shape", "layers.NodeAttention_SP.act", "tensorflow.transpose", "tensorflow.contrib.layers.bias_add", "tensorflow.nn.leaky_relu"], "methods", ["None"], ["", "", "def", "_call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "seq_fts", "=", "tf", ".", "layers", ".", "conv1d", "(", "inputs", ",", "self", ".", "out_sz", ",", "1", ",", "use_bias", "=", "False", ")", "\n", "\n", "# simplest self-attention possible", "\n", "f_1", "=", "tf", ".", "layers", ".", "conv1d", "(", "seq_fts", ",", "1", ",", "1", ")", "\n", "f_2", "=", "tf", ".", "layers", ".", "conv1d", "(", "seq_fts", ",", "1", ",", "1", ")", "\n", "f_1", "=", "tf", ".", "reshape", "(", "f_1", ",", "(", "self", ".", "nb_nodes", ",", "1", ")", ")", "\n", "f_2", "=", "tf", ".", "reshape", "(", "f_2", ",", "(", "self", ".", "nb_nodes", ",", "1", ")", ")", "\n", "f_1", "=", "self", ".", "bias_mat", "*", "f_1", "\n", "f_2", "=", "self", ".", "bias_mat", "*", "tf", ".", "transpose", "(", "f_2", ",", "[", "1", ",", "0", "]", ")", "\n", "\n", "logits", "=", "tf", ".", "sparse_add", "(", "f_1", ",", "f_2", ")", "\n", "lrelu", "=", "tf", ".", "SparseTensor", "(", "indices", "=", "logits", ".", "indices", ",", "\n", "values", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "logits", ".", "values", ")", ",", "\n", "dense_shape", "=", "logits", ".", "dense_shape", ")", "\n", "coefs", "=", "tf", ".", "sparse_softmax", "(", "lrelu", ")", "\n", "\n", "# As tf.sparse_tensor_dense_matmul expects its arguments to have rank-2,", "\n", "# here we make an assumption that our input is of batch size 1, and reshape appropriately.", "\n", "# The method will fail in all other cases!", "\n", "coefs", "=", "tf", ".", "sparse_reshape", "(", "coefs", ",", "[", "self", ".", "nb_nodes", ",", "self", ".", "nb_nodes", "]", ")", "\n", "seq_fts", "=", "tf", ".", "squeeze", "(", "seq_fts", ")", "\n", "vals", "=", "tf", ".", "sparse_tensor_dense_matmul", "(", "coefs", ",", "seq_fts", ")", "\n", "vals", "=", "tf", ".", "expand_dims", "(", "vals", ",", "axis", "=", "0", ")", "\n", "vals", ".", "set_shape", "(", "[", "1", ",", "self", ".", "nb_nodes", ",", "self", ".", "out_sz", "]", ")", "\n", "ret", "=", "self", ".", "act", "(", "tf", ".", "contrib", ".", "layers", ".", "bias_add", "(", "vals", ")", ")", "\n", "\n", "return", "ret", "# activation", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.layers.get_layer_uid": [[10, 19], ["None"], "function", ["None"], ["def", "get_layer_uid", "(", "layer_name", "=", "''", ")", ":", "\n", "    ", "\"\"\"Helper function, assigns unique layer IDs\n    \"\"\"", "\n", "if", "layer_name", "not", "in", "_LAYER_UIDS", ":", "\n", "        ", "_LAYER_UIDS", "[", "layer_name", "]", "=", "1", "\n", "return", "1", "\n", "", "else", ":", "\n", "        ", "_LAYER_UIDS", "[", "layer_name", "]", "+=", "1", "\n", "return", "_LAYER_UIDS", "[", "layer_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.sparse_to_tuple": [[6, 13], ["numpy.vstack().transpose", "scipy.isspmatrix_coo", "sparse_mx.tocoo.tocoo", "numpy.vstack"], "function", ["None"], ["def", "sparse_to_tuple", "(", "sparse_mx", ")", ":", "\n", "    ", "if", "not", "sp", ".", "isspmatrix_coo", "(", "sparse_mx", ")", ":", "\n", "        ", "sparse_mx", "=", "sparse_mx", ".", "tocoo", "(", ")", "\n", "", "coords", "=", "np", ".", "vstack", "(", "(", "sparse_mx", ".", "row", ",", "sparse_mx", ".", "col", ")", ")", ".", "transpose", "(", ")", "\n", "values", "=", "sparse_mx", ".", "data", "\n", "shape", "=", "sparse_mx", ".", "shape", "\n", "return", "coords", ",", "values", ",", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.preprocess_graph": [[15, 22], ["scipy.coo_matrix", "numpy.array", "scipy.diags", "adj_.dot().transpose().dot().tocoo", "preprocessing.sparse_to_tuple", "scipy.eye", "adj_.sum", "numpy.power().flatten", "adj_.dot().transpose().dot", "numpy.power", "adj_.dot().transpose", "adj_.dot"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.sparse_to_tuple"], ["", "def", "preprocess_graph", "(", "adj", ")", ":", "\n", "    ", "adj", "=", "sp", ".", "coo_matrix", "(", "adj", ")", "\n", "adj_", "=", "adj", "+", "sp", ".", "eye", "(", "adj", ".", "shape", "[", "0", "]", ")", "\n", "rowsum", "=", "np", ".", "array", "(", "adj_", ".", "sum", "(", "1", ")", ")", "\n", "degree_mat_inv_sqrt", "=", "sp", ".", "diags", "(", "np", ".", "power", "(", "rowsum", ",", "-", "0.5", ")", ".", "flatten", "(", ")", ")", "\n", "adj_normalized", "=", "adj_", ".", "dot", "(", "degree_mat_inv_sqrt", ")", ".", "transpose", "(", ")", ".", "dot", "(", "degree_mat_inv_sqrt", ")", ".", "tocoo", "(", ")", "\n", "return", "sparse_to_tuple", "(", "adj_normalized", ")", "\n", "# return adj_normalized.todense()", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.construct_H_with_KNN": [[25, 40], ["sklearn.metrics.pairwise.cosine_distances", "preprocessing.construct_H_with_KNN_from_distance", "len", "X.reshape.reshape"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.construct_H_with_KNN_from_distance"], ["", "def", "construct_H_with_KNN", "(", "X", ",", "k_neig", "=", "10", ",", "is_probH", "=", "False", ",", "m_prob", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    init multi-scale hypergraph Vertex-Edge matrix from original node feature matrix\n    :param X: N_object x feature_number\n    :param K_neigs: the number of neighbor expansion\n    :param is_probH: prob Vertex-Edge matrix or binary\n    :param m_prob: prob\n    :return: N_object x N_hyperedge\n    \"\"\"", "\n", "if", "len", "(", "X", ".", "shape", ")", "!=", "2", ":", "\n", "        ", "X", "=", "X", ".", "reshape", "(", "-", "1", ",", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "dis_mat", "=", "cos_dis", "(", "X", ")", "\n", "H", "=", "construct_H_with_KNN_from_distance", "(", "dis_mat", ",", "k_neig", ",", "is_probH", ",", "m_prob", ")", "\n", "return", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.construct_H_with_KNN_from_distance": [[42, 69], ["numpy.zeros", "range", "numpy.array().squeeze", "numpy.average", "numpy.any", "numpy.array", "numpy.exp", "numpy.argsort"], "function", ["None"], ["", "def", "construct_H_with_KNN_from_distance", "(", "dis_mat", ",", "k_neig", ",", "is_probH", "=", "False", ",", "m_prob", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    construct hypregraph incidence matrix from hypergraph node distance matrix\n    :param dis_mat: node distance matrix\n    :param k_neig: K nearest neighbor\n    :param is_probH: prob Vertex-Edge matrix or binary\n    :param m_prob: prob\n    :return: N_object X N_hyperedge\n    \"\"\"", "\n", "n_obj", "=", "dis_mat", ".", "shape", "[", "0", "]", "\n", "# construct hyperedge from the central feature space of each node", "\n", "n_edge", "=", "n_obj", "\n", "H", "=", "np", ".", "zeros", "(", "(", "n_obj", ",", "n_edge", ")", ")", "\n", "for", "center_idx", "in", "range", "(", "n_obj", ")", ":", "\n", "        ", "dis_mat", "[", "center_idx", ",", "center_idx", "]", "=", "0", "\n", "dis_vec", "=", "dis_mat", "[", "center_idx", "]", "\n", "nearest_idx", "=", "np", ".", "array", "(", "np", ".", "argsort", "(", "dis_vec", ")", ")", ".", "squeeze", "(", ")", "\n", "avg_dis", "=", "np", ".", "average", "(", "dis_vec", ")", "\n", "if", "not", "np", ".", "any", "(", "nearest_idx", "[", ":", "k_neig", "]", "==", "center_idx", ")", ":", "\n", "            ", "nearest_idx", "[", "k_neig", "-", "1", "]", "=", "center_idx", "\n", "\n", "", "for", "node_idx", "in", "nearest_idx", "[", ":", "k_neig", "]", ":", "\n", "            ", "if", "is_probH", ":", "\n", "                ", "H", "[", "node_idx", ",", "center_idx", "]", "=", "np", ".", "exp", "(", "-", "dis_vec", "[", "0", ",", "node_idx", "]", "**", "2", "/", "(", "m_prob", "*", "avg_dis", ")", "**", "2", ")", "\n", "", "else", ":", "\n", "                ", "H", "[", "node_idx", ",", "center_idx", "]", "=", "1.0", "\n", "", "", "", "return", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.construct_data": [[71, 77], ["preprocessing.construct_H_with_KNN", "scipy.lil_matrix", "preprocessing.preprocess_graph"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.construct_H_with_KNN", "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.preprocess_graph"], ["", "def", "construct_data", "(", "input_data", ",", "k_neig", ")", ":", "\n", "    ", "X", "=", "input_data", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "adj", "=", "construct_H_with_KNN", "(", "X", ",", "k_neig", ")", "\n", "adj", "=", "sp", ".", "lil_matrix", "(", "adj", ")", "\n", "adj", "=", "preprocess_graph", "(", "adj", ")", "\n", "return", "adj", "\n", "", ""]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.kdd_utilities.encoder": [[31, 86], ["tensorflow.variable_scope", "tensorflow.expand_dims", "range", "tensorflow.add", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.layers.dense", "attns.append", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.layers.dense", "NodeAttention_SP"], "function", ["None"], ["def", "encoder", "(", "x_inp", ",", "adj", ",", "n_samples", ",", "is_training", "=", "False", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Encoder architecture in tensorflow\n\n    Maps the data into the latent space\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        x_inp (tensor): input data for the encoder.\n        reuse (bool): sharing variables or not\n\n    Returns:\n        (tensor): last activation layer of the encoder\n\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder'", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "name_net", "=", "'layer_1'", "\n", "net_mlp", "=", "x_inp", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net_mlp", "=", "tf", ".", "layers", ".", "dense", "(", "net_mlp", ",", "\n", "units", "=", "64", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "", "name_net", "=", "'layer_2'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net_mlp", "=", "tf", ".", "layers", ".", "dense", "(", "net_mlp", ",", "\n", "units", "=", "32", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "### GCN branch", "\n", "", "net_gcn", "=", "tf", ".", "expand_dims", "(", "x_inp", ",", "1", ")", "\n", "\n", "attns", "=", "[", "]", "\n", "k", "=", "2", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "attns", ".", "append", "(", "NodeAttention_SP", "(", "bias_mat", "=", "adj", ",", "nb_nodes", "=", "n_samples", ",", "\n", "out_sz", "=", "32", "//", "k", ",", "act", "=", "tf", ".", "nn", ".", "tanh", ")", "(", "net_gcn", ")", ")", "\n", "\n", "", "net_gcn", "=", "tf", ".", "concat", "(", "attns", ",", "axis", "=", "-", "1", ")", "[", "0", "]", "\n", "\n", "### Fusion module", "\n", "net", "=", "tf", ".", "add", "(", "net_mlp", ",", "net_gcn", ")", "\n", "### Last layer", "\n", "name_net", "=", "'layer_3'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "8", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.kdd_utilities.decoder": [[88, 130], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.layers.dense"], "function", ["None"], ["", "def", "decoder", "(", "z_inp", ",", "n_features", ",", "is_training", "=", "False", ",", "getter", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Decoder architecture in tensorflow\n\n    Generates data from the latent space\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        z_inp (tensor): variable in the latent space\n        reuse (bool): sharing variables or not\n\n    Returns:\n        (tensor): last activation layer of the generator\n\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'decoder'", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "name_net", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "z_inp", ",", "\n", "units", "=", "32", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "name_net", "=", "'layer_2'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "64", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "name_net", "=", "'layer_3'", "\n", "# there actually are 121 features in kdd", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "n_features", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.kdd_utilities.feature_extractor": [[132, 151], ["tensorflow.losses.cosine_distance", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.norm", "tensorflow.norm", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "feature_extractor", "(", "x", ",", "x_r", ")", ":", "\n", "    ", "\"\"\"\n    Computes the reconstruction features for the autoencoder\n\n    Args:\n        - x : [N, 121] input data\n        - x_r : same shape - reconstructed thanks to the autoencoder\n\n    Returns:\n        - f : chosen features\n              here relative Euclidean distance and cosine similarity\n    \"\"\"", "\n", "dist", "=", "tf", ".", "norm", "(", "x", "-", "x_r", ",", "keepdims", "=", "True", ",", "axis", "=", "1", ")", "/", "tf", ".", "norm", "(", "x", ",", "keepdims", "=", "True", ",", "axis", "=", "1", ")", "\n", "cosine_dist", "=", "tf", ".", "losses", ".", "cosine_distance", "(", "tf", ".", "nn", ".", "l2_normalize", "(", "x", ",", "1", ")", ",", "tf", ".", "nn", ".", "l2_normalize", "(", "x_r", ",", "1", ")", ",", "axis", "=", "1", ",", "\n", "reduction", "=", "tf", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"dist\"", ",", "tf", ".", "reduce_mean", "(", "dist", ")", ",", "[", "\"loss\"", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"cosine\"", ",", "tf", ".", "reduce_mean", "(", "1", "-", "cosine_dist", ")", ",", "[", "\"loss\"", "]", ")", "\n", "# tf.summary.scalar(\"cosine_dist\", tf.reduce_mean(cosine_dist), [\"loss\"])", "\n", "return", "tf", ".", "concat", "(", "[", "dist", ",", "1", "-", "cosine_dist", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.kdd_utilities.estimator": [[153, 198], ["tensorflow.contrib.layers.xavier_initializer", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dropout", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dropout", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.nn.softmax"], "function", ["None"], ["", "def", "estimator", "(", "z_inp", ",", "K", ",", "is_training", "=", "False", ",", "getter", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Estimation network architecture in tensorflow\n\n    Computes the probability of x represented by z to be in the training data\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        z_inp (tensor): variable in the latent space + reconstruction features\n        reuse (bool): sharing variables or not\n\n    Returns:\n        logits (tensor): last activation layer of the estimation network (shape 1)\n\n    \"\"\"", "\n", "init_kernel", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'estimator'", ",", "reuse", "=", "reuse", ",", "custom_getter", "=", "getter", ")", ":", "\n", "        ", "name_layer", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_layer", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "z_inp", ",", "\n", "units", "=", "20", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "rate", "=", "0.5", ",", "name", "=", "'dropout'", ",", "training", "=", "is_training", ")", "\n", "\n", "", "name_layer", "=", "'layer_2'", "\n", "with", "tf", ".", "variable_scope", "(", "name_layer", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "8", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "rate", "=", "0.5", ",", "name", "=", "'dropout'", ",", "training", "=", "is_training", ")", "\n", "\n", "", "name_layer", "=", "'layer_3'", "\n", "with", "tf", ".", "variable_scope", "(", "name_layer", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "K", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "logits", "=", "tf", ".", "nn", ".", "softmax", "(", "net", ")", "\n", "\n", "", "", "return", "logits", "\n", "", ""]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.arrhythmia_utilities.encoder": [[32, 84], ["tensorflow.variable_scope", "tensorflow.expand_dims", "range", "tensorflow.add", "tensorflow.variable_scope", "tensorflow.layers.dense", "attns.append", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.layers.dense", "NodeAttention_SP"], "function", ["None"], ["def", "encoder", "(", "x_inp", ",", "adj", ",", "n_samples", ",", "is_training", "=", "False", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Encoder architecture in tensorflow\n\n    Maps the data into the latent space\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        x_inp (tensor): input data for the encoder.\n        reuse (bool): sharing variables or not\n\n    Returns:\n        (tensor): last activation layer of the encoder\n\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder'", ",", "reuse", "=", "reuse", ")", ":", "\n", "\n", "### MLP branch", "\n", "        ", "net_mlp", "=", "x_inp", "\n", "name_net", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net_mlp", "=", "tf", ".", "layers", ".", "dense", "(", "net_mlp", ",", "\n", "units", "=", "32", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "### GCN branch", "\n", "", "net_gcn", "=", "tf", ".", "expand_dims", "(", "x_inp", ",", "1", ")", "\n", "\n", "attns", "=", "[", "]", "\n", "k", "=", "2", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "attns", ".", "append", "(", "NodeAttention_SP", "(", "bias_mat", "=", "adj", ",", "nb_nodes", "=", "n_samples", ",", "\n", "out_sz", "=", "32", "//", "k", ",", "act", "=", "tf", ".", "nn", ".", "tanh", ")", "(", "net_gcn", ")", ")", "\n", "\n", "", "net_gcn", "=", "tf", ".", "concat", "(", "attns", ",", "axis", "=", "-", "1", ")", "[", "0", "]", "\n", "\n", "# Fusion module", "\n", "net", "=", "tf", ".", "add", "(", "net_mlp", ",", "net_gcn", ")", "\n", "\n", "### Last layer", "\n", "name_net", "=", "'layer_2'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "2", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.arrhythmia_utilities.decoder": [[85, 120], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.layers.dense"], "function", ["None"], ["", "def", "decoder", "(", "z_inp", ",", "n_features", ",", "is_training", "=", "False", ",", "getter", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Decoder architecture in tensorflow\n\n    Generates data from the latent space\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        z_inp (tensor): variable in the latent space\n        reuse (bool): sharing variables or not\n\n    Returns:\n        (tensor): last activation layer of the generator\n\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'decoder'", ",", "reuse", "=", "reuse", ")", ":", "\n", "\n", "        ", "name_net", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "z_inp", ",", "\n", "units", "=", "10", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "name_net", "=", "'layer_2'", "\n", "#there actually are 121 features in kdd", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "n_features", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.arrhythmia_utilities.feature_extractor": [[121, 140], ["tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reduce_sum", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.norm", "tensorflow.norm", "tensorflow.multiply", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "feature_extractor", "(", "x", ",", "x_r", ")", ":", "\n", "    ", "\"\"\"\n    Computes the reconstruction features for the autoencoder\n\n    Args:\n        - x : [N, 121] input data\n        - x_r : same shape - reconstructed thanks to the autoencoder\n\n    Returns:\n        - f : chosen features\n              here relative Euclidean distance and cosine similarity\n    \"\"\"", "\n", "dist", "=", "tf", ".", "norm", "(", "x", "-", "x_r", ",", "keepdims", "=", "True", ",", "axis", "=", "1", ")", "/", "tf", ".", "norm", "(", "x", ",", "keepdims", "=", "True", ",", "axis", "=", "1", ")", "\n", "n1", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "x", ",", "1", ")", "\n", "n2", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "x_r", ",", "1", ")", "\n", "cosine_similarity", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "n1", ",", "n2", ")", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"dist\"", ",", "tf", ".", "reduce_mean", "(", "dist", ")", ",", "[", "\"loss\"", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"cosine\"", ",", "tf", ".", "reduce_mean", "(", "cosine_similarity", ")", ",", "[", "\"loss\"", "]", ")", "\n", "return", "tf", ".", "concat", "(", "[", "dist", ",", "cosine_similarity", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.arrhythmia_utilities.estimator": [[141, 177], ["tensorflow.contrib.layers.xavier_initializer", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dropout", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.nn.softmax"], "function", ["None"], ["", "def", "estimator", "(", "z_inp", ",", "K", ",", "is_training", "=", "False", ",", "getter", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Estimation network architecture in tensorflow\n\n    Computes the probability of x represented by z to be in the training data\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        z_inp (tensor): variable in the latent space + reconstruction features\n        reuse (bool): sharing variables or not\n\n    Returns:\n        logits (tensor): last activation layer of the estimation network (shape 1)\n\n    \"\"\"", "\n", "init_kernel", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'estimator'", ",", "reuse", "=", "reuse", ",", "custom_getter", "=", "getter", ")", ":", "\n", "        ", "name_layer", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_layer", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "z_inp", ",", "\n", "units", "=", "10", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "rate", "=", "0.5", ",", "name", "=", "'dropout'", ",", "training", "=", "is_training", ")", "\n", "\n", "", "name_layer", "=", "'layer_2'", "\n", "with", "tf", ".", "variable_scope", "(", "name_layer", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "K", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "logits", "=", "tf", ".", "nn", ".", "softmax", "(", "net", ")", "\n", "\n", "", "", "return", "logits", "\n", "", ""]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.gmm_utils.tricky_divide": [[14, 16], ["tensorflow.transpose", "tensorflow.transpose"], "function", ["None"], ["def", "tricky_divide", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "tf", ".", "transpose", "(", "tf", ".", "transpose", "(", "x", ")", "/", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.gmm_utils.tricky_multiply": [[17, 19], ["tensorflow.transpose", "tensorflow.transpose"], "function", ["None"], ["", "def", "tricky_multiply", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "tf", ".", "transpose", "(", "tf", ".", "transpose", "(", "x", ")", "*", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.gmm_utils.compute_energy_and_penalty": [[21, 109], ["tensorflow.expand_dims", "tensorflow.tile", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.squeeze", "tensorflow.reduce_sum", "gammas.get_shape", "z.get_shape", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "numpy.tile", "tensorflow.constant_initializer", "tensorflow.get_variable", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.reduce_mean", "tensorflow.cond", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_sum", "gmm_utils.add_noise", "tensorflow.cond", "tensorflow.matrix_inverse", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.matrix_diag_part", "numpy.expand_dims", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.exp", "tensorflow.sqrt", "tensorflow.ones_initializer", "tensorflow.ones_initializer", "numpy.identity", "tensorflow.control_dependencies", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.shape", "tensorflow.identity", "tensorflow.identity", "tensorflow.matrix_determinant", "tf.get_variable.assign", "tf.get_variable.assign", "tf.cond.assign"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.gmm_utils.add_noise"], ["", "def", "compute_energy_and_penalty", "(", "z", ",", "gammas", ",", "is_training", ")", ":", "\n", "    ", "\"\"\"\n    Computes the energy and penalty of the GMM as described\n    in Zong, Bo et al. \u201cDeep Autoencoding Gaussian Mixture Model\n                        for Unsupervised Anomaly Detection.\u201d (2018).\n\n    K: number of mixtures in the GMM\n    N: number of samples\n    M: number of features of z\n\n    Args:\n        - z :       [N, M] - the reconstruction features concatenated\n                    with the latent representation of x\n\n        - gamma :   [N, K] - density of probability - output of the\n                    estimation network\n\n    Returns:\n\n        - E(z):     Tensor of shape [batch_size] - energy of the\n                    GMM computed by the networks\n\n        - P(sigma): Scalar - Penalty appled to small values in diagonal entries of\n                    covariance matrices\n\n    Note: could probably be simplified\n\n    \"\"\"", "\n", "#shapes", "\n", "K", "=", "gammas", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "M", "=", "z", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'gmm_parameters'", ")", ":", "\n", "        ", "phis", "=", "tf", ".", "get_variable", "(", "'phis'", ",", "shape", "=", "[", "K", "]", ",", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "\n", "mus", "=", "tf", ".", "get_variable", "(", "'mus'", ",", "shape", "=", "[", "K", ",", "M", "]", ",", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "\n", "\n", "init_sigmas", "=", "0.5", "*", "np", ".", "expand_dims", "(", "np", ".", "identity", "(", "M", ")", ",", "axis", "=", "0", ")", "\n", "init_sigmas", "=", "np", ".", "tile", "(", "init_sigmas", ",", "[", "2", ",", "1", ",", "1", "]", ")", "\n", "init_sigmas", "=", "tf", ".", "constant_initializer", "(", "init_sigmas", ")", "\n", "sigmas", "=", "tf", ".", "get_variable", "(", "'sigmas'", ",", "shape", "=", "[", "K", ",", "M", ",", "M", "]", ",", "initializer", "=", "init_sigmas", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "False", ")", "\n", "\n", "sums", "=", "tf", ".", "reduce_sum", "(", "gammas", ",", "axis", "=", "0", ")", "\n", "sums_exp_dims", "=", "tf", ".", "expand_dims", "(", "sums", ",", "axis", "=", "-", "1", ")", "\n", "\n", "phis_", "=", "tf", ".", "reduce_mean", "(", "gammas", ",", "axis", "=", "0", ")", "\n", "mus_", "=", "tf", ".", "matmul", "(", "gammas", ",", "z", ",", "transpose_a", "=", "True", ")", "/", "sums_exp_dims", "\n", "\n", "def", "assign_training_phis_mus", "(", ")", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "phis", ".", "assign", "(", "phis_", ")", ",", "mus", ".", "assign", "(", "mus_", ")", "]", ")", ":", "\n", "                ", "return", "[", "tf", ".", "identity", "(", "phis", ")", ",", "tf", ".", "identity", "(", "mus", ")", "]", "\n", "\n", "", "", "phis", ",", "mus", "=", "tf", ".", "cond", "(", "is_training", ",", "assign_training_phis_mus", ",", "lambda", ":", "[", "phis", ",", "mus", "]", ")", "\n", "phis_exp_dims", "=", "tf", ".", "expand_dims", "(", "phis", ",", "axis", "=", "0", ")", "\n", "phis_exp_dims", "=", "tf", ".", "expand_dims", "(", "phis_exp_dims", ",", "axis", "=", "-", "1", ")", "\n", "phis_exp_dims", "=", "tf", ".", "expand_dims", "(", "phis_exp_dims", ",", "axis", "=", "-", "1", ")", "\n", "\n", "zs_exp_dims", "=", "tf", ".", "expand_dims", "(", "z", ",", "1", ")", "\n", "zs_exp_dims", "=", "tf", ".", "expand_dims", "(", "zs_exp_dims", ",", "-", "1", ")", "\n", "mus_exp_dims", "=", "tf", ".", "expand_dims", "(", "mus", ",", "0", ")", "\n", "mus_exp_dims", "=", "tf", ".", "expand_dims", "(", "mus_exp_dims", ",", "-", "1", ")", "\n", "\n", "zs_minus_mus", "=", "zs_exp_dims", "-", "mus_exp_dims", "\n", "\n", "sigmas_", "=", "tf", ".", "matmul", "(", "zs_minus_mus", ",", "zs_minus_mus", ",", "transpose_b", "=", "True", ")", "\n", "broadcast_gammas", "=", "tf", ".", "expand_dims", "(", "gammas", ",", "axis", "=", "-", "1", ")", "\n", "broadcast_gammas", "=", "tf", ".", "expand_dims", "(", "broadcast_gammas", ",", "axis", "=", "-", "1", ")", "\n", "sigmas_", "=", "broadcast_gammas", "*", "sigmas_", "\n", "sigmas_", "=", "tf", ".", "reduce_sum", "(", "sigmas_", ",", "axis", "=", "0", ")", "\n", "sigmas_", "=", "sigmas_", "/", "tf", ".", "expand_dims", "(", "sums_exp_dims", ",", "axis", "=", "-", "1", ")", "\n", "sigmas_", "=", "add_noise", "(", "sigmas_", ")", "\n", "\n", "def", "assign_training_sigmas", "(", ")", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "sigmas", ".", "assign", "(", "sigmas_", ")", "]", ")", ":", "\n", "                ", "return", "tf", ".", "identity", "(", "sigmas", ")", "\n", "\n", "", "", "sigmas", "=", "tf", ".", "cond", "(", "is_training", ",", "assign_training_sigmas", ",", "lambda", ":", "sigmas", ")", "\n", "\n", "", "inversed_sigmas", "=", "tf", ".", "expand_dims", "(", "tf", ".", "matrix_inverse", "(", "sigmas", ")", ",", "axis", "=", "0", ")", "\n", "inversed_sigmas", "=", "tf", ".", "tile", "(", "inversed_sigmas", ",", "[", "tf", ".", "shape", "(", "zs_minus_mus", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "energy", "=", "tf", ".", "matmul", "(", "zs_minus_mus", ",", "inversed_sigmas", ",", "transpose_a", "=", "True", ")", "\n", "energy", "=", "tf", ".", "matmul", "(", "energy", ",", "zs_minus_mus", ")", "\n", "energy", "=", "tf", ".", "squeeze", "(", "phis_exp_dims", "*", "tf", ".", "exp", "(", "-", "0.5", "*", "energy", ")", ",", "axis", "=", "[", "2", ",", "3", "]", ")", "\n", "energy_divided_by", "=", "tf", ".", "expand_dims", "(", "tf", ".", "sqrt", "(", "2.0", "*", "m", ".", "pi", "*", "tf", ".", "matrix_determinant", "(", "sigmas", ")", ")", ",", "axis", "=", "0", ")", "+", "1e-12", "\n", "energy", "=", "tf", ".", "reduce_sum", "(", "energy", "/", "energy_divided_by", ",", "axis", "=", "1", ")", "+", "1e-12", "\n", "energy", "=", "-", "1.0", "*", "tf", ".", "log", "(", "energy", ")", "\n", "\n", "penalty", "=", "1.0", "/", "tf", ".", "matrix_diag_part", "(", "sigmas", ")", "\n", "penalty", "=", "tf", ".", "reduce_sum", "(", "penalty", ")", "\n", "return", "energy", ",", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.gmm_utils.add_noise": [[110, 123], ["tensorflow.name_scope", "tensorflow.diag", "tensorflow.expand_dims", "tensorflow.tile", "mat.get_shape().as_list", "tensorflow.random_normal", "mat.get_shape", "mat.get_shape"], "function", ["None"], ["", "def", "add_noise", "(", "mat", ",", "stdev", "=", "0.001", ")", ":", "\n", "    ", "\"\"\"\n    :param mat: should be of shape(k, d, d)\n    :param stdev: the standard deviation of noise\n    :return: a matrix with little noises\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'gaussian_noise'", ")", ":", "\n", "        ", "dims", "=", "mat", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "noise", "=", "stdev", "+", "tf", ".", "random_normal", "(", "[", "dims", "]", ",", "0", ",", "stdev", "*", "1e-1", ")", "\n", "noise", "=", "tf", ".", "diag", "(", "noise", ")", "\n", "noise", "=", "tf", ".", "expand_dims", "(", "noise", ",", "axis", "=", "0", ")", "\n", "noise", "=", "tf", ".", "tile", "(", "noise", ",", "(", "mat", ".", "get_shape", "(", ")", "[", "0", "]", ",", "1", ",", "1", ")", ")", "\n", "", "return", "mat", "+", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.satellite_utilities.encoder": [[31, 85], ["tensorflow.variable_scope", "tensorflow.expand_dims", "range", "tensorflow.add", "tensorflow.variable_scope", "tensorflow.layers.dense", "attns.append", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.layers.dense", "NodeAttention_SP"], "function", ["None"], ["def", "encoder", "(", "x_inp", ",", "adj", ",", "n_samples", ",", "is_training", "=", "False", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Encoder architecture in tensorflow\n\n    Maps the data into the latent space\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        x_inp (tensor): input data for the encoder.\n        reuse (bool): sharing variables or not\n\n    Returns:\n        (tensor): last activation layer of the encoder\n\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder'", ",", "reuse", "=", "reuse", ")", ":", "\n", "\n", "### MLP branch", "\n", "        ", "net_mlp", "=", "x_inp", "\n", "name_net", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net_mlp", "=", "tf", ".", "layers", ".", "dense", "(", "net_mlp", ",", "\n", "units", "=", "16", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "\n", "### GCN branch", "\n", "", "net_gcn", "=", "tf", ".", "expand_dims", "(", "x_inp", ",", "1", ")", "\n", "\n", "attns", "=", "[", "]", "\n", "k", "=", "1", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "attns", ".", "append", "(", "NodeAttention_SP", "(", "bias_mat", "=", "adj", ",", "nb_nodes", "=", "n_samples", ",", "\n", "out_sz", "=", "16", "//", "k", ",", "act", "=", "tf", ".", "nn", ".", "tanh", ")", "(", "net_gcn", ")", ")", "\n", "\n", "", "net_gcn", "=", "tf", ".", "concat", "(", "attns", ",", "axis", "=", "-", "1", ")", "[", "0", "]", "\n", "\n", "# Fusion module", "\n", "net", "=", "tf", ".", "add", "(", "net_mlp", ",", "net_gcn", ")", "\n", "#net = net_gcn", "\n", "#net = net_mlp", "\n", "### Last layer", "\n", "name_net", "=", "'layer_2'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "1", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.satellite_utilities.decoder": [[86, 121], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.layers.dense"], "function", ["None"], ["", "def", "decoder", "(", "z_inp", ",", "n_features", ",", "is_training", "=", "False", ",", "getter", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Decoder architecture in tensorflow\n\n    Generates data from the latent space\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        z_inp (tensor): variable in the latent space\n        reuse (bool): sharing variables or not\n\n    Returns:\n        (tensor): last activation layer of the generator\n\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'decoder'", ",", "reuse", "=", "reuse", ")", ":", "\n", "\n", "        ", "name_net", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "z_inp", ",", "\n", "units", "=", "16", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "name_net", "=", "'layer_2'", "\n", "#there actually are 121 features in kdd", "\n", "with", "tf", ".", "variable_scope", "(", "name_net", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "n_features", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.satellite_utilities.feature_extractor": [[122, 141], ["tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reduce_sum", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.norm", "tensorflow.norm", "tensorflow.multiply", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "feature_extractor", "(", "x", ",", "x_r", ")", ":", "\n", "    ", "\"\"\"\n    Computes the reconstruction features for the autoencoder\n\n    Args:\n        - x : [N, 121] input data\n        - x_r : same shape - reconstructed thanks to the autoencoder\n\n    Returns:\n        - f : chosen features\n              here relative Euclidean distance and cosine similarity\n    \"\"\"", "\n", "dist", "=", "tf", ".", "norm", "(", "x", "-", "x_r", ",", "keepdims", "=", "True", ",", "axis", "=", "1", ")", "/", "tf", ".", "norm", "(", "x", ",", "keepdims", "=", "True", ",", "axis", "=", "1", ")", "\n", "n1", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "x", ",", "1", ")", "\n", "n2", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "x_r", ",", "1", ")", "\n", "cosine_similarity", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "n1", ",", "n2", ")", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"dist\"", ",", "tf", ".", "reduce_mean", "(", "dist", ")", ",", "[", "\"loss\"", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"cosine\"", ",", "tf", ".", "reduce_mean", "(", "cosine_similarity", ")", ",", "[", "\"loss\"", "]", ")", "\n", "return", "tf", ".", "concat", "(", "[", "dist", ",", "cosine_similarity", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.satellite_utilities.estimator": [[142, 178], ["tensorflow.contrib.layers.xavier_initializer", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dropout", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.nn.softmax"], "function", ["None"], ["", "def", "estimator", "(", "z_inp", ",", "K", ",", "is_training", "=", "False", ",", "getter", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\" Estimation network architecture in tensorflow\n\n    Computes the probability of x represented by z to be in the training data\n\n    Note:\n        Provides histogram and distribution tensorflow summaries\n\n    Args:\n        z_inp (tensor): variable in the latent space + reconstruction features\n        reuse (bool): sharing variables or not\n\n    Returns:\n        logits (tensor): last activation layer of the estimation network (shape 1)\n\n    \"\"\"", "\n", "init_kernel", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'estimator'", ",", "reuse", "=", "reuse", ",", "custom_getter", "=", "getter", ")", ":", "\n", "        ", "name_layer", "=", "'layer_1'", "\n", "with", "tf", ".", "variable_scope", "(", "name_layer", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "z_inp", ",", "\n", "units", "=", "10", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "rate", "=", "0.5", ",", "name", "=", "'dropout'", ",", "training", "=", "is_training", ")", "\n", "\n", "", "name_layer", "=", "'layer_2'", "\n", "with", "tf", ".", "variable_scope", "(", "name_layer", ")", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "\n", "units", "=", "K", ",", "\n", "kernel_initializer", "=", "init_kernel", ",", "\n", "name", "=", "'fc'", ")", "\n", "logits", "=", "tf", ".", "nn", ".", "softmax", "(", "net", ")", "\n", "\n", "", "", "return", "logits", "\n", "", ""]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.display_parameters": [[16, 24], ["print", "print", "print", "print"], "function", ["None"], ["def", "display_parameters", "(", "batch_size", ",", "starting_lr", ",", "\n", "l1", ",", "l2", ",", "l3", ",", "label", ")", ":", "\n", "    ", "'''See parameters\n    '''", "\n", "print", "(", "'Batch size: '", ",", "batch_size", ")", "\n", "print", "(", "'Starting learning rate: '", ",", "starting_lr", ")", "\n", "print", "(", "'Weights loss - l1:'", ",", "l1", ",", "'; l2:'", ",", "l2", ",", "'; l3:'", ",", "l3", ")", "\n", "print", "(", "'Anomalous label: '", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.display_progression_epoch": [[26, 33], ["int", "sys.stdout.write", "chr", "str"], "function", ["None"], ["", "def", "display_progression_epoch", "(", "j", ",", "id_max", ")", ":", "\n", "    ", "'''See epoch progression\n       sys.stdout.write(\" \")\u7684\u672c\u8d28\u662fprint(\" \", end=\"\")\n    '''", "\n", "batch_progression", "=", "int", "(", "(", "j", "/", "id_max", ")", "*", "100", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "str", "(", "batch_progression", ")", "+", "' % epoch'", "+", "chr", "(", "13", ")", ")", "\n", "_", "=", "sys", ".", "stdout", ".", "flush", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.create_logdir": [[35, 38], ["None"], "function", ["None"], ["", "def", "create_logdir", "(", "model_name", ",", "dataset", ",", "K", ",", "v", ",", "KNN", ",", "l1", ",", "l2", ",", "l3", ")", ":", "\n", "    ", "\"\"\" Directory to save training logs, weights, biases, etc.\"\"\"", "\n", "return", "\"train_logs/{}/{}_KNN{}_K{}_v{}_l1{}_l2{}_l3{}\"", ".", "format", "(", "model_name", ",", "dataset", ",", "KNN", ",", "K", ",", "v", ",", "l1", ",", "l2", ",", "l3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.reconstruction_error": [[40, 42], ["tensorflow.norm"], "function", ["None"], ["", "def", "reconstruction_error", "(", "x", ",", "x_rec", ")", ":", "\n", "    ", "return", "tf", ".", "norm", "(", "x", "-", "x_rec", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.train_and_test": [[44, 249], ["logging.getLogger", "importlib.import_module", "importlib.import_module", "tensorflow.placeholder", "tensorflow.sparse_placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "logging.getLogger.info", "logging.getLogger.warning", "run.display_parameters", "tensorflow.Variable", "tensorflow.concat", "logging.getLogger.info", "importlib.import_module.get_train", "trainx.copy", "np.random.RandomState", "int", "run.create_logdir", "os.path.sep.join", "tensorboardX.SummaryWriter", "logging.getLogger.info", "tensorflow.Session", "tf.Session.run", "logging.getLogger.info", "importlib.import_module.get_shape_input", "tensorflow.variable_scope", "tensorflow.variable_scope", "dec", "tensorflow.variable_scope", "tensorflow.layers.flatten", "tensorflow.layers.flatten", "feat_ex", "tensorflow.variable_scope", "est", "tensorflow.variable_scope", "cadgmm.compute_energy_and_penalty", "tensorflow.variable_scope", "tensorflow.reduce_sum", "tensorflow.name_scope", "run.reconstruction_error", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.minimize", "tensorflow.name_scope", "tensorflow.summary.merge_all", "tensorflow.global_variables_initializer", "time.time", "range", "logging.getLogger.info", "print", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "enc", "enc", "tensorflow.pow", "tensorflow.name_scope", "tensorflow.greater_equal", "tensorflow.name_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "str", "run.display_progression_epoch", "tf.Session.run", "tf.Session.run", "np.isnan", "tensorflow.contrib.distributions.percentile", "tensorflow.contrib.distributions.percentile", "np.random.RandomState.permutation", "np.random.RandomState.permutation", "np.reshape", "construct_data", "construct_data", "logging.getLogger.info", "time.time"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.display_parameters", "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_train", "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.create_logdir", "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.run", "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_shape_input", "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.gmm_utils.compute_energy_and_penalty", "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.reconstruction_error", "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.display_progression_epoch", "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.run", "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.run", "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.construct_data", "home.repos.pwc.inspect_result.haoyfan_CADGMM.utils.preprocessing.construct_data"], ["", "def", "train_and_test", "(", "model_name", ",", "dataset", ",", "n_epochs", ",", "it_e_val", ",", "K", ",", "v", ",", "KNN", ",", "l1", ",", "l2", ",", "l3", ",", "label", ",", "\n", "random_seed", ")", ":", "\n", "    ", "\"\"\" Runs the CADGMM on the specified dataset\n\n    Note:\n        Saves summaries on tensorboard. To display them, please use cmd line\n        tensorboard --logdir=model.training_logdir() --port=number\n    Args:\n        n_epochs (int): number of epochs\n        weight (float, optional): weight for the anomaly score composition\n        anomalous_label (int): int in range 0 to 10, is the class/digit\n                                which is considered outlier\n    \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"{}.train.{}.{}\"", ".", "format", "(", "model_name", ",", "dataset", ",", "label", ")", ")", "\n", "\n", "# Import model and data", "\n", "model", "=", "importlib", ".", "import_module", "(", "'{}.{}_utilities'", ".", "format", "(", "model_name", ",", "dataset", ")", ")", "\n", "data", "=", "importlib", ".", "import_module", "(", "\"data.{}\"", ".", "format", "(", "dataset", ")", ")", "\n", "\n", "# Parameters", "\n", "starting_lr", "=", "model", ".", "params", "[", "\"learning_rate\"", "]", "\n", "batch_size", "=", "model", ".", "params", "[", "\"batch_size\"", "]", "\n", "if", "n_epochs", "==", "-", "1", ":", "n_epochs", "=", "model", ".", "params", "[", "\"n_epochs\"", "]", "\n", "if", "l1", "==", "-", "1", ":", "l1", "=", "model", ".", "params", "[", "\"l1\"", "]", "\n", "if", "l2", "==", "-", "1", ":", "l2", "=", "model", ".", "params", "[", "\"l2\"", "]", "\n", "if", "l3", "==", "-", "1", ":", "l3", "=", "model", ".", "params", "[", "\"l3\"", "]", "\n", "if", "K", "==", "-", "1", ":", "K", "=", "model", ".", "params", "[", "\"K\"", "]", "\n", "if", "KNN", "==", "-", "1", ":", "KNN", "=", "model", ".", "params", "[", "\"KNN\"", "]", "\n", "\n", "x_pl", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "data", ".", "get_shape_input", "(", ")", ",", "name", "=", "'x_pl'", ")", "\n", "adj", "=", "tf", ".", "sparse_placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'adj'", ")", "\n", "\n", "is_training_pl", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "[", "]", ",", "name", "=", "'is_training_pl'", ")", "\n", "learning_rate", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", ")", ",", "name", "=", "\"lr_pl\"", ")", "\n", "\n", "logger", ".", "info", "(", "'Building training graph...'", ")", "\n", "\n", "logger", ".", "warning", "(", "\"The CADGMM is training with the following parameters:\"", ")", "\n", "display_parameters", "(", "batch_size", ",", "starting_lr", ",", "l1", ",", "l2", ",", "l3", ",", "\n", "label", ")", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "'global_step'", ",", "trainable", "=", "False", ")", "\n", "\n", "if", "model", ".", "params", "[", "\"is_image\"", "]", ":", "\n", "        ", "enc", "=", "model", ".", "encoder", "\n", "", "else", ":", "\n", "        ", "enc", "=", "model", ".", "encoder", "\n", "", "dec", "=", "model", ".", "decoder", "\n", "feat_ex", "=", "model", ".", "feature_extractor", "\n", "est", "=", "model", ".", "estimator", "\n", "\n", "\n", "x_features", "=", "x_pl", "\n", "n_features", "=", "x_features", ".", "shape", "[", "1", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder_model'", ")", ":", "\n", "        ", "if", "model", ".", "params", "[", "\"is_image\"", "]", ":", "\n", "            ", "z_c", "=", "enc", "(", "x_features", ",", "adj", ",", "n_samples", "=", "batch_size", ",", "is_training", "=", "is_training_pl", ")", "\n", "", "else", ":", "\n", "            ", "z_c", "=", "enc", "(", "x_features", ",", "adj", ",", "n_samples", "=", "batch_size", ",", "is_training", "=", "is_training_pl", ")", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'decoder_model'", ")", ":", "\n", "        ", "x_rec", "=", "dec", "(", "z_c", ",", "n_features", ",", "is_training", "=", "is_training_pl", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'feature_extractor_model'", ")", ":", "\n", "        ", "x_flat", "=", "tf", ".", "layers", ".", "flatten", "(", "x_features", ")", "\n", "x_rec_flat", "=", "tf", ".", "layers", ".", "flatten", "(", "x_rec", ")", "\n", "z_r", "=", "feat_ex", "(", "x_flat", ",", "x_rec_flat", ")", "\n", "\n", "", "z", "=", "tf", ".", "concat", "(", "[", "z_c", ",", "z_r", "]", ",", "axis", "=", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'estimator_model'", ")", ":", "\n", "        ", "gamma", "=", "est", "(", "z", ",", "K", ",", "is_training", "=", "is_training_pl", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'gmm'", ")", ":", "\n", "        ", "energy", ",", "penalty", "=", "gmm", ".", "compute_energy_and_penalty", "(", "z", ",", "gamma", ",", "is_training_pl", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'reg'", ")", ":", "\n", "        ", "regularization", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "z_c", ",", "2", ")", ",", "axis", "=", "1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'loss_functions'", ")", ":", "\n", "# reconstruction error", "\n", "        ", "rec_error", "=", "reconstruction_error", "(", "x_flat", ",", "x_rec_flat", ")", "\n", "loss_rec", "=", "tf", ".", "reduce_mean", "(", "rec_error", ")", "\n", "loss_reg", "=", "tf", ".", "reduce_mean", "(", "regularization", ")", "\n", "# probabilities to observe", "\n", "loss_energy", "=", "tf", ".", "reduce_mean", "(", "energy", ")", "\n", "\n", "# full loss", "\n", "full_loss", "=", "loss_rec", "+", "l1", "*", "loss_energy", "+", "l2", "*", "penalty", "+", "l3", "*", "loss_reg", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'optimizer'", ")", ":", "\n", "        ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ",", "\n", "beta1", "=", "0.5", ",", "name", "=", "'dis_optimizer'", ")", "\n", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "full_loss", ",", "global_step", "=", "global_step", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'predictions'", ")", ":", "\n", "# Highest 20% are anomalous", "\n", "            ", "if", "dataset", "==", "\"kdd\"", ":", "\n", "                ", "per", "=", "tf", ".", "contrib", ".", "distributions", ".", "percentile", "(", "energy", ",", "80", ")", "\n", "", "else", ":", "\n", "                ", "per", "=", "tf", ".", "contrib", ".", "distributions", ".", "percentile", "(", "energy", ",", "80", ")", "\n", "", "y_pred", "=", "tf", ".", "greater_equal", "(", "energy", ",", "per", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "'summary'", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'loss_summary'", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'loss_rec'", ",", "loss_rec", ",", "[", "'loss'", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss_reg'", ",", "loss_rec", ",", "[", "'loss'", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'mean_energy'", ",", "loss_energy", ",", "[", "'loss'", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'penalty'", ",", "penalty", ",", "[", "'loss'", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'full_loss'", ",", "full_loss", ",", "[", "'loss'", "]", ")", "\n", "\n", "", "sum_op_loss", "=", "tf", ".", "summary", ".", "merge_all", "(", "'loss'", ")", "\n", "\n", "# Data", "\n", "", "logger", ".", "info", "(", "'Data loading...'", ")", "\n", "\n", "trainx", ",", "trainy", "=", "data", ".", "get_train", "(", "label", ",", "v", ")", "\n", "trainx_copy", "=", "trainx", ".", "copy", "(", ")", "\n", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "nr_batches_train", "=", "int", "(", "trainx", ".", "shape", "[", "0", "]", "/", "batch_size", ")", "\n", "\n", "save_dir", "=", "create_logdir", "(", "model_name", ",", "dataset", ",", "K", ",", "v", ",", "KNN", ",", "l1", ",", "l2", ",", "l3", ")", "\n", "logdir", "=", "os", ".", "path", ".", "sep", ".", "join", "(", "[", "save_dir", ",", "str", "(", "random_seed", ")", "]", ")", "\n", "\n", "writer", "=", "SummaryWriter", "(", "logdir", ")", "\n", "logger", ".", "info", "(", "'Start training...'", ")", "\n", "\n", "# Initialize session", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "logger", ".", "info", "(", "'Initialization done'", ")", "\n", "train_batch", "=", "0", "\n", "epoch", "=", "0", "\n", "while", "epoch", "<", "n_epochs", ":", "\n", "\n", "        ", "lr", "=", "starting_lr", "\n", "begin", "=", "time", ".", "time", "(", ")", "\n", "\n", "# construct randomly permuted minibatches", "\n", "trainx", "=", "trainx", "[", "rng", ".", "permutation", "(", "trainx", ".", "shape", "[", "0", "]", ")", "]", "# shuffling dataset", "\n", "trainx_copy", "=", "trainx_copy", "[", "rng", ".", "permutation", "(", "trainx", ".", "shape", "[", "0", "]", ")", "]", "\n", "train_l_rec", ",", "train_l_reg", ",", "train_l_energy", ",", "train_penalty", ",", "train_f_loss", "=", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "\n", "# training", "\n", "for", "t", "in", "range", "(", "nr_batches_train", ")", ":", "\n", "\n", "            ", "display_progression_epoch", "(", "t", ",", "nr_batches_train", ")", "\n", "ran_from", "=", "t", "*", "batch_size", "\n", "ran_to", "=", "ran_from", "+", "batch_size", "\n", "train_data", "=", "trainx", "[", "ran_from", ":", "ran_to", "]", "\n", "if", "model", ".", "params", "[", "\"is_image\"", "]", ":", "\n", "                ", "x_inps", "=", "train_data", "\n", "x_inps", "=", "np", ".", "reshape", "(", "x_inps", ",", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "train_adj_norm", "=", "construct_data", "(", "x_inps", ",", "k_neig", "=", "KNN", ")", "\n", "", "else", ":", "\n", "                ", "train_adj_norm", "=", "construct_data", "(", "train_data", ",", "k_neig", "=", "KNN", ")", "\n", "", "feed_dict", "=", "{", "x_pl", ":", "train_data", ",", "\n", "adj", ":", "train_adj_norm", ",", "\n", "is_training_pl", ":", "True", ",", "\n", "learning_rate", ":", "lr", "}", "\n", "\n", "_", ",", "sm", ",", "step", "=", "sess", ".", "run", "(", "[", "train_op", ",", "\n", "sum_op_loss", ",", "\n", "global_step", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "l_rec", ",", "l_reg", ",", "l_energy", ",", "l_penalty", ",", "f_loss", "=", "sess", ".", "run", "(", "[", "loss_rec", ",", "loss_reg", ",", "loss_energy", ",", "penalty", ",", "full_loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "train_l_rec", "+=", "l_rec", "\n", "train_l_reg", "+=", "l_reg", "\n", "train_l_energy", "+=", "l_energy", "\n", "train_penalty", "+=", "l_penalty", "\n", "train_f_loss", "+=", "f_loss", "\n", "\n", "if", "np", ".", "isnan", "(", "f_loss", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"Loss is nan - Stopping\"", ")", "\n", "break", "\n", "\n", "", "train_batch", "+=", "1", "\n", "\n", "", "train_l_rec", "/=", "nr_batches_train", "\n", "train_l_reg", "/=", "nr_batches_train", "\n", "train_l_energy", "/=", "nr_batches_train", "\n", "train_penalty", "/=", "nr_batches_train", "\n", "train_f_loss", "/=", "nr_batches_train", "\n", "\n", "logger", ".", "info", "(", "'Epoch terminated'", ")", "\n", "print", "(", "\"Epoch %d | time = %ds | loss rec = %.4f | loss en = %.4f | loss pen = %.4f | loss reg = %.4f \"", "\n", "\"| loss = %.4f\"", "\n", "%", "(", "epoch", ",", "time", ".", "time", "(", ")", "-", "begin", ",", "train_l_rec", ",", "\n", "l1", "*", "train_l_energy", ",", "\n", "l2", "*", "train_penalty", ",", "\n", "l3", "*", "train_l_reg", ",", "\n", "train_f_loss", ")", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "'train_l_rec'", ",", "train_l_rec", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'train_l_reg'", ",", "train_l_reg", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'train_l_energy'", ",", "train_l_energy", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'train_penalty'", ",", "train_penalty", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'train_f_loss'", ",", "train_f_loss", ",", "epoch", ")", "\n", "\n", "epoch", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.run": [[251, 276], ["str", "tensorflow.ConfigProto", "set_session", "tensorflow.Session", "tensorflow.Graph().as_default", "tensorflow.set_random_seed", "print", "print", "print", "run.train_and_test", "tensorflow.Graph"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.cadgmm.run.train_and_test"], ["", "", "def", "run", "(", "args", ")", ":", "\n", "    ", "import", "os", "\n", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "import", "tensorflow", "as", "tf", "\n", "from", "keras", ".", "backend", ".", "tensorflow_backend", "import", "set_session", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allocator_type", "=", "'BFC'", "\n", "# config.gpu_options.per_process_gpu_memory_fraction = 0.3", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "set_session", "(", "tf", ".", "Session", "(", "config", "=", "config", ")", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "# Set the graph level seed", "\n", "        ", "tf", ".", "set_random_seed", "(", "args", ".", "rd", ")", "\n", "\n", "print", "(", "\"#\"", "*", "30", ")", "\n", "print", "(", "\"Model: {}, dataset: {}, KNN={}, seed: {}\"", ".", "format", "(", "args", ".", "model", ",", "\n", "args", ".", "dataset", ",", "\n", "args", ".", "KNN", ",", "args", ".", "rd", ")", ")", "\n", "print", "(", "\"#\"", "*", "30", ")", "\n", "\n", "train_and_test", "(", "args", ".", "model", ",", "args", ".", "dataset", ",", "args", ".", "nb_epochs", ",", "args", ".", "it_e_val", ",", "\n", "args", ".", "K", ",", "args", ".", "v", ",", "args", ".", "KNN", ",", "\n", "args", ".", "l1", ",", "args", ".", "l2", ",", "args", ".", "l3", ",", "\n", "args", ".", "label", ",", "args", ".", "rd", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd.get_train": [[9, 12], ["kdd._get_adapted_dataset"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset"], ["def", "get_train", "(", "label", "=", "0", ",", "v", "=", "0", ",", "scale", "=", "False", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get training dataset for KDD 10 percent\"\"\"", "\n", "return", "_get_adapted_dataset", "(", "\"train\"", ",", "scale", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd.get_test": [[13, 16], ["kdd._get_adapted_dataset"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset"], ["", "def", "get_test", "(", "label", "=", "0", ",", "v", "=", "0", ",", "scale", "=", "False", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get testing dataset for KDD 10 percent\"\"\"", "\n", "return", "_get_adapted_dataset", "(", "\"test\"", ",", "scale", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd.get_valid": [[17, 20], ["None"], "function", ["None"], ["", "def", "get_valid", "(", "label", "=", "0", ",", "scale", "=", "False", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get validation dataset for KDD 10 percent\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd.get_shape_input": [[21, 24], ["None"], "function", ["None"], ["", "def", "get_shape_input", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the dataset for KDD 10 percent\"\"\"", "\n", "return", "(", "None", ",", "121", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd.get_shape_label": [[25, 28], ["None"], "function", ["None"], ["", "def", "get_shape_label", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the labels in KDD 10 percent\"\"\"", "\n", "return", "(", "None", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd.get_anomalous_proportion": [[29, 31], ["None"], "function", ["None"], ["", "def", "get_anomalous_proportion", "(", ")", ":", "\n", "    ", "return", "0.2", "\n", "", "def", "_get_dataset", "(", "scale", ",", "v", ")", ":", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._get_dataset": [[81, 180], ["kdd._col_names", "pandas.read_csv", "df[].copy", "scaler.transform.astype", "np.concatenate.astype", "scaler.transform.astype", "np.concatenate.astype", "int", "int", "kdd._encode_text_dummy", "pd.read_csv.sample", "kdd._to_xy", "kdd._to_xy", "np.concatenate.flatten().astype", "np.concatenate.flatten().astype", "pd.read_csv.sample", "kdd._to_xy", "numpy.size", "int", "numpy.arange", "numpy.arange", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.random.shuffle", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.random.shuffle", "print", "sklearn.preprocessing.MinMaxScaler", "sklearn.preprocessing.MinMaxScaler.fit", "sklearn.preprocessing.MinMaxScaler.transform", "sklearn.preprocessing.MinMaxScaler.transform", "np.concatenate.flatten", "np.concatenate.flatten", "len", "len", "len", "len", "pd.read_csv.index.isin", "numpy.where", "numpy.where"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._col_names", "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._encode_text_dummy", "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._to_xy", "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._to_xy", "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._to_xy"], ["", "def", "_get_dataset", "(", "scale", ",", "v", ")", ":", "\n", "    ", "\"\"\" Gets the basic dataset\n    Returns :\n            dataset (dict): containing the data\n                dataset['x_train'] (np.array): training images shape\n                (?, 120)\n                dataset['y_train'] (np.array): training labels shape\n                (?,)\n                dataset['x_test'] (np.array): testing images shape\n                (?, 120)\n                dataset['y_test'] (np.array): testing labels shape\n                (?,)\n    \"\"\"", "\n", "col_names", "=", "_col_names", "(", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "\"data/kddcup.data_10_percent_corrected\"", ",", "header", "=", "None", ",", "names", "=", "col_names", ")", "\n", "text_l", "=", "[", "'protocol_type'", ",", "'service'", ",", "'flag'", ",", "'land'", ",", "'logged_in'", ",", "'is_host_login'", ",", "'is_guest_login'", "]", "\n", "\n", "for", "name", "in", "text_l", ":", "\n", "        ", "_encode_text_dummy", "(", "df", ",", "name", ")", "\n", "\n", "", "labels", "=", "df", "[", "'label'", "]", ".", "copy", "(", ")", "\n", "labels", "[", "labels", "!=", "'normal.'", "]", "=", "0", "\n", "labels", "[", "labels", "==", "'normal.'", "]", "=", "1", "\n", "\n", "df", "[", "'label'", "]", "=", "labels", "\n", "if", "v", "==", "0", ":", "\n", "        ", "df_train", "=", "df", ".", "sample", "(", "frac", "=", "0.5", ",", "random_state", "=", "42", ")", "\n", "df_test", "=", "df", ".", "loc", "[", "~", "df", ".", "index", ".", "isin", "(", "df_train", ".", "index", ")", "]", "\n", "\n", "x_train", ",", "y_train", "=", "_to_xy", "(", "df_train", ",", "target", "=", "'label'", ")", "\n", "x_test", ",", "y_test", "=", "_to_xy", "(", "df_test", ",", "target", "=", "'label'", ")", "\n", "\n", "y_train", "=", "y_train", ".", "flatten", "(", ")", ".", "astype", "(", "int", ")", "\n", "y_test", "=", "y_test", ".", "flatten", "(", ")", ".", "astype", "(", "int", ")", "\n", "x_train", "=", "x_train", "[", "y_train", "!=", "1", "]", "\n", "y_train", "=", "y_train", "[", "y_train", "!=", "1", "]", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "df", ".", "sample", "(", "frac", "=", "1", ",", "random_state", "=", "42", ")", "\n", "features", ",", "labels", "=", "_to_xy", "(", "dataset", ",", "target", "=", "'label'", ")", "\n", "\n", "size_alldata", "=", "np", ".", "size", "(", "features", ",", "axis", "=", "0", ")", "\n", "\n", "size_traindata", "=", "size_alldata", "//", "2", "\n", "\n", "normal_x_data", "=", "features", "[", "labels", "==", "0", "]", "\n", "normal_y_data", "=", "labels", "[", "labels", "==", "0", "]", "\n", "size_nomaldata", "=", "normal_x_data", ".", "shape", "[", "0", "]", "\n", "\n", "anormal_x_data", "=", "features", "[", "labels", "==", "1", "]", "\n", "anormal_y_data", "=", "labels", "[", "labels", "==", "1", "]", "\n", "size_anormaldata", "=", "anormal_x_data", ".", "shape", "[", "0", "]", "\n", "size_tadata", "=", "int", "(", "v", "*", "size_anormaldata", ")", "\n", "size_tndata", "=", "size_traindata", "+", "size_tadata", "\n", "\n", "randNdata", "=", "np", ".", "arange", "(", "size_nomaldata", ")", "\n", "randAdata", "=", "np", ".", "arange", "(", "size_anormaldata", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randNdata", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randAdata", ")", "\n", "x_tndata", "=", "normal_x_data", "[", "randNdata", "[", ":", "size_tndata", "]", "]", "\n", "y_tndata", "=", "normal_y_data", "[", "randNdata", "[", ":", "size_tndata", "]", "]", "\n", "x_tadata", "=", "anormal_x_data", "[", "randAdata", "[", ":", "size_tadata", "]", "]", "\n", "y_tadata", "=", "anormal_y_data", "[", "randAdata", "[", ":", "size_tadata", "]", "]", "\n", "\n", "x_tendata", "=", "normal_x_data", "[", "randNdata", "[", "size_tndata", ":", "]", "]", "\n", "y_tendata", "=", "normal_y_data", "[", "randNdata", "[", "size_tndata", ":", "]", "]", "\n", "x_teadata", "=", "anormal_x_data", "[", "randAdata", "[", "size_tadata", ":", "]", "]", "\n", "y_teadata", "=", "anormal_y_data", "[", "randAdata", "[", "size_tadata", ":", "]", "]", "\n", "x_train", "=", "np", ".", "concatenate", "(", "(", "x_tndata", ",", "x_tadata", ")", ",", "axis", "=", "0", ")", "\n", "y_train", "=", "np", ".", "concatenate", "(", "(", "y_tndata", ",", "y_tadata", ")", ",", "axis", "=", "0", ")", "\n", "N_train", "=", "x_train", ".", "shape", "[", "0", "]", "\n", "randIdt", "=", "np", ".", "arange", "(", "N_train", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randIdt", ")", "\n", "x_train", "=", "x_train", "[", "randIdt", "[", ":", "]", "]", "\n", "y_train", "=", "y_train", "[", "randIdt", "[", ":", "]", "]", "\n", "\n", "x_test", "=", "np", ".", "concatenate", "(", "(", "x_tendata", ",", "x_teadata", ")", ",", "axis", "=", "0", ")", "\n", "y_test", "=", "np", ".", "concatenate", "(", "(", "y_tendata", ",", "y_teadata", ")", ",", "axis", "=", "0", ")", "\n", "N_test", "=", "x_test", ".", "shape", "[", "0", "]", "\n", "randIdt", "=", "np", ".", "arange", "(", "N_test", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randIdt", ")", "\n", "x_test", "=", "x_test", "[", "randIdt", "[", ":", "]", "]", "\n", "y_test", "=", "y_test", "[", "randIdt", "[", ":", "]", "]", "\n", "", "if", "scale", ":", "\n", "        ", "print", "(", "\"Scaling KDD dataset\"", ")", "\n", "scaler", "=", "MinMaxScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "x_train", ")", "\n", "x_train", "=", "scaler", ".", "transform", "(", "x_train", ")", "\n", "x_test", "=", "scaler", ".", "transform", "(", "x_test", ")", "\n", "\n", "\n", "", "dataset", "=", "{", "}", "\n", "dataset", "[", "'x_train'", "]", "=", "x_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'y_train'", "]", "=", "y_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'x_test'", "]", "=", "x_test", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'y_test'", "]", "=", "y_test", ".", "astype", "(", "np", ".", "float32", ")", "\n", "normal_ratio_train", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_train", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_train", ")", "*", "100", ")", "\n", "normal_ratio_test", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_test", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_test", ")", "*", "100", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._get_adapted_dataset": [[182, 200], ["kdd._get_dataset", "kdd._adapt_ratio"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_dataset", "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._adapt_ratio"], ["", "def", "_get_adapted_dataset", "(", "split", ",", "scale", ",", "v", ")", ":", "\n", "    ", "\"\"\" Gets the adapted dataset for the experiments\n\n    Args :\n            split (str): train or test\n    Returns :\n            (tuple): <training, testing> images and labels\n    \"\"\"", "\n", "# print(\"_get_adapted\",scale)", "\n", "dataset", "=", "_get_dataset", "(", "scale", ",", "v", ")", "\n", "key_img", "=", "'x_'", "+", "split", "\n", "key_lbl", "=", "'y_'", "+", "split", "\n", "\n", "if", "split", "==", "'test'", ":", "\n", "        ", "dataset", "[", "key_img", "]", ",", "dataset", "[", "key_lbl", "]", "=", "_adapt_ratio", "(", "dataset", "[", "key_img", "]", ",", "\n", "dataset", "[", "key_lbl", "]", ")", "\n", "\n", "", "return", "(", "dataset", "[", "key_img", "]", ",", "dataset", "[", "key_lbl", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._encode_text_dummy": [[202, 211], ["pandas.get_dummies", "df.drop"], "function", ["None"], ["", "def", "_encode_text_dummy", "(", "df", ",", "name", ")", ":", "\n", "    ", "\"\"\"Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1]\n    for red,green,blue)\n    \"\"\"", "\n", "dummies", "=", "pd", ".", "get_dummies", "(", "df", ".", "loc", "[", ":", ",", "name", "]", ")", "\n", "for", "x", "in", "dummies", ".", "columns", ":", "\n", "        ", "dummy_name", "=", "\"{}-{}\"", ".", "format", "(", "name", ",", "x", ")", "\n", "df", ".", "loc", "[", ":", ",", "dummy_name", "]", "=", "dummies", "[", "x", "]", "\n", "", "df", ".", "drop", "(", "name", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._to_xy": [[212, 220], ["df.as_matrix().astype", "dummies.as_matrix().flatten().astype", "result.append", "df.as_matrix", "dummies.as_matrix().flatten", "dummies.as_matrix"], "function", ["None"], ["", "def", "_to_xy", "(", "df", ",", "target", ")", ":", "\n", "    ", "\"\"\"Converts a Pandas dataframe to the x,y inputs that TensorFlow needs\"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "x", "in", "df", ".", "columns", ":", "\n", "        ", "if", "x", "!=", "target", ":", "\n", "            ", "result", ".", "append", "(", "x", ")", "\n", "", "", "dummies", "=", "df", "[", "target", "]", "\n", "return", "df", ".", "as_matrix", "(", "result", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "dummies", ".", "as_matrix", "(", ")", ".", "flatten", "(", ")", ".", "astype", "(", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._col_names": [[221, 233], ["None"], "function", ["None"], ["", "def", "_col_names", "(", ")", ":", "\n", "    ", "\"\"\"Column names of the dataframe\"\"\"", "\n", "return", "[", "\"duration\"", ",", "\"protocol_type\"", ",", "\"service\"", ",", "\"flag\"", ",", "\"src_bytes\"", ",", "\n", "\"dst_bytes\"", ",", "\"land\"", ",", "\"wrong_fragment\"", ",", "\"urgent\"", ",", "\"hot\"", ",", "\"num_failed_logins\"", ",", "\n", "\"logged_in\"", ",", "\"num_compromised\"", ",", "\"root_shell\"", ",", "\"su_attempted\"", ",", "\"num_root\"", ",", "\n", "\"num_file_creations\"", ",", "\"num_shells\"", ",", "\"num_access_files\"", ",", "\"num_outbound_cmds\"", ",", "\n", "\"is_host_login\"", ",", "\"is_guest_login\"", ",", "\"count\"", ",", "\"srv_count\"", ",", "\"serror_rate\"", ",", "\n", "\"srv_serror_rate\"", ",", "\"rerror_rate\"", ",", "\"srv_rerror_rate\"", ",", "\"same_srv_rate\"", ",", "\n", "\"diff_srv_rate\"", ",", "\"srv_diff_host_rate\"", ",", "\"dst_host_count\"", ",", "\"dst_host_srv_count\"", ",", "\n", "\"dst_host_same_srv_rate\"", ",", "\"dst_host_diff_srv_rate\"", ",", "\"dst_host_same_src_port_rate\"", ",", "\n", "\"dst_host_srv_diff_host_rate\"", ",", "\"dst_host_serror_rate\"", ",", "\"dst_host_srv_serror_rate\"", ",", "\n", "\"dst_host_rerror_rate\"", ",", "\"dst_host_srv_rerror_rate\"", ",", "\"label\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.kdd._adapt_ratio": [[234, 271], ["int", "numpy.random.RandomState", "np.random.RandomState.permutation", "int", "numpy.concatenate", "numpy.concatenate", "int", "np.random.RandomState.permutation", "int", "len", "len", "len", "len", "len", "len", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "_adapt_ratio", "(", "x", ",", "y", ",", "rho", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"Adapt the ratio of normal/anomalous data\"\"\"", "\n", "\n", "# Normal data: label =0, anomalous data: label =1", "\n", "\n", "normal_ratio_test", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y", ")", "*", "100", ")", "\n", "\n", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "# seed shuffling", "\n", "\n", "inliersx", "=", "x", "[", "y", "==", "0", "]", "\n", "inliersy", "=", "y", "[", "y", "==", "0", "]", "\n", "outliersx", "=", "x", "[", "y", "==", "1", "]", "\n", "outliersy", "=", "y", "[", "y", "==", "1", "]", "\n", "\n", "size_outliers", "=", "outliersx", ".", "shape", "[", "0", "]", "\n", "inds", "=", "rng", ".", "permutation", "(", "size_outliers", ")", "\n", "outliersx", ",", "outliersy", "=", "outliersx", "[", "inds", "]", ",", "outliersy", "[", "inds", "]", "\n", "\n", "size_x", "=", "inliersx", ".", "shape", "[", "0", "]", "\n", "out_size_x", "=", "int", "(", "size_x", "*", "rho", "/", "(", "1", "-", "rho", ")", ")", "\n", "\n", "out_sample_x", "=", "outliersx", "[", ":", "out_size_x", "]", "\n", "out_sample_y", "=", "outliersy", "[", ":", "out_size_x", "]", "\n", "\n", "x_adapted", "=", "np", ".", "concatenate", "(", "(", "inliersx", ",", "out_sample_x", ")", ",", "axis", "=", "0", ")", "\n", "y_adapted", "=", "np", ".", "concatenate", "(", "(", "inliersy", ",", "out_sample_y", ")", ",", "axis", "=", "0", ")", "\n", "\n", "normal_ratio_test1", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_adapted", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_adapted", ")", "*", "100", ")", "\n", "\n", "\n", "size_x", "=", "x_adapted", ".", "shape", "[", "0", "]", "\n", "inds", "=", "rng", ".", "permutation", "(", "size_x", ")", "\n", "x_adapted", ",", "y_adapted", "=", "x_adapted", "[", "inds", "]", ",", "y_adapted", "[", "inds", "]", "\n", "normal_ratio_test2", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_adapted", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_adapted", ")", "*", "100", ")", "\n", "\n", "return", "x_adapted", ",", "y_adapted", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia.get_train": [[10, 13], ["arrhythmia._get_adapted_dataset"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset"], ["def", "get_train", "(", "label", "=", "0", ",", "scale", "=", "False", ",", "v", "=", "0", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get training dataset for Thyroid dataset\"\"\"", "\n", "return", "_get_adapted_dataset", "(", "\"train\"", ",", "scale", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia.get_test": [[14, 17], ["arrhythmia._get_adapted_dataset"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset"], ["", "def", "get_test", "(", "label", "=", "0", ",", "scale", "=", "False", ",", "v", "=", "0", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get testing dataset for Thyroid dataset\"\"\"", "\n", "return", "_get_adapted_dataset", "(", "\"test\"", ",", "scale", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia.get_valid": [[18, 21], ["arrhythmia._get_adapted_dataset"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset"], ["", "def", "get_valid", "(", "label", "=", "0", ",", "scale", "=", "False", ",", "v", "=", "0", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get validation dataset for Thyroid dataset\"\"\"", "\n", "return", "_get_adapted_dataset", "(", "\"valid\"", ",", "scale", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia.get_shape_input": [[22, 25], ["None"], "function", ["None"], ["", "def", "get_shape_input", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the dataset for Thyroid dataset\"\"\"", "\n", "return", "(", "None", ",", "274", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia.get_shape_input_flatten": [[26, 29], ["None"], "function", ["None"], ["", "def", "get_shape_input_flatten", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the dataset for Thyroid dataset\"\"\"", "\n", "return", "(", "None", ",", "274", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia.get_shape_label": [[30, 33], ["None"], "function", ["None"], ["", "def", "get_shape_label", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the labels in Thyroid dataset\"\"\"", "\n", "return", "(", "None", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia.get_anomalous_proportion": [[34, 36], ["None"], "function", ["None"], ["", "def", "get_anomalous_proportion", "(", ")", ":", "\n", "    ", "return", "0.15", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia._get_dataset": [[37, 139], ["scipy.io.loadmat", "full_y_data.flatten().astype", "numpy.size", "numpy.size", "numpy.size", "numpy.arange", "numpy.arange", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.random.shuffle", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.random.shuffle", "numpy.squeeze", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.random.shuffle", "numpy.squeeze", "scaler.transform.astype", "np.concatenate.astype", "np.concatenate.astype", "np.squeeze.astype", "scaler.transform.astype", "np.squeeze.astype", "int", "int", "print", "sklearn.preprocessing.MinMaxScaler", "sklearn.preprocessing.MinMaxScaler.fit", "sklearn.preprocessing.MinMaxScaler.transform", "sklearn.preprocessing.MinMaxScaler.transform", "full_y_data.flatten", "len", "len", "len", "len", "int", "int", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "_get_dataset", "(", "scale", ",", "v", ")", ":", "\n", "    ", "\"\"\" Gets the basic dataset\n    Returns :\n            dataset (dict): containing the data\n                dataset['x_train'] (np.array): training images shape\n                (?, 120)\n                dataset['y_train'] (np.array): training labels shape\n                (?,)\n                dataset['x_test'] (np.array): testing images shape\n                (?, 120)\n                dataset['y_test'] (np.array): testing labels shape\n                (?,)\n    \"\"\"", "\n", "data", "=", "scipy", ".", "io", ".", "loadmat", "(", "\"data/arrhythmia.mat\"", ")", "\n", "\n", "full_x_data", "=", "data", "[", "\"X\"", "]", "\n", "full_y_data", "=", "data", "[", "'y'", "]", "\n", "\n", "y_data", "=", "full_y_data", ".", "flatten", "(", ")", ".", "astype", "(", "int", ")", "\n", "\n", "normal_x_data", "=", "full_x_data", "[", "y_data", "!=", "1", "]", "\n", "normal_y_data", "=", "full_y_data", "[", "y_data", "!=", "1", "]", "\n", "anormal_x_data", "=", "full_x_data", "[", "y_data", "==", "1", "]", "\n", "anormal_y_data", "=", "full_y_data", "[", "y_data", "==", "1", "]", "\n", "\n", "\n", "size_alldata", "=", "np", ".", "size", "(", "full_x_data", ",", "axis", "=", "0", ")", "\n", "size_normaldata", "=", "np", ".", "size", "(", "normal_x_data", ",", "axis", "=", "0", ")", "\n", "size_anormaldata", "=", "np", ".", "size", "(", "anormal_x_data", ",", "axis", "=", "0", ")", "\n", "#size_traindata = size_alldata // 2", "\n", "size_traindata", "=", "size_normaldata", "-", "size_anormaldata", "\n", "size_validdata", "=", "size_traindata", "//", "2", "+", "size_anormaldata", "//", "2", "\n", "size_testdata", "=", "size_validdata", "\n", "\n", "size_tadata", "=", "v", "*", "size_anormaldata", "# size of anomal data in train data", "\n", "size_tndata", "=", "size_traindata", "-", "size_tadata", "# size of nomal data in train data", "\n", "\n", "randNdata", "=", "np", ".", "arange", "(", "size_normaldata", ")", "\n", "randAdata", "=", "np", ".", "arange", "(", "size_anormaldata", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randNdata", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randAdata", ")", "\n", "x_tndata", "=", "normal_x_data", "[", "randNdata", "[", ":", "size_tndata", "]", "]", "\n", "y_tndata", "=", "normal_y_data", "[", "randNdata", "[", ":", "size_tndata", "]", "]", "\n", "x_tadata", "=", "anormal_x_data", "[", "randAdata", "[", ":", "int", "(", "size_tadata", ")", "]", "]", "\n", "y_tadata", "=", "anormal_y_data", "[", "randAdata", "[", ":", "int", "(", "size_tadata", ")", "]", "]", "\n", "\n", "x_vndata", "=", "normal_x_data", "[", "randNdata", "[", ":", "size_traindata", "//", "2", "]", "]", "\n", "y_vndata", "=", "normal_y_data", "[", "randNdata", "[", ":", "size_traindata", "//", "2", "]", "]", "\n", "x_vadata", "=", "anormal_x_data", "[", "randAdata", "[", ":", "size_anormaldata", "//", "2", "]", "]", "\n", "y_vadata", "=", "anormal_y_data", "[", "randAdata", "[", ":", "size_anormaldata", "//", "2", "]", "]", "\n", "\n", "x_tendata", "=", "normal_x_data", "[", "randNdata", "[", "size_traindata", "//", "2", ":", "size_traindata", "]", "]", "\n", "y_tendata", "=", "normal_y_data", "[", "randNdata", "[", "size_traindata", "//", "2", ":", "size_traindata", "]", "]", "\n", "x_teadata", "=", "anormal_x_data", "[", "randAdata", "[", "size_anormaldata", "//", "2", ":", "]", "]", "\n", "y_teadata", "=", "anormal_y_data", "[", "randAdata", "[", "size_anormaldata", "//", "2", ":", "]", "]", "\n", "x_train", "=", "np", ".", "concatenate", "(", "(", "x_tndata", ",", "x_tadata", ")", ",", "axis", "=", "0", ")", "\n", "y_train", "=", "np", ".", "concatenate", "(", "(", "y_tndata", ",", "y_tadata", ")", ",", "axis", "=", "0", ")", "\n", "N_train", "=", "x_train", ".", "shape", "[", "0", "]", "\n", "randIdt", "=", "np", ".", "arange", "(", "N_train", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randIdt", ")", "\n", "x_train", "=", "x_train", "[", "randIdt", "[", ":", "]", "]", "\n", "y_train", "=", "y_train", "[", "randIdt", "[", ":", "]", "]", "\n", "\n", "x_valid", "=", "np", ".", "concatenate", "(", "(", "x_vndata", ",", "x_vadata", ")", ",", "axis", "=", "0", ")", "\n", "y_valid", "=", "np", ".", "concatenate", "(", "(", "y_vndata", ",", "y_vadata", ")", ",", "axis", "=", "0", ")", "\n", "N_valid", "=", "x_valid", ".", "shape", "[", "0", "]", "\n", "randIdt", "=", "np", ".", "arange", "(", "N_valid", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randIdt", ")", "\n", "x_valid", "=", "x_valid", "[", "randIdt", "[", ":", "]", "]", "\n", "y_valid", "=", "y_valid", "[", "randIdt", "[", ":", "]", "]", "\n", "y_valid", "=", "np", ".", "squeeze", "(", "y_valid", ")", "\n", "\n", "x_test", "=", "np", ".", "concatenate", "(", "(", "x_tendata", ",", "x_teadata", ")", ",", "axis", "=", "0", ")", "\n", "y_test", "=", "np", ".", "concatenate", "(", "(", "y_tendata", ",", "y_teadata", ")", ",", "axis", "=", "0", ")", "\n", "N_test", "=", "x_test", ".", "shape", "[", "0", "]", "\n", "randIdt", "=", "np", ".", "arange", "(", "N_test", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randIdt", ")", "\n", "x_test", "=", "x_test", "[", "randIdt", "[", ":", "]", "]", "\n", "y_test", "=", "y_test", "[", "randIdt", "[", ":", "]", "]", "\n", "y_test", "=", "np", ".", "squeeze", "(", "y_test", ")", "\n", "\n", "if", "scale", ":", "\n", "        ", "print", "(", "\"Scaling dataset\"", ")", "\n", "scaler", "=", "MinMaxScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "x_train", ")", "\n", "x_train", "=", "scaler", ".", "transform", "(", "x_train", ")", "\n", "x_test", "=", "scaler", ".", "transform", "(", "x_test", ")", "\n", "\n", "", "dataset", "=", "{", "}", "\n", "dataset", "[", "'x_train'", "]", "=", "x_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'y_train'", "]", "=", "y_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'x_valid'", "]", "=", "x_valid", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'y_valid'", "]", "=", "y_valid", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'x_test'", "]", "=", "x_test", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'y_test'", "]", "=", "y_test", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "normal_ratio_train", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_train", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_train", ")", "*", "100", ")", "\n", "normal_ratio_test", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_test", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_test", ")", "*", "100", ")", "\n", "\n", "\n", "\n", "return", "dataset", "\n", "", "def", "_get_adapted_dataset", "(", "split", ",", "scale", ",", "v", ")", ":", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia._get_adapted_dataset": [[139, 155], ["arrhythmia._get_dataset", "print"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_dataset"], ["", "def", "_get_adapted_dataset", "(", "split", ",", "scale", ",", "v", ")", ":", "\n", "    ", "\"\"\" Gets the adapted dataset for the experiments\n\n    Args :\n            split (str): train or test\n    Returns :\n            (tuple): <training, testing> images and labels\n    \"\"\"", "\n", "# print(\"_get_adapted\",scale)", "\n", "dataset", "=", "_get_dataset", "(", "scale", ",", "v", ")", "\n", "key_img", "=", "'x_'", "+", "split", "\n", "key_lbl", "=", "'y_'", "+", "split", "\n", "\n", "print", "(", "\"Size of split\"", ",", "split", ",", "\":\"", ",", "dataset", "[", "key_lbl", "]", ".", "shape", "[", "0", "]", ")", "\n", "\n", "return", "(", "dataset", "[", "key_img", "]", ",", "dataset", "[", "key_lbl", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.arrhythmia._to_xy": [[156, 164], ["df.as_matrix().astype", "dummies.as_matrix().astype", "result.append", "df.as_matrix", "dummies.as_matrix"], "function", ["None"], ["", "def", "_to_xy", "(", "df", ",", "target", ")", ":", "\n", "    ", "\"\"\"Converts a Pandas dataframe to the x,y inputs that TensorFlow needs\"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "x", "in", "df", ".", "columns", ":", "\n", "        ", "if", "x", "!=", "target", ":", "\n", "            ", "result", ".", "append", "(", "x", ")", "\n", "", "", "dummies", "=", "df", "[", "target", "]", "\n", "return", "df", ".", "as_matrix", "(", "result", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "dummies", ".", "as_matrix", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_train": [[11, 14], ["satellite._get_adapted_dataset"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset"], ["def", "get_train", "(", "label", "=", "0", ",", "scale", "=", "False", ",", "v", "=", "0", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get training dataset for Thyroid dataset\"\"\"", "\n", "return", "_get_adapted_dataset", "(", "\"train\"", ",", "scale", ",", "v", "=", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_test": [[16, 19], ["satellite._get_adapted_dataset"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset"], ["", "def", "get_test", "(", "label", "=", "0", ",", "scale", "=", "False", ",", "v", "=", "0", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get testing dataset for Thyroid dataset\"\"\"", "\n", "return", "_get_adapted_dataset", "(", "\"test\"", ",", "scale", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_valid": [[21, 24], ["None"], "function", ["None"], ["", "def", "get_valid", "(", "label", "=", "0", ",", "scale", "=", "False", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Get validation dataset for Thyroid dataset\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_shape_input": [[26, 29], ["None"], "function", ["None"], ["", "def", "get_shape_input", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the dataset for Thyroid dataset\"\"\"", "\n", "return", "(", "None", ",", "36", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_shape_input_flatten": [[31, 34], ["None"], "function", ["None"], ["", "def", "get_shape_input_flatten", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the dataset for Thyroid dataset\"\"\"", "\n", "return", "(", "None", ",", "36", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_shape_label": [[36, 39], ["None"], "function", ["None"], ["", "def", "get_shape_label", "(", ")", ":", "\n", "    ", "\"\"\"Get shape of the labels in Thyroid dataset\"\"\"", "\n", "return", "(", "None", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite.get_anomalous_proportion": [[41, 43], ["None"], "function", ["None"], ["", "def", "get_anomalous_proportion", "(", ")", ":", "\n", "    ", "return", "0.32", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_dataset": [[89, 169], ["scipy.io.loadmat", "full_y_data.flatten().astype", "numpy.size", "numpy.size", "numpy.size", "numpy.arange", "numpy.arange", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.random.shuffle", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.random.shuffle", "numpy.squeeze", "scaler.transform.astype", "np.concatenate.astype", "scaler.transform.astype", "np.squeeze.astype", "int", "int", "print", "sklearn.preprocessing.MinMaxScaler", "sklearn.preprocessing.MinMaxScaler.fit", "sklearn.preprocessing.MinMaxScaler.transform", "sklearn.preprocessing.MinMaxScaler.transform", "full_y_data.flatten", "len", "len", "len", "len", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "_get_dataset", "(", "scale", ",", "v", ")", ":", "\n", "    ", "\"\"\" Gets the basic dataset\n    Returns :\n            dataset (dict): containing the data\n                dataset['x_train'] (np.array): training images shape\n                (?, 120)\n                dataset['y_train'] (np.array): training labels shape\n                (?,)\n                dataset['x_test'] (np.array): testing images shape\n                (?, 120)\n                dataset['y_test'] (np.array): testing labels shape\n                (?,)\n    \"\"\"", "\n", "data", "=", "scipy", ".", "io", ".", "loadmat", "(", "\"data/satellite.mat\"", ")", "\n", "\n", "full_x_data", "=", "data", "[", "\"X\"", "]", "\n", "full_y_data", "=", "data", "[", "'y'", "]", "\n", "\n", "y_data", "=", "full_y_data", ".", "flatten", "(", ")", ".", "astype", "(", "int", ")", "\n", "\n", "normal_x_data", "=", "full_x_data", "[", "y_data", "!=", "1", "]", "\n", "normal_y_data", "=", "full_y_data", "[", "y_data", "!=", "1", "]", "\n", "anormal_x_data", "=", "full_x_data", "[", "y_data", "==", "1", "]", "\n", "anormal_y_data", "=", "full_y_data", "[", "y_data", "==", "1", "]", "\n", "\n", "size_alldata", "=", "np", ".", "size", "(", "full_x_data", ",", "axis", "=", "0", ")", "\n", "size_normaldata", "=", "np", ".", "size", "(", "normal_x_data", ",", "axis", "=", "0", ")", "\n", "size_anormaldata", "=", "np", ".", "size", "(", "anormal_x_data", ",", "axis", "=", "0", ")", "\n", "size_traindata", "=", "size_alldata", "//", "2", "\n", "size_tadata", "=", "v", "*", "size_anormaldata", "# size of anomal data in train data", "\n", "size_tndata", "=", "size_traindata", "-", "size_tadata", "# size of nomal data in train data", "\n", "randNdata", "=", "np", ".", "arange", "(", "size_normaldata", ")", "\n", "randAdata", "=", "np", ".", "arange", "(", "size_anormaldata", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randNdata", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randAdata", ")", "\n", "x_tndata", "=", "normal_x_data", "[", "randNdata", "[", ":", "size_tndata", "]", "]", "\n", "y_tndata", "=", "normal_y_data", "[", "randNdata", "[", ":", "size_tndata", "]", "]", "\n", "x_tadata", "=", "anormal_x_data", "[", "randAdata", "[", ":", "size_tadata", "]", "]", "\n", "y_tadata", "=", "anormal_y_data", "[", "randAdata", "[", ":", "size_tadata", "]", "]", "\n", "\n", "x_tendata", "=", "normal_x_data", "[", "randNdata", "[", "size_tndata", ":", "]", "]", "\n", "y_tendata", "=", "normal_y_data", "[", "randNdata", "[", "size_tndata", ":", "]", "]", "\n", "x_teadata", "=", "anormal_x_data", "[", "randAdata", "[", "size_tadata", ":", "]", "]", "\n", "y_teadata", "=", "anormal_y_data", "[", "randAdata", "[", "size_tadata", ":", "]", "]", "\n", "x_train", "=", "np", ".", "concatenate", "(", "(", "x_tndata", ",", "x_tadata", ")", ",", "axis", "=", "0", ")", "\n", "y_train", "=", "np", ".", "concatenate", "(", "(", "y_tndata", ",", "y_tadata", ")", ",", "axis", "=", "0", ")", "\n", "N_train", "=", "x_train", ".", "shape", "[", "0", "]", "\n", "randIdt", "=", "np", ".", "arange", "(", "N_train", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randIdt", ")", "\n", "x_train", "=", "x_train", "[", "randIdt", "[", ":", "]", "]", "\n", "y_train", "=", "y_train", "[", "randIdt", "[", ":", "]", "]", "\n", "\n", "x_test", "=", "np", ".", "concatenate", "(", "(", "x_tendata", ",", "x_teadata", ")", ",", "axis", "=", "0", ")", "\n", "y_test", "=", "np", ".", "concatenate", "(", "(", "y_tendata", ",", "y_teadata", ")", ",", "axis", "=", "0", ")", "\n", "N_test", "=", "x_test", ".", "shape", "[", "0", "]", "\n", "randIdt", "=", "np", ".", "arange", "(", "N_test", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "randIdt", ")", "\n", "x_test", "=", "x_test", "[", "randIdt", "[", ":", "]", "]", "\n", "y_test", "=", "y_test", "[", "randIdt", "[", ":", "]", "]", "\n", "y_test", "=", "np", ".", "squeeze", "(", "y_test", ")", "\n", "\n", "if", "scale", ":", "\n", "        ", "print", "(", "\"Scaling dataset\"", ")", "\n", "scaler", "=", "MinMaxScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "x_train", ")", "\n", "x_train", "=", "scaler", ".", "transform", "(", "x_train", ")", "\n", "x_test", "=", "scaler", ".", "transform", "(", "x_test", ")", "\n", "\n", "", "dataset", "=", "{", "}", "\n", "dataset", "[", "'x_train'", "]", "=", "x_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'y_train'", "]", "=", "y_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'x_test'", "]", "=", "x_test", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dataset", "[", "'y_test'", "]", "=", "y_test", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "normal_ratio_train", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_train", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_train", ")", "*", "100", ")", "\n", "normal_ratio_test", "=", "int", "(", "len", "(", "np", ".", "where", "(", "y_test", "==", "0", ")", "[", "0", "]", ")", "/", "len", "(", "y_test", ")", "*", "100", ")", "\n", "\n", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_adapted_dataset": [[171, 187], ["satellite._get_dataset", "print"], "function", ["home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._get_dataset"], ["", "def", "_get_adapted_dataset", "(", "split", ",", "scale", ",", "v", ")", ":", "\n", "    ", "\"\"\" Gets the adapted dataset for the experiments\n\n    Args :\n            split (str): train or test\n    Returns :\n            (tuple): <training, testing> images and labels\n    \"\"\"", "\n", "# print(\"_get_adapted\",scale)", "\n", "dataset", "=", "_get_dataset", "(", "scale", ",", "v", ")", "\n", "key_img", "=", "'x_'", "+", "split", "\n", "key_lbl", "=", "'y_'", "+", "split", "\n", "\n", "print", "(", "\"Size of split\"", ",", "split", ",", "\":\"", ",", "dataset", "[", "key_lbl", "]", ".", "shape", "[", "0", "]", ")", "\n", "\n", "return", "(", "dataset", "[", "key_img", "]", ",", "dataset", "[", "key_lbl", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haoyfan_CADGMM.data.satellite._to_xy": [[189, 197], ["df.as_matrix().astype", "dummies.as_matrix().astype", "result.append", "df.as_matrix", "dummies.as_matrix"], "function", ["None"], ["", "def", "_to_xy", "(", "df", ",", "target", ")", ":", "\n", "    ", "\"\"\"Converts a Pandas dataframe to the x,y inputs that TensorFlow needs\"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "x", "in", "df", ".", "columns", ":", "\n", "        ", "if", "x", "!=", "target", ":", "\n", "            ", "result", ".", "append", "(", "x", ")", "\n", "", "", "dummies", "=", "df", "[", "target", "]", "\n", "return", "df", ".", "as_matrix", "(", "result", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "dummies", ".", "as_matrix", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]]}