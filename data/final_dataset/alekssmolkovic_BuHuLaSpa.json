{"home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.vae-multiD.MyEvaluation.__init__": [[142, 146], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.iVAE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "validation_data", "=", "(", ")", ",", "interval", "=", "10", ")", ":", "\n", "        ", "super", "(", "Callback", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "interval", "=", "interval", "\n", "self", ".", "X_val", ",", "self", ".", "y_val", "=", "validation_data", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.vae-multiD.MyEvaluation.on_epoch_end": [[147, 204], ["encoder.predict", "numpy.median", "print", "print", "medians.append", "numpy.sum", "numpy.sum", "vae-multiD.get_perf_stats", "auc_zmean2.append", "imtafe_zmean2.append", "print", "vae-multiD.get_perf_stats", "auc_zmean2_shift.append", "imtafe_zmean2_shift.append", "print", "tensorflow.keras.backend.mean().numpy", "print", "klhist.append", "vae-multiD.get_perf_stats", "auc_kl.append", "imtafe_kl.append", "print", "print", "wghts.append", "encoder_wghts.append", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.power", "numpy.power", "vae-multiD.get_perf_stats", "auc_zlogvar.append", "imtafe_zlogvar.append", "print", "tensorflow.keras.backend.sum", "numpy.reshape", "numpy.reshape", "vae.get_weights", "encoder.get_weights", "numpy.asarray", "numpy.asarray", "numpy.save", "numpy.save", "numpy.asarray", "numpy.asarray", "numpy.reshape", "numpy.reshape", "tensorflow.keras.backend.mean", "numpy.asarray", "numpy.asarray", "numpy.median", "numpy.round", "numpy.round", "numpy.round", "numpy.round", "numpy.ndarray.flatten", "tensorflow.keras.backend.exp", "numpy.round", "numpy.round", "numpy.round", "numpy.round", "tensorflow.keras.backend.square"], "methods", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.get_perf_stats", "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.get_perf_stats", "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.get_perf_stats", "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.get_perf_stats"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "if", "epoch", "%", "self", ".", "interval", "==", "0", ":", "\n", "            ", "encoded", "=", "encoder", ".", "predict", "(", "self", ".", "X_val", ",", "verbose", "=", "0", ")", "\n", "# get zmeans and z_logvars", "\n", "z_means", "=", "encoded", "[", "0", "]", "\n", "z_logvars", "=", "encoded", "[", "1", "]", "\n", "\n", "# calculate the mean of zmeans for each dimension, we get a vector of dim. of latent dim", "\n", "z_means_mean", "=", "np", ".", "median", "(", "z_means", ",", "axis", "=", "0", ")", "\n", "print", "(", "f\"zmeans_median: {z_means_mean}\"", ")", "\n", "print", "(", "f\"zlogvar_median: {np.median(z_logvars, axis=0)}\"", ")", "\n", "medians", ".", "append", "(", "z_means_mean", ")", "\n", "\n", "# calculate zmean^2 by taking the square of each component, then summing", "\n", "z_means2", "=", "np", ".", "sum", "(", "np", ".", "power", "(", "z_means", ",", "2", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# calculate the shifted zmean^2 by taking the difference between the value and the mean for each component, squaring, then summing", "\n", "z_means2_shifted", "=", "np", ".", "sum", "(", "np", ".", "power", "(", "z_means", "-", "z_means_mean", ",", "2", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# calculate performances of each classifier", "\n", "auc2", ",", "imtafe2", "=", "get_perf_stats", "(", "self", ".", "y_val", ",", "z_means2", ")", "\n", "auc_zmean2", ".", "append", "(", "auc2", ")", "\n", "imtafe_zmean2", ".", "append", "(", "imtafe2", ")", "\n", "print", "(", "f\"\\nAt epoch {epoch+1} the zmean2 AUC is {np.round(auc2, 2)} and imtafe is {np.round(imtafe2, 2)}.\\n\"", ")", "\n", "\n", "auc2sh", ",", "imtafe2sh", "=", "get_perf_stats", "(", "self", ".", "y_val", ",", "z_means2_shifted", ")", "\n", "auc_zmean2_shift", ".", "append", "(", "auc2sh", ")", "\n", "imtafe_zmean2_shift", ".", "append", "(", "imtafe2sh", ")", "\n", "print", "(", "f\"\\nAt epoch {epoch+1} the zmean2 shifted AUC is {np.round(auc2sh, 2)} and imtafe is {np.round(imtafe2sh, 2)}.\\n\"", ")", "\n", "if", "zdim", "==", "1", ":", "\n", "                ", "auclv", ",", "imtafelv", "=", "get_perf_stats", "(", "np", ".", "reshape", "(", "self", ".", "y_val", ",", "-", "1", ")", ",", "np", ".", "reshape", "(", "np", ".", "ndarray", ".", "flatten", "(", "z_logvars", ")", ",", "-", "1", ")", ")", "\n", "auc_zlogvar", ".", "append", "(", "auclv", ")", "\n", "imtafe_zlogvar", ".", "append", "(", "imtafelv", ")", "\n", "print", "(", "f\"\\nAt epoch {epoch+1} the zlogvar AUC is {np.round(auclv, 2)} and imtafe is {np.round(imtafelv, 2)}.\\n\"", ")", "\n", "\n", "\n", "", "kls", "=", "-", "0.5", "*", "K", ".", "sum", "(", "1", "+", "z_logvars", "-", "K", ".", "square", "(", "z_means", ")", "-", "K", ".", "exp", "(", "z_logvars", ")", ",", "axis", "=", "-", "1", ")", "\n", "kl", "=", "K", ".", "mean", "(", "kls", ")", ".", "numpy", "(", ")", "\n", "print", "(", "f\"kl: {kl}\"", ")", "\n", "klhist", ".", "append", "(", "kl", ")", "\n", "auckl", ",", "imtafekl", "=", "get_perf_stats", "(", "np", ".", "reshape", "(", "self", ".", "y_val", ",", "-", "1", ")", ",", "np", ".", "reshape", "(", "kls", ",", "-", "1", ")", ")", "\n", "auc_kl", ".", "append", "(", "auckl", ")", "\n", "imtafe_kl", ".", "append", "(", "imtafekl", ")", "\n", "print", "(", "f\"\\nAt epoch {epoch+1} the kl AUC is {np.round(auckl, 2)} and imtafe is {np.round(imtafekl, 2)}.\\n\"", ")", "\n", "print", "(", "\"Saving...\"", ")", "\n", "\n", "# np.save(f\"{flag}_history_{optimizer}_{sb}.npy\", (history.history)['loss'])", "\n", "wghts", ".", "append", "(", "vae", ".", "get_weights", "(", ")", ")", "\n", "encoder_wghts", ".", "append", "(", "encoder", ".", "get_weights", "(", ")", ")", "\n", "np", ".", "save", "(", "f\"runs/{flag}_wghts_{outlabel}.npy\"", ",", "np", ".", "asarray", "(", "wghts", ")", ")", "\n", "np", ".", "save", "(", "f\"runs/{flag}_encwghts_{outlabel}.npy\"", ",", "np", ".", "asarray", "(", "encoder_wghts", ")", ")", "\n", "if", "zdim", "==", "1", ":", "\n", "                ", "np", ".", "save", "(", "f\"runs/{flag}_perf_{outlabel}.npy\"", ",", "np", ".", "asarray", "(", "[", "auc_zmean2", ",", "imtafe_zmean2", ",", "auc_zmean2_shift", ",", "imtafe_zmean2_shift", ",", "auc_kl", ",", "imtafe_kl", ",", "auc_zlogvar", ",", "imtafe_zlogvar", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "np", ".", "save", "(", "f\"runs/{flag}_perf_{outlabel}.npy\"", ",", "np", ".", "asarray", "(", "[", "auc_zmean2", ",", "imtafe_zmean2", ",", "auc_zmean2_shift", ",", "imtafe_zmean2_shift", ",", "auc_kl", ",", "imtafe_kl", "]", ")", ")", "\n", "", "np", ".", "save", "(", "f\"runs/{flag}_medians_{outlabel}.npy\"", ",", "np", ".", "asarray", "(", "medians", ")", ")", "\n", "np", ".", "save", "(", "f\"runs/{flag}_kls_{outlabel}.npy\"", ",", "np", ".", "asarray", "(", "klhist", ")", ")", "\n", "# train on data", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.vae-multiD.find_nearest": [[43, 47], ["numpy.asarray", "numpy.abs().argmin", "numpy.abs"], "function", ["None"], ["def", "find_nearest", "(", "array", ",", "value", ")", ":", "\n", "    ", "array", "=", "np", ".", "asarray", "(", "array", ")", "\n", "idx", "=", "(", "np", ".", "abs", "(", "array", "-", "value", ")", ")", ".", "argmin", "(", ")", "\n", "return", "array", "[", "idx", "]", "\n", "# we need a function which will compute and return the AUC and inverse-mistag at 0.5 efficiency", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.vae-multiD.get_perf_stats": [[50, 68], ["sklearn.metrics.roc_auc_score", "sklearn.metrics.roc_curve", "sklearn.metrics.roc_auc_score", "sklearn.metrics.roc_curve", "list().index", "vae-multiD.find_nearest", "list().index", "list", "list", "vae-multiD.find_nearest", "list", "list"], "function", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.find_nearest", "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.find_nearest"], ["", "def", "get_perf_stats", "(", "labels", ",", "measures", ")", ":", "\n", "    ", "global", "activation", "\n", "global", "optimizer", "\n", "auc", "=", "metrics", ".", "roc_auc_score", "(", "labels", ",", "measures", ")", "\n", "fpr", ",", "tpr", ",", "thresholds", "=", "metrics", ".", "roc_curve", "(", "labels", ",", "measures", ")", "\n", "try", ":", "\n", "        ", "imtafe", "=", "1", "/", "fpr", "[", "list", "(", "tpr", ")", ".", "index", "(", "find_nearest", "(", "list", "(", "tpr", ")", ",", "0.5", ")", ")", "]", "\n", "", "except", ":", "\n", "        ", "imtafe", "=", "1", "\n", "", "if", "auc", "<", "0.5", ":", "\n", "        ", "measures", "=", "[", "-", "i", "for", "i", "in", "measures", "]", "\n", "auc", "=", "metrics", ".", "roc_auc_score", "(", "labels", ",", "measures", ")", "\n", "fpr", ",", "tpr", ",", "thresholds", "=", "metrics", ".", "roc_curve", "(", "labels", ",", "measures", ")", "\n", "try", ":", "\n", "            ", "imtafe", "=", "1", "/", "fpr", "[", "list", "(", "tpr", ")", ".", "index", "(", "find_nearest", "(", "list", "(", "tpr", ")", ",", "0.5", ")", ")", "]", "\n", "", "except", ":", "\n", "            ", "imtafe", "=", "1", "\n", "", "", "return", "auc", ",", "imtafe", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.vae-multiD.sampling": [[91, 96], ["tensorflow.keras.backend.random_normal", "tensorflow.keras.backend.exp", "tensorflow.keras.backend.shape"], "function", ["None"], ["@", "tf", ".", "function", "\n", "def", "sampling", "(", "args", ")", ":", "\n", "    ", "z_mean", ",", "z_log_var", "=", "args", "\n", "epsilon", "=", "K", ".", "random_normal", "(", "shape", "=", "(", "K", ".", "shape", "(", "z_mean", ")", "[", "0", "]", ",", "latent_dim", ")", ",", "mean", "=", "0.0", ",", "stddev", "=", "1.0", ")", "\n", "return", "z_mean", "+", "K", ".", "exp", "(", "0.5", "*", "z_log_var", ")", "*", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.ivae-multiD-step2reco.MyEvaluation.__init__": [[115, 118], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.iVAE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "interval", "=", "10", ")", ":", "\n", "        ", "super", "(", "Callback", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "interval", "=", "interval", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.ivae-multiD-step2reco.MyEvaluation.on_epoch_end": [[119, 123], ["wghts.append", "numpy.save", "decoder.get_weights", "numpy.asarray"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "if", "epoch", "%", "self", ".", "interval", "==", "0", ":", "\n", "            ", "wghts", ".", "append", "(", "decoder", ".", "get_weights", "(", ")", ")", "\n", "np", ".", "save", "(", "f\"runs/{flag_dec_only}_wghts_{optimizer}_{datalabel}_{invm_relative_error}_{ii}.npy\"", ",", "np", ".", "asarray", "(", "wghts", ")", ")", "\n", "# train on data", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v1_paper.ivae-multiD-step2reco.sampling": [[80, 89], ["tensorflow.keras.backend.random_normal", "tensorflow.equal", "tensorflow.reduce_sum", "tensorflow.keras.backend.exp", "tensorflow.keras.backend.shape"], "function", ["None"], ["@", "tf", ".", "function", "\n", "def", "sampling", "(", "args", ")", ":", "\n", "    ", "mean", "=", "args", "[", "0", "]", "\n", "logvar", "=", "args", "[", "1", "]", "\n", "epsilon", "=", "K", ".", "random_normal", "(", "shape", "=", "(", "K", ".", "shape", "(", "mean", ")", "[", "0", "]", ",", "latent_dim", ")", ",", "mean", "=", "0.0", ",", "stddev", "=", "1.0", ")", "\n", "if", "tf", ".", "equal", "(", "tf", ".", "reduce_sum", "(", "logvar", ")", ",", "0.0", ")", ":", "\n", "        ", "return", "mean", "\n", "", "else", ":", "\n", "        ", "return", "mean", "+", "K", ".", "exp", "(", "0.5", "*", "logvar", ")", "*", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.Encoder.__init__": [[139, 162], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.BatchNormalization"], "methods", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.iVAE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "latent_dim", ",", "hidden_dims", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_batchnorm", "=", "args", ".", "batchnorm", "\n", "# initialise layers in a loop over hidden_dims", "\n", "# input layer does not need to be initialised", "\n", "self", ".", "dense_hidden_layers", "=", "[", "\n", "Dense", "(", "\n", "hid_dim", ",", "\n", "# set activation from argparse", "\n", "activation", "=", "args", ".", "activation", ",", "\n", "# we can set an initializer if we like", "\n", "#kernel_initializer = tf.keras.initializers.RandomUniform(minval=0.01, maxval=0.1, seed=None),", "\n", "#bias_initializer = tf.keras.initializers.RandomUniform(minval=0.01, maxval=0.1, seed=None)", "\n", ")", "\n", "for", "hid_dim", "in", "hidden_dims", "\n", "]", "\n", "if", "self", ".", "use_batchnorm", ":", "\n", "            ", "self", ".", "batch_norm_layers", "=", "[", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "\n", "for", "hid_dim", "in", "hidden_dims", "]", "\n", "\n", "# initialise two outputs layers for the z_means and z_log_vars", "\n", "", "self", ".", "dense_mean_layer", "=", "Dense", "(", "latent_dim", ")", "\n", "self", ".", "dense_log_var_layer", "=", "Dense", "(", "latent_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.Encoder.sampling": [[163, 176], ["tensorflow.keras.backend.random_normal", "tensorflow.keras.backend.random_normal", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.exp", "tensorflow.exp"], "methods", ["None"], ["", "def", "sampling", "(", "self", ",", "inputs", ",", "is_z", "=", "True", ")", ":", "\n", "        ", "z_mean", ",", "z_log_var", "=", "inputs", "\n", "if", "is_z", ":", "\n", "# normal z sampling using the reparameterization trick", "\n", "            ", "batch", "=", "tf", ".", "shape", "(", "z_mean", ")", "[", "0", "]", "\n", "dim", "=", "tf", ".", "shape", "(", "z_mean", ")", "[", "1", "]", "\n", "epsilon", "=", "tf", ".", "keras", ".", "backend", ".", "random_normal", "(", "shape", "=", "(", "batch", ",", "dim", ")", ")", "\n", "return", "z_mean", "+", "tf", ".", "exp", "(", "0.5", "*", "z_log_var", ")", "*", "epsilon", "\n", "", "else", ":", "\n", "# sample invariant masses with a 10% error", "\n", "            ", "epsilon", "=", "tf", ".", "keras", ".", "backend", ".", "random_normal", "(", "shape", "=", "z_mean", ".", "shape", ")", "\n", "ret", "=", "z_mean", "+", "tf", ".", "exp", "(", "0.5", "*", "z_log_var", ")", "*", "epsilon", "\n", "return", "tf", ".", "reshape", "(", "ret", ",", "(", "ret", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.Encoder.call": [[178, 211], ["enumerate", "ivae.Encoder.dense_mean_layer", "ivae.Encoder.dense_log_var_layer", "ivae.Encoder.sampling", "tensorflow.math.log", "ivae.Encoder.sampling", "hs.append", "hid_lay", "hs.append", "hs.append", "hid_lay", "hid_lay"], "methods", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.Encoder.sampling", "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.Encoder.sampling"], ["", "", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "# hidden layers will be saved in the list hs", "\n", "        ", "normal_inputs", "=", "inputs", "[", "0", "]", "\n", "m_inv_inputs", "=", "inputs", "[", "1", "]", "\n", "hs", "=", "[", "]", "\n", "# we loop through the hidden layers that were initialised in the init method", "\n", "for", "i", ",", "hid_lay", "in", "enumerate", "(", "self", ".", "dense_hidden_layers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "hs", ".", "append", "(", "hid_lay", "(", "normal_inputs", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "use_batchnorm", ":", "# can use batch normalization", "\n", "                    ", "hs", ".", "append", "(", "self", ".", "batch_norm_layers", "[", "i", "-", "1", "]", "(", "hid_lay", "(", "hs", "[", "i", "-", "1", "]", ")", ",", "\n", "training", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "                    ", "hs", ".", "append", "(", "hid_lay", "(", "hs", "[", "i", "-", "1", "]", ")", ")", "\n", "# the output from the hidden layers are saved in the list h", "\n", "", "", "", "if", "self", ".", "use_batchnorm", ":", "\n", "            ", "h", "=", "self", ".", "batch_norm_layers", "[", "-", "1", "]", "(", "hs", "[", "-", "1", "]", ",", "training", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "h", "=", "hs", "[", "-", "1", "]", "\n", "\n", "# the outputs from the hidden layer are then passed to the z_mean and z_log_var layers that were initialised in the init method", "\n", "", "z_mean", "=", "self", ".", "dense_mean_layer", "(", "h", ")", "\n", "z_log_var", "=", "self", ".", "dense_log_var_layer", "(", "h", ")", "\n", "# then from the outputs of these layers the sampling step is performed using the sampling method defined above", "\n", "# z = [ self.sampling((z_mean, z_log_var)) for i in range(args.samples) ]", "\n", "z", "=", "self", ".", "sampling", "(", "(", "z_mean", ",", "z_log_var", ")", ",", "is_z", "=", "True", ")", "\n", "# sample the invariant mass with a 10% error", "\n", "m_inv_mean", "=", "m_inv_inputs", "\n", "m_inv_log_var", "=", "tf", ".", "math", ".", "log", "(", "(", "0.1", "*", "m_inv_mean", ")", "**", "2", ")", "\n", "m_inv_rnd", "=", "self", ".", "sampling", "(", "(", "m_inv_mean", ",", "m_inv_log_var", ")", ",", "is_z", "=", "False", ")", "\n", "# finally, when the encoder is called, it returns the means, variances, and sampled z's + invariant masses calculated for a single batch", "\n", "return", "z_mean", ",", "z_log_var", ",", "z", ",", "m_inv_rnd", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.Decoder.__init__": [[221, 242], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.BatchNormalization"], "methods", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.iVAE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "original_dim", ",", "hidden_dims", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# initialise layers in a loop over hidden_dims", "\n", "self", ".", "use_batchnorm", "=", "args", ".", "batchnorm", "\n", "self", ".", "dense_hidden_layers", "=", "[", "\n", "Dense", "(", "\n", "hid_dim", ",", "\n", "# set activation from argparse", "\n", "activation", "=", "args", ".", "activation", ",", "\n", "# we can set an initializer if we like", "\n", "#kernel_initializer = tf.keras.initializers.RandomUniform(minval=0.01, maxval=0.1, seed=None),", "\n", "#bias_initializer = tf.keras.initializers.RandomUniform(minval=0.01, maxval=0.1, seed=None)", "\n", ")", "\n", "for", "hid_dim", "in", "hidden_dims", "[", ":", ":", "-", "1", "]", "# should flip the hidden layers this time, to be symmetric wrt the encoder", "\n", "\n", "]", "\n", "if", "self", ".", "use_batchnorm", ":", "\n", "            ", "self", ".", "batch_norm_layers", "=", "[", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "\n", "for", "hid_dim", "in", "hidden_dims", "]", "\n", "# the output layer is then defined with the dimension of the inputs", "\n", "", "self", ".", "dense_output", "=", "Dense", "(", "original_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.Decoder.call": [[244, 265], ["enumerate", "ivae.Decoder.dense_output", "hs.append", "hid_lay", "hs.append", "hs.append", "hid_lay", "hid_lay"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "# hidden layers will be saved in the list hs", "\n", "        ", "hs", "=", "[", "]", "\n", "# we loop through the hidden layers that were initialised in the init method", "\n", "for", "i", ",", "hid_lay", "in", "enumerate", "(", "self", ".", "dense_hidden_layers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# hs.append(hid_lay(tf.concat([inputs,tf.transpose(imasses)],axis=1)))", "\n", "                ", "hs", ".", "append", "(", "hid_lay", "(", "inputs", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "use_batchnorm", ":", "\n", "                    ", "hs", ".", "append", "(", "self", ".", "batch_norm_layers", "[", "i", "-", "1", "]", "(", "hid_lay", "(", "hs", "[", "i", "-", "1", "]", ")", ",", "\n", "training", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "                    ", "hs", ".", "append", "(", "hid_lay", "(", "hs", "[", "i", "-", "1", "]", ")", ")", "\n", "# the output from the hidden layers are saved in the list h", "\n", "", "", "", "if", "self", ".", "use_batchnorm", ":", "\n", "            ", "h", "=", "self", ".", "batch_norm_layers", "[", "-", "1", "]", "(", "hs", "[", "-", "1", "]", ",", "training", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "h", "=", "hs", "[", "-", "1", "]", "\n", "# the outputs are simply the numbers on the last layer of the VAE, which are returned by this call method", "\n", "", "return", "self", ".", "dense_output", "(", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.iVAE.__init__": [[274, 281], ["super().__init__", "ivae.Encoder", "ivae.Decoder"], "methods", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.iVAE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "original_dim", ",", "hidden_dims", ",", "latent_dim", ")", ":", "\n", "        ", "super", "(", "iVAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# define the dimension of the data for this VAE", "\n", "self", ".", "original_dim", "=", "original_dim", "\n", "# intialise the encoder and decoder for this VAE", "\n", "self", ".", "encoder", "=", "Encoder", "(", "latent_dim", "=", "latent_dim", ",", "hidden_dims", "=", "hidden_dims", ")", "\n", "self", ".", "decoder", "=", "Decoder", "(", "original_dim", ",", "hidden_dims", "=", "hidden_dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.iVAE.call": [[283, 290], ["ivae.iVAE.encoder", "ivae.iVAE.decoder", "tensorflow.concat"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "# this batch is passed through the encoder by calling the encoder below, returning the means, variances, and sampled z's", "\n", "        ", "z_mean", ",", "z_log_var", ",", "z", ",", "m_inv_rnd", "=", "self", ".", "encoder", "(", "inputs", ")", "\n", "# we pass the sampled z's and invariant masses for the batch to the decoder which returns the ouput data for each element of the batch, which we save as reconstructed", "\n", "reconstructed", "=", "self", ".", "decoder", "(", "tf", ".", "concat", "(", "[", "z", ",", "m_inv_rnd", "]", ",", "1", ")", ")", "\n", "# finally we return reconstructed, i.e. the outputs from the decode for a single batch", "\n", "return", "z_mean", ",", "z_log_var", ",", "[", "reconstructed", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.load_data": [[98, 129], ["sklearn.preprocessing.MaxAbsScaler", "sklearn.preprocessing.MaxAbsScaler", "numpy.load", "numpy.load", "numpy.load", "len", "len", "maxabsScaler_x.fit_transform.astype", "invmasses.astype.astype", "sklearn.preprocessing.MaxAbsScaler.fit_transform", "numpy.asarray", "x_signal.astype.astype", "sklearn.preprocessing.MaxAbsScaler.fit_transform", "invmasses_rescaled.reshape.reshape", "numpy.asarray", "tensorflow.data.Dataset.from_tensor_slices().batch", "tensorflow.data.Dataset.from_tensor_slices().batch", "invmasses.astype.reshape", "tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices", "range", "range"], "function", ["None"], ["def", "load_data", "(", "batch_size", ")", ":", "\n", "# initialise the scaler transforms for the inputs and the invariant masses", "\n", "    ", "maxabsScaler_x", "=", "MaxAbsScaler", "(", ")", "\n", "maxabsScaler_m", "=", "MaxAbsScaler", "(", ")", "\n", "# load the inputs, truth labels, and invariant masses", "\n", "x_train", "=", "np", ".", "load", "(", "args", ".", "data", ")", "\n", "y_train", "=", "np", ".", "load", "(", "args", ".", "labels", ")", "\n", "invmasses", "=", "np", ".", "load", "(", "args", ".", "masses", ")", "\n", "# determine the number of events", "\n", "num_events", "=", "len", "(", "x_train", ")", "\n", "# determine the dimension of the inputs", "\n", "original_dim", "=", "len", "(", "x_train", "[", "0", "]", ")", "\n", "# define input and invariant masses as type 'float32'", "\n", "x_train", "=", "x_train", ".", "astype", "(", "'float32'", ")", "\n", "invmasses", "=", "invmasses", ".", "astype", "(", "'float32'", ")", "\n", "# fit the transformation for the inputs according to maxabs, and apply it to x_train", "\n", "x_train", "=", "maxabsScaler_x", ".", "fit_transform", "(", "x_train", ")", "\n", "# extract signal-only events so we can study these alone", "\n", "x_signal", "=", "np", ".", "asarray", "(", "[", "x_train", "[", "i", "]", "for", "i", "in", "range", "(", "num_events", ")", "if", "y_train", "[", "i", "]", "==", "1", "]", ")", "\n", "x_signal", "=", "x_signal", ".", "astype", "(", "'float32'", ")", "\n", "# re-shape the invariant masses from a 1D vector to an array, so that the maxabs transform can be performed, then perform the transformation as for x_train", "\n", "invmasses_rescaled", "=", "maxabsScaler_m", ".", "fit_transform", "(", "invmasses", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", "\n", "# re-shape the invariant masses back to a 1D vector", "\n", "invmasses_rescaled", "=", "invmasses_rescaled", ".", "reshape", "(", "-", "1", ")", "\n", "invmasses_signal_rescaled", "=", "np", ".", "asarray", "(", "[", "invmasses_rescaled", "[", "i", "]", "for", "i", "in", "range", "(", "num_events", ")", "if", "y_train", "[", "i", "]", "==", "1", "]", ")", "\n", "# now we use tensorflows Dataset module to slice the input data and the invariant mass data into batches for training", "\n", "train_dataset_filtered", "=", "(", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "x_train", ")", ".", "batch", "(", "batch_size", ")", ")", "\n", "invmass_dataset_rescaled_filtered", "=", "(", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "invmasses_rescaled", ")", ".", "batch", "(", "batch_size", ")", ")", "\n", "\n", "# now we return all of the information necessary to plug the data into the VAE", "\n", "return", "num_events", ",", "train_dataset_filtered", ",", "original_dim", ",", "x_train", ",", "y_train", ",", "x_signal", ",", "invmass_dataset_rescaled_filtered", ",", "invmasses_rescaled", ",", "invmasses", ",", "invmasses_signal_rescaled", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.reco_loss_fn": [[311, 324], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "mse_loss_fn", "tensorflow.reduce_mean", "mae_loss_fn", "tensorflow.reduce_mean", "msle_loss_fn", "tensorflow.reduce_mean", "mape_loss_fn", "tensorflow.reduce_mean", "kld_loss_fn", "huber_loss_fn"], "function", ["None"], ["def", "reco_loss_fn", "(", "inputs", ",", "reconstructed", ")", ":", "\n", "    ", "if", "args", ".", "reconstructionloss", "==", "\"mse\"", ":", "\n", "        ", "return", "multireco", "*", "tf", ".", "reduce_mean", "(", "[", "mse_loss_fn", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ")", "\n", "", "elif", "args", ".", "reconstructionloss", "==", "\"mae\"", ":", "\n", "        ", "return", "multireco", "*", "tf", ".", "reduce_mean", "(", "[", "mae_loss_fn", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ")", "\n", "", "elif", "args", ".", "reconstructionloss", "==", "\"msle\"", ":", "\n", "        ", "return", "multireco", "*", "tf", ".", "reduce_mean", "(", "[", "msle_loss_fn", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ")", "\n", "", "elif", "args", ".", "reconstructionloss", "==", "\"mape\"", ":", "\n", "        ", "return", "multireco", "*", "tf", ".", "reduce_mean", "(", "[", "mape_loss_fn", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ")", "\n", "", "elif", "args", ".", "reconstructionloss", "==", "\"kld\"", ":", "\n", "        ", "return", "multireco", "*", "tf", ".", "reduce_mean", "(", "[", "kld_loss_fn", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ")", "\n", "", "elif", "args", ".", "reconstructionloss", "==", "\"huber\"", ":", "\n", "        ", "return", "multireco", "*", "tf", ".", "reduce_mean", "(", "[", "huber_loss_fn", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ")", "\n", "# below we define the function to compute the reconstruction losses for individual events to be used for classification", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.reco_losses_fn": [[325, 338], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "mse_loss_fn_noreduce", "mae_loss_fn_noreduce", "msle_loss_fn_noreduce", "mape_loss_fn_noreduce", "kld_loss_fn_noreduce", "huber_loss_fn_noreduce"], "function", ["None"], ["", "", "def", "reco_losses_fn", "(", "inputs", ",", "reconstructed", ")", ":", "\n", "    ", "if", "args", ".", "reconstructionloss", "==", "\"mse\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "mse_loss_fn_noreduce", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"mae\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "mae_loss_fn_noreduce", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"msle\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "msle_loss_fn_noreduce", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"mape\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "mape_loss_fn_noreduce", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"kld\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "kld_loss_fn_noreduce", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"huber\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "huber_loss_fn_noreduce", "(", "inputs", ",", "ri", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "# below we define the function to compute the reconstruction losses for individual observables to be used for classification", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.reco_losses_obs_fn": [[339, 352], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "mse_loss_fn_noreduce", "mae_loss_fn_noreduce", "msle_loss_fn_noreduce", "mape_loss_fn_noreduce", "kld_loss_fn_noreduce", "huber_loss_fn_noreduce", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.transpose"], "function", ["None"], ["", "", "def", "reco_losses_obs_fn", "(", "inputs", ",", "reconstructed", ")", ":", "\n", "    ", "if", "args", ".", "reconstructionloss", "==", "\"mse\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "mse_loss_fn_noreduce", "(", "np", ".", "transpose", "(", "inputs", ")", ",", "np", ".", "transpose", "(", "ri", ")", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"mae\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "mae_loss_fn_noreduce", "(", "np", ".", "transpose", "(", "inputs", ")", ",", "np", ".", "transpose", "(", "ri", ")", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"msle\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "msle_loss_fn_noreduce", "(", "np", ".", "transpose", "(", "inputs", ")", ",", "np", ".", "transpose", "(", "ri", ")", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"mape\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "mape_loss_fn_noreduce", "(", "np", ".", "transpose", "(", "inputs", ")", ",", "np", ".", "transpose", "(", "ri", ")", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"kld\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "kld_loss_fn_noreduce", "(", "np", ".", "transpose", "(", "inputs", ")", ",", "np", ".", "transpose", "(", "ri", ")", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "", "if", "args", ".", "reconstructionloss", "==", "\"huber\"", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "[", "huber_loss_fn_noreduce", "(", "np", ".", "transpose", "(", "inputs", ")", ",", "np", ".", "transpose", "(", "ri", ")", ")", "for", "ri", "in", "reconstructed", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.kl_loss_fn": [[354, 356], ["tensorflow.reduce_mean", "tensorflow.exp", "tensorflow.square"], "function", ["None"], ["", "", "def", "kl_loss_fn", "(", "zm", ",", "zlv", ")", ":", "\n", "    ", "return", "-", "multikl", "*", "0.5", "*", "tf", ".", "reduce_mean", "(", "zlv", "-", "tf", ".", "square", "(", "zm", ")", "-", "tf", ".", "exp", "(", "zlv", ")", "+", "1", ")", "\n", "# below we define a function to compute the KL loss for individual events to be used for classification", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.kl_losses_fn": [[357, 359], ["tensorflow.reduce_mean", "tensorflow.exp", "tensorflow.square"], "function", ["None"], ["", "def", "kl_losses_fn", "(", "zm", ",", "zlv", ")", ":", "\n", "    ", "return", "-", "multikl", "*", "0.5", "*", "tf", ".", "reduce_mean", "(", "zlv", "-", "tf", ".", "square", "(", "zm", ")", "-", "tf", ".", "exp", "(", "zlv", ")", "+", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.find_nearest": [[367, 371], ["numpy.asarray", "numpy.abs().argmin", "numpy.abs"], "function", ["None"], ["def", "find_nearest", "(", "array", ",", "value", ")", ":", "\n", "    ", "array", "=", "np", ".", "asarray", "(", "array", ")", "\n", "idx", "=", "(", "np", ".", "abs", "(", "array", "-", "value", ")", ")", ".", "argmin", "(", ")", "\n", "return", "array", "[", "idx", "]", "\n", "# we need a function which will compute and return the AUC and inverse-mistag at 0.5 efficiency", "\n"]], "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.get_perf_stats": [[372, 388], ["sklearn.metrics.roc_auc_score", "sklearn.metrics.roc_curve", "sklearn.metrics.roc_auc_score", "sklearn.metrics.roc_curve", "list().index", "ivae.find_nearest", "list().index", "list", "list", "ivae.find_nearest", "list", "list"], "function", ["home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.find_nearest", "home.repos.pwc.inspect_result.alekssmolkovic_BuHuLaSpa.v0_lhco.ivae.find_nearest"], ["", "def", "get_perf_stats", "(", "labels", ",", "measures", ")", ":", "\n", "    ", "auc", "=", "metrics", ".", "roc_auc_score", "(", "labels", ",", "measures", ")", "\n", "fpr", ",", "tpr", ",", "thresholds", "=", "metrics", ".", "roc_curve", "(", "labels", ",", "measures", ")", "\n", "try", ":", "\n", "        ", "imtafe", "=", "1", "/", "fpr", "[", "list", "(", "tpr", ")", ".", "index", "(", "find_nearest", "(", "list", "(", "tpr", ")", ",", "0.5", ")", ")", "]", "\n", "", "except", ":", "\n", "        ", "imtafe", "=", "1", "\n", "", "if", "auc", "<", "0.5", ":", "\n", "        ", "measures", "=", "[", "-", "i", "for", "i", "in", "measures", "]", "\n", "auc", "=", "metrics", ".", "roc_auc_score", "(", "labels", ",", "measures", ")", "\n", "fpr", ",", "tpr", ",", "thresholds", "=", "metrics", ".", "roc_curve", "(", "labels", ",", "measures", ")", "\n", "try", ":", "\n", "            ", "imtafe", "=", "1", "/", "fpr", "[", "list", "(", "tpr", ")", ".", "index", "(", "find_nearest", "(", "list", "(", "tpr", ")", ",", "0.5", ")", ")", "]", "\n", "", "except", ":", "\n", "            ", "imtafe", "=", "1", "\n", "", "", "return", "auc", ",", "imtafe", "\n", "\n"]]}