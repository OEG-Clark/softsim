{"home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.vgg.Vgg16.__init__": [[12, 30], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "range", "torchvision.models.vgg16", "vgg.Vgg16.slice1.add_module", "vgg.Vgg16.slice2.add_module", "vgg.Vgg16.slice3.add_module", "vgg.Vgg16.slice4.add_module", "vgg.Vgg16.parameters", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "super", "(", "Vgg16", ",", "self", ")", ".", "__init__", "(", ")", "\n", "vgg_pretrained_features", "=", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", ".", "features", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice4", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "for", "x", "in", "range", "(", "4", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "4", ",", "9", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "9", ",", "16", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "16", ",", "23", ")", ":", "\n", "            ", "self", ".", "slice4", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.vgg.Vgg16.forward": [[31, 43], ["vgg.Vgg16.slice1", "vgg.Vgg16.slice2", "vgg.Vgg16.slice3", "vgg.Vgg16.slice4", "collections.namedtuple", "collections.namedtuple."], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu1_2", "=", "h", "\n", "h", "=", "self", ".", "slice2", "(", "h", ")", "\n", "h_relu2_2", "=", "h", "\n", "h", "=", "self", ".", "slice3", "(", "h", ")", "\n", "h_relu3_3", "=", "h", "\n", "h", "=", "self", ".", "slice4", "(", "h", ")", "\n", "h_relu4_3", "=", "h", "\n", "vgg_outputs", "=", "namedtuple", "(", "\"VggOutputs\"", ",", "[", "'relu1_2'", ",", "'relu2_2'", ",", "'relu3_3'", ",", "'relu4_3'", "]", ")", "\n", "out", "=", "vgg_outputs", "(", "h_relu1_2", ",", "h_relu2_2", ",", "h_relu3_3", ",", "h_relu4_3", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.InceptionV3.__init__": [[31, 128], ["torch.Module.__init__", "sorted", "max", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.parameters", "inception.fid_inception_v3", "torchvision.models.inception_v3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.fid_inception_v3", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["def", "__init__", "(", "self", ",", "\n", "output_blocks", "=", "[", "DEFAULT_BLOCK_INDEX", "]", ",", "\n", "resize_input", "=", "True", ",", "\n", "normalize_input", "=", "True", ",", "\n", "requires_grad", "=", "False", ",", "\n", "use_fid_inception", "=", "True", ")", ":", "\n", "        ", "\"\"\"Build pretrained InceptionV3\n\n        Parameters\n        ----------\n        output_blocks : list of int\n            Indices of blocks to return features of. Possible values are:\n                - 0: corresponds to output of first max pooling\n                - 1: corresponds to output of second max pooling\n                - 2: corresponds to output which is fed to aux classifier\n                - 3: corresponds to output of final average pooling\n        resize_input : bool\n            If true, bilinearly resizes input to width and height 299 before\n            feeding input to model. As the network without fully connected\n            layers is fully convolutional, it should be able to handle inputs\n            of arbitrary size, so resizing might not be strictly needed\n        normalize_input : bool\n            If true, scales the input from range (0, 1) to the range the\n            pretrained Inception network expects, namely (-1, 1)\n        requires_grad : bool\n            If true, parameters of the model require gradients. Possibly useful\n            for finetuning the network\n        use_fid_inception : bool\n            If true, uses the pretrained Inception model used in Tensorflow's\n            FID implementation. If false, uses the pretrained Inception model\n            available in torchvision. The FID Inception model has different\n            weights and a slightly different structure from torchvision's\n            Inception model. If you want to compute FID scores, you are\n            strongly advised to set this parameter to true to get comparable\n            results.\n        \"\"\"", "\n", "super", "(", "InceptionV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "resize_input", "=", "resize_input", "\n", "self", ".", "normalize_input", "=", "normalize_input", "\n", "self", ".", "output_blocks", "=", "sorted", "(", "output_blocks", ")", "\n", "self", ".", "last_needed_block", "=", "max", "(", "output_blocks", ")", "\n", "\n", "assert", "self", ".", "last_needed_block", "<=", "3", ",", "'Last possible output block index is 3'", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "if", "use_fid_inception", ":", "\n", "            ", "inception", "=", "fid_inception_v3", "(", ")", "\n", "", "else", ":", "\n", "            ", "inception", "=", "models", ".", "inception_v3", "(", "pretrained", "=", "True", ")", "\n", "\n", "# Block 0: input to maxpool1", "\n", "", "block0", "=", "[", "\n", "inception", ".", "Conv2d_1a_3x3", ",", "\n", "inception", ".", "Conv2d_2a_3x3", ",", "\n", "inception", ".", "Conv2d_2b_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block0", ")", ")", "\n", "\n", "# Block 1: maxpool1 to maxpool2", "\n", "if", "self", ".", "last_needed_block", ">=", "1", ":", "\n", "            ", "block1", "=", "[", "\n", "inception", ".", "Conv2d_3b_1x1", ",", "\n", "inception", ".", "Conv2d_4a_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block1", ")", ")", "\n", "\n", "# Block 2: maxpool2 to aux classifier", "\n", "", "if", "self", ".", "last_needed_block", ">=", "2", ":", "\n", "            ", "block2", "=", "[", "\n", "inception", ".", "Mixed_5b", ",", "\n", "inception", ".", "Mixed_5c", ",", "\n", "inception", ".", "Mixed_5d", ",", "\n", "inception", ".", "Mixed_6a", ",", "\n", "inception", ".", "Mixed_6b", ",", "\n", "inception", ".", "Mixed_6c", ",", "\n", "inception", ".", "Mixed_6d", ",", "\n", "inception", ".", "Mixed_6e", ",", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block2", ")", ")", "\n", "\n", "# Block 3: aux classifier to final avgpool", "\n", "", "if", "self", ".", "last_needed_block", ">=", "3", ":", "\n", "            ", "block3", "=", "[", "\n", "inception", ".", "Mixed_7a", ",", "\n", "inception", ".", "Mixed_7b", ",", "\n", "inception", ".", "Mixed_7c", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block3", ")", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.InceptionV3.forward": [[129, 164], ["enumerate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "block", "outp.append"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"Get Inception feature maps\n\n        Parameters\n        ----------\n        inp : torch.autograd.Variable\n            Input tensor of shape Bx3xHxW. Values are expected to be in\n            range (0, 1)\n\n        Returns\n        -------\n        List of torch.autograd.Variable, corresponding to the selected output\n        block, sorted ascending by index\n        \"\"\"", "\n", "outp", "=", "[", "]", "\n", "x", "=", "inp", "\n", "\n", "if", "self", ".", "resize_input", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "\n", "size", "=", "(", "299", ",", "299", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "2", "*", "x", "-", "1", "# Scale from range (0, 1) to range (-1, 1)", "\n", "\n", "", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "if", "idx", "in", "self", ".", "output_blocks", ":", "\n", "                ", "outp", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "idx", "==", "self", ".", "last_needed_block", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "outp", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionA.__init__": [[195, 197], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "pool_features", ")", ":", "\n", "        ", "super", "(", "FIDInceptionA", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "pool_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionA.forward": [[198, 216], ["inception.FIDInceptionA.branch1x1", "inception.FIDInceptionA.branch5x5_1", "inception.FIDInceptionA.branch5x5_2", "inception.FIDInceptionA.branch3x3dbl_1", "inception.FIDInceptionA.branch3x3dbl_2", "inception.FIDInceptionA.branch3x3dbl_3", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionA.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch5x5", "=", "self", ".", "branch5x5_1", "(", "x", ")", "\n", "branch5x5", "=", "self", ".", "branch5x5_2", "(", "branch5x5", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_3", "(", "branch3x3dbl", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch5x5", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionC.__init__": [[220, 222], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "channels_7x7", ")", ":", "\n", "        ", "super", "(", "FIDInceptionC", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "channels_7x7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionC.forward": [[223, 244], ["inception.FIDInceptionC.branch1x1", "inception.FIDInceptionC.branch7x7_1", "inception.FIDInceptionC.branch7x7_2", "inception.FIDInceptionC.branch7x7_3", "inception.FIDInceptionC.branch7x7dbl_1", "inception.FIDInceptionC.branch7x7dbl_2", "inception.FIDInceptionC.branch7x7dbl_3", "inception.FIDInceptionC.branch7x7dbl_4", "inception.FIDInceptionC.branch7x7dbl_5", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionC.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch7x7", "=", "self", ".", "branch7x7_1", "(", "x", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_2", "(", "branch7x7", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_3", "(", "branch7x7", ")", "\n", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_1", "(", "x", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_2", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_3", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_4", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_5", "(", "branch7x7dbl", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch7x7", ",", "branch7x7dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionE_1.__init__": [[248, 250], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FIDInceptionE_1", ",", "self", ")", ".", "__init__", "(", "in_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionE_1.forward": [[251, 277], ["inception.FIDInceptionE_1.branch1x1", "inception.FIDInceptionE_1.branch3x3_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_1.branch3x3dbl_1", "inception.FIDInceptionE_1.branch3x3dbl_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionE_1.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_1.branch3x3_2a", "inception.FIDInceptionE_1.branch3x3_2b", "inception.FIDInceptionE_1.branch3x3dbl_3a", "inception.FIDInceptionE_1.branch3x3dbl_3b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "[", "\n", "self", ".", "branch3x3_2a", "(", "branch3x3", ")", ",", "\n", "self", ".", "branch3x3_2b", "(", "branch3x3", ")", ",", "\n", "]", "\n", "branch3x3", "=", "torch", ".", "cat", "(", "branch3x3", ",", "1", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "[", "\n", "self", ".", "branch3x3dbl_3a", "(", "branch3x3dbl", ")", ",", "\n", "self", ".", "branch3x3dbl_3b", "(", "branch3x3dbl", ")", ",", "\n", "]", "\n", "branch3x3dbl", "=", "torch", ".", "cat", "(", "branch3x3dbl", ",", "1", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionE_2.__init__": [[281, 283], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FIDInceptionE_2", ",", "self", ")", ".", "__init__", "(", "in_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.FIDInceptionE_2.forward": [[284, 311], ["inception.FIDInceptionE_2.branch1x1", "inception.FIDInceptionE_2.branch3x3_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_2.branch3x3dbl_1", "inception.FIDInceptionE_2.branch3x3dbl_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "inception.FIDInceptionE_2.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_2.branch3x3_2a", "inception.FIDInceptionE_2.branch3x3_2b", "inception.FIDInceptionE_2.branch3x3dbl_3a", "inception.FIDInceptionE_2.branch3x3dbl_3b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "[", "\n", "self", ".", "branch3x3_2a", "(", "branch3x3", ")", ",", "\n", "self", ".", "branch3x3_2b", "(", "branch3x3", ")", ",", "\n", "]", "\n", "branch3x3", "=", "torch", ".", "cat", "(", "branch3x3", ",", "1", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "[", "\n", "self", ".", "branch3x3dbl_3a", "(", "branch3x3dbl", ")", ",", "\n", "self", ".", "branch3x3dbl_3b", "(", "branch3x3dbl", ")", ",", "\n", "]", "\n", "branch3x3dbl", "=", "torch", ".", "cat", "(", "branch3x3dbl", ",", "1", ")", "\n", "\n", "# Patch: The FID Inception model uses max pooling instead of average", "\n", "# pooling. This is likely an error in this specific Inception", "\n", "# implementation, as other Inception models use average pooling here", "\n", "# (which matches the description in the paper).", "\n", "branch_pool", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.inception.fid_inception_v3": [[166, 191], ["torchvision.models.inception_v3", "inception.FIDInceptionA", "inception.FIDInceptionA", "inception.FIDInceptionA", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionE_1", "inception.FIDInceptionE_2", "load_state_dict_from_url", "models.inception_v3.load_state_dict"], "function", ["None"], ["", "", "def", "fid_inception_v3", "(", ")", ":", "\n", "    ", "\"\"\"Build pretrained Inception model for FID computation\n\n    The Inception model for FID computation uses a different set of weights\n    and has a slightly different structure than torchvision's Inception.\n\n    This method first constructs torchvision's Inception and then patches the\n    necessary parts that are different in the FID Inception model.\n    \"\"\"", "\n", "inception", "=", "models", ".", "inception_v3", "(", "num_classes", "=", "1008", ",", "\n", "aux_logits", "=", "False", ",", "\n", "pretrained", "=", "False", ")", "\n", "inception", ".", "Mixed_5b", "=", "FIDInceptionA", "(", "192", ",", "pool_features", "=", "32", ")", "\n", "inception", ".", "Mixed_5c", "=", "FIDInceptionA", "(", "256", ",", "pool_features", "=", "64", ")", "\n", "inception", ".", "Mixed_5d", "=", "FIDInceptionA", "(", "288", ",", "pool_features", "=", "64", ")", "\n", "inception", ".", "Mixed_6b", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "128", ")", "\n", "inception", ".", "Mixed_6c", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "inception", ".", "Mixed_6d", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "inception", ".", "Mixed_6e", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "192", ")", "\n", "inception", ".", "Mixed_7b", "=", "FIDInceptionE_1", "(", "1280", ")", "\n", "inception", ".", "Mixed_7c", "=", "FIDInceptionE_2", "(", "2048", ")", "\n", "\n", "state_dict", "=", "load_state_dict_from_url", "(", "FID_WEIGHTS_URL", ",", "progress", "=", "True", ")", "\n", "inception", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "inception", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.get_activations": [[75, 151], ["model.eval", "numpy.empty", "tqdm", "print", "len", "print", "len", "len", "range", "numpy.array", "images.transpose.transpose", "torch.from_numpy().type", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy().reshape", "print", "len", "print", "imageio.imread().astype", "img_lst.append", "batch.cuda.cuda", "model", "torch.nn.functional.adaptive_avg_pool2d", "skimage.color.gray2rgb", "torch.from_numpy", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy", "imageio.imread", "str", "torch.nn.functional.adaptive_avg_pool2d.cpu"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["def", "get_activations", "(", "files", ",", "model", ",", "batch_size", "=", "50", ",", "dims", "=", "2048", ",", "\n", "cuda", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- files       : List of image files paths\n    -- model       : Instance of inception model\n    -- batch_size  : Batch size of images for the model to process at once.\n                     Make sure that the number of samples is a multiple of\n                     the batch size, otherwise some samples are ignored. This\n                     behavior is retained to match the original FID score\n                     implementation.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the number\n                     of calculated batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, dims) that contains the\n       activations of the given tensor when feeding inception with the\n       query tensor.\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "len", "(", "files", ")", "%", "batch_size", "!=", "0", ":", "\n", "        ", "print", "(", "(", "'Warning: number of images is not a multiple of the '", "\n", "'batch size. Some samples are going to be ignored.'", ")", ")", "\n", "", "if", "batch_size", ">", "len", "(", "files", ")", ":", "\n", "        ", "print", "(", "(", "'Warning: batch size is bigger than the data size. '", "\n", "'Setting batch size to data size'", ")", ")", "\n", "batch_size", "=", "len", "(", "files", ")", "\n", "\n", "", "n_batches", "=", "len", "(", "files", ")", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "dims", ")", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "n_batches", ")", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "'\\rPropagating batch %d/%d'", "%", "(", "i", "+", "1", ",", "n_batches", ")", ",", "\n", "end", "=", "''", ",", "flush", "=", "True", ")", "\n", "", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "# images = np.array([imread(str(f)).astype(np.float32)", "\n", "#                    for f in files[start:end]])", "\n", "img_lst", "=", "[", "]", "\n", "for", "f", "in", "files", "[", "start", ":", "end", "]", ":", "\n", "            ", "img", "=", "imageio", ".", "imread", "(", "str", "(", "f", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "if", "img", ".", "ndim", "==", "2", ":", "\n", "                ", "img", "=", "color", ".", "gray2rgb", "(", "img", ")", "\n", "", "assert", "img", ".", "ndim", "==", "3", "\n", "img_lst", ".", "append", "(", "img", ")", "\n", "", "images", "=", "np", ".", "array", "(", "img_lst", ")", "\n", "# print(images.shape)", "\n", "\n", "# Reshape to (n_images, 3, height, width)", "\n", "images", "=", "images", ".", "transpose", "(", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "images", "/=", "255", "\n", "\n", "batch", "=", "torch", ".", "from_numpy", "(", "images", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "if", "cuda", ":", "\n", "            ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "\n", "", "pred", "=", "model", "(", "batch", ")", "[", "0", "]", "\n", "\n", "# If model output is not scalar, apply global spatial average pooling.", "\n", "# This happens if you choose a dimensionality not equal 2048.", "\n", "if", "pred", ".", "shape", "[", "2", "]", "!=", "1", "or", "pred", ".", "shape", "[", "3", "]", "!=", "1", ":", "\n", "            ", "pred", "=", "adaptive_avg_pool2d", "(", "pred", ",", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "' done'", ")", "\n", "\n", "", "return", "pred_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.calculate_frechet_distance": [[153, 208], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "print", "scipy.linalg.sqrtm", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["", "def", "calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n\n    Stable version by Dougal J. Sutherland.\n\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an\n               representative data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an\n               representative data set.\n\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# Product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "        ", "msg", "=", "(", "'fid calculation produces singular product; '", "\n", "'adding %s to diagonal of cov estimates'", ")", "%", "eps", "\n", "print", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# Numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "        ", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "            ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "'Imaginary component {}'", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "return", "(", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "\n", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.calculate_activation_statistics": [[210, 233], ["fid_score.get_activations", "numpy.mean", "numpy.cov"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.get_activations"], ["", "def", "calculate_activation_statistics", "(", "files", ",", "model", ",", "batch_size", "=", "50", ",", "\n", "dims", "=", "2048", ",", "cuda", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculation of the statistics used by the FID.\n    Params:\n    -- files       : List of image files paths\n    -- model       : Instance of inception model\n    -- batch_size  : The images numpy array is split into batches with\n                     batch size batch_size. A reasonable batch size\n                     depends on the hardware.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the\n                     number of calculated batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the inception model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the inception model.\n    \"\"\"", "\n", "act", "=", "get_activations", "(", "files", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ",", "verbose", ")", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score._compute_statistics_of_path": [[235, 247], ["pathlib.Path.endswith", "numpy.load", "np.load.close", "pathlib.Path", "fid_score.calculate_activation_statistics", "list", "list", "pathlib.Path.glob", "pathlib.Path.glob"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.calculate_activation_statistics"], ["", "def", "_compute_statistics_of_path", "(", "path", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", ":", "\n", "    ", "if", "path", ".", "endswith", "(", "'.npz'", ")", ":", "\n", "        ", "f", "=", "np", ".", "load", "(", "path", ")", "\n", "m", ",", "s", "=", "f", "[", "'mu'", "]", "[", ":", "]", ",", "f", "[", "'sigma'", "]", "[", ":", "]", "\n", "f", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "        ", "path", "=", "pathlib", ".", "Path", "(", "path", ")", "\n", "files", "=", "list", "(", "path", ".", "glob", "(", "'*.jpg'", ")", ")", "+", "list", "(", "path", ".", "glob", "(", "'*.png'", ")", ")", "\n", "m", ",", "s", "=", "calculate_activation_statistics", "(", "files", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "\n", "", "return", "m", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.calculate_fid_given_paths": [[249, 289], ["utils.inception.InceptionV3", "fid_score._compute_statistics_of_path", "print", "print", "numpy.load", "numpy.load", "print", "fid_score.calculate_frechet_distance", "utils.inception.InceptionV3.cuda", "print", "fid_score.save_training_set_stat", "os.path.join", "os.path.join", "os.path.exists", "RuntimeError", "os.path.exists", "os.path.exists", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score._compute_statistics_of_path", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.calculate_frechet_distance", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.save_training_set_stat"], ["", "def", "calculate_fid_given_paths", "(", "paths", ",", "batch_size", "=", "1", ",", "cuda", "=", "True", ",", "dims", "=", "2048", ")", ":", "\n", "    ", "\"\"\"Calculates the FID of two paths\n    \n    Args:\n        paths: tuple/list. len = 2. \n        paths[0]: path for generated images.\n        path[1]: path of training set images.\n\n    Return:\n        fid_value. scalar. FID score.\n    \"\"\"", "\n", "for", "p", "in", "paths", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "p", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Invalid path: %s'", "%", "p", ")", "\n", "\n", "", "", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "\n", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", "\n", "if", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# m1, s1:", "\n", "", "m1", ",", "s1", "=", "_compute_statistics_of_path", "(", "paths", "[", "0", "]", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "print", "(", "'m1:'", ",", "m1", ".", "shape", ",", "'s1:'", ",", "s1", ".", "shape", ")", "\n", "\n", "# m2, s2:", "\n", "train_set_path", "=", "paths", "[", "1", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "train_set_path", ",", "'m.npy'", ")", ")", "or", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "train_set_path", ",", "'s.npy'", ")", ")", ":", "\n", "        ", "print", "(", "'Training set stat not saved. Calculating ...'", ")", "\n", "save_training_set_stat", "(", "train_set_path", ")", "\n", "", "print", "(", "'loading training set stat at %s'", "%", "paths", "[", "1", "]", ")", "\n", "m2", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "1", "]", ",", "'m.npy'", ")", ")", "\n", "s2", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "1", "]", ",", "'s.npy'", ")", ")", "\n", "print", "(", "'loaded training set stat at %s'", "%", "paths", "[", "1", "]", ")", "\n", "\n", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "\n", "return", "fid_value", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score.save_training_set_stat": [[290, 299], ["utils.inception.InceptionV3().cuda", "fid_score._compute_statistics_of_path", "print", "numpy.save", "numpy.save", "print", "os.path.join", "os.path.join", "utils.inception.InceptionV3"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.fid_score._compute_statistics_of_path"], ["", "def", "save_training_set_stat", "(", "path", ")", ":", "\n", "    ", "dims", "=", "2048", "\n", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", ".", "cuda", "(", ")", "\n", "m", ",", "s", "=", "_compute_statistics_of_path", "(", "path", ",", "model", ",", "batch_size", "=", "1", ",", "dims", "=", "dims", ",", "cuda", "=", "True", ")", "\n", "print", "(", "'saving training set stat at %s'", "%", "path", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'m.npy'", ")", ",", "m", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'s.npy'", ")", ",", "s", ")", "\n", "print", "(", "'training set stat saved at %s'", "%", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.perceptual.VGGFeature.__init__": [[10, 13], ["torch.Module.__init__", "perceptual.VGGFeature.add_module", "utils.vgg.Vgg16"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "VGGFeature", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'vgg'", ",", "Vgg16", "(", ")", ")", "\n", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.perceptual.VGGFeature.__call__": [[13, 17], ["perceptual.VGGFeature.vgg", "x.clone"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "(", "x", ".", "clone", "(", ")", "+", "1.", ")", "/", "2.", "# [-1,1] -> [0,1]", "\n", "x_vgg", "=", "self", ".", "vgg", "(", "x", ")", "\n", "return", "x_vgg", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.perceptual.gram_matrix": [[18, 24], ["y.size", "y.view", "y.view.transpose", "y.view.bmm"], "function", ["None"], ["", "", "def", "gram_matrix", "(", "y", ")", ":", "\n", "    ", "(", "b", ",", "ch", ",", "h", ",", "w", ")", "=", "y", ".", "size", "(", ")", "\n", "features", "=", "y", ".", "view", "(", "b", ",", "ch", ",", "w", "*", "h", ")", "\n", "features_t", "=", "features", ".", "transpose", "(", "1", ",", "2", ")", "\n", "gram", "=", "features", ".", "bmm", "(", "features_t", ")", "/", "(", "ch", "*", "h", "*", "w", ")", "\n", "return", "gram", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.perceptual.perceptual_loss": [[26, 51], ["enumerate", "zip", "torch.functional.mse_loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "perceptual.gram_matrix", "perceptual.gram_matrix", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.perceptual.gram_matrix", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.perceptual.gram_matrix"], ["", "def", "perceptual_loss", "(", "vgg_features1", ",", "vgg_features2", ",", "beta", "=", "1e5", ",", "layer", "=", "'relu1_2'", ")", ":", "\n", "    ", "'''\n    Calculate perceptual loss based on two vgg features.\n\n    Agrs:\n        vgg_features1, vgg_features2: vgg features. \n\n    Output:\n        loss_perceptual, loss_content, loss_style: scalar Tensor. \n    '''", "\n", "if", "layer", "==", "'relu1_2'", ":", "\n", "        ", "loss_content", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "(", "vgg_features1", ".", "relu1_2", ",", "vgg_features2", ".", "relu1_2", ")", "\n", "", "elif", "layer", "==", "'relu2_2'", ":", "\n", "        ", "loss_content", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "(", "vgg_features1", ".", "relu2_2", ",", "vgg_features2", ".", "relu2_2", ")", "\n", "", "elif", "layer", "==", "'relu3_3'", ":", "\n", "        ", "loss_content", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "(", "vgg_features1", ".", "relu3_3", ",", "vgg_features2", ".", "relu3_3", ")", "\n", "", "loss_style", "=", "0", "\n", "for", "_", ",", "(", "vf_g", ",", "vf_c", ")", "in", "enumerate", "(", "zip", "(", "vgg_features1", ",", "vgg_features2", ")", ")", ":", "\n", "# print('vf_g:', vf_g.size())", "\n", "        ", "gm_g", ",", "gm_c", "=", "gram_matrix", "(", "vf_g", ")", ",", "gram_matrix", "(", "vf_c", ")", "\n", "# print('gm_g:', gm_g.size())", "\n", "loss_style", "+=", "nn", ".", "functional", ".", "mse_loss", "(", "gm_g", ",", "gm_c", ")", "\n", "", "loss_perceptual", "=", "loss_content", "+", "1e5", "*", "loss_style", "\n", "\n", "return", "loss_perceptual", ",", "loss_content", ",", "loss_style", "\n", "", ""]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.__init__": [[15, 17], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.reset": [[18, 21], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "values", "=", "[", "]", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append": [[22, 25], ["utils.AverageMeter.values.append"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["", "def", "append", "(", "self", ",", "val", ")", ":", "\n", "\t\t", "self", ".", "values", ".", "append", "(", "val", ")", "\n", "self", ".", "counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.val": [[26, 29], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "val", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "values", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.avg": [[30, 33], ["sum", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "\t\t", "return", "sum", "(", "self", ".", "values", ")", "/", "len", "(", "self", ".", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.last_avg": [[34, 42], ["sum"], "methods", ["None"], ["", "@", "property", "\n", "def", "last_avg", "(", "self", ")", ":", "\n", "\t\t", "if", "self", ".", "counter", "==", "0", ":", "\n", "\t\t\t", "return", "self", ".", "latest_avg", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "latest_avg", "=", "sum", "(", "self", ".", "values", "[", "-", "self", ".", "counter", ":", "]", ")", "/", "self", ".", "counter", "\n", "self", ".", "counter", "=", "0", "\n", "return", "self", ".", "latest_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.ReplayBuffer.__init__": [[159, 163], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_size", "=", "50", ")", ":", "\n", "\t\t", "assert", "(", "max_size", ">", "0", ")", ",", "'Empty buffer or trying to create a black hole. Be careful.'", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.ReplayBuffer.push_and_pop": [[164, 179], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "utils.ReplayBuffer.data.append", "to_return.append", "random.uniform", "random.randint", "to_return.append", "to_return.append", "utils.ReplayBuffer.data[].clone"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append", "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["", "def", "push_and_pop", "(", "self", ",", "data", ")", ":", "\n", "\t\t", "to_return", "=", "[", "]", "\n", "for", "element", "in", "data", ".", "data", ":", "\n", "\t\t\t", "element", "=", "torch", ".", "unsqueeze", "(", "element", ",", "0", ")", "\n", "if", "len", "(", "self", ".", "data", ")", "<", "self", ".", "max_size", ":", "\n", "\t\t\t\t", "self", ".", "data", ".", "append", "(", "element", ")", "\n", "to_return", ".", "append", "(", "element", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "if", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "\t\t\t\t\t", "i", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "max_size", "-", "1", ")", "\n", "to_return", ".", "append", "(", "self", ".", "data", "[", "i", "]", ".", "clone", "(", ")", ")", "\n", "self", ".", "data", "[", "i", "]", "=", "element", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "to_return", ".", "append", "(", "element", ")", "\n", "", "", "", "return", "Variable", "(", "torch", ".", "cat", "(", "to_return", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.LambdaLR.__init__": [[181, 186], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "n_epochs", ",", "offset", ",", "decay_start_epoch", ")", ":", "\n", "\t\t", "assert", "(", "(", "n_epochs", "-", "decay_start_epoch", ")", ">", "0", ")", ",", "\"Decay must start before the training session ends!\"", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "offset", "=", "offset", "\n", "self", ".", "decay_start_epoch", "=", "decay_start_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.LambdaLR.step": [[187, 189], ["max"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "epoch", ")", ":", "\n", "\t\t", "return", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "self", ".", "offset", "-", "self", ".", "decay_start_epoch", ")", "/", "(", "self", ".", "n_epochs", "-", "self", ".", "decay_start_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.save_ckpt": [[44, 67], ["torch.save", "torch.save", "netG.state_dict", "netD.state_dict", "optimizer_G.state_dict", "optimizer_D.state_dict", "optimizer_gamma.state_dict", "lr_scheduler_G.state_dict", "lr_scheduler_D.state_dict", "lr_scheduler_gamma.state_dict"], "function", ["None"], ["", "", "", "def", "save_ckpt", "(", "epoch", ",", "netG", ",", "netD", ",", "\n", "optimizer_G", ",", "optimizer_D", ",", "optimizer_gamma", ",", "\n", "lr_scheduler_G", ",", "lr_scheduler_D", ",", "lr_scheduler_gamma", ",", "\n", "loss_G_lst", ",", "loss_G_perceptual_lst", ",", "loss_G_GAN_lst", ",", "loss_D_lst", ",", "channel_number_lst", ",", "\n", "path", ")", ":", "\n", "\n", "\t", "ckpt", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'netG'", ":", "netG", ".", "state_dict", "(", ")", ",", "\n", "'netD'", ":", "netD", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_G'", ":", "optimizer_G", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_D'", ":", "optimizer_D", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_gamma'", ":", "optimizer_gamma", ".", "state_dict", "(", ")", ",", "\n", "'lr_scheduler_G'", ":", "lr_scheduler_G", ".", "state_dict", "(", ")", ",", "\n", "'lr_scheduler_D'", ":", "lr_scheduler_D", ".", "state_dict", "(", ")", ",", "\n", "'lr_scheduler_gamma'", ":", "lr_scheduler_gamma", ".", "state_dict", "(", ")", ",", "\n", "'loss_G_lst'", ":", "loss_G_lst", ",", "\n", "'loss_G_perceptual_lst'", ":", "loss_G_perceptual_lst", ",", "\n", "'loss_G_GAN_lst'", ":", "loss_G_GAN_lst", ",", "\n", "'loss_D_lst'", ":", "loss_D_lst", ",", "\n", "'channel_number_lst'", ":", "channel_number_lst", ",", "\n", "}", "\n", "torch", ".", "save", "(", "ckpt", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.load_ckpt": [[68, 95], ["print", "torch.load", "torch.load", "netG.load_state_dict", "netD.load_state_dict", "optimizer_G.load_state_dict", "optimizer_D.load_state_dict", "optimizer_gamma.load_state_dict", "lr_scheduler_G.load_state_dict", "lr_scheduler_D.load_state_dict", "lr_scheduler_gamma.load_state_dict", "os.path.isfile", "Exception"], "function", ["None"], ["", "def", "load_ckpt", "(", "netG", ",", "netD", ",", "\n", "optimizer_G", ",", "optimizer_D", ",", "optimizer_gamma", ",", "\n", "lr_scheduler_G", ",", "lr_scheduler_D", ",", "lr_scheduler_gamma", ",", "path", ")", ":", "\n", "\n", "\t", "if", "not", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "\t\t", "raise", "Exception", "(", "'No such file: %s'", "%", "path", ")", "\n", "", "print", "(", "\"===>>> loading checkpoint from %s\"", "%", "path", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "path", ")", "\n", "\n", "epoch", "=", "ckpt", "[", "'epoch'", "]", "\n", "loss_G_lst", "=", "ckpt", "[", "'loss_G_lst'", "]", "\n", "loss_G_perceptual_lst", "=", "ckpt", "[", "'loss_G_perceptual_lst'", "]", "\n", "loss_G_GAN_lst", "=", "ckpt", "[", "'loss_G_GAN_lst'", "]", "\n", "loss_D_lst", "=", "ckpt", "[", "'loss_D_lst'", "]", "\n", "channel_number_lst", "=", "ckpt", "[", "'channel_number_lst'", "]", "\n", "# best_FID = ckpt['best_FID']", "\n", "\n", "netG", ".", "load_state_dict", "(", "ckpt", "[", "'netG'", "]", ")", "\n", "netD", ".", "load_state_dict", "(", "ckpt", "[", "'netD'", "]", ")", "\n", "optimizer_G", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer_G'", "]", ")", "\n", "optimizer_D", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer_D'", "]", ")", "\n", "optimizer_gamma", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer_gamma'", "]", ")", "\n", "lr_scheduler_G", ".", "load_state_dict", "(", "ckpt", "[", "'lr_scheduler_G'", "]", ")", "\n", "lr_scheduler_D", ".", "load_state_dict", "(", "ckpt", "[", "'lr_scheduler_D'", "]", ")", "\n", "lr_scheduler_gamma", ".", "load_state_dict", "(", "ckpt", "[", "'lr_scheduler_gamma'", "]", ")", "\n", "\n", "return", "epoch", ",", "loss_G_lst", ",", "loss_G_perceptual_lst", ",", "loss_G_GAN_lst", ",", "loss_D_lst", ",", "channel_number_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.save_ckpt_finetune": [[96, 118], ["torch.save", "torch.save", "netG.state_dict", "netD.state_dict", "optimizer_G.state_dict", "optimizer_D.state_dict", "lr_scheduler_G.state_dict", "lr_scheduler_D.state_dict"], "function", ["None"], ["", "def", "save_ckpt_finetune", "(", "epoch", ",", "netG", ",", "netD", ",", "\n", "optimizer_G", ",", "optimizer_D", ",", "\n", "lr_scheduler_G", ",", "lr_scheduler_D", ",", "\n", "loss_G_lst", ",", "loss_G_perceptual_lst", ",", "loss_G_GAN_lst", ",", "loss_D_lst", ",", "\n", "best_FID", ",", "\n", "path", ")", ":", "\n", "\n", "\t", "ckpt", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'netG'", ":", "netG", ".", "state_dict", "(", ")", ",", "\n", "'netD'", ":", "netD", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_G'", ":", "optimizer_G", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_D'", ":", "optimizer_D", ".", "state_dict", "(", ")", ",", "\n", "'lr_scheduler_G'", ":", "lr_scheduler_G", ".", "state_dict", "(", ")", ",", "\n", "'lr_scheduler_D'", ":", "lr_scheduler_D", ".", "state_dict", "(", ")", ",", "\n", "'loss_G_lst'", ":", "loss_G_lst", ",", "\n", "'loss_G_perceptual_lst'", ":", "loss_G_perceptual_lst", ",", "\n", "'loss_G_GAN_lst'", ":", "loss_G_GAN_lst", ",", "\n", "'loss_D_lst'", ":", "loss_D_lst", ",", "\n", "'best_FID'", ":", "best_FID", ",", "\n", "}", "\n", "torch", ".", "save", "(", "ckpt", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.load_ckpt_finetune": [[119, 145], ["print", "torch.load", "torch.load", "netG.load_state_dict", "netD.load_state_dict", "optimizer_G.load_state_dict", "optimizer_D.load_state_dict", "lr_scheduler_G.load_state_dict", "lr_scheduler_D.load_state_dict", "os.path.isfile", "Exception"], "function", ["None"], ["", "def", "load_ckpt_finetune", "(", "netG", ",", "netD", ",", "\n", "optimizer_G", ",", "optimizer_D", ",", "\n", "lr_scheduler_G", ",", "lr_scheduler_D", ",", "\n", "path", ")", ":", "\n", "\n", "\t", "if", "not", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "\t\t", "raise", "Exception", "(", "'No such file: %s'", "%", "path", ")", "\n", "", "print", "(", "\"===>>> loading checkpoint from %s\"", "%", "path", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "path", ")", "\n", "epoch", "=", "ckpt", "[", "'epoch'", "]", "\n", "loss_G_lst", "=", "ckpt", "[", "'loss_G_lst'", "]", "\n", "loss_G_perceptual_lst", "=", "ckpt", "[", "'loss_G_perceptual_lst'", "]", "\n", "loss_G_GAN_lst", "=", "ckpt", "[", "'loss_G_GAN_lst'", "]", "\n", "loss_D_lst", "=", "ckpt", "[", "'loss_D_lst'", "]", "\n", "\n", "best_FID", "=", "ckpt", "[", "'best_FID'", "]", "\n", "\n", "netG", ".", "load_state_dict", "(", "ckpt", "[", "'netG'", "]", ")", "\n", "netD", ".", "load_state_dict", "(", "ckpt", "[", "'netD'", "]", ")", "\n", "\n", "optimizer_G", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer_G'", "]", ")", "\n", "optimizer_D", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer_D'", "]", ")", "\n", "\n", "lr_scheduler_G", ".", "load_state_dict", "(", "ckpt", "[", "'lr_scheduler_G'", "]", ")", "\n", "lr_scheduler_D", ".", "load_state_dict", "(", "ckpt", "[", "'lr_scheduler_D'", "]", ")", "\n", "return", "epoch", ",", "loss_G_lst", ",", "loss_G_perceptual_lst", ",", "loss_G_GAN_lst", ",", "loss_D_lst", ",", "best_FID", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.tensor2image": [[147, 152], ["np.tile.astype", "numpy.tile", "tensor[].cpu().float().numpy", "tensor[].cpu().float", "tensor[].cpu"], "function", ["None"], ["", "def", "tensor2image", "(", "tensor", ")", ":", "\n", "\t", "image", "=", "127.5", "*", "(", "tensor", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "+", "1.0", ")", "\n", "if", "image", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "\t\t", "image", "=", "np", ".", "tile", "(", "image", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "", "return", "image", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.weights_init_normal": [[190, 198], ["classname.find", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "classname.find", "torch.nn.init.normal", "torch.nn.init.normal", "torch.nn.init.constant", "torch.nn.init.constant"], "function", ["None"], ["", "", "def", "weights_init_normal", "(", "m", ")", ":", "\n", "\t", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", ":", "\n", "# torch.nn.init.normal(m.weight.data, 0.0, 0.02)", "\n", "\t\t", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "\n", "\t\t", "torch", ".", "nn", ".", "init", ".", "normal", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "0.02", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.soft_threshold": [[200, 209], ["torch.no_grad", "torch.no_grad", "torch.abs", "torch.abs", "torch.sign", "torch.sign", "torch.functional.relu"], "function", ["None"], ["", "", "def", "soft_threshold", "(", "w", ",", "th", ")", ":", "\n", "\t", "'''\n\tpytorch soft-sign function\n\t'''", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t", "temp", "=", "torch", ".", "abs", "(", "w", ")", "-", "th", "\n", "# print('th:', th)", "\n", "# print('temp:', temp.size())", "\n", "return", "torch", ".", "sign", "(", "w", ")", "*", "nn", ".", "functional", ".", "relu", "(", "temp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.get_feature_hook": [[213, 223], ["_output.size", "_output.size"], "function", ["None"], ["def", "get_feature_hook", "(", "self", ",", "_input", ",", "_output", ")", ":", "\n", "\t", "global", "count_ops", ",", "num_ids", "\n", "# print('------>>>>>>')", "\n", "# print('{}th node, input shape: {}, output shape: {}, input channel: {}, output channel {}'.format(", "\n", "# \tnum_ids, _input[0].size(2), _output.size(2), _input[0].size(1), _output.size(1)))", "\n", "# print(self)", "\n", "delta_ops", "=", "self", ".", "in_channels", "*", "self", ".", "out_channels", "*", "self", ".", "kernel_size", "[", "0", "]", "*", "self", ".", "kernel_size", "[", "1", "]", "*", "_output", ".", "size", "(", "2", ")", "*", "_output", ".", "size", "(", "3", ")", "/", "self", ".", "groups", "\n", "count_ops", "+=", "delta_ops", "\n", "# print('ops is {:.6f}M'.format(delta_ops / 1024.  /1024.))", "\n", "num_ids", "+=", "1", "\n", "# print('')", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.measure_model": [[225, 240], ["torch.randn", "torch.randn", "net.named_modules", "net", "print", "isinstance", "isinstance", "hooks.append", "module[].register_forward_hook"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["", "def", "measure_model", "(", "net", ",", "H_in", ",", "W_in", ")", ":", "\n", "\t", "import", "torch", "\n", "import", "torch", ".", "nn", "as", "nn", "\n", "_input", "=", "torch", ".", "randn", "(", "(", "1", ",", "3", ",", "H_in", ",", "W_in", ")", ")", "\n", "#_input, net = _input.cpu(), net.cpu()", "\n", "hooks", "=", "[", "]", "\n", "for", "module", "in", "net", ".", "named_modules", "(", ")", ":", "\n", "\t\t", "if", "isinstance", "(", "module", "[", "1", "]", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "module", "[", "1", "]", ",", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "# print(module)", "\n", "\t\t\t", "hooks", ".", "append", "(", "module", "[", "1", "]", ".", "register_forward_hook", "(", "get_feature_hook", ")", ")", "\n", "\n", "", "", "_out", "=", "net", "(", "_input", ")", "\n", "global", "count_ops", "\n", "print", "(", "'count_ops: {:.6f}M'", ".", "format", "(", "count_ops", "/", "1024.", "/", "1024.", ")", ")", "# in Million", "\n", "return", "count_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.show_sparsity": [[242, 268], ["model.modules", "numpy.concatenate", "print", "matplotlib.hist", "matplotlib.savefig", "matplotlib.close", "print", "model.load_state_dict", "numpy.sum", "numpy.mean", "os.path.exists", "Exception", "torch.load", "torch.load", "isinstance", "m.weight.data.cpu().numpy().squeeze", "scaler_list.append", "numpy.abs", "m.weight.data.cpu().numpy", "m.weight.data.cpu"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["", "def", "show_sparsity", "(", "model", ",", "save_name", ",", "model_path", "=", "None", ")", ":", "\n", "# load model if necessary:", "\n", "\t", "if", "model_path", "is", "not", "None", ":", "\n", "\t\t", "if", "not", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "\t\t\t", "raise", "Exception", "(", "\"G model path doesn't exist at %s!\"", "%", "model_path", ")", "\n", "", "print", "(", "'Loading generator from %s'", "%", "model_path", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "\n", "# get all scaler parameters form the network:", "\n", "", "scaler_list", "=", "[", "]", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "\t\t", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "InstanceNorm2d", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "\t\t\t", "m_cpu", "=", "m", ".", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "squeeze", "(", ")", "\n", "# print('m_cpu:', type(m_cpu), m_cpu.shape)", "\n", "scaler_list", ".", "append", "(", "m_cpu", ")", "\n", "", "", "all_scaler", "=", "np", ".", "concatenate", "(", "scaler_list", ",", "axis", "=", "0", ")", "\n", "print", "(", "'all_scaler:'", ",", "all_scaler", ".", "shape", ",", "'L0 (sum):'", ",", "np", ".", "sum", "(", "all_scaler", "!=", "0", ")", ",", "'L1 (mean):'", ",", "np", ".", "mean", "(", "np", ".", "abs", "(", "all_scaler", ")", ")", ")", "\n", "\n", "# save npy and plt png:", "\n", "# np.save(save_name + '.npy', all_scaler)", "\n", "n", ",", "bins", ",", "patches", "=", "plt", ".", "hist", "(", "all_scaler", ",", "50", ")", "\n", "# print(n)", "\n", "plt", ".", "savefig", "(", "save_name", "+", "'.png'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "return", "all_scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.none_zero_channel_num": [[269, 289], ["model.modules", "numpy.concatenate", "numpy.sum", "print", "print", "model.load_state_dict", "numpy.mean", "os.path.exists", "Exception", "torch.load", "torch.load", "isinstance", "m.weight.data.cpu().numpy().squeeze", "scaler_list.append", "numpy.abs", "m.weight.data.cpu().numpy", "m.weight.data.cpu"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.AverageMeter.append"], ["", "def", "none_zero_channel_num", "(", "model", ",", "model_path", "=", "None", ")", ":", "\n", "# load model if necessary:", "\n", "\t", "if", "model_path", "is", "not", "None", ":", "\n", "\t\t", "if", "not", "os", ".", "path", ".", "exists", "(", "model_path", ")", ":", "\n", "\t\t\t", "raise", "Exception", "(", "\"G model path doesn't exist at %s!\"", "%", "model_path", ")", "\n", "", "print", "(", "'Loading generator from %s'", "%", "model_path", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "\n", "# get all scaler parameters form the network:", "\n", "", "scaler_list", "=", "[", "]", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "\t\t", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "InstanceNorm2d", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "\t\t\t", "m_cpu", "=", "m", ".", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "squeeze", "(", ")", "\n", "# print('m_cpu:', type(m_cpu), m_cpu.shape)", "\n", "scaler_list", ".", "append", "(", "m_cpu", ")", "\n", "", "", "all_scaler", "=", "np", ".", "concatenate", "(", "scaler_list", ",", "axis", "=", "0", ")", "\n", "l0norm", "=", "np", ".", "sum", "(", "all_scaler", "!=", "0", ")", "\n", "print", "(", "'all_scaler:'", ",", "all_scaler", ".", "shape", ",", "'L0 (sum):'", ",", "l0norm", ",", "'L1 (mean):'", ",", "np", ".", "mean", "(", "np", ".", "abs", "(", "all_scaler", ")", ")", ")", "\n", "\n", "return", "l0norm", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.create_dir": [[291, 294], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "create_dir", "(", "_path", ")", ":", "\n", "\t", "if", "not", "os", ".", "path", ".", "exists", "(", "_path", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.fourD2threeD": [[295, 312], ["numpy.split", "enumerate", "numpy.concatenate", "numpy.split", "numpy.concatenate", "img.squeeze"], "function", ["None"], ["", "", "def", "fourD2threeD", "(", "batch", ",", "n_row", "=", "10", ")", ":", "\n", "\t", "'''\n\tConvert a batch of images (N,W,H,C) to a single big image (W*n, H*m, C)\n\tInput:\n\t\tbatch: type=ndarray, shape=(N,W,H,C)\n\tReturn:\n\t\trows: type=ndarray, shape=(W*n, H*m, C)\n\t'''", "\n", "N", "=", "batch", ".", "shape", "[", "0", "]", "\n", "img_list", "=", "np", ".", "split", "(", "batch", ",", "N", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "img_list", ")", ":", "\n", "\t\t", "img_list", "[", "i", "]", "=", "img", ".", "squeeze", "(", "axis", "=", "0", ")", "\n", "", "one_row", "=", "np", ".", "concatenate", "(", "img_list", ",", "axis", "=", "1", ")", "\n", "# print('one_row:', one_row.shape)", "\n", "row_list", "=", "np", ".", "split", "(", "one_row", ",", "n_row", ",", "axis", "=", "1", ")", "\n", "rows", "=", "np", ".", "concatenate", "(", "row_list", ",", "axis", "=", "0", ")", "\n", "return", "rows", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.layer_param_num": [[315, 324], ["model.named_parameters", "torch.flatten", "torch.flatten", "W.dim", "torch.flatten.dim", "name.strip().split", "name.strip().split", "name.strip", "name.strip"], "function", ["None"], ["", "def", "layer_param_num", "(", "model", ",", "param_name", "=", "[", "'weight'", "]", ")", ":", "\n", "\t", "count_res", "=", "{", "}", "\n", "for", "name", ",", "W", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "\t\t", "if", "name", ".", "strip", "(", ")", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "in", "param_name", "and", "name", ".", "strip", "(", ")", ".", "split", "(", "\".\"", ")", "[", "-", "2", "]", "[", ":", "2", "]", "!=", "\"bn\"", "and", "W", ".", "dim", "(", ")", ">", "1", ":", "\n", "# W_nz = torch.nonzero(W.data)", "\n", "\t\t\t", "W_nz", "=", "torch", ".", "flatten", "(", "W", ".", "data", ")", "\n", "if", "W_nz", ".", "dim", "(", ")", ">", "0", ":", "\n", "\t\t\t\t", "count_res", "[", "name", "]", "=", "W_nz", ".", "shape", "[", "0", "]", "\n", "", "", "", "return", "count_res", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.model_param_num": [[326, 332], ["utils.layer_param_num", "sum", "layer_param_num.values"], "function", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.utils.utils.layer_param_num"], ["", "def", "model_param_num", "(", "model", ",", "param_name", "=", "[", "'weight'", "]", ")", ":", "\n", "\t", "'''\n\tFind parameter numbers in the model. in Million.\n\t'''", "\n", "layer_size_dict", "=", "layer_param_num", "(", "model", ",", "param_name", ")", "\n", "return", "sum", "(", "layer_size_dict", ".", "values", "(", ")", ")", "/", "1024", "/", "1024", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.datasets.datasets.ImageDataset.__init__": [[10, 20], ["torchvision.Compose", "sorted", "print", "glob.glob", "len", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset_dir", ",", "transforms_", "=", "None", ")", ":", "\n", "        ", "'''\n        Construct a dataset with all images from a dir.\n\n        dataset_dir: str. img folder path\n        '''", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "transforms_", ")", "\n", "\n", "self", ".", "files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ")", "+", "'/*.jpg'", ")", ")", "\n", "print", "(", "'files:'", ",", "len", "(", "self", ".", "files", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.datasets.datasets.ImageDataset.__getitem__": [[21, 27], ["PIL.Image.open", "img.convert.convert.convert", "datasets.ImageDataset.transform", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "self", ".", "files", "[", "index", "%", "len", "(", "self", ".", "files", ")", "]", ")", "\n", "img", "=", "img", ".", "convert", "(", "\"RGB\"", ")", "\n", "item", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.datasets.datasets.ImageDataset.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.datasets.datasets.PairedImageDataset.__init__": [[33, 55], ["torchvision.Compose", "print", "print", "os.path.join", "os.path.join", "sorted", "sorted", "os.path.join", "os.path.join", "sorted", "sorted", "len", "len", "len", "len", "glob.glob", "glob.glob", "glob.glob", "glob.glob"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset_dir", ",", "soft_data_dir", ",", "mode", "=", "'A2B'", ",", "transforms_", "=", "None", ")", ":", "\n", "        ", "'''\n        Construct a dataset with all images from a dir.\n\n        dataset: str. dataset name\n        style: str. 'A2B' or 'B2A'\n        '''", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "transforms_", ")", "\n", "\n", "if", "mode", "in", "[", "'A2B'", "]", ":", "\n", "            ", "path_A", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'train'", ",", "'A'", ")", "\n", "path_B", "=", "os", ".", "path", ".", "join", "(", "soft_data_dir", ",", "'B'", ")", "\n", "self", ".", "files_A", "=", "sorted", "(", "glob", ".", "glob", "(", "path_A", "+", "'/*.jpg'", ")", ")", "\n", "self", ".", "files_B", "=", "sorted", "(", "glob", ".", "glob", "(", "path_B", "+", "'/*.png'", ")", ")", "\n", "", "else", ":", "\n", "            ", "path_A", "=", "os", ".", "path", ".", "join", "(", "soft_data_dir", ",", "'A'", ")", "\n", "path_B", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'train'", ",", "'B'", ")", "\n", "self", ".", "files_A", "=", "sorted", "(", "glob", ".", "glob", "(", "path_A", "+", "'/*.png'", ")", ")", "\n", "self", ".", "files_B", "=", "sorted", "(", "glob", ".", "glob", "(", "path_B", "+", "'/*.jpg'", ")", ")", "\n", "", "print", "(", "'files_A:'", ",", "len", "(", "self", ".", "files_A", ")", ")", "\n", "print", "(", "'files_B:'", ",", "len", "(", "self", ".", "files_B", ")", ")", "\n", "assert", "len", "(", "self", ".", "files_A", ")", "==", "len", "(", "self", ".", "files_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.datasets.datasets.PairedImageDataset.__getitem__": [[56, 71], ["PIL.Image.open", "PIL.Image.fromarray.convert", "numpy.asarray", "numpy.flip", "PIL.Image.fromarray", "datasets.PairedImageDataset.transform", "PIL.Image.open", "PIL.Image.fromarray.convert", "numpy.asarray", "numpy.flip", "PIL.Image.fromarray", "datasets.PairedImageDataset.transform", "numpy.uint8", "numpy.uint8", "len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_A", "=", "Image", ".", "open", "(", "self", ".", "files_A", "[", "index", "%", "len", "(", "self", ".", "files_A", ")", "]", ")", "\n", "img_A", "=", "img_A", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_A", "=", "np", ".", "asarray", "(", "img_A", ")", "# PIL.Image to np.ndarray", "\n", "img_A", "=", "np", ".", "flip", "(", "img_A", ",", "axis", "=", "1", ")", "# data augumentation: horrizental flip", "\n", "img_A", "=", "Image", ".", "fromarray", "(", "np", ".", "uint8", "(", "img_A", ")", ")", "# np.ndarray to PIL.Image", "\n", "item_A", "=", "self", ".", "transform", "(", "img_A", ")", "\n", "\n", "img_B", "=", "Image", ".", "open", "(", "self", ".", "files_B", "[", "index", "%", "len", "(", "self", ".", "files_B", ")", "]", ")", "\n", "img_B", "=", "img_B", ".", "convert", "(", "\"RGB\"", ")", "\n", "img_B", "=", "np", ".", "asarray", "(", "img_B", ")", "# PIL.Image to np.ndarray", "\n", "img_B", "=", "np", ".", "flip", "(", "img_B", ",", "axis", "=", "1", ")", "# data augumentation: horrizental flip", "\n", "img_B", "=", "Image", ".", "fromarray", "(", "np", ".", "uint8", "(", "img_B", ")", ")", "# np.ndarray to PIL.Image", "\n", "item_B", "=", "self", ".", "transform", "(", "img_B", ")", "\n", "return", "{", "'A'", ":", "item_A", ",", "'B'", ":", "item_B", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.datasets.datasets.PairedImageDataset.__len__": [[72, 74], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files_A", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.LinQuantSteOp.forward": [[17, 29], ["input.div().round_().mul_", "input.div().round_", "input.div"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "signed", ",", "nbits", ",", "max_val", ")", ":", "\n", "        ", "\"\"\"\n        In the forward pass we apply the quantizer\n        \"\"\"", "\n", "assert", "max_val", ">", "0", "\n", "if", "signed", ":", "\n", "            ", "int_max", "=", "2", "**", "(", "nbits", "-", "1", ")", "-", "1", "\n", "", "else", ":", "\n", "            ", "int_max", "=", "2", "**", "nbits", "\n", "", "scale", "=", "max_val", "/", "int_max", "\n", "return", "input", ".", "div", "(", "scale", ")", ".", "round_", "(", ")", ".", "mul_", "(", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.LinQuantSteOp.backward": [[31, 39], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "\"\"\"\n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n        \"\"\"", "\n", "return", "grad_output", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Conv2dQuant.__init__": [[44, 54], ["torch.Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "padding_mode", "=", "'zeros'", ")", ":", "\n", "        ", "super", "(", "Conv2dQuant", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "dilation", ",", "groups", ",", "\n", "bias", ",", "padding_mode", ")", "\n", "self", ".", "nbits", "=", "_NBITS", "\n", "self", ".", "input_signed", "=", "False", "\n", "self", ".", "input_quant", "=", "True", "\n", "self", ".", "input_max", "=", "_ACTMAX", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Conv2dQuant.conv2d_forward": [[55, 64], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.pad", "torch.pad", "torch.pad", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["None"], ["", "def", "conv2d_forward", "(", "self", ",", "input", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "padding_mode", "==", "'circular'", ":", "\n", "            ", "expanded_padding", "=", "(", "(", "self", ".", "padding", "[", "1", "]", "+", "1", ")", "//", "2", ",", "self", ".", "padding", "[", "1", "]", "//", "2", ",", "\n", "(", "self", ".", "padding", "[", "0", "]", "+", "1", ")", "//", "2", ",", "self", ".", "padding", "[", "0", "]", "//", "2", ")", "\n", "return", "F", ".", "conv2d", "(", "F", ".", "pad", "(", "input", ",", "expanded_padding", ",", "mode", "=", "'circular'", ")", ",", "\n", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "\n", "_pair", "(", "0", ")", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "", "return", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Conv2dQuant.forward": [[65, 77], ["models.Conv2dQuant.weight.abs().max().item", "quantize", "models.Conv2dQuant.conv2d_forward", "quantize", "quantize.clamp", "models.Conv2dQuant.weight.abs().max", "models.Conv2dQuant.weight.abs"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Conv2dQuant.conv2d_forward"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "self", ".", "input_quant", ":", "\n", "            ", "max_val", "=", "self", ".", "input_max", "\n", "if", "self", ".", "input_signed", ":", "\n", "                ", "min_val", "=", "-", "max_val", "\n", "", "else", ":", "\n", "                ", "min_val", "=", "0.0", "\n", "", "input", "=", "quantize", "(", "input", ".", "clamp", "(", "min", "=", "min_val", ",", "max", "=", "max_val", ")", ",", "self", ".", "input_signed", ",", "self", ".", "nbits", ",", "max_val", ")", "\n", "\n", "", "max_val", "=", "self", ".", "weight", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "weight", "=", "quantize", "(", "self", ".", "weight", ",", "True", ",", "self", ".", "nbits", ",", "max_val", ")", "\n", "return", "self", ".", "conv2d_forward", "(", "input", ",", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.ConvTrans2dQuant.__init__": [[80, 90], ["torch.ConvTranspose2d.__init__"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "output_padding", "=", "0", ",", "groups", "=", "1", ",", "bias", "=", "True", ",", "\n", "dilation", "=", "1", ",", "padding_mode", "=", "'zeros'", ")", ":", "\n", "        ", "super", "(", "ConvTrans2dQuant", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "output_padding", ",", "groups", ",", "bias", ",", "\n", "dilation", ",", "padding_mode", ")", "\n", "self", ".", "nbits", "=", "_NBITS", "\n", "self", ".", "input_signed", "=", "False", "\n", "self", ".", "input_quant", "=", "True", "\n", "self", ".", "input_max", "=", "_ACTMAX", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.ConvTrans2dQuant.forward": [[91, 111], ["models.ConvTrans2dQuant._output_padding", "models.ConvTrans2dQuant.weight.abs().max().item", "quantize", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "ValueError", "quantize", "quantize.clamp", "models.ConvTrans2dQuant.weight.abs().max", "models.ConvTrans2dQuant.weight.abs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "output_size", "=", "None", ")", ":", "\n", "# type: (Tensor, Optional[List[int]]) -> Tensor", "\n", "        ", "if", "self", ".", "padding_mode", "!=", "'zeros'", ":", "\n", "            ", "raise", "ValueError", "(", "'Only `zeros` padding mode is supported for ConvTranspose2d'", ")", "\n", "\n", "", "output_padding", "=", "self", ".", "_output_padding", "(", "input", ",", "output_size", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "kernel_size", ")", "\n", "\n", "if", "self", ".", "input_quant", ":", "\n", "            ", "max_val", "=", "self", ".", "input_max", "\n", "if", "self", ".", "input_signed", ":", "\n", "                ", "min_val", "=", "-", "max_val", "\n", "", "else", ":", "\n", "                ", "min_val", "=", "0.0", "\n", "", "input", "=", "quantize", "(", "input", ".", "clamp", "(", "min", "=", "min_val", ",", "max", "=", "max_val", ")", ",", "self", ".", "input_signed", ",", "self", ".", "nbits", ",", "max_val", ")", "\n", "\n", "", "max_val", "=", "self", ".", "weight", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "weight", "=", "quantize", "(", "self", ".", "weight", ",", "True", ",", "self", ".", "nbits", ",", "max_val", ")", "\n", "return", "F", ".", "conv_transpose2d", "(", "\n", "input", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "\n", "output_padding", ",", "self", ".", "groups", ",", "self", ".", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.ResidualBlock.__init__": [[115, 130], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "conv_class", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "conv_class", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_features", "=", "256", ",", "mid_features", "=", "256", ",", "conv_class", "=", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "super", "(", "ResidualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "mid_features", ">", "0", ":", "\n", "            ", "conv_block", "=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", ",", "\n", "conv_class", "(", "in_features", ",", "mid_features", ",", "3", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "mid_features", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "1", ")", ",", "\n", "conv_class", "(", "mid_features", ",", "in_features", ",", "3", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "in_features", ",", "affine", "=", "False", ")", "]", "\n", "\n", "self", ".", "conv_block", "=", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_block", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.ResidualBlock.forward": [[131, 133], ["models.ResidualBlock.conv_block"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "+", "self", ".", "conv_block", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Generator.__init__": [[135, 197], ["torch.Module.__init__", "print", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "print", "len", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "conv_class", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "conv_class", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "conv_class", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "transconv_class", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "transconv_class", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "conv_class", "torch.Tanh", "torch.Tanh", "torch.Tanh", "int", "int", "models.ResidualBlock", "int", "int", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "n_residual_blocks", "=", "9", ",", "dim_lst", "=", "None", ",", "alpha", "=", "1", ",", "quant", "=", "False", ")", ":", "\n", "        ", "'''\n        Args:\n            dim_lst: channel dimensions. [int]\n            alpha: channel width factor. float. \n        '''", "\n", "\n", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "quant", ":", "\n", "            ", "print", "(", "'!!! Quantized model !!!'", ")", "\n", "\n", "", "if", "quant", ":", "\n", "            ", "conv_class", "=", "Conv2dQuant", "\n", "transconv_class", "=", "ConvTrans2dQuant", "\n", "", "else", ":", "\n", "            ", "conv_class", "=", "nn", ".", "Conv2d", "\n", "transconv_class", "=", "nn", ".", "ConvTranspose2d", "\n", "\n", "", "if", "dim_lst", "is", "None", ":", "\n", "            ", "dim_lst", "=", "[", "64", ",", "128", "]", "+", "[", "256", "]", "*", "n_residual_blocks", "+", "[", "128", ",", "64", "]", "\n", "", "if", "alpha", "is", "not", "1", ":", "\n", "            ", "dim_lst", "=", "(", "np", ".", "array", "(", "dim_lst", ")", "*", "alpha", ")", ".", "astype", "(", "int", ")", ".", "tolist", "(", ")", "\n", "", "print", "(", "dim_lst", ")", "\n", "assert", "len", "(", "dim_lst", ")", "==", "4", "+", "n_residual_blocks", "\n", "\n", "# Initial convolution block       ", "\n", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "conv_class", "(", "input_nc", ",", "dim_lst", "[", "0", "]", ",", "7", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "dim_lst", "[", "0", "]", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "\n", "# do not quantize the input image", "\n", "if", "conv_class", "is", "Conv2dQuant", ":", "\n", "            ", "model", "[", "1", "]", ".", "input_quant", "=", "False", "\n", "\n", "# Downsampling", "\n", "", "model", "+=", "[", "conv_class", "(", "dim_lst", "[", "0", "]", ",", "dim_lst", "[", "1", "]", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "dim_lst", "[", "1", "]", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "\n", "model", "+=", "[", "conv_class", "(", "dim_lst", "[", "1", "]", ",", "int", "(", "256", "*", "alpha", ")", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "int", "(", "256", "*", "alpha", ")", ",", "affine", "=", "False", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "\n", "# Residual blocks", "\n", "for", "i", "in", "range", "(", "n_residual_blocks", ")", ":", "\n", "            ", "model", "+=", "[", "ResidualBlock", "(", "in_features", "=", "int", "(", "256", "*", "alpha", ")", ",", "mid_features", "=", "dim_lst", "[", "2", "+", "i", "]", ",", "conv_class", "=", "conv_class", ")", "]", "\n", "\n", "# Upsampling", "\n", "", "model", "+=", "[", "transconv_class", "(", "int", "(", "256", "*", "alpha", ")", ",", "dim_lst", "[", "2", "+", "n_residual_blocks", "]", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "output_padding", "=", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "dim_lst", "[", "2", "+", "n_residual_blocks", "]", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "model", "+=", "[", "transconv_class", "(", "dim_lst", "[", "2", "+", "n_residual_blocks", "]", ",", "dim_lst", "[", "2", "+", "n_residual_blocks", "+", "1", "]", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "output_padding", "=", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "dim_lst", "[", "2", "+", "n_residual_blocks", "+", "1", "]", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "\n", "# Output layer", "\n", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "conv_class", "(", "dim_lst", "[", "2", "+", "n_residual_blocks", "+", "1", "]", ",", "output_nc", ",", "7", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Generator.forward": [[198, 200], ["models.Generator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__": [[202, 225], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# A bunch of convolutions one after another", "\n", "model", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "64", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "]", "\n", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "128", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "]", "\n", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "256", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "]", "\n", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "4", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "512", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "]", "\n", "\n", "# FCN classification layer", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "512", ",", "1", ",", "4", ",", "padding", "=", "1", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TAMU-VITA_GAN-Slimming.models.models.Discriminator.forward": [[226, 230], ["models.Discriminator.model", "torch.avg_pool2d().view", "torch.avg_pool2d().view", "torch.avg_pool2d().view", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "models.Discriminator.size", "models.Discriminator.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "# Average pooling and flatten", "\n", "return", "F", ".", "avg_pool2d", "(", "x", ",", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ".", "view", "(", "x", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "\n"]]}