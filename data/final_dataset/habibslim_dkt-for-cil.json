{"home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits_lucir.load_model": [[19, 39], ["torch.nn.AvgPool2d", "torch.load.to", "torch.no_grad", "torch.load", "os.path.isfile", "print", "exit"], "function", ["None"], ["def", "load_model", "(", "model_load_path", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Loading a fine-tuning model and normalizing it following SiW,\n    while keeping only the first learned head for each task.\n\n    Args:\n        model_load_path: Serialized model full path\n        device:          Torch device to be used\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Loading the state dictionary", "\n", "        ", "if", "not", "os", ".", "path", ".", "isfile", "(", "model_load_path", ")", ":", "\n", "            ", "print", "(", "\"File: %s\"", "%", "model_load_path", ",", "\" not found. Stopping at this task.\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "# Loading the model", "\n", "", "base_net", "=", "torch", ".", "load", "(", "model_load_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "", "base_net", ".", "avgpool", "=", "torch", ".", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "return", "base_net", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits_lucir.parse_args": [[41, 88], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "os.path.expanduser", "os.path.expanduser", "os.path.join", "print", "print", "list", "datasets.dataset_config.dataset_config.keys"], "function", ["None"], ["", "def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extracting validation and test logits for each incremental state.'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'GPU (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed (default=%(default)s)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--models-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory containing serialized models'", ")", "\n", "parser", ".", "add_argument", "(", "'--logits-outdir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save task logits'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--datasets'", ",", "default", "=", "[", "'cifar100'", "]", ",", "type", "=", "str", ",", "choices", "=", "list", "(", "dataset_config", ".", "keys", "(", ")", ")", ",", "\n", "help", "=", "'Dataset or datasets used (default=%(default)s)'", ",", "nargs", "=", "'+'", ",", "metavar", "=", "\"DATASET\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of subprocesses to use for dataloader (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pin-memory'", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Copy Tensors into CUDA pinned memory before returning them (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of samples per batch to load (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "\n", "# Setting base model name", "\n", "dset_name", "=", "args", ".", "datasets", "[", "0", "]", "\n", "dset_name", "=", "'cifar100_half'", "if", "dset_name", "==", "'cif100_half'", "else", "dset_name", "\n", "args", ".", "models_base_name", "=", "\"%s_s%d_k0_model_\"", "%", "(", "dset_name", ",", "args", ".", "num_tasks", ")", "\n", "\n", "# Updating paths", "\n", "args", ".", "models_dir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "models_dir", ")", "\n", "args", ".", "logits_outdir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "logits_outdir", ")", "\n", "args", ".", "models_base_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "args", ".", "models_base_name", ")", "\n", "\n", "# Printing input arguments", "\n", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits_lucir.extract_logits": [[90, 114], ["torch.tensor().to", "torch.tensor().to", "torch.no_grad", "net.eval", "torch.tensor", "torch.tensor", "targets.to.to", "net", "torch.cat", "torch.cat", "images.to"], "function", ["None"], ["", "def", "extract_logits", "(", "net", ",", "loader", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Extracting output logits using the supplied network.\n\n    Args:\n        net:    Instantiated model\n        loader: Loader for the current task\n        device: Torch device to be used\n    \"\"\"", "\n", "all_logits", "=", "torch", ".", "tensor", "(", "[", "]", ")", ".", "to", "(", "device", ")", "\n", "all_labels", "=", "torch", ".", "tensor", "(", "[", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "net", ".", "eval", "(", ")", "\n", "for", "images", ",", "targets", "in", "loader", ":", "\n", "# Forwarding through current model", "\n", "            ", "targets", "=", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "net", "(", "images", ".", "to", "(", "device", ")", ")", "\n", "\n", "# Concatenating to output matrix", "\n", "all_logits", "=", "torch", ".", "cat", "(", "(", "all_logits", ",", "outputs", ")", ")", "\n", "all_labels", "=", "torch", ".", "cat", "(", "(", "all_labels", ",", "targets", ")", ")", "\n", "\n", "", "", "return", "all_logits", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits_lucir.main": [[116, 183], ["warnings.filterwarnings", "extract_logits_lucir.parse_args", "utils.seed_everything", "torch.cuda.is_available", "datasets.data_loader.get_loaders", "enumerate", "print", "torch.cuda.set_device", "print", "os.path.exists", "os.makedirs", "print", "print", "print", "extract_logits_lucir.load_model", "print", "range", "print", "extract_logits_lucir.extract_logits", "torch.save", "torch.save", "print", "print", "extract_logits_lucir.extract_logits", "torch.save", "torch.save", "print", "print"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.seed_everything", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_loaders", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.load_model", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.extract_logits", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.extract_logits"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Extracting and saving output logits.\n    \"\"\"", "\n", "# Filtering EXIF warnings", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ")", "\n", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "\n", "# Fixing random seed", "\n", "utils", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "# Selecting device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "device", "=", "'cuda'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'WARNING: CUDA unavailable, using CPU instead!'", ")", "\n", "device", "=", "'cpu'", "\n", "\n", "# Instantiating data loaders", "\n", "", "val_loader", ",", "_", ",", "tst_loader", ",", "taskcla", "=", "get_loaders", "(", "args", ".", "datasets", ",", "args", ".", "num_tasks", ",", "None", ",", "\n", "args", ".", "batch_size", ",", "num_workers", "=", "8", ",", "\n", "pin_memory", "=", "False", ",", "\n", "force_order", "=", "True", ",", "val_only", "=", "True", ")", "\n", "\n", "# Creating output logits dir, if necessary", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "logits_outdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "logits_outdir", ")", "\n", "\n", "# - P: Number of new classes per state", "\n", "", "for", "t", ",", "(", "_", ",", "P", ")", "in", "enumerate", "(", "taskcla", ")", ":", "\n", "        ", "print", "(", "'*'", "*", "108", ")", "\n", "print", "(", "'Task {:2d}'", ".", "format", "(", "t", ")", ")", "\n", "print", "(", "'*'", "*", "108", ")", "\n", "\n", "# Loading the network for this task", "\n", "task_model", "=", "\"%s%d.pth\"", "%", "(", "args", ".", "models_base_path", ",", "t", ")", "\n", "net", "=", "load_model", "(", "task_model", ",", "device", ")", "\n", "print", "(", "\"Loaded task model from: %s\"", "%", "task_model", ")", "\n", "\n", "# Extracting and serializing validation and test logits", "\n", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "# val:", "\n", "            ", "val_logits", ",", "val_labels", "=", "extract_logits", "(", "net", ",", "val_loader", "[", "u", "]", ",", "device", ")", "\n", "val_logits_file", "=", "\"%slogits_val_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "val_logits", ",", "val_logits_file", ")", "\n", "val_labels_file", "=", "\"%slabels_val_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "val_labels", ",", "val_labels_file", ")", "\n", "\n", "print", "(", "'Val logits shape: '", ",", "val_logits", ".", "shape", ")", "\n", "print", "(", "'Val labels shape: '", ",", "val_labels", ".", "shape", ")", "\n", "\n", "# test:", "\n", "tst_logits", ",", "tst_labels", "=", "extract_logits", "(", "net", ",", "tst_loader", "[", "u", "]", ",", "device", ")", "\n", "tst_logits_file", "=", "\"%slogits_tst_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "tst_logits", ",", "tst_logits_file", ")", "\n", "tst_labels_file", "=", "\"%slabels_tst_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "tst_labels", ",", "tst_labels_file", ")", "\n", "\n", "print", "(", "'Test logits shape: '", ",", "tst_logits", ".", "shape", ")", "\n", "print", "(", "'Test labels shape: '", ",", "tst_labels", ".", "shape", ")", "\n", "\n", "", "print", "(", "'-'", "*", "108", ")", "\n", "\n", "", "print", "(", "\"All output logits succesfully saved!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.finetuning.parse_args": [[26, 81], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "int", "print", "print", "list", "datasets.dataset_config.dataset_config.keys"], "function", ["None"], ["def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Finetuning a base model across multiple incremental steps.'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'GPU (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--models-dir'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save the basic step model.'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--datasets'", ",", "default", "=", "[", "'cif100'", "]", ",", "type", "=", "str", ",", "choices", "=", "list", "(", "dataset_config", ".", "keys", "(", ")", ")", ",", "\n", "help", "=", "'Dataset or datasets used (default=%(default)s)'", ",", "nargs", "=", "'+'", ",", "metavar", "=", "\"DATASET\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of subprocesses to use for dataloader (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pin-memory'", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Copy Tensors into CUDA pinned memory before returning them (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Real batch size, before gradient accumulation (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--eff-batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Effective batch size, after gradient accumulation (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Test batch size (default=%(default)s)'", ")", "\n", "\n", "# training args", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Starting learning rate (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-decay'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Learning rate decay (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "default", "=", "0.0005", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Weight decay (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Momentum (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepochs'", ",", "default", "=", "200", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of epochs per training session (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "default", "=", "60", ",", "required", "=", "False", ",", "\n", "help", "=", "'Use patience while training (default=%(default)s)'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "\n", "args", ".", "iter_size", "=", "int", "(", "args", ".", "eff_batch_size", "/", "args", ".", "batch_size", ")", "\n", "\n", "# Printing input arguments", "\n", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.finetuning.main": [[83, 225], ["warnings.filterwarnings", "finetuning.parse_args", "utils.seed_everything", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "datasets.data_loader.get_loaders", "len", "time.time", "enumerate", "print", "print", "print", "print", "os.path.exists", "print", "exit", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "print", "print", "print", "print", "max", "os.path.join", "torchvision.models.resnet18().to", "print", "torch.load", "torch.load", "torch.load", "models.resnet18().to.load_state_dict", "torch.Linear().to", "torch.CrossEntropyLoss", "torch.SGD", "torch.optim.lr_scheduler.ReduceLROnPlateau", "copy.deepcopy", "time.time", "range", "os.path.join", "print", "torch.save", "torch.save", "torch.save", "torchvision.models.resnet18", "models.resnet18().to.parameters", "optim.SGD.zero_grad", "models.resnet18().to.train", "enumerate", "lr_scheduler.ReduceLROnPlateau.step", "print", "models.resnet18().to.eval", "range", "copy.deepcopy.state_dict", "torch.Linear", "models.resnet18().to.", "nn.CrossEntropyLoss.", "criterion.backward", "criterion.data.item", "criterion.cpu().data.numpy", "time.time", "float", "copy.deepcopy", "time.time", "images.to", "targets.to", "optim.SGD.step", "optim.SGD.zero_grad", "datetime.timedelta", "models.resnet18().to.", "utils.calculate_metrics", "len", "images.to", "targets.to", "criterion.cpu", "round"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.seed_everything", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_loaders", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.resnet18", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.calculate_metrics"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Main training routine.\n    \"\"\"", "\n", "# Filtering EXIF warnings", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "\"(Possibly )?corrupt EXIF data\"", ",", "UserWarning", ")", "\n", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "\n", "# Fixing random seed", "\n", "utils", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "# Checking directory folder", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "models_dir", ")", ":", "\n", "        ", "print", "(", "\"Model directory [%s] not found. Exiting.\"", "%", "args", ".", "models_dir", ")", "\n", "exit", "(", "-", "1", ")", "\n", "\n", "# Selecting device", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "device", "=", "'cuda'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'WARNING: CUDA unavailable, using CPU instead!'", ")", "\n", "device", "=", "'cpu'", "\n", "\n", "# Instantiating data loaders", "\n", "", "trn_loader", ",", "val_loader", ",", "tst_loader", ",", "taskcla", "=", "get_loaders", "(", "args", ".", "datasets", ",", "\n", "args", ".", "num_tasks", ",", "None", ",", "\n", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "\n", "force_order", "=", "True", ")", "\n", "\n", "# Storing evaluation metrics", "\n", "max_task", "=", "len", "(", "taskcla", ")", "\n", "\n", "# Main loop", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "\n", "# - P: Number of new classes per state", "\n", "for", "t", ",", "(", "_", ",", "P", ")", "in", "enumerate", "(", "taskcla", ")", ":", "\n", "        ", "print", "(", "'*'", "*", "108", ")", "\n", "print", "(", "'Task {:2d}'", ".", "format", "(", "t", ")", ")", "\n", "print", "(", "'*'", "*", "108", ")", "\n", "\n", "batch_lr", "=", "args", ".", "lr", "/", "(", "t", "+", "1", ")", "\n", "\n", "nb_old_cls", "=", "P", "if", "t", "==", "0", "else", "t", "*", "P", "\n", "nb_new_cls", "=", "P", "\n", "\n", "# Loading previous batch model", "\n", "prev_t", "=", "max", "(", "t", "-", "1", ",", "0", ")", "\n", "model_load_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "'task%d.ckpt'", "%", "prev_t", ")", "\n", "model_ft", "=", "models", ".", "resnet18", "(", "pretrained", "=", "False", ",", "num_classes", "=", "nb_old_cls", ")", ".", "to", "(", "device", ")", "\n", "\n", "print", "(", "'Loading saved model from '", "+", "model_load_path", ")", "\n", "state", "=", "torch", ".", "load", "(", "model_load_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_ft", ".", "load_state_dict", "(", "state", "[", "'state_dict'", "]", ")", "\n", "\n", "if", "t", ">", "0", ":", "\n", "            ", "model_ft", ".", "fc", "=", "nn", ".", "Linear", "(", "512", ",", "nb_old_cls", "+", "nb_new_cls", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Defining Loss and Optimizer", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer_ft", "=", "optim", ".", "SGD", "(", "model_ft", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "batch_lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer_ft", ",", "\n", "patience", "=", "args", ".", "patience", ",", "\n", "factor", "=", "args", ".", "lr_decay", ")", "\n", "\n", "best_val_acc", "=", "-", "1", "\n", "best_model", "=", "deepcopy", "(", "model_ft", ")", "\n", "\n", "# Training", "\n", "starting_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "nepochs", ")", ":", "\n", "# Training the model", "\n", "                ", "optimizer_ft", ".", "zero_grad", "(", ")", "\n", "model_ft", ".", "train", "(", ")", "\n", "\n", "loss", "=", "None", "\n", "running_loss", "=", "0.0", "\n", "nb_batches", "=", "0", "\n", "\n", "for", "i", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "trn_loader", "[", "t", "]", ")", ":", "\n", "                    ", "nb_batches", "+=", "1", "\n", "images", ",", "targets", "=", "images", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "# Forward + backward + optimize", "\n", "outputs", "=", "model_ft", "(", "images", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "loss", ".", "data", "/=", "args", ".", "iter_size", "\n", "loss", ".", "backward", "(", ")", "\n", "running_loss", "+=", "loss", ".", "data", ".", "item", "(", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "args", ".", "iter_size", "==", "0", ":", "\n", "                        ", "optimizer_ft", ".", "step", "(", ")", "\n", "optimizer_ft", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "scheduler", ".", "step", "(", "loss", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "current_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "starting_time", "\n", "print", "(", "'{:03}/{:03} | {} | Train : loss = {:.4f} '", ".", "\n", "format", "(", "epoch", "+", "1", ",", "args", ".", "nepochs", ",", "\n", "timedelta", "(", "seconds", "=", "round", "(", "current_elapsed_time", ")", ")", ",", "\n", "running_loss", "/", "nb_batches", ")", ")", "\n", "\n", "# Evaluating the model on the test set", "\n", "model_ft", ".", "eval", "(", ")", "\n", "total_top1_hits", ",", "N", "=", "0", ",", "0", "\n", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "                    ", "for", "images", ",", "targets", "in", "tst_loader", "[", "u", "]", ":", "\n", "                        ", "images", ",", "targets", "=", "images", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "model_ft", "(", "images", ")", "\n", "_", ",", "top1_hits", "=", "utils", ".", "calculate_metrics", "(", "outputs", ",", "targets", ")", "\n", "\n", "total_top1_hits", "+=", "top1_hits", "\n", "N", "+=", "len", "(", "targets", ")", "\n", "\n", "", "", "top1_avg", "=", "float", "(", "total_top1_hits", ")", "/", "N", "\n", "if", "top1_avg", ">", "best_val_acc", ":", "\n", "                    ", "best_val_acc", "=", "top1_avg", "\n", "best_model", "=", "deepcopy", "(", "model_ft", ")", "\n", "\n", "# Saving the model for this state", "\n", "", "", "saved_model", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "'task%d.ckpt'", "%", "t", ")", "\n", "print", "(", "'Saved best model at: ['", "+", "saved_model", "+", "']'", ")", "\n", "state", "=", "{", "\n", "'state_dict'", ":", "best_model", ".", "state_dict", "(", ")", "\n", "}", "\n", "torch", ".", "save", "(", "state", ",", "saved_model", ")", "\n", "\n", "# Final output", "\n", "", "", "print", "(", "'[Elapsed time = {:.1f} mn]'", ".", "format", "(", "(", "time", ".", "time", "(", ")", "-", "tstart", ")", "/", "60", ")", ")", "\n", "print", "(", "'Done!'", ")", "\n", "\n", "print", "(", "'-'", "*", "108", ")", "\n", "print", "(", "\"All tasks optimized and evaluated.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCLayer.__init__": [[24, 33], ["super().__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.ones", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__"], ["def", "__init__", "(", "self", ",", "device", ",", "init_zero", "=", "False", ")", ":", "\n", "        ", "super", "(", "BiCLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "init_zero", ":", "\n", "            ", "self", ".", "alpha", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "requires_grad", "=", "False", ",", "device", "=", "device", ")", ")", "\n", "self", ".", "beta", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "requires_grad", "=", "False", ",", "device", "=", "device", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "alpha", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "requires_grad", "=", "False", ",", "device", "=", "device", ")", ")", "\n", "self", ".", "beta", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "requires_grad", "=", "False", ",", "device", "=", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCLayer.forward": [[34, 39], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Overloading the forward pass.\n        \"\"\"", "\n", "return", "self", ".", "alpha", "*", "x", "+", "self", ".", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.__init__": [[46, 55], ["super().__init__", "torch.nn.ModuleList"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__"], ["def", "__init__", "(", "self", ",", "device", ",", "method", ")", ":", "\n", "        ", "super", "(", "BiCNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "t", "=", "0", "\n", "\n", "# Initializing the local list of BiC \"heads\"", "\n", "self", ".", "bias_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.add_head": [[56, 62], ["BiCLayer().to", "adaptive_bic.BiCLayer"], "methods", ["None"], ["", "def", "add_head", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Extending the layer for an additional task.\n        \"\"\"", "\n", "self", ".", "bias_layers", "+=", "[", "BiCLayer", "(", "self", ".", "device", ")", ".", "to", "(", "self", ".", "device", ")", "]", "\n", "self", ".", "t", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.beta_l2": [[63, 71], ["None"], "methods", ["None"], ["", "def", "beta_l2", "(", "self", ",", "loss", ",", "lambd", ")", ":", "\n", "        ", "\"\"\"\n        Adding an L2 loss over all trainable beta variables.\n        \"\"\"", "\n", "for", "layer", "in", "self", ".", "bias_layers", ":", "\n", "            ", "if", "layer", ".", "beta", ".", "requires_grad", ":", "\n", "                ", "loss", "+=", "lambd", "*", "(", "(", "layer", ".", "beta", "[", "0", "]", "*", "layer", ".", "beta", "[", "0", "]", ")", "/", "2.", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.forward": [[72, 82], ["adaptive_bic.BiCNet.forward_all", "adaptive_bic.BiCNet.forward_last", "adaptive_bic.BiCNet.forward_past"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.forward_all", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.forward_last", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.forward_past"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forwarding the BiC model using a specific method.\n        \"\"\"", "\n", "if", "self", ".", "method", "in", "[", "CalibrationMethod", ".", "FORWARD_ALL", ",", "CalibrationMethod", ".", "ADAPTIVE", "]", ":", "\n", "            ", "return", "self", ".", "forward_all", "(", "x", ")", "\n", "", "elif", "self", ".", "method", "==", "CalibrationMethod", ".", "FORWARD_LAST", ":", "\n", "            ", "return", "self", ".", "forward_last", "(", "x", ")", "\n", "", "elif", "self", ".", "method", "==", "CalibrationMethod", ".", "FORWARD_PAST", ":", "\n", "            ", "return", "self", ".", "forward_past", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.forward_all": [[83, 96], ["enumerate", "torch.chunk"], "methods", ["None"], ["", "", "def", "forward_all", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forwarding through every BiC layer.\n\n        Args:\n            x:      Logits extracted for all previous classes.\n        \"\"\"", "\n", "bic_outputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "x_", "in", "enumerate", "(", "torch", ".", "chunk", "(", "x", ",", "self", ".", "t", ",", "dim", "=", "1", ")", ")", ":", "\n", "            ", "bic_outputs", "+=", "[", "self", ".", "bias_layers", "[", "i", "]", "(", "x_", ")", "]", "\n", "\n", "", "return", "bic_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.forward_last": [[97, 113], ["enumerate", "torch.chunk"], "methods", ["None"], ["", "def", "forward_last", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Multiply all logits of the last task with the last alpha/beta coefficients learned.\n\n        Args:\n            x:     Logits extracted for all previous classes.\n        \"\"\"", "\n", "bic_outputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "x_", "in", "enumerate", "(", "torch", ".", "chunk", "(", "x", ",", "self", ".", "t", ",", "dim", "=", "1", ")", ")", ":", "\n", "            ", "if", "i", "==", "self", ".", "t", "-", "1", ":", "\n", "                ", "bic_outputs", "+=", "[", "self", ".", "bias_layers", "[", "i", "]", "(", "x_", ")", "]", "\n", "", "else", ":", "\n", "                ", "bic_outputs", "+=", "[", "x_", "]", "\n", "\n", "", "", "return", "bic_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.forward_past": [[114, 130], ["enumerate", "torch.chunk"], "methods", ["None"], ["", "def", "forward_past", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Multiply all logits of all past tasks with the last alpha/beta coefficients learned.\n\n        Args:\n            x:     Logits extracted for all previous classes.\n        \"\"\"", "\n", "bic_outputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "x_", "in", "enumerate", "(", "torch", ".", "chunk", "(", "x", ",", "self", ".", "t", ",", "dim", "=", "1", ")", ")", ":", "\n", "            ", "if", "i", "<", "self", ".", "t", "-", "1", ":", "\n", "                ", "bic_outputs", "+=", "[", "self", ".", "bias_layers", "[", "self", ".", "t", "-", "1", "]", "(", "x_", ")", "]", "\n", "", "else", ":", "\n", "                ", "bic_outputs", "+=", "[", "x_", "]", "\n", "\n", "", "", "return", "bic_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.print_parameters": [[131, 147], ["max", "print", "print", "enumerate", "print", "print", "print", "print", "print", "str().ljust", "str().ljust", "str", "str", "round", "round", "float", "float"], "methods", ["None"], ["", "def", "print_parameters", "(", "self", ",", "prec", "=", "5", ")", ":", "\n", "        ", "\"\"\"\n        Printing model parameters.\n        \"\"\"", "\n", "max_chars", "=", "max", "(", "8", ",", "prec", "+", "5", ")", "\n", "\n", "print", "(", "\"BiC params:\"", ")", "\n", "print", "(", "\"------------\"", ")", "\n", "for", "t", ",", "layer", "in", "enumerate", "(", "self", ".", "bias_layers", ")", ":", "\n", "            ", "print", "(", "\"\\tLayer %d\"", "%", "t", ")", "\n", "print", "(", "\"\\t\\t\u03b1=\"", ",", "str", "(", "round", "(", "float", "(", "layer", ".", "alpha", ")", ",", "prec", ")", ")", ".", "ljust", "(", "max_chars", ")", ",", "\" | %s\"", "\n", "%", "(", "\"active\"", "if", "layer", ".", "alpha", ".", "requires_grad", "else", "\"frozen\"", ")", ")", "\n", "print", "(", "\"\\t\\t\u03b2=\"", ",", "str", "(", "round", "(", "float", "(", "layer", ".", "beta", ")", ",", "prec", ")", ")", ".", "ljust", "(", "max_chars", ")", ",", "\" | %s\"", "\n", "%", "(", "\"active\"", "if", "layer", ".", "alpha", ".", "requires_grad", "else", "\"frozen\"", ")", ")", "\n", "print", "(", "\"\\t------------\"", ")", "\n", "", "print", "(", "\"------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.set_alpha": [[148, 153], ["torch.nn.Parameter", "torch.tensor"], "methods", ["None"], ["", "def", "set_alpha", "(", "self", ",", "val", ")", ":", "\n", "        ", "\"\"\"\n        Setting alpha coefficient value on the last layer.\n        \"\"\"", "\n", "self", ".", "bias_layers", "[", "-", "1", "]", ".", "alpha", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "val", ",", "device", "=", "self", ".", "device", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.set_beta": [[154, 159], ["torch.nn.Parameter", "torch.tensor"], "methods", ["None"], ["", "def", "set_beta", "(", "self", ",", "val", ")", ":", "\n", "        ", "\"\"\"\n        Setting alpha coefficient value on the last layer.\n        \"\"\"", "\n", "self", ".", "bias_layers", "[", "-", "1", "]", ".", "beta", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "val", ",", "device", "=", "self", ".", "device", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.train_init": [[160, 168], ["adaptive_bic.BiCNet.train_all", "adaptive_bic.BiCNet.train_last"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.train_all", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.train_last"], ["", "def", "train_init", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Initializing training of the linear layer.\n        \"\"\"", "\n", "if", "self", ".", "method", "==", "CalibrationMethod", ".", "ADAPTIVE", ":", "\n", "            ", "self", ".", "train_all", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "train_last", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.train_last": [[169, 180], ["None"], "methods", ["None"], ["", "", "def", "train_last", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Disabling the update of all 1..t-1 BiC heads (where t is the current head count, and the id of the last task).\n        Enabling updates on the last layer.\n        \"\"\"", "\n", "for", "layer", "in", "self", ".", "bias_layers", "[", ":", "self", ".", "t", "-", "1", "]", ":", "\n", "            ", "layer", ".", "alpha", ".", "requires_grad", "=", "False", "\n", "layer", ".", "beta", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "bias_layers", "[", "self", ".", "t", "-", "1", "]", ".", "alpha", ".", "requires_grad", "=", "True", "\n", "self", ".", "bias_layers", "[", "self", ".", "t", "-", "1", "]", ".", "beta", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.train_all": [[181, 188], ["None"], "methods", ["None"], ["", "def", "train_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Enabling updates on the all BiC layers.\n        \"\"\"", "\n", "for", "layer", "in", "self", ".", "bias_layers", ":", "\n", "            ", "layer", ".", "alpha", ".", "requires_grad", "=", "True", "\n", "layer", ".", "beta", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.trainable_p": [[189, 200], ["None"], "methods", ["None"], ["", "", "def", "trainable_p", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the list of trainable parameters.\n        \"\"\"", "\n", "params", "=", "[", "]", "\n", "for", "layer", "in", "self", ".", "bias_layers", ":", "\n", "            ", "if", "layer", ".", "alpha", ".", "requires_grad", ":", "\n", "                ", "params", "+=", "[", "layer", ".", "alpha", "]", "\n", "", "if", "layer", ".", "beta", ".", "requires_grad", ":", "\n", "                ", "params", "+=", "[", "layer", ".", "beta", "]", "\n", "", "", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.parse_args": [[18, 93], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "os.path.expanduser", "print", "print", "os.path.expanduser", "os.path.expanduser", "list", "calib_methods.keys"], "function", ["None"], ["def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Calibrating BiC coefficients using pre-extracted'", "\n", "'logits from incremental models'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'GPU (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed (default=%(default)s)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logits-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory containing serialized logits and associated labels'", ")", "\n", "parser", ".", "add_argument", "(", "'--bic-models-outdir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save BiC parameters'", ")", "\n", "parser", ".", "add_argument", "(", "'--bic-models-dir'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Input directory containing BiC parameters.'", "\n", "'If specified, will run in inference mode only.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--eval-only'", ",", "action", "=", "'store_true'", ",", "required", "=", "False", ",", "\n", "help", "=", "'Only evaluate the model from the raw logits (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--recalibrate'", ",", "action", "=", "'store_true'", ",", "required", "=", "False", ",", "\n", "help", "=", "'Recalibrate using the formula from SiW (default=%(default)s)'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of subprocesses to use for dataloader (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pin-memory'", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Copy Tensors into CUDA pinned memory before returning them (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of samples per batch to load (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "\n", "# training args", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "0.001", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Starting learning rate (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepochs'", ",", "default", "=", "200", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of epochs per training session (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Use patience while training (default=%(default)s)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gridsearch'", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Use gridsearch to optimize the BiC layers (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--step'", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Step for gridsearch (default=%(default)s)'", ")", "\n", "\n", "# For a description of each method, check the CalibrationMethod class definition", "\n", "calib_methods", "=", "{", "'forward-all'", ":", "CalibrationMethod", ".", "FORWARD_ALL", ",", "\n", "'forward-past'", ":", "CalibrationMethod", ".", "FORWARD_PAST", ",", "\n", "'forward-last'", ":", "CalibrationMethod", ".", "FORWARD_LAST", ",", "\n", "'adaptive'", ":", "CalibrationMethod", ".", "ADAPTIVE", "}", "\n", "parser", ".", "add_argument", "(", "'--calib-method'", ",", "default", "=", "'adaptive'", ",", "type", "=", "str", ",", "choices", "=", "list", "(", "calib_methods", ".", "keys", "(", ")", ")", ",", "\n", "help", "=", "'Calibration method to use (default=%(default)s)'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "\n", "# Calibration method", "\n", "args", ".", "calib_method", "=", "calib_methods", "[", "args", ".", "calib_method", "]", "\n", "\n", "# Updating paths", "\n", "args", ".", "logits_dir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "logits_dir", ")", "\n", "if", "args", ".", "bic_models_outdir", ":", "\n", "        ", "args", ".", "bic_models_outdir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "bic_models_outdir", ")", "\n", "", "if", "args", ".", "bic_models_dir", ":", "\n", "        ", "args", ".", "bic_models_dir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "bic_models_dir", ")", "\n", "\n", "# Printing input arguments", "\n", "", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.read_logits": [[95, 108], ["torch.load", "os.path.isfile", "print", "exit"], "function", ["None"], ["", "def", "read_logits", "(", "file_path", ")", ":", "\n", "    ", "\"\"\"\n    Reading serialized output logits.\n\n    Args:\n        file_path:  File path for the serialized output logits\n    \"\"\"", "\n", "# Loading output logits", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "file_path", ")", ":", "\n", "        ", "print", "(", "\"File: %s\"", "%", "file_path", ",", "\" not found. Stopping at this task.\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "return", "torch", ".", "load", "(", "file_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.read_labels": [[110, 123], ["torch.load().type", "os.path.isfile", "print", "exit", "torch.load"], "function", ["None"], ["", "def", "read_labels", "(", "file_path", ")", ":", "\n", "    ", "\"\"\"\n    Reading serialized output labels, and packing them in batches.\n\n    Args:\n        file_path:  File path for the serialized output logits\n    \"\"\"", "\n", "# Loading output logits", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "file_path", ")", ":", "\n", "        ", "print", "(", "\"File: %s\"", "%", "file_path", ",", "\" not found. Stopping at this task.\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "return", "torch", ".", "load", "(", "file_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.compute_topk_acc": [[125, 141], ["min", "pred.t.topk", "pred.t.t", "pred.t.eq", "correct[].reshape().float().sum", "targets.view().expand_as", "correct[].reshape().float", "targets.view", "correct[].reshape"], "function", ["None"], ["", "def", "compute_topk_acc", "(", "pred", ",", "targets", ",", "topk", ")", ":", "\n", "    ", "\"\"\"\n    Computing top-k accuracy given prediction and target vectors.\n\n    Args:\n        pred:    Network prediction\n        targets: Ground truth labels\n        topk:    k value\n    \"\"\"", "\n", "topk", "=", "min", "(", "topk", ",", "pred", ".", "shape", "[", "1", "]", ")", "\n", "_", ",", "pred", "=", "pred", ".", "topk", "(", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "targets", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "hits_tag", "=", "correct", "[", ":", "topk", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "\n", "return", "hits_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.calculate_metrics": [[143, 159], ["isinstance", "calibrate_bic.compute_topk_acc", "calibrate_bic.compute_topk_acc", "torch.cat", "compute_topk_acc.item", "compute_topk_acc.item"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.compute_topk_acc", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.compute_topk_acc"], ["", "def", "calculate_metrics", "(", "outputs", ",", "targets", ")", ":", "\n", "    ", "\"\"\"\n    Computing top-1 and top-5 task-agnostic accuracy metrics.\n\n    Args:\n        outputs: Network outputs list\n        targets: Ground truth labels\n    \"\"\"", "\n", "if", "isinstance", "(", "outputs", ",", "list", ")", ":", "\n", "        ", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "\n", "# Top-k prediction for TAg", "\n", "", "hits_tag_top5", "=", "compute_topk_acc", "(", "outputs", ",", "targets", ",", "5", ")", "\n", "hits_tag_top1", "=", "compute_topk_acc", "(", "outputs", ",", "targets", ",", "1", ")", "\n", "\n", "return", "hits_tag_top5", ".", "item", "(", ")", ",", "hits_tag_top1", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.average_scores": [[161, 185], ["torch.no_grad", "torch.tensor().to", "range", "float", "bic_net.forward", "torch.cat", "torch.cat.max", "torch.cat", "torch.cat.mean", "torch.tensor", "val_logits[].to"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet.forward"], ["", "def", "average_scores", "(", "t", ",", "val_logits", ",", "bic_net", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Pre-compute mean top-1 metrics for recalibration.\n\n    Args:\n        t:            Current task index\n        val_logits:   Data loader to use\n        bic_net:      Current recalibration model\n        device:       Device to use\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "all_max", "=", "torch", ".", "tensor", "(", "[", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "# Correcting logits with the current model", "\n", "            ", "logits", "=", "bic_net", ".", "forward", "(", "val_logits", "[", "u", "]", ".", "to", "(", "device", ")", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "logits", ",", "dim", "=", "1", ")", "\n", "# Computing top-1 values alongside each axis", "\n", "max_vals", ",", "_", "=", "logits", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "all_max", "=", "torch", ".", "cat", "(", "(", "max_vals", ",", "all_max", ")", ")", "\n", "\n", "# Averaging values", "\n", "", "return", "float", "(", "all_max", ".", "mean", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.recalibrate": [[187, 204], ["enumerate", "torch.cat", "torch.chunk"], "function", ["None"], ["", "", "def", "recalibrate", "(", "t", ",", "metrics", ",", "outputs", ")", ":", "\n", "    ", "\"\"\"\n    Recalibrating the output prediction vectors, using mean top-1 statistics (following [1].)\n\n        [1] Belouadah et al., \"Initial classifier weights replay for memoryless class incremental learning\"\n\n    Args:\n        t:        Current task index\n        metrics:  Recalibration metrics to apply\n        outputs:  Network outputs tensor\n    \"\"\"", "\n", "calib_out", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "torch", ".", "chunk", "(", "outputs", ",", "t", "+", "1", ",", "dim", "=", "1", ")", ")", ":", "\n", "        ", "calib_fact", "=", "metrics", "[", "t", "]", "/", "metrics", "[", "i", "]", "\n", "calib_out", "+=", "[", "calib_fact", "*", "x", "]", "\n", "\n", "", "return", "torch", ".", "cat", "(", "calib_out", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.bic_eval": [[206, 249], ["torch.no_grad", "torch.split", "torch.split", "zip", "recalibrate.to", "targets.to.to", "calibrate_bic.calculate_metrics", "len", "calibrate_bic.recalibrate", "bic_net.forward"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.calculate_metrics", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.recalibrate", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet.forward"], ["", "def", "bic_eval", "(", "bic_net", ",", "tst_logits", ",", "tst_labels", ",", "batch_size", ",", "use_bic", ",", "device", ",", "metrics", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Returns the top-5 and top-1 task-agnostic accuracy metrics for the BiC-corrected model,\n    evaluated on test data.\n\n    Args:\n        bic_net:      BiC network to use for evaluation\n        tst_logits:   Logits extracted on the test set (for this task)\n        tst_labels:   Test loader (only used for the targets)\n        batch_size:   Batch size to use\n        use_bic:      Forward through the BiC layer to evaluate\n        device:       Torch device to be used\n        metrics:      Recalibration metrics to apply\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "total_acc_tag_top5", ",", "total_acc_tag_top1", ",", "N", "=", "0", ",", "0", ",", "0", "\n", "\n", "# Splitting logits/labels into batches", "\n", "tst_logits", "=", "torch", ".", "split", "(", "tst_logits", ",", "batch_size", ")", "\n", "tst_labels", "=", "torch", ".", "split", "(", "tst_labels", ",", "batch_size", ")", "\n", "\n", "for", "logits", ",", "targets", "in", "zip", "(", "tst_logits", ",", "tst_labels", ")", ":", "\n", "            ", "logits", "=", "logits", ".", "to", "(", "device", ")", "\n", "targets", "=", "targets", ".", "to", "(", "device", ")", "\n", "\n", "# Applying the recalibration factor", "\n", "if", "metrics", ":", "\n", "                ", "logits", "=", "recalibrate", "(", "bic_net", ".", "t", "-", "1", ",", "metrics", ",", "logits", ")", "\n", "\n", "# Applying BiC correction", "\n", "", "if", "use_bic", ":", "\n", "                ", "outputs", "=", "bic_net", ".", "forward", "(", "logits", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "logits", "\n", "\n", "", "hits_tag_top5", ",", "hits_tag_top1", "=", "calculate_metrics", "(", "outputs", ",", "targets", ")", "\n", "\n", "# Task Agnostic top-5 accuracies", "\n", "total_acc_tag_top5", "+=", "hits_tag_top5", "\n", "total_acc_tag_top1", "+=", "hits_tag_top1", "\n", "N", "+=", "len", "(", "targets", ")", "\n", "\n", "", "", "return", "total_acc_tag_top5", "/", "N", ",", "total_acc_tag_top1", "/", "N", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.bic_train": [[251, 363], ["print", "bic_net.train_init", "torch.optim.Adam", "bic_net.print_parameters", "copy.deepcopy", "range", "print", "copy.deepcopy.print_parameters", "bic_net.trainable_p", "time.time", "collections.Counter", "time.time", "logits.to.to", "targets.to.to", "bic_net.forward", "torch.cat", "torch.nn.functional.cross_entropy", "bic_net.beta_l2", "calibrate_bic.compute_topk_acc", "torch.optim.Adam.zero_grad", "bic_net.beta_l2.backward", "torch.optim.Adam.step", "print", "print", "copy.deepcopy", "calibrate_bic.recalibrate", "bic_net.beta_l2.item", "len", "print", "int"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.train_init", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.print_parameters", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.print_parameters", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.trainable_p", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet.forward", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.beta_l2", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.compute_topk_acc", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.recalibrate"], ["", "def", "bic_train", "(", "bic_net", ",", "bic_loader", ",", "n_epochs", ",", "lr", ",", "patience", ",", "device", ",", "metrics", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Train for a single task.\n\n    Args:\n        bic_net:     BiC network to use for evaluation\n        bic_loader:  Validation loader for the current task\n        n_epochs:    Number of epochs to train the BiC layer over\n        lr:          Learning rate\n        patience:    False to disable learning rate diminution after train accuracy stagnation\n        device:      Device to use\n        metrics:     Recalibration metrics to apply\n    \"\"\"", "\n", "print", "(", "\"Training BiC layer...\"", ")", "\n", "\n", "# Setting trainable parameters", "\n", "bic_net", ".", "train_init", "(", ")", "\n", "\n", "# Using Adam as the main optimizer (better than SGD for this task)", "\n", "bic_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "bic_net", ".", "trainable_p", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "0.005", ")", "\n", "bic_net", ".", "print_parameters", "(", ")", "\n", "\n", "# Stopping after max_patience epochs if accuracy does not improve", "\n", "if", "not", "patience", ":", "\n", "        ", "patience", "=", "n_epochs", "*", "2", "\n", "", "current_patience", "=", "0", "\n", "min_lr", "=", "1e-5", "\n", "prev_acc", "=", "-", "1", "\n", "\n", "# Epochs loop", "\n", "class_count", "=", "False", "\n", "best_bic", "=", "deepcopy", "(", "bic_net", ")", "\n", "best_acc", "=", "0", "\n", "\n", "# Accuracy metric to use for training evaluation", "\n", "topk", "=", "5", "\n", "\n", "for", "e", "in", "range", "(", "n_epochs", ")", ":", "\n", "# Train bias correction layers", "\n", "        ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "total_loss", ",", "total_acc", "=", "0", ",", "0", "\n", "N", "=", "0", "\n", "\n", "dic_c", "=", "Counter", "(", ")", "\n", "for", "logits", ",", "targets", "in", "bic_loader", ":", "\n", "            ", "logits", "=", "logits", ".", "to", "(", "device", ")", "\n", "targets", "=", "targets", ".", "to", "(", "device", ")", "\n", "\n", "# (for the new class: alpha=1, beta=0.)", "\n", "all_outs", "=", "bic_net", ".", "forward", "(", "logits", ")", "\n", "pred_all_classes", "=", "torch", ".", "cat", "(", "all_outs", ",", "dim", "=", "1", ")", "\n", "\n", "if", "metrics", ":", "\n", "                ", "pred_all_classes", "=", "recalibrate", "(", "bic_net", ".", "t", "-", "1", ",", "metrics", ",", "pred_all_classes", ")", "\n", "\n", "# Outputs from all tasks are modified, except for the new task (alpha=1,beta=0 fixed for last task)", "\n", "", "loss", "=", "torch", ".", "nn", ".", "functional", ".", "cross_entropy", "(", "pred_all_classes", ",", "targets", ")", "\n", "loss", "=", "bic_net", ".", "beta_l2", "(", "loss", ",", "lambd", "=", "0.1", ")", "\n", "\n", "# Log", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "*", "len", "(", "targets", ")", "\n", "total_acc", "+=", "compute_topk_acc", "(", "pred_all_classes", ",", "targets", ",", "topk", ")", "\n", "\n", "# Backward", "\n", "bic_optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "bic_optimizer", ".", "step", "(", ")", "\n", "\n", "N", "+=", "logits", ".", "shape", "[", "0", "]", "\n", "if", "not", "class_count", ":", "\n", "                ", "for", "t", "in", "targets", ":", "\n", "                    ", "dic_c", "[", "int", "(", "t", ")", "]", "+=", "1", "\n", "\n", "# scheduler.step(e)", "\n", "", "", "", "clock1", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "not", "class_count", ":", "\n", "            ", "print", "(", "\"Seen classes count :: \"", ",", "dic_c", ")", "\n", "class_count", "=", "True", "\n", "\n", "# Printing training status", "\n", "", "train_acc", "=", "100", "*", "(", "total_acc", "/", "N", ")", "\n", "if", "(", "e", "%", "25", ")", "==", "0", "or", "train_acc", ">", "best_acc", ":", "\n", "            ", "bst", "=", "\"*\"", "if", "(", "train_acc", ">", "best_acc", ")", "else", "\" \"", "\n", "print", "(", "bst", ",", "'| Epoch {:3d}, time={:5.1f}s | Train: loss={:.3f}, Top-{:d} Train TAg acc={:5.2f}% |'", "\n", ".", "format", "(", "e", "+", "1", ",", "clock1", "-", "clock0", ",", "total_loss", "/", "N", ",", "topk", ",", "train_acc", ")", ")", "\n", "\n", "# Updating patience", "\n", "", "if", "train_acc", "<=", "prev_acc", ":", "\n", "            ", "current_patience", "+=", "1", "\n", "", "else", ":", "\n", "            ", "current_patience", "=", "0", "\n", "", "prev_acc", "=", "train_acc", "\n", "\n", "if", "current_patience", ">", "patience", ":", "\n", "            ", "if", "lr", "/", "10", ">", "min_lr", ":", "\n", "                ", "lr", "/=", "10", "\n", "old_lr", "=", "bic_optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "bic_optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr", "\n", "print", "(", "'| Epoch {:3d}: train_acc not improving, lr changed to {:.8f} from {:.8f}'", "\n", ".", "format", "(", "e", "+", "1", ",", "lr", ",", "old_lr", ")", ")", "\n", "current_patience", "=", "0", "\n", "\n", "# Saving the best model", "\n", "", "", "if", "train_acc", ">", "best_acc", ":", "\n", "            ", "best_bic", "=", "deepcopy", "(", "bic_net", ")", "\n", "best_acc", "=", "train_acc", "\n", "\n", "", "", "print", "(", ")", "\n", "best_bic", ".", "print_parameters", "(", ")", "\n", "\n", "return", "best_bic", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.bic_train_grid": [[365, 445], ["print", "copy.deepcopy", "numpy.arange", "numpy.arange", "bic_net.print_parameters", "print", "copy.deepcopy.print_parameters", "print", "print", "exit", "len", "len", "torch.no_grad", "print", "collections.Counter", "logits.to.to", "targets.to.to", "bic_net.set_alpha", "bic_net.set_beta", "bic_net.forward", "torch.cat", "calibrate_bic.compute_topk_acc", "print", "print", "copy.deepcopy", "int"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.print_parameters", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.print_parameters", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.set_alpha", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.set_beta", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet.forward", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.compute_topk_acc"], ["", "def", "bic_train_grid", "(", "bic_net", ",", "bic_loader", ",", "grid_p", ",", "method", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Train the model using a gridsearch approach.\n\n    Args:\n        bic_net:     BiC network to use for evaluation\n        bic_loader:  Validation loader for the current task\n        grid_p:      Grid precision\n        method:      Forward method to use\n        device:      Device to use\n    \"\"\"", "\n", "print", "(", "\"Training BiC layer...\"", ")", "\n", "\n", "if", "method", "==", "CalibrationMethod", ".", "ADAPTIVE", ":", "\n", "        ", "print", "(", "\"Gridsearch incompatible with adaptiveBiC.\"", ")", "\n", "exit", "(", "-", "1", ")", "\n", "\n", "# Epochs loop", "\n", "", "class_count", "=", "False", "\n", "best_bic", "=", "deepcopy", "(", "bic_net", ")", "\n", "best_acc", "=", "0", "\n", "\n", "# Generating parameter spaces", "\n", "alpha_p", "=", "np", ".", "arange", "(", "0.5", ",", "1.", ",", "grid_p", ")", "\n", "beta_p", "=", "np", ".", "arange", "(", "-", "0.5", ",", "0.5", ",", "grid_p", ")", "\n", "\n", "# Printing first parameters", "\n", "bic_net", ".", "print_parameters", "(", ")", "\n", "\n", "it_tot", "=", "len", "(", "alpha_p", ")", "*", "len", "(", "beta_p", ")", "\n", "it_cur", "=", "0", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "alpha", "in", "alpha_p", ":", "\n", "            ", "it_per", "=", "(", "it_cur", "/", "it_tot", ")", "*", "100", "\n", "print", "(", "\"Explored %d %% of the parameter space.\\n\"", "%", "it_per", ")", "\n", "for", "beta", "in", "beta_p", ":", "\n", "                ", "it_cur", "+=", "1", "\n", "\n", "# Train bias correction layers", "\n", "N", "=", "0", "\n", "total_acc", "=", "0", "\n", "\n", "dic_c", "=", "Counter", "(", ")", "\n", "for", "logits", ",", "targets", "in", "bic_loader", ":", "\n", "                    ", "logits", "=", "logits", ".", "to", "(", "device", ")", "\n", "targets", "=", "targets", ".", "to", "(", "device", ")", "\n", "\n", "# Setting alpha and beta values on the last layer", "\n", "bic_net", ".", "set_alpha", "(", "alpha", ")", "\n", "bic_net", ".", "set_beta", "(", "beta", ")", "\n", "\n", "# Forwarding through the current model", "\n", "all_outs", "=", "bic_net", ".", "forward", "(", "logits", ")", "\n", "pred_all_classes", "=", "torch", ".", "cat", "(", "all_outs", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute accuracy of current model", "\n", "total_acc", "+=", "compute_topk_acc", "(", "pred_all_classes", ",", "targets", ",", "5", ")", "\n", "\n", "N", "+=", "logits", ".", "shape", "[", "0", "]", "\n", "for", "t", "in", "targets", ":", "\n", "                        ", "dic_c", "[", "int", "(", "t", ")", "]", "+=", "1", "\n", "\n", "", "", "train_acc", "=", "100", "*", "(", "total_acc", "/", "N", ")", "\n", "\n", "if", "not", "class_count", ":", "\n", "                    ", "print", "(", "\"Seen classes count :: \"", ",", "dic_c", ")", "\n", "class_count", "=", "True", "\n", "\n", "# Saving the best model", "\n", "", "if", "train_acc", ">", "best_acc", ":", "\n", "                    ", "print", "(", "\"New best model found! Top-5 Acc: {:5.2f}%\"", ".", "format", "(", "train_acc", ")", ")", "\n", "best_bic", "=", "deepcopy", "(", "bic_net", ")", "\n", "best_acc", "=", "train_acc", "\n", "\n", "", "", "", "", "print", "(", ")", "\n", "best_bic", ".", "print_parameters", "(", ")", "\n", "print", "(", "\"-----------\"", ")", "\n", "\n", "return", "best_bic", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.make_bic_loader": [[447, 488], ["torch.split", "torch.split", "zip", "range", "torch.split", "torch.split", "zip"], "function", ["None"], ["", "def", "make_bic_loader", "(", "t", ",", "val_logits", ",", "val_labels", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"\n    Mixing all validation logits from previous and new classes.\n        Previous and old classes logits must all have a number of dimensions\n        equal to the total number of seen classes at time t.\n        Thus, previous logits must be obtained by forwarding all validation sets\n        through the model at time t.\n\n    Args:\n        t:            Current test task identifier\n        val_logits:   List of validation logits for all tasks val. sets,\n                      from the model at time t.\n        val_labels:   Validation loader for all tasks.\n        batch_size:   Current batch size\n    \"\"\"", "\n", "\n", "new_val_tuples", "=", "[", "]", "\n", "new_cls_batches", "=", "0", "\n", "\n", "# Fetching targets/logits from new classes", "\n", "logits", "=", "torch", ".", "split", "(", "val_logits", "[", "t", "]", ",", "batch_size", ")", "\n", "labels", "=", "torch", ".", "split", "(", "val_labels", "[", "t", "]", ",", "batch_size", ")", "\n", "for", "lg", ",", "tg", "in", "zip", "(", "logits", ",", "labels", ")", ":", "\n", "        ", "new_val_tuples", "+=", "[", "(", "lg", ",", "tg", ")", "]", "\n", "new_cls_batches", "+=", "1", "\n", "\n", "# Fetching targets/logits from old classes", "\n", "# -> Create logits/targets tensor, filter by class count and concatenate, and at the end split into batches", "\n", "", "old_val_tuples", "=", "[", "]", "\n", "\n", "for", "k", "in", "range", "(", "t", ")", ":", "\n", "# Splitting logits in batches", "\n", "        ", "logits", "=", "torch", ".", "split", "(", "val_logits", "[", "k", "]", ",", "batch_size", ")", "\n", "labels", "=", "torch", ".", "split", "(", "val_labels", "[", "k", "]", ",", "batch_size", ")", "\n", "\n", "old_cls_batches", "=", "0", "\n", "for", "lg", ",", "tg", "in", "zip", "(", "logits", ",", "labels", ")", ":", "\n", "            ", "old_val_tuples", "+=", "[", "(", "lg", ",", "tg", ")", "]", "\n", "old_cls_batches", "+=", "1", "\n", "\n", "", "", "return", "old_val_tuples", "+", "new_val_tuples", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.main": [[490, 621], ["warnings.filterwarnings", "calibrate_bic.parse_args", "utils.seed_everything", "torch.cuda.is_available", "adaptive_bic.BiCNet().to", "time.time", "range", "utils.print_summary", "print", "print", "print", "print", "print", "torch.cuda.set_device", "print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "print", "print", "print", "bic_train.add_head", "range", "utils.print_summary", "adaptive_bic.BiCNet", "range", "calibrate_bic.read_logits", "calibrate_bic.read_labels", "calibrate_bic.bic_eval", "print", "torch.save", "print", "calibrate_bic.average_scores", "range", "calibrate_bic.make_bic_loader", "torch.load", "bic_train.load_state_dict", "calibrate_bic.bic_eval", "print", "bic_train.state_dict", "calibrate_bic.read_logits", "print", "calibrate_bic.bic_train_grid", "calibrate_bic.bic_train", "time.time", "calibrate_bic.read_labels"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.seed_everything", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.print_summary", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.adaptive_bic.BiCNet.add_head", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.print_summary", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.read_logits", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.read_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.bic_eval", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.average_scores", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.make_bic_loader", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.bic_eval", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.read_logits", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.bic_train_grid", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.bic_train", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.calibrate_bic.read_labels"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Calibrating BiC parameters for each 1..n-1 task.\n    \"\"\"", "\n", "# Filtering EXIF warnings", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "\"(Possibly )?corrupt EXIF data\"", ",", "UserWarning", ")", "\n", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "if", "args", ".", "bic_models_dir", ":", "\n", "        ", "print", "(", "\"BiC parameters supplied: running in eval mode using [%s].\"", "%", "args", ".", "bic_models_dir", ")", "\n", "\n", "# Fixing random seed", "\n", "", "utils", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "# Selecting device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "device", "=", "'cuda'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'WARNING: CUDA unavailable, using CPU instead!'", ")", "\n", "device", "=", "'cpu'", "\n", "\n", "# Average metrics for recalibration", "\n", "# mapping t :-> u(M_t) mean of top-1 predictions in model t", "\n", "", "avg_metrics", "=", "{", "}", "\n", "\n", "# Storing evaluation metrics", "\n", "max_task", "=", "args", ".", "num_tasks", "\n", "acc_tag_top5", "=", "(", "np", ".", "zeros", "(", "(", "max_task", ",", "max_task", ")", ")", ",", "np", ".", "zeros", "(", "(", "max_task", ",", "max_task", ")", ")", ")", "\n", "acc_tag_top1", "=", "(", "np", ".", "zeros", "(", "(", "max_task", ",", "max_task", ")", ")", ",", "np", ".", "zeros", "(", "(", "max_task", ",", "max_task", ")", ")", ")", "\n", "\n", "# Initializing BicNet", "\n", "bic_net", "=", "BiCNet", "(", "device", ",", "args", ".", "calib_method", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Main loop", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "num_tasks", ")", ":", "\n", "        ", "print", "(", "'*'", "*", "108", ")", "\n", "print", "(", "'Task {:2d}'", ".", "format", "(", "t", ")", ")", "\n", "print", "(", "'*'", "*", "108", ")", "\n", "\n", "# Adding a head to the BiC layer", "\n", "bic_net", ".", "add_head", "(", ")", "\n", "\n", "# Loading validation logits for this task", "\n", "if", "t", ">", "0", "or", "args", ".", "recalibrate", ":", "\n", "            ", "val_logits", "=", "[", "]", "\n", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "                ", "val_logits_file", "=", "\"%s/logits/logits_val_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", "\n", "val_logits", "+=", "[", "read_logits", "(", "val_logits_file", ")", "]", "\n", "print", "(", "\"Loaded val logits from: %s\"", "%", "val_logits_file", ")", "\n", "\n", "# Computing mean top-1 scores", "\n", "", "if", "args", ".", "recalibrate", ":", "\n", "                ", "avg_metrics", "[", "t", "]", "=", "average_scores", "(", "t", ",", "val_logits", ",", "bic_net", ",", "device", ")", "\n", "\n", "# Training the layer, if not in evaluation mode", "\n", "", "if", "t", ">", "0", "and", "not", "(", "args", ".", "bic_models_dir", "or", "args", ".", "eval_only", ")", ":", "\n", "# Loading validation labels for model t", "\n", "                ", "val_labels", "=", "[", "]", "\n", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "                    ", "val_labels_file", "=", "\"%s/logits/labels_val_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", "\n", "val_labels", "+=", "[", "read_labels", "(", "val_labels_file", ")", "]", "\n", "print", "(", "\"Loaded val logits from: %s\"", "%", "val_labels_file", ")", "\n", "\n", "# Training the layer", "\n", "", "bic_loader", "=", "make_bic_loader", "(", "t", ",", "val_logits", ",", "val_labels", ",", "args", ".", "batch_size", ")", "\n", "\n", "if", "args", ".", "gridsearch", ":", "\n", "# TODO: Remove gridsearch code", "\n", "                    ", "bic_net", "=", "bic_train_grid", "(", "bic_net", ",", "bic_loader", ",", "\n", "args", ".", "step", ",", "args", ".", "calib_method", ",", "\n", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "                    ", "bic_net", "=", "bic_train", "(", "bic_net", ",", "bic_loader", ",", "\n", "args", ".", "nepochs", ",", "args", ".", "lr", ",", "\n", "args", ".", "patience", ",", "\n", "device", "=", "device", ",", "metrics", "=", "avg_metrics", ")", "\n", "\n", "# Evaluating the model on the test set", "\n", "", "", "", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "# Loading output logits of model t on test set u", "\n", "            ", "tst_logits_file", "=", "\"%s/logits/logits_tst_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", "\n", "tst_logits", "=", "read_logits", "(", "tst_logits_file", ")", "\n", "\n", "# Loading labels for model t on test set u", "\n", "tst_labels_file", "=", "\"%s/logits/labels_tst_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", "\n", "tst_labels", "=", "read_labels", "(", "tst_labels_file", ")", "\n", "\n", "# Loading a trained BiC model", "\n", "if", "args", ".", "bic_models_dir", "and", "not", "args", ".", "eval_only", ":", "\n", "                ", "bic_model_file", "=", "\"%s/bic_model_%d.ckpt\"", "%", "(", "args", ".", "bic_models_dir", ",", "t", ")", "\n", "bic_state_dict", "=", "torch", ".", "load", "(", "bic_model_file", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "bic_net", ".", "load_state_dict", "(", "bic_state_dict", ")", "\n", "\n", "", "if", "not", "args", ".", "eval_only", ":", "\n", "# -> with BiC:", "\n", "                ", "acc_tag_top5", "[", "0", "]", "[", "t", ",", "u", "]", ",", "acc_tag_top1", "[", "0", "]", "[", "t", ",", "u", "]", "=", "bic_eval", "(", "bic_net", ",", "\n", "tst_logits", ",", "tst_labels", ",", "\n", "args", ".", "batch_size", ",", "\n", "use_bic", "=", "True", ",", "device", "=", "device", ",", "\n", "metrics", "=", "avg_metrics", ")", "\n", "\n", "print", "(", "'>>> With    BiC on task {:2d} : | Top-5 TAg acc={:5.2f}% | Top-1 TAg acc={:5.2f}% <<<'", ".", "\n", "format", "(", "u", ",", "100", "*", "acc_tag_top5", "[", "0", "]", "[", "t", ",", "u", "]", ",", "100", "*", "acc_tag_top1", "[", "0", "]", "[", "t", ",", "u", "]", ")", ")", "\n", "\n", "# -> without BiC:", "\n", "", "acc_tag_top5", "[", "1", "]", "[", "t", ",", "u", "]", ",", "acc_tag_top1", "[", "1", "]", "[", "t", ",", "u", "]", "=", "bic_eval", "(", "bic_net", ",", "\n", "tst_logits", ",", "tst_labels", ",", "\n", "args", ".", "batch_size", ",", "\n", "use_bic", "=", "False", ",", "device", "=", "device", ",", "\n", "metrics", "=", "avg_metrics", ")", "\n", "print", "(", "'>>> Without BiC on task {:2d} : | Top-5 TAg acc={:5.2f}% | Top-1 TAg acc={:5.2f}% <<<'", ".", "\n", "format", "(", "u", ",", "100", "*", "acc_tag_top5", "[", "1", "]", "[", "t", ",", "u", "]", ",", "100", "*", "acc_tag_top1", "[", "1", "]", "[", "t", ",", "u", "]", ")", ")", "\n", "\n", "# Saving learned parameters", "\n", "", "if", "args", ".", "bic_models_outdir", "and", "not", "args", ".", "bic_models_dir", ":", "\n", "            ", "bic_model_file", "=", "\"%s/bic_model_%d.ckpt\"", "%", "(", "args", ".", "bic_models_outdir", ",", "t", ")", "\n", "torch", ".", "save", "(", "bic_net", ".", "state_dict", "(", ")", ",", "bic_model_file", ")", "\n", "\n", "# Print Summary", "\n", "", "", "if", "not", "args", ".", "eval_only", ":", "\n", "        ", "utils", ".", "print_summary", "(", "[", "acc_tag_top5", "[", "0", "]", ",", "acc_tag_top1", "[", "0", "]", "]", ",", "[", "'Top-5 TAg Acc (BiC)'", ",", "'Top-1 TAg Acc (BiC)'", "]", ")", "\n", "", "utils", ".", "print_summary", "(", "[", "acc_tag_top5", "[", "1", "]", ",", "acc_tag_top1", "[", "1", "]", "]", ",", "[", "'Top-5 TAg Acc (raw)'", ",", "'Top-1 TAg Acc (raw)'", "]", ")", "\n", "print", "(", "'[Elapsed time = {:.1f} mn]'", ".", "format", "(", "(", "time", ".", "time", "(", ")", "-", "tstart", ")", "/", "60", ")", ")", "\n", "print", "(", "'Done!'", ")", "\n", "\n", "print", "(", "'-'", "*", "108", ")", "\n", "print", "(", "\"All tasks optimized and evaluated.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.basic_step.parse_args": [[25, 80], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "int", "print", "print", "list", "datasets.dataset_config.dataset_config.keys"], "function", ["None"], ["def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Training a model for the first (non-incremental) step.'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'GPU (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--models-dir'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save the basic step model.'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--datasets'", ",", "default", "=", "[", "'cif100'", "]", ",", "type", "=", "str", ",", "choices", "=", "list", "(", "dataset_config", ".", "keys", "(", ")", ")", ",", "\n", "help", "=", "'Dataset or datasets used (default=%(default)s)'", ",", "nargs", "=", "'+'", ",", "metavar", "=", "\"DATASET\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of subprocesses to use for dataloader (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pin-memory'", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Copy Tensors into CUDA pinned memory before returning them (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Real batch size, before gradient accumulation (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--eff-batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Effective batch size, after gradient accumulation (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Test batch size (default=%(default)s)'", ")", "\n", "\n", "# training args", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Starting learning rate (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-decay'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Learning rate decay (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "default", "=", "0.0005", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Weight decay (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Momentum (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepochs'", ",", "default", "=", "200", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of epochs per training session (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "default", "=", "60", ",", "required", "=", "False", ",", "\n", "help", "=", "'Use patience while training (default=%(default)s)'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "\n", "args", ".", "iter_size", "=", "int", "(", "args", ".", "eff_batch_size", "/", "args", ".", "batch_size", ")", "\n", "\n", "# Printing input arguments", "\n", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.basic_step.main": [[82, 216], ["warnings.filterwarnings", "basic_step.parse_args", "utils.seed_everything", "datasets.data_loader.get_loaders", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torchvision.models.resnet18", "model.to.to", "torch.CrossEntropyLoss", "torch.SGD", "copy.deepcopy", "copy.deepcopy", "torch.optim.lr_scheduler.ReduceLROnPlateau", "print", "print", "time.time", "range", "print", "os.path.exists", "os.makedirs", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "print", "model.to.parameters", "optim.SGD.zero_grad", "model.to.train", "enumerate", "lr_scheduler.ReduceLROnPlateau.step", "model.to.eval", "print", "os.path.join", "print", "print", "torch.save", "torch.save", "torch.save", "model.to.", "nn.CrossEntropyLoss.", "criterion.backward", "criterion.data.item", "criterion.cpu().data.numpy", "model.to.", "utils.calculate_metrics", "len", "float", "float", "copy.deepcopy", "copy.deepcopy", "time.time", "datetime.timedelta", "copy.deepcopy.state_dict", "copy.deepcopy.state_dict", "images.to", "targets.to", "optim.SGD.step", "optim.SGD.zero_grad", "images.to", "targets.to", "datetime.timedelta", "str", "round", "criterion.cpu", "round", "time.time"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.seed_everything", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_loaders", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.resnet18", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.calculate_metrics"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Main training routine.\n    \"\"\"", "\n", "# Filtering EXIF warnings", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "\"(Possibly )?corrupt EXIF data\"", ",", "UserWarning", ")", "\n", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "\n", "# Fixing random seed", "\n", "utils", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "# Creating output model directories", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "models_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "models_dir", ")", "\n", "\n", "# Instantiating data loaders", "\n", "", "trn_loader", ",", "val_loader", ",", "tst_loader", ",", "taskcla", "=", "get_loaders", "(", "args", ".", "datasets", ",", "\n", "args", ".", "num_tasks", ",", "None", ",", "\n", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "\n", "force_order", "=", "True", ")", "\n", "trn_loader", "=", "trn_loader", "[", "0", "]", "\n", "val_loader", "=", "tst_loader", "[", "0", "]", "\n", "\n", "# - S: Total number of states", "\n", "# - P: Number of new classes in state 0", "\n", "S", ",", "P", "=", "taskcla", "[", "0", "]", "\n", "\n", "# Selecting device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "device", "=", "'cuda'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'WARNING: CUDA unavailable, using CPU instead!'", ")", "\n", "device", "=", "'cpu'", "\n", "\n", "# Creating model", "\n", "", "model", "=", "models", ".", "resnet18", "(", "pretrained", "=", "False", ",", "num_classes", "=", "P", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "# Defining loss and optimizer", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "lr", ",", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "\n", "best_val_acc", "=", "-", "1", "\n", "best_epoch", "=", "0", "\n", "best_model", "=", "deepcopy", "(", "model", ")", "\n", "best_optimizer", "=", "deepcopy", "(", "optimizer", ")", "\n", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "\n", "patience", "=", "args", ".", "patience", ",", "\n", "factor", "=", "args", ".", "lr_decay", ")", "\n", "\n", "# Training", "\n", "print", "(", "\"-\"", "*", "20", ")", "\n", "print", "(", "\"Training...\"", ")", "\n", "starting_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "nepochs", ")", ":", "\n", "# Training the model", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "loss", "=", "None", "\n", "running_loss", "=", "0.0", "\n", "nb_batches", "=", "0", "\n", "new_best", "=", "False", "\n", "\n", "for", "i", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "trn_loader", ")", ":", "\n", "            ", "nb_batches", "+=", "1", "\n", "images", ",", "targets", "=", "images", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "\n", "# Forward + backward + optimize", "\n", "outputs", "=", "model", "(", "images", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "loss", ".", "data", "/=", "args", ".", "iter_size", "\n", "loss", ".", "backward", "(", ")", "\n", "running_loss", "+=", "loss", ".", "data", ".", "item", "(", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "args", ".", "iter_size", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "", "scheduler", ".", "step", "(", "loss", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "# Evaluating the model", "\n", "model", ".", "eval", "(", ")", "\n", "total_top5_hits", ",", "total_top1_hits", ",", "N", "=", "0", ",", "0", ",", "0", "\n", "for", "images", ",", "targets", "in", "val_loader", ":", "\n", "            ", "images", ",", "targets", "=", "images", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "model", "(", "images", ")", "\n", "top5_hits", ",", "top1_hits", "=", "utils", ".", "calculate_metrics", "(", "outputs", ",", "targets", ")", "\n", "\n", "total_top5_hits", "+=", "top5_hits", "\n", "total_top1_hits", "+=", "top1_hits", "\n", "N", "+=", "len", "(", "targets", ")", "\n", "\n", "", "top1_avg", "=", "float", "(", "total_top1_hits", ")", "/", "N", "\n", "top5_avg", "=", "float", "(", "total_top5_hits", ")", "/", "N", "\n", "\n", "if", "top1_avg", ">", "best_val_acc", ":", "\n", "            ", "best_val_acc", "=", "top1_avg", "\n", "best_model", "=", "deepcopy", "(", "model", ")", "\n", "best_optimizer", "=", "deepcopy", "(", "optimizer", ")", "\n", "best_epoch", "=", "epoch", "\n", "new_best", "=", "True", "\n", "\n", "", "current_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "starting_time", "\n", "print", "(", "'{:03}/{:03} | {} | Train : loss = {:.4f} | Val : acc@1 = {:.3f}% ; acc@5 = {:.3f}%  {:s}'", ".", "\n", "format", "(", "epoch", "+", "1", ",", "args", ".", "nepochs", ",", "\n", "timedelta", "(", "seconds", "=", "round", "(", "current_elapsed_time", ")", ")", ",", "\n", "running_loss", "/", "nb_batches", ",", "\n", "top1_avg", "*", "100", ",", "top5_avg", "*", "100", ",", "\n", "\"*\"", "if", "new_best", "else", "\"\"", ")", ")", "\n", "\n", "", "print", "(", "'Finished training, elapsed training time : {}'", ".", "format", "(", "\n", "timedelta", "(", "seconds", "=", "round", "(", "time", ".", "time", "(", ")", "-", "starting_time", ")", ")", ")", ")", "\n", "\n", "# Training finished", "\n", "if", "best_model", "is", "not", "None", ":", "\n", "        ", "saved_model", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "'task0.ckpt'", ")", "\n", "\n", "print", "(", "'Saved best model at: ['", "+", "saved_model", "+", "']'", ")", "\n", "state", "=", "{", "\n", "'epoch'", ":", "best_epoch", ",", "\n", "'state_dict'", ":", "best_model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "best_optimizer", ".", "state_dict", "(", ")", ",", "\n", "'best_val_acc'", ":", "best_val_acc", "\n", "}", "\n", "print", "(", "'best acc = '", "+", "str", "(", "best_val_acc", ")", ")", "\n", "torch", ".", "save", "(", "state", ",", "saved_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.seed_everything": [[12, 22], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "str"], "function", ["None"], ["def", "seed_everything", "(", "seed", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Fixing all random seeds\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "cudnn_deterministic", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.print_summary": [[24, 55], ["zip", "print", "print", "print", "range", "print", "print", "print", "range", "print", "print", "numpy.trace", "print", "numpy.mean", "print", "metric[].mean", "metric[].mean"], "function", ["None"], ["", "def", "print_summary", "(", "metrics_list", ",", "labels_list", ")", ":", "\n", "    ", "\"\"\"\n    Print metrics summary across incremental states\n\n    Args:\n        metrics_list: Network prediction\n        labels_list:  List of labels for the given metrics\n    \"\"\"", "\n", "for", "metric", ",", "name", "in", "zip", "(", "metrics_list", ",", "labels_list", ")", ":", "\n", "        ", "print", "(", "'*'", "*", "108", ")", "\n", "print", "(", "name", ")", "\n", "mean_inc_acc", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "metric", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "print", "(", "'\\t'", ",", "end", "=", "''", ")", "\n", "for", "j", "in", "range", "(", "metric", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "print", "(", "'{:5.2f}% '", ".", "format", "(", "100", "*", "metric", "[", "i", ",", "j", "]", ")", ",", "end", "=", "''", ")", "\n", "", "if", "np", ".", "trace", "(", "metric", ")", "==", "0.0", ":", "\n", "                ", "if", "i", ">", "0", ":", "\n", "                    ", "avg", "=", "100", "*", "metric", "[", "i", ",", ":", "i", "]", ".", "mean", "(", ")", "\n", "mean_inc_acc", "+=", "[", "avg", "]", "\n", "print", "(", "'\\tAvg.:{:5.2f}% '", ".", "format", "(", "avg", ")", ",", "end", "=", "''", ")", "\n", "", "", "else", ":", "\n", "                ", "avg", "=", "100", "*", "metric", "[", "i", ",", ":", "i", "+", "1", "]", ".", "mean", "(", ")", "\n", "mean_inc_acc", "+=", "[", "avg", "]", "\n", "print", "(", "'\\tAvg.:{:5.2f}% '", ".", "format", "(", "avg", ")", ",", "end", "=", "''", ")", "\n", "", "print", "(", ")", "\n", "", "print", "(", ")", "\n", "\n", "# Computing AIA across all incremental states (thus excluding the first non-incremental state)", "\n", "print", "(", "'\\tMean Incremental Acc.: {:5.2f}%'", ".", "format", "(", "np", ".", "mean", "(", "mean_inc_acc", "[", "1", ":", "]", ")", ")", ")", "\n", "", "print", "(", "'*'", "*", "108", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.compute_topk_acc": [[57, 73], ["min", "pred.t.topk", "pred.t.t", "pred.t.eq", "correct[].reshape().float().sum", "targets.view().expand_as", "correct[].reshape().float", "targets.view", "correct[].reshape"], "function", ["None"], ["", "def", "compute_topk_acc", "(", "pred", ",", "targets", ",", "topk", ")", ":", "\n", "    ", "\"\"\"\n    Computing top-k accuracy given prediction and target vectors.\n\n    Args:\n        pred:    Network prediction\n        targets: Ground truth labels\n        topk:    k value\n    \"\"\"", "\n", "topk", "=", "min", "(", "topk", ",", "pred", ".", "shape", "[", "1", "]", ")", "\n", "_", ",", "pred", "=", "pred", ".", "topk", "(", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "targets", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "hits_tag", "=", "correct", "[", ":", "topk", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "\n", "return", "hits_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.calculate_metrics": [[75, 90], ["utils.compute_topk_acc", "utils.compute_topk_acc", "compute_topk_acc.item", "compute_topk_acc.item"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.compute_topk_acc", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.compute_topk_acc"], ["", "def", "calculate_metrics", "(", "outputs", ",", "targets", ")", ":", "\n", "    ", "\"\"\"\n    Computing top-1 and top-5 task-agnostic accuracy metrics.\n\n    Args:\n        outputs: Network outputs list\n        targets: Ground truth labels\n    \"\"\"", "\n", "pred", "=", "outputs", "\n", "\n", "# Top-k prediction for TAg", "\n", "hits_tag_top5", "=", "compute_topk_acc", "(", "pred", ",", "targets", ",", "5", ")", "\n", "hits_tag_top1", "=", "compute_topk_acc", "(", "pred", ",", "targets", ",", "1", ")", "\n", "\n", "return", "hits_tag_top5", ".", "item", "(", ")", ",", "hits_tag_top1", ".", "item", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.convert_logits.parse_args": [[11, 34], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "os.path.expanduser", "print", "print"], "function", ["None"], ["def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Converting saved logits from numpy to torch format.'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--logits-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save task logits'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "\n", "# Updating paths", "\n", "args", ".", "logits_dir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "logits_dir", ")", "\n", "\n", "# Printing input arguments", "\n", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.convert_logits.to_torch": [[36, 48], ["numpy.load", "torch.save", "torch.from_numpy"], "function", ["None"], ["", "def", "to_torch", "(", "file_name", ")", ":", "\n", "    ", "\"\"\"\n    Convert an input numpy matrix to torch format.\n\n    Args:\n        file_name:  File name of the .npy file to be converted\n    \"\"\"", "\n", "full_file", "=", "\"%s.npy\"", "%", "file_name", "\n", "np_mat", "=", "np", ".", "load", "(", "full_file", ")", "\n", "\n", "full_file", "=", "\"%s.ckpt\"", "%", "file_name", "\n", "torch", ".", "save", "(", "torch", ".", "from_numpy", "(", "np_mat", ")", ",", "full_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.convert_logits.main": [[50, 87], ["warnings.filterwarnings", "convert_logits.parse_args", "range", "print", "print", "os.listdir", "print", "print", "print", "print", "range", "print", "item.endswith", "convert_logits.to_torch", "convert_logits.to_torch", "convert_logits.to_torch", "convert_logits.to_torch", "os.remove", "os.path.join"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.convert_logits.to_torch", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.convert_logits.to_torch", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.convert_logits.to_torch", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.convert_logits.to_torch"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Extracting output logits and saving them in the \"results_path\" folder.\n    \"\"\"", "\n", "# Filtering EXIF warnings", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "\"(Possibly )?corrupt EXIF data\"", ",", "UserWarning", ")", "\n", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "\n", "# Iterating over", "\n", "for", "t", "in", "range", "(", "args", ".", "num_tasks", ")", ":", "\n", "        ", "print", "(", "'*'", "*", "108", ")", "\n", "print", "(", "'Task {:2d}'", ".", "format", "(", "t", ")", ")", "\n", "print", "(", "'*'", "*", "108", ")", "\n", "\n", "# Extracting and serializing validation and test logits", "\n", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "# Validation logits/labels", "\n", "            ", "to_torch", "(", "\"%slogits_val_%d_%d\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", ")", "\n", "to_torch", "(", "\"%slabels_val_%d_%d\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", ")", "\n", "\n", "# Test logits/labels", "\n", "to_torch", "(", "\"%slogits_tst_%d_%d\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", ")", "\n", "to_torch", "(", "\"%slabels_tst_%d_%d\"", "%", "(", "args", ".", "logits_dir", ",", "t", ",", "u", ")", ")", "\n", "\n", "", "print", "(", "'-'", "*", "108", ")", "\n", "\n", "", "print", "(", "\"All output logits succesfully converted!\"", ")", "\n", "print", "(", "\"Deleting numpy logits...\"", ",", "end", "=", "\" \"", ")", "\n", "\n", "# Deleting numpy logits", "\n", "for", "item", "in", "os", ".", "listdir", "(", "args", ".", "logits_dir", ")", ":", "\n", "        ", "if", "item", ".", "endswith", "(", "\".npy\"", ")", ":", "\n", "            ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "args", ".", "logits_dir", ",", "item", ")", ")", "\n", "\n", "", "", "print", "(", "\"Done.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.load_model": [[35, 148], ["torchvision.models.resnet18.to", "range", "net.fc.parameters", "torch.split", "torch.split", "list", "torch.no_grad", "torch.load", "torch.mean", "torch.std", "zip", "torch.nn.Linear", "os.path.isfile", "print", "exit", "torchvision.models.resnet18.load_state_dict", "torchvision.models.resnet18.set_state_dict", "torchvision.models.resnet18.fc.parameters", "print", "print", "enumerate", "torchvision.models.resnet18", "extract_logits.load_model.get_heads"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.resnet18"], ["def", "load_model", "(", "state", ",", "base_net", ",", "model_load_path", ",", "model_type", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Loading a serialized model (FACIL/LwF-compatible/LUCIR-compatible/torchvision-compatible)\n\n    Args:\n        state:\n            t:  Incremental state index\n            S:  Total number of states\n            P:  Number of new classes in each state (should be constant)\n        base_net:        Previously loaded model\n        model_load_path: Serialized model full path\n        model_type:      Accomodate for loading method-specific models\n        device:          Torch device to be used\n    \"\"\"", "\n", "def", "normalize_mat", "(", "W_", ")", ":", "\n", "        ", "\"\"\"\n        Normalizing a weight matrix W, class-wise.\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "W_", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "mu", "=", "torch", ".", "mean", "(", "W_", "[", "i", "]", ")", "\n", "std", "=", "torch", ".", "std", "(", "W_", "[", "i", "]", ")", "\n", "W_", "[", "i", "]", "=", "(", "W_", "[", "i", "]", "-", "mu", ")", "/", "std", "\n", "\n", "", "", "def", "get_heads", "(", "net", ",", "P_", ")", ":", "\n", "        ", "\"\"\"\n        Fetching the heads of a network.\n\n        Args:\n            net: Network\n            P_:  Number of classes in each head\n        \"\"\"", "\n", "W_", ",", "b_", "=", "net", ".", "fc", ".", "parameters", "(", ")", "\n", "\n", "W_split", "=", "torch", ".", "split", "(", "W_", ",", "P_", ")", "\n", "b_split", "=", "torch", ".", "split", "(", "b_", ",", "P_", ")", "\n", "\n", "return", "list", "(", "zip", "(", "W_split", ",", "b_split", ")", ")", "\n", "\n", "", "t", ",", "S", ",", "P", "=", "state", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Instantiating the base network", "\n", "        ", "first_init", "=", "False", "\n", "if", "base_net", "is", "None", ":", "\n", "            ", "first_init", "=", "True", "\n", "\n", "if", "model_type", "in", "CUSTOM_MODELS", ":", "\n", "                ", "base_net", "=", "torchvision", ".", "models", ".", "resnet18", "(", "pretrained", "=", "False", ",", "num_classes", "=", "0", ")", "\n", "\n", "", "if", "model_type", "in", "SIW_METHODS", ":", "\n", "                ", "base_net", ".", "init_heads", "=", "[", "]", "\n", "\n", "# Adding new heads", "\n", "", "", "if", "model_type", "in", "CUSTOM_MODELS", ":", "\n", "            ", "base_net", ".", "fc", "=", "torch", ".", "nn", ".", "Linear", "(", "512", ",", "(", "t", "+", "1", ")", "*", "P", ")", "\n", "\n", "# Loading the state dictionary", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "model_load_path", ")", ":", "\n", "            ", "print", "(", "\"File: %s\"", "%", "model_load_path", ",", "\" not found. Stopping at this task.\"", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "# Loading model weights", "\n", "", "state_dict", "=", "torch", ".", "load", "(", "model_load_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "if", "model_type", "in", "CUSTOM_MODELS", ":", "\n", "            ", "base_net", ".", "load_state_dict", "(", "state_dict", "[", "'state_dict'", "]", ")", "\n", "", "else", ":", "\n", "            ", "base_net", ".", "set_state_dict", "(", "state_dict", ")", "\n", "\n", "# Applying SiW - specific methods", "\n", "", "if", "model_type", "in", "SIW_METHODS", ":", "\n", "# Normalizing heads weights, class-wise", "\n", "            ", "if", "model_type", "==", "ModelType", ".", "CUSTOM_SIW", ":", "\n", "                ", "for", "head", "in", "get_heads", "(", "base_net", ",", "P", ")", ":", "\n", "                    ", "W", ",", "b", "=", "head", "\n", "normalize_mat", "(", "W", ")", "\n", "\n", "# DEBUG", "\n", "", "for", "j", ",", "head", "in", "enumerate", "(", "get_heads", "(", "base_net", ",", "P", ")", ")", ":", "\n", "                    ", "W", ",", "b", "=", "head", "\n", "print", "(", "\"W[%d]::shape = \"", "%", "j", ",", "W", ".", "shape", ")", "\n", "print", "(", "\"W[%d]::mean = \"", "%", "j", ",", "round", "(", "float", "(", "torch", ".", "mean", "(", "W", ")", ")", ",", "3", ")", ")", "\n", "print", "(", "\"W[%d]::std = \"", "%", "j", ",", "round", "(", "float", "(", "torch", ".", "std", "(", "W", ")", ")", ",", "3", ")", ")", "\n", "print", "(", ")", "\n", "# ----------------------------", "\n", "\n", "# Saving the initial head learned for the last task", "\n", "", "", "W", ",", "b", "=", "get_heads", "(", "base_net", ",", "P", ")", "[", "-", "1", "]", "\n", "base_net", ".", "init_heads", "+=", "[", "(", "torch", ".", "clone", "(", "W", ")", ",", "torch", ".", "clone", "(", "b", ")", ")", "]", "\n", "\n", "# Restoring all of the initial heads", "\n", "if", "not", "first_init", ":", "\n", "                ", "W", ",", "b", "=", "base_net", ".", "fc", ".", "parameters", "(", ")", "\n", "for", "j", ",", "init_head", "in", "enumerate", "(", "base_net", ".", "init_heads", ")", ":", "\n", "                    ", "W_0", ",", "b_0", "=", "init_head", "\n", "W", ".", "data", "[", "j", "*", "P", ":", "(", "j", "+", "1", ")", "*", "P", ",", "]", "=", "W_0", "\n", "b", ".", "data", "[", "j", "*", "P", ":", "(", "j", "+", "1", ")", "*", "P", "]", "=", "b_0", "\n", "\n", "# DEBUG", "\n", "", "", "W", ",", "b", "=", "base_net", ".", "fc", ".", "parameters", "(", ")", "\n", "print", "(", "\"W::shape\"", ",", "W", ".", "data", ".", "shape", ")", "\n", "\n", "print", "(", "\"Number of heads: %d \"", "%", "len", "(", "get_heads", "(", "base_net", ",", "P", ")", ")", ")", "\n", "for", "j", ",", "(", "head", ",", "init_head", ")", "in", "enumerate", "(", "zip", "(", "get_heads", "(", "base_net", ",", "P", ")", ",", "base_net", ".", "init_heads", ")", ")", ":", "\n", "                ", "W", ",", "_", "=", "head", "\n", "print", "(", "\" W[%d] :: %d x %d\"", "%", "(", "j", ",", "W", ".", "shape", "[", "0", "]", ",", "W", ".", "shape", "[", "1", "]", ")", ")", "\n", "print", "(", "\" W[%d] :: \"", "%", "j", ",", "[", "round", "(", "float", "(", "v", ")", ",", "3", ")", "for", "v", "in", "W", "[", "0", "]", "[", "30", ":", "45", "]", "]", "+", "[", "\"...\"", "]", ")", "\n", "\n", "W", ",", "_", "=", "init_head", "\n", "print", "(", "\"*W[%d] :: \"", "%", "j", ",", "[", "round", "(", "float", "(", "v", ")", ",", "3", ")", "for", "v", "in", "W", "[", "0", "]", "[", "30", ":", "45", "]", "]", "+", "[", "\"...\"", "]", ")", "\n", "print", "(", ")", "\n", "###########", "\n", "\n", "", "", "", "return", "base_net", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.parse_args": [[150, 208], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "os.path.expanduser", "os.path.expanduser", "os.path.join", "print", "print", "list", "datasets.dataset_config.dataset_config.keys"], "function", ["None"], ["", "def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extracting validation and test logits for each incremental state.'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'GPU (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed (default=%(default)s)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--models-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory containing serialized models'", ")", "\n", "parser", ".", "add_argument", "(", "'--logits-outdir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save task logits'", ")", "\n", "parser", ".", "add_argument", "(", "'--models-base-name'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Base serialized PyTorch task model name'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--datasets'", ",", "default", "=", "[", "'cifar100'", "]", ",", "type", "=", "str", ",", "choices", "=", "list", "(", "dataset_config", ".", "keys", "(", ")", ")", ",", "\n", "help", "=", "'Dataset or datasets used (default=%(default)s)'", ",", "nargs", "=", "'+'", ",", "metavar", "=", "\"DATASET\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of subprocesses to use for dataloader (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pin-memory'", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Copy Tensors into CUDA pinned memory before returning them (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of samples per batch to load (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "\n", "# model args", "\n", "parser", ".", "add_argument", "(", "'--network'", ",", "default", "=", "'resnet18'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Network architecture used (default=%(default)s)'", ",", "metavar", "=", "\"NETWORK\"", ")", "\n", "\n", "model_types", "=", "{", "'base'", ":", "ModelType", ".", "BASE", ",", "\n", "'ft'", ":", "ModelType", ".", "CUSTOM_FT", ",", "\n", "'siw-init'", ":", "ModelType", ".", "CUSTOM_INIT_REPLAY", ",", "\n", "'siw'", ":", "ModelType", ".", "CUSTOM_SIW", "}", "\n", "parser", ".", "add_argument", "(", "'--model-type'", ",", "type", "=", "str", ",", "default", "=", "'base'", ",", "\n", "help", "=", "'Use a specific model type when loading checkpoints'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "\n", "# Base model to use", "\n", "args", ".", "model_type", "=", "model_types", "[", "args", ".", "model_type", "]", "\n", "\n", "# Updating paths", "\n", "args", ".", "models_dir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "models_dir", ")", "\n", "args", ".", "logits_outdir", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "logits_outdir", ")", "\n", "args", ".", "models_base_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "args", ".", "models_base_name", ")", "\n", "\n", "# Printing input arguments", "\n", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.extract_logits": [[210, 239], ["torch.tensor().to", "torch.tensor().to", "torch.no_grad", "net.eval", "torch.tensor", "torch.tensor", "targets.to.to", "net", "isinstance", "torch.cat", "torch.cat", "images.to", "torch.cat"], "function", ["None"], ["", "def", "extract_logits", "(", "net", ",", "loader", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Extracting output logits using the supplied network.\n\n    Args:\n        net:    Instantiated model\n        loader: Loader for the current task\n        device: Torch device to be used\n    \"\"\"", "\n", "all_logits", "=", "torch", ".", "tensor", "(", "[", "]", ")", ".", "to", "(", "device", ")", "\n", "all_labels", "=", "torch", ".", "tensor", "(", "[", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Defining a feature extractor", "\n", "        ", "net", ".", "eval", "(", ")", "\n", "\n", "for", "images", ",", "targets", "in", "loader", ":", "\n", "# Forwarding through current model", "\n", "            ", "targets", "=", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "net", "(", "images", ".", "to", "(", "device", ")", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "list", ")", ":", "\n", "                ", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "\n", "# Concatenating to output matrix", "\n", "", "all_logits", "=", "torch", ".", "cat", "(", "(", "all_logits", ",", "outputs", ")", ")", "\n", "all_labels", "=", "torch", ".", "cat", "(", "(", "all_labels", ",", "targets", ")", ")", "\n", "\n", "", "", "return", "all_logits", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.main": [[241, 312], ["warnings.filterwarnings", "extract_logits.parse_args", "utils.seed_everything", "torch.cuda.is_available", "datasets.data_loader.get_loaders", "enumerate", "print", "torch.cuda.set_device", "print", "os.path.exists", "os.makedirs", "print", "print", "print", "extract_logits.load_model", "print", "range", "print", "extract_logits.extract_logits", "torch.save", "torch.save", "print", "print", "extract_logits.extract_logits", "torch.save", "torch.save", "print", "print"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.utils.seed_everything", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_loaders", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.load_model", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.extract_logits", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.src.extract_logits.extract_logits"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Extracting and saving output logits.\n    \"\"\"", "\n", "# Filtering EXIF warnings", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "\"(Possibly )?corrupt EXIF data\"", ",", "UserWarning", ")", "\n", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "\n", "# Fixing random seed", "\n", "utils", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "# Selecting device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "device", "=", "'cuda'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'WARNING: CUDA unavailable, using CPU instead!'", ")", "\n", "device", "=", "'cpu'", "\n", "\n", "# Instantiating data loaders", "\n", "", "_", ",", "val_loader", ",", "tst_loader", ",", "taskcla", "=", "get_loaders", "(", "args", ".", "datasets", ",", "args", ".", "num_tasks", ",", "None", ",", "\n", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "\n", "force_order", "=", "True", ")", "\n", "\n", "# Creating output logits dir, if necessary", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "logits_outdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "logits_outdir", ")", "\n", "\n", "# Main loop", "\n", "", "net", "=", "None", "\n", "\n", "# - P: Number of new classes per state", "\n", "for", "t", ",", "(", "_", ",", "P", ")", "in", "enumerate", "(", "taskcla", ")", ":", "\n", "        ", "print", "(", "'*'", "*", "108", ")", "\n", "print", "(", "'Task {:2d}'", ".", "format", "(", "t", ")", ")", "\n", "print", "(", "'*'", "*", "108", ")", "\n", "\n", "# Loading the network for this task", "\n", "task_model", "=", "\"%s%d.ckpt\"", "%", "(", "args", ".", "models_base_path", ",", "t", ")", "\n", "net", "=", "load_model", "(", "(", "t", ",", "args", ".", "num_tasks", ",", "P", ")", ",", "\n", "net", ",", "task_model", ",", "args", ".", "model_type", ",", "device", ")", "\n", "print", "(", "\"Loaded task model from: %s\"", "%", "task_model", ")", "\n", "\n", "# Extracting and serializing validation and test logits", "\n", "for", "u", "in", "range", "(", "t", "+", "1", ")", ":", "\n", "# val:", "\n", "            ", "val_logits", ",", "val_labels", "=", "extract_logits", "(", "net", ",", "val_loader", "[", "u", "]", ",", "device", ")", "\n", "val_logits_file", "=", "\"%slogits_val_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "val_logits", ",", "val_logits_file", ")", "\n", "val_labels_file", "=", "\"%slabels_val_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "val_labels", ",", "val_labels_file", ")", "\n", "\n", "print", "(", "'Val logits shape: '", ",", "val_logits", ".", "shape", ")", "\n", "print", "(", "'Val labels shape: '", ",", "val_labels", ".", "shape", ")", "\n", "\n", "# test:", "\n", "tst_logits", ",", "tst_labels", "=", "extract_logits", "(", "net", ",", "tst_loader", "[", "u", "]", ",", "device", ")", "\n", "tst_logits_file", "=", "\"%slogits_tst_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "tst_logits", ",", "tst_logits_file", ")", "\n", "tst_labels_file", "=", "\"%slabels_tst_%d_%d.ckpt\"", "%", "(", "args", ".", "logits_outdir", ",", "t", ",", "u", ")", "\n", "torch", ".", "save", "(", "tst_labels", ",", "tst_labels_file", ")", "\n", "\n", "print", "(", "'Test logits shape: '", ",", "tst_logits", ".", "shape", ")", "\n", "print", "(", "'Test labels shape: '", ",", "tst_labels", ".", "shape", ")", "\n", "\n", "", "print", "(", "'-'", "*", "108", ")", "\n", "\n", "", "print", "(", "\"All output logits succesfully saved!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.split_images_labels": [[5, 13], ["images.append", "labels.append", "numpy.array", "numpy.array"], "function", ["None"], ["def", "split_images_labels", "(", "imgs", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "item", "in", "imgs", ":", "\n", "        ", "images", ".", "append", "(", "item", "[", "0", "]", ")", "\n", "labels", ".", "append", "(", "item", "[", "1", "]", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "images", ")", ",", "np", ".", "array", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.split_images_labels_paths": [[15, 25], ["images.append", "labels.append", "paths.append", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "split_images_labels_paths", "(", "imgs", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "paths", "=", "[", "]", "\n", "for", "item", "in", "imgs", ":", "\n", "        ", "images", ".", "append", "(", "item", "[", "0", "]", ")", "\n", "labels", ".", "append", "(", "item", "[", "1", "]", ")", "\n", "paths", ".", "append", "(", "item", "[", "2", "]", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "images", ")", ",", "np", ".", "array", "(", "labels", ")", ",", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.merge_images_labels": [[27, 37], ["list", "list", "range", "len", "len", "len", "imgs.append"], "function", ["None"], ["", "def", "merge_images_labels", "(", "images", ",", "labels", ")", ":", "\n", "    ", "images", "=", "list", "(", "images", ")", "\n", "labels", "=", "list", "(", "labels", ")", "\n", "assert", "(", "len", "(", "images", ")", "==", "len", "(", "labels", ")", ")", "\n", "imgs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "images", ")", ")", ":", "\n", "        ", "item", "=", "(", "images", "[", "i", "]", ",", "labels", "[", "i", "]", ")", "\n", "imgs", ".", "append", "(", "item", ")", "\n", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.save_protosets": [[39, 46], ["os.path.join", "open", "open.close", "open.write", "int", "str"], "function", ["None"], ["", "def", "save_protosets", "(", "current_eval_set", ",", "ckp_prefix", ",", "b", ",", "output_dir", ")", ":", "\n", "    ", "ckp_name", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "ckp_prefix", "+", "'_protoset_{}.lst'", ".", "format", "(", "b", ")", ")", "\n", "protoset_file", "=", "open", "(", "ckp_name", ",", "'w'", ")", "\n", "for", "protoset", "in", "current_eval_set", ":", "\n", "        ", "path", ",", "class_", "=", "protoset", "[", "0", "]", ",", "int", "(", "protoset", "[", "1", "]", ")", "\n", "protoset_file", ".", "write", "(", "path", "+", "' '", "+", "str", "(", "class_", ")", "+", "'\\n'", ")", "\n", "", "protoset_file", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.ImagesFolder.__init__": [[42, 69], ["open().readlines", "list", "e.strip.strip.strip", "int", "samples.append", "len", "RuntimeError", "set", "open", "e.strip.strip.split", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "print", "sys.exit", "e.strip.strip.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "images_list_file", ",", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "return_path", "=", "False", ")", ":", "\n", "        ", "self", ".", "return_path", "=", "return_path", "\n", "images_list_file", "=", "open", "(", "images_list_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "samples", "=", "[", "]", "\n", "for", "e", "in", "images_list_file", ":", "\n", "            ", "e", "=", "e", ".", "strip", "(", ")", "\n", "image_path", "=", "e", ".", "split", "(", ")", "[", "0", "]", "\n", "try", ":", "\n", "                ", "assert", "(", "os", ".", "path", ".", "exists", "(", "image_path", ")", ")", "\n", "", "except", "AssertionError", ":", "\n", "                ", "print", "(", "'Cant find '", "+", "image_path", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "", "image_class", "=", "int", "(", "e", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "samples", ".", "append", "(", "(", "image_path", ",", "image_class", ")", ")", "\n", "\n", "", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"No image found\"", ")", ")", "\n", "\n", "", "self", ".", "loader", "=", "default_loader", "\n", "self", ".", "extensions", "=", "IMG_EXTENSIONS", "\n", "self", ".", "classes", "=", "list", "(", "set", "(", "[", "e", "[", "1", "]", "for", "e", "in", "samples", "]", ")", ")", "\n", "self", ".", "samples", "=", "samples", "\n", "self", ".", "targets", "=", "[", "s", "[", "1", "]", "for", "s", "in", "samples", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "imgs", "=", "self", ".", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.ImagesFolder.__getitem__": [[70, 87], ["utils_loader.ImagesFolder.loader", "utils_loader.ImagesFolder.transform", "utils_loader.ImagesFolder.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "if", "self", ".", "return_path", ":", "\n", "            ", "return", "(", "sample", ",", "target", ")", ",", "self", ".", "samples", "[", "index", "]", "[", "0", "]", "\n", "", "return", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.ImagesFolder.__len__": [[88, 90], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.ImagesFolder.__repr__": [[91, 100], ["utils_loader.ImagesFolder.__len__", "utils_loader.ImagesFolder.transform.__repr__().replace", "utils_loader.ImagesFolder.target_transform.__repr__().replace", "utils_loader.ImagesFolder.transform.__repr__", "utils_loader.ImagesFolder.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__len__", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.ImagesFolder.__repr__", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.ImagesFolder.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.pil_loader": [[8, 12], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.default_loader": [[14, 16], ["utils_loader.pil_loader"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_loader.pil_loader"], ["", "", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.lucir.parse_args": [[34, 99], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "int", "os.path.join", "os.path.join", "print", "print"], "function", ["None"], ["def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Training the LwF baseline.'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--models-dir'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save the basic step model.'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--datasets'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Dataset or datasets used (default=%(default)s)'", ",", "nargs", "=", "'+'", ",", "metavar", "=", "\"DATASET\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Real batch size, before gradient accumulation (default=%(default)s)'", ")", "\n", "\n", "# training args", "\n", "parser", ".", "add_argument", "(", "'--adapt-lambda'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Adjust lambda after each task (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambd'", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Lambda base value (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--less-forget'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "\n", "help", "=", "'Use the less-forget constraint (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Starting learning rate (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-factor'", ",", "default", "=", "5.", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Learning rate decay factor (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-strat'", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "'Learning rate scheduler strategy (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "default", "=", "0.00001", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Weight decay (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'SGD momentum (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of subprocesses to use for dataloader (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepochs'", ",", "default", "=", "200", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of epochs per training session (default=%(default)s)'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "args", ".", "datasets", "=", "args", ".", "datasets", "[", "0", "]", "\n", "\n", "# Total number of classes", "\n", "args", ".", "num_classes_total", "=", "dataset_config", "[", "args", ".", "datasets", "]", "[", "'num_classes'", "]", "\n", "\n", "# Number of classes per task", "\n", "args", ".", "num_classes", "=", "int", "(", "args", ".", "num_classes_total", "/", "args", ".", "num_tasks", ")", "\n", "\n", "# Defining training/validation sets lists", "\n", "lists_path", "=", "dataset_config", "[", "args", ".", "datasets", "]", "[", "'path'", "]", "\n", "args", ".", "train_list", "=", "os", ".", "path", ".", "join", "(", "lists_path", ",", "'train_no_val.lst'", ")", "\n", "args", ".", "test_list", "=", "os", ".", "path", ".", "join", "(", "lists_path", ",", "'test.lst'", ")", "\n", "\n", "# Loading dataset statistics", "\n", "args", ".", "images_stats", "=", "dataset_config", "[", "args", ".", "datasets", "]", "[", "'normalize'", "]", "\n", "\n", "# Printing input arguments", "\n", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.lucir.main": [[101, 435], ["lucir.parse_args", "warnings.filterwarnings", "numpy.random.seed", "torch.device", "torch.device", "torch.device", "torch.device", "torchvision.transforms.Normalize", "utils_loader.ImagesFolder", "utils_loader.ImagesFolder", "utils_loader.ImagesFolder", "utils_dataset.split_images_labels", "utils_dataset.split_images_labels", "numpy.arange", "list", "range", "numpy.array", "max", "numpy.zeros", "range", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "numpy.array", "numpy.array", "X_valid_cumuls.append", "X_train_cumuls.append", "numpy.concatenate", "Y_valid_cumuls.append", "Y_train_cumuls.append", "numpy.concatenate", "print", "numpy.array", "numpy.array", "utils_dataset.merge_images_labels", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "utils_dataset.merge_images_labels", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "print", "os.path.join", "print", "modified_resnet.resnet18.to", "torch.SGD", "torch.optim.lr_scheduler.MultiStepLR", "print", "utils_incremental.train_eval_LF.train_eval_LF", "torch.save", "torch.save", "torch.save", "torch.save", "print", "torch.Sequential", "print", "numpy.zeros", "range", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "numpy.array", "utils_dataset.merge_images_labels", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "utils_incremental.compute_accuracy.compute_accuracy", "print", "numpy.array", "utils_dataset.merge_images_labels", "utils_dataset.save_protosets", "top1_cnn_cumul_acc.append", "top5_cnn_cumul_acc.append", "top1_icarl_cumul_acc.append", "top5_icarl_cumul_acc.append", "top1_ncm_cumul_acc.append", "top5_ncm_cumul_acc.append", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "print", "print", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "range", "len", "int", "modified_resnet.resnet18", "print", "print", "print", "print", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "print", "modified_resnet.resnet18.fc.fc1.weight.data.norm", "torch.mean().to().type", "torch.mean().to().type", "torch.mean().to().type", "torch.mean().to().type", "torch.Sequential", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "modified_resnet.resnet18.to", "torch.zeros.to", "list", "filter", "modified_resnet.resnet18.parameters", "copy.deepcopy.to", "os.path.isdir", "os.makedirs", "range", "numpy.concatenate", "float", "float", "float", "float", "float", "float", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "numpy.where", "copy.deepcopy", "print", "modified_linear.SplitCosineLinear", "copy.deepcopy", "print", "modified_linear.SplitCosineLinear", "math.sqrt", "list.index", "list.index", "numpy.array", "utils_dataset.merge_images_labels", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "utils_incremental.compute_features.compute_features", "torch.normalize", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "str", "min", "max", "min", "max", "map", "modified_resnet.resnet18.parameters", "str", "utils_dataset.merge_images_labels", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "utils_incremental.compute_features.compute_features", "X_protoset_cumuls.append", "Y_protoset_cumuls.append", "numpy.linalg.norm", "numpy.linalg.norm", "list.index", "list.index", "str", "str", "str", "str", "str", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "torch.mean().to", "torch.mean().to", "torch.mean().to", "torch.mean().to", "len", "numpy.zeros", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.normalize", "len", "modified_resnet.resnet18.fc.fc1.parameters", "modified_resnet.resnet18.fc.fc1.parameters", "list", "numpy.zeros", "numpy.linalg.norm", "numpy.sum", "numpy.ones", "numpy.concatenate", "str", "str", "str", "str", "str", "str", "list", "len", "id", "modified_resnet.resnet18.children", "range", "len", "numpy.ones", "numpy.dot", "numpy.dot", "numpy.dot", "numpy.dot", "range", "range", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "modified_resnet.resnet18.children", "numpy.where", "len", "range", "numpy.where", "numpy.where"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.split_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.split_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.merge_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.merge_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.train_eval_LF.train_eval_LF", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.merge_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.compute_accuracy.compute_accuracy", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.merge_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.save_protosets", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.resnet18", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.merge_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.compute_features.compute_features", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_dataset.merge_images_labels", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.compute_features.compute_features"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Main training routine.\n    \"\"\"", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "\n", "# Filtering EXIF warnings", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "\"(Possibly )?corrupt EXIF data\"", ",", "UserWarning", ")", "\n", "\n", "# Defining output models prefixes", "\n", "ckp_prefix", "=", "'{}_s{}_k{}'", ".", "format", "(", "args", ".", "datasets", ",", "args", ".", "num_tasks", ",", "0", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Defining device", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "# Instantiating dataloaders", "\n", "dataset_mean", ",", "dataset_std", "=", "args", ".", "images_stats", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "dataset_mean", ",", "std", "=", "dataset_std", ")", "\n", "\n", "trainset", "=", "ImagesFolder", "(", "\n", "args", ".", "train_list", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ")", "\n", "\n", "testset", "=", "ImagesFolder", "(", "\n", "args", ".", "test_list", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "]", ")", ")", "\n", "\n", "evalset", "=", "ImagesFolder", "(", "\n", "args", ".", "test_list", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "]", ")", ")", "\n", "################################", "\n", "\n", "# Initialization", "\n", "X_train_total", ",", "Y_train_total", "=", "split_images_labels", "(", "trainset", ".", "imgs", ")", "\n", "X_valid_total", ",", "Y_valid_total", "=", "split_images_labels", "(", "testset", ".", "imgs", ")", "\n", "\n", "top1_cnn_cumul_acc", "=", "[", "]", "\n", "top5_cnn_cumul_acc", "=", "[", "]", "\n", "top1_icarl_cumul_acc", "=", "[", "]", "\n", "top5_icarl_cumul_acc", "=", "[", "]", "\n", "top1_ncm_cumul_acc", "=", "[", "]", "\n", "top5_ncm_cumul_acc", "=", "[", "]", "\n", "\n", "# Defining the class order", "\n", "order", "=", "np", ".", "arange", "(", "args", ".", "num_classes_total", ")", "\n", "order_list", "=", "list", "(", "order", ")", "\n", "\n", "# Initialization of the variables for this run", "\n", "X_valid_cumuls", "=", "[", "]", "\n", "X_protoset_cumuls", "=", "[", "]", "\n", "X_train_cumuls", "=", "[", "]", "\n", "Y_valid_cumuls", "=", "[", "]", "\n", "Y_protoset_cumuls", "=", "[", "]", "\n", "Y_train_cumuls", "=", "[", "]", "\n", "\n", "# The following contains all the training samples of the different classes", "\n", "# because we want to compare our method with the theoretical case where all the training samples are stored", "\n", "prototypes", "=", "[", "[", "]", "for", "_", "in", "range", "(", "args", ".", "num_classes_total", ")", "]", "\n", "for", "orde", "in", "range", "(", "args", ".", "num_classes_total", ")", ":", "\n", "        ", "prototypes", "[", "orde", "]", "=", "X_train_total", "[", "np", ".", "where", "(", "Y_train_total", "==", "order", "[", "orde", "]", ")", "]", "\n", "\n", "", "prototypes", "=", "np", ".", "array", "(", "prototypes", ")", "\n", "max_class_len", "=", "max", "(", "len", "(", "e", ")", "for", "e", "in", "prototypes", ")", "\n", "\n", "alpha_dr_herding", "=", "np", ".", "zeros", "(", "(", "int", "(", "args", ".", "num_classes_total", "/", "args", ".", "num_classes", ")", ",", "\n", "max_class_len", ",", "args", ".", "num_classes", ")", ",", "np", ".", "float32", ")", "\n", "\n", "for", "b", "in", "range", "(", "0", ",", "args", ".", "num_tasks", ")", ":", "\n", "        ", "if", "b", "==", "0", ":", "\n", "############################################################", "\n", "            ", "last_iter", "=", "0", "\n", "############################################################", "\n", "# initializing the model", "\n", "tg_model", "=", "modified_resnet", ".", "resnet18", "(", "num_classes", "=", "args", ".", "num_classes", ")", "\n", "in_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "out_features", "=", "tg_model", ".", "fc", ".", "out_features", "\n", "print", "(", "\"in_features:\"", ",", "in_features", ",", "\"out_features:\"", ",", "out_features", ")", "\n", "ref_model", "=", "None", "\n", "", "elif", "b", "==", "1", ":", "\n", "############################################################", "\n", "            ", "last_iter", "=", "b", "\n", "############################################################", "\n", "# increment classes", "\n", "ref_model", "=", "copy", ".", "deepcopy", "(", "tg_model", ")", "\n", "in_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "out_features", "=", "tg_model", ".", "fc", ".", "out_features", "\n", "print", "(", "\"in_features:\"", ",", "in_features", ",", "\"out_features:\"", ",", "out_features", ")", "\n", "new_fc", "=", "modified_linear", ".", "SplitCosineLinear", "(", "in_features", ",", "out_features", ",", "args", ".", "num_classes", ")", "\n", "new_fc", ".", "fc1", ".", "weight", ".", "data", "=", "tg_model", ".", "fc", ".", "weight", ".", "data", "\n", "new_fc", ".", "sigma", ".", "data", "=", "tg_model", ".", "fc", ".", "sigma", ".", "data", "\n", "tg_model", ".", "fc", "=", "new_fc", "\n", "lamda_mult", "=", "out_features", "*", "1.0", "/", "args", ".", "num_classes", "\n", "", "else", ":", "\n", "############################################################", "\n", "            ", "last_iter", "=", "b", "\n", "############################################################", "\n", "ref_model", "=", "copy", ".", "deepcopy", "(", "tg_model", ")", "\n", "in_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "out_features1", "=", "tg_model", ".", "fc", ".", "fc1", ".", "out_features", "\n", "out_features2", "=", "tg_model", ".", "fc", ".", "fc2", ".", "out_features", "\n", "print", "(", "\"in_features:\"", ",", "in_features", ",", "\n", "\"out_features1:\"", ",", "out_features1", ",", "\n", "\"out_features2:\"", ",", "out_features2", ")", "\n", "new_fc", "=", "modified_linear", ".", "SplitCosineLinear", "(", "in_features", ",", "out_features1", "+", "out_features2", ",", "args", ".", "num_classes", ")", "\n", "new_fc", ".", "fc1", ".", "weight", ".", "data", "[", ":", "out_features1", "]", "=", "tg_model", ".", "fc", ".", "fc1", ".", "weight", ".", "data", "\n", "new_fc", ".", "fc1", ".", "weight", ".", "data", "[", "out_features1", ":", "]", "=", "tg_model", ".", "fc", ".", "fc2", ".", "weight", ".", "data", "\n", "new_fc", ".", "sigma", ".", "data", "=", "tg_model", ".", "fc", ".", "sigma", ".", "data", "\n", "tg_model", ".", "fc", "=", "new_fc", "\n", "lamda_mult", "=", "(", "out_features1", "+", "out_features2", ")", "*", "1.0", "/", "args", ".", "num_classes", "\n", "\n", "", "if", "b", ">", "0", "and", "args", ".", "less_forget", "and", "args", ".", "adapt_lambda", ":", "\n", "            ", "cur_lamda", "=", "args", ".", "lambd", "*", "math", ".", "sqrt", "(", "lamda_mult", ")", "\n", "", "else", ":", "\n", "            ", "cur_lamda", "=", "args", ".", "lambd", "\n", "", "if", "b", ">", "0", "and", "args", ".", "less_forget", ":", "\n", "            ", "print", "(", "\"###############################\"", ")", "\n", "print", "(", "\"Lamda for less forget is set to \"", ",", "cur_lamda", ")", "\n", "print", "(", "\"###############################\"", ")", "\n", "\n", "# Prepare the training data for the current batch of classes", "\n", "", "indices_train_10", "=", "np", ".", "array", "(", "[", "i", "in", "order", "[", "range", "(", "last_iter", "*", "args", ".", "num_classes", ",", "(", "b", "+", "1", ")", "*", "args", ".", "num_classes", ")", "]", "\n", "for", "i", "in", "Y_train_total", "]", ")", "\n", "indices_test_10", "=", "np", ".", "array", "(", "[", "i", "in", "order", "[", "range", "(", "last_iter", "*", "args", ".", "num_classes", ",", "(", "b", "+", "1", ")", "*", "args", ".", "num_classes", ")", "]", "\n", "for", "i", "in", "Y_valid_total", "]", ")", "\n", "\n", "X_train", "=", "X_train_total", "[", "indices_train_10", "]", "\n", "X_valid", "=", "X_valid_total", "[", "indices_test_10", "]", "\n", "X_valid_cumuls", ".", "append", "(", "X_valid", ")", "\n", "X_train_cumuls", ".", "append", "(", "X_train", ")", "\n", "X_valid_cumul", "=", "np", ".", "concatenate", "(", "X_valid_cumuls", ")", "\n", "\n", "Y_train", "=", "Y_train_total", "[", "indices_train_10", "]", "\n", "Y_valid", "=", "Y_valid_total", "[", "indices_test_10", "]", "\n", "Y_valid_cumuls", ".", "append", "(", "Y_valid", ")", "\n", "Y_train_cumuls", ".", "append", "(", "Y_train", ")", "\n", "Y_valid_cumul", "=", "np", ".", "concatenate", "(", "Y_valid_cumuls", ")", "\n", "\n", "if", "b", "!=", "0", ":", "\n", "            ", "X_protoset", "=", "np", ".", "concatenate", "(", "X_protoset_cumuls", ")", "\n", "Y_protoset", "=", "np", ".", "concatenate", "(", "Y_protoset_cumuls", ")", "\n", "X_train", "=", "np", ".", "concatenate", "(", "(", "X_train", ",", "X_protoset", ")", ",", "axis", "=", "0", ")", "\n", "Y_train", "=", "np", ".", "concatenate", "(", "(", "Y_train", ",", "Y_protoset", ")", ")", "\n", "\n", "# Launch the training loop", "\n", "", "print", "(", "'Batch of classes number {0} arrives ...'", ".", "format", "(", "b", "+", "1", ")", ")", "\n", "map_Y_train", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "Y_train", "]", ")", "\n", "map_Y_valid_cumul", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "Y_valid_cumul", "]", ")", "\n", "\n", "# Imprint weights", "\n", "if", "b", ">", "0", ":", "\n", "            ", "print", "(", "\"Imprint weights\"", ")", "\n", "#########################################", "\n", "# compute the average norm of old embdding", "\n", "old_embedding_norm", "=", "tg_model", ".", "fc", ".", "fc1", ".", "weight", ".", "data", ".", "norm", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "average_old_embedding_norm", "=", "torch", ".", "mean", "(", "old_embedding_norm", ",", "dim", "=", "0", ")", ".", "to", "(", "'cpu'", ")", ".", "type", "(", "torch", ".", "DoubleTensor", ")", "\n", "#########################################", "\n", "tg_feature_model", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "tg_model", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "\n", "num_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "novel_embedding", "=", "torch", ".", "zeros", "(", "(", "args", ".", "num_classes", ",", "num_features", ")", ")", "\n", "\n", "for", "cls_idx", "in", "range", "(", "b", "*", "args", ".", "num_classes", ",", "(", "b", "+", "1", ")", "*", "args", ".", "num_classes", ")", ":", "\n", "                ", "cls_indices", "=", "np", ".", "array", "(", "[", "i", "==", "cls_idx", "for", "i", "in", "map_Y_train", "]", ")", "\n", "assert", "(", "len", "(", "np", ".", "where", "(", "cls_indices", "==", "1", ")", "[", "0", "]", ")", "<=", "max_class_len", ")", "\n", "current_eval_set", "=", "merge_images_labels", "(", "X_train", "[", "cls_indices", "]", ",", "np", ".", "zeros", "(", "len", "(", "X_train", "[", "cls_indices", "]", ")", ")", ")", "\n", "evalset", ".", "imgs", "=", "evalset", ".", "samples", "=", "current_eval_set", "\n", "evalloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "evalset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "num_samples", "=", "len", "(", "X_train", "[", "cls_indices", "]", ")", "\n", "cls_features", "=", "compute_features", "(", "tg_feature_model", ",", "evalloader", ",", "num_samples", ",", "num_features", ")", "\n", "norm_features", "=", "F", ".", "normalize", "(", "torch", ".", "from_numpy", "(", "cls_features", ")", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "cls_embedding", "=", "torch", ".", "mean", "(", "norm_features", ",", "dim", "=", "0", ")", "\n", "novel_embedding", "[", "cls_idx", "-", "b", "*", "args", ".", "num_classes", "]", "=", "F", ".", "normalize", "(", "cls_embedding", ",", "p", "=", "2", ",", "\n", "dim", "=", "0", ")", "*", "average_old_embedding_norm", "\n", "", "tg_model", ".", "to", "(", "device", ")", "\n", "tg_model", ".", "fc", ".", "fc2", ".", "weight", ".", "data", "=", "novel_embedding", ".", "to", "(", "device", ")", "\n", "\n", "############################################################", "\n", "", "current_train_imgs", "=", "merge_images_labels", "(", "X_train", ",", "map_Y_train", ")", "\n", "trainset", ".", "imgs", "=", "trainset", ".", "samples", "=", "current_train_imgs", "\n", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "print", "(", "'Training-set size = '", "+", "str", "(", "len", "(", "trainset", ")", ")", ")", "\n", "\n", "current_test_imgs", "=", "merge_images_labels", "(", "X_valid_cumul", ",", "map_Y_valid_cumul", ")", "\n", "testset", ".", "imgs", "=", "testset", ".", "samples", "=", "current_test_imgs", "\n", "testloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "testset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "print", "(", "'Max and Min of train labels: {}, {}'", ".", "format", "(", "min", "(", "map_Y_train", ")", ",", "max", "(", "map_Y_train", ")", ")", ")", "\n", "print", "(", "'Max and Min of valid labels: {}, {}'", ".", "format", "(", "min", "(", "map_Y_valid_cumul", ")", ",", "max", "(", "map_Y_valid_cumul", ")", ")", ")", "\n", "##############################################################", "\n", "ckp_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "ckp_prefix", "+", "'_model_{}.pth'", ".", "format", "(", "b", ")", ")", "\n", "print", "(", "'ckp_name'", ",", "ckp_name", ")", "\n", "\n", "###############################", "\n", "if", "b", ">", "0", "and", "args", ".", "less_forget", ":", "\n", "# fix the embedding of old classes", "\n", "            ", "ignored_params", "=", "list", "(", "map", "(", "id", ",", "tg_model", ".", "fc", ".", "fc1", ".", "parameters", "(", ")", ")", ")", "\n", "base_params", "=", "filter", "(", "lambda", "p", ":", "id", "(", "p", ")", "not", "in", "ignored_params", ",", "\n", "tg_model", ".", "parameters", "(", ")", ")", "\n", "tg_params", "=", "[", "{", "'params'", ":", "base_params", ",", "'lr'", ":", "args", ".", "lr", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "tg_model", ".", "fc", ".", "fc1", ".", "parameters", "(", ")", ",", "'lr'", ":", "0", ",", "'weight_decay'", ":", "0", "}", "]", "\n", "", "else", ":", "\n", "            ", "tg_params", "=", "tg_model", ".", "parameters", "(", ")", "\n", "###############################", "\n", "", "tg_model", "=", "tg_model", ".", "to", "(", "device", ")", "\n", "if", "b", ">", "0", ":", "\n", "            ", "ref_model", "=", "ref_model", ".", "to", "(", "device", ")", "\n", "", "tg_optimizer", "=", "optim", ".", "SGD", "(", "tg_params", ",", "lr", "=", "args", ".", "lr", ",", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "tg_lr_scheduler", "=", "lr_scheduler", ".", "MultiStepLR", "(", "tg_optimizer", ",", "milestones", "=", "args", ".", "lr_strat", ",", "gamma", "=", "args", ".", "lr_factor", ")", "\n", "###############################", "\n", "print", "(", "\"train_eval_LF\"", ")", "\n", "tg_model", "=", "train_eval_LF", "(", "args", ".", "nepochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "\n", "trainloader", ",", "testloader", ",", "\n", "b", ",", "0", ",", "cur_lamda", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "models_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "models_dir", ")", "\n", "", "torch", ".", "save", "(", "tg_model", ",", "ckp_name", ")", "\n", "\n", "# Exemplars", "\n", "nb_protos_cl", "=", "0", "\n", "print", "(", "'nb_protos_cl = '", "+", "str", "(", "nb_protos_cl", ")", ")", "\n", "\n", "tg_feature_model", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "tg_model", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "\n", "num_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "\n", "# Prepare the protoset", "\n", "X_protoset_cumuls", "=", "[", "]", "\n", "Y_protoset_cumuls", "=", "[", "]", "\n", "\n", "# Class means for iCaRL and NCM + Storing the selected exemplars in the protoset", "\n", "print", "(", "'Computing mean-of_exemplars and theoretical mean...'", ")", "\n", "class_means", "=", "np", ".", "zeros", "(", "(", "num_features", ",", "args", ".", "num_classes_total", ",", "2", ")", ")", "\n", "for", "b2", "in", "range", "(", "b", "+", "1", ")", ":", "\n", "            ", "for", "iter_dico", "in", "range", "(", "args", ".", "num_classes", ")", ":", "\n", "                ", "current_cl", "=", "order", "[", "range", "(", "b2", "*", "args", ".", "num_classes", ",", "(", "b2", "+", "1", ")", "*", "args", ".", "num_classes", ")", "]", "\n", "current_eval_set", "=", "merge_images_labels", "(", "prototypes", "[", "b2", "*", "args", ".", "num_classes", "+", "iter_dico", "]", ",", "\n", "np", ".", "zeros", "(", "len", "(", "prototypes", "[", "b2", "*", "args", ".", "num_classes", "+", "iter_dico", "]", ")", ")", ")", "\n", "evalset", ".", "imgs", "=", "evalset", ".", "samples", "=", "current_eval_set", "\n", "evalloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "evalset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "num_samples", "=", "len", "(", "prototypes", "[", "b2", "*", "args", ".", "num_classes", "+", "iter_dico", "]", ")", "\n", "mapped_prototypes", "=", "compute_features", "(", "tg_feature_model", ",", "evalloader", ",", "num_samples", ",", "num_features", ")", "\n", "\n", "D", "=", "mapped_prototypes", ".", "T", "\n", "D", "=", "D", "/", "np", ".", "linalg", ".", "norm", "(", "D", ",", "axis", "=", "0", ")", "\n", "D2", "=", "D", "\n", "\n", "# iCaRL", "\n", "alph", "=", "alpha_dr_herding", "[", "b2", ",", ":", ",", "iter_dico", "]", "\n", "assert", "(", "(", "alph", "[", "num_samples", ":", "]", "==", "0", ")", ".", "all", "(", ")", ")", "\n", "alph", "=", "alph", "[", ":", "num_samples", "]", "\n", "alph", "=", "(", "alph", ">", "0", ")", "*", "(", "alph", "<", "nb_protos_cl", "+", "1", ")", "*", "1.", "\n", "X_protoset_cumuls", ".", "append", "(", "prototypes", "[", "b2", "*", "args", ".", "num_classes", "+", "iter_dico", "]", "[", "np", ".", "where", "(", "alph", "==", "1", ")", "[", "0", "]", "]", ")", "\n", "Y_protoset_cumuls", ".", "append", "(", "\n", "order", "[", "b2", "*", "args", ".", "num_classes", "+", "iter_dico", "]", "*", "np", ".", "ones", "(", "len", "(", "np", ".", "where", "(", "alph", "==", "1", ")", "[", "0", "]", ")", ")", ")", "\n", "alph", "=", "alph", "/", "np", ".", "sum", "(", "alph", ")", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "0", "]", "=", "(", "np", ".", "dot", "(", "D", ",", "alph", ")", "+", "np", ".", "dot", "(", "D2", ",", "alph", ")", ")", "/", "2", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "0", "]", "/=", "np", ".", "linalg", ".", "norm", "(", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "0", "]", ")", "\n", "\n", "# Normal NCM", "\n", "alph", "=", "np", ".", "ones", "(", "num_samples", ")", "/", "num_samples", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "1", "]", "=", "(", "np", ".", "dot", "(", "D", ",", "alph", ")", "+", "np", ".", "dot", "(", "D2", ",", "alph", ")", ")", "/", "2", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "1", "]", "/=", "np", ".", "linalg", ".", "norm", "(", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "1", "]", ")", "\n", "\n", "", "", "class_means_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "models_dir", ",", "ckp_prefix", "+", "'_class_means_{}.pth'", ".", "format", "(", "b", ")", ")", "\n", "\n", "torch", ".", "save", "(", "class_means", ",", "class_means_name", ")", "\n", "\n", "current_means", "=", "class_means", "[", ":", ",", "order", "[", "range", "(", "0", ",", "(", "b", "+", "1", ")", "*", "args", ".", "num_classes", ")", "]", "]", "\n", "##############################################################", "\n", "# Calculate validation error of model on the cumul of classes:", "\n", "map_Y_valid_cumul", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "Y_valid_cumul", "]", ")", "\n", "current_eval_set", "=", "merge_images_labels", "(", "X_valid_cumul", ",", "map_Y_valid_cumul", ")", "\n", "evalset", ".", "imgs", "=", "evalset", ".", "samples", "=", "current_eval_set", "\n", "evalloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "evalset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "cumul_acc", "=", "compute_accuracy", "(", "tg_model", ",", "tg_feature_model", ",", "current_means", ",", "evalloader", ")", "\n", "\n", "###############################", "\n", "print", "(", "'Saving protoset...'", ")", "\n", "map_Y_protoset_cumuls", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "np", ".", "concatenate", "(", "Y_protoset_cumuls", ")", "]", ")", "\n", "current_eval_set", "=", "merge_images_labels", "(", "np", ".", "concatenate", "(", "X_protoset_cumuls", ")", ",", "map_Y_protoset_cumuls", ")", "\n", "save_protosets", "(", "current_eval_set", ",", "ckp_prefix", ",", "b", ",", "args", ".", "models_dir", ")", "\n", "##############################################################", "\n", "\n", "top1_cnn_cumul_acc", ".", "append", "(", "float", "(", "str", "(", "cumul_acc", "[", "0", "]", ")", "[", ":", "6", "]", ")", ")", "\n", "top5_cnn_cumul_acc", ".", "append", "(", "float", "(", "str", "(", "cumul_acc", "[", "1", "]", ")", "[", ":", "6", "]", ")", ")", "\n", "top1_icarl_cumul_acc", ".", "append", "(", "float", "(", "str", "(", "cumul_acc", "[", "2", "]", ")", "[", ":", "6", "]", ")", ")", "\n", "top5_icarl_cumul_acc", ".", "append", "(", "float", "(", "str", "(", "cumul_acc", "[", "3", "]", ")", "[", ":", "6", "]", ")", ")", "\n", "top1_ncm_cumul_acc", ".", "append", "(", "float", "(", "str", "(", "cumul_acc", "[", "4", "]", ")", "[", ":", "6", "]", ")", ")", "\n", "top5_ncm_cumul_acc", ".", "append", "(", "float", "(", "str", "(", "cumul_acc", "[", "5", "]", ")", "[", ":", "6", "]", ")", ")", "\n", "\n", "print", "(", "\"###########################################################\"", ")", "\n", "print", "(", "'TOP-1 detailed Results'", ")", "\n", "print", "(", "'LUCIR - CNN = '", "+", "str", "(", "top1_cnn_cumul_acc", ")", ")", "\n", "print", "(", "'LUCIR - NCM = '", "+", "str", "(", "top1_ncm_cumul_acc", ")", ")", "\n", "print", "(", "'iCaRL       = '", "+", "str", "(", "top1_icarl_cumul_acc", ")", ")", "\n", "print", "(", "\"###########################################################\"", ")", "\n", "print", "(", "'TOP-5 detailed Results'", ")", "\n", "print", "(", "'LUCIR - CNN = '", "+", "str", "(", "top5_cnn_cumul_acc", ")", ")", "\n", "print", "(", "'LUCIR - NCM = '", "+", "str", "(", "top5_ncm_cumul_acc", ")", ")", "\n", "print", "(", "'iCaRL       = '", "+", "str", "(", "top5_icarl_cumul_acc", ")", ")", "\n", "print", "(", "\"###########################################################\"", ")", "\n", "print", "(", "'mean inc accuracy'", ")", "\n", "mean_top1_cnn_cumul_acc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "top1_cnn_cumul_acc", ")", "[", "1", ":", "]", ")", "\n", "mean_top5_cnn_cumul_acc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "top5_cnn_cumul_acc", ")", "[", "1", ":", "]", ")", "\n", "mean_top1_icarl_cumul_acc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "top1_icarl_cumul_acc", ")", "[", "1", ":", "]", ")", "\n", "mean_top5_icarl_cumul_acc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "top5_icarl_cumul_acc", ")", "[", "1", ":", "]", ")", "\n", "mean_top1_ncm_cumul_acc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "top1_ncm_cumul_acc", ")", "[", "1", ":", "]", ")", "\n", "mean_top5_ncm_cumul_acc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "top5_ncm_cumul_acc", ")", "[", "1", ":", "]", ")", "\n", "print", "(", "\n", "'LUCIR - CNN | acc@1 = {:.2f} \\t acc@5 = {:.2f} '", ".", "format", "(", "mean_top1_cnn_cumul_acc", ",", "mean_top5_cnn_cumul_acc", ")", ")", "\n", "print", "(", "\n", "'LUCIR - NCM | acc@1 = {:.2f} \\t acc@5 = {:.2f} '", ".", "format", "(", "mean_top1_ncm_cumul_acc", ",", "mean_top5_ncm_cumul_acc", ")", ")", "\n", "print", "(", "'iCaRL       | acc@1 = {:.2f} \\t acc@5 = {:.2f} '", ".", "format", "(", "mean_top1_icarl_cumul_acc", ",", "\n", "mean_top5_icarl_cumul_acc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_linear.CosineLinear.__init__": [[16, 26], ["torch.nn.Module.__init__", "torch.nn.parameter.Parameter", "modified_linear.CosineLinear.reset_parameters", "torch.Tensor", "torch.nn.parameter.Parameter", "modified_linear.CosineLinear.register_parameter", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_linear.CosineLinear.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "sigma", "=", "True", ")", ":", "\n", "        ", "super", "(", "CosineLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "if", "sigma", ":", "\n", "            ", "self", ".", "sigma", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'sigma'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_linear.CosineLinear.reset_parameters": [[27, 35], ["modified_linear.CosineLinear.weight.data.uniform_", "math.sqrt", "modified_linear.CosineLinear.sigma.data.fill_", "modified_linear.CosineLinear.weight.size"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reinitializing network parameters (Xavier's initialization).\n        \"\"\"", "\n", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "weight", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "if", "self", ".", "sigma", "is", "not", "None", ":", "\n", "            ", "self", ".", "sigma", ".", "data", ".", "fill_", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_linear.CosineLinear.forward": [[36, 45], ["torch.nn.functional.linear", "torch.nn.functional.normalize", "torch.nn.functional.normalize"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Performing a forward pass.\n        \"\"\"", "\n", "out", "=", "F", ".", "linear", "(", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ",", "\n", "F", ".", "normalize", "(", "self", ".", "weight", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ")", "\n", "if", "self", ".", "sigma", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "sigma", "*", "out", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_linear.SplitCosineLinear.__init__": [[51, 62], ["torch.nn.Module.__init__", "modified_linear.CosineLinear", "modified_linear.CosineLinear", "torch.nn.parameter.Parameter", "modified_linear.SplitCosineLinear.sigma.data.fill_", "modified_linear.SplitCosineLinear.register_parameter", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features1", ",", "out_features2", ",", "sigma", "=", "True", ")", ":", "\n", "        ", "super", "(", "SplitCosineLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features1", "+", "out_features2", "\n", "self", ".", "fc1", "=", "CosineLinear", "(", "in_features", ",", "out_features1", ",", "False", ")", "\n", "self", ".", "fc2", "=", "CosineLinear", "(", "in_features", ",", "out_features2", ",", "False", ")", "\n", "if", "sigma", ":", "\n", "            ", "self", ".", "sigma", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "self", ".", "sigma", ".", "data", ".", "fill_", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'sigma'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_linear.SplitCosineLinear.forward": [[63, 73], ["modified_linear.SplitCosineLinear.fc1", "modified_linear.SplitCosineLinear.fc2", "torch.cat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Performing a forward pass.\n        \"\"\"", "\n", "out1", "=", "self", ".", "fc1", "(", "x", ")", "\n", "out2", "=", "self", ".", "fc2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "out1", ",", "out2", ")", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "sigma", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "sigma", "*", "out", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.__init__": [[26, 32], ["utils_metrics.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.reset": [[33, 38], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update": [[39, 44], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.accuracy": [[4, 19], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].reshape().float().sum", "res.append", "correct[].reshape().float().sum.mul_", "target.view", "correct[].reshape().float", "correct[].reshape"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "# print( correct[:k])", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.BasicBlock.__init__": [[25, 34], ["torch.Module.__init__", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.conv3x3", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.BasicBlock.forward": [[35, 52], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.Bottleneck.__init__": [[57, 69], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.Bottleneck.forward": [[70, 91], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.ResNet.__init__": [[94, 115], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.ResNet._make_layer": [[116, 132], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.ResNet.forward": [[133, 149], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.size"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.conv3x3": [[16, 20], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.resnet18": [[151, 161], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.resnet34": [[163, 173], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.resnet50": [[175, 185], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.resnet101": [[187, 197], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.resnet.resnet152": [[199, 209], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.BasicBlock.__init__": [[22, 32], ["torch.Module.__init__", "modified_resnet.conv3x3", "torch.BatchNorm2d", "torch.ReLU", "modified_resnet.conv3x3", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.conv3x3", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "last", "=", "False", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "last", "=", "last", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.BasicBlock.forward": [[33, 54], ["modified_resnet.BasicBlock.conv1", "modified_resnet.BasicBlock.bn1", "modified_resnet.BasicBlock.relu", "modified_resnet.BasicBlock.conv2", "modified_resnet.BasicBlock.bn2", "modified_resnet.BasicBlock.downsample", "modified_resnet.BasicBlock.relu"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Performing a forward pass.\n        \"\"\"", "\n", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "if", "not", "self", ".", "last", ":", "# remove ReLU in the last layer", "\n", "            ", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet.__init__": [[61, 82], ["torch.Module.__init__", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "torch.MaxPool2d", "modified_resnet.ResNet._make_layer", "modified_resnet.ResNet._make_layer", "modified_resnet.ResNet._make_layer", "modified_resnet.ResNet._make_layer", "torch.AvgPool2d", "modified_linear.CosineLinear", "modified_resnet.ResNet.modules", "isinstance", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer"], ["def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "last_phase", "=", "True", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "modified_linear", ".", "CosineLinear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet._make_layer": [[83, 103], ["torch.Sequential", "torch.Sequential", "block", "range", "layers.append", "range", "torch.Conv2d", "torch.BatchNorm2d", "layers.append", "block", "layers.append", "block", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "last_phase", "=", "False", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", "]", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "if", "last_phase", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "blocks", "-", "1", ")", ":", "\n", "                ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "last", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "                ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.ResNet.forward": [[104, 123], ["modified_resnet.ResNet.conv1", "modified_resnet.ResNet.bn1", "modified_resnet.ResNet.relu", "modified_resnet.ResNet.maxpool", "modified_resnet.ResNet.layer1", "modified_resnet.ResNet.layer2", "modified_resnet.ResNet.layer3", "modified_resnet.ResNet.layer4", "modified_resnet.ResNet.avgpool", "modified_resnet.ResNet.view", "modified_resnet.ResNet.fc", "modified_resnet.ResNet.size"], "methods", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Performing a forward pass.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.conv3x3": [[8, 14], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    3x3 convolution with padding\n    \"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.modified_resnet.resnet18": [[125, 134], ["modified_resnet.ResNet"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_pytorch.savepickle": [[11, 16], ["utils_pytorch.mkdir_p", "print", "os.dirname", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_pytorch.mkdir_p"], ["def", "savepickle", "(", "data", ",", "file_path", ")", ":", "\n", "    ", "mkdir_p", "(", "osp", ".", "dirname", "(", "file_path", ")", ",", "delete", "=", "False", ")", "\n", "print", "(", "'pickle into'", ",", "file_path", ")", "\n", "with", "open", "(", "file_path", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "data", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_pytorch.unpickle": [[18, 22], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "unpickle", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_pytorch.mkdir_p": [[24, 34], ["subprocess.call", "os.exists", "subprocess.call", "print"], "function", ["None"], ["", "def", "mkdir_p", "(", "path", ",", "delete", "=", "False", ",", "print_info", "=", "True", ")", ":", "\n", "    ", "if", "path", "==", "''", ":", "\n", "        ", "return", "\n", "\n", "", "if", "delete", ":", "\n", "        ", "subprocess", ".", "call", "(", "(", "'rm -r '", "+", "path", ")", ".", "split", "(", ")", ")", "\n", "", "if", "not", "osp", ".", "exists", "(", "path", ")", ":", "\n", "        ", "if", "print_info", ":", "\n", "            ", "print", "(", "'mkdir -p  '", "+", "path", ")", "\n", "", "subprocess", ".", "call", "(", "(", "'mkdir -p '", "+", "path", ")", ".", "split", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_pytorch.get_mean_and_std": [[36, 49], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "print", "torch.zeros.div_", "torch.zeros.div_", "range", "len", "len", "inputs[].mean", "inputs[].std"], "function", ["None"], ["", "", "def", "get_mean_and_std", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"Compute the mean and std value of dataset.\"\"\"", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "True", ",", "num_workers", "=", "2", ")", "\n", "mean", "=", "torch", ".", "zeros", "(", "3", ")", "\n", "std", "=", "torch", ".", "zeros", "(", "3", ")", "\n", "print", "(", "'==> Computing mean and std..'", ")", "\n", "for", "inputs", ",", "targets", "in", "dataloader", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "mean", "[", "i", "]", "+=", "inputs", "[", ":", ",", "i", ",", ":", ",", ":", "]", ".", "mean", "(", ")", "\n", "std", "[", "i", "]", "+=", "inputs", "[", ":", ",", "i", ",", ":", ",", ":", "]", ".", "std", "(", ")", "\n", "", "", "mean", ".", "div_", "(", "len", "(", "dataset", ")", ")", "\n", "std", ".", "div_", "(", "len", "(", "dataset", ")", ")", "\n", "return", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_pytorch.init_params": [[51, 65], ["net.modules", "isinstance", "torch.kaiming_normal_", "isinstance", "torch.constant_", "torch.constant_", "torch.constant_", "isinstance", "torch.normal_", "torch.constant_"], "function", ["None"], ["", "def", "init_params", "(", "net", ")", ":", "\n", "    ", "\"\"\"Init layer parameters.\"\"\"", "\n", "for", "m", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "if", "m", ".", "bias", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ",", "std", "=", "1e-3", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_pytorch.format_time": [[67, 99], ["int", "int", "int", "int", "int", "str", "str", "str", "str", "str"], "function", ["None"], ["", "", "", "", "def", "format_time", "(", "seconds", ")", ":", "\n", "    ", "days", "=", "int", "(", "seconds", "/", "3600", "/", "24", ")", "\n", "seconds", "=", "seconds", "-", "days", "*", "3600", "*", "24", "\n", "hours", "=", "int", "(", "seconds", "/", "3600", ")", "\n", "seconds", "=", "seconds", "-", "hours", "*", "3600", "\n", "minutes", "=", "int", "(", "seconds", "/", "60", ")", "\n", "seconds", "=", "seconds", "-", "minutes", "*", "60", "\n", "secondsf", "=", "int", "(", "seconds", ")", "\n", "seconds", "=", "seconds", "-", "secondsf", "\n", "millis", "=", "int", "(", "seconds", "*", "1000", ")", "\n", "\n", "f", "=", "''", "\n", "i", "=", "1", "\n", "if", "days", ">", "0", ":", "\n", "        ", "f", "+=", "str", "(", "days", ")", "+", "'D'", "\n", "i", "+=", "1", "\n", "", "if", "hours", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "hours", ")", "+", "'h'", "\n", "i", "+=", "1", "\n", "", "if", "minutes", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "minutes", ")", "+", "'m'", "\n", "i", "+=", "1", "\n", "", "if", "secondsf", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "secondsf", ")", "+", "'s'", "\n", "i", "+=", "1", "\n", "", "if", "millis", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "millis", ")", "+", "'ms'", "\n", "i", "+=", "1", "\n", "", "if", "f", "==", "''", ":", "\n", "        ", "f", "=", "'0ms'", "\n", "\n", "", "return", "f", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.train_eval.train_eval": [[10, 64], ["min", "range", "torch.device", "torch.device", "torch.device", "ref_model.eval", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "tg_model.eval", "print", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_model", "utils_metrics.accuracy", "utils_metrics.AverageMeter.update", "utils_metrics.AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.KLDivLoss", "torch.log_softmax", "torch.softmax", "ref_model.detach"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.accuracy", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.softmax"], ["def", "train_eval", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "\n", "trainloader", ",", "testloader", ",", "\n", "iteration", ",", "start_iteration", ",", "\n", "T", ",", "beta", ",", "\n", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "\n", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "# train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "# cross entropy + distillation", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "F", ".", "log_softmax", "(", "outputs", "[", ":", ",", ":", "num_old_classes", "]", "/", "T", ",", "dim", "=", "1", ")", ",", "F", ".", "softmax", "(", "ref_outputs", ".", "detach", "(", ")", "/", "T", ",", "dim", "=", "1", ")", ")", "*", "T", "*", "T", "*", "beta", "*", "num_old_classes", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "# eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "return", "tg_model", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.train_eval.train_eval2": [[66, 122], ["min", "range", "torch.device", "torch.device", "torch.device", "ref_model.eval", "print", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "tg_model.eval", "print", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "str", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_model", "utils_metrics.accuracy", "utils_metrics.AverageMeter.update", "utils_metrics.AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.KLDivLoss", "torch.log_softmax", "torch.softmax", "ref_model.detach"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.accuracy", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.softmax"], ["", "def", "train_eval2", "(", "P", ",", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "\n", "trainloader", ",", "testloader", ",", "\n", "iteration", ",", "start_iteration", ",", "\n", "T", ",", "beta", ",", "\n", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "-", "P", "\n", "print", "(", "'old = '", "+", "str", "(", "num_old_classes", ")", ")", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "# train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "# cross entropy + distillation", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "F", ".", "log_softmax", "(", "outputs", "[", ":", ",", ":", "num_old_classes", "]", "/", "T", ",", "dim", "=", "1", ")", ",", "\n", "F", ".", "softmax", "(", "ref_outputs", ".", "detach", "(", ")", "/", "T", ",", "dim", "=", "1", ")", ")", "*", "T", "*", "T", "*", "beta", "*", "num_old_classes", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "# eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "return", "tg_model", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.train_eval_LF.get_ref_features": [[12, 15], ["None"], "function", ["None"], ["def", "get_ref_features", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "ref_features", "\n", "ref_features", "=", "inputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.train_eval_LF.get_cur_features": [[17, 20], ["None"], "function", ["None"], ["", "def", "get_cur_features", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "cur_features", "\n", "cur_features", "=", "inputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.train_eval_LF.train_eval_LF": [[22, 82], ["min", "range", "torch.device", "torch.device", "ref_model.eval", "ref_model.fc.register_forward_hook", "tg_model.fc.register_forward_hook", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "tg_model.eval", "print", "print", "ref_model.fc.register_forward_hook.remove", "tg_model.fc.register_forward_hook.remove", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_model", "utils_metrics.accuracy", "utils_metrics.AverageMeter.update", "utils_metrics.AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.CosineEmbeddingLoss", "ref_features.detach", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.accuracy", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update"], ["", "def", "train_eval_LF", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "\n", "trainloader", ",", "testloader", ",", "\n", "iteration", ",", "start_iteration", ",", "\n", "lamda", ",", "\n", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "handle_ref_features", "=", "ref_model", ".", "fc", ".", "register_forward_hook", "(", "get_ref_features", ")", "\n", "handle_cur_features", "=", "tg_model", ".", "fc", ".", "register_forward_hook", "(", "get_cur_features", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "CosineEmbeddingLoss", "(", ")", "(", "cur_features", ",", "ref_features", ".", "detach", "(", ")", ",", "\n", "torch", ".", "ones", "(", "inputs", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "device", ")", ")", "*", "lamda", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "# eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "print", "(", "\"Removing register_forward_hook\"", ")", "\n", "handle_ref_features", ".", "remove", "(", ")", "\n", "handle_cur_features", ".", "remove", "(", ")", "\n", "\n", "", "return", "tg_model", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.compute_features.compute_features": [[5, 21], ["tg_feature_model.eval", "numpy.zeros", "torch.device", "torch.no_grad", "inputs.to.to", "numpy.squeeze", "torch.cuda.is_available", "tg_feature_model().cpu", "tg_feature_model"], "function", ["None"], ["def", "compute_features", "(", "tg_feature_model", ",", "evalloader", ",", "num_samples", ",", "num_features", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "", "tg_feature_model", ".", "eval", "(", ")", "\n", "\n", "features", "=", "np", ".", "zeros", "(", "[", "num_samples", ",", "num_features", "]", ")", "\n", "start_idx", "=", "0", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "inputs", ",", "targets", "in", "evalloader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", ")", "\n", "features", "[", "start_idx", ":", "start_idx", "+", "inputs", ".", "shape", "[", "0", "]", ",", ":", "]", "=", "np", ".", "squeeze", "(", "tg_feature_model", "(", "inputs", ")", ".", "cpu", "(", ")", ")", "\n", "start_idx", "=", "start_idx", "+", "inputs", ".", "shape", "[", "0", "]", "\n", "", "", "assert", "(", "start_idx", "==", "num_samples", ")", "\n", "\n", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.utils_incremental.compute_accuracy.compute_accuracy": [[10, 86], ["tg_model.eval", "tg_feature_model.eval", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "utils_metrics.AverageMeter", "torch.device", "torch.device", "torch.no_grad", "torch.no_grad", "enumerate", "print", "print", "print", "targets.size", "tg_model", "torch.softmax", "F.softmax.max", "predicted.eq().sum().item", "utils_metrics.accuracy", "utils_metrics.AverageMeter.update", "utils_metrics.AverageMeter.update", "numpy.squeeze", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to.max", "predicted_icarl.eq().sum().item", "utils_metrics.accuracy", "utils_metrics.AverageMeter.update", "utils_metrics.AverageMeter.update", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to.max", "predicted_ncm.eq().sum().item", "utils_metrics.accuracy", "utils_metrics.AverageMeter.update", "utils_metrics.AverageMeter.update", "torch.cuda.is_available", "torch.cuda.is_available", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "tg_feature_model", "scipy.spatial.distance.cdist", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "scipy.spatial.distance.cdist", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "scale.repeat().type().to", "predicted.eq().sum", "np.squeeze.cpu", "scipy.spatial.distance.cdist", "torch.from_numpy", "torch.from_numpy", "predicted_icarl.eq().sum", "np.squeeze.cpu", "scipy.spatial.distance.cdist", "torch.from_numpy", "torch.from_numpy", "predicted_ncm.eq().sum", "min", "np.squeeze.reshape().cpu", "min", "np.squeeze.reshape().cpu", "min", "scale.repeat().type", "predicted.eq", "predicted_icarl.eq", "predicted_ncm.eq", "np.squeeze.reshape", "np.squeeze.reshape", "scale.repeat"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.softmax", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.accuracy", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.accuracy", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.accuracy", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lucir.utils_metrics.AverageMeter.update"], ["def", "compute_accuracy", "(", "tg_model", ",", "tg_feature_model", ",", "class_means", ",", "evalloader", ",", "scale", "=", "None", ",", "print_info", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "", "tg_model", ".", "eval", "(", ")", "\n", "tg_feature_model", ".", "eval", "(", ")", "\n", "\n", "num_classes", "=", "tg_model", ".", "fc", ".", "out_features", "\n", "\n", "correct", "=", "0", "\n", "correct_icarl", "=", "0", "\n", "correct_ncm", "=", "0", "\n", "\n", "top1_correct", "=", "AverageMeter", "(", ")", "\n", "top5_correct", "=", "AverageMeter", "(", ")", "\n", "top1_correct_icarl", "=", "AverageMeter", "(", ")", "\n", "top5_correct_icarl", "=", "AverageMeter", "(", ")", "\n", "top1_correct_ncm", "=", "AverageMeter", "(", ")", "\n", "top5_correct_ncm", "=", "AverageMeter", "(", ")", "\n", "\n", "total", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "evalloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "outputs", "=", "F", ".", "softmax", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "                ", "assert", "(", "scale", ".", "shape", "[", "0", "]", "==", "1", ")", "\n", "assert", "(", "outputs", ".", "shape", "[", "1", "]", "==", "scale", ".", "shape", "[", "1", "]", ")", "\n", "outputs", "=", "outputs", "/", "scale", ".", "repeat", "(", "outputs", ".", "shape", "[", "0", "]", ",", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "to", "(", "device", ")", "\n", "", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "min", "(", "5", ",", "num_classes", ")", ")", ")", "\n", "top1_correct", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5_correct", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "outputs_feature", "=", "np", ".", "squeeze", "(", "tg_feature_model", "(", "inputs", ")", ")", "\n", "try", ":", "\n", "                ", "sqd_icarl", "=", "cdist", "(", "class_means", "[", ":", ",", ":", ",", "0", "]", ".", "T", ",", "outputs_feature", ".", "cpu", "(", ")", ",", "'sqeuclidean'", ")", "\n", "", "except", ":", "\n", "                ", "sqd_icarl", "=", "cdist", "(", "class_means", "[", ":", ",", ":", ",", "0", "]", ".", "T", ",", "outputs_feature", ".", "reshape", "(", "1", ",", "-", "1", ")", ".", "cpu", "(", ")", ",", "'sqeuclidean'", ")", "\n", "\n", "", "score_icarl", "=", "torch", ".", "from_numpy", "(", "(", "-", "sqd_icarl", ")", ".", "T", ")", ".", "to", "(", "device", ")", "\n", "_", ",", "predicted_icarl", "=", "score_icarl", ".", "max", "(", "1", ")", "\n", "correct_icarl", "+=", "predicted_icarl", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "score_icarl", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "min", "(", "5", ",", "num_classes", ")", ")", ")", "\n", "top1_correct_icarl", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5_correct_icarl", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "# Compute score for NCM", "\n", "try", ":", "\n", "                ", "sqd_ncm", "=", "cdist", "(", "class_means", "[", ":", ",", ":", ",", "1", "]", ".", "T", ",", "outputs_feature", ".", "cpu", "(", ")", ",", "'sqeuclidean'", ")", "\n", "", "except", ":", "\n", "                ", "sqd_ncm", "=", "cdist", "(", "class_means", "[", ":", ",", ":", ",", "1", "]", ".", "T", ",", "outputs_feature", ".", "reshape", "(", "1", ",", "-", "1", ")", ".", "cpu", "(", ")", ",", "'sqeuclidean'", ")", "\n", "\n", "", "score_ncm", "=", "torch", ".", "from_numpy", "(", "(", "-", "sqd_ncm", ")", ".", "T", ")", ".", "to", "(", "device", ")", "\n", "_", ",", "predicted_ncm", "=", "score_ncm", ".", "max", "(", "1", ")", "\n", "correct_ncm", "+=", "predicted_ncm", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "score_ncm", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "min", "(", "5", ",", "num_classes", ")", ")", ")", "\n", "top1_correct_ncm", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5_correct_ncm", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "if", "print_info", ":", "\n", "        ", "print", "(", "\"LUCIR-CNN  | acc@1 = {:.2f}%\\tacc@5 = {:.2f}%\"", ".", "format", "(", "top1_correct", ".", "avg", ",", "top5_correct", ".", "avg", ")", ")", "\n", "print", "(", "\"LUCIR-NCM  | acc@1 = {:.2f}%\\tacc@5 = {:.2f}%\"", ".", "format", "(", "top1_correct_ncm", ".", "avg", ",", "top5_correct_ncm", ".", "avg", ")", ")", "\n", "print", "(", "\"iCaRL      | acc@1 = {:.2f}%\\tacc@5 = {:.2f}%\"", ".", "format", "(", "top1_correct_icarl", ".", "avg", ",", "top5_correct_icarl", ".", "avg", ")", ")", "\n", "\n", "", "top1_cnn_acc", ",", "top5_cnn_acc", "=", "top1_correct", ".", "avg", ",", "top5_correct", ".", "avg", "\n", "top1_icarl_acc", ",", "top5_icarl_acc", "=", "top1_correct_icarl", ".", "avg", ",", "top5_correct_icarl", ".", "avg", "\n", "top1_ncm_acc", ",", "top5_ncm_acc", "=", "top1_correct_ncm", ".", "avg", ",", "top5_correct_ncm", ".", "avg", "\n", "\n", "return", "[", "top1_cnn_acc", ",", "top5_cnn_acc", ",", "top1_icarl_acc", ",", "top5_icarl_acc", ",", "top1_ncm_acc", ",", "top5_ncm_acc", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.memory_dataset.MemoryDataset.__init__": [[10, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "transform", ",", "class_indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialization\"\"\"", "\n", "self", ".", "labels", "=", "data", "[", "'y'", "]", "\n", "self", ".", "images", "=", "data", "[", "'x'", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "class_indices", "=", "class_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.memory_dataset.MemoryDataset.__len__": [[17, 20], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Denotes the total number of samples\"\"\"", "\n", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.memory_dataset.MemoryDataset.__getitem__": [[21, 27], ["PIL.Image.fromarray", "memory_dataset.MemoryDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Generates one sample of data\"\"\"", "\n", "x", "=", "Image", ".", "fromarray", "(", "self", ".", "images", "[", "index", "]", ")", "\n", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "y", "=", "self", ".", "labels", "[", "index", "]", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.memory_dataset.get_data": [[29, 125], ["numpy.cumsum", "numpy.concatenate", "range", "numpy.isin", "zip", "numpy.isin", "zip", "range", "data.keys", "data.keys", "len", "list", "len", "class_order.copy.copy", "numpy.random.shuffle", "numpy.array", "range", "numpy.array", "range", "np.array.sum", "np.isin.sum", "len", "class_order.copy.index", "[].append", "[].append", "np.isin.sum", "len", "class_order.copy.index", "[].append", "[].append", "len", "data.keys", "taskcla.append", "numpy.unique", "range", "str", "numpy.array", "numpy.unique", "range", "numpy.asarray", "list", "random.sample", "random.sample.sort", "range", "int", "len", "[].append", "[].append", "[].pop", "[].pop", "numpy.where", "numpy.round", "numpy.asarray", "len"], "function", ["None"], ["", "", "def", "get_data", "(", "trn_data", ",", "tst_data", ",", "num_tasks", ",", "nc_first_task", ",", "validation", ",", "shuffle_classes", ",", "class_order", "=", "None", ")", ":", "\n", "    ", "\"\"\"Prepare data: dataset splits, task partition, class order\"\"\"", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "if", "class_order", "is", "None", ":", "\n", "        ", "num_classes", "=", "len", "(", "np", ".", "unique", "(", "trn_data", "[", "'y'", "]", ")", ")", "\n", "class_order", "=", "list", "(", "range", "(", "num_classes", ")", ")", "\n", "", "else", ":", "\n", "        ", "num_classes", "=", "len", "(", "class_order", ")", "\n", "class_order", "=", "class_order", ".", "copy", "(", ")", "\n", "", "if", "shuffle_classes", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "class_order", ")", "\n", "\n", "# compute classes per task and num_tasks", "\n", "", "if", "nc_first_task", "is", "None", ":", "\n", "        ", "cpertask", "=", "np", ".", "array", "(", "[", "num_classes", "//", "num_tasks", "]", "*", "num_tasks", ")", "\n", "for", "i", "in", "range", "(", "num_classes", "%", "num_tasks", ")", ":", "\n", "            ", "cpertask", "[", "i", "]", "+=", "1", "\n", "", "", "else", ":", "\n", "        ", "assert", "nc_first_task", "<", "num_classes", ",", "\"first task wants more classes than exist\"", "\n", "remaining_classes", "=", "num_classes", "-", "nc_first_task", "\n", "assert", "remaining_classes", ">=", "(", "num_tasks", "-", "1", ")", ",", "\"at least one class is needed per task\"", "# better minimum 2", "\n", "cpertask", "=", "np", ".", "array", "(", "[", "nc_first_task", "]", "+", "[", "remaining_classes", "//", "(", "num_tasks", "-", "1", ")", "]", "*", "(", "num_tasks", "-", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "remaining_classes", "%", "(", "num_tasks", "-", "1", ")", ")", ":", "\n", "            ", "cpertask", "[", "i", "+", "1", "]", "+=", "1", "\n", "\n", "", "", "assert", "num_classes", "==", "cpertask", ".", "sum", "(", ")", ",", "\"something went wrong, the split does not match num classes\"", "\n", "cpertask_cumsum", "=", "np", ".", "cumsum", "(", "cpertask", ")", "\n", "init_class", "=", "np", ".", "concatenate", "(", "(", "[", "0", "]", ",", "cpertask_cumsum", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# initialize data structure", "\n", "for", "tt", "in", "range", "(", "num_tasks", ")", ":", "\n", "        ", "data", "[", "tt", "]", "=", "{", "}", "\n", "data", "[", "tt", "]", "[", "'name'", "]", "=", "'task-'", "+", "str", "(", "tt", ")", "\n", "data", "[", "tt", "]", "[", "'trn'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "tt", "]", "[", "'val'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "tt", "]", "[", "'tst'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "\n", "# ALL OR TRAIN", "\n", "", "filtering", "=", "np", ".", "isin", "(", "trn_data", "[", "'y'", "]", ",", "class_order", ")", "\n", "if", "filtering", ".", "sum", "(", ")", "!=", "len", "(", "trn_data", "[", "'y'", "]", ")", ":", "\n", "        ", "trn_data", "[", "'x'", "]", "=", "trn_data", "[", "'x'", "]", "[", "filtering", "]", "\n", "trn_data", "[", "'y'", "]", "=", "np", ".", "array", "(", "trn_data", "[", "'y'", "]", ")", "[", "filtering", "]", "\n", "", "for", "this_image", ",", "this_label", "in", "zip", "(", "trn_data", "[", "'x'", "]", ",", "trn_data", "[", "'y'", "]", ")", ":", "\n", "# If shuffling is false, it won't change the class number", "\n", "        ", "this_label", "=", "class_order", ".", "index", "(", "this_label", ")", "\n", "# add it to the corresponding split", "\n", "this_task", "=", "(", "this_label", ">=", "cpertask_cumsum", ")", ".", "sum", "(", ")", "\n", "data", "[", "this_task", "]", "[", "'trn'", "]", "[", "'x'", "]", ".", "append", "(", "this_image", ")", "\n", "data", "[", "this_task", "]", "[", "'trn'", "]", "[", "'y'", "]", ".", "append", "(", "this_label", "-", "init_class", "[", "this_task", "]", ")", "\n", "\n", "# ALL OR TEST", "\n", "", "filtering", "=", "np", ".", "isin", "(", "tst_data", "[", "'y'", "]", ",", "class_order", ")", "\n", "if", "filtering", ".", "sum", "(", ")", "!=", "len", "(", "tst_data", "[", "'y'", "]", ")", ":", "\n", "        ", "tst_data", "[", "'x'", "]", "=", "tst_data", "[", "'x'", "]", "[", "filtering", "]", "\n", "tst_data", "[", "'y'", "]", "=", "tst_data", "[", "'y'", "]", "[", "filtering", "]", "\n", "", "for", "this_image", ",", "this_label", "in", "zip", "(", "tst_data", "[", "'x'", "]", ",", "tst_data", "[", "'y'", "]", ")", ":", "\n", "# If shuffling is false, it won't change the class number", "\n", "        ", "this_label", "=", "class_order", ".", "index", "(", "this_label", ")", "\n", "# add it to the corresponding split", "\n", "this_task", "=", "(", "this_label", ">=", "cpertask_cumsum", ")", ".", "sum", "(", ")", "\n", "data", "[", "this_task", "]", "[", "'tst'", "]", "[", "'x'", "]", ".", "append", "(", "this_image", ")", "\n", "data", "[", "this_task", "]", "[", "'tst'", "]", "[", "'y'", "]", ".", "append", "(", "this_label", "-", "init_class", "[", "this_task", "]", ")", "\n", "\n", "# check classes", "\n", "", "for", "tt", "in", "range", "(", "num_tasks", ")", ":", "\n", "        ", "data", "[", "tt", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", ")", ")", "\n", "assert", "data", "[", "tt", "]", "[", "'ncla'", "]", "==", "cpertask", "[", "tt", "]", ",", "\"something went wrong splitting classes\"", "\n", "\n", "# validation", "\n", "", "if", "validation", ">", "0.0", ":", "\n", "        ", "for", "tt", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "for", "cc", "in", "range", "(", "data", "[", "tt", "]", "[", "'ncla'", "]", ")", ":", "\n", "                ", "cls_idx", "=", "list", "(", "np", ".", "where", "(", "np", ".", "asarray", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", ")", "==", "cc", ")", "[", "0", "]", ")", "\n", "rnd_img", "=", "random", ".", "sample", "(", "cls_idx", ",", "int", "(", "np", ".", "round", "(", "len", "(", "cls_idx", ")", "*", "validation", ")", ")", ")", "\n", "rnd_img", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "for", "ii", "in", "range", "(", "len", "(", "rnd_img", ")", ")", ":", "\n", "                    ", "data", "[", "tt", "]", "[", "'val'", "]", "[", "'x'", "]", ".", "append", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'x'", "]", "[", "rnd_img", "[", "ii", "]", "]", ")", "\n", "data", "[", "tt", "]", "[", "'val'", "]", "[", "'y'", "]", ".", "append", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", "[", "rnd_img", "[", "ii", "]", "]", ")", "\n", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'x'", "]", ".", "pop", "(", "rnd_img", "[", "ii", "]", ")", "\n", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", ".", "pop", "(", "rnd_img", "[", "ii", "]", ")", "\n", "\n", "# convert them to numpy arrays", "\n", "", "", "", "", "for", "tt", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "for", "split", "in", "[", "'trn'", ",", "'val'", ",", "'tst'", "]", ":", "\n", "            ", "data", "[", "tt", "]", "[", "split", "]", "[", "'x'", "]", "=", "np", ".", "asarray", "(", "data", "[", "tt", "]", "[", "split", "]", "[", "'x'", "]", ")", "\n", "\n", "# other", "\n", "", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", ",", "class_order", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_loaders": [[8, 70], ["enumerate", "print", "print", "print", "data_loader.get_transforms", "data_loader.get_datasets", "taskcla.extend", "range", "list", "range", "sum", "trn_load.append", "val_load.append", "tst_load.append", "len", "len", "len", "range", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_transforms", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_datasets"], ["def", "get_loaders", "(", "datasets", ",", "num_tasks", ",", "nc_first_task", ",", "batch_size", ",", "num_workers", ",", "\n", "pin_memory", ",", "force_order", "=", "True", ",", "val_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"Apply transformations to Datasets and create the DataLoaders for each task\"\"\"", "\n", "\n", "trn_load", ",", "val_load", ",", "tst_load", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "taskcla", "=", "[", "]", "\n", "dataset_offset", "=", "0", "\n", "for", "idx_dataset", ",", "cur_dataset", "in", "enumerate", "(", "datasets", ",", "0", ")", ":", "\n", "# get configuration for current dataset", "\n", "        ", "dc", "=", "dataset_config", "[", "cur_dataset", "]", "\n", "\n", "# fixing class order", "\n", "if", "force_order", ":", "\n", "            ", "class_order", "=", "list", "(", "range", "(", "dc", "[", "'num_classes'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "class_order", "=", "dc", "[", "'class_order'", "]", "\n", "\n", "# transformations", "\n", "", "trn_transform", ",", "tst_transform", "=", "get_transforms", "(", "resize", "=", "dc", "[", "'resize'", "]", ",", "\n", "pad", "=", "dc", "[", "'pad'", "]", ",", "\n", "crop", "=", "dc", "[", "'crop'", "]", ",", "\n", "flip", "=", "dc", "[", "'flip'", "]", ",", "\n", "normalize", "=", "dc", "[", "'normalize'", "]", ",", "\n", "extend_channel", "=", "dc", "[", "'extend_channel'", "]", ")", "\n", "\n", "# datasets", "\n", "trn_dset", ",", "val_dset", ",", "tst_dset", ",", "curtaskcla", "=", "get_datasets", "(", "cur_dataset", ",", "dc", "[", "'path'", "]", ",", "num_tasks", ",", "nc_first_task", ",", "\n", "validation", "=", "dc", "[", "'validation'", "]", ",", "\n", "trn_transform", "=", "trn_transform", ",", "\n", "tst_transform", "=", "tst_transform", ",", "\n", "class_order", "=", "class_order", ",", "\n", "val_only", "=", "val_only", ")", "\n", "\n", "# apply offsets in case of multiple datasets", "\n", "if", "idx_dataset", ">", "0", ":", "\n", "            ", "for", "tt", "in", "range", "(", "num_tasks", ")", ":", "\n", "                ", "trn_dset", "[", "tt", "]", ".", "labels", "=", "[", "elem", "+", "dataset_offset", "for", "elem", "in", "trn_dset", "[", "tt", "]", ".", "labels", "]", "\n", "val_dset", "[", "tt", "]", ".", "labels", "=", "[", "elem", "+", "dataset_offset", "for", "elem", "in", "val_dset", "[", "tt", "]", ".", "labels", "]", "\n", "tst_dset", "[", "tt", "]", ".", "labels", "=", "[", "elem", "+", "dataset_offset", "for", "elem", "in", "tst_dset", "[", "tt", "]", ".", "labels", "]", "\n", "", "", "dataset_offset", "=", "dataset_offset", "+", "sum", "(", "[", "tc", "[", "1", "]", "for", "tc", "in", "curtaskcla", "]", ")", "\n", "\n", "# reassign class idx for multiple dataset case", "\n", "curtaskcla", "=", "[", "(", "tc", "[", "0", "]", "+", "idx_dataset", "*", "num_tasks", ",", "tc", "[", "1", "]", ")", "for", "tc", "in", "curtaskcla", "]", "\n", "\n", "# extend final taskcla list", "\n", "taskcla", ".", "extend", "(", "curtaskcla", ")", "\n", "\n", "# loaders", "\n", "for", "tt", "in", "range", "(", "num_tasks", ")", ":", "\n", "            ", "trn_load", ".", "append", "(", "data", ".", "DataLoader", "(", "trn_dset", "[", "tt", "]", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", ")", "\n", "val_load", ".", "append", "(", "data", ".", "DataLoader", "(", "val_dset", "[", "tt", "]", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", ")", "\n", "tst_load", ".", "append", "(", "data", ".", "DataLoader", "(", "tst_dset", "[", "tt", "]", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", ")", "\n", "\n", "# Debugging outputs", "\n", "", "", "print", "(", "\"Train set size/task: %d\"", "%", "len", "(", "trn_load", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Val set size/task: %d\"", "%", "len", "(", "val_load", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Test set size/task: %d\"", "%", "len", "(", "tst_load", "[", "0", "]", ")", ")", "\n", "\n", "return", "trn_load", ",", "val_load", ",", "tst_load", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_datasets": [[72, 101], ["base_dataset.get_data", "range", "trn_dset.append", "val_dset.append", "tst_dset.append", "Dataset", "Dataset", "Dataset"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.get_data"], ["", "def", "get_datasets", "(", "dataset", ",", "path", ",", "num_tasks", ",", "nc_first_task", ",", "validation", ",", "\n", "trn_transform", ",", "tst_transform", ",", "\n", "class_order", "=", "None", ",", "val_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"Extract datasets and create Dataset class\"\"\"", "\n", "\n", "trn_dset", ",", "val_dset", ",", "tst_dset", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "# read data paths and compute splits -- path needs to have a train.txt and a test.txt with image-label pairs", "\n", "all_data", ",", "taskcla", ",", "class_indices", "=", "basedat", ".", "get_data", "(", "path", ",", "num_tasks", "=", "num_tasks", ",", "nc_first_task", "=", "nc_first_task", ",", "\n", "validation", "=", "validation", ",", "shuffle_classes", "=", "class_order", "is", "None", ",", "\n", "class_order", "=", "class_order", ",", "\n", "val_only", "=", "val_only", ")", "\n", "\n", "# set dataset type", "\n", "Dataset", "=", "basedat", ".", "BaseDataset", "\n", "\n", "# get datasets, apply correct label offsets for each task", "\n", "offset", "=", "0", "\n", "for", "task", "in", "range", "(", "num_tasks", ")", ":", "\n", "        ", "all_data", "[", "task", "]", "[", "'trn'", "]", "[", "'y'", "]", "=", "[", "label", "+", "offset", "for", "label", "in", "all_data", "[", "task", "]", "[", "'trn'", "]", "[", "'y'", "]", "]", "\n", "all_data", "[", "task", "]", "[", "'val'", "]", "[", "'y'", "]", "=", "[", "label", "+", "offset", "for", "label", "in", "all_data", "[", "task", "]", "[", "'val'", "]", "[", "'y'", "]", "]", "\n", "all_data", "[", "task", "]", "[", "'tst'", "]", "[", "'y'", "]", "=", "[", "label", "+", "offset", "for", "label", "in", "all_data", "[", "task", "]", "[", "'tst'", "]", "[", "'y'", "]", "]", "\n", "\n", "trn_dset", ".", "append", "(", "Dataset", "(", "all_data", "[", "task", "]", "[", "'trn'", "]", ",", "trn_transform", ",", "class_indices", ")", ")", "\n", "val_dset", ".", "append", "(", "Dataset", "(", "all_data", "[", "task", "]", "[", "'val'", "]", ",", "tst_transform", ",", "class_indices", ")", ")", "\n", "tst_dset", ".", "append", "(", "Dataset", "(", "all_data", "[", "task", "]", "[", "'tst'", "]", ",", "tst_transform", ",", "class_indices", ")", ")", "\n", "offset", "+=", "taskcla", "[", "task", "]", "[", "1", "]", "\n", "\n", "", "return", "trn_dset", ",", "val_dset", ",", "tst_dset", ",", "taskcla", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.data_loader.get_transforms": [[103, 122], ["trn_transform_list.append", "tst_transform_list.append", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Compose", "torchvision.Compose"], "function", ["None"], ["", "def", "get_transforms", "(", "resize", ",", "pad", ",", "crop", ",", "flip", ",", "normalize", ",", "extend_channel", ")", ":", "\n", "    ", "\"\"\"Unpack transformations and apply to train or test splits\"\"\"", "\n", "\n", "trn_transform_list", "=", "[", "]", "\n", "tst_transform_list", "=", "[", "]", "\n", "\n", "trn_transform_list", "+=", "[", "transforms", ".", "RandomResizedCrop", "(", "224", ")", "]", "\n", "trn_transform_list", "+=", "[", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "trn_transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "\n", "tst_transform_list", "+=", "[", "transforms", ".", "Resize", "(", "256", ")", "]", "\n", "tst_transform_list", "+=", "[", "transforms", ".", "CenterCrop", "(", "224", ")", "]", "\n", "tst_transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "\n", "# normalization", "\n", "trn_transform_list", ".", "append", "(", "transforms", ".", "Normalize", "(", "mean", "=", "normalize", "[", "0", "]", ",", "std", "=", "normalize", "[", "1", "]", ")", ")", "\n", "tst_transform_list", ".", "append", "(", "transforms", ".", "Normalize", "(", "mean", "=", "normalize", "[", "0", "]", ",", "std", "=", "normalize", "[", "1", "]", ")", ")", "\n", "\n", "return", "transforms", ".", "Compose", "(", "trn_transform_list", ")", ",", "transforms", ".", "Compose", "(", "tst_transform_list", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.dataset_config.get_dset_mean_std": [[19, 36], ["open().readlines", "print", "exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "float", "re.findall", "re.findall"], "function", ["None"], ["def", "get_dset_mean_std", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"\n    Retrieving normalizing constants of a given dataset.\n    \"\"\"", "\n", "datasets_mean_std_file", "=", "open", "(", "_DSET_MEAN_STD_FILE", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", ",", "dataset_stat", "=", "line", "[", "0", "]", ",", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "dataset", ":", "\n", "            ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "dataset_std", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "1", "]", ")", "]", "\n", "return", "dataset_mean", ",", "dataset_std", "\n", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__init__": [[11, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "transform", ",", "class_indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialization\"\"\"", "\n", "self", ".", "labels", "=", "data", "[", "'y'", "]", "\n", "self", ".", "images", "=", "data", "[", "'x'", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "class_indices", "=", "class_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__len__": [[18, 21], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Denotes the total number of samples\"\"\"", "\n", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.BaseDataset.__getitem__": [[22, 28], ["PIL.Image.open().convert", "base_dataset.BaseDataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Generates one sample of data\"\"\"", "\n", "x", "=", "Image", ".", "open", "(", "self", ".", "images", "[", "index", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "y", "=", "self", ".", "labels", "[", "index", "]", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.datasets.base_dataset.get_data": [[30, 135], ["numpy.loadtxt", "numpy.cumsum", "numpy.concatenate", "range", "range", "data.keys", "numpy.loadtxt", "numpy.loadtxt", "os.path.join", "len", "list", "len", "class_order.copy.copy", "numpy.random.shuffle", "numpy.array", "range", "numpy.array", "range", "np.array.sum", "int", "class_order.copy.index", "[].append", "[].append", "int", "class_order.copy.index", "[].append", "[].append", "len", "data.keys", "taskcla.append", "os.path.join", "os.path.join", "numpy.unique", "range", "str", "os.path.isabs", "os.path.join", "os.path.isabs", "os.path.join", "numpy.unique", "range", "list", "random.sample", "random.sample.sort", "range", "int", "len", "[].append", "[].append", "[].pop", "[].pop", "numpy.where", "numpy.round", "numpy.asarray", "len"], "function", ["None"], ["", "", "def", "get_data", "(", "path", ",", "num_tasks", ",", "nc_first_task", ",", "validation", ",", "shuffle_classes", ",", "class_order", "=", "None", ",", "val_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"Prepare data: dataset splits, task partition, class order\"\"\"", "\n", "\n", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "\n", "# read filenames and labels", "\n", "if", "val_only", ":", "\n", "        ", "trn_lines", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'val.lst'", ")", ",", "dtype", "=", "'<U200'", ")", "\n", "validation", "=", "0.", "\n", "", "else", ":", "\n", "        ", "trn_lines", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.lst'", ")", ",", "dtype", "=", "'<U200'", ")", "\n", "", "tst_lines", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.lst'", ")", ",", "dtype", "=", "'<U200'", ")", "\n", "\n", "if", "class_order", "is", "None", ":", "\n", "        ", "num_classes", "=", "len", "(", "np", ".", "unique", "(", "trn_lines", "[", ":", ",", "1", "]", ")", ")", "\n", "class_order", "=", "list", "(", "range", "(", "num_classes", ")", ")", "\n", "", "else", ":", "\n", "        ", "num_classes", "=", "len", "(", "class_order", ")", "\n", "class_order", "=", "class_order", ".", "copy", "(", ")", "\n", "", "if", "shuffle_classes", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "class_order", ")", "\n", "\n", "# compute classes per task and num_tasks", "\n", "", "if", "nc_first_task", "is", "None", ":", "\n", "        ", "cpertask", "=", "np", ".", "array", "(", "[", "num_classes", "//", "num_tasks", "]", "*", "num_tasks", ")", "\n", "for", "i", "in", "range", "(", "num_classes", "%", "num_tasks", ")", ":", "\n", "            ", "cpertask", "[", "i", "]", "+=", "1", "\n", "", "", "else", ":", "\n", "        ", "assert", "nc_first_task", "<", "num_classes", ",", "\"first task wants more classes than exist\"", "\n", "remaining_classes", "=", "num_classes", "-", "nc_first_task", "\n", "assert", "remaining_classes", ">=", "(", "num_tasks", "-", "1", ")", ",", "\"at least one class is needed per task\"", "# better minimum 2", "\n", "cpertask", "=", "np", ".", "array", "(", "[", "nc_first_task", "]", "+", "[", "remaining_classes", "//", "(", "num_tasks", "-", "1", ")", "]", "*", "(", "num_tasks", "-", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "remaining_classes", "%", "(", "num_tasks", "-", "1", ")", ")", ":", "\n", "            ", "cpertask", "[", "i", "+", "1", "]", "+=", "1", "\n", "\n", "", "", "assert", "num_classes", "==", "cpertask", ".", "sum", "(", ")", ",", "\"something went wrong, the split does not match num classes\"", "\n", "cpertask_cumsum", "=", "np", ".", "cumsum", "(", "cpertask", ")", "\n", "init_class", "=", "np", ".", "concatenate", "(", "(", "[", "0", "]", ",", "cpertask_cumsum", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# initialize data structure", "\n", "for", "tt", "in", "range", "(", "num_tasks", ")", ":", "\n", "        ", "data", "[", "tt", "]", "=", "{", "}", "\n", "data", "[", "tt", "]", "[", "'name'", "]", "=", "'task-'", "+", "str", "(", "tt", ")", "\n", "data", "[", "tt", "]", "[", "'trn'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "tt", "]", "[", "'val'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "tt", "]", "[", "'tst'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "\n", "# ALL OR TRAIN", "\n", "", "for", "this_image", ",", "this_label", "in", "trn_lines", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isabs", "(", "this_image", ")", ":", "\n", "            ", "this_image", "=", "os", ".", "path", ".", "join", "(", "path", ",", "this_image", ")", "\n", "\n", "", "this_label", "=", "int", "(", "this_label", ")", "\n", "if", "this_label", "not", "in", "class_order", ":", "\n", "            ", "continue", "\n", "# If shuffling is false, it won't change the class number", "\n", "", "this_label", "=", "class_order", ".", "index", "(", "this_label", ")", "\n", "\n", "# add it to the corresponding split", "\n", "this_task", "=", "(", "this_label", ">=", "cpertask_cumsum", ")", ".", "sum", "(", ")", "\n", "data", "[", "this_task", "]", "[", "'trn'", "]", "[", "'x'", "]", ".", "append", "(", "this_image", ")", "\n", "data", "[", "this_task", "]", "[", "'trn'", "]", "[", "'y'", "]", ".", "append", "(", "this_label", "-", "init_class", "[", "this_task", "]", ")", "\n", "\n", "# ALL OR TEST", "\n", "", "for", "this_image", ",", "this_label", "in", "tst_lines", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isabs", "(", "this_image", ")", ":", "\n", "            ", "this_image", "=", "os", ".", "path", ".", "join", "(", "path", ",", "this_image", ")", "\n", "", "this_label", "=", "int", "(", "this_label", ")", "\n", "if", "this_label", "not", "in", "class_order", ":", "\n", "            ", "continue", "\n", "# If shuffling is false, it won't change the class number", "\n", "", "this_label", "=", "class_order", ".", "index", "(", "this_label", ")", "\n", "\n", "# add it to the corresponding split", "\n", "this_task", "=", "(", "this_label", ">=", "cpertask_cumsum", ")", ".", "sum", "(", ")", "\n", "data", "[", "this_task", "]", "[", "'tst'", "]", "[", "'x'", "]", ".", "append", "(", "this_image", ")", "\n", "data", "[", "this_task", "]", "[", "'tst'", "]", "[", "'y'", "]", ".", "append", "(", "this_label", "-", "init_class", "[", "this_task", "]", ")", "\n", "\n", "# check classes", "\n", "", "for", "tt", "in", "range", "(", "num_tasks", ")", ":", "\n", "        ", "data", "[", "tt", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", ")", ")", "\n", "assert", "data", "[", "tt", "]", "[", "'ncla'", "]", "==", "cpertask", "[", "tt", "]", ",", "\"something went wrong splitting classes\"", "\n", "\n", "# validation", "\n", "", "if", "validation", ">", "0.0", ":", "\n", "        ", "for", "tt", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "for", "cc", "in", "range", "(", "data", "[", "tt", "]", "[", "'ncla'", "]", ")", ":", "\n", "                ", "cls_idx", "=", "list", "(", "np", ".", "where", "(", "np", ".", "asarray", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", ")", "==", "cc", ")", "[", "0", "]", ")", "\n", "rnd_img", "=", "random", ".", "sample", "(", "cls_idx", ",", "int", "(", "np", ".", "round", "(", "len", "(", "cls_idx", ")", "*", "validation", ")", ")", ")", "\n", "rnd_img", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "for", "ii", "in", "range", "(", "len", "(", "rnd_img", ")", ")", ":", "\n", "                    ", "data", "[", "tt", "]", "[", "'val'", "]", "[", "'x'", "]", ".", "append", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'x'", "]", "[", "rnd_img", "[", "ii", "]", "]", ")", "\n", "data", "[", "tt", "]", "[", "'val'", "]", "[", "'y'", "]", ".", "append", "(", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", "[", "rnd_img", "[", "ii", "]", "]", ")", "\n", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'x'", "]", ".", "pop", "(", "rnd_img", "[", "ii", "]", ")", "\n", "data", "[", "tt", "]", "[", "'trn'", "]", "[", "'y'", "]", ".", "pop", "(", "rnd_img", "[", "ii", "]", ")", "\n", "\n", "# other", "\n", "", "", "", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", ",", "class_order", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args": [[30, 86], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "int", "os.path.join", "os.path.join", "print", "print"], "function", ["None"], ["def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"\n    Parsing input arguments.\n    \"\"\"", "\n", "# Arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Training the LwF baseline.'", ")", "\n", "\n", "# miscellaneous args", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--models-dir'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Output directory to save the basic step model.'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--datasets'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Dataset or datasets used (default=%(default)s)'", ",", "nargs", "=", "'+'", ",", "metavar", "=", "\"DATASET\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num-tasks'", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of tasks per dataset (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Real batch size, before gradient accumulation (default=%(default)s)'", ")", "\n", "\n", "# training args", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Starting learning rate (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-factor'", ",", "default", "=", "5.", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Learning rate decay factor (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-strat'", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "'Learning rate scheduler strategy (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "default", "=", "0.00001", ",", "type", "=", "float", ",", "required", "=", "False", ",", "\n", "help", "=", "'Weight decay (default=%(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--nepochs'", ",", "default", "=", "200", ",", "type", "=", "int", ",", "required", "=", "False", ",", "\n", "help", "=", "'Number of epochs per training session (default=%(default)s)'", ")", "\n", "\n", "args", ",", "extra_args", "=", "parser", ".", "parse_known_args", "(", "argv", ")", "\n", "args", ".", "datasets", "=", "args", ".", "datasets", "[", "0", "]", "\n", "\n", "# Total number of classes", "\n", "args", ".", "num_classes_total", "=", "dataset_config", "[", "args", ".", "datasets", "]", "[", "'num_classes'", "]", "\n", "\n", "# Number of classes per task", "\n", "args", ".", "num_classes", "=", "int", "(", "args", ".", "num_classes_total", "/", "args", ".", "num_tasks", ")", "\n", "\n", "# Defining training/validation sets lists", "\n", "lists_path", "=", "dataset_config", "[", "args", ".", "datasets", "]", "[", "'path'", "]", "\n", "args", ".", "train_list", "=", "os", ".", "path", ".", "join", "(", "lists_path", ",", "'train_no_val.lst'", ")", "\n", "args", ".", "val_list", "=", "os", ".", "path", ".", "join", "(", "lists_path", ",", "'test.lst'", ")", "\n", "\n", "# Loading dataset statistics", "\n", "images_mean", ",", "_", "=", "dataset_config", "[", "args", ".", "datasets", "]", "[", "'normalize'", "]", "\n", "args", ".", "images_mean", "=", "[", "e", "*", "255", "for", "e", "in", "images_mean", "]", "\n", "\n", "# Printing input arguments", "\n", "print", "(", "\"Input arguments:\"", ")", "\n", "print", "(", "args", ")", "\n", "\n", "return", "args", ",", "extra_args", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.main": [[88, 237], ["lwf.parse_args", "numpy.random.seed", "numpy.zeros", "range", "print", "numpy.arange", "utils_data.prepare_files", "range", "os.path.exists", "os.makedirs", "files_protoset.append", "open", "pickle.dump", "pickle.dump", "pickle.dump", "print", "utils_data.read_data", "tensorflow.train.batch", "tensorflow.one_hot", "tensorflow.reset_default_graph", "utils_icarl.prepare_networks", "utils_icarl.prepare_networks", "tensorflow.Session", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "sess.run", "range", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "sess.run", "utils_resnet.save_model", "open", "pickle.dump", "open", "pickle.dump", "tensorflow.device", "tensorflow.concat", "tensorflow.reduce_mean", "tensorflow.placeholder", "tensorflow.train.MomentumOptimizer", "tf.train.MomentumOptimizer.minimize", "variables_graph2[].assign", "tensorflow.device", "tensorflow.concat", "tensorflow.concat", "order[].astype", "order[].astype", "tensorflow.sigmoid", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.placeholder", "tensorflow.train.MomentumOptimizer", "tf.train.MomentumOptimizer.minimize", "tensorflow.global_variables_initializer", "sess.run", "sess.run", "print", "print", "range", "str", "tensorflow.reduce_sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "range", "tensorflow.stack", "tensorflow.reduce_sum", "tensorflow.concat", "int", "sess.run", "loss_batch.append", "tensorflow.get_collection", "len", "tensorflow.get_collection", "variables_graph[].assign", "numpy.ceil", "len", "numpy.average", "print", "range", "str", "str", "str", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "range", "len", "range", "range", "len", "len", "zip", "numpy.argsort"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.lwf.parse_args", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_data.prepare_files", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_data.read_data", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_icarl.prepare_networks", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_icarl.prepare_networks", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.save_model"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Main training routine.\n    \"\"\"", "\n", "# Parsing input arguments", "\n", "args", ",", "_", "=", "parse_args", "(", "argv", ")", "\n", "\n", "device", "=", "'/gpu:0'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "models_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "models_dir", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Initializing variables", "\n", "class_means", "=", "np", ".", "zeros", "(", "(", "512", ",", "args", ".", "num_tasks", "*", "args", ".", "num_classes", ",", "2", ",", "args", ".", "num_tasks", ")", ")", "\n", "loss_batch", "=", "[", "]", "\n", "files_protoset", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "args", ".", "num_tasks", "*", "args", ".", "num_classes", ")", ":", "\n", "        ", "files_protoset", ".", "append", "(", "[", "]", ")", "\n", "\n", "# Random mixing", "\n", "", "print", "(", "\"Preparing data...\"", ")", "\n", "order", "=", "np", ".", "arange", "(", "args", ".", "num_tasks", "*", "args", ".", "num_classes", ")", "\n", "\n", "# Preparing the files per group of classes", "\n", "files_train", ",", "files_valid", "=", "utils_data", ".", "prepare_files", "(", "args", ".", "train_list", ",", "args", ".", "val_list", ",", "\n", "args", ".", "num_tasks", ",", "args", ".", "num_classes", ")", "\n", "\n", "with", "open", "(", "args", ".", "models_dir", "+", "str", "(", "args", ".", "num_classes", ")", "+", "'settings_resnet.pickle'", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "order", ",", "fp", ")", "\n", "pickle", ".", "dump", "(", "files_valid", ",", "fp", ")", "\n", "pickle", ".", "dump", "(", "files_train", ",", "fp", ")", "\n", "\n", "# Main algorithm", "\n", "", "for", "itera", "in", "range", "(", "args", ".", "num_tasks", ")", ":", "\n", "# Files to load : training samples + protoset", "\n", "        ", "print", "(", "'Batch of classes number {0} arrives ...'", ".", "format", "(", "itera", "+", "1", ")", ")", "\n", "\n", "# Adding the stored exemplars to the training set", "\n", "files_from_cl", "=", "files_train", "[", "itera", "]", "\n", "\n", "# Importing the data reader", "\n", "image_train", ",", "label_train", "=", "utils_data", ".", "read_data", "(", "files_from_cl", "=", "files_from_cl", ")", "\n", "image_batch", ",", "label_batch_0", "=", "tf", ".", "train", ".", "batch", "(", "[", "image_train", ",", "label_train", "]", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "num_threads", "=", "8", ")", "\n", "label_batch", "=", "tf", ".", "one_hot", "(", "label_batch_0", ",", "args", ".", "num_tasks", "*", "args", ".", "num_classes", ")", "\n", "\n", "# Defining the objective for the neural network", "\n", "if", "itera", "==", "0", ":", "\n", "# No distillation", "\n", "            ", "variables_graph", ",", "variables_graph2", ",", "scores", ",", "scores_stored", "=", "utils_icarl", ".", "prepare_networks", "(", "args", ".", "images_mean", ",", "\n", "device", ",", "image_batch", ",", "\n", "args", ".", "num_classes", ",", "\n", "args", ".", "num_tasks", ")", "\n", "\n", "# Define the objective for the neural network: 1 vs all cross_entropy", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "                ", "scores", "=", "tf", ".", "concat", "(", "scores", ",", "0", ")", "\n", "l2_reg", "=", "args", ".", "weight_decay", "*", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ",", "scope", "=", "'ResNet18'", ")", ")", "\n", "loss_class", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "label_batch", ",", "logits", "=", "scores", ")", ")", "\n", "loss", "=", "loss_class", "+", "l2_reg", "\n", "learning_rate", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "]", ")", "\n", "opt", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "learning_rate", ",", "0.9", ")", "\n", "train_step", "=", "opt", ".", "minimize", "(", "loss", ",", "var_list", "=", "variables_graph", ")", "\n", "\n", "", "", "if", "itera", ">", "0", ":", "\n", "# Distillation", "\n", "            ", "variables_graph", ",", "variables_graph2", ",", "scores", ",", "scores_stored", "=", "utils_icarl", ".", "prepare_networks", "(", "args", ".", "images_mean", ",", "\n", "device", ",", "image_batch", ",", "\n", "args", ".", "num_classes", ",", "\n", "args", ".", "num_tasks", ")", "\n", "\n", "# Copying the network to use its predictions as ground truth labels", "\n", "op_assign", "=", "[", "(", "variables_graph2", "[", "i", "]", ")", ".", "assign", "(", "variables_graph", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "variables_graph", ")", ")", "]", "\n", "\n", "# Define the objective for the neural network : 1 vs all cross_entropy + distillation", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "                ", "scores", "=", "tf", ".", "concat", "(", "scores", ",", "0", ")", "\n", "scores_stored", "=", "tf", ".", "concat", "(", "scores_stored", ",", "0", ")", "\n", "old_cl", "=", "(", "order", "[", "range", "(", "itera", "*", "args", ".", "num_classes", ")", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "new_cl", "=", "(", "order", "[", "range", "(", "itera", "*", "args", ".", "num_classes", ",", "args", ".", "num_tasks", "*", "args", ".", "num_classes", ")", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "label_old_classes", "=", "tf", ".", "sigmoid", "(", "tf", ".", "stack", "(", "[", "scores_stored", "[", ":", ",", "i", "]", "for", "i", "in", "old_cl", "]", ",", "axis", "=", "1", ")", ")", "\n", "label_new_classes", "=", "tf", ".", "stack", "(", "[", "label_batch", "[", ":", ",", "i", "]", "for", "i", "in", "new_cl", "]", ",", "axis", "=", "1", ")", "\n", "pred_old_classes", "=", "tf", ".", "stack", "(", "[", "scores", "[", ":", ",", "i", "]", "for", "i", "in", "old_cl", "]", ",", "axis", "=", "1", ")", "\n", "pred_new_classes", "=", "tf", ".", "stack", "(", "[", "scores", "[", ":", ",", "i", "]", "for", "i", "in", "new_cl", "]", ",", "axis", "=", "1", ")", "\n", "l2_reg", "=", "args", ".", "weight_decay", "*", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ",", "scope", "=", "'ResNet18'", ")", ")", "\n", "loss_class", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "label_old_classes", ",", "logits", "=", "pred_old_classes", ")", ",", "\n", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "label_new_classes", ",", "logits", "=", "pred_new_classes", ")", "]", ",", "1", ")", ")", "\n", "loss", "=", "loss_class", "+", "l2_reg", "\n", "learning_rate", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "]", ")", "\n", "opt", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "learning_rate", ",", "0.9", ")", "\n", "train_step", "=", "opt", ".", "minimize", "(", "loss", ",", "var_list", "=", "variables_graph", ")", "\n", "\n", "# Run the learning phase", "\n", "", "", "with", "tf", ".", "Session", "(", "config", "=", "config", ")", "as", "sess", ":", "\n", "# Launch the data reader", "\n", "            ", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "coord", "=", "coord", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "lr", "=", "args", ".", "lr", "\n", "\n", "# Run the loading of the weights for the learning network and the copy network", "\n", "if", "itera", ">", "0", ":", "\n", "                ", "void0", "=", "sess", ".", "run", "(", "[", "(", "variables_graph", "[", "i", "]", ")", ".", "assign", "(", "save_weights", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "variables_graph", ")", ")", "]", ")", "\n", "void1", "=", "sess", ".", "run", "(", "op_assign", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "nepochs", ")", ":", "\n", "                ", "print", "(", "\"Batch of classes {} out of {} batches\"", ".", "format", "(", "itera", "+", "1", ",", "args", ".", "num_tasks", ")", ")", "\n", "print", "(", "'Epoch %i'", "%", "epoch", ")", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "np", ".", "ceil", "(", "len", "(", "files_from_cl", ")", "/", "args", ".", "batch_size", ")", ")", ")", ":", "\n", "                    ", "loss_class_val", ",", "_", ",", "sc", ",", "lab", "=", "sess", ".", "run", "(", "[", "loss_class", ",", "train_step", ",", "scores", ",", "label_batch_0", "]", ",", "\n", "feed_dict", "=", "{", "learning_rate", ":", "lr", "}", ")", "\n", "loss_batch", ".", "append", "(", "loss_class_val", ")", "\n", "\n", "# Plot the training error every 10 batches", "\n", "if", "len", "(", "loss_batch", ")", "==", "10", ":", "\n", "# print(np.mean(loss_batch))", "\n", "                        ", "loss_batch", "=", "[", "]", "\n", "\n", "# Plot the training top 1 accuracy every 80 batches", "\n", "", "if", "(", "i", "+", "1", ")", "%", "80", "==", "0", ":", "\n", "                        ", "stat", "=", "[", "]", "\n", "stat", "+=", "(", "[", "ll", "in", "best", "for", "ll", ",", "best", "in", "zip", "(", "lab", ",", "np", ".", "argsort", "(", "sc", ",", "axis", "=", "1", ")", "[", ":", ",", "-", "1", ":", "]", ")", "]", ")", "\n", "stat", "=", "np", ".", "average", "(", "stat", ")", "\n", "print", "(", "'Training accuracy %f'", "%", "stat", ")", "\n", "\n", "# Decrease the learning by 5 every 10 epoch after 20 epochs at the first learning rate", "\n", "", "", "if", "epoch", "in", "args", ".", "lr_strat", ":", "\n", "                    ", "lr", "/=", "args", ".", "lr_factor", "\n", "\n", "", "", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "threads", ")", "\n", "\n", "# copy weights to store network", "\n", "save_weights", "=", "sess", ".", "run", "(", "[", "variables_graph", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "variables_graph", ")", ")", "]", ")", "\n", "utils_resnet", ".", "save_model", "(", "args", ".", "models_dir", "+", "'model-iteration'", "+", "str", "(", "args", ".", "num_classes", ")", "+", "'-%i.pickle'", "%", "itera", ",", "\n", "scope", "=", "'ResNet18'", ",", "sess", "=", "sess", ")", "\n", "\n", "# Reset the graph", "\n", "", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "# Pickle class means and protoset", "\n", "with", "open", "(", "args", ".", "models_dir", "+", "str", "(", "args", ".", "num_classes", ")", "+", "'class_means.pickle'", ",", "'wb'", ")", "as", "fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "class_means", ",", "fp", ")", "\n", "", "with", "open", "(", "args", ".", "models_dir", "+", "str", "(", "args", ".", "num_classes", ")", "+", "'files_protoset.pickle'", ",", "'wb'", ")", "as", "fp", ":", "\n", "            ", "pickle", ".", "dump", "(", "files_protoset", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.relu": [[5, 10], ["tensorflow.maximum", "tensorflow.nn.relu"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["def", "relu", "(", "x", ",", "name", ",", "alpha", ")", ":", "\n", "    ", "if", "alpha", ">", "0", ":", "\n", "        ", "return", "tf", ".", "maximum", "(", "alpha", "*", "x", ",", "x", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "relu", "(", "x", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.get_variable": [[12, 18], ["tensorflow.device", "tensorflow.get_variable"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable"], ["", "", "def", "get_variable", "(", "name", ",", "shape", ",", "dtype", ",", "initializer", ",", "trainable", "=", "True", ",", "regularizer", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "        ", "var", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "shape", ",", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "initializer", ",", "regularizer", "=", "regularizer", ",", "trainable", "=", "trainable", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.conv": [[20, 45], ["tensorflow.contrib.layers.xavier_initializer_conv2d", "inp.get_shape().as_list", "inp.get_shape().as_list", "inp.get_shape().as_list", "inp.get_shape().as_list", "tensorflow.variable_scope", "utils_resnet.get_variable", "utils_resnet.get_variable", "tensorflow.add", "relu.set_shape", "tensorflow.add", "utils_resnet.relu", "inp.get_shape", "inp.get_shape", "inp.get_shape", "inp.get_shape", "tensorflow.zeros_initializer", "tensorflow.nn.atrous_conv2d", "tensorflow.nn.conv2d"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["", "def", "conv", "(", "inp", ",", "name", ",", "size", ",", "out_channels", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "dilation", "=", "None", ",", "padding", "=", "'SAME'", ",", "apply_relu", "=", "True", ",", "alpha", "=", "0.0", ",", "bias", "=", "True", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer_conv2d", "(", ")", ")", ":", "\n", "    ", "batch_size", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "res1", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "res2", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "in_channels", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "W", "=", "get_variable", "(", "\"W\"", ",", "shape", "=", "[", "size", ",", "size", ",", "in_channels", ",", "out_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "initializer", ",", "regularizer", "=", "tf", ".", "nn", ".", "l2_loss", ")", "\n", "b", "=", "get_variable", "(", "\"b\"", ",", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "out_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "trainable", "=", "bias", ")", "\n", "\n", "if", "dilation", ":", "\n", "            ", "assert", "(", "strides", "==", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "out", "=", "tf", ".", "add", "(", "tf", ".", "nn", ".", "atrous_conv2d", "(", "inp", ",", "W", ",", "rate", "=", "dilation", ",", "padding", "=", "padding", ")", ",", "b", ",", "name", "=", "'convolution'", ")", "\n", "out", ".", "set_shape", "(", "[", "batch_size", ",", "res1", ",", "res2", ",", "out_channels", "]", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "tf", ".", "add", "(", "tf", ".", "nn", ".", "conv2d", "(", "inp", ",", "W", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", ",", "b", ",", "name", "=", "'convolution'", ")", "\n", "\n", "", "if", "apply_relu", ":", "\n", "            ", "out", "=", "relu", "(", "out", ",", "alpha", "=", "alpha", ",", "name", "=", "'relu'", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.softmax": [[47, 54], ["tensorflow.reduce_max", "tensorflow.exp", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "softmax", "(", "target", ",", "axis", ",", "name", "=", "None", ")", ":", "\n", "    ", "max_axis", "=", "tf", ".", "reduce_max", "(", "target", ",", "axis", ",", "keep_dims", "=", "True", ")", "\n", "target_exp", "=", "tf", ".", "exp", "(", "target", "-", "max_axis", ")", "\n", "normalize", "=", "tf", ".", "reduce_sum", "(", "target_exp", ",", "axis", ",", "keep_dims", "=", "True", ")", "\n", "softmax", "=", "target_exp", "/", "normalize", "\n", "\n", "return", "softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.batch_norm": [[56, 80], ["inp.get_shape().as_list", "tensorflow.variable_scope", "utils_resnet.get_variable", "utils_resnet.get_variable", "utils_resnet.get_variable", "utils_resnet.get_variable", "tensorflow.nn.moments", "get_variable.assign", "get_variable.assign", "tensorflow.nn.batch_normalization", "inp.get_shape", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.control_dependencies", "tensorflow.nn.batch_normalization"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable"], ["", "def", "batch_norm", "(", "inp", ",", "name", ",", "phase", ",", "decay", "=", "0.9", ")", ":", "\n", "    ", "channels", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "moving_mean", "=", "get_variable", "(", "\"mean\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "moving_variance", "=", "get_variable", "(", "\"var\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "offset", "=", "get_variable", "(", "\"offset\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "scale", "=", "get_variable", "(", "\"scale\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "\n", "regularizer", "=", "tf", ".", "nn", ".", "l2_loss", ")", "\n", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "inp", ",", "axes", "=", "[", "0", ",", "1", ",", "2", "]", ",", "shift", "=", "moving_mean", ")", "\n", "\n", "mean_op", "=", "moving_mean", ".", "assign", "(", "decay", "*", "moving_mean", "+", "(", "1", "-", "decay", ")", "*", "mean", ")", "\n", "var_op", "=", "moving_variance", ".", "assign", "(", "decay", "*", "moving_variance", "+", "(", "1", "-", "decay", ")", "*", "variance", ")", "\n", "\n", "assert", "(", "phase", "in", "[", "'train'", ",", "'test'", "]", ")", "\n", "if", "phase", "==", "'train'", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "mean_op", ",", "var_op", "]", ")", ":", "\n", "                ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "inp", ",", "mean", ",", "variance", ",", "offset", ",", "scale", ",", "0.01", ",", "name", "=", "'norm'", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "inp", ",", "moving_mean", ",", "moving_variance", ",", "offset", ",", "scale", ",", "0.01", ",", "name", "=", "'norm'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.pool": [[82, 95], ["tensorflow.variable_scope", "tensorflow.nn.max_pool", "tensorflow.nn.avg_pool"], "function", ["None"], ["", "", "", "def", "pool", "(", "inp", ",", "name", ",", "kind", ",", "size", ",", "stride", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "assert", "kind", "in", "[", "'max'", ",", "'avg'", "]", "\n", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", "\n", "sizes", "=", "[", "1", ",", "size", ",", "size", ",", "1", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "if", "kind", "==", "'max'", ":", "\n", "            ", "out", "=", "tf", ".", "nn", ".", "max_pool", "(", "inp", ",", "sizes", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "kind", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "tf", ".", "nn", ".", "avg_pool", "(", "inp", ",", "sizes", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "kind", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.ResNet18": [[97, 160], ["utils_resnet.conv", "utils_resnet.batch_norm", "utils_resnet.pool", "utils_resnet.ResNet18.residual_block"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.conv", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.batch_norm", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.pool"], ["", "def", "ResNet18", "(", "inp", ",", "phase", ",", "num_outputs", "=", "1000", ",", "alpha", "=", "0.0", ")", ":", "\n", "    ", "def", "residual_block", "(", "inp", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'a'", ",", "increase_dim", "=", "False", ",", "last", "=", "False", ")", ":", "\n", "        ", "input_num_filters", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "if", "increase_dim", ":", "\n", "            ", "first_stride", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", "\n", "out_num_filters", "=", "input_num_filters", "*", "2", "\n", "", "else", ":", "\n", "            ", "first_stride", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "out_num_filters", "=", "input_num_filters", "\n", "\n", "", "layer", "=", "conv", "(", "inp", ",", "'resconv1'", "+", "nom", ",", "size", "=", "3", ",", "strides", "=", "first_stride", ",", "\n", "out_channels", "=", "out_num_filters", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_resconv1'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "layer", "=", "conv", "(", "layer", ",", "'resconv2'", "+", "nom", ",", "size", "=", "3", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "out_channels", "=", "out_num_filters", ",", "\n", "apply_relu", "=", "False", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_resconv2'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "\n", "if", "increase_dim", ":", "\n", "            ", "projection", "=", "conv", "(", "inp", ",", "'projconv'", "+", "nom", ",", "size", "=", "1", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "out_channels", "=", "out_num_filters", ",", "\n", "alpha", "=", "alpha", ",", "apply_relu", "=", "False", ",", "padding", "=", "'SAME'", ",", "bias", "=", "False", ")", "\n", "projection", "=", "batch_norm", "(", "projection", ",", "'batch_norm_projconv'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "if", "last", ":", "\n", "                ", "block", "=", "layer", "+", "projection", "\n", "", "else", ":", "\n", "                ", "block", "=", "layer", "+", "projection", "\n", "block", "=", "tf", ".", "nn", ".", "relu", "(", "block", ",", "name", "=", "'relu'", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "last", ":", "\n", "                ", "block", "=", "layer", "+", "inp", "\n", "", "else", ":", "\n", "                ", "block", "=", "layer", "+", "inp", "\n", "block", "=", "tf", ".", "nn", ".", "relu", "(", "block", ",", "name", "=", "'relu'", ")", "\n", "\n", "", "", "return", "block", "\n", "\n", "# First conv", "\n", "", "layer", "=", "conv", "(", "inp", ",", "\"conv1\"", ",", "size", "=", "7", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "out_channels", "=", "64", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_1'", ",", "phase", "=", "phase", ")", "\n", "layer", "=", "pool", "(", "layer", ",", "'pool1'", ",", "'max'", ",", "size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "# First stack of residual blocks", "\n", "for", "letter", "in", "'ab'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Second stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'c'", ",", "increase_dim", "=", "True", ")", "\n", "for", "letter", "in", "'d'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Third stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'e'", ",", "increase_dim", "=", "True", ")", "\n", "for", "letter", "in", "'f'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Fourth stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'g'", ",", "increase_dim", "=", "True", ")", "\n", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'h'", ",", "increase_dim", "=", "False", ",", "last", "=", "True", ")", "\n", "\n", "layer", "=", "pool", "(", "layer", ",", "'pool_last'", ",", "'avg'", ",", "size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "'VALID'", ")", "\n", "layer", "=", "conv", "(", "layer", ",", "name", "=", "'fc'", ",", "size", "=", "1", ",", "out_channels", "=", "num_outputs", ",", "padding", "=", "'VALID'", ",", "\n", "apply_relu", "=", "False", ",", "alpha", "=", "alpha", ")", "[", ":", ",", "0", ",", "0", ",", ":", "]", "\n", "\n", "return", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.get_weight_initializer": [[162, 171], ["tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "params.items", "tensorflow.get_variable().assign", "initializer.append", "tensorflow.get_variable"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable"], ["", "def", "get_weight_initializer", "(", "params", ")", ":", "\n", "    ", "initializer", "=", "[", "]", "\n", "\n", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "for", "layer", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "op", "=", "tf", ".", "get_variable", "(", "'%s'", "%", "layer", ")", ".", "assign", "(", "value", ")", "\n", "initializer", ".", "append", "(", "op", ")", "\n", "", "return", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_resnet.save_model": [[173, 178], ["tensorflow.get_collection", "pickle.dump", "open", "sess.run", "v.name.split"], "function", ["None"], ["", "def", "save_model", "(", "name", ",", "scope", ",", "sess", ")", ":", "\n", "    ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "scope", "=", "scope", ")", "\n", "d", "=", "[", "(", "v", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", ",", "sess", ".", "run", "(", "v", ")", ")", "for", "v", "in", "variables", "]", "\n", "\n", "pickle", ".", "dump", "(", "d", ",", "open", "(", "name", ",", "'wb'", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu": [[9, 14], ["tensorflow.maximum", "tensorflow.nn.relu"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["def", "relu", "(", "x", ",", "name", ",", "alpha", ")", ":", "\n", "    ", "if", "alpha", ">", "0", ":", "\n", "        ", "return", "tf", ".", "maximum", "(", "alpha", "*", "x", ",", "x", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "relu", "(", "x", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable": [[16, 22], ["tensorflow.device", "tensorflow.get_variable"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable"], ["", "", "def", "get_variable", "(", "name", ",", "shape", ",", "dtype", ",", "initializer", ",", "trainable", "=", "True", ",", "regularizer", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "        ", "var", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "shape", ",", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "initializer", ",", "regularizer", "=", "regularizer", ",", "trainable", "=", "trainable", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.conv": [[24, 49], ["tensorflow.contrib.layers.xavier_initializer_conv2d", "inp.get_shape().as_list", "inp.get_shape().as_list", "inp.get_shape().as_list", "inp.get_shape().as_list", "tensorflow.variable_scope", "tf_resnet.get_variable", "tf_resnet.get_variable", "tensorflow.add", "relu.set_shape", "tensorflow.add", "tf_resnet.relu", "inp.get_shape", "inp.get_shape", "inp.get_shape", "inp.get_shape", "tensorflow.zeros_initializer", "tensorflow.nn.atrous_conv2d", "tensorflow.nn.conv2d"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.relu"], ["", "def", "conv", "(", "inp", ",", "name", ",", "size", ",", "out_channels", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "dilation", "=", "None", ",", "padding", "=", "'SAME'", ",", "apply_relu", "=", "True", ",", "alpha", "=", "0.0", ",", "bias", "=", "True", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer_conv2d", "(", ")", ")", ":", "\n", "    ", "batch_size", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "res1", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "res2", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "in_channels", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "W", "=", "get_variable", "(", "\"W\"", ",", "shape", "=", "[", "size", ",", "size", ",", "in_channels", ",", "out_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "initializer", ",", "regularizer", "=", "tf", ".", "nn", ".", "l2_loss", ")", "\n", "b", "=", "get_variable", "(", "\"b\"", ",", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "out_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "trainable", "=", "bias", ")", "\n", "\n", "if", "dilation", ":", "\n", "            ", "assert", "(", "strides", "==", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "out", "=", "tf", ".", "add", "(", "tf", ".", "nn", ".", "atrous_conv2d", "(", "inp", ",", "W", ",", "rate", "=", "dilation", ",", "padding", "=", "padding", ")", ",", "b", ",", "name", "=", "'convolution'", ")", "\n", "out", ".", "set_shape", "(", "[", "batch_size", ",", "res1", ",", "res2", ",", "out_channels", "]", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "tf", ".", "add", "(", "tf", ".", "nn", ".", "conv2d", "(", "inp", ",", "W", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", ",", "b", ",", "name", "=", "'convolution'", ")", "\n", "\n", "", "if", "apply_relu", ":", "\n", "            ", "out", "=", "relu", "(", "out", ",", "alpha", "=", "alpha", ",", "name", "=", "'relu'", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.softmax": [[51, 58], ["tensorflow.reduce_max", "tensorflow.exp", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "softmax", "(", "target", ",", "axis", ",", "name", "=", "None", ")", ":", "\n", "    ", "max_axis", "=", "tf", ".", "reduce_max", "(", "target", ",", "axis", ",", "keep_dims", "=", "True", ")", "\n", "target_exp", "=", "tf", ".", "exp", "(", "target", "-", "max_axis", ")", "\n", "normalize", "=", "tf", ".", "reduce_sum", "(", "target_exp", ",", "axis", ",", "keep_dims", "=", "True", ")", "\n", "softmax", "=", "target_exp", "/", "normalize", "\n", "\n", "return", "softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.batch_norm": [[60, 85], ["inp.get_shape().as_list", "tensorflow.variable_scope", "tf_resnet.get_variable", "tf_resnet.get_variable", "tf_resnet.get_variable", "tf_resnet.get_variable", "tensorflow.nn.moments", "get_variable.assign", "get_variable.assign", "tensorflow.nn.batch_normalization", "inp.get_shape", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.control_dependencies", "tensorflow.nn.batch_normalization"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable"], ["", "def", "batch_norm", "(", "inp", ",", "name", ",", "phase", ",", "decay", "=", "0.9", ")", ":", "\n", "    ", "channels", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "moving_mean", "=", "get_variable", "(", "\"mean\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "trainable", "=", "False", ")", "\n", "moving_variance", "=", "get_variable", "(", "\"var\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "offset", "=", "get_variable", "(", "\"offset\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "scale", "=", "get_variable", "(", "\"scale\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "regularizer", "=", "tf", ".", "nn", ".", "l2_loss", ")", "\n", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "inp", ",", "axes", "=", "[", "0", ",", "1", ",", "2", "]", ",", "shift", "=", "moving_mean", ")", "\n", "\n", "mean_op", "=", "moving_mean", ".", "assign", "(", "decay", "*", "moving_mean", "+", "(", "1", "-", "decay", ")", "*", "mean", ")", "\n", "var_op", "=", "moving_variance", ".", "assign", "(", "decay", "*", "moving_variance", "+", "(", "1", "-", "decay", ")", "*", "variance", ")", "\n", "\n", "assert", "(", "phase", "in", "[", "'train'", ",", "'test'", "]", ")", "\n", "if", "phase", "==", "'train'", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "mean_op", ",", "var_op", "]", ")", ":", "\n", "                ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "inp", ",", "mean", ",", "variance", ",", "offset", ",", "scale", ",", "0.01", ",", "name", "=", "'norm'", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "inp", ",", "moving_mean", ",", "moving_variance", ",", "offset", ",", "scale", ",", "0.01", ",", "name", "=", "'norm'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.pool": [[87, 100], ["tensorflow.variable_scope", "tensorflow.nn.max_pool", "tensorflow.nn.avg_pool"], "function", ["None"], ["", "", "", "def", "pool", "(", "inp", ",", "name", ",", "kind", ",", "size", ",", "stride", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "assert", "kind", "in", "[", "'max'", ",", "'avg'", "]", "\n", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", "\n", "sizes", "=", "[", "1", ",", "size", ",", "size", ",", "1", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "if", "kind", "==", "'max'", ":", "\n", "            ", "out", "=", "tf", ".", "nn", ".", "max_pool", "(", "inp", ",", "sizes", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "kind", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "tf", ".", "nn", ".", "avg_pool", "(", "inp", ",", "sizes", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "kind", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.ResNet18": [[102, 166], ["tf_resnet.conv", "tf_resnet.batch_norm", "tf_resnet.pool", "tf_resnet.ResNet18.residual_block"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.conv", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.batch_norm", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.pool"], ["", "def", "ResNet18", "(", "inp", ",", "phase", ",", "num_outputs", "=", "1000", ",", "alpha", "=", "0.0", ")", ":", "\n", "    ", "def", "residual_block", "(", "inp", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'a'", ",", "increase_dim", "=", "False", ",", "last", "=", "False", ")", ":", "\n", "        ", "input_num_filters", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "if", "increase_dim", ":", "\n", "            ", "first_stride", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", "\n", "out_num_filters", "=", "input_num_filters", "*", "2", "\n", "", "else", ":", "\n", "            ", "first_stride", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "out_num_filters", "=", "input_num_filters", "\n", "\n", "", "layer", "=", "conv", "(", "inp", ",", "'resconv1'", "+", "nom", ",", "size", "=", "3", ",", "strides", "=", "first_stride", ",", "\n", "out_channels", "=", "out_num_filters", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_resconv1'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "layer", "=", "conv", "(", "layer", ",", "'resconv2'", "+", "nom", ",", "size", "=", "3", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "out_channels", "=", "out_num_filters", ",", "apply_relu", "=", "False", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_resconv2'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "\n", "if", "increase_dim", ":", "\n", "            ", "projection", "=", "conv", "(", "inp", ",", "'projconv'", "+", "nom", ",", "size", "=", "1", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "out_channels", "=", "out_num_filters", ",", "alpha", "=", "alpha", ",", "\n", "apply_relu", "=", "False", ",", "padding", "=", "'SAME'", ",", "bias", "=", "False", ")", "\n", "projection", "=", "batch_norm", "(", "projection", ",", "'batch_norm_projconv'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "if", "last", ":", "\n", "                ", "block", "=", "layer", "+", "projection", "\n", "", "else", ":", "\n", "                ", "block", "=", "layer", "+", "projection", "\n", "block", "=", "tf", ".", "nn", ".", "relu", "(", "block", ",", "name", "=", "'relu'", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "last", ":", "\n", "                ", "block", "=", "layer", "+", "inp", "\n", "", "else", ":", "\n", "                ", "block", "=", "layer", "+", "inp", "\n", "block", "=", "tf", ".", "nn", ".", "relu", "(", "block", ",", "name", "=", "'relu'", ")", "\n", "\n", "", "", "return", "block", "\n", "\n", "# First conv", "\n", "", "layer", "=", "conv", "(", "inp", ",", "\"conv1\"", ",", "size", "=", "7", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "out_channels", "=", "64", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_1'", ",", "phase", "=", "phase", ")", "\n", "layer", "=", "pool", "(", "layer", ",", "'pool1'", ",", "'max'", ",", "size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "# First stack of residual blocks", "\n", "for", "letter", "in", "'ab'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Second stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'c'", ",", "increase_dim", "=", "True", ")", "\n", "for", "letter", "in", "'d'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Third stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'e'", ",", "increase_dim", "=", "True", ")", "\n", "for", "letter", "in", "'f'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Fourth stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'g'", ",", "increase_dim", "=", "True", ")", "\n", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'h'", ",", "increase_dim", "=", "False", ",", "last", "=", "True", ")", "\n", "\n", "layer", "=", "pool", "(", "layer", ",", "'pool_last'", ",", "'avg'", ",", "size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "'VALID'", ")", "\n", "layer", "=", "conv", "(", "layer", ",", "name", "=", "'fc'", ",", "size", "=", "1", ",", "out_channels", "=", "num_outputs", ",", "padding", "=", "'VALID'", ",", "apply_relu", "=", "False", ",", "alpha", "=", "alpha", ")", "[", ":", ",", "\n", "0", ",", "0", ",", ":", "]", "\n", "\n", "return", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_weight_initializer": [[167, 176], ["tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "params.items", "tensorflow.get_variable().assign", "initializer.append", "tensorflow.get_variable"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_variable"], ["", "def", "get_weight_initializer", "(", "params", ")", ":", "\n", "    ", "initializer", "=", "[", "]", "\n", "\n", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "for", "layer", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "op", "=", "tf", ".", "get_variable", "(", "'%s'", "%", "layer", ")", ".", "assign", "(", "value", ")", "\n", "initializer", ".", "append", "(", "op", ")", "\n", "", "return", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.save_model": [[178, 183], ["tensorflow.get_collection", "pickle.dump", "open", "sess.run", "v.name.split"], "function", ["None"], ["", "def", "save_model", "(", "name", ",", "scope", ",", "sess", ")", ":", "\n", "    ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "scope", "=", "scope", ")", "\n", "d", "=", "[", "(", "v", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", ",", "sess", ".", "run", "(", "v", ")", ")", "for", "v", "in", "variables", "]", "\n", "\n", "pickle", ".", "dump", "(", "d", ",", "open", "(", "name", ",", "'wb'", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_icarl.reading_data_and_preparing_network": [[12, 35], ["utils_data.read_data_test", "tensorflow.train.batch", "tensorflow.one_hot", "tensorflow.constant", "tensorflow.reduce_mean", "dict", "utils_resnet.get_weight_initializer", "tensorflow.variable_scope", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "pickle.load", "tensorflow.device", "utils_resnet.ResNet18", "tensorflow.get_default_graph", "open", "tf.get_default_graph.get_operation_by_name", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_data.read_data_test", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.get_weight_initializer", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.ResNet18"], ["def", "reading_data_and_preparing_network", "(", "images_mean", ",", "files_from_cl", ",", "device", ",", "itera", ",", "batch_size", ",", "nb_groups", ",", "nb_cl", ",", "\n", "save_path", ")", ":", "\n", "    ", "image_train", ",", "label_train", ",", "file_string", "=", "utils_data", ".", "read_data_test", "(", "files_from_cl", "=", "files_from_cl", ")", "\n", "image_batch", ",", "label_batch", ",", "file_string_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "image_train", ",", "label_train", ",", "file_string", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "num_threads", "=", "8", ")", "\n", "label_batch_one_hot", "=", "tf", ".", "one_hot", "(", "label_batch", ",", "nb_groups", "*", "nb_cl", ")", "\n", "\n", "# Network and loss function", "\n", "mean_img", "=", "tf", ".", "constant", "(", "images_mean", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "3", "]", ",", "name", "=", "'img_mean'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'ResNet18'", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "scores", "=", "utils_resnet", ".", "ResNet18", "(", "image_batch", "-", "mean_img", ",", "phase", "=", "'test'", ",", "num_outputs", "=", "nb_cl", "*", "nb_groups", ")", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "op_feature_map", "=", "graph", ".", "get_operation_by_name", "(", "'ResNet18/pool_last/avg'", ")", ".", "outputs", "[", "0", "]", "\n", "\n", "", "", "loss_class", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "label_batch_one_hot", ",", "logits", "=", "scores", ")", ")", "\n", "\n", "# Initialization", "\n", "params", "=", "dict", "(", "\n", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'model-iteration'", "+", "str", "(", "nb_cl", ")", "+", "'-%i.pickle'", ")", "%", "itera", ",", "'rb'", ")", ")", ")", "\n", "inits", "=", "utils_resnet", ".", "get_weight_initializer", "(", "params", ")", "\n", "\n", "return", "inits", ",", "scores", ",", "label_batch", ",", "loss_class", ",", "file_string_batch", ",", "op_feature_map", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_icarl.load_class_in_feature_space": [[37, 56], ["range", "numpy.concatenate", "numpy.array", "numpy.array", "int", "sess.run", "np.array.extend", "np.array.extend", "np.concatenate.append", "numpy.ceil", "numpy.linalg.norm", "len"], "function", ["None"], ["", "def", "load_class_in_feature_space", "(", "files_from_cl", ",", "batch_size", ",", "scores", ",", "label_batch", ",", "loss_class", ",", "file_string_batch", ",", "\n", "op_feature_map", ",", "sess", ")", ":", "\n", "    ", "processed_files", "=", "[", "]", "\n", "label_dico", "=", "[", "]", "\n", "d_tot", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "np", ".", "ceil", "(", "len", "(", "files_from_cl", ")", "/", "batch_size", ")", "+", "1", ")", ")", ":", "\n", "        ", "sc", ",", "l", ",", "loss", ",", "files_tmp", ",", "feat_map_tmp", "=", "sess", ".", "run", "(", "\n", "[", "scores", ",", "label_batch", ",", "loss_class", ",", "file_string_batch", ",", "op_feature_map", "]", ")", "\n", "processed_files", ".", "extend", "(", "files_tmp", ")", "\n", "label_dico", ".", "extend", "(", "l", ")", "\n", "mapped_prototypes", "=", "feat_map_tmp", "[", ":", ",", "0", ",", "0", ",", ":", "]", "# plater la couche de sortie", "\n", "d_tot", ".", "append", "(", "mapped_prototypes", ".", "T", "/", "np", ".", "linalg", ".", "norm", "(", "mapped_prototypes", ".", "T", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "d_tot", "=", "np", ".", "concatenate", "(", "d_tot", ",", "axis", "=", "1", ")", "\n", "processed_files", "=", "np", ".", "array", "(", "processed_files", ")", "\n", "label_dico", "=", "np", ".", "array", "(", "label_dico", ")", "\n", "\n", "return", "d_tot", ",", "processed_files", ",", "label_dico", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_icarl.prepare_networks": [[58, 85], ["tensorflow.constant", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "tensorflow.device", "utils_resnet.ResNet18", "scores.append", "tensorflow.device", "utils_resnet.ResNet18", "scores_stored.append"], "function", ["home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.ResNet18", "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.tf_resnet.ResNet18"], ["", "def", "prepare_networks", "(", "images_mean", ",", "device", ",", "image_batch", ",", "nb_cl", ",", "nb_groups", ")", ":", "\n", "    ", "mean_img", "=", "tf", ".", "constant", "(", "images_mean", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "3", "]", ",", "name", "=", "'img_mean'", ")", "\n", "scores", "=", "[", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'ResNet18'", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "score", "=", "utils_resnet", ".", "ResNet18", "(", "image_batch", "-", "mean_img", ",", "phase", "=", "'train'", ",", "num_outputs", "=", "nb_cl", "*", "nb_groups", ")", "\n", "scores", ".", "append", "(", "score", ")", "\n", "\n", "", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "\n", "# First score and initialization", "\n", "", "variables_graph", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "scope", "=", "'ResNet18'", ")", "\n", "scores_stored", "=", "[", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'store_ResNet18'", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "score", "=", "utils_resnet", ".", "ResNet18", "(", "image_batch", "-", "mean_img", ",", "phase", "=", "'test'", ",", "num_outputs", "=", "nb_cl", "*", "nb_groups", ")", "\n", "scores_stored", ".", "append", "(", "score", ")", "\n", "\n", "", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "\n", "", "variables_graph2", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "scope", "=", "'store_ResNet18'", ")", "\n", "\n", "return", "variables_graph", ",", "variables_graph2", ",", "scores", ",", "scores_stored", "\n", "", ""]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_data.read_data": [[5, 20], ["numpy.array", "numpy.array", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.train.slice_input_producer", "tensorflow.read_file", "tensorflow.image.resize_images", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right", "len", "len", "tensorflow.image.decode_jpeg", "e.split", "e.split"], "function", ["None"], ["def", "read_data", "(", "files_from_cl", ")", ":", "\n", "    ", "image_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "0", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "labels_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "1", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "\n", "assert", "(", "len", "(", "image_list", ")", "==", "len", "(", "labels_list", ")", ")", "\n", "images", "=", "tf", ".", "convert_to_tensor", "(", "image_list", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "labels", "=", "tf", ".", "convert_to_tensor", "(", "labels_list", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "input_queue", "=", "tf", ".", "train", ".", "slice_input_producer", "(", "[", "images", ",", "labels", "]", ",", "shuffle", "=", "True", ",", "capacity", "=", "2000", ")", "\n", "image_file_content", "=", "tf", ".", "read_file", "(", "input_queue", "[", "0", "]", ")", "\n", "label", "=", "input_queue", "[", "1", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "tf", ".", "image", ".", "decode_jpeg", "(", "image_file_content", ",", "channels", "=", "3", ")", ",", "[", "256", ",", "256", "]", ")", "\n", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "224", ",", "224", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "\n", "return", "image", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_data.read_data_test": [[22, 38], ["numpy.array", "numpy.array", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.train.slice_input_producer", "tensorflow.read_file", "tensorflow.image.resize_images", "len", "len", "tensorflow.image.decode_jpeg", "e.split", "e.split"], "function", ["None"], ["", "def", "read_data_test", "(", "files_from_cl", ")", ":", "\n", "    ", "image_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "0", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "labels_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "1", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "files_list", "=", "files_from_cl", "# or put only the base name?", "\n", "\n", "assert", "(", "len", "(", "image_list", ")", "==", "len", "(", "labels_list", ")", ")", "\n", "images", "=", "tf", ".", "convert_to_tensor", "(", "image_list", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "files", "=", "tf", ".", "convert_to_tensor", "(", "files_list", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "labels", "=", "tf", ".", "convert_to_tensor", "(", "labels_list", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "input_queue", "=", "tf", ".", "train", ".", "slice_input_producer", "(", "[", "images", ",", "labels", ",", "files", "]", ",", "shuffle", "=", "False", ",", "capacity", "=", "2000", ")", "\n", "image_file_content", "=", "tf", ".", "read_file", "(", "input_queue", "[", "0", "]", ")", "\n", "label", "=", "input_queue", "[", "1", "]", "\n", "file_string", "=", "input_queue", "[", "2", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "tf", ".", "image", ".", "decode_jpeg", "(", "image_file_content", ",", "channels", "=", "3", ")", ",", "[", "224", ",", "224", "]", ")", "\n", "\n", "return", "image", ",", "label", ",", "file_string", "\n", "\n"]], "home.repos.pwc.inspect_result.habibslim_dkt-for-cil.lwf.utils_data.prepare_files": [[40, 100], ["open().readlines", "open().readlines", "len", "len", "range", "range", "line.strip.strip", "line.strip.split", "train_dict.keys", "files_train.append", "len", "len", "line.strip.strip", "line.strip.split", "val_dict.keys", "files_valid.append", "len", "len", "open", "open", "int", "train_dict.keys", "train_dict[].append", "int", "val_dict.keys", "val_dict[].append", "int", "group_images.extend", "int", "group_images.extend", "int", "int"], "function", ["None"], ["", "def", "prepare_files", "(", "train_images_path", ",", "val_images_path", ",", "nb_groups", ",", "nb_cl", ")", ":", "\n", "    ", "files_train", "=", "[", "]", "\n", "files_valid", "=", "[", "]", "\n", "\n", "train_list", "=", "open", "(", "train_images_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "val_list", "=", "open", "(", "val_images_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "\n", "total_train_images_number", "=", "len", "(", "train_list", ")", "\n", "total_val_images_number", "=", "len", "(", "val_list", ")", "\n", "\n", "train_dict", "=", "{", "}", "\n", "for", "line", "in", "train_list", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "img_path_class", "=", "line", ".", "split", "(", ")", "\n", "image_path", ",", "image_class", "=", "img_path_class", "[", "0", "]", ",", "int", "(", "img_path_class", "[", "1", "]", ")", "\n", "if", "image_class", "not", "in", "train_dict", ".", "keys", "(", ")", ":", "\n", "            ", "train_dict", "[", "image_class", "]", "=", "[", "line", "]", "\n", "", "else", ":", "\n", "            ", "train_dict", "[", "image_class", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "", "for", "num", "in", "range", "(", "nb_groups", ")", ":", "\n", "        ", "group_images", "=", "[", "]", "\n", "for", "key", "in", "train_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "num", "*", "nb_cl", "<=", "int", "(", "key", ")", "<", "(", "num", "+", "1", ")", "*", "nb_cl", ":", "\n", "                ", "group_images", ".", "extend", "(", "train_dict", "[", "int", "(", "key", ")", "]", ")", "\n", "", "", "files_train", ".", "append", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "len", "(", "files_train", ")", "==", "nb_groups", ")", "\n", "train_images_number", "=", "0", "\n", "for", "group_images", "in", "files_train", ":", "\n", "        ", "train_images_number", "+=", "len", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "train_images_number", "==", "total_train_images_number", ")", "\n", "\n", "# Same for validation", "\n", "val_dict", "=", "{", "}", "\n", "for", "line", "in", "val_list", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "img_path_class", "=", "line", ".", "split", "(", ")", "\n", "image_path", ",", "image_class", "=", "img_path_class", "[", "0", "]", ",", "int", "(", "img_path_class", "[", "1", "]", ")", "\n", "if", "image_class", "not", "in", "val_dict", ".", "keys", "(", ")", ":", "\n", "            ", "val_dict", "[", "image_class", "]", "=", "[", "line", "]", "\n", "", "else", ":", "\n", "            ", "val_dict", "[", "image_class", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "", "for", "num", "in", "range", "(", "nb_groups", ")", ":", "\n", "        ", "group_images", "=", "[", "]", "\n", "for", "key", "in", "val_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "num", "*", "nb_cl", "<=", "int", "(", "key", ")", "<", "(", "num", "+", "1", ")", "*", "nb_cl", ":", "\n", "                ", "group_images", ".", "extend", "(", "val_dict", "[", "int", "(", "key", ")", "]", ")", "\n", "", "", "files_valid", ".", "append", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "len", "(", "files_valid", ")", "==", "nb_groups", ")", "\n", "val_images_number", "=", "0", "\n", "for", "group_images", "in", "files_valid", ":", "\n", "        ", "val_images_number", "+=", "len", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "val_images_number", "==", "total_val_images_number", ")", "\n", "\n", "return", "files_train", ",", "files_valid", "\n", "", ""]]}